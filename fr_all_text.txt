Une injection sous-cutanée (SC) est une injection réalisée dans l'hypoderme en pratiquant un pli cutané à l'aide des doigts.
Elle est également appelée injection hypodermique.Les sites les plus utilisés sont la ceinture abdominale antéro-latérale et postéro-latérale (souvent le moins douloureux) mais l'on peut également réaliser ce type d'injection sur les bras et les cuisses (au milieu de la face externe).Les injections sous-cutanées les plus fréquentes sont les insulines et les traitements préventifs (et curatifs) des phlébites.Cette voie aboutit à un passage systémique, c'est-à-dire à une diffusion de la substance dans la circulation sanguine où elle pourra avoir un effet pharmacologique.Pour réaliser une injection sous-cutanée, il est nécessaire de pincer la peau et de piquer à 90° avec une aiguille courte et à 45° avec une aiguille longue.
Il ne faut arrêter de pincer qu'une fois l'injection faite avec d'une aiguille courte ou bien relâcher le pli avant d'injecter avec une aiguille longue.
Une gastro-entérite ou gastroentérite est une inflammation du système digestif pouvant entraîner de la nausée, des vomissements, des crampes abdominales, des flatulences et de la diarrhée, ainsi que de la déshydratation, de la fièvre et des céphalées (maux de tête).La gastro-entérite peut être d'origine bactérienne, c'est-à-dire due à la consommation d'eau ou de nourriture contaminée par des bactéries, telles que les colibacilles présents dans les selles.
Des symptômes de gastro-entérite peuvent aussi être dus à des parasites internes, protozoaires ou amibes pathogènes, tel qu'Entamoeba histolytica provoquant la dysenterie amibienne ou amibiase généralement due à des installations sanitaires absentes ou inadéquates.Cependant, dans plus des deux tiers des cas, elle est causée par des virus comme les rotavirus (provoquant en particulier la gastro-entérite infantile), les norovirus (dont le virus de Norwalk), les adénovirus, des calicivirus et des astrovirus.
La gastro-entérite est communément appelée « grippe intestinale » (terme inadéquat mais très répandu), lorsqu’elle est causée par un virus, et « empoisonnement alimentaire » ou plus justement « intoxication alimentaire » lorsque causée par une bactérie.La gastro-entérite peut également révéler une dysenterie des voyageurs, aussi connue sous le terme de diarrhée du voyageur ou tourista.
Celle-ci peut être due à une infection, le plus souvent par des bactéries (notamment Salmonella, Aeromonas, Escherichia coli, Campylobacter, Shigella, Vibrio cholerae (causant le choléra) et Vibrio (non cholérique)).
Parfois, l'infection peut provenir de virus, norovirus (principalement virus de Norwalk), adénovirus, astrovirus, entérovirus, rotavirus.
Plus rarement, la tourista sera causée par des amibes ou protozoaires parasitaires (Cyclospora, Entamoeba histolytica, Cryptosporidium, Giardia ou autre parasite intestinal).La diarrhée s'accompagne souvent de vomissements et de poussées de fièvre, mais les symptômes varient en fonction des individus.
En effet, certains se contentent de vomir, d'autres n'ont aucun symptôme, et certains n'ont que la diarrhée.
Si elle est trop importante, elle peut mener à une déshydratation de l'organisme.Si la diarrhée perdure, elle peut laisser des séquelles sur la paroi intestinale, menant à une pathologie appelée syndrome de malabsorption.Le rotavirus est la cause la plus courante de diarrhée et de déshydratation chez l'enfant, en particulier dans les pays développés.
Dans le monde, on estime que 125 millions de diarrhées sont provoquées annuellement par ce virus (soit plus de 1 900 cas pour 100 000 habitants).
On estime que chaque année, 800 000 personnes meurent de gastro-entérite dans le monde, dont 500 000 enfants de moins de cinq ans, ce qui représente 25 % des morts par diarrhées et 6 % des morts de moins de cinq ans.Aux États-Unis, on estime que le rotavirus touche 80 % des enfants de moins d'un an ; chaque année, 500 000 enfants doivent faire l'objet de soins médicaux, et 50 000 doivent être hospitalisés.En France, lors du pic de l'épidémie hivernale 2005–2006, on estime que 1 850 000 personnes ont consulté leur médecin généraliste en 8 semaines pour une gastro-entérite ; l'incidence a été de 367 cas pour 100 000 habitants (le seuil épidémique étant fixé à 279 cas pour 100 000 habitants),.
La surveillance de l'évolution de l'incidence en France est effectuée par le réseau Sentinelles de l'Inserm qui publie ces données, comme une société de communication spécialisée qui met aussi ces données à la disposition du public.Il s'agit donc d'un important problème de santé publique.
D'autant que chaque année, l'épidémie de gastro-entérite à rotavirus concorde souvent avec les épidémies de bronchiolite et de grippe, pouvant mettre en difficulté les systèmes de soins pédiatriques.On peut remarquer que les gastro-entérites virales sont en recrudescence pendant l’hiver, surtout en Amérique du Nord et en Europe.Les symptômes habituels de la gastro-entérite sont des nausées, la perte d'appétit, crampes abdominales et vomissements qui apparaissent brutalement, de la diarrhée, de la fièvre et des céphalées (maux de tête).
Plus rarement, des vertiges et une hypotension peuvent accompagner les symptômes, sans doute liés à la déshydratation et à la fatigue.Les symptômes communément associés à la gastro-entérite, c'est-à-dire principalement les vomissements et la diarrhée, peuvent également être signes d'un empoisonnement (fruits de mer, champignons toxiques) ou d'infections systémiques (pneumonie, septicémie, etc.).
Par un interrogatoire précis et le contexte clinique, il sera possible d'éliminer ces hypothèses.La gastro-entérite peut parfois déboucher sur des complications telles que la déshydratation, pouvant même conduire à une hospitalisation.
Les personnes à risque sont les jeunes enfants et les nourrissons, les personnes âgées, et les personnes ayant un système immunitaire affaibli par une maladie (VIH par exemple).Les signes de la déshydratation sont une sècheresse de la peau, de la bouche, des yeux, les parties molles du crâne (chez les nourrissons) enfoncées, des faiblesses, des crampes, une perte de poids, et des urines moins fréquentes et plus foncées que d'habitude.Si l'on suspecte une gastro-entérite d'origine bactérienne, il est possible d'effectuer une analyse des selles au laboratoire (coproculture) à la recherche de la bactérie en cause.La plupart des gens se rétablissent d'eux-mêmes en un ou deux jours sans traitement particulier autre que les mesures suivantes :La gastro-entérite d'origine bactérienne se traite par antibiotique, voire par bactériophagique dans les cas graves de dysenterie par germe multirésistant.Outre un éventuel traitement médicamenteux, boire des préparations liquides riches en sels minéraux pour éviter la déshydratation ; la réintroduction précoce des aliments, incluant les fibres alimentaires, aide à contrôler plus rapidement les symptômes.
Parfois cela ne suffit pas.Manger et boire en petites quantités : éviter les breuvages excessivement sucrés qui (par phénomène d'osmose) entretiennent les diarrhées, sans se limiter à la diète BRATT (banane, riz, compote de pomme, thé, et pain grillé).
D'ailleurs, les Centres pour la prévention et le contrôle des maladies américains déconseillent formellement la diète BRATT.Sur ordonnance : dompéridone, métoclopramide, alizapride, métopimazine.Sans ordonnance : diménhydrinate.Sans ordonnance : charbon végétal non activé ou charbon activé (le charbon de bois est utilisé pour ses capacités d'adsorption physique par les forces de Van Der Waals, il absorbe les gaz de différentes provenances, ainsi que les toxines bactériennes, virales et celles du métabolisme, ce qui lui confère un effet antidiarrhéique).Parmi les nutriments ayant un effet clair sur la diarrhée infantile, le zinc a été étudié initialement dans les pays en voie de développement, ce qui a débouché sur la recommandation faite par l'OMS de supplémenter en zinc tout enfant traité pour diarrhée.
Le résultat de cette approche est une baisse de l'utilisation des antibiotiques, une réduction des hospitalisations et une baisse des épisodes d'infection respiratoire basse chez les sujets traités.
Une supplémentation en zinc seule n'est pas souhaitable, du fait de son impact potentiel sur l'absorption de cuivre ou de fer.
L'association de micronutriments semble la meilleure approche.Les liquides et électrolytes perdus de l’organisme doivent absolument être remplacés, si on veut éviter la déshydratation sévère pouvant causer la mort.Pour prévenir la déshydratation, il faut prendre une solution de réhydratation orale.
Cette solution sera absorbée même en présence de vomissements.
C'est le meilleur moyen de remplacer l’eau et les sels perdus, mais cela ne lutte pas contre la diarrhée elle-même.
Cela est indispensable pour les nourrissons et les jeunes enfants qui ont eu plusieurs selles diarrhéiques.
Les enfants allaités doivent continuer à l’être tout en prenant la solution de réhydratation.Les solutions de réhydratation peuvent se retrouver sous diverses formes.
Dans les cas de déshydratation très sévère, on l'administre en soluté, par voie intraveineuse, en hôpital.
On en retrouve également sous forme de liquides prêts à boire, ou sous forme de poudres en sachets appelés sels de réhydratation orale (SRO), à mélanger à de l'eau saine, eau de source ou eau bouillie, vendues en pharmacie sans ordonnance médicale.Bien que pas conseillé par rapport à la solution de réhydratation, on peut temporairement préparer soi-même une alternative à une solution de réhydratation.La gastro-entérite se transmet en consommant des aliments ou de l'eau contaminés, ainsi que par contact direct avec les malades.
En période à risque (hivernale) ou lorsqu'un membre de la famille est malade, les actions suivantes permettent de lutter contre la propagation de la gastro-entérite.
Ce sont des gestes simples comme les suivants, qui permettent d'éviter les épidémies :En 2006, deux vaccins anti-rotavirus ont été mis sur le marché en France.
Leur efficacité a été démontrée contre les souches les plus répandues en Europe et aux États-Unis.
Si, en 2006, le Haut Conseil de la santé publique avait décidé de différer la recommandation pour les nourrissons de moins de 6 mois en raison du coût du vaccin (environ 150 euros), il a revu sa position fin 2013 « sous réserve d’une politique tarifaire conduisant à des ratios coût/efficacité acceptables pour ces deux vaccins ».Au Canada, depuis 2007, il existe un vaccin pentavalent oral à virus vivant contre la gastro-entérite à rotavirus.
Il s'appelle Rotateq (de l'entreprise Merck Frosst).
Il est conçu pour les jeunes enfants.
Il est également disponible en France sur prescription du pédiatre.
La première dose doit être donnée avant la 12e semaine de vie de l'enfant, la 2e deux mois plus tard et la dernière avant que l'enfant ait eu 32 semaines.
Ce vaccin protège à 90 % durant environ 2 ans.Une mutation sur le gène FUT2, présente chez 20 % des Européens, confère une haute résistance, voire une immunité, contre le norovirus, responsable à 85 % des gastro-entérites non bactériennes, en dehors du jeune enfant.
Un système conjugué est un système chimique constitué d'atomes liés par des liaisons covalentes avec au moins une liaison π délocalisée.
Cette délocalisation permet d'envisager plusieurs représentations de Lewis (appelées formes mésomères, résonantes ou canoniques) mettant ainsi en évidence les propriétés chimiques de la molécule.
Le terme « conjugué » a été inventé en 1899 par le chimiste allemand Johannes Thiele.La conjugaison, origine de cette délocalisation, peut être de différentes natures :Ce composé présente - formellement - deux liaisons doubles sur les trois liaisons présentes entre les atomes de carbone.
De fait, les liaisons se délocalisent sur l'ensemble du squelette carboné en apportant un caractère de liaison double sur la liaison centrale (formellement simple) et font apparaitre des charges en bouts de chaîne.Ce type de conjugaison présente un cas particulier, la conjugaison croisée qui intervient quand sur trois liaisons π qui peuvent interagir, deux interagissent entre elles par conjugaison et la troisième est exclue de l'interaction.
Des exemples de conjugaison croisée sont donnés par la benzophénone, les dendralènes, les radialènes ou les fullerènes.Ces systèmes conduisent à une délocalisation générale des électrons sur toutes les orbitales p alignées, parallèles et adjacentes des atomes, ce qui abaisse leur énergie et augmente ainsi leur stabilité.La délocalisation des électrons crée une région où ils n'appartiennent pas à une seule liaison ou atome, mais plutôt à un groupe, les différences de probabilités de présence dans deux régions de l'espace voisines (ici pour une chaîne d'atomes) s'amoindrissent (on donne l'image d'un déplacement continu des électrons entre deux liaisons consécutives).
Ces modifications correspondent à une combinaison de formes mésomères (dites aussi résonantes ou canoniques) telle que l'énergie du système soit minimale (donc il s'agit du minimum absolu de la surface d'énergie potentielle associée aux présences électroniques) : cette notion est parfois présentée par l'introduction d'un pourcentage de localisation de la liaison.Cette stabilisation du système par délocalisation des électrons a des effets sur sa réactivité: elle favorisera par exemple la formation d'un produit plutôt que celle de son isomère, le premier étant stabilisé par mésomérie, ou favorisera la stabilité d'un intermédiaire réactionnel plutôt qu'un autre, orientant la réaction selon un mécanisme plutôt qu'un autre (compétition SN1/SN2 par exemple).Les systèmes conjugués possèdent des propriétés uniques qui donnent des couleurs intenses.
De nombreux pigments utilisent des systèmes d'électrons conjugués, comme la longue chaîne d'hydrocarbure conjuguée du β-carotène, donnant une couleur fortement orangée.
Quand un électron du système absorbe un photon de lumière de la bonne longueur d'onde, il peut être porté à un niveau d'énergie plus élevé (voir particule dans une boîte).
La majorité de ces transitions électroniques se font d'un électron d'une orbitale pi vers une orbitale pi antiliante (π vers π*), un électron non liant peut aussi être déplacé (n vers π*).
Les systèmes conjugués de moins de huit doubles liaisons conjuguées absorbent uniquement dans les ultraviolets et apparaissent incolores à l'œil humain.
À chaque double liaison ajoutée, le système absorbe des photons de plus grande longueur d'onde (et donc de plus basse énergie), et la couleur du composé s'étend du bleu au jaune.
Les composés orange ou rouges ne s'appuient typiquement pas que sur les seules doubles liaisons.L'absorption de la lumière du spectre ultraviolet à visible peut être mesurée avec la spectroscopie UV/Visible.
L'absorption de la lumière forme la base de toute la photochimie.Les systèmes conjugués forment la base des chromophores, qui sont les parties absorbant la lumière d'une molécule, qui peuvent rendre un composé coloré.
De tels chromophores sont souvent présents dans des composés organiques variés, et parfois présents dans les polymères, qui sont colorés ou brillent dans le noir.
Ils sont habituellement causés par les systèmes annulaires conjugués avec des liaisons comme C=O et N=N en plus des liaisons C-C conjuguées.La conjugaison dans les structures cycliques a pour résultat l'aromaticité, une stabilité inhabituelle présente dans certains systèmes conjugués cycliques.Cependant posséder des liaisons simples et doubles en alternance n'est pas nécessairement suffisant à un système pour être conjugué.
Certains hydrocarbures cycliques (comme le cyclooctatétraène) possèdent en effet une alternance liaison simple/double.
Bien que la molécule puisse apparaître plane en ne regardant que sa structure chimique, la molécule ne l'est pas, et adopte typiquement une conformation « bateau ».
Puisque les orbitales p de la molécule ne peuvent pas s'aligner, les électrons ne sont pas partagés entre les atomes de carbone, et le système n'est pas conjugué.
Un essai de vaccin est un essai clinique qui vise à établir l'innocuité et l'efficacité d'un vaccin avant sa licence.Le premier vaccin candidat est identifié par des évaluations précliniques impliquant un criblage à haut débit et une sélection d'antigènes appropriés pour la réponse immunitaire.
Des étapes précliniques sont également nécessaires pour déterminer la plage de dose approximative et les formulations de médicaments appropriées (par exemple, comprimés, injections, etc.).
C'est également l'étape à laquelle les candidats-médicaments sont d'abord pilotés sur un animal expérimental avant de passer à la phase un des tests.
Des vaccins tels que le vaccin antipoliomyélitique oral ont été prétestés pour les effets secondaires et l'immunité chez les singes ainsi que chez les primates non humains.
Les avancées scientifiques récentes ont aidé à utiliser des animaux génétiquement modifiés dans le cadre du protocole préclinique dans l'espoir d'identifier plus précisément les réactions médicamenteuses chez l'homme.
Comprendre l'innocuité des vaccins et la réponse immunitaire aux médicaments, comme la toxicité, sont des éléments essentiels de la phase préclinique.
L'herpès est une maladie virale, contagieuse (sexuellement transmissible si l'herpès est HSV2 ou par simple contact buccal si HSV1), et responsable d'affection de la peau, des muqueuses et parfois du système nerveux, caractérisée par des crises d'éruption vésiculeuse de boutons groupés.
Ces crises d'une quinzaine de jours sont plus ou moins espacées dans le temps ; elles sont déclenchées par de nombreux facteurs, dont une baisse de l'immunité, souvent par un stress, et parfois par l'exposition au soleil,.
La maladie est jugée bénigne chez les sujets en bonne santé, mais peut se révéler très sérieuse chez l'immunodéprimé, le nouveau-né ou la femme enceinte.L'herpès, parfois vécu péniblement, n'est jamais totalement guéri.
Il impose donc au porteur de prendre des précautions, y compris hors des périodes de crises où il reste potentiellement contagieux.Le nom est dérivé du mot grec ἕρπειν (herpein « ramper »), en référence à la propagation des lésions cutanées, impliquant généralement des cloques, observées dans les poussées d'herpès simplex 1 et 2, et de Zona.L'humain est le seul réservoir connu du virus de l'herpès, dont la transmission semble strictement inter-humaine (pour les deux types viraux connus).L'herpès reste sous-diagnostiqué car souvent asymptomatique.
Il est de plus souvent confondu avec une mycose ou une irritation et, la crise ne durant parfois que quelques jours, les patients n'arrivent pas toujours à obtenir un rendez-vous assez tôt avec un médecin.Les évaluations de prévalence varient significativement selon les pays ou les époques.
Ainsi :Les virus HSV-1 et -2 sont connus depuis longtemps.
Ils restent parfois asymptomatiques toute une vie en restant sous forme dormante dans les ganglions nerveux.
Ils peuvent aussi brutalement ou répétitivement se manifester sous des formes génitale et faciale, qui se propagent facilement entre sujets ayant des contacts intimes.La virulence de la primo-infection dépend aussi du type d’herpès ainsi que de sa souche mais aussi de l’âge de l’hôte et de son statut immunitaire.
Ainsi la primo-infection est plus spécialement asymptomatique chez le jeune enfant.Normalement, la primo-infection est asymptomatique et est un élément crucial dans la limitation de la réplication du virus ce qui permet généralement l’évitement des symptômes.
Cependant, quelques individus peuvent expérimenter une infection primaire avec des vésicules d’herpès gingivo-stomatique.
Généralement, l’infection par l’herpès génital, qui peut elle aussi être asymptomatique, peut présenter des lésions génitales ulcérantes accompagnées ou non de symptômes généralisés tels que fièvre et maux de tête,.
Une infection herpétique peut mener à un herpès cornéen.Les infections herpétiques se propagent rarement vers d’autres organes.
Généralement, seuls les patients immunodéprimés ou les femmes enceintes peuvent présenter des complications plus graves telles que par exemple une méningite,.Dans les cas de l'herpès 1 ou communément appelé herpès labial, les manifestations sont fréquentes sur le pourtour de la bouche ou autour des narines, mais également à l'intérieur de la bouche, au fond de la gorge, sur les gencives, sur les joues ou sur le front, voire les yeux.
Pour l'herpès génital (HSV-2), les manifestations se situent principalement près des organes génitaux.
Cependant, il est possible de voir une infection au HSV-1 sur les organes génitaux et une infection HSV-2 dans la région faciale.
De plus, la persistance du virus est définitive, on reste porteur du virus dans les ganglions sensitifs jusqu’à sa mort.La pénétration du virus dans l'organisme se produit à l'occasion d'un contact avec un sujet infecté (même en l'absence de manifestations cutanées visibles) : les virus pénètrent l'hôte quand ils sont déposés sur une brèche cutanéo-muqueuse.
Ils se multiplient dans les cellules épithéliales où ils sont responsables d'une dégénérescence cellulaire avec ballonisation aspécifique.
Ces mécanismes peuvent être à l'origine des manifestations de primo-infection herpétique.Ils rejoignent ensuite le ganglion nerveux correspondant à la zone infectée, par voie centripète, en « remontant » le long des nerfs sensitifs, selon un mécanisme dit « transport rétrograde axoplasmique » (destiné au transport de protéines ou d'autres molécules dans le neurone et parfois impliqué dans la dégénérescence nerveuse quand des neurotoxiques (plomb par exemple) rempruntent cette voie).
Le virus peut circuler rapidement (et dans les deux sens) dans les neurones et  passent facilement d'un neurone à un autre.
Cependant, les types 1 et 2 du virus Herpes simplex ne se fixent pas au neurone de la même manière.Les récurrences herpétiques se produisent lorsque, en réponse à un stress physique ou psychique variable, les virus regagnent la peau pour s'y développer à nouveau.
Ces épisodes sont plus ou moins fréquents d'un individu à l'autre, et d'intensité variable, mais fixes dans leur topographie.Lors de la primo-infection, le système immunitaire entre en lutte contre le virus, inhibant en partie la réplication du HSV dans le corps humain.
Cette première ligne de défense est non spécifique.
Elle est en grande partie orchestrée par les macrophages dans les premières heures de l’infection.
Le HSV induit la production de INF-α/β et de TNF chez les macrophages.
Ces cytokines jouent un rôle d'activateur sur les macrophages eux-mêmes et sur leur production d'espèces réactives de l'oxygène (ERO), qui ont tous deux comme résultat de freiner la prolifération du virus dans les cellules avoisinantes.
Cependant, les virus HSV (1 et 2) contournent la défense de l’hôte en inhibant la présentation de l’antigène de surface des cellules hôte infectées.
Le virus inhibe l'exposition du CMH1 et donc secondairement l'action des T cytotoxiques.
Les virus HSV (1 et 2) s'expriment rapidement après l’invasion de l’hôte, par une protéine ICP47 qui inhibe le transporteur de l'antigène, ainsi l'anticorps ne peut pas exécuter son action de reconnaissance.La primo-infection est parfaitement asymptomatique dans un cas sur deux (et dans la plupart des primo-infection d'herpès génital, pour les deux types d'herpès).Dans l'autre moitié des cas, les manifestations consistent souvent en un bouquet de vésicules translucides devenant rapidement jaunâtres et croûteuses avec des sensations de picotements, de brûlures ou de démangeaisons.
Des infections de la peau (visage, doigts, fesses) peuvent apparaitre alors qu'aucune atteinte de la muqueuse ne se manifeste,.
Certaines lésions sont atypiques et sous-diagnostiquées car confondues avec d’autres dermatoses génitales,.On croyait autrefois que HSV-1 ne causait d'infection que sur la partie supérieure du corps (orofaciale notamment) et que le HSV-2 n'attaquait que la partie inférieure du corps.
Cette idée est abandonnée : « HSV-1 et  HSV-2 peuvent infecter toute région cutanéo-muqueuse ».Les patients symptomatiques et asymptomatiques ont des taux d'excrétion virale identiques.
On ignore encore pourquoi la réactivation du virus tend à être asymptomatique chez certains individus et symptomatiques chez d'autres.Pour les sujets symptomatiques, le nombre d'occurrences, c’est-à-dire de crises, varie selon les individus et dépend de trois facteurs :C'est le classique « bouton de fièvre », essentiellement transmis par contact buccal.La forme la plus connue est la forme labiale (feu sauvage, dans le registre populaire).
Elle évolue via plusieurs stades : Un accès d'herpès labial dure de 8 à 15 jours.
L'affection est contagieuse en tout temps, mais plus encore quand les lésions sont encore présentes (y compris sous forme de croûtes, qu'il ne faut pas toucher, et qui peuvent saigner légèrement sans que cela ne soit visible).C'est avec l'herpès néonatal la forme la plus grave de l'herpès.
Cette encéphalite aiguë nécrosante focale, presque toujours due au HSV-1 (hors infection néonatale), peut survenir à tout âge.
Sans traitement rapide la mortalité dépasse 70 % des cas et le risque de séquelles est élevé chez les survivants.
Rarement (20 cas décrits en France de 1966 à 1998) il s'agit d'une complication de l'herpès chez la femme enceinte.
Elle nécessite donc un diagnostic et un traitement urgents.C'est l'une des complications possibles (mais rares) de l'herpès de la femme enceinte.Elle est généralement anictérique (sans jaunisse) mais caractérisée par une insuffisance hépato-cellulaire majeure.Elle doit être évoquée face à toute hépatopathie de la femme enceinte (après diagnostique différentiel ayant éliminé - surtout au troisième trimestre de grossesse - une stéatose hépatique aiguë gravidique et/ou une cholestase gravidique.C'est avec l'encéphalite herpétique la forme la plus grave de l'herpès.
Sans traitement rapide la mortalité est élevée et des séquelles graves sont inévitables chez les survivants ;Il nécessite un diagnostic et un traitement urgents.Selon les pédiatres et les publications de la Croix verte allemande (de) (DGK), une infection par le virus de l'herpès est particulièrement dangereuse pour les bébés de moins de six semaines,.
Les nouveau-nés dont la mère est déjà infectée par le virus herpès simplex reçoivent les anticorps maternels spécifiques de la classe des immunoglobulines G (IgG) par le placenta dès la 34e semaine de grossesse.
Cette protection naturelle peut protéger contre une infection herpétique ou au moins en réduire la gravité.Plus généralement, il est conseillé d'être vigilant contre les infections d'herpès tout au long de la première année de vie.Ils sont essentiellement utilisés en cas d'herpès génital, d'herpès de la femme enceinte ou d'herpès du nouveau-né.Les examens de laboratoire se basent sur deux types de prélèvements : échantillon de lésion (vésicules herpétiques), ou prise de sang.Pour l'herpès oro-facial, l'examen clinique visuel est en général suffisant.Les lésions prélevées par un écouvillonnage pouvant être analysées par différentes techniques :C'est le moyen de référence mais elle doit être pratiquée par un laboratoire spécialisé, ce qui nécessite parfois le transport du prélèvement qui doit se faire dans les plus brefs délais et être maintenu réfrigéré ou congelé si le délai de transport dépasse 36 heures.La sensibilité est comprise entre 60 et 100 % elle diminue en fonction de la zone prélevée et du temps écoulé entre l'apparition des vésicules et le prélèvement.Un bon prélèvement doit être fait dans une vésicule fraîche au contenu non troublé, moins de 48h après son apparition.C'est une technique rapide sa sensibilité est de 80 à 90 % et sa spécificité de 85 à 95 %C'est une technique très rapide mais elle nécessite la lecture au microscope à fluorescence par un personnel spécialisé et averti.La sensibilité est de 75 à 100 % et la spécificité de 95 %.Les délais sont plus longs (24 à 48 heures) et nécessitent un transport dans un laboratoire spécialisé.C'est une technique très sensible et spécifique utilisable même sur un prélèvement de mauvaise qualité ou mal conservé.Toutefois son coût élevé empêche son utilisation en routine.L'intérêt de cette ancienne technique est limité aux situations où une autre technique ne peut être utilisée.
Elle est peu sensible (60 %) et peu spécifique car elle ne permet pas de distinguer l'herpès de la varicelle et du zona.La sérologie herpétique est principalement indiquée si l’examen direct est négatif et en l’absence de lésions, ou pour établir le diagnostic du HSV-1 ou du HSV-2.On distingue deux types de sérologies :La sérologie spécifique de HSV-1 ne permet pas d’établir un diagnostic d’infection génitale ancienne à HSV-1.
En revanche, une séropositivité pour HSV-2 permet généralement d’établir le diagnostic d’herpès génital à HSV-2.Une réaction sérologique peut être négative alors que le sujet est atteint d'herpès car 1 à 3 mois sont nécessaires à la séroconversion.Deux formes de traitements existent à ce jour, à base de crèmes à appliquer ou de médicaments antiviraux.
Les traitements sont d’autant plus efficaces qu’ils sont administrés très précocement dès l’apparition des tout premiers signes.
Plus le traitement antiviral sera pris tôt, plus les manifestations cliniques seront limitées en intensité et en durée.
Les antiviraux empêchent le virus de se reproduire et n’agissent que dans les cellules infectées par le virus.Des précautions d’hygiène sont indispensables pour limiter le risque de contamination, et doivent être respectées tant par les malades que par l'entourage, même en l'absence de crise visible.
Ces précautions aident également à limiter le risque d'auto-inoculation, qui peut amener le virus dans des zones très sensibles (herpès génital ou oculaire, aux conséquences graves).Ces mesures peuvent sembler lourdes au quotidien : elles restent pourtant le seul moyen d'éviter la maladie, qui peut dans certains cas avoir des conséquences dramatiques (aucun vaccin ou médicament n'éradiquant le virus).
En effet, le simple bouton de fièvre peut évoluer vers des formes plus graves, par simple progression du virus, ou auto-contamination d'autres zones du corps.
Beaucoup de gens ignorent ces précautions ou ne veulent pas les mettre en pratique, ce qui explique que le virus soit si répandu.Certaines personnes sont plus à risque que d'autres : immunodéprimé, nouveau-né, femme enceinte, porteurs d'une dermatite atopique.Toute personne atteinte, même si la maladie se limite pour le moment à de simples boutons de fièvre, est contaminée et doit prendre les précautions suivantes pour protéger son entourage :Les traitements actuels ne guérissent pas la maladie mais réduisent la charge virale en période de crise.
Les médicaments utilisés sont des antiviraux dont quelques exemples sont l'aciclovir, et sa prodrogue le valaciclovir, le famciclovir et le cidofovir.Le mécanisme d'action : les antiviraux sont des analogues de base qui sont incorporés par les cellules infectées par les virus.
La thymidine kinase des virus est moins spécifique que la thymidine kinase des cellules humaines et permet donc de phosphoryler des analogues de bases.
Par la suite, ces analogues de bases entrent en compétition avec les bases phosphatées de la cellule et une fois incorporés, les analogues de bases inhibent l'ADN polymérase.
Exemple en absence d'infection, l'aciclovir n'est pas transformé en aciclovir monophosphate car il y a absence de TK virale et donc les étapes ultérieures ne sont pas possibles.
Cependant, certains HSV sont résistants aux traitements contre les antiviraux.
L'une des causes de résistance est la mutation du gène de la thymidine kinase chez l'HSV.D'autres molécules à action anti-virale sont en cours de développement, comme le pritelivir.Aucun vaccin n'existe actuellement contre l'herpès, malgré de nombreux essais.
Une sous-unité protéique est une chaîne polypeptidique qui entre dans la constitution d'un complexe protéique par auto-assemblage.
De nombreuses protéines sont constituées de plus d'un seul peptide : les protéines oligomériques sont formées de quelques chaînes polypeptidiques, par exemple l'hémoglobine et l'ADN polymérase ; d'autres peuvent en contenir un très grand nombre et sont dites multimériques, par exemple les microtubules et les protéines constitutives du cytosquelette.Les sous-unités d'une protéine multimérique peuvent être identiques, homologues ou bien complètement différentes et dédiées à des tâches distinctes.
Par exemple, une protéine constituée de deux sous-unités identiques sera qualifiée d'homodimérique, tandis que si les deux sous-unités sont dissemblables, elle sera qualifiée d'hétérodimérique.Des enzymes peuvent ainsi posséder des sous-unités dites catalytiques, sur laquelle se trouve le site actif, et des sous-unités de régulation.
On parle souvent d'holoenzyme pour désigner une enzyme dont toutes les sous-unités requises pour assurer l'intégralité de ses fonctions biologiques sont présentes.Du point de vue génétique, chaque sous-unité d'une protéine ou d'une enzyme est encodée par un gène dédié.Les sous-unités sont généralement nommées avec des lettres grecques, des chiffres romains, voire des lettres latines.
Ainsi, l'ATP synthase possède deux sous-unités F1 et FO constituées elles-mêmes respectivement du complexe α3β3γδε pour la première et, chez l'homme, des sous-unités A, B, C, d, e, f, g, F6 et 8 (ou A6L), chacune codée par un ou plusieurs gènes.
En production ou en gestion de projet, un lot peut désigner un produit semi-fini, fini ou un ensemble de produits/pièces/articles/objets, etc., issus d'une même fabrication.
Les produits, par exemple, peuvent faire l'objet d'une fourniture à un client à une même date.La production de produits avec la gestion de lots permet la traçabilité des produits vendus aux clients, notamment en cas de réclamation ou de rappel en cas de non conformité.
Le rappel des produits défectueux peut alors se faire sur un ou plusieurs lots plutôt que sur l'ensemble des produits.On distingue :
Le consensus scientifique est le jugement, la position, et l'opinion collectifs des personnes de la communauté scientifique qui travaillent sur un domaine particulier d'étude.
Le consensus implique un accord général, mais pas nécessairement à l'unanimité.Un consensus scientifique peut être considéré comme controversé dans la sphère publique alors qu'il est accepté par la communauté scientifique.
Parmi les cas fréquemment remis en cause dans les sphères médiatiques, politiques ou encore religieuses, et ce malgré le large consensus scientifique dont ils font l'objet, on peut citer :D'autres grands consensus scientifiques ont été largement débattus lors de leur théorisation avant d'être largement acceptés.
Un antigène est une macromolécule naturelle ou synthétique qui, reconnue par des anticorps ou des cellules du système immunitaire d’un organisme, peut déclencher une réaction immunitaire.
Les antigènes sont généralement des protéines, des polysaccharides et leurs dérivés lipidiques.
Des fragments d'antigènes appelés haptènes peuvent aussi provoquer une allergie.Les antigènes (de l'acronyme anglais antigen, pour antibody generator) et les anticorps, dont la combinaison est à la base de la réaction immunologique d’un organisme contre un agent extérieur, n’ont pas de définition intrinsèque, mais se définissent l’un par rapport à l’autre :Ainsi toute substance étrangère, tout microbe, introduit dans le corps, peut se comporter en antigène, c’est-à-dire y provoquer la fabrication de protéines spéciales, les anticorps qui ont la propriété de neutraliser les effets nocifs de la substance étrangère ou du microbe et des toxines qu’ils produisent.
Ce faisant, le corps devient réfractaire à l’agent envahisseur ; on dit qu'il s’immunise.Les antigènes, en tant que marqueurs d'agents étrangers à l'organisme, sont à la base de la réaction immunitaire adaptative.
C'est la reconnaissance de l'antigène par les cellules immunocompétentes, directement ou via les cellules présentatrices d'antigène (CPA), qui active l'immunité spécifique.Dans le cas d'antigènes protéiques, on nomme « épitope » ou « déterminant antigénique » la partie de l'antigène reconnue par un anticorps ou un récepteur lymphocytaire.
Un même antigène peut comporter plusieurs épitopes (identiques ou différents) et ainsi provoquer une réaction immunitaire variée.
Il existe des épitopes séquentiels, correspondant à une séquence d'acides aminés, et des épitopes conformationnels, liés à la structure de la protéine et donc sensibles à la dénaturation.
La reconnaissance de l'antigène par les lymphocytes dépend de la nature de l'épitope.
Les lymphocytes B se lient directement aux épitopes conformationnels grâce aux immunoglobulines de leur membrane.
Les lymphocytes T reconnaissent les épitopes séquentiels présentés par les cellules présentatrices d'antigènes.C’est le potentiel d’un antigène à provoquer une réaction immunitaire.
Elle dépend :C’est la capacité de l’antigène à être reconnu par le système immunitaire.
Une substance peut être antigénique mais pas immunogène.Ils sont étrangers à l’individu et peuvent être :Ce sont des antigènes propres à l’hôte (auto-antigènes) et pouvant être considérés comme étrangers (dans le cadre de maladies auto-immunes notamment ; ces antigènes sont dits cryptiques, c'est-à-dire qu'ils ne sont pas reconnus par le système immunitaire en situation normale.
Du grec ancien κρυπτικός, kriptikós : "caché").
Ils sont présentés par les molécules HLA de classe 1 aux CD8.Les antigènes de type protéique sont très immunogènes et souvent utilisés pour fabriquer des vaccins (pour cela, il faut un PM minimum de 1 500 Da).Ce sont des polymères à structure ordonnée constitués d’épitopes identiques se répétant.Deux types :Les polyosides sont des constituants ubiquitaires à la surface cellulaire, ils sont également très immunogènes.Ils sont généralement très peu immunogènes sauf s’ils sont associés à des protéines.Leur immunogénicité est très faible même s’il existe des anticorps anti-ADN.
De la même manière que pour les lipides, on peut augmenter leur pouvoir immunogène en les associant à des protéines.Quand une molécule fait moins de 1 500 Da, elle ne présente qu’un seul déterminant antigénique, on l’appelle alors : haptène.Un haptène est non immunogène.
En l’associant à une protéine porteuse (carrier) qui apporte au moins un déterminant supplémentaire, le complexe devient immunogène.Il s’agit de macromolécules de synthèse obtenues par polymérisation d’acides aminés.C’est le nombre d’anticorps capables de se lier simultanément sur une molécule.
La valence est donc proportionnelle à la surface de la molécule mais ne reflète pas le nombre d'épitopes à cause de l’encombrement stérique que peuvent occasionner les anticorps.Il existe aussi des réponses immunitaires dites indépendantes de l'interaction avec des lymphocytes T auxiliaires.
Ces réponses sont très faibles voire absentes chez le nourrisson avant 2 ans.
Toutefois la plupart des antigènes sont thymo-dépendants.Ils sont impliqués dans une coopération avec les lymphocytes T.
La CPA doit dégrader l’antigène (structure complexe, ex : protéine) et le présenter à sa surface par les molécules CMH de classe II.
Les antigènes thymo-dépendants impliquent toutes les Immunoglobulines.
Le lymphocyte B peut en effet commencer sa maturation après le contact avec le lymphocyte T auxiliaire, il rejoint un centre germinatif dans l'organe lymphoïde secondaire où il se trouve et entame son processus de maturation : hypermutations somatiques, commutation isotypique, maturation d'affinité.
Ainsi une telle réponse immunitaire est de plus grande qualité, mais plus longue à mettre en place par le corps (temps de latence).L’agrégation de l’antigène à motifs répétés (par exemple des antigènes exogènes de nature polyosidiques) à la surface des lymphocytes B suffit à activer ces LB.
Ce type d’antigène n’implique que les Immunoglobulines M puisqu'il n'y a pas maturation de ces lymphocytes B et donc pas de commutation isotypique, qui normalement a lieu pendant la maturation des lymphocytes B après un contact entre le lymphocyte B et le lymphocyte T auxiliaire et la migration des lymphocytes B dans un centre germinatif de l'organe lymphoïde secondaire en question, où il mature.
Ces antigènes induisent donc une réponse immunitaire plus rapide, mais de moins grande qualité.Il faut noter que la réponse thymo-indépendante est de deux types : un type I et un type II, selon le mode d'activation des lymphocytes B impliqués (et donc selon la nature de l'antigène TI).
La réponse TI-1 implique une voie commune d'activation parmi plusieurs lymphocytes B différents, la réponse n'est donc pas spécifique et l'activation est polyclonale (ce qui est différent de la notion d'anticorps polyclonaux).
Une réaction analogue, mais toutefois non comparable, se produit lors de la réponse immunitaire avec un superantigène.
Une telle réponse immunitaire s'explique parce que ces antigènes peuvent être reconnus par des récepteurs communs à plusieurs lymphocytes B, et donc plusieurs types de lymphocytes B différents réagissent.
La réponse immunitaire est régulée par le phénomène de tolérance périphérique, médié principalement par les lymphocytes T régulateurs et B régulateurs (découverts récemment).La réponse TI-2, quant à elle, provoque une stimulation monoclonale (ce qui est différent de la notion d'anticorps monoclonaux) des lymphocytes B. Comme dans une réponse immunitaire classique seuls les lymphocytes B capables de reconnaître l'antigène dont ils sont spécifiques vont être activés et réagir.
Cette fois-ci la reconnaissance de l'antigène passe par le récepteur des cellules B (BCR), qui est spécifique d'un seul type de lymphocyte B, ce qui explique pourquoi la réponse est cette fois-ci spécifique et donc monoclonale.Un état immunodépressif caractérise un organisme dont le fonctionnement du système immunitaire est altéré de façon négative, la personne immunodépressive voit ses défenses immunitaires affaiblies.
Plusieurs causes sont possibles : des médicaments immunosuppresseurs (dans ce cas l'immunodépression est réversible), des infections par certains virus (comme le VIH-1), un état de fatigue transitoire, la malnutrition ou encore la présence de maladies qui ne concernent pas obligatoirement directement le système immunitaire, mais qui jouent un rôle dans son affaiblissement (soit directement soit par les traitements médicamenteux lourds).Pour une personne immunodéprimée au niveau de la lignée des lymphocytes T (T CD4+ par exemple) les antigènes thymo-dépendants peuvent être un facteur de risques, celui-ci évoluant selon le niveau de gravité de cette immunodépression.
Ces antigènes nécessitant une coopération des lymphocytes B avec les lymphocytes T auxiliaires, si ces derniers ne sont pas en nombre suffisant le corps peut avoir du mal à se défendre, voire en être incapable et être agressé par des maladies opportunistes causant la mort (par exemple dans le cas de la phase SIDA de l'infection par le VIH-1 où la lignée CD4+ est gravement touchée).
Une personne immunodéprimée au niveau de cette lignée peut tout de même réagir de façon convenable aux antigènes TI.
Cependant rares sont les antigènes induisant une réponse de type TI.
De plus cela ne change rien à la gravité d'un état immunodépressif prononcé, puisque c'est le corps lui-même qui développe des affections, soit parce qu'il ne maintient plus son intégrité (il ne supprime plus les cellules anormales, ce qui débouche sur des cancers), soit parce qu'il est beaucoup plus fragile à des agents pathogènes externes (virus, bactéries…).Dans le cas d'une immunodépression touchant la lignée humorale, les conséquences sont tout aussi graves mais l'immunité à médiation cellulaire reste active.
Dans le cas de personnes immunodéprimées il convient donc de rechercher la cause de cette immunodépression et la lignée touchée, pour adapter les traitements et les vaccinations, qui sont différentes des personnes en bonne santé
Le mot inoculation (du latin inoculatio, par l'anglais inoculation) a d'abord désigné la variolisation, procédé de traitement de la variole apporté d'Istanbul en Angleterre, au début du XVIIIe siècle et qui consistait à protéger le sujet d'une forme grave de cette maladie en le mettant en contact avec de la substance prélevée sur les vésicules d'une personne faiblement atteinte.En France, ce n'est qu'à partir du milieu du XVIIIe siècle que s'est diffusée la pratique de la variolisation.
La Condamine s'est battu pour son introduction, donnant en 1754, 1758 et 1765 trois mémoires à l'Académie des sciences sur « l'inoculation de la petite vérole,, ».Par une première extension de son sens, le mot s'est appliqué à toute introduction d'un agent infectieux dans un organisme, du fait de l'intervention humaine et dans un but thérapeutique.
Ainsi d'abord de l'« inoculation de la vaccine », ou vaccination, méthode également préventive et qui a succédé à la variolisation.
Ainsi, plus tardivement, et pour prendre cette fois un exemple de type curatif, de l'« inoculation du paludisme » dans le traitement de la syphilis par la malariathérapie.Mais par la suite, le même mot en est venu à désigner l'introduction dans un organisme de tout agent pathogène, volontairement ou non, et du fait ou non de l'intervention humaine.
En effet, l'agent peut  être un venin, une toxine ou un poison, inoculé par un animal aussi bien que par l'homme et, quand il l'est par l'homme, dans une tout autre intention que thérapeutique,.L'inoculation de micro-organismes favorisant la croissance des plantes se pratique également sur les végétaux, dont on essaie par exemple d'augmenter la capacité à fixer l'azote en leur inoculant des bactéries du genre Rhizobium (biofertilisation).L’inoculation psychologique utilise un mécanisme similaire à la vaccination pour protéger les attitudes et les croyances existantes chez les individus.
Un essai clinique, ou étude clinique, ou encore essai thérapeutique, est une étude scientifique réalisée en thérapeutique médicale humaine pour évaluer l'efficacité et la tolérance d'une méthode diagnostique ou d'un traitement.
L'objectif d'un essai n'est pas d'apporter un bénéfice thérapeutique au volontaire.
Le Comité international des rédacteurs de revue médicales en donne la définition suivante : « Tout projet de recherche qui affecte de façon prospective des sujets humains à des groupes d'intervention et de comparaison afin d'étudier la relation de cause à effet entre un acte médical et l'évolution d'un état de santé ».Ces études sont souvent effectuées après des études expérimentales non-cliniques (sur des modèles animaux ou cellulaires) pour confirmer leur pertinence et leur sécurité.
Elles nécessitent aussi l'accord des autorités de santé et d'éthique du pays où elles ont lieu.En fonction du type d'étude et du stade du développement du médicament ou du dispositif, les investigateurs enrôlent des volontaires sains ou des patients.
Les études peuvent être monocentriques avec un faible nombre de participants (par exemple études pilotes).
À l'extrême inverse elles peuvent être multicentriques et inclure des milliers de patients.La fiabilité de ces études repose sur une méthode scientifique rigoureuse et éprouvée afin de limiter tout biais, toute erreur de collecte des données ou d'interprétation des résultats.
Les Bonnes Pratiques Cliniques sont une norme internationale relative à la bioéthique s'appliquant aux essais cliniques réalisés sur des sujets humains.Les résultats sont publiés dans des revues médicales et présentés lors de congrès.
Dans le cas des médicaments, ils servent à établir le dossier permettant d'en valider l'utilisation auprès d'instances nationales ou internationales.Le concept des essais cliniques est assez ancien, il a été introduit et formalisé par le philosophe et médecin musulman d'origine perse ( ابن سينا ) Avicenne en 1025 apr.
dans son ouvrage encyclopédique de médecine médiévale «   كتاب القانون في الطب - Kitab Al Qanûn fi Al-Tibb - (livre des lois médicales) ».
Dans cet ouvrage Avicenne établit les règles de l’expérimentation des médicaments, incluant un guide précis pour la pratique expérimentale, dans le but de découvrir et de prouver l’efficacité des médicaments et des substances,.
Ainsi, les 7 lois sur le médicament énoncées par Avicenne dans le deuxième volume du Kitab Al Qanûn fi Al-Tibb peuvent être énoncées :Frederick Akbar Mahomed (1849-1884) qui travailla pour le Guy's Hospital de Londres, a réussi grâce à ses essais cliniques à séparer les patients souffrant de néphrite chronique (avec une hypertension secondaire), des patients qui ont ce qu’on nomme actuellement une hypertension artérielle.
Il a aussi fondé le registre collectif des investigateurs de la British Medical Association qui collecte les données des médecins pratiquant à l’extérieur des hôpitaux.
C’est le précurseur des essais cliniques faits en collaboration.Un des plus célèbres essais cliniques fut celui de James Lind qui démontra en 1747 que les agrumes peuvent soigner le scorbut,.
Il compare les effets de différentes substances allant du vinaigre au cidre, sur des groupes de marins atteints de scorbut.
Il découvre que le groupe qui a reçu des oranges et des citrons s’est rétabli du scorbut en 6 jours.
La répartition des patients entre « traités » et « non traités » a varié avec le temps.
Il s'est fait dans un premier temps suivant des critères imprécis, où l'investigateur joue le rôle principal dans la sélection.
Au XIXe siècle, elle se fait essentiellement de manière alternée (un patient dans le groupe traité, le suivant dans le groupe non traité, ou tel jour d'admission correspond à un traitement et tel autre jour non).
L'un des premiers essais par tirage au sort (par « pile ou face ») a été publié en 1937, mais est resté isolé, le premier essai clinique randomisé et théorisé en tant que tel a été publié en 1948 (évaluation de la streptomycine dans le traitement de la tuberculose).Sur le plan méthodologique, les essais sont mis au point dans les années 1920 par les statisticiens anglais.
Sur le plan éthique, les essais sont encadrés depuis 1947 par le Code de Nuremberg.En 2016, les États-Unis sont le pays où ont eu lieu le plus grand nombre d'essais cliniques de médicaments,.En Europe et dans de nombreux pays (États-Unis, Japon, etc.), les données cliniques pouvant être utilisées pour l'obtention d'une autorisation de mise sur le marché (AMM) doivent obligatoirement avoir été obtenues dans des essais obéissant aux bonnes pratiques cliniques.
Les données de sécurité précliniques, c'est-à-dire permettant d'évaluer, sur l'animal, la toxicité potentielle de l'élément testé, doivent quant à elles avoir été obtenues dans des essais obéissant aux bonnes pratiques de laboratoire (arrêté du 14 mars 2000).
Des critères d'éthique sont indispensables dans tout essai clinique.
Les volontaires participants aux études cliniques doivent être informés et donner leur consentement éclairé à l'inclusion dans l'essai.
Ils doivent être avertis des risques éventuels de façon exhaustive.
Bioethics International publie un indicateur sur le niveau d’éthique des essais cliniques des compagnies pharmaceutiques afin de protéger les participants.En France, l'avis d'un comité de protection des personnes est obligatoire.
Ce comité rendra son avis en vérifiant l'intérêt scientifique et médical de l'étude, son rapport risque éventuel/ bénéfice attendu, la conformité aux bonnes pratiques de la méthode, notamment en ce qui concerne le promoteur et l'investigateur principal de l'étude et la présence d'une assurance permettant d'indemniser les participants à l'étude en cas de dommages.Les liens financiers entre les investigateurs et les promoteurs de l'étude, quand ils existent, doivent être annoncés.
Les conflits d'intérêts doivent être évités.Un élément de qualité d'un essai clinique est d'être prospectif.
Il s'agit de définir avant le début de cet essai :À l'inverse, une étude dite rétrospective s'intéressera à la recherche de liens entre un état de santé présent et un événement antérieur.
Elle repose sur l'exploitation de documents dont la fiabilité ne peut être garantie et expose à des biais de sélection.Dans une étude comparative, les résultats du traitement administré sont évalués par comparaison avec les résultats obtenus dans un groupe témoin, lequel ne reçoit pas ce traitement, mais un placebo ou bien un traitement de référence.
Le placebo permet de déterminer l’effet du traitement étudié par rapport à ce qui est considéré comme l’absence d’effet (car les éventuels effets observés avec le placebo ne sont pas imputables à sa substance).
Le traitement de référence peut être utilisé à la place d’un placebo pour des raisons éthiques : lorsqu’un traitement efficace est connu, on ne peut pas en priver les patients pour les besoins d’une expérience, et l’étude vise alors à déterminer si le traitement étudié présente des avantages sur le traitement de référence.Un groupe témoin est indispensable pour valider l'efficacité d'une procédure.
L'exemple suivant explique pourquoi : si une étude sur un médicament montre 50 % de guérisons, une approche hâtive pourrait conclure à une nette efficacité.
Mais si, dans le groupe témoin de cette étude, la proportion de guérisons est de 100 %, le médicament sera au contraire jugé nocif.Dans tous les cas, les différents groupes doivent être constitués de populations présentant les mêmes caractéristiques globales, qu’il s’agisse de caractéristiques spécifiques à l’affection étudiée (sévérité, avancement) ou non (âge, sexe, taille, poids, etc.), afin qu'à la fin de l'étude les éventuelles différences observées ne puissent être attribuées qu'au traitement.
Les caractéristiques pertinentes doivent être déterminées avant le début de l’étude afin d’éviter tout biais.La répartition entre le groupe-contrôle et le groupe recevant l'intervention doit être fait de manière aléatoire.
On parle alors d'étude hasardisée ou randomisée, toute autre méthode induisant des biais de sélection.Il est préférable, lorsque cela est possible, que le sujet ignore à quel groupe il est assigné et s'il reçoit, par exemple, une molécule active ou un placebo.
On parle alors d'un simple aveugle.
Lorsque l'expérimentateur ignore également à quel groupe est assigné le sujet, on parle d'étude « en double aveugle ».
Le respect de ces critères permet d'éviter des biais d'interprétation en fonction de « l'intime conviction » des protagonistes.
Ce n'est qu'à la fin de l'étude, lorsque l'ensemble des observations est complété, que les compositions des groupes sont révélées afin d'analyser les résultats du traitement statistique.Lorsque le patient et l'expérimentateur connaissent tous deux l'appartenance au groupe, on parle d'étude ouverte.Le caractère multicentrique, c'est-à-dire le fait que l'étude se déroule simultanément dans plusieurs lieux différents, est également un caractère de qualité, permettant l'étude d'un plus grand échantillon et limitant des biais de sélection géographiques, climatiques ou ethniques.Tous les participants à l'étude restent étudiés dans le groupe auquel ils ont été assignés, même s'ils n'ont pas entièrement achevé le protocole, afin d'éviter un biais d'attrition, c’est-à-dire une « disparition » de l'étude de sujets ayant arrêté le protocole pour des raisons diverses, notamment de tolérance.
Dans le cas inverse où les patients sont exclus de l'analyse lorsque le protocole initial n'est pas totalement respecté, on parle d'analyse per protocole.Les résultats d'une étude peuvent être donnés à la fois en intention de traiter et per protocole, la première analyse s'approchant le plus de la réalité, la seconde d'une étude dans des conditions idéales.Un comité de surveillance et de suivi (en anglais Data Monitoring Committee DMC ou Data Safety and Montoring Board DSMB), groupe d'experts indépendants du promoteur, peut être institué pour évaluer les données du point de vue de la sécurité des patients et de l'efficacité du traitement lors d'analyses intermédiaires.
Il peut être amené à recommander l'arrêt de l'essai.
Il est prévu en particulier pour des études internationales multicentriques pour lesquelles la surveillance peut s'avérer complexe.Un biais est une cause d'erreur potentielle dans les résultats d'une analyse statistique liée à la méthode de l'expérimentation.Ils sont dus à des différences entre les groupes initiaux et les groupes finaux, liés à des sorties d'essai ou des interruptions de traitement.Par exemple, soient 2 groupes égaux de 100 participants initialement, le groupe A traité, le groupe B recevant un placebo.
Dans le groupe A on compte 50 sorties d'essai pour intolérance, 25 améliorations, 25 stagnations, dans le groupe B, 0 sorties, 25 améliorations, 75 stagnations.
Si on n'analyse pas les patients sortis d'essai, on a 50 % d'amélioration dans le groupe A contre 25 % dans le groupe B. En revanche si on analyse en intention de traiter, on n'observe plus de différence.Le biais de confusion est lié à une erreur d'appréciation entre les effets de la thérapeutique étudiée et les conséquences de la maladie traitée.
Le risque de biais de confusion est atténué par l’utilisation d’un groupe-contrôle.Il est lié à une différence de composition entre le groupe traité et le groupe témoin.
Si le groupe témoin est, par exemple constitué de patients de l'année précédente, il y a toutes les chances que la prise en charge médicale ait évolué entre les deux groupes.
D'autre part, si la sélection se fait sur des critères objectifs (date de naissance, jour de consultation, etc.), l'expérimentateur pourra deviner à quel groupe appartient le patient et le double aveugle n'est plus possible.
La randomisation, ou tirage au sort, est le seul moyen pour éviter un biais de sélection.Il est lié à des différences de prise en charge au niveau du groupe traité et du groupe témoin.
Par exemple, si le double aveugle n'est pas respecté, il est probable que l'expérimentateur ne suivra pas de la même façon les effets secondaires manifestés par le patient recevant le placebo.Le biais d'évaluation survient lorsque le critère de jugement n'est pas recherché de la même manière dans les deux groupes.
Le risque de biais d'évaluation est supprimé si l'essai est en double insu.Même si on ne peut parler en toute rigueur de biais, les études cliniques ont d'autres limitations :Le développement d'un nouveau médicament ou d'un nouveau vaccin pour une indication thérapeutique donnée se déroule le plus souvent en quatre « phases » précédées d'une phase dite pré-clinique.
Chaque « phase » peut comporter plusieurs essais.
La phase de découverte des médicaments et la phase pré-clinique représentent 31,9 % du coût total de la R & D des groupes pharmaceutiques.
La phase des essais cliniques, assumée essentiellement par les grands groupes pharmaceutiques, représente 41,2 % du coût total de la R & D.Elle consiste en l'étude de la molécule, sa structure, son effet sur les cellules, son effet sur l'animal au niveau comportemental et biologique, l'étude des organes-cibles.
Elle se réalise in vitro puis in vivo sur des modèles d'animaux, des rongeurs (souris, rat et gerbilles) et des non-rongeurs : chien (de moins en moins utilisé), porc pour sa « proximité biologique » avec l’homme ou primates (lorsqu’une molécule a démontré son intérêt).À partir de ces études on détermine la dose maximale tolérée (maximal tolerated dose, MTD) qui représente la dose maximale que l'animal de laboratoire peut tolérer, la dose sans effet observable (en anglais no observed effect level, NOEL) et la dose sans effet toxique observable (en anglais : no observable adverse effect level, NOAEL).Pour calculer la première dose maximale sécuritaire à utiliser chez l'humain, la dose sans effet toxique observable est convertie en dose équivalente chez l'humain (human equivalent dose, HED).
Pour obtenir la HED, la NOAEL obtenue à partir du rat est multipliée par 0,16 alors que la NOAEL provenant du chien est multipliée par 0,54.
La première dose maximale recommandée ou maximum recommended starting dose (MRSD) chez l'humain est calculée à partir de la plus petite HED obtenue.
La plus petite HED est alors divisée par 10 pour donner la MRSD.Une étude de phase I est le préliminaire à l'étude d'efficacité d'un médicament.
Elle a lieu après la phase pré-clinique.
Il s'agit d'évaluer la tolérance et l'absence d'effets indésirables chez des sujets le plus souvent volontaires sains, indemnisés (et non rémunérés) pour cela.
Parfois ces essais peuvent être proposés à des patients en impasse thérapeutique, pour lesquels le traitement étudié représente la seule chance de survie.Cette phase permet également d'étudier la cinétique et le métabolisme chez l'homme de la substance étudiée.Les groupes étudiés sont le plus souvent de petite taille (20 à 80 participants).Certains médicaments dont on sait par nature qu'ils sont toxiques (par exemple les anticancéreux) peuvent ne pas faire l'objet d'une phase I et entrer directement en phase II.La phase II ou étude pilote consiste à déterminer la dose optimale du médicament et ses éventuels effets indésirables.
Population éligible : malades (souvent moins de 500).
Elle est subdivisée en deux phases : les phases IIa et IIb.
La phase IIa estime l’efficacité de la molécule sur un nombre limité (de 100 à 200) de malades, alors que la phase IIb détermine la dose thérapeutique de la molécule sur une plus grande échelle (de 100 à plus de 300 malades).La phase III ou « étude pivot » est l'étude comparative d'efficacité proprement dite.
En cas de positivité, elle conduit à une demande d'autorisation de mise sur le marché.
Elle compare le traitement soit à un placebo, soit à un traitement de référence.
Les groupes sont de taille importante, souvent plusieurs milliers de participants.
Il s'agit de programmes extrêmement onéreux, dont le financement peut être public ou privé (compagnies pharmaceutiques).
Compte tenu des enjeux financiers, certaines dérives éthiques ont été dénoncées.
Les résultats peuvent être moins probants que lors de la phase II (tout en conservant un degré de significativité) ou, parfois, infirmer, l'étude de phase II.La phase IV (ou post-marketing) est le suivi à long terme d'un traitement alors que le traitement est autorisé sur le marché.
Elle doit permettre de dépister des effets secondaires rares ou des complications tardives.
Cette phase est à la charge des laboratoires.Différents tests statistiques sont utilisés afin d'exploiter les résultats bruts des essais, en fonction de la nature des paramètres étudiés (variables discrètes ou continues), de la taille des échantillons et de l'objet des études.
L'emploi de tests adaptés est fondamental, un test inadapté pouvant fournir des conclusions complètement erronées.Le résultat est en général une comparaison entre les groupes avec une valeur p permettant d'évaluer le caractère plus ou moins significatif de la différence observée.
Par exemple, si l'on dit que « Dans le groupe traité la survie est significativement supérieure (p < 0,01) », cela signifie que le hasard seul aurait eu moins d'une chance sur cent de produire une telle différence entre les deux groupes.
Un p supérieur à 0,05 doit faire rejeter le caractère significatif de la différence, mais ne permet pas non plus de conclure à l'absence de différence.
On parle alors de différence non significative.Des logiciels sont à disposition des promoteurs et des investigateurs pour la gestion et le suivi d'essais cliniques,,.La pertinence d'une étude clinique va, en croissant :La science médicale évolue grâce aux essais cliniques de médicaments, aux tests d’appareils nouveaux et aux études sur les interventions novatrices.
Mais on ne connaît pas tous les résultats, car un tiers des essais ne sont jamais rapportés dans un article scientifique, et ceux qui le sont ne sont pas toujours de manière complète.
Cela constitue typiquement un biais.C’est pourquoi, depuis quelques années, l’enregistrement des essais dès l'établissement de leur protocole tend à devenir obligatoire pour certaines études de grande envergure.
L’International Committee of Medical Journal Editors, où siègent les revues médicales majeures, accepte de publier les résultats d’une étude seulement si elle a été enregistrée au départ.
Cette politique a été mise à jour, en particulier pour préciser que rendre public un résumé de moins de 500 mots ou un tableau de résultats ne contrevient pas à la règle de non-publication antérieure.
Le gouvernement des États-Unis exige que soient diffusés tous les essais sur des médicaments, des produits biologiques et des appareils qui auront besoin d’être approuvés par la Food and Drug Administration.
Cela doit se faire dans une base de données accessible sur internet.
À partir de septembre 2008, le dossier des études devra être enrichi des résultats obtenus, dans un délai d’un an après l’intervention auprès du dernier « sujet ».
Cette base contient plus de 52 000 études faites dans plus de 150 pays (30 % proviennent d’en dehors des États-Unis).En parallèle, l’industrie pharmaceutique américaine alimente une autre base de données, également accessible par internet, contenant le résultat des études cliniques réalisées pour les médicaments sur le marché.Les Instituts de recherche en santé du Canada demandent pour leur part l’enregistrement auprès de « Current Controlled Trials », qui attribue un International Standard Randomised Controlled Trial Number (ISRCTN).Comme les registres se multiplient, l’Organisation mondiale de la santé les a regroupés dans son système d'enregistrement international des essais cliniques, qui se veut la porte d’entrée pour tous les essais en cours dans le monde entier.
Il donne accès à une demi-douzaine de registres primaires (les plus rigoureux) et à plusieurs autres dits associés.
La multiplicité de ces bases rend peu aisé l'accès aux informations par un non-professionnel.
Sans que ce soit évident, la recherche peut se faire avec des descripteurs MeSH, qui seront automatiquement éclatés (exploded).
Les questions retrouvent aussi des synonymes, ce qui est intéressant quand les molécules expérimentées n’ont pas encore de nom officiel.
La démarche peut se faire en sens inverse : remonter d’une référence du Medline vers le protocole de recherche original.Depuis septembre 2009, l'ANSM (anciennement l'AFSSAPS) met en ligne le « Répertoire public des essais cliniques des médicaments » sur son site internet.
Cela correspond à un résumé succinct de l'étude, transmis par le promoteur, pour tous les essais cliniques conduits en France et dont la demande initiale a été faite après le 22 mai 2009.
La maladie de Lyme est une maladie vectorielle et une zoonose (maladie infectieuse touchant l'être humain et de nombreux animaux).
La maladie de Lyme est nommée d'après les villes de Lyme et Old Lyme, deux villes des États-Unis, dans l'État du Connecticut où elle a été signalée pour la première fois en 1975 et identifiée en 1977.
Transmise par piqûre de tiques dures Ixodes, c'est une maladie bactérienne, due à une borrélie (Borrelia burgdorferi, au sens étroit, prédominante en Amérique du Nord).L'expression borréliose de Lyme désigne souvent la « maladie de Lyme européenne », due à une plus grande diversité de borrélies (principalement Borrelia garinii, B. afzelii… ou B. burgdorferi au sens large).
Maladie de Lyme et borréliose de Lyme sont souvent synonymes, dues alors à Borrelia burgdorferi au sens large.
Les autres borrélioses sont dites fièvres récurrentes (cosmopolite transmise par poux, et régionales par tiques molles).La maladie se manifeste initialement par une éruption cutanée (érythème migrant) centrée sur une piqûre de tique.
Non traitée elle peut évoluer en trois stades de longue durée, caractérisées par une grande diversité car pouvant toucher plusieurs systèmes et organes.
Elle se présente alors sous des formes plutôt cutanées, articulaires ou neurologiques, de façon aigüe ou chronique.La maladie est en expansion, devenue la plus fréquente des maladies vectorielles transmises à l'humain dans l'hémisphère nord.
Dans près de 90 % des cas, elle est traitée efficacement par une antibiothérapie de 2 à 4 semaines.L'existence et la signification de formes non guéries par le traitement standard, ou l'attribution de pathologies chroniques à la maladie de Lyme, posent le problème de la « maladie chronique de Lyme ».La complexité du diagnostic clinique, l'interprétation problématique des tests sérologiques, des lignes directrices contestées pour le diagnostic, le traitement et la gestion antibiotique de la maladie de Lyme chronique entretiennent une controverse sociétale dite Lyme War aux États-Unis ou Scandale de Lyme en France.Les borrélioses existent depuis longtemps :En 1969, le premier cas documenté d'érythème chronique migrant, survenu chez un chasseur en forêt, est publié aux États-Unis.En 1975, deux mères de la ville de Lyme, ayant des enfants diagnostiqués comme victimes d'une forme d'arthrite rhumatoïde juvénile avaient observé que de nombreux autres enfants de la commune présentaient des problèmes similaires.
Alertée, une équipe d'épidémiologistes de l'université Yale, dirigée par Allen Steere, met rapidement en évidence une situation atypique :Allen Steere (en) nomme alors cette maladie « maladie ou arthrite de Lyme » du nom de la ville, en l'attribuant à une transmission par tique dans un article publié en 1977.En 1977, la piqûre de la tique Ixodes dammini (devenu Ixodes scapularis) est rapportée à un cas humain d'érythème chronique migrant.En 1982, Willy Burgdorfer isole la bactérie spirochète responsable de la maladie dans le tube digestif de I. scapularis, dite « tique du cerf » en Amérique du Nord.
Après inoculation au lapin, il montre que ce spirochète peut provoquer un érythème migrant.
Il observe aussi une forte réaction entre le sérum de malades et la bactérie.
C'est en son honneur qu'on nommera en 1984 cette bactérie Borrelia burgdorferi.
À la même période, on détecte des spirochètes identiques ou proches en Europe (en Suisse), dans des tiques Ixodes ricinus.La responsabilité de ce spirochète sera confirmée en l'isolant dans le sang, la peau et le liquide cérébrospinal de patients atteints de la maladie de Lyme.En 1984, le dermatologue allemand Klaus Weber montre une augmentation d'anticorps de type IgG dans le sang de patients présentant une acrodermatite chronique atrophiante, établissant ainsi un premier rapport entre les manifestations précoces et tardives de la maladie.Ce sont toujours des bactéries du genre Borrelia, classées parmi les spirochètes en raison de leur caractère serpentiforme et spiralé.Borrelia burgdorferi sl (sensu lato) désigne un « complexe » d'une trentaine d'espèces, dont plusieurs sont pathogènes pour l'humain.
Les trois principales étant : Borrelia burgdorferi ss (sensu stricto), B. garinii, B. afzelii.
Au début du XXIe siècle, les méthodes de génétique moléculaire (typage moléculaire des bactéries) ont permis de détecter de nouvelles espèces pathogènes pour l'humain : comme B. spielmanii ou B. bavariensis en Eurasie, ou B. bissettii en Eurasie, Amérique, Australie.On a aussi montré (en 2016) que certaines souches d'une même espèce de Borrélie sont plus pathogènes pour l'humain que d'autres.Quelle que soit l'espèce de Borrélie en cause, l'atteinte initiale peut se manifester (parfois) par un érythème migrant ; sinon les évolutions diffèrent.
Les associations ne sont pas absolues, mais préférentielles, expliquant en partie la prédominance géographique de certaines formes compliquées de la maladie.Les vecteurs sont surtout des tiques du genre Ixodes.
Ces vecteurs majeurs ont en commun d'avoir un cycle de transmission à trois hôtes successifs, en forêt ou prairie humide, de 2 à 7 ans selon l'espèce et le climat.En Amérique du Nord, le vecteur principal est Ixodes scapularis , dans le nord-est et le Midwest.
Tous les stades, surtout nymphes et adultes femelles peuvent piquer l'humain.
Ixodes pacificus, source de 5 % environ des cas déclarés aux États-Unis, se trouve plutôt dans l'Ouest.
Son efficacité pathogène sur l'humain est moindre (seul le stade adulte pique l'humain).En Eurasie et surtout en Europe, le principal vecteur est Ixodes ricinus.
Elle prédomine dans les régions boisées, en piquant l'humain à tous les stades (larves et nymphes au printemps, adultes à la fin de l'été).En Eurasie tempérée et froide, surtout Asie et presque tout l'ex-URSS, le principal vecteur est Ixodes persulcatus.Certains arthropodes hématophages tels que les taons, les moustiques… pourraient être des vecteurs potentiels de Lyme.
Ce rôle éventuel de vecteur accessoire est en discussion.La proportion de tiques infectées varie beaucoup selon le stade de développement, les espèces, les saisons et les régions : moins de 2 % des I. pacificus en Californie, jusqu'à 30 % de tiques contaminées en France, 60 % en Autriche, et 100 % à Long Island.En France, une étude menée en 2021 par l'INRAE montre que 15 % des tiques qui piquent les êtres humains seraient porteuses de bactéries Borrelia bugdorferi sensu lato.La bactérie se développe en deux stades : elle se multiplie d'abord dans l'intestin moyen de la larve, à ce stade, la bactérie est « non motile », c'est-à-dire incapable de se déplacer par ses propres moyens.
Puis, dans une seconde phase, sous l'effet du repas de sang (d'un premier hôte petit rongeur), la bactérie devient motile et capable de pénétrer l'hémocœle de la tique, et de gagner les « glandes salivaires » de la nymphe ou de la tique adulte.De là, elle passe dans la salive et est injectée chez les hôtes suivants (mammifère, oiseau, reptile…).
Ceci explique pourquoi c'est généralement via la piqûre d'une nymphe de tique, et non par piqûre de larve, que la bactérie est transmise aux grands mammifères.De façon exceptionnelle, la bactérie peut aussi diffuser vers les ovaires de la tique, ce qui donne lieu à une transmission transovarienne dite « verticale », la tique transmettant directement la bactérie à sa descendance.
Ceci explique que, dans ces cas là, une larve de tique peut être infectante, avant même d'avoir effectué un repas sanguin.En 2017, l'INRA a lancé un projet de sciences citoyennes pour une meilleure connaissance des vecteurs de la maladie de Lyme, en lien avec le plan national de lutte contre la maladie de Lyme.
Une application pour Smartphone permet notamment à chaque citoyen de signaler les piqûres de tiques, et ceux-ci sont invités à transmettre les tiques aux laboratoires pour les analyser et ainsi mieux connaître la répartition des espèces de vecteurs et de borrélies.Le réservoir des borrelia est constitué par des petits rongeurs, hôtes principaux des tiques au stade de larves ou de nymphes.
À ce stade initial, les larves et nymphes se nourrissent d'abord sur une même espèce de petit rongeurs.
Au début de l'été, les nymphes infectées contaminent leur hôte, et à la fin de l'été l'hôte infecté contamine les larves.
Les larves infectées muent, deviennent nymphes et le cycle recommence l'année suivante.
Ce cycle initial est essentiel pour le maintien des borrelia dans la nature.En poursuivant leur développement (de la nymphe à l'adulte), les tiques contaminées transmettent la bactérie à d'autres hôtes (rongeurs, grands mammifères, oiseaux, parfois reptiles).
À ce stade, les tiques se reproduisent et le cycle recommence.
Cette partie du cycle est indispensable pour le maintien des tiques, mais pas pour les borrelia.Les espèces qui jouent un rôle réel de réservoir peuvent varier selon les pays et régions.
En Europe, plus de 300 espèces ont été ainsi identifiées : ce sont majoritairement les petits rongeurs, mais aussi les mammifères de taille moyenne (renard, lièvre…) ou de grande taille comme les cervidés, ou encore les oiseaux.
Ces espèces-réservoirs sont celles d'animaux sauvages vivant en zone boisées, broussailles, prairies, humides et tempérées… en contact régulier et permanent avec l'habitat habituel des tiques.
Les cycles européens paraissent plus complexes et plus variés qu'en Amérique.En Amérique du Nord, contrairement à l'Europe, les espèces-réservoirs prédominantes se distinguent plus nettement.
Par exemple, dans le nord-est et le Midwest : la souris à pattes blanches et le cerf de Virginie.
Les oiseaux migrateurs pourraient jouer un rôle dans l'expansion des tiques au Canada.Des animaux domestiques peuvent aussi être infectés, en particulier les chiens, les moutons, bovins et chevaux, lesquels peuvent présenter des atteintes articulaires (chevaux) ou rénales (chiens) contrairement aux espèces sauvages à infections inapparentes.L'humain qui s'insère dans ce cycle, en s'exposant aux tiques, est en fait un hôte accidentel terminal des tiques.Une même tique peut injecter dans son hôte jusqu’à cinq agents pathogènes différents, ensembles ou de façon différée, la coinfection par plusieurs espèces de Borrelia chez les tiques semblant même être la règle plutôt que l'exception.Ainsi des co-infections possibles, transmises par les tiques à l'humain sont :Les agents connus autres que des Borrelia provoquent des symptômes généralement non spécifiques (maux de tête, douleurs articulaires et musculaires, fatigue…) et une fièvre plus importante que dans la maladie de Lyme.L'impact sanitaire réel d'autres pathogènes potentiels qui constituerait un « pathobiome » des tiques est encore mal connu,.
(2014), les coinfections pourraient, au moins partiellement, expliquer la variabilité de la sévérité et des manifestations cliniques, parfois chroniques, observées dans l'expression de la maladie de Lyme.Les humains se contaminent lors d'une rencontre avec les tiques vectrices (contaminées) qui se trouvent en particulier dans les milieux boisés humides avec sous-bois embroussaillés ; du printemps au début de l'automne.
Elles sont situées dans le tapis végétal à moins d'un mètre de hauteur.Elles chassent « à l'affût » en détectant la présence d'un hôte à proximité grâce à des capteurs sensibles au CO2, à la chaleur et substances biochimiques (organe de Haller).Une fois sur le corps de l'hôte, une tique recherche les zones chaudes et humides comme les plis du corps : chez l'humain, creux du coude ou du genou, aisselle, aine… Elle peut passer sous les vêtements et atteindre la peau où elle se fixe par son rostre pour faire son repas sanguin.Ce repas sanguin dure de 3 à 5 jours.
La transmission se fait au cours du repas, par passage de bactéries du tube digestif de la tique, à ses glandes salivaires.
Salive et bactéries sont inoculées dans l'épiderme, et non directement dans un vaisseau sanguin.
Cette progression ne débute qu'après la piqûre de la tique, il faut plusieurs heures avant qu'elle ne soit contaminante.
Aussi une tique retirée assez rapidement ne transmet pas de maladies.Le risque de développer une maladie de Lyme après piqûre de tique est de l'ordre de 1 à 5 %.
Seul un tiers des patients atteints de maladie de Lyme a eu conscience ou se souvient d'une piqûre de tique.La transmission directe mère-enfant in utero est possible quand la mère est infectée durant la grossesse.
La maladie n'a pas d'effet sur le fœtus, si la mère est traitée par antibiothérapie adaptée.Les autres modes de transmission n'ont pas été démontrés : de personne à personne (par toucher, baiser, ou acte sexuel), par air, eau, aliments, allaitement maternel, transfusion sanguine,…Il n'existe pas de risques de contamination directe à partir d'un animal de compagnie infecté.Le CDC américain recommande aux malades de Lyme ayant une infection active en cours d'antibiothérapie de ne pas donner leur sang, ceux qui ont terminé leur traitement pouvant être donneurs.
En France, l'attitude est similaire (report temporaire).La maladie de Lyme existe sur tous les continents mais prédomine en zone tempérée de l'hémisphère nord, où elle est la première maladie vectorielle (y compris en Europe).
La maladie touche plus les jeunes enfants et les plus de 45 ans, avec un pic de fréquence correspondant à l'activité des tiques (début du printemps à la fin de l'automne).
Les zones nordiques et d'altitude sont de plus en plus touchées, sans doute parce qu'elles se réchauffent.Aux États-Unis, près de 30 000 cas sont signalés chaque année aux CDC, dont 95 % des cas dans 14 États du nord-est et du Midwest, mais des études estiment que le nombre de cas diagnostiqués serait de l'ordre de 300 000, avec la même distribution géographique.
La prévalence de la maladie augmente aussi au Canada, notamment démontrée par un suivi de sérologiques chez les chiens ; en 2019, on estimait qu'un tiers des cas environ sont signalés dans les régions canadienne d'émergence de la maladie.En Europe, son incidence augmente selon un gradient sud-nord et ouest-est, généralement entre une latitude de 35° Nord et 60° Nord, et au-dessous d'une altitude de 1 300 m.
Elle est estimée à 65 000 cas par an, répartis de façon hétérogène, avec un maximum en Slovénie et en Autriche avec plus de 100 cas pour 100 000 habitants.En Belgique, de 2000 à 2016, en moyenne 200 à 300 personnes sont hospitalisées par an pour cette maladie ; près de 10 000 consultent un généraliste pour érythème migrant.En Suisse, il y aurait 200 à 600 consultations par an pour de nouveaux cas de maladie de Lyme (estimation pour 2008-2018).En France, en 2005 il y avait 43 cas estimés pour 100 000 habitants, avec une incidence moyenne estimée à 9,5 cas pour 100 000 habitants.
Mais cette incidence varie beaucoup selon les régions : la maladie semble exceptionnelle sur le pourtour méditerranéen (climat trop sec pour le vecteur), alors que dans le Nord-Est elle est environ 10 fois supérieure à la moyenne nationale.Selon le réseau Sentinelle, ce taux est évalué à 69 / 100 000 en 2017 avec plus de 100 cas dans l'Est et dans le Limousin.
En 2020, selon le même réseau, ce taux est passé à à 91  cas pour 100 000 habitants en 2020, avec plus de 300 cas pour 100 000 habitants dans l'Est  et 667 cas pour 100 000 habitants dans le Limousin.Les activités de promenade en forêt, camping, jardinage, activités naturalistes, chasse, travaux agricoles et surtout foresterie exposent à la maladie :Remarque : les facteurs de risque étaient similaires pour une borréliose de Lyme diagnostiquée par un tests Western blot ou au vu des antécédents cliniques.L'épidémiologie de la maladie de Lyme est celle d'une zoonose « à foyers naturels », c'est-à-dire dont la répartition est irrégulière avec des zones endémiques localisées, séparées par des zones plus ou moins indemnes (à l'échelle nationale — différences régionales — comme à l'échelle régionale — différences locales —, etc.).Cette zonation fluctue dans le temps et dans l'espace, selon les conditions climatiques et écologiques, la saison, le nombre et le déplacement d'hôtes (oiseaux et gros mammifères notamment…) porteurs de tique et/ou de borrélies.La progression de la maladie depuis les années 1970 résulte essentiellement d'une augmentation d'incidence et d'une extension des régions atteintes, et moindrement d'une amélioration du dépistage et de la surveillance,.L'augmentation de la prévalence de cette maladie peut résulter d'une évolution génétique des agents, des vecteurs et des hôtes, en rapport avec les modifications des écosystèmes.Le réchauffement climatique entraîne des températures minima plus élevées (nocturnes et hivernales) et des printemps plus précoces, ce qui retentit probablement sur la distribution locale des tiques, leur densité de population et leur taux de survie,.À ce phénomène global, s'ajoutent les aménagements forestiers et agricoles : le drainage, la fragmentation forestière et des paysages, les coupes rases, le reboisement, etc.
Ces activités humaines peuvent entraîner une perturbation de la dynamique des populations faunistiques et des équilibres sylvocynégétiques.Ces processus réduisent la biodiversité, considérée comme élément stabilisateur.
Ils se manifestent par une augmentation de densité des vertébrés domestiques et sauvages (hôtes réservoirs compétents) avec un recul de leurs grands prédateurs.Par exemple, en Amérique, le cerf de Virginie et la souris à pattes blanches (hôtes principaux pour les tiques vectrices de Lyme) ont connu une augmentation rapide de densité.Dans le nord-est, du XVIIe siècle au début du XIXe siècle, les colons ont défriché de vastes étendues de forêts pour leurs activités agricoles avec une quasi-disparition des cervidés et de leurs prédateurs.
À la fin du XIXe siècle, la région s'industrialise et l'agriculture décline ; les terres abandonnées se reboisent, habitat favorable pour la multiplication du cerf de Virginie.
Au cours du XXe siècle, cette reforestation s'accompagne d'un développement résidentiel péri-urbain en zone boisée.
Les conditions sont alors réunies pour une plus grande proximité permanente souris-cerfs-tiques-humains.En Europe, comme en Amérique du Nord, une présence humaine accrue en forêt ou en lisière de forêt (habitat péri-urbain, activités de chasse ou de loisir…) accroit la possibilité de contact entre la tique, l'humain et ses animaux domestiques (chien, cheval…).Le contexte de guerre et de guerre civile pourrait aussi favoriser ce type de zoonoses ; ainsi en Serbie, peu après le début des guerres dites Guerres de Yougoslavie, on a constaté une forte augmentation des cas de borrélioses de Lyme.La mondialisation, le commerce et le tourisme internationaux jouent également un rôle, par diffusion géographique d'hôtes et de parasites.
Par exemple, en France, un nouvel animal de compagnie, l'écureuil de Corée ou tamia de Sibérie, relâché dans la nature par ses propriétaires, a été suspecté d'être un nouvel hôte réservoir, car il s'est rapidement adapté : une des plus grandes populations de tamias (entre dix et vingt mille individus) se trouve ainsi dans la forêt de Sénart.Après inoculation, sauf en cas d'allergie à la salive de tique, il y a peu de réaction inflammatoire immédiate, car les borrélies peuvent modifier leurs antigènes de surface, Outer surface proteins ou Osp (A-F), et échapper aux premières défenses immunitaires.
En l'absence de traitement, elles diffusent localement dans la peau à partir du site d'inoculation (érythème migrant).Puis elles diffusent par voie sanguine vers les tissus articulaires, neurologiques et cardiaques.
Chez le sujet immunocompétent, après plusieurs semaines ou mois, les réponses anticorps finissent généralement par contrôler l'infection disséminée, même en l'absence de traitement, et les symptômes s'estompent.Chez les espèces-réservoirs de borrélies, comme la souris, les infections ne semblent pas pathogènes malgré la persistance à vie de la bactérie, suggérant que les systèmes immunitaires de certains hôtes sauvages ont co-évolué avec la bactérie de façon à la « tolérer ».L'humain n'est pas un hôte réservoir naturel ; son système immunitaire reste activé tant que la bactérie n'est pas éliminée (celle-ci pouvant persister longtemps dans des sites localisés dans divers tissus,).
Cette persistance et sa signification médicale dans divers tissus font l'objet de discussions.
Non-traitée, la bactérie a été mise en évidence des années après inoculation, notamment dans les lésions cutanées tardives (acrodermatite chronique atrophiante ou ACA).Des études de cas suggèrent que, même après un traitement antibiotique intense et de long terme, la bactérie peut durablement persister dans l'organisme, dans divers organe sous forme d'agrégats (de type biofilms) protégés du système immunitaire,.
Cette persistance est aussi observée dans le modèle animal (in vivo) où l'on retrouve une forme de B. burgdorferi survivante à un traitement antibiotique,.Chez l'humain, une infection ne crée pas d'immunité protectrice, même si des anticorps restent présents.Classiquement, la maladie évolue en trois phases, non obligatoires.
Chaque phase peut être révélatrice ou s'intriquer avec une autre, avec des poussées ou des rémissions à chaque phase.
Outre les variations selon les zones géographiques (Amérique et Eurasie), la maladie est aussi variable selon les patients (certains ne présentent que la phase primaire, d'autres la phase tertiaire).La phase primaire, ou précoce localisée, qui survient 3 à 30 jours après l'inoculation, est une phase cutanée, représentée par l'érythème migrant.
Dans 20 à 30 % des cas, elle est absente ou passe inaperçue.La phase secondaire, ou précoce disséminée, se manifeste dans les semaines ou mois après inoculation.
Elle peut être révélatrice (apparaître en premier).
Selon les cas (germe causal en rapport avec la zone géographique), les troubles peuvent être neurologiques, articulaires, cardiaques, ou cutanés.Ces deux premières phases sont parfois regroupées en une seule phase dite précoce, surtout en Europe, car les troubles sont divers (plus grande variété de borrélies).
La maladie de Lyme se présente comme un ensemble polymorphe (maladies apparemment différentes).
Alors qu'en Amérique du Nord, la maladie de Lyme se présente plutôt sous une forme articulaire, unique ou prédominante.La phase tertiaire se produit des mois ou des années après inoculation.
Elle signe une infection persistante ou résurgente, elle peut être aussi révélatrice.
Ces formes tardives sont reconnues lorsqu'elles forment des ensembles typiques et cohérents d'un point de vue clinique et biologique.
Elles sont discutées ou controversées quand la clinique n'est pas caractéristique et la biologie non validée.L'existence et l'importance de formes asymptomatiques est en discussion.
Leur fréquence serait de l'ordre de 5 % de sujets séropositifs en zone d'endémie, et jusqu'à 20 % dans des populations à risques (travailleurs forestiers).
Ces cas asymptomatiques indiqueraient un contact ancien avec la bactérie, ou une ancienne infection guérie.C'est une phase précoce et locale, réalisant l'érythème migrant caractéristique, mais non systématique.
Elle correspond à une infection initiale cutanée, localisée autour du point de piqûre.Cette lésion apparaît de 3 à 30 jours après.
Elle siège le plus souvent aux membres inférieurs ou à la partie inférieure du tronc ; plus rarement à la tête (petits enfants).Il s'agit d'un érythème annulaire avec une bordure active qui s'étend de façon centrifuge, tandis que le centre s'éclaircit avec petite tache rouge centrale (séquelle de la piqûre de tique).
Le diamètre initial de l'anneau est de quelques cm, puis jusqu'à 15 cm en moyenne, pouvant dépasser les 20 cm (un cas de 70 cm a été publié).Cet érythème migrant peut présenter quelques différences entre sa forme américaine et européenne.La lésion est unique, légèrement chaude, mais indolore, et sans prurit.
En Europe, où la maladie est plus souvent due à B. afzelii ou B. garinii, l'inflammation est à ce stade généralement moins intense qu'en Amérique du Nord, et la croissance (migration) de l'érythème y est souvent plus lente.Cet érythème migrant est habituellement isolé, sans fièvre, sans syndrome inflammatoire.
Plus rarement, il peut exister des signes de dissémination précoce avec fièvre, douleurs, troubles neurologiques.Elle est souvent faite de lésions multiples.
La partie centrale reste rouge ou foncée et devient plus indurée.
Son bord externe reste également rouge, mais plus rarement, la portion de peau située entre le centre et le bord retrouve une couleur normale.
Parfois une nécrose centrale, ou une vésicule apparaît à l'emplacement de la piqûre, éventuellement avec prurit intense persistant, si la maladie n'a pas été soignée précocement.Plus souvent qu'en Europe, il peut exister des signes de dissémination précoce avec fièvre, douleurs, troubles neurologiques.Quand les aspects caractéristiques de ces deux formes sont présents, l'érythème migrant est pratiquement pathognomonique, et suffit à lui seul au diagnostic.Cet érythème migrant disparaît spontanément en 4 à 6 semaines.
Avec un traitement précoce, l'évolution est plus rapide : la lésion disparaît en moins d'une semaine, et la maladie n'évolue pas vers des formes plus compliquées.Elle survient le plus souvent à partir de quelques semaines à quelques mois après l'inoculation, lorsque la lésion initiale est restée absente ou passée inaperçue, ou sans antibiothérapie adaptée.Ce stade correspond à une dissémination bactérienne, suivie d'une focalisation sur des tissus particuliers.Les manifestations sont dominées en Europe par des troubles neurologiques (« neuroborréliose ») et en Amérique par des troubles rhumatologiques (« arthrite de Lyme »).
Plus rarement se rencontrent des troubles cardiaques, cutanés et oculaires.Si la phase primaire est absente (phase secondaire révélatrice), le diagnostic peut être confirmé par l'association d'arguments cliniques, épidémiologiques et biologiques (à ce stade, l'infection active est habituellement détectable dans le liquide céphalorachidien et sur les tests sérologiques pertinents, mieux qu'en phase trois).L'incidence de ces neuroborrélioses (formes neurologiques de la maladie de Lyme) varie selon les pays et les régions.
En Europe, on trouve plus de 15 % de neuroborréliose parmi les maladies de Lyme, alors qu'aux États-Unis, cette proportion ne dépasse pas les 8 %.En Europe, elle varie aussi selon les régions, pour cent mille habitants : Danemark 0,5 cas, Suède 1 cas, Allemagne 3 cas, Alsace 10 cas.Les formes les plus fréquentes (70 à 80 % des neuroborréliose) sont les méningoradiculites (polynévrite avec infection du liquide cérébrospinal).
Elles apparaissent après 3 semaines à plus de 3 mois après la piqûre de tique.Il s'agit d'abord de troubles sensitifs, plus souvent que moteurs, de la zone de l'érythème migrant.
Les douleurs sont sévères (brûlure, arrachement), souvent à recrudescence nocturne et provoquant l'insomnie.
Ces douleurs n'ont pas toujours un trajet radiculaire strict.
Il peut exister une atteinte associée des nerfs crâniens, se manifestant surtout par une paralysie faciale périphérique, bilatérale dans un tiers des cas.La neuroborréliose est la cause la plus fréquente de paralysie faciale périphérique chez l'enfant.Plus rarement, dans 0,5 à 8 % des cas, on peut trouver des méningites aiguës, des myélites aiguës, des encéphalites aiguës.Dans ces manifestations neurologiques aiguës ou subaiguës, le diagnostic est fait par l'étude du liquide cérébrospinal (LCS).
La ponction lombaire permet de confirmer une méningite lymphocytaire.
Une sérologie du LCS est associée à la recherche d'une synthèse intrathécale d'anticorps spécifiques.Chez l'enfant, en cas de paralysie faciale périphérique, une sérologie sanguine positive est considérée comme suffisante pour confirmer le diagnostic et prescrire une antibiothérapie.Les radiculites hyperalgiques résistent aux antalgiques habituels.
Elles peuvent disparaître spontanément en quelques semaines ou mois.
Elles cèdent plus rapidement en quelques jours avec une antibiothérapie adaptée.Les manifestations articulaires ont été à l'origine de la redécouverte de la maladie aux États-Unis, où elles sont plus fréquentes (60 % des malades) qu'en Europe (10 à 15 %).
Elle s'observe à tout âge, mais plus souvent chez l'enfant.En Europe, elles sont précoces (quelques jours à quelques semaines après l'inoculation) et guérissent spontanément le plus souvent.
En Amérique, elles sont plus tardives (6 mois en moyenne jusqu'à 2 ans), pour devenir plus souvent chroniques, réalisant le tableau de l'arthrite de Lyme.
En Europe, les troubles articulaires sont classés en phase secondaire, alors qu'en Amérique, ils appartiennent à la phase tertiaire.Dans sa forme la plus typique, l'arthrite de Lyme réalise une atteinte d'une seule grosse articulation (mono- ou oligoarthrite), avec douleurs et épanchement de liquide synovial, surtout au genou (moins souvent épaule, coude…).
Cette atteinte est asymétrique, récidivante (avec poussées et rémissions), parfois permanente, et susceptible de durer plusieurs années en l'absence de traitement.La plupart des patients guérissent par antibiothérapie adaptée, mais certains conservent une synovite post-infectieuse, réfractaire aux antibiotiques.À l'exception d'une asthénie marquée, les troubles généraux sont rares.
En particulier, il n'y a pas en général de fièvre dans une maladie de Lyme.Dans moins de 5 % des cas, il peut exister des troubles cardiaques par bloc atrio-ventriculaire, se manifestant par des palpitations intermittentes ou des malaises.
Ces derniers troubles sont spontanément régressifs et ne nécessitent que très rarement la mise en place d'un stimulateur cardiaque définitif.
Une péricardite d'évolution prolongée est possible.
Une maladie de Lyme doit être recherchée systématiquement chez tout patient jeune ayant un bloc atrio-ventriculaire paroxystique inexpliqué.Dans la même proportion, on peut trouver une manifestation dite lymphocytome borrélien.
C'est un nodule rouge violacé, de 1 à 2 cm, qui siège le plus souvent au niveau de la face, du lobule de l'oreille, de l'aréole mammaire ou du scrotum.Dans 1 % des cas, il existe des troubles ophtalmologiques divers : conjonctivite, uvéite, kératite, etc.La limite entre les formes secondaire et tertiaire est difficile à établir.
Une forme secondaire se prolonge devenant tertiaire, ou des manifestations tertiaires apparaissent, apparemment primitives, des années après l'infection.Des phénomènes auto immunitaires pourraient expliquer ces symptômes, mais la responsabilité directe de la bactérie au cours de ces manifestations tardives reste discutée,.Il s'agit de formes chroniques : cutanées, articulaires ou neurologiques.
Du point de vue clinique, elles ne sont guère spécifiques (elles peuvent aussi se rencontrer en dehors de la maladie de Lyme), à l'exception de l'acrodermatite chronique atrophiante.L'acrodermatite chronique atrophiante, ou ACA, autrefois aussi nommée « maladie de Pick-Herxheimer », est liée à la maladie de Lyme de manière certaine : le germe a pu être isolé dans les biopsies de la lésion.
C'est le symptôme le plus net de cette troisième phase, mais il n'est principalement observé qu'en Europe et pas chez tous les patients.L'ACA commence avec un changement de couleur et de texture d'une surface de peau, habituellement sur une région exposées au soleil des membres supérieurs ou inférieurs.
L'atrophie se traduit par des surfaces de peau qui deviennent très fines et transparentes, prenant une apparence rappelant un papier froissé de cigarette et une couleur rouge à violacée, avec parfois l'apparence de certains lichens plan.
L'ACA d'abord localisée peut ensuite s'étendre peu à peu et parfois se bilatéraliser.Il s'agit d'une arthrite de Lyme (voir section phase secondaire) qui persiste et se prolonge en étant réfractaire à l'antibiothérapie.La « neuroborréliose tardive » regroupe plusieurs entités, dont l'encéphalite (atteinte cérébrale) et les polyneuropathies (atteinte des nerfs).
Elles apparaissent au-delà de 6 mois après la piqûre de tique.L'encéphalite ou encéphalomyélite, chronique ou tardive, se manifeste par des troubles variés : troubles cognitifs, difficultés de concentration parfois associés un état de fatigue, douleurs, faiblesse musculaire, troubles moteurs….
Le lien avec une maladie de Lyme est reconnu lorsqu'on retrouve une synthèse d'anticorps spécifiques dans le liquide cérébrospinal.Une polyneuropathie se manifeste d'abord avec des pics de douleurs, parfois accompagnés d'engourdissements et picotements dans les mains ou les pieds.
Elle est classiquement associée à l'acrodermatite atrophiante.
Il peut s'agir aussi de douleurs radiculaires chroniques isolées se manifestant comme une sciatique.Elles sont mal connues et difficiles à rattacher formellement à une borréliose.Des manifestations dermatologiques (autres que le lymphocytome et l'acrodermatite) ont été décrites : morphée, sclérodermie, dermatomyosite… mais le lien avec une maladie de Lyme reste hypothétique et discuté.Certains patients, après un traitement antibiotique bien conduit, présentent des troubles subjectifs chroniques (céphalées, fatigue, et douleurs articulaires) alors que la clinique et la biologie objectives sont en faveur de la guérison.
On parle alors de « syndrome post-borréliose de Lyme » ou PLDS Post-Lyme Disease Syndrom.
À partir de là, et selon une continuité confuse, le terme de « maladie chronique de Lyme » est apparu.
Non ou mal défini, il regroupe tout un ensemble de pathologies chroniques diverses, rapportées à une maladie de Lyme.
Il s'agit de revendications, apparues aux États-Unis dans les années 1990, et portées tout autant par des patients soignés et traités, mais non guéris, que par des patients ni diagnostiqués, ni traités auparavant pour maladie de Lyme.
Ce mouvement associatif entend défendre ce diagnostic et bénéficier de thérapies alternatives,.L'examen clinique reste l'élément de base de la démarche diagnostique d'une maladie de Lyme, On recherche la notion de piqûre de tique et d'érythème migrant, l'origine géographique et les activités du malade en évaluant le caractère plus ou moins caractéristique des lésions.
Les différents examens s'organisent et s'interprètent en fonction de ces données cliniques.
En 2019, le diagnostic de confirmation le plus consensuel repose sur une sérologie à deux niveaux, pour chaque stade de l'infection, sauf en présence d'Erythema migrans (1er stade) qui fait considérer l'infection comme certaine.Il existe des difficultés de diagnostic sérologiques en Europe du fait de la diversité des espèces pathogènes impliquées, comme celle des réactifs ; d'où l'absence d'une standardisation.
Alors qu'aux États-Unis, la sérologie est plus facile à interpréter (critères standards du CDC), du fait de la présence d'une espèce pathogène très prédominante (B. Burdorgferi au sens strict),.
Néanmoins, dans les années 2010, même aux États-Unis, « la variabilité inter-laboratoires était considérable et reste un problème dans les tests de maladie de Lyme ».Lors de la phase primaire, le diagnostic est exclusivement clinique pour l'érythème migrant.
À ce stade, la sérologie est inutile, la production d'anticorps étant encore insuffisante.
De même les données biologiques, toujours à ce stade, sont habituellement normales.
La présence d'un syndrome inflammatoire important doit faire évoquer un autre diagnostic.Lors de la phase secondaire, les examens sérologiques (dosages d'anticorps) se discutent en fonction du contexte.
Il existe deux méthodes couramment utilisées en pratique : ELISA et Western Blot.
Le test ELISA est utilisé en première intention, s'il est positif ou douteux, il doit être confirmé par Western-Blot.
L'administration de Stevia ou de Serrapeptase avant le test, par son effet anti biofilm, permet de relâcher des bactéries dans le système sanguin ce qui améliore la sensibilité de la détection.Cette sérologie se pratique dans le sang (lymphocytome, atteinte cardiaque, arthrite…), dans le liquide articulaire (arthrite) ou dans le liquide cérébro-spinal (neuroborréliose).Une sérologie positive n'a de valeur pathologique que dans un contexte clinique évocateur.
Inversement, une sérologie négative dans le même contexte incite à répéter ou poursuivre l'investigation.La PCR vise à détecter la présence d'un fragment de génome d'une borrelia.
C'est un examen optionnel, en deuxième intention, dans des cas douteux (contexte clinique et épidémiologique évocateur, mais sérologie négative).
Il se fait sur des localisations particulières (prélèvement cutané, liquide cérébrospinal, liquide articulaire) selon le contexte.La PCR est très spécifique, mais ne prouve pas une infection active, car l'ADN des borrélies peut persister après leur mort (élimination sous antibiotiques).
Aussi aux États-Unis comme en Europe, la sérologie reste, en pratique courante, la seule méthode immédiatement disponible pour le diagnostic.
En 2019, « aucun test sérologique ne permet (…) de faire la différence entre une infection passée et une infection active.
Le rôle de l’interniste est double : penser à une maladie de Lyme devant des symptômes focaux et/ou généraux mais aussi ne pas attribuer à tort à une maladie de Lyme des symptômes qui doivent faire ouvrir le champ des diagnostics différentiels ».Une étude a montré que l'on peut détecter une infection active par analyse de l'ADN libre circulant, avec un sensibilité supérieure à la sérologie.À la phase primaire, lorsqu'il est atypique, l'érythème migrant peut être confondu avec un eczéma nummulaire, un érythème polymorphe, une dermatophytose, etc. et, dans le sud-est des États-Unis à un STARI (acronyme de Southern tick-associated rash illness).Lorsque l'érythème migrant est absent ou passé inaperçu, de nombreux diagnostics peuvent être évoqués à la phase secondaire : neurologiques (encéphalite ou myélite virale, Guillain-Barré, paralysie faciale a frigore, sclérose en plaques…), rhumatologiques (polyarthrite rhumatoïde, arthrite réactionnelle, arthrite juvénile…).À la phase tardive, l'acrodermite chronique peut être confondue avec des troubles liés à une insuffisance veineuse, ou à des sclérodermies localisées.
Les troubles généraux font discuter d'une fibromyalgie ou d'une fatigue chronique.La différence peut être faite par la sérologie, et par le fait que les symptômes s'améliorent sous antibiothérapie.La situation la plus complexe se présente lorsqu'un patient est étiqueté « malade chronique de Lyme » ou CLD Chronic Lyme Disease.
Cette entité n'est pas reconnue par la communauté scientifique à cause d'une absence de définition de ces patients, et de l'incapacité de déterminer la présence de germes actifs persistant après traitement standard.L'existence d'un Lyme chronique n'est pas démontrée scientifiquement,.Aux États-Unis, des diagnostics seraient effectués dans le cadre d'une « contre-culture » pseudoscientifique rassemblant des associations, des laboratoires de tests diagnostiques non validés, et des médecins auto-proclamés spécialistes de l'affection ou « Lyme literate medical doctors » (LLMD), ayant des activités de lobbying auprès du Congrès américain et sur Internet.Ces diagnostics de « maladie chronique de Lyme » se répartissent en quatre catégories :Une étude récente (2019) a cherché à estimer le nombre de cas de forme chronique de la maladie aux États-Unis en 2016 et 2020.
Ses résultats montrent une prévalence des formes chroniques « élevée et en augmentation » aux États-Unis : sur la base des données disponibles, de 69 011 à 1 523 869 personnes en étaient victimes en 2016, et en 2020 la prévalence pourrait atteindre 1 944 189 cas.La prise en charge de la maladie de Lyme a fait l'objet de la publication de recommandations.
Celles de l'« Infectious Diseases Society of America » (IDSA), l'« American Academy of Neurology » (AAN) et de l'« American College of Rheumatology » (ACR) datent de 2020.L'objectif du traitement antibiotique est de guérir les manifestations cliniques et d'éviter l'évolution vers des formes secondaires et tertiaires, ce qui s'obtient par l'éradication complète des Borrelia.
On ne cherche pas à obtenir une sérologie négative.En pratique, on utilise une cycline, et en deuxième intention ou dans des cas particuliers, une β-lactamine (céphalosporine).En phase primaire (érythème migrant), l'amoxicilline ou la doxycycline doivent être prescrits durant 14  à   21 jours, au plus tôt : dans les 72 heures si possible pour un meilleur résultat.En phase secondaire et tertiaire, pour les neuroborrélioses, les céphalosporines sont principalement utilisées, habituellement la ceftriaxone, pour une durée de 21 à 28 jours, au moins ; par voie veineuse périphérique en cas de méningo-encéphalite.Pour les formes tertiaires, des durées plus longues peuvent être proposées selon les cas.En mai 2019 un ensemble de sociétés savantes françaises émet l'avis suivant : Chez environ 15 % des patients, l'antibiothérapie peut provoquer une réaction de Jarisch-Herxheimer, liée à la lyse des bactéries, avec exacerbation des symptômes.
Il s'agit d'une réaction transitoire sans gravité, qui disparaît en quelques heures, ou un à deux jours.En 2021, des chercheurs américains ont fait part d'un traitement microbien potentiel recourant à l'hygromicine A pour traiter cette maladie.
Cette découverte pourrait permettre également d'éradiquer la maladie dans l'environnement par l'apposition d'appâts dans des zones naturelles infectées.Les infections traitées en phase primaire sont guéries par les antibiotiques recommandés.
Si la phase primaire passe inaperçue, ou insuffisamment traitée, la maladie continue d'évoluer.Environ 10 % des patients traités, et peut être plus chez ceux ayant une neuroborréliose, continuent d'avoir des troubles subjectifs (fatigue, douleurs musculaires, troubles cognitifs…).
Ces troubles persistent plus de 6 mois après antibiothérapie préconisée, et jusqu'à plus de 10 ans, au moins de façon intermittente.Même si la plupart des patients s'améliorent au fil des mois, cet état affecte durablement la qualité de vie.
C'est le « syndrome post-borréliose de Lyme », ou PLDS Post-Lyme Disease Syndrom.
Dans cette situation, les études contrôlées ne montrent pas de différence entre une antibiothérapie prolongée et un placebo, ce qui indique que la bactérie ne peut pas être responsables des symptomes.Si l'antibiothérapie prolongée n'est pas une solution pour ces états chroniques, de nouvelles stratégies de prise en charge doivent être mises en œuvre ; en sachant que près de 40 % des patients chroniques de « post-borréliose de Lyme » sont améliorés par un placebo.
Le malade « post-Lyme » rejoint alors les millions de personnes qui, dans le monde, souffrent de fatigue et douleurs chroniques d'origine indéterminée.Ainsi, les troubles dépressifs sont à traiter selon les normes habituelles, et les douleurs persistantes selon une approche multidisciplinaire analogue à celle du traitement de la fibromyalgie.
Il existe donc des combinaisons de médicaments (antalgiques, d'antidépresseurs…), de thérapies comportementales, kinésithérapie et acupuncture.Des techniques d'origine neurochirurgicales, dites de neuromodulation par stimulation spinale, ont été développées pour traiter des syndromes complexes de douleurs chroniques ou des douleurs post-opératoires.
Elles semblent pouvoir diminuer la douleur de patients atteints d'arthrite de Lyme chronique et résistante aux traitements classiques (médicaments, kinésithérapie),.Parallèlement, des vaccins sont en cours de développement.De nombreux traitements alternatifs sont proposés sur le net.
Le problème central étant qu'ils prétendent soigner des symptômes d'une maladie alors que son existence n'est pas prouvée (les études citées dans le paragraphe précédent concluant même à son inexistence).
Sans preuve d'efficacité -ce qui est logique puisque l'existence même de la maladie n'est pas validée- certains présentent un risque certain d'effet indésirable,.Des préparations phytothérapeutiques sont proposées ou distribuées par divers laboratoires.Plusieurs plantes, et surtout la quinine du Ghana (Cryptolepis sanguinolenta), et la renouée du Japon (Polygonum cuspidatum) ont été étudiées et testées in vitro sur des cultures de Borrelia avec des résultats encourageants qui demeurent à être confirmés.En France, le Tic Tox, est un mélange d'huiles essentielles et de propolis mis au point par Bernard Christophe (1949-2016), un pharmacien alsacien spécialisé en phyto-aromathérapie.
Ce produit a été suspendu en 2012, en attendant sa mise en conformité avec la réglementation, par l'Agence nationale de sécurité du médicament et des produits de santé (AFSSAPS), qui a fait valoir notamment qu'il contient de la sauge officinale (potentiellement toxique selon les doses ingérées) et un terpène, la thuyone, outre une « absence d'autorisation de mise sur le marché, » (AMM).La prévention primaire (agir directement sur la cause : hôtes et vecteurs) est difficile, à cause de la diversité du réservoir animal.
Agir sur l'un des facteurs d'émergence (voir section épidémiologie) est toujours discuté, car si l'on cerne à peu près ces facteurs, la façon dont ils réagissent entre eux est mal connue.
Par exemple, aux États-Unis où la diversité des réservoirs semble moins grande, la réduction de la population des cervidés (cerfs de Virginie notamment), comme moyen de réduire la maladie humaine,,, fait débat.Les mesures recommandées sont l'évitement d'une exposition aux tiques.Une étude de sciences participatives lancée l’été 2017 en France par l'Inra, basée sur une application (« Signalement Tiques ») permettant de cartographier les lieux où ont eu lieu les piqûres de tiques vient de montrer que — contre toute attente — si 53 % des cas concernent la forêt, 1/3 (27 % exactement) des piqûres déclarées volontairement ont eu lieu dans des jardins de maisons privés, et « seulement 10 % dans des prairies ».
Les déclarants sont invités à photographier la tique et à l’envoyer par courrier aux chercheurs (54 envois par jour en moyenne en mai 2018).
Un biais probable joue en la faveur des déclarations sur l’humain et le public des répondants n'est sans doute pas représentatifs de toute la population.
Pour 1 254 signalements de piqûres sur les animaux, 4 198 l’ont été chez l’humain.
Les piqûres concernent d’abord des personnes de 20 à 40 ans (30 % des cas), et de 40 à 60 ans (26 %).
Ce taux chute à 17 % chez les 5 à 20 ans.
Suivent les personnes de plus de 60 ans (15 % des cas), et les enfants de moins de 5 ans (12 % des cas).
Pour les animaux, les déclarations concernent surtout les chiens (45 % des cas) et chats (44 %) et moindrement les chevaux et le bétail (6 et 5 % des cas).Parmi les mesures parfois préconisées :Ces précautions ne sont pas toujours suffisantes et n'ont pas une efficacité démontrée à 100 %, car les nymphes de tique sont à la limite de la visibilité (1 à 2 mm) et leur piqûre est indolore.
De plus, les animaux de compagnie peuvent ramener des tiques à la maison, d'où une contamination croisée avec l'être humain.La contamination nécessite un temps long de présence de la tique sur la peau.
Si le risque débute dès la première heure, il est proportionnel au temps de contact, avec un maximum entre 48 et 72 heures (le repas sanguin de la tique durant de 2 à 5 jours).Si la tique est retirée de la peau dans les 36 premières heures après qu'elle s'y est fixée, les risques de contamination sont réputés faibles ; inférieurs à 1 %, car les borrelia ne sont à ce moment pas encore dans les glandes salivaires de la tique mais dans son tube digestif.
Pour infecter l'hôte, elles doivent encore migrer du tube digestif aux glandes salivaires, ce qui peut demander 2  à   3 jours, cette durée pouvant être raccourcie en Europe.Les méthodes folkloriques, qui utilisent une goutte de divers produits visant à endormir, étouffer, ou détacher la tique sont trop lents ou font risquer une régurgitation de la tique : éther, benzine, essence, gazoil, huile de table, vernis à ongle, chaleur par cigarette allumée… Il ne s'agit pas d'attendre, la tique doit donc être retirée le plus rapidement possible, sans la manipuler,.Divers modèles de pinces spéciales ou de sortes de petits pieds de biche qui permettent d'extraire les tiques en les tournant doucement sont vendus en pharmacie (avec un modèle plus petit pour les larves et nymphes).
Il ne faut pas tirer, mais tourner doucement comme pour dévisser, on peut extraire sans peine la tique, au moins si elle n'est pas ancrée depuis trop longtemps.
Ce geste évite le risque de laisser le rostre ou la tête et son cément fichés dans la peau, ce qui peut provoquer une infection, voire un abcès.À défaut de tire-tique, on peut utiliser une pince fine à épiler, pour tirer la tique sans la tordre ou l'écraser,.Après le retrait de la tique (et non avant, pas de produit sur une tique attachée), la plaie doit être soigneusement désinfectée et surveillée.
À ce stade, l'antibiothérapie prophylactique n'est pas recommandée pour une piqûre simple de tique, en raison de la faible probabilité de contamination.
Celle-ci peut se discuter dans certains cas particuliers (femme enceinte, personne immunodéprimée…) ou encore, en zone hyperendémique, lorsque la tique est retirée tard et gorgée de sang.Il en est de même aux États-Unis où, après piqûre de tique, l'antibiothérapie prophylactique n'est pas généralement recommandée par les CDC.
Les exceptions concernent les zones hyperendémiques où toute personne mordue de plus de 8 ans peut recevoir une dose unique de 200 mg de doxycycline dans les 72 h après le retrait de la tique.
Pour cela, toutes les conditions suivantes doivent être réunies : pas de contre-indication à la doxycycline, tique I. scapularis identifiée, tique gorgée de sang avec un temps estimé supérieur à 36 h d'attachement.Après piqûre de tique, une surveillance de la plaie est nécessaire et suffisante.
Dans les jours ou semaines qui suivent, il est impératif de consulter un médecin pour antibiothérapie adaptée, si une tache apparaît et grandit progressivement (érythème migrant).
Il en est de même en cas d'apparition d'un état fébrile ou grippal (plus souvent en Amérique qu'en Europe).Il n'existe plus en 2020 de vaccin humain disponible contre la maladie de Lyme.Des vaccins vétérinaires existent, dont pour le chien, soit basés sur la bactérie entière tuée, soit sur des sous-unités (protéines de surface OspA ou OspC).Un vaccin (recombinant), le Lymerix de Smith-Kline-Beecham, a été commercialisé aux États-Unis de décembre 1998 (après approbation par la FDA) à février 2002.
Il ciblait une des protéines de surface les plus communes de B. Burgorferi, Osp A.
Il a été recommandé pour les personnes à risques en zone d'endémie, et 1,4 million de doses ont été distribuées.
Les études ont montré que son efficacité était de l'ordre de 70 à 80 % sans effets secondaires significatifs, mais des incertitudes sur son effet protecteur à long terme impliquaient que des rappels annuels pouvaient être nécessaires.En 1999, des rumeurs associent le vaccin à des arthrites auto-immunes, et conduisent à des poursuites judiciaires, une action collective est ainsi menée par 121 plaignants.
Les études effectuées par le CDC et la FDA ne confirment pas de relations de causalité, en estimant que les avantages du vaccin l'emportent sur les risques.
Le vaccin reste donc à disposition du public, mais les ventes s'effondrent en raison de la couverture médiatique des procès en cours et des polémiques sur le risque théorique d'auto-immunité.En 2002, le fabricant retire de lui-même son vaccin du marché, pour des raisons économiques.
En 2003, un accord est conclu avec les plaignants : ils cessent toute poursuite judiciaire en échange d'un million de dollars servant à rembourser les frais d'avocats et de justice.Les recherches vaccinales cherchent à cibler les protéines de surface les plus constantes de la bactérie,.
Un vaccin de ce type pour l'Europe et les États-Unis est en préparation.Selon Stanley Plotkin, le vaccin idéal contre la maladie de Lyme doit avoir au moins 80 % d'efficacité sur deux ans, des deux côtés de l'Atlantique, être bien toléré, ne pas comporter de déterminant antigénique à risque théorique, et être utilisable chez l'enfant.
Il doit aussi être accepté par le public ; pour éviter les fautes de communication commises lors de l'affaire du Lymerix, un nouveau vaccin devra répondre à une demande concertée des acteurs de santé publique, et du public afin qu'il existe un marché pour ce vaccin,.Une autre stratégie est de casser le cycle de vie de la bactérie par un vaccin (ou des vaccins) ciblant les réservoirs animaux et/ou les vecteurs (tiques) :Les maladies transmises par les tiques (maladie de Lyme notamment) ont un coût annuel qui s'élève à plusieurs dizaines de millions d'euros par an pour de nombreux pays (ex : coût estimé à 20 millions d’euros/an pour les Pays-Bas et à 80 millions d’euros/an pour l’Allemagne pour ce qui concerne le milieu des années 2010.Aux États-Unis où on estime que malgré les actions d'information et de prévention, le nombre de cas de maladie de Lyme a pratiquement triplé de 1990 à 2019 (plus de 300 000 cas/an), les actions préventives et de gestion de la maladie sont freinées par des diagnostics inadéquats (avec une sous estimation du nombre de cas : 30 000 cas officiellement déclarés de maladies à tiques aux États-Unis par an, contre 300 000 probablement en réalité), notait le New England Journal of Medicine.
Le fabricant du seul vaccin disponible contre la maladie de Lyme l'a retiré au motif d'une baisse des ventes et de problèmes de responsabilité.En 2018, les NIH avaient dépensé 23 millions USD pour la seule maladie de Lyme en 2018, pour un total de 56 millions USD affecté à toutes les maladies transmises par les tiques.
En 2019, après l'avis d'un groupe consultatif mandaté par le gouvernement des États-Unis (avis alarmant et concluant au besoin d'augmenter les actions et les moyens financiers de la recherche au sujet des maladies à tiques au niveau fédéral), les NIH ont produit un nouveau plan stratégique pour lutter contre ces maladies, et en Avril 2019, ils ont lancé un appel à propositions de prévention des maladies transmises par les tiques, doté de 6 millions de dollars d'ici 2020.
De leur côté, selon la revue Science, les scientifiques espèrent encore plus d'argent pour améliorer le diagnostic de la maladie, et les moyens de la soigner.Il s'agit de thèses et arguments développés par un courant alternatif, opposé aux recommandations officielles des sociétés savantes qui, elles, font consensus à leur niveau international et qui sont reprises par l'ensemble des autorités sanitaires en Amérique du Nord comme en Europe.Le courant alternatif est apparu aux États-Unis, dans les années 1990, où des médecins se sont rassemblés dans une International Lyme and Associated Diseases Society (ILADS), appuyée par des associations de malades.
Ce courant soutient que les recommandations officielles sont trop restrictives, que la maladie est sous-diagnostiquée et sous-traitée.
Il cherche donc à promouvoir de nouvelles attitudes thérapeutiques auprès des pouvoirs publics, notamment par la reconnaissance d'une « maladie chronique de Lyme », et d'une antibiothérapie de très longue durée, parfois associée à des thérapies non conventionnelles.Pour la majorité de la communauté médicale, le courant du « Lyme chronique » serait un ensemble de microbiologie, immunologie et pharmacologie « alternatives », diffusés sur internet et d'autres médias, mêlés à des témoignages de patients.
Ce courant représenterait 2 % des médecins dans le Connecticut, l'une des régions où l'endémie de Lyme est la plus forte ; il s'agirait d'attitudes reposant sur des présomptions ou des convictions subjectives, et non sur des éléments scientifiques validés.
La forme chronique de la maladie s'exprimerait le plus souvent par des symptômes subjectifs, les divers tests (tests urinaires, comptage de lymphocytes CD 57, immunofluorescence pour mettre en évidence des formes L de Borrelia, etc.) auraient été mis au point par des « laboratoires spécialisés de Lyme » et ne seraient pas cliniquement validés ni agréés par la FDA.En 2019, une revue des recommandations européennes et américaines concernant le diagnostic de la maladie de Lyme, montre que sur les directives de 16 sociétés savantes de 7 pays, une seule présente une discordance majeure (une société allemande, la Deutsche Borreliose-Gesellschaft, non reconnue comme société académique par les autorités allemandes).
La conclusion est « Contrairement au débat animé qui a lieu sur Internet et dans les médias européens et américains, notre analyse montre que la majorité des recommandations scientifiques médicales avec un score qualitatif élevé s'accordent sur les méthodes diagnostiques cliniques de la maladie de Lyme ».Le terme de Lyme chronique (ou syndrome post-traitement) peut désigner les rechutes, les symptômes persistants après l'arrêt du traitement antibiotique ou des complications chroniques attribuées, de façon consensuelle, à la maladie de Lyme.
Il peut aussi désigner des formes chroniques contestées par la majorité de la communauté médicale, ce qui prête à confusion.La forme chronique  de la maladie a fait l'objet de définitions, par exemple en Suisse en 2005 : « preuves cliniques et de laboratoire documentées d'une infection antérieure par B. burgdorferi, cycle complet d'antibiothérapie appropriée, symptômes incluant fatigue, arthralgie, myalgie, dysfonctionnement cognitif ou douleur radiculaire persistant pendant plus de 6 mois, association plausible en temps opportun entre l'infection documentée par B. burgdorferi et apparition des symptômes (c.-à-d.
symptômes persistants ou récurrents ayant débuté dans les 6 mois suivant la fin d'une antibiothérapie recommandée pour la borréliose de Lyme précoce ou tardive) et exclusion des autres causes somatiques ou psychiatriques des symptômes ».En France, en 2018, un rapport de la HAS propose de distinguer une entité appelée SPPT (Syndrome Persistant Polymorphe après possible piqûre de tique) définie comme l'association de polyalgies (douleurs multiples), fatigue et troubles cognitifs durant plus de 6 mois.De même, aux États-Unis en 2019, L'ILADS a défini la forme chronique de la maladie de Lyme comme « maladie multisystémique avec un large éventail de symptômes et/ou de signes qui sont présents de manière continue ou intermittente pendant au moins six mois ».
Les symptômes persistants sont fatigue, douleurs, troubles du sommeil, cognitifs et neurologiques, à traiter par antibiothérapie prolongée.
La forme chronique résulte « d'une infection active et continue par l'un des nombreux membres pathogènes du complexe Borrelia burgdorferi sensu lato (Bbsl).
L'infection a des périodes de latence variables et les signes et symptômes peuvent augmenter, diminuer et migrer ».Pour l'ILADS, représentant le courant minoritaire alternatif, la maladie est ubiquitaire et répandue sous des formes ou des transmissions méconnues (par exemple sexuelle).L'ILADS distingue la forme chronique non traitée, et précédemment traitée (avec dans ce dernier cas des manifestations de forme chronique persistant ou réapparaissant après le traitement et présentes en continu ou selon un schéma récidivant/rémittent sur une durée de six mois ou plus).
Ces définitions ont été élaborées sur la base d'une « revue systématique de plus de 250 articles révisés par des pairs dans la littérature internationale ».Le caractère chronique, d'abord silencieux, puis antibiorésistant de la maladie peut avoir plusieurs explications (compatibles entre elles) :En 2014, pour la très grande majorité des experts, représentés par l'IDSA, l'implication de ces 3 variants morphologiques dans une forme chronique de la maladie de Lyme n'était pas démontrée.
En 2015, l'IDSA met en doute le concept de « crypto-infections » (lié à des co-infections, quand la tique transmet plusieurs maladies), surtout quand des bactéries non connues pour être transmissibles par tiques, voire des pathogènes fantaisistes sont évoqués.
En 2019, pour la quasi-totalité des sociétés savantes d'infectiologie d'Europe et d'Amérique du Nord, il n'existe pas d'arguments scientifiques permettant de définir une « maladie chronique de Lyme »,.Selon le Professeur Lantos, membre du panel des recommandations de l’IDSA, de telles controverses persisteront « aussi longtemps que des patients continueront à souffrir de symptômes inexpliqués, affectant leur qualité de vie ».Une « guerre du Lyme » se déroule aux États-Unis à coups de procédures judiciaires et d'affrontements violents menés par des militants activistes et  visant principalement l'IDSA (Infectious Diseases Society of America) accusée de ne pas reconnaitre la maladie chronique de Lyme et ses formes  multiples telles que l'autisme, les morgellons, la sclérose en plaques, la maladie de Parkinson ou la maladie d'Alzheimer.Ces militants sont souvent des patients atteints d'affections chroniques non indemnisés par les compagnies d'assurances pour les traitements de longue durée, et qui accusent donc les autorités officielles d'agir de façon non scientifique et non éthiques par intérêt financier.
En 2000, ces activistes ont pu convaincre le Congrès d'enquêter sur le CDC et le NIH, sans résultats.Au Connecticut, une enquête sans précédent a eu lieu sur l'IDSA (Infectious Diseases Society of America), société savante accusée de violer la loi antitrust, au motif que ses recommandations étaient les seules à être reprises par les autorités sanitaires.
Un compromis temporaire est apparemment trouvé avec la publication, en 2011 (révisée en 2014), des recommandations de l'ILADS sur un site officiel, mais il s'agit en fait d'un site qui ne fait que recenser des recommandations sans les valider.
Les recommandations officielles américaines restent donc celles de l'IDSA publiées sur les sites du CDC ou du NIH.Au Texas, en 2021, un juge fédéral a débouté un groupe de patients accusant l'IDSA de complot et de négationnisme de la maladie chronique de Lyme.
Le juge a estimé que les recommandations de l'IDSA suivent l'état du savoir actuel, et que l'adhésion à ces recommandations est volontaire.De l'autre côté, plusieurs médecins membres de l'ILADS (International Lyme And Associated Diseases Society) sont poursuivis et condamnés par action disciplinaire ou pénale pour manquements divers à l'éthique, fraudes commerciales, évasions fiscales, traitements illusoires ou dangereux.La définition, les limites et la valeur des moyens diagnostiques de la « maladie chronique de Lyme » restent discutés.
Cette question est devenue un problème sociétal, par les polémiques qu'elle provoque.
En France, elle entraînerait une double perte de confiance « pour les patients qui perdent confiance en leur médecin, pour les médecins qui perdent confiance en eux-mêmes » dans un climat de méfiance réciproque.Les principales associations sont Lyme sans frontières fondée en 2012, 700 adhérents en France et en Belgique en 2013, dont 90 % de malades ; et France Lyme créée en 2008, revendiquant 400 adhérents en 2014 et 2 700 adhérents au 31 mars 2019.
Il existe d'autres associations plus petites à vocation locale.
Un rapport de la Haute Autorité de santé (HAS) de 2014 fait état que la majorité des dirigeants sont des femmes et appartiennent à la catégorie des cadres et professions intellectuelles supérieures.Selon le rapport de 2014 de la HAS qui cite une sociologue, il existe un « face-à-face acrimonieux » entre la légitimité des associations et l’autorité de la science.
Les premiers défendent leur savoir par expérience personnelle et intime, la seconde se fonde sur l'observation, et la déduction scientifique (médecine basée sur des faits).
Toujours selon le rapport, ces associations sont plus proches de l'attitude des antivaccins que de celle des associations de lutte contre le VIH, du fait qu'elles « demeurent le plus souvent crispées sur leur ressentiment à l’encontre du corps médical et des experts.
Et dès lors, le système d’action autour de la question de la borréliose de Lyme offre aujourd’hui le spectacle d’une légitimité sociale sans autorité ».Si ces associations partagent certains traits avec celles militant contre la contamination par le VIH — orientation « communautariste » (on se replie sur une pathologie spécifique), ambivalence des rapports avec les pouvoirs publics entre collaboration et affrontement, légitimité de l’« expertise » des patients (la « légitimité incorporée du malade ») opposée à l’expertise des scientifiques et du corps médical, etc. — elles s’en distinguent par l'absence d’universalisme (au service de la santé publique dans un champ de risque donné), l’absence de professionnalisation de militants tendant à devenir des experts reconnus consultés par les pouvoirs publics, l’absence de capital social (densité des réseaux de relations avec les scientifiques, les médias et la politique).Le rapport note : « Loin de tout « délire », la contestation des associations est au contraire parfaitement rationnelle, ce qui n’empêche pas certains de leurs arguments d’être très faibles » et « Aussi les militantes défendent-elles une notion essentialiste de la science — arcane reposant sur une expérience intime — afin d’en revendiquer le monopole du fait d’être les victimes de la maladie et, du moins veulent-elles le croire, les seules à ne pas cacher la vérité (car libres de tout conflit d’intérêt) ».Jusqu'en juin 2018, la prise en charge en France se basait sur une conférence de consensus de 2006, établissant des protocoles officiels.Ces critiques sont rejetées par la SPILF (société de pathologie infectieuse de langue française) qui juge les recommandations de 2006 restent valables au vu des connaissances actuelles ; de même pour l'Académie de Médecine.
Le 20 juin 2018, la HAS publie de nouvelles recommandations de prise en charge de la borréliose de Lyme.
Elles confirment (en les précisant) les protocoles de diagnostic et de traitement déjà adoptés, mais comme aux États-Unis, elle distingue un « syndrome post-borréliose de Lyme » ou PLDS Post-Lyme Disease, la HAS distingue « la/le symptomatologie/syndrome persistant(e) polymorphe après possible piqûre de tique » ou SPPT.
Cette dénomination de compromis (faute de consensus) doit améliorer la prise en charge des patients.Le 2 juillet 2018, l'Académie de médecine « exprime clairement sa profonde déception » devant ce texte.
Puis le 19 juillet 2018, un ensemble de sociétés savantes et professionnelles refusent de cautionner cette dénomination de SPPT et d'en suivre les recommandations.En Septembre 2018 (trois mois après la publication des recommandations de la HAS), Jérôme Salomon (directeur général de la Santé), toujours à la recherche d'un consensus, a donc demandé à Pierre Tattevin, président de la SPILF « d'élaborer de nouvelles recommandations pratiques pour la prévention, le diagnostic et le traitement de la borréliose de Lyme et autres maladies vectorielles à tiques… ».
De son côté, la HAS a expliqué qu'avant de publier ses recommandations, elle a tenté en vain de trouver un consensus avec la SPILF.
Elle a donc publié ces recommandations sans la signature de la SPILF, car convaincue qu'elles reflétaient l'état de l'art, mais en prévoyant deux réunions par an de réactualisation des recommandations au vu des avancées scientifiques, en espérant aboutir à des recommandations communes avec la SPILF qui en 2019 « considère toujours que les tests de dépistage sont efficaces » et qu'il n'existe pas de forme chronique de la maladie.En 2019, le 10 avril, le Sénat doit auditionner Jérôme Salomon et Dominique Le Guludec (présidente de la HAS).Le 7 mai 2019, le Bulletin épidémiologique hebdomadaire publie une étude montrant que dans une série de cas de diagnostic présumé de Lyme, le diagnostic a été confirmé dans moins de 10 % des cas, le traitement antibiotique présomptif échouant dans 80 % des cas, 80 % des patients ayant une autre maladie.
Selon l'éditorialiste du bulletin, il existe un important sur-diagnostic et sur-traitement de la maladie de Lyme, tendance retrouvée à l'étranger.
Ce qui pose un problème éthique de santé publique : dans la construction des recommandations de prise en charge, peut-on prendre en compte des modèles alternatifs en l’absence de faits probants ?.Les borrelia, dont celles de la maladie de Lyme, ne sont pas classées comme agent potentiel de bioterrorisme,.En 2004, un avocat de Long Island, Michael Carroll, sort un livre conspirationniste intitulé Lab 257, où il affirme qu’Erich Traub, un scientifique nazi transfuge aux Etats-Unis, collaborant à Fort Detrick dans le cadre du programme Operation Paperclip, aurait travaillé sur la fièvre aphteuse et la manipulation de tiques, entre autres sur l'île de Plum Island à quelques kilomètres au large de la ville de Lyme, où des tiques se seraient échappées sur oiseaux migrateurs.
Michael Caroll reconnait cependant ne pas avoir de preuve de ce qu'il avance.En France, l'infectiologue controversé Christian Perronne reprend ces propos en 2016 en affirmant que l'explosion de la maladie de Lyme a été cachée par « l'armée américaine et les scientifiques sous sa coupe », ce qui serait une théorie du complot.En 2019, Kris Newby, publie un livre intitulé Bitten, the secret history of Lyme Disease and biological weapons, où elle aurait interviewé Willy Burgdorfer celui qui, en 1982, a découvert l'agent de la maladie de Lyme, Borrelia burgdorferi.
Burgdorfer aurait raconté avoir travaillé sur des armes biologiques pour l'armée américaine durant la guerre froide.
Il était chargé d'élever des puces, des tiques, des moustiques et autres arthropodes pour les  infecter avec des agents pathogènes, et ce serait, selon Burgdorfer, l'une de ces expériences qui aurait mal tourné et provoqué l'épidémie de Lyme aux États-Unis.
Pour autant, aucun élément ne vient étayer cette thèse ni confirmer les propos attribués à Burgdorfer.À la suite de ces publications, le représentant républicain du New Jersey Chris Smith a fait adopter un amendement visant à lancer une enquête sur ces accusations,, demande rejetée par le Sénat.Quant au Plum  Island animal disease center (PIADC), situé à 15 km de la ville de Lyme, il affirme sur son site internet n'avoir jamais mené de recherches sur la maladie de Lyme, ni aucune recherche classée secret défense.
Un vaccin contre la maladie à coronavirus 2019 (Covid-19) entraîne et prépare le système immunitaire à reconnaître et à combattre le coronavirus SARS-CoV-2, ce qui permet de prévenir cette maladie.Pour développer rapidement une gamme de vaccins contre la Covid-19, une collaboration inédite naît en 2020 entre l'industrie pharmaceutique multinationale, différents organismes gouvernementaux et des fondations philanthropiques.
La mise au point d'un vaccin capable de protéger durablement contre le SARS-CoV-2 s'avère un défi technologique.
Avant la pandémie de Covid-19, aucun vaccin contre une maladie infectieuse n'a été développé en moins d'un an et aucun vaccin n'existait pour lutter contre un coronavirus humain.
Il préexistait toutefois une base de connaissances sur la structure et la fonction des coronavirus, causant des maladies comme le SRAS ou le syndrome respiratoire du Moyen-Orient.Différentes approches technologiques ont été explorées.
Certains vaccins ont été jugés prioritaires et ont été soutenus financièrement et institutionnellement.
Des technologies dites de nouvelle génération, comme les vaccins à ARN ou les vaccins à vecteur viral, ont ainsi été favorisées.
Des technologies plus traditionnelles comme les vaccins à virus inactivé ou de sous-unité protéique ont également été retenues.
En revanche en 2021, aucun vaccin à virus vivant atténué n'est encore disponible.
Les choix technologiques et la commercialisation des premiers vaccins contre la Covid-19 sont ceux effectués par l'Initiative ACT-A et l'Opération Warp Speed lancée le 15 mai 2020 par le président américain Donald Trump.En août 2021, selon l'Organisation mondiale de la santé (OMS), il y aurait 110 vaccins contre le coronavirus SARS-CoV-2 autorisés ou en phase d'étude clinique, ainsi que 184 vaccins potentiels à l'étude.
Plusieurs vaccins étudiés lors d'essais cliniques de phase III ont affiché une efficacité vaccinale allant jusqu'à 95 % contre les souches du virus circulant au début 2021.
Vingt-et-un vaccins sont approuvés par au moins une autorité nationale pour administration au public :À l'exception des vaccins à virus inactivé qui permettent à l'organisme de se familiariser avec l'ensemble des protéines virales du SARS-CoV-2, la plupart des vaccins développés incorporent la protéine S de la souche de Wuhan (D614), reproduite à l'identique ou avec la mutation dite « 2P ».
Quelques vaccins ciblent uniquement un fragment de la protéine S, appelé RBD.
En 2022, des vaccins bivalents (Pfizer et Moderna) élargissent la couverture aux variants Omicron.Plusieurs pays ont mis sur pied des campagnes de vaccination priorisant les groupes plus à risque, comme les personnes âgées ou à haut risque d'exposition.
Début août 2021, près de 9 milliards de doses de vaccin anti-Covid ont été administrées dans le monde.En 2020, une pandémie se propage dans le monde et provoque un choc systémique sanitaire, sociétal et économique.
L'agent infectieux en cause est un coronavirus, le SARS-CoV-2.
Pour sortir de cette crise, des investissements considérables et le monde de la recherche sont mobilisés au niveau international pour développer des vaccins contre ce virus.Avant la Covid-19, aucun vaccin contre une maladie infectieuse n'avait été développé en moins d'un an et aucun vaccin n'existait pour lutter contre un coronavirus humain.
Des projets antérieurs avaient tenté, sans grand succès, de développer des vaccins contre les coronavirus humains du SARS-CoV-1 et du MERS-CoV.
Ces vaccins anti-SARS-CoV-1 et anti-MERS avaient été testés sur des animaux non humains, comme les singes,,.Des vaccins ont été développés contre plusieurs coronavirus affectant les animaux.
Un vaccin contre le coronavirus de la diarrhée épidémique porcine est disponible commercialement.
D'autres ont été développés avec plus ou moins de succès contre le virus de la bronchite infectieuse chez les oiseaux, le coronavirus canin et le coronavirus félin (FCoV).
Les vaccins développés contre le FCoV ciblaient la protéine S.
En présence d’anticorps ciblant directement la protéine S, ce coronavirus mute et les anticorps deviennent non neutralisants et facilitent l'infection des globules blancs.
En détournant les anticorps à son profit, le virus développe un tropisme pour des globules blancs (les macrophages) où il se réplique activement.
Ce qui dégénère en péritonite infectieuse féline (PIF).En 2020, des dizaines de milliards de dollars ont été investis par des entreprises, des gouvernements, des organisations internationales de santé et des groupes de recherche universitaires pour développer des dizaines de vaccins candidats et se préparer à des programmes mondiaux de vaccination pour immuniser la population contre la Covid-19,,,.
En février 2020, l'OMS déclare ne pas s'attendre à avoir un vaccin disponible contre la Covid-19, avant 18 mois (horizon automne 2021).
Fin avril 2020, l'Initiative ACT-A est mise en place par le G20, l’OMS et la Fondation Bill-et-Melinda-Gates dans le but de coordonner et accélérer au niveau mondial, la mise au point et la production de produits de diagnostic, de traitements et de vaccins contre la Covid-19.
Dans les faits, les choix technologiques et la commercialisation des premiers vaccins contre la covid ont été orientés par l'Initiative ACT-A ainsi que par l'opération Warp Speed lancée le 15 mai 2020 par le président américain Donald Trump.Dès janvier 2020, plusieurs vaccins ont commencé à être élaborés en Russie, ainsi qu'en Occident par la firme pharmaceutique Johnson & Johnson ou à l'université d'Oxford.
En Allemagne, le Pr Uğur Şahin, patron de BioNTech, conçoit un vaccin à base d'ARN en l'espace d'un week-end.
En février 2020, une équipe de recherche de l'Imperial College de Londres affiche sa volonté de réduire le temps de développement normal du vaccin « de deux à trois ans à seulement quatorze jours »,, l'équipe de l'Imperial College étant alors au stade de test du vaccin sur les animaux.
En mars 2020, au moins 35 entreprises et établissements universitaires développent chacun leur vaccin.
Quelque 300 études cliniques sont alors en cours.
Le 11 août 2020, l'OMS recense 168 vaccins à l'étude dans le monde : 28 auraient déjà été évalués dans des essais cliniques sur l'homme, et six seraient en phase III des essais cliniques, avant l'homologation.
À la mi-octobre, ce nombre était de 193, dont 10 en phase III.Le 18 décembre, la Haute Autorité de santé indique qu'il n'est actuellement pas nécessaire de vacciner systématiquement les personnes ayant déjà développé une forme symptomatique de la Covid-19.
Elle précise que le recul actuel de 3 mois environ montre qu’il n’y a pas d’effet indésirable grave particulier lorsqu’une personne ayant déjà eu la Covid-19 se fait vacciner mais qu'il est cependant préférable de respecter un délai minimal de 3 mois à partir du début des symptômes.
Des études montrent qu'une personne contaminée pourrait être immunisée de 6 mois à plusieurs années, ce qui suggère qu’une campagne de vaccination serait efficace sans forcément avoir recours, pensait-on, à des injections fréquentes.La mise au point d’un vaccin approprié capable de protéger durablement contre le SARS-CoV-2 s'avère être un défi technologique.
Une étude suggère que l'immunité acquise avec quatre types de coronavirus de rhumes saisonniers ne dépasse pas un an,, ce qui laisserait présager qu'une réinfection est possible.
Toutefois il est avéré qu'il existe chez les humains une immunité cellulaire de long terme contre différents coronavirus (HCoV-229E, HCoV-NL63, HCoV-OC43) provoquant un simple rhume,.
La question est de savoir si cette réinfection est asymptomatique, symptomatique ou aggravée.Des virus tels que les coronavirus utilisent les récepteurs Fc pour infecter les globules blancs, par un mécanisme connu sous le nom de facilitation dépendante des anticorps.
Dans le cas du SARS-CoV-1, ce risque est constaté et a été bien documenté chez l'animal de laboratoire avec des vaccins inactivés et des vaccins exprimant la protéine S en entier,,.
Dans le cas du vaccin contre la COVID-19, ce risque est pris en compte par les agences de régulation et intégré dans les prérequis à une commercialisation,.Outre le risque de la facilitation de l'infection par des anticorps, un autre risque théorique est le phénomène de « péché originel antigénique », appelé également « effet Hoskins ».
Selon un consensus d'experts tenu en mai 2020, ces risques n'empêchent pas la recherche vaccinale, mais doivent être surveillés.L'urgence de créer un vaccin contre la Covid-19 a conduit à raccourcir à quelques mois un processus qui nécessite généralement plusieurs années.
Depuis le début du XXIe siècle, la fusion de nouvelles techniques telles que les biotechnologies et la bio-informatique permet d'accélérer la vitesse de fabrication des vaccins.
Par exemple, l'utilisation de ces outils permet de :L'ensemble de ces données est traité par une grande variété de logiciels qui permettent par exemple de classer les séquences génétiques, de donner la structure 3D d'une protéine virale, de comparer les épitopes, et de déterminer dans le cas du SARS-CoV-2 la glycoprotéine S (spike, spicule ou péplomère) du virus, comme la cible à privilégier pour une réponse immunitaire.Dans le futur, d'autres vaccins pourraient cibler d'autres protéines virales, comme la protéine N du virus.
Le meilleur scénario serait la production d'un vaccin universel contre les coronavirus.Afin de coordonner la réponse mondiale à la pandémie de Covid-19, en avril 2020 est mise en place par le G20 et l'OMS l'Initiative ACT-A.
Elle réunit des gouvernements, des scientifiques, des entreprises, la société civile, des organismes philanthropiques et des organisations mondiales telles que la Fondation Bill-et-Melinda-Gates, la Coalition pour les innovations en matière de préparation aux épidémies (CEPI), la Fondation pour de nouveaux outils diagnostiques novateurs (FIND), Gavi L'Alliance du Vaccin, le Fonds mondial, Unitaid, Wellcome, et la Banque mondiale.L'Initiative ACT-A est organisée en quatre piliers : (1) les vaccins (également appelés « COVAX »), (2) les diagnostics, (3) la thérapeutique et (4) une coordination des systèmes de santé.
Le dispositif COVAX (COVID-19 Vaccines Global Access) est codirigé par l'OMS, la CEPI et l'alliance Gavi.
Son objectif est d’accélérer la mise au point de vaccins contre la Covid-19 et d'« en assurer un accès juste et équitable », à l’échelle mondiale.
L'OMS prévoit dès l'origine des essais cliniques internationaux, randomisés, de grande envergure et sur de multiples sites, pour permettre l'évaluation simultanée des avantages et des risques de chaque vaccin candidat dans un délai de 3 – 6 mois.Certains vaccins ont été jugés prioritaires et ont été soutenus financièrement et institutionnellement par la Coalition pour les innovations en matière de préparation aux épidémies (CEPI) : le vaccin à vecteur développé par Oxford pour AstraZeneca, ceux à ARNm de CureVac et Moderna, celui à ADN d'Inovio Pharmaceuticals, celui à protéines recombinantes de Novavax et celui de l'université du Queensland.
Le vaccin développé par l'université du Queensland est le V451 (en).
Il incorporait des anticorps contre le VIH (anti-gp41 (en)), et a du être abandonné en décembre 2020 après que les essais aient produit des faux positifs au VIH chez les personnes vaccinées.Différents pays ont ainsi été incités à passer des commandes auprès de ces industriels, sous réserve que l'efficacité et l'innocuité des vaccins soient démontrées.
Au 15 octobre 2020, le budget consacré à ces pré-commandes est de 12 milliards de dollars aux États-Unis et de 2,3 milliards d'euros en Europe.Le processus d'élaboration et d'évaluation de vaccins est un équilibre entre, :Après des essais concluants sur modèle animal,, les essais de phase I testent principalement l'innocuité et le dosage préliminaire chez quelques dizaines de sujets sains, tandis que les essais de phase II - après le succès de la phase I - évaluent l'immunogénicité, les niveaux de dose (efficacité basée sur les biomarqueurs) et les effets indésirables du vaccin candidat, généralement sur des centaines des personnes.
Un essai de phase I-II est généralement randomisé et contrôlé par placebo.
Les essais de phase III impliquent généralement plus de participants sur plusieurs sites, incluent un groupe témoin et testent l'efficacité du vaccin pour prévenir la maladie (un essai «interventionnel» ou «pivot»), tout en surveillant les effets indésirables à la dose optimale.
La définition de l'innocuité, de l'efficacité et des paramètres cliniques d'un vaccin dans un essai de phase III peut varier entre les essais de différentes sociétés, comme la définition du degré d'effets secondaires, de l'infection ou de la quantité de transmission, et si le vaccin prévient la Covid modérée ou sévère,.En janvier 2021, il existe au moins neuf technologies différentes ayant été mobilisées pour créer un vaccin contre la Covid-19.
Ces approches vaccinales se focalisent sur la protéine S du SARS-CoV-2 de la souche d'origine de Wuhan (D614).
Les vaccins à ARNm et les vaccins à vecteur sont des technologies dites de nouvelle génération.
D'autres technologies ciblent un plus large panel de protéines du SARS-CoV-2, et ne se limitent pas à la seule protéine S, comme les vaccins à virus inactivés ou ceux à virus vivants atténués.Les vaccins ciblant uniquement la protéine S et ceux à virus inactivés offrent une protection d'au moins six à huit mois, mais de durée réelle encore inconnue.
Malgré les mutations du SARS-CoV-2, certains vaccins sont susceptibles d'offrir une protection à vie ou du moins à long terme (10 ans), dont des vaccins traditionnels à virus vivants atténués ou des technologies de nouvelle génération, basées sur l'immunité cellulaire, et qui offrent une protection sans générer d'anticorps.Chez la plupart des humains, il existe déjà un « répertoire antigénique » contre différentes protéines de coronavirus (HCoV-229E, HCoV-NL63, HCoV-OC43) provoquant un simple rhume.
Dans le cas d’une infection au SARS-CoV-2, une immunité cellulaire croisée est généralement mobilisée pour lutter contre l’infection,.
Les vaccins contre le SARS-CoV-2 vont compléter cette immunité préexistante en ciblant généralement une seule protéine du virus : la protéine S.
La protéine S va devenir une cible prioritaire pour les lymphocytes T et plus encore pour les lymphocytes B qui vont produire des anticorps pour la neutraliser.Pour cibler la protéine S du SARS-CoV-2, différentes technologies ont été mobilisées : les vaccins à ARN messagers ou à ADN, les vaccins à vecteurs viraux non réplicatifs ou encore des vaccins à protéines recombinantes.Plusieurs vaccins utilisent une « mutation 2P » pour verrouiller la protéine S dans sa configuration de pré-fusion (c'est-à-dire dans un état de conformation « masqué »), stimulant une réponse immunitaire au virus avant qu'il ne s'attache à une cellule humaine.
Concrètement une « mutation 2P » consiste en l’ajout de deux prolines (substitution d'acides aminés sur la protéine S aux codons K986P et V987P) entre le heptad repeat 1 (HR1) et le central helix (CH) de la protéine S du SARS-CoV-2,.Les vaccins à ARNm sont des technologies dites de nouvelle génération.
La biochimiste Katalin Karikó est à l'origine de la technologie des ARN messagers, et en 1997 elle rencontre l’immunologiste Drew Weissman avec lequel elle perfectionne sa technologie.
Les ARN messagers permettent aux cellules du muscle dans lesquelles ils sont injectés de synthétiser la protéine S du SARS-CoV-2.
Des cellules se transforment ainsi en usine à produire des protéines S.
Les cellules exposent les protéines S produites à leur surface, ce qui permet à des globules blancs de se familiariser avec la protéine S, de la reconnaître et de produire des anticorps contre celle-ci.
L'ARN messager délivré par le vaccin est encapsulé dans des nanoparticules de lipide.
Ces nanoparticules contiennent du polyéthylène glycol 2000.
Cette technologie est utilisée par les Américains Pfizer et Moderna, l’Allemand CureVac/Bayer, et est en projet pour le Français Sanofi Pasteur.Le vaccin Pfizer-BioNtech a été conçu à la fin janvier 2020 par le cofondateur de BioNTech (BNT), Uğur Şahin,.
Le 17 mars 2020, Pfizer annonce un partenariat avec BioNTech et les sociétés développent deux formules, le « BNT162b1 » et le « BNT162b2 ».
Le BNT162b1 ne fait produire par les cellules qu'un fragment de la protéine S, le domaine de liaison au récepteur (RBD).
Le BNT162b2 fait produire par les cellules la protéine S de la souche d'origine (celle de Wuhan) dans son intégralité, avec comme seule modification la mutation 2P.
Finalement, seul le BNT162b2 est commercialisé, rebaptisé Tozinaméran.Le National Institute of Allergy and Infectious Diseases (NIAID) des États-Unis a collaboré avec Moderna pour développer un vaccin à ARN dont le nom de code est « mRNA-1273 ».
Cet ARN messager est encapsulé dans des nanoparticules lipidiques avec comme seule modification la mutation 2P.
Comme le vaccin de Pfizer commercialisé (BNT162b2), c'est l'ensemble de la protéine S de la souche d'origine qui est synthétisée par des cellules et qui devient la cible d'anticorps.Le vaccin Zorecimeran du laboratoire allemand CureVac/Bayer, tout comme le vaccin MRT5500 du laboratoire français Sanofi Pasteur, qui devaient tous les deux être commercialisés d'ici la fin 2021, intègrent également une protéine S de la souche d'origine avec la mutation 2P,.
Les deux développements sont abandonnés à l'automne 2021,.En aout 2022, Moderna porte plaine contre Pfizer pour violation de brevet concernant leur vaccin à ARN messager.Les vaccins à vecteur utilisent un virus modifié dont une partie du génome a été remplacée par une séquence permettant de synthétiser la protéine S du SARS-CoV-2.
Le vecteur utilisé peut être un adénovirus, le virus de la rougeole ou d'autres.
Des cellules de la personne vaccinée vont être infectées par ce vecteur, et vont se mettre à produire des protéines S comme dans le cas des vaccins à ARN.Cinq vaccins à vecteur contre la Covid-19 ont été mis sur le marché :Le vaccin d'AstraZeneca-Oxford contre la Covid-19 est basé sur un vecteur adénoviral simien (chimpanzé) génétiquement modifié pour contenir la protéine S,.
Le vaccin Spoutnik V et le vaccin Convidicea utilisent comme vecteur un adénovirus de type 5 (Ad5), et le vaccin Janssen un adénovirus de type 26 (Ad26).
L'Université de Hong Kong essaye de développer un vaccin avec un virus atténué de la grippe comme vecteur et n'incorpore qu'un fragment de la protéine S, appelé RBD.
L'Institut Pasteur qui utilisait un vecteur du virus de la rougeole a abandonné ses recherches sur ce type de vaccin.Les vaccins sous-unitaires présentent directement un ou plusieurs antigènes de la protéine S sans les faire produire par des cellules de la personne vaccinée comme dans le cas des vaccins à ARN ou des vaccins à vecteur.
Dans le cas des vaccins à protéines recombinantes, des protéines S du SARS-CoV-2 sont produites en laboratoire par un virus qui n’est pas le SARS-CoV-2, en l'occurrence un baculovirus (virus en forme de batonnet).
Ces protéines S sont ensuite purifiées et injectées.
Un adjuvant est ajouté pour booster la réponse immunitaire.Cinq vaccins sous-unitaires contre la Covid19 ont déjà été mis sur le marché :D’ici la fin 2021, deux vaccins sous-unitaires contre la Covid19 pourraient être autorisés en Occident :Parmi les vaccins contre le SARS-CoV-2 qui sont déjà sur le marché, une seule technologie cible un plus large panel de protéines virales du SARS-CoV-2 que la seule protéine S.
Il s’agit des vaccins inactivés, qui utilisent des virus qui ont perdu tout pouvoir infectant par procédé physico-chimique.
Plusieurs injections, par voie intramusculaire ou sous-cutanée, sont souvent nécessaires pour obtenir une immunisation suffisante.
Neuf vaccins inactivés contre la Covid-19 ont déjà été mis sur le marché :Un vaccin inactivé a également été développé par le laboratoire français Valneva.
Ce vaccin - appelé VLA2001 - est en juillet 2021 en phase III, et il est prévu qu’une demande de mise sur le marché soit lancée au cours de l'automne 2021.Les vaccins à virus vivant entier et atténué comptent parmi les plus anciennes technologies vaccinales disponibles.
Affaiblir un virus vivant implique généralement de réduire sa virulence ou sa capacité à se répliquer.
Le virus infecte toujours les cellules et provoque des symptômes bénins.
L'utilisation d'un virus vivant atténué présente un avantage : la vaccination ressemble à une infection naturelle, ce qui conduit généralement à des réponses immunitaires robustes et à une mémoire des antigènes du virus qui peut durer de nombreuses années,.Des inquiétudes ont été exprimées sur le fait qu’avec une telle technologie, il existe un risque théorique de mutation et de recombinaison avec un coronavirus sauvage pour recréer une souche sauvage.
La HAS ajoute que « Ces vaccins posent également des problèmes de sécurité évidents lorsque l’on s’adresse à des infections potentiellement graves nécessitant de s’assurer de leur parfaite atténuation »,.Un vaccin à virus vivant atténué peut facilement être produit à grande échelle et être distribué à bas prix.
Au moins trois vaccins vivants atténués contre la Covid-19 sont actuellement développés respectivement par les laboratoires américains Codagenix et Meissa, ainsi que par le Serum Institute of India.De nouvelles biotechnologies utilisant des méthodes « immuno-informatiques » permettent de sélectionner des épitopes (déterminants antigéniques) à partir de sérum de convalescents.
Ces épitopes sont choisis dans des zones des protéines du virus qui mutent très peu.
Il s'agit de peptides servant de base à des vaccins susceptibles de stimuler préférentiellement les lymphocytes T.Cette approche aurait l'avantage d'apporter une protection au niveau des muqueuses respiratoires, avec une immunité plus étendue et plus durable, par rapport aux vaccins basés sur la production d'anticorps ciblant la seule protéine S, et dont l'efficacité peut être réduite par l'apparition de nouveaux variants.
La mise au point de vaccins à lymphocytes T est un moyen d'éviter tout risque de facilitation de l'infection par des anticorps à la suite d'une vaccination.
Cependant cette technologie vaccinale doit encore faire ses preuves mais elle ouvre de nouvelles pistes.Ces recherches vaccinales sont au stade de phase 1.
Elles sont effectuées, entre autres, par le laboratoire américain EpiVax Therapeutics, ou le laboratoire français Ose Immunotherapeutics,.
Dans le cas du vaccin CoVepiT développé par Ose, les 55 épitopes sélectionnés se trouvent sur 11 protéines du SARS-CoV-2 dont la protéine S et la protéine N.Les entreprises françaises GTP Bioways et LinKinVax s'associent pour le développement d'un vaccin de seconde génération, moins sensible aux mutations que les vaccins à ARN, et dont l'efficacité pourrait donc être plus longue.
La technologie de ce vaccin repose sur des anticoprs monoclonaux qui vont agir sur certaines cellules du système immunitaire fondamentales pour la stimulation et la régulation des réponses immunitaires.
GTP Bioways explique que les cellules ciblées par les anticorps du vaccin sont comme des professeurs qui « éduquent le système immunitaire pour lui apprendre à répondre ».
La réponse immunitaire attendue ciblera des zones du virus dans lesquelles peu de mutations se produisent.
Les premiers essais cliniques sont prévus en 2023,.Des chercheurs de l'Université du Texas à Austin ont mis au point "une protéine S-6P" (également appelée HexaPro), très stable, "où 6 acides aminés ont été substitués par des prolines".
Cette protéine, très facile à produire industriellement, "peut être entreposée à température ambiante" et supporter 3 cycles de congélation/décongélation.
La séquence d'ADN codant l'HexaPro est incorporée à un virus de la maladie de Newcastle (NDV) pour créer un nouveau vaccin recombinant, le NDV-HXP-S qui peut être produit dans des œufs comme le vaccin contre la grippe saisonnière.La version injectable du NDV-HXP-S est en études cliniques en Thaïlande, au Vietnam et au Brésil où, sous le nom de ButanVac, il est mis en fabrication fin avril 2021.La version intranasale, évaluée au Mexique par le laboratoire Avi-Mex, facile à administrer et à produire, peu coûteuse, est "une option idéale pour généraliser la vaccination à tous les pays, quels que soient leurs moyens financiers ou l'état de leurs structures sanitaires".
Le vaccin HexaPro est facilement adaptable à de nouveaux variants.Une étude, conduite par une vingtaine de chercheurs australiens de l’Université Griffith et de l’Université du Queensland et publiée le 29 octobre 2021 dans la revue Science Advances, démontre la supériorité de l'administration du NDV-HXP-S par patch, pour produire une réponse immunitaire innée et adaptative, sur l'injection par aiguille,.Les scientifiques ont cherché à savoir si les vaccins existants contre des affections non liées pouvaient stimuler le système immunitaire et réduire la gravité de l'infection au Covid-19.
Il existe des preuves expérimentales que le vaccin BCG contre la tuberculose a des effets non spécifiques sur le système immunitaire.
Fin mars 2020, des essais cliniques sont effectués dans divers pays (France, Allemagne, Pays-Bas, Australie) dans le but de tester les propriétés immunologiques du BCG, vaccin antituberculeux.
« Deux études menées chez les adultes montrent une réduction de 70 % des infections respiratoires grâce au BCG », indique au Figaro Mihai Netea, spécialiste des maladies infectieuses au Centre médical de l’université Radboud de Nimègue aux Pays-Bas.Une étude a démontré, sur une cohorte de 6 000 professionnels de santé, que le vaccin BCG protège de la Covid-19.
Les professionnels de santé qui se sont fait re-vacciner avec le BCG sont moins susceptibles d’être testés positifs pour les anticorps anti-SARS-CoV-2, ce qui démontre que leur réponse immunitaire innée ou cellulaire est efficace contre le virus.
Une vingtaine d’essais cliniques randomisés sont en cours pour vérifier si l'administration d'un rappel du BCG peut induire un effet protecteur contre l'infection par le SARS-CoV-2.Le vaccin Pfizer peut être administré à des enfants de 5 à 11 ans.
Pour ce public, le dosage est diminué à un tiers de la dose destinée aux adultes et adolescents, ce qui suffit pour induire la réponse immunitaire attendue.En France, la vaccination des enfants est simplement recommandée aux enfants souffrant de comorbidités ou ayant dans leur entourage des personnes immunodéprimées.
Le rappel s'effectue trois semaines apès la primoinjection.Au Canada, la vaccination est recommandée à l'ensemble des enfants de 5 à 11 ans et la dose de rappel est offerte au moins 8 semaines après la primoinjection.
Une troisième dose est recommandée pour les enfants ayant une immunodépression modérée à grave.Pfizer-BioNTech et Moderna ont développé des vaccins bivalents qui ciblent, en plus de la souche historique, le variant Omicron BA.1.
Ces vaccins ont été autorisés par l'Agence européenne des médicaments (EMA) le 1er septembre 2022.
Ils permettent de se protéger contre de nouveaux variants, qui — comme le BA.5.3.1 ou le BA.2.75 — continuent à se développer dans la famille des variants Omicron.Pfizer propose également un vaccin bivalent qui cible la souche historique et les sous-variants Omicron BA.4 ou BA.5.
Il est autorisé par l'EMA le 12 septembre 2022.L'efficacité d'un nouveau vaccin est définie par son efficacité lors des essais cliniques.
Dans le cas de la Covid-19, l'efficacité est évaluée au regard du risque de contracter une forme modérée ou sévère chez les participants vaccinés dans l'essai, comparé au risque de contracter la maladie chez les participants non vaccinés.Sans vaccin, la réponse immunitaire face au SARS-CoV-2 diffère d'un patient à l'autre : 40 % sont asymptomatiques, 40 % sont symptomatiques légers type grippe, 15 % développent une forme modérée pouvant conduire à un Covid long, et 5 % risquent une forme sévère pouvant nécessiter des soins de réanimation.Pour un vaccin contre la Covid-19, une efficacité de 0 % signifie que le vaccin ne protège pas plus qu'un placebo.
Une efficacité de 50 % signifie qu'il y a deux fois moins de cas de forme modérée ou sévère que chez les individus non vaccinés.
L'efficacité d'un vaccin anti-Covid reflète la prévention de la maladie mais n'empêche pas d'être infecté par le virus : les personnes vaccinées peuvent être asymptomatiques et contagieuses.
Les vaccins semblent toutefois réduire la transmission de la maladie.
La Food and Drug Administration (FDA) des États-Unis et l'Agence européenne des médicaments (AEM) ont fixé un seuil de 50 % comme efficacité requise pour approuver un vaccin Covid-19,.Les vaccins anti-Covid actuellement sur le marché ont une durée de protection inconnue.
Ces vaccins ont été développés à partir de la souche initiale du virus.
Et certains ont déjà une efficacité moindre pour certains variants apparus dès décembre 2020 :En février 2021, la FDA des États-Unis estime que tous les vaccins autorisés par la FDA restent en l'état efficaces pour se protéger contre les souches circulantes du SARS-CoV-2.
Aux États-Unis, en Juin 2021, sur 853 000 personnes hospitalisées pour cause de Covid-19, la quasi-totalité était non vaccinée, moins de 1 200 étant complètement vaccinées, soit environ 0,1 %, tandis que concernant les nouveaux variants, ce taux serait, début juillet au Royaume-Uni (où des vaccins sont assez différents), proche de 10 %.En septembre 2021, l'OMS fait une proposition d'interdiction mondiale de 3ème dose jusqu'à la fin de l'année 2021, pour une meilleure répartition des doses à l'échelle mondiale et intensifier les efforts de vaccination dans les pays les moins riches.Une étude publiée en décembre 2021 ayant testé l'efficacité de six vaccins face au variant Omicron observe que seuls 3 patients sur 13 ayant reçu deux doses du BBIBP-CorV de Sinopharm, 1 patient sur 12 ayant reçu le vaccin Janssen et aucun des 11 patients complètement vaccinés avec le Spoutnik V généraient des anticorps neutralisants contre le variant Omicron.
Les trois autres vaccins testés, d'AstraZeneca, Moderna et Pfizer–BioNTech, étaient également moins efficaces avec seulement deux doses.Début janvier 2022, des études aux États-Unis montrent que dans la classe d'âge 12-17 ans, avec la dose de rappel du vaccin Pfizer-BioNTtech, le risque d'hospitalisation est 11 fois moins important que chez les non-vaccinés.Une étude réalisée en juillet 2021 indique que, dans un comté du Massachussetts, que les trois quarts des personnes infectées lors de divers rassemblements de masse étaient entièrement vaccinées.
Cette étude offre des preuves clés renforçant l'hypothèse selon laquelle les personnes vaccinées peuvent propager la variante la plus transmissible en étant facteur d'une flambée estivale d'infections.
Ces données, détaillées dans le rapport hebdomadaire du CDC sur la morbidité et la mortalité, ont aidé à convaincre les scientifiques du CDC d'inverser les recommandations sur le port du masque et de conseiller aux personnes vaccinées de porter des masques dans les lieux publics intérieurs accueillant de nombreux visiteurs.
L'étude suggère que les individus vaccinés portaient autant de virus dans le nez que les individus non vaccinés.
Cette étude et d'autres données récentes semblent montrer que les vaccins offrent une protection significative contre les formes graves ou mortelles, mais n'offrent pas de protection totale contre tout risque d'infection.À la mi août 2021, l’augmentation rapide des contaminations en Israël malgré un taux élevé de couverture vaccinale fait dire aux autorités médicales que les vaccins ne sont pas suffisamment efficaces pour contrôler le variant delta,.Fin septembre 2021, un article publié dans European Journal of Epidemiology étudie la relation entre le pourcentage de la population entièrement vaccinée et les nouveaux cas de COVID-19 dans 68 pays et dans 2 947 comtés aux États-Unis.
Il note l'absence d'association significative entre le pourcentage de la population entièrement vaccinée et les nouveaux cas de COVID-19.
Cette situation est illustrée, par exemple, par la comparaison de l'Islande et du Portugal.
Ces deux pays ont plus de 75 % de leur population entièrement vaccinée et ont plus de cas de COVID-19 pour 1 million d'habitants que des pays comme le Vietnam et l'Afrique du Sud qui ont environ 10 % de leur population entièrement vaccinée.
Israël, avec plus de 60 % de sa population entièrement vaccinée, a enregistré le taux de cas de COVID-19 par million de personnes le plus élevé en août 2021.
Même si les vaccinations offrent une protection aux individus contre les hospitalisations graves et les décès, les Centres pour le contrôle et la prévention des maladies (CDC) aux États-Unis signalent une augmentation de 0,01 à 9 % et de 0 à 15,1 % (entre janvier et mai 2021) des taux d'hospitalisations et décès, respectivement, parmi les personnes complètement vaccinées.
Les auteurs préconisent de mettre en place d'autres mesures, pharmacologiques et non pharmacologiques, parallèlement aux mesures visant à augmenter les taux de vaccination.En octobre 2021, une étude qui s'est déroulée de septembre 2020 à septembre 2021 portant notamment sur le risque de contagion au sein des ménages montre que les personnes qui ont reçu deux doses de vaccin peuvent être tout aussi contagieuses que celles qui n'ont pas été vaccinées.
Le risque qu'ils transmettent le virus à d'autres colocataires non vaccinés est d'environ deux sur cinq, soit 38 %.
Ce chiffre tombe à un sur quatre, ou 25 %, si les colocataires sont également complètement vaccinés.
En raison du fait que la susceptibilité à l'infection augmente déjà quelques mois après la deuxième dose de vaccin, les auteurs de l'étude recommandent aux personnes éligibles pour les injections de rappel de les recevoir rapidement.En 2021, une équipe de chercheurs s'est intéressée aux anticorps produits après vaccination par le vaccin Pfizer-BioNTech chez différents publics dont des personnes déjà immunisées contre le SARS-CoV-1 de 2002.
Ils se sont rendu compte que des anticorps produits chez ces personnes étaient efficaces contre les deux souches SARS-CoV-1 et SARS-CoV-2 mais aussi contre l'ensemble des sarbécovirus capables de se lier à l'ACE2 humain.
Ces anticorps permettent donc une protection contre l'ensemble des variants actuels et pourraient mieux prévenir de futures sarbécoviroses,.En effet, les anticorps neutralisants ciblent généralement le site de liaison au récepteur (RBS - Receptor Binding Site) de la spicule, mais la variabilité de cet épitope limite les capacités de neutralisation d'un anticorps.
L'anticorps identifié se caractérise par une reconnaissance coordonnée de sites stables hors du RBS par la chaîne lourde et du RBS par la chaîne légère avec un angle de liaison imitant celui du récepteur ACE2.
Ainsi la neutralisation est moins dépendante du RBS, très variable.L'enseignement tiré de cet anticorps pourrait orienter la conception de médicaments ou vaccins contre un spectre plus large de sarbecovirus.Une observation publiée dans le NEJM rapporte une série de 12 cas ayant développé une réaction d'hypersensibilité retardée au point d'injection, appelée « bras COVID-19 » (douleur, rougeur indurée jusqu'à plus de 10 cm de diamètre), après avoir reçu le vaccin Moderna MRNA-1273.
Cette réaction apparait de 4 à 11 jours après vaccination (première dose) et disparait en 4 à 5 jours, elle survient chez 8 vaccinés sur 1000, et elle ne contre-indique pas la deuxième dose.En France, le 19 janvier 2021, alors que plus de 500 000 personnes ont reçu une première injection par le vaccin Pfizer, l'Agence nationale de sécurité du médicament (ANSM) relève une centaine de cas « non graves » de réaction allergiques, une vingtaine de cas « graves » et cinq décès parmi les personnes vaccinées sans que des liens de cause à effet aient pu être établis.
Les données mises à jour en décembre 2021 aux États-Unis mentionnent que des réactions anaphylactiques sont survenues chez environ 5 personnes par million de personnes vaccinées.
L’agence américaine complète l’information en notant que ces effets existent pour tous types de vaccins et sont pris en charge immédiatement par les personnels de santé.La vaccination avec Pfizer-BioNTech m-RNA SARS-CoV-2 est connue pour provoquer de rares réactions allergiques, allant de l'urticaire à l'anaphylaxie potentiellement mortelle en passant par le gonflement de la langue (1 cas sur 100 000), en particulier chez les personnes présentant des allergies connues.Officiellement il n'y a pas de risque accru d'évènements thrombotiques après la vaccination par le mRNA COVID-19 de Pfizer et Moderna.Pourtant le 11 mars 2021, les autorités danoises suspendent provisoirement et pour une période minimale de deux semaines l'utilisation du vaccin AstraZeneca.
La suspension de ce vaccin a été décidée « après des rapports de cas graves de formation de caillots sanguins chez des personnes vaccinées », a expliqué l'Agence nationale danoise de la santé.Le vaccin est abandonné définitivement par le Danemark le 14 avril 2021 et temporairement par la Norvège.Le rapport de l'ANSM de mai 2021 pointe des risques de thrombose liés au vaccin d'AstraZeneca.
Il considère cependant que la balance bénéfice-risque reste favorable pour les personnes de plus de 55 ans, mais déconseille son utilisation pour les personnes plus jeunes.L'Italie suspend, le 11 juin 2021, l'utilisation du vaccin AstraZeneca pour les personnes de moins de 60 ans, à la suite du décès d'une jeune femme après avoir reçu ce vaccin.
Selon un rapport de l'agence de presse Xinhua, une jeune femme de 18 ans est décédée d'un caillot sanguin le 10 juin après avoir reçu une première dose du vaccin AstraZeneca le 25 mai.
Il est dit que cette personne souffrait de thrombocytopénie auto-immune (faible taux de plaquettes sanguines) et qu'elle suivait une double thérapie hormonale.Après plusieurs plaintes déposées contre AstraZaneca pour des cas de thrombose, plusieurs pays tels que la France, le Canada, l'Allemagne ont suspendu son utilisation en dessous d'un certain âge.L'EMA (Agence européenne des médicaments) a classé le syndrome de Guillain-Barré comme effet secondaire « très rare » du vaccin contre la Covid-19 du laboratoire américain Johnson & Johnson, Janssen, de même ensuite pour le Syndrome de Parsonage-Turner.Le syndrome inflammatoire multisystémique (SIM) chez l'enfant apparaît dès avril 2020 comme une conséquence possible de la maladie Covid-19, survenant dans une période de 2 à 6 semaines après guérison.
En octobre 2020, un syndrome analogue est mis en évidence chez l'adulte.En juillet 2021, le premier cas de SIM chez l'adulte vacciné est observé chez une femme à la suite d'une vaccination avec le vaccin Pfizer ; les symptômes de la patiente ont commencé par un « bras COVID-19 » qui a évolué vers un SIM.Une augmentation des cas de myocardite et de péricardite a été signalée aux États-Unis et en Israël après la vaccination par le mRNA COVID-19 de Pfizer et Moderna, en particulier chez les adolescents et les jeunes adultes,.Le phénomène reste toutefois marginal avec seulement 2,7 cas de myocardites supplémentaires pour 100 000 personnes dans la population vaccinée.
En comparaison l'augmentation des cas de myocardites causées par la Covid-19 est bien supérieure avec 16 fois plus de cas de myocardites.
Le rapport bénéfice sur risque reste donc favorable à la vaccination.Début octobre, l'Islande suspend l'utilisation du vaccin Moderna « invoquant de légers risques accrus d’inflammations cardiaques ».
La Suède et la Finlande suspendent l’emploi du vaccin Moderna pour les moins de 30 ans.
Le Danemark et la Norvège déconseillent formellement son usage pour les moins de 18 ans.Début novembre 2021 parait une étude française menée par la structure Epi-Phare, associant l'Assurance maladie et l’Agence du médicament, qui confirme le risque de souffrir d’une myocardite ou d'une péricardite « particulièrement marqué » chez les hommes de 12 à 29 ans, dans la semaine suivant la deuxième injection des vaccins de Pfizer et surtout de Moderna.
Chez les hommes de 30 à 50 ans, c'est un cas pour 211 000 doses de Pfizer et un pour 37 700 doses de Moderna.
Le 8 novembre 2021, la Haute Autorité de santé déconseille le vaccin de Moderna pour les moins de 30 ans en raison d'un risque plus élevé de myocardite.
Ce vaccin qui était suspendu depuis la mi-octobre pour les doses de rappel en France est donc réautorisé pour les personnes de plus de 30 ans, avec une demi-dose (50 µg),.
Le 14 décembre, le Conseil scientifique, présidé par Jean-François Delfraissy recommande de revenir à la pleine dose de 100 µg pour mieux lutter contre le variant Omicron.
Un communiqué de presse de Moderna du 20 décembre affirme que la dose de 50 µg augmente le niveau des anticorps neutralisants contre le variant Omicron d'un facteur 37, celle à 100 µg d'un facteur 83.Début août 2021 de nombreux témoignages sont apparus sur les réseaux sociaux concernant un dérèglement du cycle menstruel après l'injection.
Pour l'heure aucun lien avec le vaccin n'a été démontré.
Il a été rapporté 229 cas avérés après injection du vaccin Pfizer et 36 après injection du vaccin Moderna.
L'Agence Nationale de la sécurité médicament a prévu d'effectuer un signalement à l'Agence Européenne des médicaments et a classé ce trouble comme "signal potentiel" après injection du vaccin Pfizer ou Moderna,,,.En septembre 2020, onze des vaccins candidats en développement clinique utilisent des adjuvants pour améliorer l'immunogénicité.
Un adjuvant immunologique est une substance formulée avec un vaccin pour amplifier la réponse immunitaire à un antigène.
Les adjuvants utilisés dans la formulation de vaccin anti-covid sont souvent nécessaires pour des vaccins à virus inactivé, des vaccins à base de protéines ou des vaccins à vecteurs recombinants.
Les sels d'aluminium, appelés « alun », ont été le premier adjuvant utilisé pour les vaccins homologués et restent l'adjuvant de choix dans environ 80 % des vaccins avec adjuvant.
L'adjuvant d'alun initie divers mécanismes moléculaires et cellulaires pour améliorer l'immunogénicité, y compris la libération de cytokines proinflammatoires,.Les adjuvants des vaccins anti-covid qui sont impliqués dans des effets secondaires sont : le polyéthylène glycol (PEG 2000) des vaccins à ARN messager et le polysorbate 80 des autres vaccins.
Les effets croisés éventuels entre les différents adjuvants sont surveillés.Les adjuvants peuvent induire des effets indésirables, classées en 4 niveaux de gravité : bénin, modéré, sévère, et grave « niveau 4 ».
Ces niveaux sont prédéfinis pour chaque type de réaction.
De façon générale, le niveau 1 est celui des réactions qui ne gênent pas l'activité quotidienne, le 2 qui la perturbent, le 3 qui l'empêchent et le 4 qui nécessitent une hospitalisation, ou qui entraînent une gêne permanente.
Généralement il s'agit de réactions locales (rougeur, gonflement, douleur) et réactions systémiques (fièvre, fatigue, maux de tête…).La surveillance des effets à plus long terme s'effectue par des études de suivi épidémiologique (avec par exemple des enquêtes de cohorte).Les industriels qui fabriquent, distribuent, administrent ou utilisent des produits médicaux (y compris les vaccins) contre la Covid-19 bénéficient d'une immunité juridique dans différents pays, dont les États-Unis, afin d'échapper à des poursuites judiciaires en cas d'effets secondaires, à l'exclusion des « fautes volontaires »,.
Le 4 février 2020, le secrétaire à la Santé et aux Services sociaux des États-Unis Alex Azar fait adopter une réglementation excluant toute poursuite d'un industriel en cas de négligence concernant les vaccins anti-Covid.
Cette disposition réglementaire devrait rester en vigueur aux États-Unis jusqu'au 1er octobre 2024.La société Pfizer a exigé des exonérations de responsabilité de grande envergure et d'autres garanties de la part de pays comme l'Argentine et le Brésil,.Dans l'Union européenne, les vaccins contre la Covid-19 sont homologués en vertu d'une autorisation de mise sur le marché (AMM) conditionnelle qui n'exempte pas les fabricants de poursuites en responsabilité civile et administrative.
Bien que les contrats d'achat avec les fabricants de vaccins restent secrets, ils semblent ne pas contenir d'exonération de responsabilité, même pour des effets secondaires inconnus au moment de l'homologation.
Dans l'Union européenne, des clauses prévoient que, dans certains cas, les États pourront prendre à leur charge les indemnités qui seraient demandées aux entreprises pharmaceutiques en cas d'effets secondaires imprévus,,.
Ces programmes de compensation - prévus pour les vaccinations - existent dans de nombreux pays développés.
La France et l'Allemagne disposent de programmes de ce type depuis les années 1960.
En France, les victimes d'effets secondaires sont considérées comme des victimes « d'accidents médicaux », lesquelles sont indemnisées par l'État via l'Office national d'indemnisation des accidents médicaux (Oniam).
Dans le cas des vaccins, cela ne concerne que les vaccins obligatoires, à savoir exclusivement ceux demandés dans le cadre de l’exercice d'une profession ou formation dans le domaine médical, ainsi que les vaccinations infantiles liées à la scolarisation.
Or, concernant les vaccins contre la covid-19, une «clause d’indemnisation» ou «clause de garantie», existe qui a pour effet de «transférer la charge de la réparation de la dette de responsabilité, des assureurs du laboratoire vers les Etats».
«L’idée est de transférer la prise en charge financière du risque résultant de la mise sur le marché d’un nouveau médicament, compte tenu des circonstances particulières et de l’urgence liées au Covid-19.
C’est la contrepartie d’un approvisionnement prioritaire en vaccins».En janvier 2022, un avocat marseillais, défendant un "adolescent de 13 ans qui a pratiquement perdu la vue après sa première injection du vaccin de Pfizer" dénonce le contrat où figure "une clause qui dédouane la société Pfizer de toute responsabilité dans le cas de survenance d'effets indésirables potentiels".
Il dépose un "recours devant le tribunal administratif de Paris contre le contrat signé entre le fabricant de vaccins Pfizer et l'Etat Français car il précise que cette clause est illégale dans des contrats publics", soulignant cette clause, par laquelle "Pfizer se dégage en réalité de toute garantie minimale d'efficacité du vaccin et de toute nocivité minimale.".
En octobre 2022 le même avocat, défendant une autre victime, assigne le fabricant BioNtech, afin "d'engager la responsabilité du producteur du vaccin mais également dans le cadre de cette demande d'expertise d'obtenir des données fournies sur le vaccin ARNmessager par Pfizer pour obtenir l'autorisation sur le vaccin et sa composition exacte".Selon une étude (parue le 18 janvier 2022 dans JAMA Network Open), 76 % des effets secondaires rapportés au vaccin (maux de tête, fatigue et douleurs au bras le plus souvent) sont en réalité imputables à l'effet nocebo (peur d'avoir quelque chose).
Dans ces cas, ces effets sont associés à tort aux piqûres de vaccin COVID-19, ils ne sont pas dus aux composants du vaccin mais à l'anxiété, l'inquiétude, les attentes et l'attribution erronée d'autres maladies ou sensations au vaccin,.
Cette étude repose sur 12 essais cliniques relatifs à divers vaccins contre la COVID, comparant la prévalence des effets secondaires systémiques tels que la fièvre, les maux de tête ou la fatigue et les effets locaux tels que douleur et gonflement au site d'injection entre les vaccinés et ceux qui ont reçu des injections de solution saline comme placebo.
Selon les auteurs, s'il est éthiquement nécessaire d'informer les participants, le public et les patients des effets secondaires de tout traitement, il faudrait aussi informer le public sur cet effet nocebo, qui est l'un des freins au consentement à la vaccination.L'affirmation qui prétend que la vaccination favoriserait le risque d'infection relève d'une analyse biaisée des statistiques.L'optimisation du bénéfice sociétal de la vaccination peut bénéficier d'une stratégie adaptée à l'état de la pandémie, à la démographie d'un pays, à l'âge des receveurs, à la disponibilité des vaccins et au risque individuel de maladie grave: au Royaume-Uni, l'intervalle entre la dose d'amorçage et la dose de rappel a été prolongé pour vacciner le plus de personnes possible le plus tôt possible, de nombreux pays commencent à donner un rappel supplémentaire aux immunodéprimés, et aux personnes âgées, et à la recherche prédit un avantage supplémentaire de la personnalisation de la dose de vaccin dans le contexte de la disponibilité limitée des vaccins lorsqu'une vague de variantes virales préoccupantes frappe un pays.En Israël, la majorité de la population a reçu une dose de rappel six mois après les deux premières doses.
« Une étude a été menée en Israël sur 1,4 million de personnes avec un groupe de patients qui avait reçu la deuxième dose il y a au moins cinq mois et un groupe de patients vacciné une troisième fois.
La troisième dose a apporté une efficacité de 93% contre l'hospitalisation, 92% contre les formes très graves de la maladie et 81% contre les risques de décès.
» Les participants avaient un âge médian de 52 ans (IQR 37-68).
La durée médiane de suivi de cette étude observationnelle était de 13 jours (IQR 6–21).Dans 28 pays de l'union européenne et de l'espace économique européen, 12 589 518 personnes de plus de 60 ans ont reçu une dose additionnelle (de rappel) en date du 19 novembre 2021 d'après l'ECDC tracker (France > 4M, Allemagne >3M, Espagne >3M, Hongrie > 1M).En Turquie, 11 millions de troisièmes doses ou de doses de rappel ont été administrées.Dans le Royaume-Uni ou la Grande-Bretagne, le nombre de troisièmes doses ou de dose de rappel est de dix millions.En France, la troisième dose s'effectue avec les deux vaccins à ARN messager (Pfizer-BioNtech ou, pour les plus de 30 ans, Moderna dosé à 50 %).
Elle est initialement réservée aux 65 ans et plus, six mois après la deuxième dose (ou 4 semaines après l'injection unique de Janssen).
Cet intervalle est ramené à 5 mois avec la cinquième vague puis à 4 mois à compter du 3 janvier 2022 pour mieux lutter contre le variant Omicron.Début 2022, certaines juridictions, comme Israel ou des provinces canadiennes, recommandent une quatrième dose pour les patients immunodéprimés,,.
La France a fait de même, pour les immunodéprimés, puis pour les plus de 60 ans (à partir du 7 avril 2022)Au 3 août 2021, selon l'OMS, 98 % des pays membres (191 sur 194) ont des vaccinations en cours.
À l'échelle mondiale 3,86 milliards de doses ont été administrées, 1,5 milliard de personnes ont reçu au moins une dose, soit 19,4 % de la population mondiale.Au 8 août 2021, selon le site Our World in Data, 4,46 milliards de doses ont été administrées, 30 % de la population mondiale a reçu au moins une dose, et 15,5 % a reçu deux doses.
Seuls 1,1 % des personnes vivant en pays à bas revenu ont reçu au moins une dose.Toujours au 8 août, la couverture vaccinale deux doses en Afrique est de 1,9 % et de 11,6 % en Asie.
Dans l'Union Européenne, elle est de 51,5 %, et de 49,4 % en France.
Les États-Unis sont à 49,8 % et le Canada à 61,8 %.Au 10 décembre 2021, 71 % de la population de l'espace économique européen comme de l'union européenne a reçu une dose ; deux-tiers de la population a reçu une vaccination normale, soit aux environs de 300 millions de personnes.
Ces taux sont de 82 % et 78 % chez les adultes.L'union européenne compte 15 % de doses additionnelles pour 60 millions de personnes dont 14 M en Allemagne, 11 en France, 9,7 en Italie, 5,2 en Espagne, 2,8 en Hongrie, 2,8 en Autriche, 2,4 en Belgique, 2 en Grèce, 1,8 au Portugal, 1,6en Suède, 1,4 en Tchéquie, 1 million en Irlande, 959 mille au Danemark et 852 mille aux Pays-Bas.En France, en comparaison avec d'autres pays (Portugal, Espagne où les prises de rendez-vous sont systématiques), on constate en juillet 2021, un taux plus faible de vaccination chez les plus de 70 ans.
Ce taux plus faible dans cette classe d'âge laisse envisager une prochaine hausse de la mortalité due à la reprise de l'épidémie par les nouveaux variants (delta, epsilon), alors que 93 % des personnes décédées avaient plus de 65 ans.
Cette hausse peut s'extrapoler des nouvelles augmentations du taux d'incidence observée depuis début juillet 2021 aux Pays-Bas, en Espagne ou au Royaume-Uni.
En France, les taux de vaccination semblent en particulier plus faibles pour les populations ayant le plus faible niveau de vie,, tandis que début juillet, 15 % des résidents d'Ehpad n'étaient pas vaccinés.Fin juillet 2021, avec 102,66 doses pour 100 habitants en moyenne, l'Union européenne dépasse les États-Unis où le taux de vaccination n'est que de 102,44 doses pour 100 habitants.En France, 92 % des adultes ont reçu au moins une dose et 90 % sont entièrement vaccinés.
Cependant les statistiques début décembre 2021 montrent que 83 % des non vaccinés de plus de 70 ans ont plus de 80 ans alors que le risque d'hospitalisation est 6 fois plus élevé en moyenne pour un non vacciné.
Cette classe d'âge est moins vaccinée que dans la plupart des pays européens,,.
Alors qu'ils constituent moins de 0,9 % de la population, les non vaccinés de plus de 80 ans représentent un faible pourcentage des hospitalisations , et au moins 20 % des décès depuis décembre 2021,.
Pour cette classe d'âge, comme pour les autres, le taux d'incidence a été à peu prés multiplié par 10 depuis le début de l'automne 2021.
Ainsi, pour les plus de 60 ans non vaccinés le risque de décès est cinq fois plus élevé après 80 ans.
La vaccination par une troisième dose pour les plus 80 ans et 6 mois après les deux premières montre à la fois une diminution au moins par 6 du risque de décès ,et que l'efficacité vaccinale est nettement plus faible au delà de 6 mois pour personnes les plus à risque.Au 9 décembre 2021, dans la tranche d'âge 70-79 ans, 99 % a reçu au moins une dose et 98 % est entièrement vaccinée.
En Janvier 2022, à l'AP-HP parmi les patients admis en réanimation et ayant reçu trois doses de vaccin, les immunodéprimés, comptent pour 70%, le reste étant principalement des patients ayant des comorbidités sévères.
Une étude plus large (Epi-Phare) portant sur 28 millions de personnes ayant eu un schéma vaccinal complet montre que moins de 10% de celles qui ont été hospitalisées pour le Covid n'avaient aucune comorbidité.En mars 2022 Le Monde révèle que des centaines de millions de doses de vaccin périmées ont été jetées, 73% du vaccin Pfizer, 18% d'Astrazeneca (En France 218 000 doses d'Astrazeneca).
Les vaccins envoyés en Afrique, l'ont été à la limite de péremption et n'ont pas pu, pour une grande part, être utilisés, ainsi en décembre 2021 100 millions de doses ont été refusées par les bénéficiaires du dispositif Covax .Différentes rumeurs et théories du complot ont circulé à propos des vaccins.
Selon un rapport du CCDH (Center for Countering Digital Hate), les deux-tiers des messages antivaccinaux partagés sur Facebook et Twitter, du 1er février au 16 mars 2021, provenaient de 12 personnes, dites « influencers » ou célébrités d'internet,.
La variolisation est l'inoculation volontaire de la variole, prélevée sur un sujet faiblement malade, ou lui-même variolisé.
Cette technique, qui remonterait à la Chine ancienne, protège les sujets d'une variole grave.
Son manque de fiabilité (rien ne prouve que le sujet variolisé ne fera pas une variole grave) et le risque de dissémination de variole ont conduit à son abandon après la découverte de la vaccination.Cette pratique consistait à inoculer une forme qu'on espérait peu virulente de la variole en mettant en contact la personne à immuniser avec le contenu de la substance suppurant des vésicules d'un malade.
Le résultat restait cependant aléatoire et risqué, le taux de mortalité pouvant atteindre 1 ou 2 % pour un taux de protection non chiffré.
En 1760, Daniel Bernoulli démontra que, malgré les risques, la généralisation de cette pratique permettrait de gagner un peu plus de trois ans d'espérance de vie à la naissance.On dit que la variolisation était une pratique de la médecine ayurvédique et qu'elle est mentionnée dans le Sactaya Grantham de Dhanvantari mais cette affirmation erronée est fondée sur une rumeur lancée en 1819 par le quotidien The  Madras Courier qui fit passer un tract de propagande vaccinale, rédigé en sanscrit par l'administration coloniale, pour la copie d'un texte ancien.On a dit également que dès le XIe siècle, les Chinois pratiquaient la variolisation.
C'est le premier ministre Wang Dan qui, après la perte d'un de ses fils de la variole, avait convoqué divers praticiens de toute la Chine pour mettre au point une prophylaxie.
Un moine taoïste apporta la technique d'inoculation qui se diffusa progressivement dans toute la Chine.
Il apparaît cependant que la plus ancienne trace connue de ce récit ne remonte qu'à 1808 dans le Zhongdou xinfa (種痘心法) écrit par Zhu Yiliang.
La pratique de la variolisation en Chine n'est documentée de manière incontestable qu'à partir du XVIe siècle.
Elle a été introduite à la cour le siècle suivant, après le décès de l'empereur Shunzhi qui avait été infecté par la maladie.La pratique s'est progressivement propagée le long de la route de la soie.
En 1701, Giacomo Pylarini (en) réalise la première inoculation à Constantinople, capitale de l'Empire ottoman, reproduisant la pratique des matrones qui introduisaient à l'intérieur des plaies un morceau de coton imbibé de pus variolique prélevé sur des malades, comme le raconte Aubry de La Mottraye.
Partiellement défigurée par cette maladie qui avait déjà emporté son frère, Lady Mary Wortley Montagu, la femme de l'ambassadeur du Royaume-Uni à Constantinople, était inquiète devant les ravages de cette maladie.
En mars 1718, elle fait inoculer son fils avec succès par le chirurgien de l'ambassade Charles Maitland (en).
À son retour à Londres où sévit une épidémie de variole, elle fait varioliser sa fille âgée de 3 ans par le même docteur en présence de médecins de la Cour royale le 11 mai 1721.
Par prudence, le collège de médecins demande à Maitland de réaliser la même expérience sur six criminels (trois hommes et trois femmes) de la prison de Newgate le 9 août 1721 puis sur des enfants pauvres d'orphelinat.
Devant le succès de cette « opération byzantine », Caroline d'Ansbach, l'épouse du roi Georges II de Grande-Bretagne, fait inoculer ses deux filles âgées de onze et neuf ans le 17 avril 1722.
Si la contribution de Lady Montagu dans la diffusion de cette nouveauté médicale est décisive, l'acceptation de la méthode, en Grande-Bretagne puis dans le monde occidental, n'est que progressive et le fait de médecins.
L'ignorance médicale (et notamment le fait que les partisans de l'inoculation n'ont alors à opposer à leurs adversaires que des statistiques assez vagues) reste en effet telle que les controverses sur la variolisation sont légion, les camps pour et contre luttant tous deux avec leurs armes idéologiques, plus politiques et morales que scientifiques.
La méthode empirique, accompagnée par des succès signifiants, mais aussi par des adversités, est revendiquée dans la seconde moitié du XVIIIe siècle par la politique populationniste des gouvernements du siècle des Lumières et comme moyen de conservation des vies individuelles par les médecins-humanistes.Lorsque Boston connut une épidémie de variole en 1721, le pasteur puritain, Cotton Mather fit la promotion de l'inoculation comme protection contre celle-ci, citant Onesimus (fin des années 1600-début 1700), un de ses esclaves, comme source de ce protocole.
Quelques années plus tôt, Onésimus avait décrit à Mather le processus d'inoculation qui avait été effectué sur lui et d'autres personnes en Afrique (comme le rapportait Mather dans une lettre),.En 1762, le britannique Daniel Sutton met au point une méthode qui lui permet de traiter plus de 13 000 personnes en réduisant le nombre de décès.
Il ouvre des centres d'inoculation jusqu'à la Nouvelle-Angleterre et à la Jamaïque et amasse une fortune considérable.En 1768, l’impératrice Catherine II de Russie demande à un médecin anglais, Thomas Dimsdale, de se faire inoculer ainsi que son fils.
À la suite de la réussite de l’opération, 140 nobles de la cour se font également inoculer.
La variolisation devient alors un effet de mode dans l’empire Russe.La variolisation est introduite en France par le docteur Théodore Tronchin qui inocule son fils puis, en 1756, les enfants de Louis Philippe d'Orléans.
Charles Marie de La Condamine passe la fin de sa vie à faire campagne pour la variolisation contre la petite vérole, maladie qui l'avait contaminé étant enfant : en 1754, il introduit l'argument probabiliste en faveur de l'inoculation auprès de l'Académie des sciences à Paris, et 1758 il en vante le mérite citant La Mottraye et l'usage répandu à Londres.
La pratique est d'abord contestée, mais un certain nombre de grands personnages suivent l'exemple du duc d'Orléans : le duc de Chartres la fait subir à ses fils, le duc de Valois et le duc de Montpensier, le 6 avril 1779.
Louis XVI a été inoculé en 1774.
Mais ce phénomène resta limité à une élite aristocratique, et ne se répandra pas parmi le peuple, malgré une tentative, en 1786 de faire inoculer les enfants abandonnés et orphelins des Provinces.
La méthode resta en France largement controversée, en raison de ses risques, parce qu'elle est accusée de provoquer des épidémies, les personnes inoculées étant contagieuses.
Le 8 juin 1763, un arrêt du parlement de Paris interdit de pratiquer la variolisation dans les villes et interdit l'accès des villes aux inoculés avant la sixième semaine.
La Faculté de médecine, sollicitée par le parlement, est partagée entre pro et anti variolisation.Cependant, entre 1765 et 1787, le docteur Jean-François-Xavier Girod (1735-1783) fait inoculer 33 619 personnes en Franche-Comté soit plus de 10 % de la population de la province.
Puis, Jean François Coste l'introduit au sein des armées napoléoniennes.
La méthode d’inoculation a été largement remplacée en 1796 par la vaccination proposée par Edward Jenner considéré comme le « père de l'immunologie ».La clavelée, aussi appelée variole ovine du fait de sa similitude avec la maladie humaine, a connu un traitement préventif par inoculation de matières contenant le virus pur.
Connu depuis probablement fort longtemps en Orient, ce traitement a été appliqué dès le XVIIIe siècle dans le midi de la France.
Cette pratique nommée en 1820 par Odier « clavelisation », — mais qui est aussi connue en anglais sous l'appellation d'« ovination » — a donné matière à législation dans la majorité des pays d’Europe continentale de 1880 à 1890.
Elle a connu un nouvel essor à partir de 1906, associée à l'administration de sérums d'animaux convalescents.À partir de 1852 Louis Willems (en) promeut pour sa part un procédé similaire pour la péripneumonie contagieuse (pleuropneumonie), mais semble-t-il avec moins de bonheur.L'aphtisation, qui avait semblablement cours à l'occasion d'épisodes de fièvre aphteuse, fut une pratique à laquelle MM.
Vallée et Carré étaient prêts à se résoudre — en association avec le sérum — avant de  mettre au point finalement le premier vaccin en 1936.
Mycobacterium bovis est la bactérie responsable d'une maladie dite  « tuberculose bovine » (TB) qui affecte les bovins d'élevage et sauvages, mais aussi de nombreux animaux sauvages mammifères autres que les bovins.
C'est l'une des formes du bacille de Koch (BK) responsables de diverses formes de tuberculose humaine.
Elle en est très proche génétiquement, mais avec un agencement différent des gènes.
C'est à partir d'une forme atténuée de ce bacille qu'est produit le vaccin BCGMycobacterium bovis peut franchir la barrière des espèces et infecter l’Homme.
Elle est donc classée parmi les « zoonoses » (infections  naturellement transmissibles de l'animal à l'homme et vice versa).
On en connait de nombreuses souches, plus ou moins virulentes.La recherche en termes de moyens de lutte épidémiologique a principalement porté sur des essais de vaccination, puis l’éradication de porteurs sauvages (avec le risque quand il s’agit d’espèces territoriales (blaireau, opossum) de contribuer à élargir les zones touchées).
La vaccination (qui s’est montrée bien plus efficace chez les renards sauvages que le piégeage dans le cas de la lutte contre la rage en Europe) a concerné le bétail, mais non les espèces sauvages.C'est une maladie probablement très ancienne, comme la tuberculose humaine.
Elle est courante chez les bovins, et durant la première moitié du XXe siècle a probablement causé une grande partie des pertes d'animaux de ferme.En 1998, l’OMS a estimé que la tuberculose bovine (TB) avait tué environ 30 millions de personnes pendant la décennie 1990-1999, ce qui est moins que la tuberculose humaine (80 millions) mais reste très important.
Pour ces deux maladies, la plupart des malades et des morts étaient dans les pays en développement.La TB est présente chez de très nombreux animaux, dans la plupart des pays en développement, où la surveillance et le contrôle sont absents ou insuffisants, rendant la prospective écoépidémiologique très difficile.De manière générale, la tuberculose préoccupe l'OMS, l'OIE et de nombreuses autorités sanitaires en raison d'une recrudescence dans certains pays, et d'une incidence croissante, notamment en raison du HIV/SIDA qui a aussi favorisé un développement nosocomial de la maladie.Ce bacille est une bactérie aérobie à croissance lente ; il lui faut 16 à 20 heures pour produire une seule génération.Il survit bien dans des tissus congelés, mais est détruit par la cuisson et divers biocides (ex tétraborate de sodium utilisé comme conservateur des tissus, dont en taxidermie).Les chercheurs étudient avec attention le génome de cette bactérie, notamment parce qu'il est proche de la tuberculose humaine et que de nombreuses bactéries sont capables d'échanges horizontaux de gènes.Le séquençage complet de Mycobacterium bovis, publié en 2003 a permis de comparer ce bacille avec ceux de M. tuberculosis et M. leprae.
Il s'est montré étonnamment proche de la bactérie responsable de la tuberculose humaine, M. tuberculosis (semblable à 99,95 %), mais une moindre redondance de l’information génétique fait qu'il a une taille plus petite.
Ce génome montre néanmoins une capacité plus large de codage de composants pour la paroi cellulaire et certaines protéines sécrétées.
Ceci évoque des interactions hôte–bacille plus complexes, et peut être un rôle dans l’ « évasion immunitaire » (capacité du bacille à échapper aux globules blancs).
En outre, les gènes de M. bovis et de M. tuberculosis sont les mêmes, ce qui invite à penser que leur expression différentielle pourrait être un facteur-clé de leur pathogénicité et de leurs «  tropismes d'accueil » (préférence en termes d’hôtes : humains, bovins ou autres mammifères).
Ces découvertes confirment ou précisent des hypothèses faites dans les années 1990 sur la base des premiers éléments de cartographie génomique de M. bovis et M. tuberculosis.Les chercheurs ont constaté que l'expression des gènes de ce bacille diffère fortement de celle de ceux de Mycobacterium tuberculosis responsable de la tuberculose humaine, bien que ces deux bactéries soient génétiquement très proches.
Si l'on compare les deux bactéries au moment de leur croissance exponentielle, une expression différentielle des gènes est détectée dans 258 gènes, soit 6 % du génome total.
Les principales variations concernent des gènes codant des protéines impliquées dans le métabolisme intermédiaire et la respiration, la construction de la paroi cellulaire et des protéines hypothétiques.
Par rapport à M. tuberculosis, les généticiens notent l'expression d'un plus grand nombre de régulateurs de transcription chez M. bovis.Les paramètres (pH, température, teneur en eau, teneur en sels, compétition avec d’autres organismes, présences de molécules naturellement bactéricides, etc.) en vertu desquels M. bovis peut ou pourrait se développer hors de l’organisme animal vivant, ne sont pas encore clairement connus.La bactérie a montré en laboratoire certaines capacités à survivre un certain temps (très variable selon les conditions) hors de l’organisme.
Mais elle ne se reproduit alors que très lentement, même dans de conditions jugées idéales de température et d’environnement.Selon les données disponibles elle ne peut pas se reproduire dans le lait, mais elle peut y survivre un certain temps (Sinha, 1994), de même que dans certains fromages à base de laits cru non pasteurisés.
Ce temps de survie varie selon les produits et selon leurs conditions de fabrication.
La littérature scientifique contient peu de preuves ou indices de survie de M. bovis dans des produits tels que la crème fraîche, le yaourt, le beurre et la crème glacée, mais les études les plus nombreuses ont concerné les fromages.
Une certaine survie a été observée dans le beurre, certains fromages et le fromage blanc (dans le fromage blanc au lait cru, la survie est encore observée à 14 jours, mais plus à 17 jours ; le produit n'est alors cependant plus adapté à la consommation car il peut commencer à être contaminé par des moisissures.
Des études ont concerné l'emmental, le cheddar, le gruyère, le munster, le camembert et le bleu d'Auvergne (« fromage bleu ») ; l’emmental a été particulièrement bien étudié, et on a montré que le processus de production avait dans ce cas une incidence sur les capacités de survie de M. bovis, peut-être en raison de l’échaudage à 53 °C du caillé durant 30–40 minutes, ce qui ne détruit pas M. bovis mais semble affecter sa capacité à survivre lors de la maturation du fromage.
Pour d'autres fromages à pâte dure tels le cheddar, une grande variabilité dans le temps est observée avec des bactéries viables durant 60 jours à plus de 200 jours dans certains cas.
Cette variabilité pourrait refléter des différences de concentration de cet organisme dans le lait utilisé.La bactérie meurt dans les fromages à longue maturation (certains fromages sont ainsi travaillés jusqu’à un an, voire plus, par exemple le cheddar ou la mimolette vieille et extra-vieille, etc.).Cette  maladie infectieuse chronique affecte une large gamme d'hôtes mammifères, dont les humains et les troupeaux de bovins, ; la bactérie infecte aussi des herbivores aussi variés que les cervidés, les camélidés (Chameau, mais aussi lama, alpaga, vigogne ou guanaco), des omnivores tels que le porc et le sanglier, ou des carnivores tels le chien, le chat domestique ou le chat sauvage, le renard, le coyote, les mustélidés, l’opossum ou des rongeurs.
Par contre, pour des raisons encore mal comprises, il affecte plus rarement les équidés, les caprins (chèvres et chamois) ou les ovins,.Les lésions macroscopiques se présentent à l'autopsie comme des papilles ou grumeaux beiges ou jaunâtres répartis ou tapissant la surface de certaines organes internes.
Chez les bovins, les tissus présentant le plus souvent des lésions macroscopiques visibles à l'examen post-mortem sont :Les lésions macroscopiques et histologiques les plus visibles et fréquents touchent les ganglions lymphatiques de la région thoracique.
Des lésions semblables peuvent être observées chez d'autres mammifères tuberculeux dont le cerfMycobacterium bovis peut néanmoins parfois être été isolé chez des bovins ne présentant aucune lésion macroscopique de la tuberculose.
Parfois des lésions existent, mais dans une zone habituellement non examinée par le vétérinaire après abattage (ex :  ganglion subiliaque).Dans la plupart des pays, la détection des lésions macroscopiques de la tuberculose lors de l'inspection vétérinaire des carcasses à l'abattoir est la principale méthode de détection des troupeaux de bovins (dont aux États-Unis dans les années 1990).Cette bactérie peut se transmettre et se propager de nombreuses façons, dont par exemple dans l'air expiré, les mucus et crachats, l’urine, les matières fécales et le pus.L'infection se produit si la bactérie est inhalée, ingérée ou introduite sous la peau ou dans le sang, et plus facilement chez les individus en état de déficience immunitaire.La maladie peut donc être transmise par contact direct avec l’animal malade (ou son cadavre) ou plutôt via ses excrétats ou par inhalation d'aérosols, selon les espèces concernées.Ils sont encore mal connus, mais la bactérie a probablement co-évolué avec les troupeaux depuis la naissance de l’élevage.
La maladie pourrait dans certains contextes jouer un rôle dans la limitation de la surpopulation de certaines espèces sauvages, notamment en l’absence de prédateurs.
Mais l'introduction par l'homme d'un variant pathogène dans une région du monde où les animaux sont immunologiquement « naïfs » à son égard peut décimer un grand nombre d'animaux.Une étude attentive de l'évolution de la régression de la tuberculose humaine depuis le XIXe siècle (fait constaté dans de nombreux pays), a montré qu’elle  a objectivement significativement régressé avant la découverte des antituberculeux, et même de la vaccination.
Les épidémiologistes supposent que ce sont les progrès de l’hygiène, de l’alimentation et des conditions de vie qui y ont contribué,,.Chez l'Homme,  M. bovis  est généralement transmise par du lait infecté, mais elle pourrait peut-être parfois aussi se propager par des microgouttelettes émises en aérosol par des animaux malades.Dans chaque région du monde, les conditions écoépidémiologiques changent, en raison d'une faune différente, de conditions d'élevages de bétail différentes, et aussi parfois peut-être en raison du caractère introduit et devenu invasif de certaines espèces ou de la présence d'autres mycobactéries qui pourraient interagir avec les souches connues de tuberculoses.
Les situations décrites ci-dessous illustrent ces situations différentes dont certaines sont jugées préoccupantes par les vétérinaires et écologues et/ou par les médecins.En Nouvelle-Zélande où les colons d'origine européenne ont introduit de nombreux troupeaux (ovins, chevaux et bovins, mais aussi 7 espèces différentes de cervidés), c'est un marsupial, l'opossum d'Australie (Trichosurus vulpecula), qui semble actuellement le principal vecteur de  dispersion du microbe.
Cet opossum est également allochtone ; il a été introduit (à partir de l’Australie) par les colons, pour sa fourrure.
Après s’être enfui d’élevages et/ou avoir été relâché par des propriétaires, il s’est ensuite reproduit dans la nature, où il a peu de prédateurs et de pathogènes mortels.
Il est aujourd’hui considéré comme espèce invasive dans le pays.
Il est de plus en plus porteurs de la bactérie de M. bovis  (environ 38 % de ces opossums étudiés en étaient porteurs dans les zones déclarées à risque d’infection pour le bétail.
Dans ces territoires déclarés à risque, près de 70 % des nouvelles infections de troupeaux semblent liées à l'opossum ou à des furets, qui eux-mêmes peuvent être infectés ou réinfectés par différents variants de la bactérie à partir des excréments des troupeaux, de cadavres, etc.En 1993, une loi dite « Biosecurity Act 1993 » a imposé une stratégie nationale de lutte antiparasitaire visant à contrôler si puis éventuellement éradiquer la maladie dans toute la Nouvelle-Zélande.
Dans ce cadre, un « Conseil de la santé animale (AHB, pour « Animal Health Board ») a été créé ; il gère d'une part un programme national de dépistage de la maladie dans le bétail néozélandais, et d'autre part un important programme de contrôle de l'opossum.
Ces deux programmes combinés visent - avant 2026 - à éradiquer  M. bovis  chez les vecteurs sauvages dans un territoire de 2,5 millions d'hectares (soit un quart des zones classées à risques de la Nouvelle-Zéland).
Il s’agira ensuite d'étendre les actions à l’ensemble du pays.Ce programme dit « TB-free New Zealand » est considérée comme " leader " dans le monde en la matière .Il a réussi à diviser par plus de 10 le taux de troupeaux infectés de cerfs et de bovins (passés de plus de 1700 troupeaux en 1994 à moins de 100 en Juillet 2011).
Une grande partie de ce succès est selon le gouvernement attribuable au « contrôle » des opossums qui a permis de réduire les  contaminations croisées entre les populations-réservoir et de briser le « cycle » de la maladie.
Par exemple, à Hohotaka, au centre de la Nouvelle-Zélande (île du Nord, de 1988 à 1994, le piégeage de cet animal en aurait réduit la densité de 87,5 %.
Dans le même temps, l’incidence annuelle de la TB dans les troupeaux locaux de bovins a diminué d'un taux comparable (83,4 %).Les opossums sont piégés ou tués par empoisonnés par des appâts par exemple empoisonnés au fluoroacétate de sodium (dit « Poison 1080 » en Nouvelle-Zélande) ou au cyanure de potassium, déposés au sol ou largués par voie aérienne.De 1979 à 1984, le contrôle de l'opossum par les autorités a été stoppé, au moins provisoirement, officiellement en raison d'un manque de financement.
Le tests réguliers et fréquents faits chez les troupeaux de bovins ont montré que le nombre de bovins infectés a ensuite de nouveau augmenté (jusqu'en 1994) .La part du territoire national où des animaux sauvages ont été trouvés porteurs de la maladie est passée d’environ 10 % à 40 %.L’opossum d’Australie semble être un vecteur de transmission de la maladie particulièrement efficace en raison du comportement qu’il adopte quand il y succombe : en phase terminale de tuberculose, il présente un comportement anormalement erratique, et il adopte un comportement diurne de recherche de nourriture (alors qu’il est normalement nocturne).
Il semble aussi rechercher des lieux où se tenir au chaud et se rapproche des habitations et élevage, on l'observe alors dans paddocks d'élevages, où il attire naturellement l'attention du bétail et des cerfs « curieux » (Le cerf a aussi été introduit en Nouvelle-Zélande pour en faire des élevages producteurs de viande, peaux, velours et trophées.
Ce comportement a pu être filmé.Il y a environ 9,3 millions de têtes de bétail dans le pays, réparties en  71 000 troupeaux et de nombreux cerfs sont élevés en enclos ou ont fondé des hardes dans la nature.
Ils y sont cependant moins densément présents que les opossums et sont donc supposés moins contribuer à disséminer les bactéries.
La santé des cheptels de bovins et d'ovins est une préoccupation majeure pour les autorités sanitaires, mais elles doivent aussi tenir compte du lobby de la chasse : sept espèces de grands cervidés sont chassés dans le pays par environ 40 000 chasseurs (à comparer à la population totale de  4,3 millions d'habitants) ; ces chasseurs abattent environ 70 000 cerfs par an.
Selon le gouvernement, sa stratégie de lutte antiparasitaire nationale 1996-2001 a atteint son objectif de réduction du nombre de troupeaux infectés (de 1700 à 800), mais sans réussir à empêcher l'expansion géographique des « zones à risque de vecteur »  (qui avaient en 2001 gagné 40 % de tout le territoire néozélandais.
Une seconde stratégie nationale a donc été mise en œuvre pour la période 2001-2013, avec l'objectif d'atteindre une prévalence de moins de 0,2 % dans les élevages de bovins et de cerfs en 2013.
Cette fois, un test de vaccination des opossums sauvage est envisagée, au moyen d'un vaccin de type BCG distribué par voie orale via des appâts dispersés dans la nature.Prévalence et risques : Dans les années 1930, il a été estimé que 30 % à 40 % (selon les sources) des bovins du Royaume-Uni étaient porteurs de cette bactérie.
Et au sein de la population humaine, les médecins détectaient annuellement environ 50.000 nouveaux cas de TB humaine,.
Aujourd’hui, selon le DEFRA et l'Agence anglaise de protection de la santé (Health Protection Agency ou HPA), le risque pour une personne de contracter la tuberculose bovine en Grande-Bretagne est très faible ; selon la HPA, les ¾ des 440 cas humains qui lui ont été signalés de 1994 à 2006 étaient âgés (> 50 ans, nés avant 1960, suggérant que la maladie était une réactivation d’une infection ancienne) et 20 % des cas étaient des personnes d’origine étrangère, probablement porteuses d’une infection acquise dans un autre pays.
Un petit nombre de cas concernaient des personnes ayant eu des contacts avec des animaux infectés.
Au Royaume-Uni, depuis 1994 il n'y a plus eu aucune preuve de cas humain pouvant être relié à une consommation récente de viande ou autre produit d’origine bovine.Le cas du blaireau : À la fin du XXe siècle, il a été démontré au Royaume-Uni que le blaireau était sensible à la bactérie, qu'il peut acquérir à partir des troupeaux qu'il approche (ou d’autres espèces) et éventuellement retransmettre à d'autres bovins domestiques, mais son rôle précis dans la transmission est mal mesuré et a été ensuite fortement relativisé.
Avant que l'importante de son rôle écoépidémiologique ait été évalué et comparé à celui d'autres espèces, à la demande d'éleveurs, des campagnes de battues, tirs et empoisonnements ou piégeage du blaireau ont été lancées.Des blaireaux (Meles meles) avaient déjà été trouvés porteurs de cette bactérie il y a une trentaine d’années, sans susciter d'émoi particulier, car c'est aussi le cas de quelques autres espèces et de nombreuses d'autres n'ont pas fait l'objet de campagnes de tests.
Puis en 1997, dans un contexte de crise sanitaire notamment lié au prion pathogène dit de « la vache folle », un comité d'examen indépendant a estimé que cet animal pouvait significativement contribuer à diffuser cette zoonose  entre les troupeaux de bovins.
Le blaireau a alors focalisé l'attention des éleveurs et chasseurs ; et il est devenu la source d'une longue dispute (non terminée) entre les défenseurs anglais de l'environnement et des animaux (désireux de sauver cette espèce déjà en régression ou disparue d’une partie de son aire naturelle de répartition) et les agriculteurs-éleveurs, auxquels se sont alliés de nombreux chasseurs (souhaitant être autorisés à détruire les blaireaux par abattage, piégeage et empoisonnement, afin de réduire les pertes dans les cheptel).Une première grande étude randomisée sur les effets de ces abattages intensifs a été faite, dont les premiers résultats ont été publiés en 2007.
Cette étude a été conçue et supervisée  par un groupe scientifique se présentant comme « indépendant » sur la TB, dit ISG (Independent Scientific Group) .Elle est basée sur une vaste expériences de terrain, où 3 stratégies sont testées et comparées dans une zone d’étude de 3 000 km2, avec un effectif dédié de 180 employés et un budget annuel de 7 millions $ (non compris les frais de laboratoire) ; la première stratégie consiste à éradiquer de manière proactive (en les recherchant et en les tuant), tous les blaireaux d’un large territoire, en observant si la maladie régresse dans les élevages de ces territoires.
La seconde stratégie consiste à tuer les blaireaux uniquement en réponse à des infections de bétail et autour des élevages.
La troisième (situation "témoin") consiste à ne pas tuer les blaireau.
Les effets éventuels des 3 « stratégies » sur la prévalence de la maladie dans les élevages ont été étudiés.
En 2007, dans son rapport final, l’ISG a conclu que : Le 26 juillet 2007, à la Chambre des lords, le ministre chargé de l'environnement, de l'alimentation et des affaires rurales (Lord Rooker) a dit au nom du gouvernement « Nous nous félicitons du rapport final du groupe scientifique indépendant, qui augmente encore les preuves disponibles.
Nous étudions attentivement les questions soulevées par ce rapport et continuerons  à travailler avec l'industrie, les conseillers du gouvernement et des experts scientifiques dans la prise de décisions politiques sur ces questions », mais le message que le blaireau était responsable de la zoonose semble persister chez une partie de la population anglaise.En 2008, le RSPCA (Royal Society for the Prevention of Cruelty to Animals) a insisté sur l'urgence de réviser cette politique de destruction qui n'est pas justifiables par une prévalence d'infection de seulement 4 à 6 % chez les blaireaux,.Au Royaume-Uni (comme ailleurs), bien d'autres mammifères (dont rongeurs connus pour être vecteurs de nombreuses zoonoses, et sangliers plus mobiles que les blaireaux) se sont révélés être infectés par la bactérie M. bovis.
Ils étaient cependant souvent moins fréquemment infectés que les bovins (et les blaireaux).
On cherche maintenant à mieux comprendre l'écoépidémiologie de cette zoonose.Les études vétérinaires, épidémiologiques et écoépidémiologiques faites en Angleterre et au Pays de Galles dans les années 2000 ont alors montré que dans certaines régions du Sud-Ouest de l'Angleterre, les cervidés, et notamment le daim, sans doute en raison de leur comportement grégaire et devenu moins mobiles et parfois en surdensité en raison de l'absence de grands prédateurs, d'apports artificiels de nourriture, de l'insularisation des massifs forestiers et d'une fragmentation croissante des forêts ont été impliqués en tant que réservoir animal et comme possible vecteur pour la transmission de la tuberculose bovine,.Il semblerait même que dans certaines régions, le daim a une responsabilité plus importante dans la transmission aux bovins et comme réservoir sauvage que le blaireau,ratio coût/efficacité : Il a été estimé en 2005 que les tentatives d’éradication de la TB ont coûté au Royaume-Uni environ £ 90 millions, sans grands résultats depuis plusieurs années.
D'un point de vue vétérinaire, ces financements auraient pu être ou pourraient être selon l'EFRA plus efficacement utilisés dans une stratégie multidimensionnelle croisant différentes méthodes de lutte contre la maladie, y compris dans la faune sauvage.Dans ce pays, la bactérie M. bovis est endémique chez le cerf de Virginie (white-tailed deer; Odocoileus virginianus) dans la partie nord-est de Michigan, et dans le nord du Minnesota et sporadiquement détecté au Mexique.Seul le cerf de Virginie a été confirmé comme un hôte sauvage lors de l’épidémie de TB qui a touché le Michigan, bien que d'autres mammifères tels que le raton laveur (Procyon lotor), et l’opossum (Didelphis virginiana) et le coyote (Canis latrans) puissent aussi servir d'hôtes réservoir ou final    Le fait que le cerf de Virginie soit un réservoir de la bactérie  M. bovis  est présenté comme un obstacle important à l’éradication de la maladie dans le bétail aux États-Unis et d'autre part, la chasse du cerf est une source importante de revenus pour le commerce local ; ainsi, en 2008, 733 998 chasseurs licenciés ont tué environ 489 922 cerfs de Virginie lors d'opérations présentées comme destinées à gérer ou contrôler la propagation de la maladie en limitant le nombre de ces cerfs.
Ces chasseurs ont acheté plus de 1,5 million de « bracelets » pour le cerf.
En 2006, cette chasse aurait rapporté 507 000 000 dollars à l'Économie du Michigan .Au Canada, les bisons sauvages et d'élevages font l'objet d'un suivi (comme pour la brucellose.La maladie est observée chez les bovins dans le monde entier, mais certains pays ont été en mesure de fortement réduire ou limiter l'incidence de la maladie grâce à des opérations de contrôle de type « Test et réforme »  appliquées au cheptel bovin (les animaux sont testés, et ceux qui portent la bactérie sont tués).Europe : La plupart des pays de l'Europe et plusieurs pays des Caraïbes (dont  Cuba) sont maintenant pratiquement exempts de  M. bovis  dans leurs élevages, mais des foyers sont périodiquement repérés dans les élevages, et la bactérie reste présente dans la nature.
Ainsi une étude récente (2004) a porté en Espagne sur 6 espèces : le cerf (Cervus elaphus), le daim (Dama dama), le sanglier (Sus scrofa), le lynx ibérique (Lynx pardinus), le lièvre (Lepus europaeus) et les bovins (Bos taurus), dans  plusieurs territoires.
Ces 6 espèces de mammifères ont été choisis pour leurs positions-clé dans les écosystèmes et parce qu’ils ont des relations reconnues avec le bétail.
Les résultats de l'étude ont confirmé les liens bétail-faune sauvage : les mêmes souches de M. bovis infectaient plusieurs espèces sauvages autour des troupeaux porteurs de la même souche, sans que l’on ait retrouvé un spoligotype localement prédominant.
Les auteurs de cette étude estiment qu'il faut mieux comprendre la transmission et de la distribution de la maladie pour mieux cibler les mesures de contrôle de la TB.Au Canada : Là ce sont le wapiti et le cerf de Virginie qui sont porteurs de la bactérie, notamment dans et autour du Parc national Riding Mountain dans le Manitoba.
Pour améliorer le contrôle et éliminer la tuberculose bovine, l'Agence canadienne d'inspection des aliments (ACIA) a divisé le Manitoba en deux zones de gestion, avec un plan de lutte contre la tuberculose (RMEA) dans la zone où la maladie a été trouvée .
La maladie a aussi été trouvé dans les troupeaux de buffle africain en Afrique du Sud.En Afrique du Sud :  Des conséquences écologiques graves sont observées en depuis 1990.
La TB s'y est rapidement développé dans la faune sauvage et a décimé les troupeaux sauvages de buffles autochtones (Syncerus caffer) et leur principal prédateur le lion.
Les premiers cas n’ont été détectés chez le buffle qu’en 1990 dans le parc national Kruger ; en 1999 plus de 70 % des buffles africains (Syncerus caffer) étaient tuberculeux dans le sud du Parc.
Une transmission inter-espèce vers le koudou et l'antilope, le chimpanzé, le babouin, ainsi que le lion a été constatée, avec des conséquences graves pour la biodiversité de la région,.Des preuves et indices semblent disculper la faune sauvage en tant que cause première ou importante par rapport aux pratiques d'élevages.
De plus la vaccination a montré dans le cas de la rage une efficacité très supérieure aux tentatives d'éradication des animaux qui avaient été supposés responsables des épidémies dans les élevages.
Dans un autre domaine, mais avec des enjeux en partie similaires, les études écoépidémiologiques concernant le H5N1 et la grippe comme zoonose ont aussi pointé l'importance des transferts d'animaux malades par l'homme, de la gestion des déchets animaux (épandage, gestion des cadavres, etc.) et des pratiques d'élevage dans les épidémies touchant les élevages.Comme c'est une zoonose, les stratégies de lutte devraient à la fois porter sur le contrôle de la bactéries dans les élevages et dans la faune sauvage et domestique (chiens, chats, etc.).
Cependant la prévalence de la maladie dans la nature, et les relations entre faune sauvage et bétail sont encore mal connues.La tuberculose est l'un des premiers bacilles découverts et étudiée par les hygiénistes.
En 1901 Von Behring, assistant de Robert Koch et premier lauréat du prix Nobel de physiologie ou médecine, déclarait lors de la cérémonie de remise du prix : « Comme vous le savez, la tuberculose chez les bovins est l'une des maladies infectieuses les plus dommageables qui puisse affecter l'agriculture » .Un siècle plus tard, l'incidence de la maladie était fortement réduite ou contrôlée dans la plupart des pays riches, avec parfois des pics 2,8 % des bovins en l’an 2000 en Grande-Bretagne sauf dans le sud-ouest où ce taux est plus important, avec une augmentation exponentielle de cas en 10 ans malgré la destruction des blaireaux qui étaient suspectés de véhiculer le bacille entre troupeaux .Pour mieux contrôler la maladie, il faudrait aussi mieux la contrôler dans la nature, chez les espèces dites « réservoir ».
Les tentatives d'éradication des espèces porteuses s’avèrent souvent être des échecs et être couteuses, voire avoir un effet inverse à ce qui était espéré, en étendant par exemple les zones touchées.
La vaccination est une piste qui semble potentiellement efficaceL'examen clinique d'un animal vivant permet éventuellement de détecter des lésions évoquant la tuberculose.
L'examen histopathologique augmente la confiance du diagnostic, mais seul l'isolement bactériologique de Mycobacterium bovis de la lésion permet de poser le diagnostic définitif.
La sensibilité de l'examen post mortem brut est affectée par la méthode employée et les sites anatomiques examinés.Ils sont nécessaires pour le dépistage sur animal vivant ou la recherche des causes sur des animaux morts.
Des faux positifs et des faux négatifs sont possibles.
Si un test était positif et que l'examen post-mortem ne trouve pas de lésions caractéristiques de la tuberculose, cela peut être dû à une infection précoce, une technique d'autopsie inadaptée ou à une infection par des mycobactéries autres que M. bovis.
Un examen bactériologique est nécessaire pour confirmer ou non la présence de la bactérie.Sur animal vivant, les tests les plus pratiqués aujourd'hui sont :Il varie beaucoup selon les lieux et les moments.
Il n'es pas ou très peu pratiqué dans les pays dits pauvres ou émergents.Dans les pays dits riches ou industriels, il est souvent pratiqué en routine, mais plus fréquent dans les zones classées à risques ou dans les années suivant l'émergence d'un nouveau foyer et dans les zones périphériques à ce foyer.
À titre d'exemple, dans les années 2000 au Royaume-Uni, tout bovin (sauf certains bœufs en engraissement, devait subir un dépistage obligatoire tous les 1, 2, 3 ou 4 ans selon la zone où est situé l'élevage.
L'intervalle entre deux dépistages variait selon la zone (selon le degré de risque estimé en fonction de la déclaration ou non de foyers les 2, 4 ou 6 années précédentes dans la zone, avec réévaluation annuelle (ou à l'occasion d'un nouveau foyer de BT) par l'autorité sanitaire (Animal Health)L'Union européenne a une stratégie visant à limiter voire éradiquer la maladie dans les États-membres, par un strict contrôle des maladies dans les échanges intracommunautaires de bétail.
Pour des raisons de sécurité sanitaire, les États-membres doivent pratiquer dans les élevage jugés indemnes de maladie le dépistage pré mouvement (c'est-à-dire chez l'éleveur avant transfert vers l'acheteur), 30 jours avant toute exportation vers un autre pays européen.
Il existe aussi un dépistage aléatoire ou post-mouvement (chez l'acheteur).Mais dans les années 2000, la situation sanitaire des troupeaux varie encore selon les pays et les conditions environnementales, conduisant à une situation épidémiologique hétérogène.
Les 10 nouveaux entrants avaient en 2004 presque éradiqué la maladie (0,2 % de prévalence), mais des préoccupations persistent sur les risques de détection tardive ou l’apparition de nouveaux variants plus virulents ou l’introduction de microbes avec des animaux importés.Elle semble être une piste potentiellement la plus efficace, en accompagnement d'une meilleure politiques de gestion de risques sanitaires dans les filières de l'élevage ; d'autant que d'importants progrès ont été récemment accomplis en matière de vaccination contre la tuberculose et que de nombreux auteurs ont conclu dès la fin du XXe siècle, d'après les retours d’expérience sur la rage, d'autres maladie et selon les données disponibles sur la tuberculose, que l’approche la plus prometteuse était la vaccination des animaux sauvages en accompagnement de la lutte contre la maladie dans les élevages.
Par exemple, le blaireau pourrait en Angleterre être vacciné.
Ceci est encore plus vrai dans les pays en développement où la mise en place d’un système complet de veille sanitaire et de tracabilité serait plus couteuse et difficile.Pourtant, la vaccination pose encore deux problèmes :Un premier vaccin fut expérimenté en 1886 par Vittorio Cavagnis tandis qu'à cette même époque Robert Koch tenta vainement de développer un sérum curatif basé sur la tuberculine.En 1902, à partir d'un bacille d'origine humaine atténué, Behring tente de produire un vaccin contre la tuberculose bovine : le « bovovaccin ».
Behring proposa également, sans succès, la « tuberculase ».
Toujours dans le domaine vétérinaire, Koch essaya le tauruman.
Pour mémoire, il faut aussi citer le sérum de Marmorek ( 1904), le sérum de Maragliano, les sérums de Richet et Héricourt, ainsi que les tentatives peu honnêtes de Friedmann (en) et de Spahlinger.C'est en 1921 qu'Albert Calmette et Camille Guérin de l'Institut Pasteur de Lille essayent avec succès le premier vaccin contre la tuberculose sur lequel ils travaillaient depuis 1908 - qui était conçu pour être un vaccin vétérinaire.
Baptisé BCG (pour Bacille de Calmette et Guérin ou Bilié de Calmette et Guérin) ce vaccin issu d'une souche vivante atténuée de Mycobacterium bovis deviendra obligatoire en France en 1950.La mortalité et morbidité des animaux d'un troupeau ont un coût pour l'éleveur.Les stratégies de lutte contre la maladie pourraient s'appuyer sur les soins vétérinaires et la vaccination, mais
La méningite est une maladie caractérisée par une inflammation des méninges, les enveloppes du névraxe (encéphale et moelle spinale).
Cette inflammation peut être due à une infection par un virus ou une bactérie par exemple, et moins souvent par un médicament.
La méningite peut menacer le pronostic vital en raison de la proximité immédiate de l'encéphale ; il s'agit d'une urgence.
C'est essentiellement le fait des méningites bactériennes, plus rares, tandis que les méningites virales, plus fréquentes, sont en principe bénignes.Les signes habituels de la méningite sont la céphalée (mal de tête), la raideur de nuque, la fièvre, la confusion, le vomissement, la photophobie (intolérance à la lumière) et la phonophobie (intolérance au bruit).
Chez les enfants, les symptômes sont souvent moins spécifiques, avec par exemple une irritabilité ou une somnolence.
Une éruption cutanée peut faire évoquer une cause particulière selon son aspect ; c'est le cas pour la méningite à méningocoque par exemple.Une ponction lombaire permet d'affirmer le diagnostic.
Il s'agit d'insérer une aiguille dans le canal vertébral pour prélever du liquide cérébrospinal ; c'est le liquide situé au sein des méninges, afin de l'examiner.
Le traitement initial de la méningite aiguë peut comporter un ou plusieurs antibiotiques, parfois un antiviral.
Une corticothérapie peut être associée afin de prévenir une réaction inflammatoire excessive.
La méningite peut laisser des séquelles non négligeables telles qu'une surdité, une épilepsie, une hydrocéphalie, un trouble cognitif, surtout lorsque le traitement n'est pas administré suffisamment rapidement.
Certaines formes de la maladie peuvent être prévenues avec la vaccination contre le méningocoque, Haemophilus influenzae type B, le pneumocoque ou le virus des oreillons par exemple.Chez l'adulte, le symptôme le plus fréquent au cours d'une méningite est la céphalée intense, présente dans 90 % des cas de méningite bactérienne, suivie par la raideur de nuque (flexion passive du cou impossible en raison d'un tonus musculaire augmenté).
La triade clinique classique associe raideur de nuque, fièvre élevée et confusion ; elle est complète dans seulement 45 % des cas de méningite bactérienne,.
En l'absence de ces trois signes, le diagnostic de méningite est très improbable.
D'autres signes sont souvent présents, tels que la photophobie ou la phonophobie.
Le sujet âgé présente fréquemment une symptomatologie a minima.
Le petit enfant montre rarement les signes précédemment cités, et peut présenter seulement une irritabilité ou une impression de malaise.
Il peut exister un bombement de la fontanelle avant 6 mois.
D'autres signes peuvent orienter vers une méningite, comme des douleurs des membres inférieurs, des extrémités froides, une modification du teint,.Chez l'adulte, la raideur de nuque est retrouvée dans 70 % des cas de méningites bactériennes.
Il peut exister d'autres signes du syndrome méningé, les signes de Kernig et de Brudzinski.
Le signe de Kernig est défini par une limitation douloureuse de l'extension passive des genoux lorsque le patient est allongé sur le dos, hanches et genoux fléchis à 90°.
Le signe de Brudzinski est positif lorsque survient une flexion involontaire des hanches et des genoux lors de la flexion passive du cou en position allongée.
Ces deux signes, souvent recherchés, ont une sensibilité limitée,.
Cependant, ils ont une très bonne spécificité.
Il existe un autre test, la manœuvre d'accentuation par secousse (traduction littérale de l'anglais) qui consiste à effectuer un mouvement de rotation active et rapide du cou, dite positive si elle provoque l'augmentation de la céphalée ; lorsqu'elle est négative, la probabilité de méningite est diminuée.La méningite causée par le méningocoque peut se différencier des autres lorsque survient une éruption pétéchiale (petites taches pourpres non effaçables à la vitropression) d'extension rapide et pouvant précéder les autres signes.
Cette éruption est localisée sur le tronc, les membres inférieurs, les conjonctives et parfois les mains.
Bien que non systématique, elle est relativement spécifique de la maladie ; cependant elle est parfois présente au cours d'autres méningites bactériennes.
Il y a d'autres signes pouvant orienter vers une cause particulière ; ainsi la présence d'un syndrome pieds-mains-bouche ou d'un herpès génital est associée avec plusieurs méningites virales.Plusieurs complications graves peuvent survenir au cours de l'évolution précoce de la maladie.
L'infection peut conduire à un sepsis avec syndrome de réponse inflammatoire systémique (tachycardie, fièvre, polypnée), une hypotension artérielle.
Cette hypotension peut survenir rapidement, notamment en rapport avec une infection à méningocoque, et définissant un sepsis sévère voire une insuffisance circulatoire aiguë ou choc septique.
Ensuite peut survenir une coagulation intravasculaire disséminée qui peut à la fois gêner la circulation et favoriser une hémorragie.
Une gangrène peut survenir au niveau des membres au cours d'une infection à méningocoque.
Lorsque le méningocoque ou le pneumocoque sont en cause, une hémorragie des glandes surrénales peut conduire au syndrome de Waterhouse-Friderichsen, souvent fatal.Une méningite peut induire un œdème cérébral qui peut engendrer une hypertension intracrânienne, voire un engagement cérébral.
Ceci peut se traduire par une perte de conscience, une perte de réflexe pupillaire, ou une rigidité corporelle.
Cette inflammation peut également gêner la circulation du liquide cérébrospinal et engendrer une hydrocéphalie.
Une crise d'épilepsie peut survenir pour de multiples raisons, telles qu'une hypertension intracrânienne ou la présence d'une inflammation localisée.
Chez l'enfant cependant, une méningite se traduit fréquemment (30 % des cas) par une crise d'épilepsie précoce sans impliquer de cause particulière.
Une crise de caractère partiel, persistant, tardif ou difficile à contrôler par le traitement est péjoratif pour le pronostic à long terme.L'inflammation des méninges peut provoquer une anomalie des nerfs crâniens (nerfs essentiellement à destination de la face et du cou et impliqués par exemple dans le mouvement des yeux, la mimique ou l'audition),.
Des symptômes visuels et auditifs peuvent également persister à distance.
D'autres complications comme une encéphalite (on parle alors de méningo-encéphalite), une vascularite ou une thrombose veineuse cérébrale peuvent survenir et se traduire par une sensation de faiblesse, des troubles sensitifs ou des mouvements anormaux,.La méningite est classiquement causée par une infection, le plus souvent virale.
Ensuite viennent les causes bactériennes, fongiques pouvant être endogène pour les immunodéprimés, ou exogène par inhalation ce qui complique la recherche du spectre et retarde la prise en charge antibiothérapique et protozoaires.
D'autres causes non infectieuses peuvent provoquer une méningite.
L'expression « méningite aseptique » est parfois utilisée dans ce type de cas, bien qu'elle puisse également désigner une méningite virale, ou une méningite bactérienne avec un examen du LCR négatif du fait soit d'un traitement antibiotique préalable, soit d'une présence bactérienne faible (cas de la méningite secondaire à une endocardite), soit d'une bactérie difficilement identifiable (comme dans le cas de la syphilis ou de la maladie de Lyme).
La méningite peut être due au paludisme ou à l'amœbose.De nombreux virus peuvent être responsables de méningite, comme des entérovirus, des herpesvirus (HSV2, HSV1, VZV), rubulavirus, VIH, LCMV.Les bactéries pouvant être responsables de méningite ne sont pas les mêmes en fonction de l'âge :Le vaccin antipneumococcique a entraîné une diminution de l'incidence de la méningite pneumococcique chez l'enfant et l'adulte.Un traumatisme crânien récent peut potentiellement entraîner une brèche ostéoméningée et mettre en contact les bactéries du nez avec les méninges.
De la même manière, l'implantation chirurgicale de matériel à l'intérieur du crâne comme une dérivation ventriculaire est associée à un risque accru de survenue de méningite.
Dans ces cas, les bactéries susceptibles sont Staphylococcus, Pseudomonas et d'autres bactéries Gram-négatif.
Ces pathogènes sont également retrouvés dans les cas d'immunodépression.
Une infection des voies aérodigestives supérieures comme une otite moyenne ou une mastoïdite peut se compliquer de méningite dans un petit nombre de cas.
Les sujets porteurs d'un implant cochléaire (dans le traitement de la surdité) présentent un plus grand risque de méningite pneumococcique.La méningite tuberculeuse, causée par Mycobacterium tuberculosis, est plus fréquente chez les patients originaires de pays où la tuberculose est endémique, ou chez les patients immunodéprimés comme dans le cas du SIDA.Une méningite bactérienne récurrente peut être favorisée par une brèche ou par un déficit immunitaire, acquis ou congénital.
Une brèche permet la communication entre le contenu de la boite crânienne et l'environnement, le plus fréquemment à la suite d'une fracture au cours d'un traumatisme crânien, notamment au niveau de la base du crâne.
Environ 60 % des cas de méningite récurrente sont en rapport avec une brèche ostéoméningée, 35 % avec un déficit immunitaire et 5 % avec une infection d'un site anatomique proche.Certains germes peuvent être responsables d'une « réaction méningée », c'est-à-dire d'une méningite qui passe au second plan en raison d'une atteinte méningée discrète et parfois de la présence d'autres localisations plus bruyantes.
De tels germes peuvent être présents dans le liquide cérébrospinal : Treponema pallidum (syphilis), Leptospira interrogans (leptospirose), Borrelia burgdorferi (maladie de Lyme), * la fièvre pourprée des Montagnes Rocheuses et d'autres rickettsioses, Pseudomonas aeruginosa ou Klebsiella pneumoniae.Une méningite d'origine fongique survient sur terrain immunodéprimé : traitement immunosuppresseur (par exemple dans la prise en charge de Réaction Immunitaire Chronique tel le lupus, l'arthrite , etc., ou des neutropénies post médication oncologique ou extrêmement agressive avec des traitements de type anti candida endologique comme le fluconazol, ou quand l'hypothermie le nécessite Amphotéricine B comme le fungizone par exemple, à la suite d'une greffe), SIDA, baisse d'immunité liée à l'âge.
C'est une situation rare en dehors d'un tel terrain.
Il y eut cependant une épidémie aux États-Unis liée à l'utilisation de matériel médical souillé.
Le début est progressif avec des symptômes pouvant durer deux semaines avant le diagnostic.
L'agent le plus fréquemment en cause est Cryptococcus neoformans ; ce germe est le plus fréquemment retrouvé en Afrique, toute cause de méningite incluse et il est responsable de 20 à 25 % des décès relatifs au SIDA en Afrique.
D'autres germes peuvent être en cause : Histoplasma capsulatum, Coccidioides immitis, Blastomyces dermatitidis, ou des espèces de Candida.Au cours d'une méningite parasitaire est évoquée lorsqu'il existe une prédominance d'éosinophiles au sein des leucocytes retrouvés dans le liquide cérébrospinal.
Les parasites les plus souvent retrouvés sont Angiostrongylus cantonensis, Gnathostoma spinigerum, Schistosoma, Taenia solium, Toxocara, Baylisascaris procyonis, Paragonimus, et d'autres plus rares.Une méningite peut être due à plusieurs situations non infectieuses, comme un cancer (méningite dite carcinomateuse) ou un médicament (principalement AINS, antibiotiques et immunoglobulines).
Des maladies inflammatoires peuvent être en cause comme la sarcoïdose (neurosarcoïdose), des connectivites comme le lupus ou des vascularites comme la maladie de Behçet.
Un kyste épidermoïde ou un kyste dermoïde peut être responsable de méningite,.
Rarement, la migraine peut être impliquée.D'autres situations sont caractérisées par une réaction méningée biologique sans réelle méningite comme le syndrome de Guillain-Barré, l'administration de produits intrarachidiens (chimiothérapie, produits de contraste, anesthésiques), le syndrome de Vogt-Koyanagi-Harada (syndrome VKH).Les méninges sont des membranes superposées qui, avec le liquide cérébrospinal, enveloppent et protègent le névraxe (encéphale et moelle spinale), au sein de la boite crânienne et du canal vertébral.
On distingue trois couches de tissu : la pie-mère, l'arachnoïde et la dure-mère.
La pie-mère est une membrane fragile et imperméable, adhérente à la surface de l'ensemble du névraxe.
L'arachnoïde est une sorte de sac qui contient le névraxe et la pie-mère, baignés dans le liquide cérébrospinal.
La dure-mère est une membrane plus solide et accolée à l'arachnoïde.
La dure-mère est également accolée à la paroi de la boite crânienne, mais elle est séparée de la paroi du canal vertébral par un espace graisseux.Les germes peuvent atteindre les méninges de plusieurs manières différentes : soit spontanément par le biais de la circulation sanguine ou par continuité directe, par exemple lorsqu'il existe une communication entre les méninges et les fosses nasales ; soit secondairement du fait d'un traumatisme crânien ou d'un acte de neurochirurgie.
Le plus souvent, une méningite est hématogène, secondairement au passage dans le sang d'un germe présent au niveau des muqueuses.
Lorsqu'il s'agit d'une bactérie, une telle invasion est souvent facilitée par une infection virale qui altère la barrière muqueuse physiologique.
Une fois dans la circulation, cette bactérie pénètre l'espace sous arachnoïdien en franchissant un point de faiblesse de la barrière hémato-encéphalique, par exemple au niveau d'un plexus choroïde.
Ainsi, une méningite survient chez un quart des nouveau-nés atteints de septicémie à streptocoque B ; c'est moins souvent le cas chez l'adulte.
Lorsque la contamination des méninges est directe, elle peut être liée à la présence d'un dispositif à demeure, à une fracture du crâne ou à une infection des voies aériennes supérieures avec formation d'un chenal vers l'espace sous-arachnoïdien ; rarement, une pathologie congénitale de la dure-mère est en cause.L'inflammation diffuse de l'espace sous-arachnoïdien au cours d'une méningite n'est pas directement lié à l'existence d'une infection, mais plutôt à la présence d'une réponse immunitaire à la suite de cette infection.
Lorsque les cellules immunitaires du système nerveux central (astrocytes et microgliocyte) détectent des molécules caractéristiques des bactéries, ils sécrètent une quantité importante de cytokines, médiateurs qui recrutent d'autres cellules pour participer à la réponse immunitaire.
La perméabilité de la barrière hémato-encéphalique est augmentée, provoquant un œdème cérébral dit « vasogénique » (augmentation de volume du cerveau lié à du passage de liquide en provenance des vaisseaux sanguins).
De nombreux leucocytes envahissent le liquide cérébrospinal, menant à une réaction inflammatoire des méninges et à un œdème interstitiel.
L'inflammation touche également les parois des vaisseaux, ce qui diminue la circulation sanguine et provoque un œdème dit « cytotoxique ».
Cet œdème, issu de trois mécanismes de formation différents, aboutit à une augmentation de la pression intracrânienne ; ceci, avec la diminution de pression artérielle souvent associée, conduit à une diminution de la vascularisation du cerveau, et les neurones privés d'oxygénation meurent par apoptose.L'administration d'un traitement antibiotique au cours d'une méningite bactérienne peut initialement aggraver le phénomène décrit ci-avant, en provoquant le relâchement de molécules issues de la destruction de bactéries.
Certains traitements concomitants, comme les corticoïdes, ont pour but d'amoindrir ce processus,.Une ponction veineuse est effectuée afin de rechercher des marqueurs d'inflammation (élévation de la CRP, hyperleucocytose) et d'effectuer une hémoculture,.L'examen complémentaire essentiel à l'identification d'une méningite est l'analyse du liquide cérébrospinal obtenu par ponction lombaire.
Toutefois une telle ponction est contre-indiquée en cas de masse cérébrale (tumeur, abcès) ou d'hypertension intracrânienne, pouvant entraîner un engagement cérébral.
En cas de situation à risque (traumatisme crânien, déficit immunitaire, signe neurologique focal, signe clinique d'hypertension intracrânienne), une imagerie cérébrale préalable est recommandée, avec un scanner ou une IRM,,.
C'est une situation concernant potentiellement environ 45 % des cas adultes.
Lorsqu'une imagerie est effectuée avant la ponction ou que celle-ci se montre difficile à réaliser, il est suggéré d'administrer un traitement antibiotique immédiatement afin de ne pas retarder le délai de mise en route du traitement, surtout si une telle attente est prévue pour dépasser 30 minutes,.
Souvent, lorsque l'imagerie n'est pas faite initialement, elle est faite plus tard dans les cas où il existe une complication.Dans les formes sévères, l'ionogramme sanguin peut montrer une hyponatrémie, fréquente en cas de méningite bactérienne et en rapport avec plusieurs facteurs, notamment la déshydratation, le SIADH et un remplissage vasculaire important,.La ponction lombaire est un geste médical permettant un prélèvement de liquide cérébrospinal.
Le patient est positionné soit en décubitus latéral, soit en position assise, rachis en flexion.
Une aiguille adéquate est insérée après avoir effectué une anesthésie locale.
Ce geste permet de mesurer la pression d'ouverture de l'espace sous arachnoïdien, en utilisant un manomètre dès que l'aiguille est en place.
Sa valeur est normalement comprise entre 6 et 18 cm d'eau ; elle est habituellement élevée en cas de méningite bactérienne,, ou à cryptocoque.
La description macroscopique du liquide peut orienter vers la nature de l'infection : un aspect opaque indique un niveau élevé de protéines, hématies, leucocytes ou bactéries, ce qui peut suggérer une origine bactérienne.L'échantillon de liquide cérébrospinal est analysé en laboratoire afin de déterminer la numération de cellules (globules rouges et globules blancs), la protéinorachie et la glucorachie.
Une coloration de Gram est également effectuée afin de mettre en évidence une bactérie, présente à l'examen direct dans 60 % des cas seulement, moins souvent en cas d'antibiothérapie préalable (20 %) ou lorsque Listeria est en cause.
La culture a une sensibilité plus élevée, de l'ordre de 75 %, mais ce résultat peut demander jusqu'à 48 heures de délai.
Parmi les leucocytes, le type majoritaire permet d'orienter le diagnostic plutôt vers une forme bactérienne si les neutrophiles prédominent, ou vers une forme virale si les lymphocytes prédominent.
Cependant, une telle analyse n'est pas fiable au début de la maladie.
Rarement, une prédominance d'éosinophiles peut suggérer une étiologie parasitaire ou fongique.La valeur normale de la glycorachie est définie en fonction de la glycémie ; elle est supérieure à 40 % de la valeur de la glycémie (60 % chez le nouveau-né).
La glycorachie est classiquement diminuée (hypoglycorachie) en cas de méningite bactérienne, avec un ratio inférieur à 40 % (60 % chez le nouveau-né).
Le dosage de lactate oriente vers une méningite bactérienne lorsqu'il est élevé, tout comme le compte de leucocytes.
SI ce taux est inférieur à 35 mg·dL-1 en l'absence d'antibiothérapie préalable, une origine bactérienne semble moins probable.D'autres tests plus spécialisés peuvent être effectués pour aider à différencier les différentes causes possibles.
Un test d'agglutination au latex peut être positif lorsque Streptococcus pneumoniae, Neisseria meningitidis, Haemophilus influenzae, Escherichia coli ou Streptococcus agalactiae sont en cause ; cependant son utilisation doit être réservée lorsque les autres examens n'ont pas permis de conclure.
Il en est de même pour le test au lysat de limule qui peut être positif en cas de méningite bactérienne.
La PCR qui permet de détecter la présence d'ADN spécifique d'un microbe donné est très sensible et spécifique et peut permettre de connaître par exemple l'agent responsable d'une ménigite virale parmi enterovirus, herpes simplex virus 2 ou le virus des oreillons.
La sérologie permet l'identification d'anticorps et peut être utilisée dans la méningite virale par exemple.En cas de suspicion de tuberculose, le prélèvement de LCS est analysé avec une coloration de Ziehl-Neelsen, de faible sensibilité, et mis en culture spécifique ; la PCR est parfois utilisée.
La suspicion de crypotcoccose nécessite un examen avec un coloration à l'encre de Chine ; une autre technique de recherche d'antigène spécifique est une technique plus sensible, notamment en cas de SIDA,.Lorsque le patient a reçu des antibiotiques avant la ponction lombaire, la situation peut être celle d'une méningite « décapitée », c'est-à-dire que l'analyse du liquide peut être faussement évocatrice d'une méningite virale en raison de l'action partielle du traitement initié.
Dans un tel cas, le traitement antibiotique doit être poursuivi sauf si la cause d'une méningite non bactérienne est mise en évidence, par exemple en cas de PCR enterovirus positive.Si classiquement il est dit qu'« il n'y a pas de contre-indication à la ponction lombaire dès l'instant où le diagnostic de méningite est suspecté », cet examen est contre-indiqué dans les cas suivants qui nécessitent une imagerie cérébrale : risques d’engagement cérébral élevé : signes de localisation neurologique, score de Glasgow < 11, crises d’épilepsie partielle ou totale ; anomalie de l’hémostase ou patient sous anticoagulation.Le diagnostic de méningite peut être porté après la mort lorsqu'une autopsie est réalisée, montrant une inflammation de la pie mère et de l'arachnoïde avec des neutrophiles pouvant gagner le système nerveux central via les nerfs ou les vaisseaux méningés, parfois entourés de pus.Pour certaines causes de méningites, des mesures de protection sont disponibles, par exemple à long terme avec la vaccination, ou à court terme avec un antibiotique.
Des mesures simples peuvent également être employées.Les méningites infectieuses sont contagieuses, bien que moins que le rhume ou la grippe.
Le mode de transmission est principalement de type "gouttelettes", c'est-à-dire que la contagion se fait à proximité immédiate, soit par contact direct, soit par l'inhalation de particules en suspension transitoire du fait de la toux par exemple.
La méningite virale à entérovirus peut être transmise par contamination dite "orofécale", c'est-à-dire que la maladie se répand avec les mains sales.
Ainsi, l'évitement du contact rapproché et le lavage des mains peuvent aider à prévenir la transmission.Depuis les années 1980, de nombreux pays appliquent chez les enfants un programme de vaccination systématique contre Haemophilus influenzae type B, permettant de pratiquement éliminer la méningite à hémophilus chez les enfants concernés.
Du fait de son coût, ce vaccin n'est pas disponible dans plusieurs pays où l'incidence est élevée,.
La vaccination contre les oreillons a également permis une diminution drastique du nombre de cas de méningites dues au virus des oreillons dans les pays où elle a été mise en place.Les vaccins antiméningococciques éprouvés sont dirigés contre les méningocoques des groupes A, C, W135 et Y.
Dans les pays où le vaccin contre le méningocoque C a été introduit, le nombre de cas de méningites liées à ce pathogène a considérablement diminué.
La vaccination contre le méningocoque C a une efficacité de plus de 90 %.
En France, depuis 2010, le vaccin anti-méningocoque C conjugué est recommandé par les autorités sanitaires.
Le vaccin quadrivalent est obligatoire pour les personnes désirant un visa pour se rendre en pèlerinage à la Mecque.
Dans certains pays (Nouvelle-Zélande, Cuba, Norvège et Chili), des vaccins contre des souches locales de méningocoque B ont été développés ; certains ont de bons résultats.En Afrique jusqu'à récemment, la prévention de la méningite à méningocoque était basée sur la détection précoce des cas et la vaccination de la population à risque par le vaccin bivalent A/C ou trivalent A/C/W135 ; cependant l'introduction d'un vaccin monovalent A a été démontré efficace, et a été décrite comme un modèle de partenariat pour le développement de produits à destination de populations à ressources limitées,.La vaccination contre le pneumocoque avec le vaccin conjugué heptavalent permet de réduire significativement l'incidence de la méningite pneumococcique,.
Le vaccin polysaccharidique à 23 valences, réservé à certains sujets (par exemple ceux ayant subi une splénectomie), ne provoque pas une réponse immunitaire significative chez toutes les personnes.
La vaccination par le BCG dans l'enfance permet de réduire le risque de survenue de méningite tuberculeuse, quand bien même cette efficacité diminue à l'âge adulte.L'antibioprophylaxie est utilisé en traitement préventif.
Dans le cas de la méningite à méningocoque, pour les sujets contact proches d'un cas, un traitement par rifampicine, ciprofloxacine ou ceftriaxone peut réduire le risque de développer la maladie à court terme,.
Les cas de résistance à la rifampicine ont été décrits en augmentation grâce à son utilisation, ce qui a poussé certains à envisager d'autres molécules.
Les antibiotiques sont fréquemment utilisés en prévention dans les cas de fracture de la base du crâne, et il n'y a pas de preuve suffisante en faveur ou en défaveur de cette attitude.
C'est le cas qu'il y ait ou non une fuite de LCS.La méningite est une affection potentiellement mortelle ; en l'absence de traitement adéquat, le taux de décès est élevé.
Un délai de traitement long est associé à un pronostic péjoratif.
Ainsi, l'instauration d'un traitement par antibiotique à large spectre ne devrait pas attendre les résultats des examens complémentaires de confirmation du diagnostic.
Si une méningite à méningocoque est suspectée lors d'une consultation de médecine de ville, l'administration de benzylpénicilline est recommandée avant le transfert à l'hôpital.
En France, il est possible d'utiliser la ceftriaxone, en raison de son spectre large, « couvrant » une grande majorité des agents de méningites, de sa disponibilité d'injection intramusculaire et de la possibilité de recours chez l'allergique à la pénicilline.
L'administration de soluté de remplissage intraveineux est recommandé en cas d'hypotension ou choc.
Étant donné que la méningite comporte un risque de complications précoces sévères, une surveillance médicale régulière est requise pour les dépister précocement et transférer le patient en unité de soins intensifs au besoin.La mise sous ventilation mécanique peut être indiquée s'il existe une altération prononcée de la conscience ou en cas d'insuffisance respiratoire.
S'il y a des signes d'hypertension intracrânienne, un monitorage de la pression intracrânienne est souhaitable afin de prendre des mesures thérapeutiques afin d'optimiser la pression de perfusion cérébrale, par exemple en diminuant la pression intracrânienne par l'administration de mannitol intraveineux.
Les crises d'épilepsie sont traitées par des anticonvulsivants.
En cas d'hydrocéphalie, il est possible de recourir à la mise en place d'un système de drainage du LCS tel que la dérivation ventriculaire.Un traitement antibiotique empirique doit être entrepris sans délai, avant même d'avoir les résultats des examens complémentaires.
Le choix de la molécule utilisée dépend de l'épidémiologie bactérienne locale des méningites.
Par exemple, au Royaume-Uni, une céphalosporine de troisième génération telle que le céfotaxime ou la ceftriaxone est recommandée,.
Aux États-Unis, il est recommandé d'associer une céphalosporine de troisième génération et la vancomycine, en raison de résistance accrue de streptocoque aux céphalosporines,,.
Le chloramphénicol, seul ou associé à l'ampicilline, semble tout aussi efficace.Un tel traitement peut être adapté en fonction de l'âge du patient et de la possibilité d'existence d'un brèche ostéoméningée (notion de traumatisme crânien ou d'intervention neurochirurgicale préalable).
Chez les jeunes enfants, les sujets de plus de 50 ans, et les sujets immunodéprimés, il est recommandé l'addition d'ampicilline à une céphalosporine de troisième génération afin de couvrir Listeria monocytogenes,.
Lorsque le résultat de l'examen bactériologique direct est connu et qu'il permet d'orienter vers un germe particulier, il est possible de modifier l'antibiothérapie pour cibler le germe suspecté.
Le résultat de la culture du LCS est plus long à obtenir, avec en général un délai de 24 à 48 heures.
Une fois connu, le traitement antibiotique peut être adapté au germe identifié et à son spectre de résistance.
Pour qu'un antibiotique soit actif au cours d'une méningite, il faut non seulement qu'il soit actif vis-à-vis du germe en cause, mais aussi qu'il diffuse dans le LCS en quantité suffisante.
Cette diffusion dépend de la capacité intrinsèque de la molécule à passer la barrière hémato-encéphalique, qui varie d'une molécule à l'autre.L'efficacité des principaux antibiotiques utilisés au cours de la méningite n'a pas été évaluée sur des sujets humains pour des raisons éthiques ; les données d'efficacité sont donc issues de tests sur des lapins de laboratoire.
La méningite tuberculeuse nécessite un traitement antibiotique prolongé pour une durée totale d'un an voire plus.Un traitement adjuvant par corticoïdes (habituellement la dexaméthasone) a plusieurs bénéfices démontrés tels que la diminution du risque de surdité et un meilleur pronostic neurologique à court terme chez les adolescents et les adultes dans des pays à revenus élevés et à prévalence du VIH faible.
Certaines études sont en faveur d'un effet sur la réduction de la mortalité tandis que d'autres ne retrouvent pas une telle association.
Les corticoïdes apparaissent également bénéfiques dans la méningite tuberculeuse chez les sujets non infectés par le VIH.Il est recommandé de commencer la corticothérapie juste avant l'antibiothérapie et de la poursuivre pour 4 jours,,.
Étant donné que l'efficacité de ce traitement est essentiellement réservée aux cas de méningite pneumococcique, certaines recommandations préconisent de l'arrêter lorsqu'un autre germe que le pneumocoque est identifié,.
Le mécanisme d'action supposé est la suppression d'une hyperactivité inflammatoire.Chez l'enfant, l'utilité de la corticothérapie dans les pays à faibles revenus n'est pas confirmée, contrairement à ceux des pays à hauts revenus, sans que les raisons soient évidentes.
Dans les pays à hauts revenus, l'utilité des corticoïdes est plus importante en cas de méningite à Haemophilus influenzae,.
La corticothérapie est donc recommandée lorsque H. influenzae est en cause, et reste controversée dans les autres cas.La méningite virale requiert habituellement un traitement uniquement symptomatique, car la plupart des virus responsables de méningites n'ont pas de traitement spécifique.
Par ailleurs, une méningite virale est le plus souvent bénigne.
Herpes simplex virus et varicella zoster virus peuvent être traitées par des antiviraux tels que l'aciclovir, bien qu'il n'existe pas d'essai thérapeutique spécifique.
Les cas de méningites virales peu symptomatiques peuvent être affranchies d'une hospitalisation et bénéficier d'un traitement symptomatique associant hydratation, repos et antalgie.
En revanche, en cas de méningo-encéphalite herpétique, un traitement antiviral s'impose.La méningite fongique, par exemple la cryptococcose, qui explique les radiographie thoracique systèmatique en Europe des sujets immunodéprimés mais aussi les bilans sanguins type sérologie anti candida, peut être traitée par une administration prolongée d'antifongique tel que l'amphotéricine B ou la flucytosine,, ou prévenu si prise de pénicilline par une prise simultanée d'un spectre anti fongique type fluconazol, cela prévient tous les risques de complication de type fongique en même temps pernicieux comme la kératite mycosique, ou la bascule en mycélium, ou dans la sphère ORL c'est la raison de examen cytopathologique des aldénoidectomies (confirmation de spectre) et administration pendant 24H de amphotéricine B chez l'adulte .
Une hypertension intracrânienne est fréquente dans ce type de méningite, aussi il est recommandé de réaliser des ponctions lombaires évacuatrices itératives (quotidiennes idéalement) ou un drainage.Non traitée, la méningite bactérienne est presque toujours fatale.
A contrario, la méningite virale a le plus souvent une évolution favorable spontanément.
La mortalité d'une méningite bactérienne, lorsqu'elle est traitée, dépend de l'âge avec une mortalité estimée de 20 à 30 % chez les nouveau-nés, 2 % chez l'enfant plus grand, et 20 à 40 % chez l'adulte,.
Le risque de décès dépend d'autres facteurs tels que le germe en cause et le temps nécessaire pour l'éliminer du LCS, le retentissement global sur l'organisme, une altération de la conscience ou un taux de leucocyte faible dans le LCS.
La méningite à Haemophilus influenzae ou à méningocoque est de meilleur pronostic qu'une méningite due au streptocoque de groupe B, au coliforme ou au pneumocoque.
Chez l'adulte également, le méningocoque a une moindre mortalité que le pneumocoque.Chez l'enfant, les séquelles potentielles, résultant d'une lésion du système nerveux, sont nombreuses : surdité, épilepsie, trouble de l'apprentissage ou du comportement, ou déficit intellectuel.
Elles sont relevées chez 15 % des survivants.
Chez les adultes, les séquelles sont notées dans un tiers des cas.
Les principales sont la surdité (14 %) et les troubles cognitifs (10 %).Bien que la méningite soit une maladie à déclaration obligatoire dans de nombreux pays, l'incidence exacte est inconnue.
En 2010 il était estimé que le nombre de décès était de 420 000.L'incidence annuelle de la méningite bactérienne est estimée à trois cas pour 100 000 personnes dans les pays occidentaux.
La méningite virale est plus fréquente avec une incidence annuelle de 11 cas pour 100 000 personnes, le plus souvent l'été.
Dans d'autres pays comme le Brésil par exemple, l'incidence est plus élevée, estimée à 46 pour 100 000.
L'Afrique subsaharienne est une région caractérisée par la survenue d'importantes épidémies de méningite à méningocoque depuis plus d'un siècle, ce qui fait que cette région est surnommée « ceinture de la méningite ».
Les épidémies surviennent habituellement à la saison sèche (entre décembre et juin) et par vagues pendant 2 à 3 années consécutives, régressant à chaque saison des pluies.
Des taux d'attaques de 100 à 800 cas pour 100 000 sont observés au cours de telles situations, par ailleurs caractérisées par un faible accès aux soins médicaux.
Le méningocoque est le germe principal de ces épidémies.
L'épidémie rapportée la plus importante a eu lieu en 1996-1997 avec plus de 250 000 cas et 25 000 morts.La méningite à méningocoque survient par épidémie en collectivité regroupant de nombreuses personnes comme dans les casernes militaires, les campus universitaires ou le pèlerinage à la Mecque.
Bien que les caractéristiques des épidémies africaines de la ceinture de la méningite ne soient pas bien comprises, de nombreux facteurs associés sont retrouvés.
Ces facteurs comprennent les caractéristiques médicales (susceptibilité immunitaire d'une population), démographiques (déplacements de populations), socio-économiques (surpopulation, pauvreté) et climatiques (sécheresse, tempêtes de sable), et la présence d'autres infections (respiratoires).Il existe des différences de distribution des causes de méningite.
Par exemple, concernant le méningocoque, les groupes B et C sont responsables de la plupart des cas en Europe, tandis que le groupe A est largement prédominant en Afrique (80 à 85 % des cas),,.Certains suggèrent qu'Hippocrate connaissait l'existence de la méningite et il semble que le méningisme était connu par des médecins du Moyen Âge tels qu'Avicenne.
La première description de la méningite tuberculeuse, appelée alors œdème cérébral, est souvent attribuée au médecin écossais Robert Whytt dans un rapport posthume apparu en 1768, bien que le lien avec le germe et la maladie n'ait été établi qu'au siècle suivant,.L'existence d'épidémies de méningites serait relativement récente.
La première épidémie majeure rapportée date de 1805 à Genève,.
De nombreuses autres épidémies ont été décrites peu après en Europe et aux États-Unis, tandis que la première épidémie rapportée en Afrique date de 1840.
Les épidémies africaines sont devenues plus fréquentes au siècle suivant, la première datant de 1905-1908 et s'étendant du Nigeria au Ghana.La première mention d'une bactérie causant une méningite remonte à 1887, quand le bactériologiste autrichien Anton Weichselbaum (en) décrivit le méningocoque.
La mortalité était alors très élevée, supérieure à 90 %.
En 1906, une sérothérapie a été mise au point à partir de chevaux, puis développée par le scientifique américain Simon Flexner, ce qui a permis de réduire la mortalité de la méningite à méningocoque,.
En 1944, la pénicilline était le premier antibiotique efficace contre la méningite.
À la fin du XXe siècle, l'introduction du vaccin dirigé contre Haemophilus influenzae a permis la diminution des cas de méningite associée.
En 2002, il a été montré que l'adjonction de corticoïdes améliorait le pronostic des méningites bactériennes,,.Selon une étude prospective, une exposition d'enfants de moins de 5 ans au tabagisme passif entraîne un doublement des infections à méningocoque, et un triplement lors d'une exposition in utero au tabagisme.
Renard est un terme ambigu qui désigne le plus souvent en français les canidés du genre Vulpes, le plus commun étant le Renard roux (Vulpes vulpes).
Toutefois, par similitude physique, le terme est aussi employé pour désigner des canidés appartenant à d'autres genres, comme les genres Atelocynus, Cerdocyon, Dusicyon, Otocyon, Lycalopex et Urocyon.
Dans la culture populaire, le renard est un personnage symbolique et littéraire qui représente l'intelligence et surtout la ruse.Le substantif masculin,, renard est une antonomase lexicalisée, résultat de l'emploi, comme nom commun, de Renart, nom propre du héros éponyme du Roman de Renart.Jusqu'à la fin du XVIIe siècle, le renard est encore fréquemment appelé un goupil.
Le terme actuel de renard, pour désigner l'animal, n'est autre que le prénom Renart donné au goupil héros du Roman de Renart.
Au centre de ce recueil d'histoires imaginaires, Renart le goupil est très rusé et les tours qu'il joue aux autres animaux et aux humains ont rendu le personnage très célèbre (on disait : « malin comme Renart »).
De ce fait, son prénom s'est substitué à goupil par éponymie.
Sur ce point, voir la symbolique du renard et le renard dans la culture.Renard a été graphié Renart jusqu'au milieu du XVIe siècle.
Le nom propre est tiré d'un anthroponyme francique *Raǥinhard, composé des éléments *raǥin (« conseil ») (cf.
Raimbaud, Rainfroy), et *hard (« dur », « fort ») (cf.
Il a pour équivalents les prénoms moyen néerlandais Reynaerd et vieux haut allemand Reginhart (allemand Reinhart).Quant au terme goupil, il est attesté sous les formes gulpil en 1155, volpil en 1180, golpilz en 1120, gupil en 1121-1134.
Il procède du gallo-roman *WULPĪCULU, variante du latin populaire *vŭlpīculus ou du bas latin vulpiculus, dont sont directement issus l'occitan volpìlh et l'ancien italien volpiglio.
La forme masculine vulpiculus est une altération du latin classique vulpēcula « petit renard » (qui a donné l'espagnol vulpeja), diminutif de vulpēs « renard » en latin classique, d'où l'italien moderne volpe.
Le passage de  à  en gallo-roman s'explique par l'influence phonétique du francique (peut-être inspirée dans ce cas par le vieux bas francique *wulf « loup »), ensuite  se durcit régulièrement en , puis se délabialise en  en français central et à l'ouest, mais pas dans les dialectes d'oïl septentrionaux (ex.
: bas-lorrain, champenois, picard, ancien normand septentrional woupil).Le latin vulpēs est issu de l'indo-européen commun *(H)ulp-i-, qui est continué par l'avestique urupi « martre » et le lituanien vilpišỹs « chat sauvage », ainsi que par des formes dérivées comme le persan rubâh (روباه) « renard » et le sanskrit lopāśá « chacal ».Le renard est un canidé.Le renard femelle adulte est la renarde.
Le renard juvénile est le renardeau.Les caractéristiques générales des renards sont celles des Canidés, avec des nuances pour chaque espèce, de même que l'habitat ou les données biologiques et comportementales peuvent varier selon l'espèce et même la sous-espèce : voir les articles détaillés pour plus d'informations sur leur physiologie ou comportement respectifs.Pour le renard le plus répandu en Eurasie, en Amérique du Nord, en Afrique du Nord et en Australie, voir Renard roux (Vulpes vulpes).En français, « renard » ne correspond pas à la tribu des Vulpini (les renards « vrais »), qui regroupe seulement les genres Vulpes (renards au sens strict), Otocyon (Renard à oreilles de chauve-souris) et Nyctereutes (Chien viverrin), ce dernier n'étant pas même assimilé aux renards par les francophones.Liste alphabétique de noms vernaculaires attestés en français.Note : certaines espèces ont plusieurs noms et, les classifications évoluant encore, certains noms scientifiques ont peut-être un autre synonyme valide.
En gras, l'espèce la plus connue des francophones.Le renard est un personnage littéraire qui a la caractéristique de représenter l'intelligence et la ruse.
On peut citer notamment : Les renards sont vecteurs de l'échinococcose alvéolaire, maladie qui peut se révéler mortelle chez l'homme.
Cette pathologie se découvre plusieurs années après l'avoir contractée : certaines personnes sont mortes car on croyait à un cancer du foie.
Ces maladies sont transmises par la salive ou les excréments des carnivores porteurs ou par ingestion d'aliments souillés par eux.
Néanmoins, un cycle se forme entre rongeurs et renards.
Le ver se trouvant dans les excréments du renard et les rongeurs le mangeant, puis le renard mangeant les rongeurs, il y a un cycle naturel.
Seuls une vingtaine à une soixantaine de cas sont déplorés chaque année en France.
De plus, les chiens et chats non vermifugés peuvent la transmettre.
Pour éviter de l'attraper, il faut avoir de l'hygiène dès que l'on est dans la nature ou avec des animaux.Certains renards font eux-mêmes preuve d'hygiène et d'astuce en sachant se débarrasser de leurs parasites externes: par exemple, il a été observé qu'un renard, après avoir récolté dans sa gueule sans l'ingérer une importante touffe de poils de bouquetins abandonnés en début d'été, se plongeait progressivement dans un lac en commençant par la queue et finissant par le museau, restant ainsi quelque temps parfaitement immergé, de sorte que les parasites migrent vers la touffe qu'ils abandonna en suite.La rage est une maladie que le renard transmettait autrefois.
Une campagne de vaccination par voie orale a permis de s'en débarrasser rapidement en Europe occidentale, si bien qu'elle ne sévit plus en France depuis 1998.Les renards ont un rôle important dans la régulation des rongeurs en campagne, tels que les campagnols, les mulots, les souris, ou encore les rats.
Ils en consomment des milliers chaque année, ce qui en fait des auxiliaire de cultures efficaces pour les agriculteurs, permettant de limiter les dégâts que font ces rongeurs aux récoltes,.Ils ont également un rôle important dans la lutte contre la maladie de Lyme en consommant les rongeurs sur lesquels vivent les tiques pouvant transmettre cette maladie, tels les campagnols et les rats taupiers.
Leur présence permet également de limiter le nombre de rongeurs contaminés en réduisant leurs déplacements,.Le renard et le chat haret qui ont été introduits en Australie contribuent à la disparition de plusieurs espèces dans ce pays :Les techniques de chasse au renard sont le déterrage (effectué en période de reproduction), la chasse à courre, au fusil, à l'arc ou le piégeage.Considéré comme espèce susceptible d'occasionner des dégâts (ESOD) en France, entre 600 000 et 1 million d'individus y sont tués chaque année.
Les chasseurs reprochent au renard de leur faire concurrence en s'attaquant au petit gibier, tels que le lapin, la perdrix ou le faisan (il serait ainsi la première cause de mortalité du faisan selon la Fédération des chasseurs de la Loire).
Réputé pour être un « voleur de poules », il est également accusé par les agriculteurs de s'attaquer aux élevages de volailles en plein air,.Les défenseurs du renard estiment cependant qu'il ne fait que profiter du « gibier d'élevage » relâché par les chasseurs eux-mêmes, qui constitue alors une proie facile ne sachant pas se défendre dans la nature,.
Ils avancent également que la responsabilité du renard dans les attaques que subissent les volailles d'élevage, bien que réelle, est surestimée par rapport à celle d'autres prédateurs comme les rapaces.
Le renard serait en outre un opportuniste, qui ne chercherait à s'attaquer qu'aux poulaillers peu protégés.
La prédominance des campagnols prairiaux dans leur régime alimentaire en fait des auxiliaires des cultures, la pullulation de ces rongeurs étant responsable de dégâts occasionnés aux productions agricoles et forestières et qui peuvent être chiffrés.
Selon les sources, la prédation exercée par un renard sur les campagnols fait économiser 2 400 à 3 000 € par an à l'agriculture, et même 3 800 € en région céréalière.Comme d'autres prédateurs, c'est également un animal qui s'autorégule : la proportion de femelles gestantes et le nombre de renardeaux par portée s'adaptent selon les ressources et le territoire disponibles.
Ses défenseurs estiment donc qu'il est inutile de chercher à réguler sa population par la chasse,.En raison de l'élimination récente et généralisée par l'Homme des grands canidés et des grands félins, les prédateurs du haut de la pyramide alimentaire dans de nombreux écosystèmes terrestres sont maintenant des carnivores de taille moyenne (tels que les lynx ou coyotes en Amérique du Nord).Or, bien qu'étant un prédateur relativement généraliste, le coyote élimine volontiers ses concurrents prédateurs, et notamment le renard.
Il est démontré que l'activité prédatrice du coyote favorise l'abondance des oiseaux chanteurs et même l'abondance de certains rongeurs ainsi que la diversité biologique.
Ceci s'explique par le fait qu'ils réduisent les populations de chiens et de chat domestiques ainsi que de renards (ce qui montre au passage l'importance du renard en matière de lutte contre les rongeurs).La réintroduction ou le confortement de populations de loup gris dans de nombreuses régions d'Amérique du Nord va à nouveau modifier la chaîne d'interactions prédateurs-proies ; une étude basée sur une série chronologique de 30 ans de suivi du loup, du coyote, du renard et de leur abondance relative dans l'état du Minnesota (États-Unis) montre en effet que le retour des loups réduit également (ou supprime parfois) à son tour des populations de coyotes, ce qui redonne au renard sa position de mésoprédateur, et qui pourrait lui permettre d'à nouveau et mieux réduire les pullulations de petits rongeurs.Ainsi, une prédation plus marquée par les petits prédateurs (renards et mustélidés), et moins marquée par les coyotes (prédateurs de moyenne envergure) grâce à leur contrôle par quelques « grands » prédateurs (loup, cougar, lynx) pourrait être plus semblable au potentiel écologique et à l'écosystème historique qui était en place avant la disparition ou régression du loup du « sommet de la pyramide » (cette situation n'est néanmoins pas comparable à la situation préhistorique où les grands prédateurs étaient non seulement plus nombreux mais aussi beaucoup plus grands et plus puissants que le loup (Lion d'Amérique, Tigre à dents de sabre, Ours à face courte…), même après trois ères glaciaires et au début de l'actuel inter-glaciaire.
La « déstructuration » ou la « restructuration » des communautés de prédateurs en raison de la perte ou de la restauration des populations de moyens et/ou grands prédateurs est susceptible de modifier le spectre de taille des proies consommées massivement, avec des implications importantes, directes et indirectes, pour la biodiversité et la santé humaine,.
Les macrophages (du grec macro-, gros et -phagein, manger) sont des cellules appartenant aux globules blancs, qui sont définis historiquement par leur capacité de phagocytose.
Ce sont des grosses cellules arrondies avec un noyau excentré et des vacuoles dans leur cytoplasme.
Ils ont deux origines : certains macrophages ont une origine embryonnaire et résident dans les tissus tout au long de la vie de l'individu, d'autres proviennent de la différenciation de leucocytes sanguins circulants, les monocytes.Les macrophages sont des phagocytes et sont donc capables de phagocytose.
Leur rôle principal est de phagocyter les débris cellulaires et les agents pathogènes.
La reconnaissance de motifs microbiens par les récepteurs situés à la surface des macrophages conduit à la phagocytose et à la destruction des agents infectieux, par le processus d'explosion oxydative (oxidative burst en anglais) et la production de radicaux libres de l'oxygène.
Les macrophages produisent également des chimiokines, permettant le recrutement d'autres cellules sur le site de l'infection.Comme les cellules dendritiques, ils sont capables de se comporter comme des cellules présentatrices d'antigène.
Ils participent à l’immunité innée en tant que défense non spécifique, mais sont capables de participer à l’immunité adaptative via le phénomène d’opsonisation.Ils ont été découverts par le biologiste russe Elie Metchnikoff en 1883.
Leur nom provient du grec : « gros mangeur », μάκρος, makros = grand et φαγεῖν, phagein = manger.La plupart des macrophages résidents des tissus sont des macrophages embryonnaires.
Ils dérivent directement de cellules de la vésicule vitelline sans passer par un état monocytaire et sont capables d'auto-renouvellement et de maintenance indépendamment des monocytes.Les macrophages de la lignée monocytaire (ou macrophages monocytaires) ont été davantage étudiés pour des raisons pratiques.
Ils sont différenciés à partir des monocytes, qui sont des phagocytes sanguins, eux-mêmes dérivés de la moelle osseuse.
Quand un monocyte infiltre un tissu en traversant l’endothélium vasculaire par diapédèse, il subit sa différenciation terminale pour devenir un macrophage.
Les monocytes, puis les macrophages sont attirés vers le lieu d’une inflammation par chimiotactisme.
Les signaux d’appel sont constitués de différents stimuli, dérivés de cellules endommagées (par nécrose ou apoptose), de pathogènes, et de produits libérés par les cellules présentes au site : l’histamine relarguée par les mastocytes et les granulocytes basophiles, et des chimiokines et cytokines libérées par des macrophages.Contrairement aux granulocytes neutrophiles, qui sont les cellules phagocytaires présentes le plus vite au lieu de l’inflammation et qui ne vivent que quelques jours, la durée de vie d’un macrophage va de plusieurs mois à des années.
Au cours du temps, on a un remplacement de la plupart des macrophages embryonnaires par des macrophages d'origine monocytaire.
Ce remplacement n'est pas observable pour la microglie, une population de macrophage embryonnaire qui peuple le système nerveux central.Les macrophages peuvent se définir par les marqueurs membranaires CSF1R et CD64.Ils interagissent grâce à la présence de plusieurs types de récepteurs : les récepteurs PAMP et DAMP, les récepteurs opsioniques, les récepteurs cytokinétiques et chimiokinétique, les récepteurs de  signalisation, les récepteurs d'adhésivité cellulaire et des récepteurs modulant leur activé par un rétrocontrôle négatif.
L'existence de deux catégories de macrophages nommées M1 et M2 a été proposée depuis les années 2000.
Les M1 sont impliqués dans la destruction des agents pathogènes.
Les M2 sont impliqués dans la réparation et cicatrisation cellulaire.
Cette différenciation se fait par une dégradation différente de l'arginine  en oxyde nitrique dans le cas de M1 et en ornithine dans le cas de M2.
Toutefois, cette distinction ne semble appropriée que dans des modèles in vitro.
L'hétérogénéité des populations de macrophages dans les modèles in vivo suggèrent que cette distinction est artificielle et ne traduit pas une réelle dichotomie dans les fonctions des macrophages.
Les macrophages forment une population "plastique" : ils peuvent changer d'un phénotype à l'autre in vivo.
On parle de polarisation des macrophages pour désigner le processus par lequel les macrophages exhibent un phénotype spécifique et une réponse fonctionnelle aux stimuli du microenvironnement et aux signaux rencontrés par les macrophages dans des tissus spécifiques.
La fonctions des macrophages est spécifiques des tissus considérés : il est délicat de leur attribuer une fonction générale.
Si on doit catégoriser les fonctions des macrophages, elles peuvent être considérées comme étant des fonctions immunitaires ou des fonctions homéostatiques.Un des rôles principaux des macrophages est le nettoyage de corps nécrotiques et de corps apoptotiques, de débris et de poussières dans le cas des poumons.
L’élimination des cellules mortes est importante dans le cadre des phases précoces de l’inflammation chronique.
Cette élimination est dominée par l’action des granulocytes neutrophiles, qui seront eux-mêmes phagocytés par les macrophages une fois vieillis (voir CD31 pour plus de détails).L’élimination de la poussière et des tissus nécrotiques est prise en charge à une plus grande échelle (hors inflammation), par des macrophages résidents qui restent à des endroits stratégiques comme les poumons, le foie, les tissus nerveux, les os, la rate et les tissus conjonctifs, et qui digèrent les particules étrangères comme la poussière et les débris, mais aussi les pathogènes, recrutant en cas de besoin des monocytes circulants pour leur différenciation locale en macrophages tissulaires.Lorsqu’un macrophage ingère un pathogène, la vésicule intracellulaire formée est nommée phagosome.
Elle va fusionner avec un lysosome.
Les enzymes lysosomiales et les radicaux libres de l’oxygène (notamment l’hypochlorite) vont tuer et digérer l’intrus.
Cependant, certains organismes peuvent résister à ce processus et survivre dans le macrophage, comme Mycobacterium tuberculosis ou les Leishmania.
Un macrophage peut digérer une centaine de bactéries avant de succomber lui-même à ses propres enzymes de digestion.Après avoir digéré un pathogène, un macrophage peut se comporter en cellule présentatrice d'antigène, c’est-à-dire présenter un antigène de manière à stimuler un lymphocyte T spécifique.
La stimulation lymphocytaire par un macrophage est moindre que celle induite par une cellule dendritique, mais les macrophages sont capables de présenter des antigènes associés  aux molécules du complexe majeur d'histocompatibilité de classe deux, et donc de stimuler des lymphocytes CD4+.Une immunisation se traduit également par la production d'anticorps dirigés contre les antigènes immunisants.
Ces anticorps vont se lier aux antigènes de surface des pathogènes.
Certains isotypes sont opsonisants, c'est-à-dire qu’il existe sur les phagocytes des récepteurs spécifiques des fragments constants des chaînes lourdes des anticorps.
(Dans le cas des IgG (immunoglobuline d'isotype G), ce sont les CD16, CD32 et CD64.)
Les macrophages possèdent ce type de récepteurs et la liaison d’un complexe immun à ces récepteurs déclenche la phagocytose.
Ainsi, un pathogène qui sera invisible aux yeux d’un macrophage deviendra visible une fois opsonisé.Les macrophages sont capables de sécréter un grand nombre de cytokines comme l'interleukine 1 (IL-1), l'interleukine 6 (IL-6), le facteur nécrosant des tumeurs (TNF-α).
Ils participent de façon active au recrutement des autres cellules de l'immunité innée.
In vitro, les macrophages M1 activés libèrent des cytokines pro-inflammatoires dont le TNF-α, l'IL-1α, l'IL-1β, l'IL-6, l'IL-12, l'IL-18 et l'IL-23.
Ils produisent de l'oxyde nitreux (NO), des espèces réactives de l'oxygènes (ROS) et des espèces réactives de l'azote (RNS).
Ils expriment également des récepteurs aux chimiokines (CCR1 et CCR5).In vitro, les macrophages M2 activés libère plutôt des cytokines de résolution de l'inflammation comme l'IL-10 ou le TGF-β.Les macrophages jouent un rôle important au niveau de la peau qui est un organe important pour l'immunité.
Ils  stimulent également les cellules impliquées dans la cicatrisation ou la régénération du derme (et un défaut de cette fonction de réparation peut conduire à des phénomènes inflammatoires et au cancer).
Les macrophages peuvent aussi stimuler les cellules souches des follicules pileux qui produisent poils et cheveux via des signaux moléculaires émis par les macrophages et reçus par les cellules souches du follicule pileux au repos (HF-SCs).Un type particulier de macrophages, les ostéoclastes, sont responsables de l'homéostasie tissulaire dans l'os.
Ils jouent un rôle de contrôle de la quantité d'os fabriqué.Certains macrophages résidents des poumons libèrent le surfactant pulmonaire.Les macrophages contribuent de façon importante dans la progression de maladies inflammatoires comme le diabète, le cancer, et l'athérosclérose.
Parmi leur rôles en pathologie humaine :La majorité des macrophages (en situation non inflammatoire) résident à des endroits stratégiques du corps.Ils sont ainsi présents aux endroits les plus susceptibles d’invasion microbienne ou d’accumulation de débris de toutes sortes.Les macrophages portent un nom différent selon leur localisation :
La maladie de Carré est une maladie virale contagieuse d'animal à animal, mais non transmissible à l'Homme.
Elle est due à un paramyxovirus proche de l'agent de la rougeole humaine et de celui de la peste bovine.
Elle affecte habituellement les canidés (loup, chien, renard), certains mustélidés (vison, furet), les ratons laveurs (1re cause de mortalité en Ontario en 2020), et possiblement les marmottes et les félidés sauvages.
Enfin, elle peut probablement toucher de nombreux autres carnivores terrestres et marins (comme le phoque).La symptomatologie associe des manifestations fébriles, des écoulements oculaires et nasaux, une atteinte respiratoire, gastro-intestinale et parfois neurologique.
Dans certains cas assez rares une hyperkératose de la truffe et des coussinets est possible.
Autrefois extrêmement fréquente, la maladie de Carré est aujourd'hui beaucoup plus rare dans les pays où les propriétaires de chiens domestiques ont adopté la prévention vaccinale.La maladie est décrite en 1905 par le vétérinaire Henri Carré.En France, elle ne semblait toucher que les chiens, mais le Réseau SAGIR a signalé une émergence de la maladie de Carré au sein de populations de carnivores sauvages, dans trois départements frontaliers de la Suisse ou de l'Italie.
En Afrique, une épidémie locale survient en 2020 à Abidjan pendant la saison des pluies.Sa répartition mondiale et européenne dans la faune sauvage n'est connue que depuis peu : elle a été signalée en Espagne puis en Italie (2006), en Allemagne (2008), en Suisse (2009) et en Belgique ainsi qu'en France début 2019.Selon l'ONCFS/Réseau SAGR, un typage génétique des souches permet de dessiner les filiation entre souches sauvages de divers pays.
Les souches européennes identifiées à  ce jour sont très apparentées entre elles et clairement apparentées aux souches identifiées sur la faune sauvage alpine d’Italie et de Suisse notamment.Un vaccin est utilisé pour protéger les chiens et les furets domestiques, mais pas pour la faune sauvage.En 1994, un tiers de la population de lions du parc du Serengeti a disparu à cause de la maladie.L’infection se produit principalement par contact rapproché, dit « nez-à-nez », et par l'exposition des muqueuses nasales, buccales et oculaires à un aérosol de gouttelettes contenant des particules infectantes.
Transporté par les macrophages à l'intérieur desquels il se réplique, le virus colonise la rate, le thymus et la moelle osseuse.
En l'absence de protection immunitaire, le virus colonise l'épithélium des organes respiratoires, digestifs et nerveux, déclenchant une symptomatologie caractéristique et un taux de mortalité élevé, surtout si d'autres agents opportunistes (bactériens, viraux, parasitaires) viennent compliquer l'infection.Ce virus étant la première cause de décès chez les ratons laveurs en Ontario, il a fait l'objet d'une étude plus approfondie, qui a mis en évidence des souches virales sauvage génétiquement distinctes des souches vaccinales disponibles en Amérique du Nord, ce qui renforce l'intérêt de mieux comprendre l'écoépidémiologie de cette maladie.
A cette occasion, on a montré que tout le sud de l'Ontario est fortement touché par la maladie, et que les méthodes de surveillance (passive et passive renforcée) ont des résultats différents.
En 2020, on n'a pas encore identifié quels étaient les facteurs environnementaux de vulnérabilité au virus chez le Raton-laveur.Le virus de la maladie de Carré est un paramyxovirus de grande taille appartenant à la même famille que le virus de la rougeole et celui de la peste bovine.
Le virus ne présente qu'un seul type antigénique, mais il peut être plus ou moins pathogène.
Relativement fragile, il ne survit pas facilement dans l’environnement.
Il est détruit par les désinfectants usuels, ce qui permet une désinfection aisée des locaux contaminés, mais résiste à la congélation.Les lésions nerveuses se concentrent principalement sur le cervelet et les pédoncules cérébelleux.
Dans la forme classique on observe une nécrose neuronale, des manchons périvasculaires lymphoplasmocytaires (accumulation massive de lymphocytes et de plasmocytes dans les espaces péri-vasculaires), ainsi que des inclusions intranucléaires ou intracytoplasmiques dans les neurones et les astrocytes.
Dans la forme démyélinisée on observe une démyélinisation primaire engendrant une dégénérescence axonale.La maladie de Carré peut provoquer des signes cliniques peu marqués chez certains chiens, mais être mortelle chez d’autres, en particulier chez les chiots.
Après une période d'incubation qui peut durer de 3 à 10 jours, la maladie débute — en l'absence de réaction immunitaire — par une poussée de fièvre qui dure de 24 à 48 heures.
Après un retour à la normale qui peut durer de un à quatre jours, la température corporelle remonte et les symptômes caractéristiques apparaissent, ainsi que des surinfections associées,.L'état général se détériore et on observe parfois une kératite, une rétinite ou un épaississement cutané au niveau de la truffe et des coussinets (hyperkératose),.L'animal infecté peut vaincre la maladie, dont les symptômes disparaissent alors après une évolution discrète.
Si la maladie se prolonge, des symptômes neurologiques peuvent apparaître, variables selon la partie du système nerveux atteinte.
De ce fait, les animaux qui survivent présentent parfois des séquelles neurologiques : chorée (caractéristique), crises convulsives, épilepsie, parésie postérieure,.La maladie de Carré peut être soupçonnée, chez un jeune chien (de 4-5 mois à un an), au vu d'un historique vaccinal lacunaire associé aux symptômes caractéristiques de la maladie.
L'automne et l'hiver sont des saisons plus propices.Du fait d'un tableau clinique très varié et d'une expression parfois atypique, des analyses de laboratoire (PCR) sont souvent nécessaires pour confirmer le diagnostic.Un traitement symptomatique, des antibiotiques et des perfusions peuvent être utiles pour lutter contre les surinfections et compenser les pertes dues aux vomissements et aux diarrhées, il n’existe pas de traitement spécifique pour la maladie de Carré ; la meilleure protection contre le virus reste la vaccination,.La maladie de Carré est une maladie virale très contagieuse.
Dans certains pays, comme en Finlande, elle tue encore de nombreux chiens.
Il existe pourtant un vaccin efficace qui induit une réponse immunitaire adaptative et une mémoire immunitaire.
La vaccination a permis de réduire considérablement l’incidence de la maladie, mais il existe toujours des zones où l’infection persiste, en particulier dans les grandes villes, où les chiens non vaccinés sont nombreux.
Les chiots nés de mère vaccinée disposent d’anticorps d’origine maternelle qui les protègent de l’infection pendant les premières semaines de vie.
Le danger survient lorsque le niveau d’anticorps maternels diminue.
À ce moment-là le chiot doit être vacciné.
Le protocole requiert une primo-vaccination comprenant deux injections effectuées à un mois d'intervalle, la première sur le chiot âgé de 7 à 8 semaines.
Un rappel annuel ou triennal (selon les vaccins) est ensuite recommandé.En France, la loi du 22 juin 1989 classe la maladie de Carré parmi les vices rédhibitoires chez le chien.
Une étude cas-témoins est une étude statistique observationnelle rétrospective utilisée en épidémiologie.
Les études cas-témoins sont utilisées pour mettre en évidence des facteurs qui peuvent contribuer à l'apparition d'une maladie en comparant des sujets qui ont cette maladie (les cas) avec des sujets qui n'ont pas la maladie mais qui sont similaires par ailleurs (les témoins).
Les études cas-témoins posent donc la question : Y a-t-il plus de gens exposés à un facteur (par exemple plus de fumeurs) chez les cas que chez les témoins ?Les études cas-témoins sont des études qui sont relativement peu onéreuses et faciles à mettre en place.
L'un des succès les plus significatifs de l'étude cas-témoins a été de démontrer le lien entre le tabagisme et le cancer du poumon.
Sir Richard Doll a été capable de montrer une association statistiquement significative entre les deux.
Les opposants ont notamment fait valoir, à juste titre, pendant de nombreuses années que ce type d'étude seul ne peut prouver un lien de causalité, mais les résultats des études de cohorte ont confirmé ce lien de causalité.
Il est maintenant admis que le tabagisme est responsable d'environ 87 % de la mortalité par cancer du poumon en France et 88 % aux États-Unis.L'une des premières études cas-témoins connue fut publiée en 1926 par Janet Lane-Claypon dans son étude intitulée A Further Report on Cancer of the Breast with Special Reference to its Associated Antecedent Conditions.
Reports on Public Health and Medical Subjects.L'échantillonnage est basé sur une variable de « sortie » : la maladie.
L'étude ne commence que quand la maladie est déjà déclarée.
On décide alors de regarder l'historique du malade.
Un groupe de personnes atteintes d'une maladie (cas) est comparé à un groupe de sujets qui n'ont pas la maladie étudiée (témoins).
Le but est la recherche d'un ou des facteurs d'exposition antérieurs à la maladie susceptibles de pouvoir l'expliquer.
Ce type d'étude sert donc à tester une hypothèse spécifique avec une association d'un facteur de risque.
S'il n'y a pas d'hypothèse, un ensemble de variables est étudié pour identifier la meilleure association « risque-maladie » (Analyse discriminante).L'étude cas-témoins est un précieux outil d'enquête qui donne des résultats rapides à faible coût, mais ces résultats devront être confirmés par d'autres études fournissant des preuves plus solides.On a réussi à démontrer (ou on n'a pas réussi à démontrer) qu'il y a plus de cas qui ont été exposés à une substance X que de témoins.
Une plante génétiquement modifiée (PGM) est un cultivar de plante dont le patrimoine génétique a été modifié par l'Homme.
Une plante transgénique est une plante dans le génome de laquelle a été introduit par transgénèse du méristème radiculaire et foliaire un ou plusieurs gènes.
En recherche fondamentale, la production de plantes génétiquement modifiées est un outil de base pour la compréhension des mécanismes cellulaires.
En agronomie, les plantes génétiquement modifiées représentent une des dernières évolutions des méthodes d'amélioration des plantes.
Dans de nombreux cas, l'objectif est d'introduire un nouveau trait non présent dans cette espèce préalablement.Comme pour la définition générale d'un organisme génétiquement modifié, la définition d'une PGM varie entre l'aspect sémantique et la définition légale.
Si la locution « plante génétiquement modifiée » implique toutes formes de modifications génétiques, les définitions légales sont généralement plus restrictives.
La principale variation de définition significative pour les plantes est l'exclusion de la méthode de la fusion cellulaire comme une méthode créant une PGM.
En effet, l'exclusion de cette méthode entraîne que de nouvelles variétés portant pourtant le même trait original soient considérées différemment du point de vue de la réglementation en matière d'OGM.Les techniques d'élaboration des PGM se fondent sur quatre étapes.
La première étape consiste à identifier un gène d'intérêt chez un organisme donneur (bactérie, plante...), puis à l'isoler et à l'intégrer dans une construction génétique (vecteur) associé le plus souvent à un marqueur de sélection qui permet de sélectionner les cellules qui ont intégré le gène d'intérêt.
Cette construction génétique est ensuite clonée afin d'en disposer en quantité suffisante.
La seconde étape consiste à transférer le gène d'intérêt dans les cellules végétales.
Pour cela, deux méthodes sont possibles.
On peut tout d'abord utiliser une bactérie du sol, Agrobacterium, qui a la capacité naturelle de réaliser la transformation génétique ; c'est-à-dire qu'elle peut intégrer dans le génome de la cellule qu'elle contamine une construction génétique contenant le gène d'intérêt.
Cette construction génétique sera auparavant introduite dans la bactérie.
Cette technique est la plus couramment utilisée.
La seconde technique nommée transfert direct se fait soit par projection d'ADN, soit par électroporation.
La projection d'ADN se fait à l'aide d'un canon à particules qui permet de projeter dans les cellules des microparticules (de tungstène ou d'or) enrobées d'ADN.
L'électroporation est une technique visant à fragiliser la membrane plasmique de protoplastes par un choc électrique afin que le gène d'intérêt puisse pénétrer dans la cellule.Une fois le gène transféré, la troisième étape vise à sélectionner les cellules transformées par un test détectant la présence ou non d'un marqueur de sélection.
Les cellules sélectionnées sont régénérées pour permettre le développement de plantules qui sont ensuite repiquées en pot.
Des analyses moléculaires sur les plantes régénérées permettent de déterminer le niveau d'expression du gène incorporé.
Si ce niveau est satisfaisant, on réalise la quatrième étape qui consiste à incorporer le gène d'intérêt dans une variété commerciale.
Pour cela, on réalise des croisements entre les plantes transformées et les variétés commerciales.
On sélectionne alors dans la descendance les plantes possédant le caractère désiré et on les croise de nouveau avec des plants de la variété commerciale (rétrocroisement).
On répète ce processus de nombreuses fois et ce afin d'obtenir une lignée quasiment isogénique de la variété commerciale possédant le gène d'intérêt.La résistance aux antibiotiques est le premier trait transféré à une plante, ou plus précisément à une cellule de plante.
En 1983, trois groupes de recherche indépendants ont obtenu des cultures cellulaires stables de pétunia, tabac, tournesol et carotte résistantes à divers antibiotiques.
La même année, Ken Barton et Mary-Dell Chilton, d'un côté, et Patty Zambryski, Marc Van Montagu et Jeff Schell, d'un autre, arrivent à régénérer des plants complets de tabacs résistants à partir de culture cellulaire ou de cals.Des gènes de résistance aux antibiotiques comme le gène Néomycine phosphotransférase sont introduits dans les cellules.
L'action d'un antibiotique permet d'inhiber la croissance des cellules non modifiées et réalise ainsi la sélection des cellules génétiquement modifiées.Les plantes rendues résistantes aux herbicides sont parmi les plus connues du grand public, en 2011 du maïs, du soja, du coton, du colza, de la betterave sucrière et du lin (et même du gazon, le pâturin des prés ou Kentucky Blue ) sont  génétiquement modifiés pour résister à une molécule contenu dans des herbicides totaux, le glyphosate, commercialisé par Monsanto sous le nom de RoundUp Ready.Cela peut poser un problème lorsque le gène de résistance se dissémine à d'autres plantes, notamment celles considérées comme mauvaises herbes (ou adventices), ce qui a notamment été le cas en culture de coton GM aux États-Unis, la résistance se diffusant à l'amaranthe de Palmer (où les effets furent désastreux en Géorgie) .Cette résistance est conférée aux plantes par des gènes codant une forme tronquée de protéines endotoxines, fabriquées par certaines souches de Bacillus thuringiensis (bactéries vivant dans le sol ; d'où le nom de maïs Bt).
Il existe de multiples toxines, actives sur différents types de larves d'insectes issues de cette souche bactérienne, reconnues depuis de longues années pour leurs propriétés insecticides utilisés en agriculture biologique ou conventionnelle.
Plusieurs espèces ont été transformées avec un gène de résistance à un ravageur.
Certaines sont commercialisées comme: le maïs, le coton, la tomate, la pomme de terre  et d'autres sont à l'essai notamment le riz et l'aubergine,.
Le maïs est la première des espèces résistantes à un ravageur à être commercialisée.
Le maïs Bt qui présente une résistance aux lépidoptères, tels que la pyrale du maïs (Ostrinia nubilalis), porte un ou plusieurs gènes de type Cry1(A).Le cotonnier Bt est autorisé à la commercialisation depuis 1996 et est cultivé dans de nombreux pays.En 2009, la Chine a émis des certificats de biosécurité pour du riz Bt.En 2009, une recommandation de commercialisation a été délivré par les autorités indiennes.L'impact de la sécheresse sur les rendements d’une culture dépend de nombreux facteurs.
L'insertion de gène permettrait une meilleure tolérance à la dessiccation et donc de maintenir des rendements en période de sécheresse.
Monsanto a réalisé dès 2009 ses premiers essais en champs avec un maïs contenant le gène CspB pour Cold Shock Protein B. Ce gène code une protéine chaperonne du même nom.
Ce gène est associé à un promoteur spécifique permettant une activation du gène qu’en cas de dessiccation.
Cette protéine permet de stabiliser les ARNm, de maintenir le niveau de transcription et donc la photosynthèse.
D’autres essais sont aujourd’hui réalisés sur d’autres espèces, notamment le blé.À ce jour, aucune PGM dite « tolérante à la sécheresse » n'a dépassé le stade de l'essai expérimental.En acceptant le chiffre de 181 millions d'hectares cultivés en OGM (fournis par l'industrie, via l'ISAAA), cela représente un peu plus de 10 % des terres cultivées, estimées par l'ONU à 1,5 milliard d'hectares .
Le génie génétique est l'ensemble des outils permettant de modifier la constitution génétique d'un organisme en supprimant, en introduisant ou en remplaçant de l'ADN.Celui-ci peut être introduit directement dans les cellules de l'organisme hôte ou dans des cellules cultivées ex vivo puis réintroduites dans l'organisme.
Un prérequis au développement du génie génétique a été la mise au point de techniques recombinantes d'acide nucléique pour former de nouvelles combinaisons de matériel génétique héritable suivies de l'incorporation de ce matériel soit indirectement à travers un système vecteur ou directement par micro-injection, macro-injection ou micro-encapsulation.Il a souvent pour but la modification des génotypes, et donc des phénotypes.Le génie génétique est un champ très actif de la recherche car les applications possibles sont multiples, notamment en santé humaine (correction d’un gène porteur d’une mutation délétère, production de protéines thérapeutiques, élimination de séquences virales persistantes, etc.), en agriculture biotechnologique (mise au point de nouvelles générations de plantes génétiquement modifiées, etc.) ou encore pour la mise au point d’outils destinés à la recherche (par exemple pour explorer la fonction d’un gène).À la suite du développement exponentiel du génie génétique, une nouvelle discipline est apparue dans les années 1960, la bioéthique, qui vise à sensibiliser les chercheurs, mais aussi les politiciens et le grand public, à la nécessité d'introduire systématiquement une dimension éthique dès la phase de recherches (principe de précaution).Au début du XXe, la redécouverte des travaux de Mendel (1822-1888) et les travaux de Morgan (1866-1945) sur la mouche drosophile permettent de comprendre que l'hérédité est due à la transmission de particules appelés gènes, disposés de manière linéaire sur les chromosomes.
Dans les années 1950, est mise en évidence la nature chimique des gènes, ainsi que la structure moléculaire de l'ADN.
En 1965, découverte des enzymes de restriction confirmée en 1973 par Paul Berg et ses collaborateurs.
Ces protéines capables de découper et recoller précisément l’ADN, donnent aux chercheurs les outils qui leur manquaient pour établir une cartographie du génome.
Elle ouvre aussi la voie à la transgénèse, qui permet d'intervenir in vitro sur des portions d'ADN et donc des gènes.
La technologie de l'ADN recombinant permet l'insertion d'une portion d'ADN (un ou plusieurs gènes) dans un autre ADN.Chez certains organismes, les technologies mises au point pour introduire un gène dans la cellule vivante restent cependant limitées par le caractère aléatoire de l’insertion de la nouvelle séquence dans le génome.
Positionné aléatoirement, le nouveau gène peut inactiver ou perturber le fonctionnement de gènes tiers, ou même être à l’origine d’effets indésirables graves comme le déclenchement d’un processus de cancérisation.
Les technologies d'insertion non ciblées ne permettent pas d’obtenir de reproductibilité de l’expérience : il n’y a pas de garantie que la nouvelle séquence soit insérée toujours au même endroit.Depuis la fin des années 1990, une nouvelle génération de technologies, capitalise sur des connaissances et des technologies plus récentes, comme les nucléases programmables (ZNFs, TALENs et CRISPR).
Elles permettent d’intervenir sur une zone spécifique de l’ADN afin d’accroître la précision de la correction ou de l’insertion pratiquée, de prévenir ainsi les toxicités cellulaires et d’offrir une reproductibilité fiable de l'intervention.Ces nouvelles technologies d'ingénierie génomique, avec la génomique synthétique (conception de génomes artificiels), figurent actuellement parmi les technologies les plus prometteuses en termes de recherche biologique appliquée et d’innovation industrielle.La production d’OGM permet d’introduire dans le génome d’un être vivant de nouveaux gènes, par insertion de portions d’ADN, ou de supprimer ou modifier certains gènes présents.
Ces modifications font appel à divers outils du génie génétique, notamment la transgénèse et plus récemment des nucléases programmables (plus particulièrement l'outil CRISPR).Le génie génétique constitue l'une des principales avancées scientifiques du XXe siècle.
Il présente en effet un fort potentiel de développement.
Toutefois, les possibilités d'application qu'il offre dans la recherche biomédicale suscitent autant de craintes que d'espoirs.
Raison pour laquelle une nouvelle discipline est apparue dans les années 1960, la bioéthique, qui vise à sensibiliser les chercheurs, mais aussi les politiciens et le grand public, à la nécessité d'introduire systématiquement une dimension éthique dès la phase des recherches.En 2015, l'Académie nationale de médecine des États-Unis a organisé un sommet international pour attirer l'attention sur les risques du génie génétique comme, plus important pour les organisateurs, l'eugénisme.
Un autre risque est l'incertitude des effets du génie génétique: compte tenu de la complexité du génome humain et l'interdépendance entre tous les gènes différents, la modification d'un gène singulier influencerait aussi des autres parties du génome.
Cependant pour la première fois des bébés dit OGM ont vu le jour en Chine, en effet grâce à la technologie CRISPR-Cas9 qui est une nouvelle innovation médicale mis au point en 2012 par la française Emmanuelle Charpentier et l'Américaine Jennifer Doudna.
Le chercheur Chinois He Jiankui l’a utilisé afin d'éviter que les jumelles Lulu et Nana ne soient pas porteuses du VIH.
La nouvelle technologie Cas9 permet de sectionner certains gènes cependant cela n’avait encore jamais été tenté sur des embryons destinés à rester en vie.Biologiste québécois, Jean-François Gariépy, avertit que le génie génétique pourrait mener au remplacement des mécanismes actuels de la reproduction humaine.
Dans la monographie Le phénotype révolutionnaire (The revolutionary phenotype), Gariépy base cette théorie sur l'hypothèse du monde à ARN où l'ARN a été remplacé par l'ADN comme réplicateur dominant dans le monde.
Si l'humanité choisissait ce chemin, la conséquence, en longue terme, serait la transformation radicale de toute société humaine conforme aux intérêts des forces manipulant le processus du génie génétique,La transgénèse consiste à introduire un ADN exogène dans le génome d'un organisme soit au moyen d'un virus ou d'une bactérie soit par introduction de l'ADN par des méthodes physico-chimiques (électroporation, transfection ou micro-injection).
La première souris transgénique a été créée par le biologiste Rudolf Jaenisch en 1974.
Les premières plantes transgéniques sont créées en 1984 en utilisant Agrobacterium tumefaciens comme vecteur d'ADN exogène,.
Une limitation importante des approches de transgenèse est que le matériel génétique exogène est inséré de façon aléatoire.
L'insertion, lorsqu'elle a lieu à proximité d'un gène endogène peut entraîner un défaut d'expression de ce dernier.À la différence de la transgenèse, les approches de recombinaison homologue permettent d'introduire, d'enlever ou de remplacer du matériel génétique, et ce de façon très précise.
Ces approches reposent sur un mécanisme naturellement présent au sein des cellules permettant de réparer un ADN endommagé en utilisant comme modèle une séquence homologue située sur un autre brin.Il est possible d’induire des recombinaisons homologues entre l’ADN naturel d’une cellule et d'un ADN exogène introduit par les chercheurs, en utilisant comme vecteur le génome modifié d’un rétrovirus par exemple.
Le phénomène de recombinaison est suffisamment souple pour qu’il soit possible d'introduire un certain niveau de changement (ajout, suppression ou modification d’une portion d’ADN) au niveau de la zone d’homologie visée.Dès les années 1980, Mario R. Capecchi et Oliver Smithies ont travaillé sur la recombinaison homologue de l'ADN comme outil de « ciblage de gène », c’est-à-dire comme instrument d’inactivation ou de modification de gènes précis.
Avec la collaboration de Martin J. Evans, ils ont mis au point un procédé permettant de modifier le génome de souris en modifiant l’ADN de cellules souches embryonnaires murines en culture, et en injectant ces cellules souches modifiées dans des embryons de souris.
Les souris génétiquement modifiées ainsi générées permettent d’étudier des maladies humaines en laboratoire.
C’est aujourd'hui un outil couramment utilisé en recherche médicale.
Les travaux des trois chercheurs leur ont valu le Prix Nobel de physiologie ou médecine en 2007.Une limitation importante de l'approche de modification génétique par recombinaison homologue est sa très faible activité spontanée, hormis chez la levure et dans les cellules souches embryonnaires de souris qui font figure d'exception.
Ceci a fortement limité son application à d'autre organismes.
Or au milieu des années 1990, les équipes de Maria Jasin et Jean-François Nicolas démontrent qu'une cassure double-brin de l'ADN de cellules mammifères stimule très fortement la recombinaison homologue (qui est utilisée par la cellule afin de réparer la cassure),.
En outre, l'analyse des séquences d'ADN après réparation met en évidence l'action d'une seconde voie de réparation d'ADN, appelée jonction d'extrémités non homologues, qui conduit à la délétion ou à l'insertion de petites séquences d'ADN (typiquement de 1 à 20 nucléotides de long).
Ces observations ont donc conduit les chercheurs à développer des nucléases (enzymes coupant l'ADN) dont la séquence d'ADN cible peut être programmée.Les enzymes de restriction couramment utilisées en biologie moléculaire pour couper l’ADN interagissent avec des séquences constituées de 1 à 10 nucléotides.
Ces séquences, très courtes et souvent palindromiques, sont généralement présentes à plusieurs endroits du génome (le génome humain comprend 6,4 milliards de bases).
Les enzymes de restriction sont donc susceptibles de couper la molécule d’ADN à de multiples reprises.Pour pratiquer une chirurgie des génomes précise et sûre, les scientifiques se sont donc tournés vers des outils plus précis.
L’ingénierie ciblée des génomes est rendue possible par l’utilisation d’enzymes capables de reconnaître et d’interagir avec des séquences d’ADN suffisamment longues pour n’exister, en toute probabilité, qu’en un exemplaire unique dans un génome donné.
L’intervention sur l’ADN se produit alors précisément au niveau de la séquence ciblée.
Avec des sites de reconnaissance de plus de 12 paires de bases, les méganucléases, les nucléases à doigts de zinc, les TALENs et les systèmes CRISPR répondent à ces critères de spécificité.Une fois la coupure de l’ADN effectuée, les mécanismes naturels de réparation de l’ADN et la recombinaison homologue permettent d’incorporer une séquence modifiée ou un gène nouveau.Le succès de ces différentes étapes (reconnaissance, coupure, recombinaison) dépend de divers facteurs, parmi lesquels l’efficacité du vecteur qui introduit l’enzyme dans la cellule, l’activité enzymatique de coupure, les capacités cellulaires de recombinaison homologue et probablement l’état de la chromatine au locus considéré.Découvertes à la fin des années 1980, les méganucléases sont des enzymes de la famille des endonucléases qui présentent la caractéristique de reconnaître des séquences d’ADN de grande taille, de 12 à 40 paires de bases.
Parmi ces méganucléases, les protéines du groupe LAGLIDADG, qui doivent leur nom à une séquence d’acides aminés conservée, sont les plus nombreuses et les mieux connues.Ces enzymes ont été identifiées dès les années 1990 comme des outils prometteurs pour l’ingénierie des génomes.
Néanmoins, malgré leur diversité dans la nature, et même si chacune d’elles peut présenter de petites variations de son site de reconnaissance de l’ADN, il existe trop peu de chances de trouver la méganucléase adaptée à l’intervention sur une séquence d’ADN bien déterminée.
Chaque nouvelle cible d’ingénierie génomique nécessite ainsi une première phase d’ingénierie protéique afin de produire une méganucléase sur mesure.Les nucléases à doigt de zinc sont des enzymes de restrictions synthétiques créées en fusionnant des domaines à doigt de zinc avec des domaines de coupure de l'ADN.La combinaison de 6 à 8 doigts de zinc dont les domaines de reconnaissance ont été caractérisés, il est possible d’obtenir des protéines spécifiques de séquences d’une vingtaine de paires de bases.
On peut ainsi contrôler l’expression d’un gène spécifique.
Il a été montré que cette stratégie permet de promouvoir un processus d’angiogenèse chez l’animal.
Il est également possible de fusionner la protéine ainsi construite avec le domaine catalytique d’une endonucléase afin de provoquer une cassure ciblée de l’ADN et d’utiliser ces protéines comme outils d’ingénierie des génomes.Les nucléases à doigts de zinc sont des outils de recherche et développement qui ont déjà été utilisés pour modifier des génomes variés, notamment par les laboratoires fédérés dans le Zinc Finger Consortium.
L’entreprise américaine Sangamo Biosciences utilise les nucléases à doigts de zinc pour des travaux sur l’ingénierie génétique des cellules souches et la modification de cellules immunitaires à des fins thérapeutiques,.
Des lymphocytes T modifiés font actuellement l’objet d’essais cliniques de phase I, portant sur le traitement d’un cancer du cerveau (le glioblastome) et la lutte contre le SIDA.Les TALENs sont des enzymes de restriction artificielles générées par fusion d'un domaine de liaison à l'ADN appelé TALE et d'un domaine ayant la capacité de cliver l'ADN.Le domaine TALE de liaison à l'ADN est constitué de répétitions de 33 ou 34 acides aminés identiques à l'exception des acides aminés 12 et 13.
Ces deux derniers résidus confèrent à un module la capacité de reconnaître une base de l'ADN selon un code très simple,.
En assemblant ces modules dans l'ordre souhaité, il est très aisé de générer une protéine qui reconnaîtra une séquence spécifique du génome.
La fusion de ce domaine TALE avec un domaine de clivage de l'ADN permet d'induire très facilement des cassures double brin sur un gène souhaité.La rapidité pour la construction de telles enzymes et leur bas coût en font des outils excellents pour réaliser de l'ingénierie des génomes.Afin de légiférer sur ces nouvelles méthodes, les différents gouvernements ont créé la commission de génie génétique dissoute le 8 décembre 2008 et le Haut Conseil des biotechnologies créé en juin 2008.Selon l’article 18 du chapitre 5 de la convention pour la protection des droits de l'homme et de la biomédecine, lorsque la recherche sur les embryons in vitro est admise par la loi, celle-ci assure une protection adéquate de l'embryon.
La constitution d'embryons humains aux fins de recherche est interdite.Les modifications effectuées par le chercheur He jiankui sont donc illégales selon la convention d’oviedo de 1997 .En novembre 2018, deux jumelles chinoises chez lesquelles une mutation censée les préserver du VIH a été introduite grâce à la technique d’édition des génomes dite CRISPR-Cas9 ont vu le jour.
Cet évènement a mis en évidence l’absence de consensus international et les divergences de pratiques des États quant à l’utilisation de la technique CRISPR sur l’homme, l’encadrement de la recherche ayant un caractère essentiellement national.CRISPR-Cas9, ou plus simplement CRISPR, est une technique d’ingénierie de l’ADN qui permet d’ajouter, de modifier ou de supprimer une séquence spécifique du génome d’un être vivant, bactérie, plante ou animal.
Contrairement aux techniques précédentes complexes à mettre en œuvre, CRISPR-Cas9 est facile à utiliser.
Elle est aussi plus précise, plus fiable et moins coûteuse.Chez l’humain, la technique CRISPR peut être utilisée tant pour modifier les cellules de l’embryon que celles d’un individu adulte.
L’intervention peut porter sur ce que l’on appelle les cellules-souches, sources de toutes les autres.
D’abord, les cellules souches germinales, reproductrices, que l’on appelle aussi gamètes (spermatozoïdes et ovules), ainsi que les cellules présentes chez le zygote (embryon aux premiers stade de développement).
Puis, les cellules souches somatiques, soit les autres cellules du corps.
Toute modification des gamètes sera transmise à la descendance, alors que la modification d’un gène sur une cellule somatique ne concernera que le seul humain soumis au traitement.
Dans le domaine médical et vétérinaire, un adjuvant immunologique (appelé aussi adjuvant vaccinal, immunoactivateur, immunoadjuvant, immunopotentialisateur, immunostimulant) ou immunomodulateur (ce terme est plus précis que celui d'adjuvant car une même substance peut, selon le sujet, les doses, l'antigène et le moment où elle est administrée, provoquer une immunostimulation ou une immunosuppression) est une substance qui — quand elle est administrée (avalée, inhalée, injectée, etc.) conjointement avec un antigène — stimule, active, prolonge, renforce ou module le système immunitaire, bien que cette substance n'ait pas elle-même et en soi de vertu antigénique,.Par rapport aux adjuvants stricto-sensu, les immunostimulants ont une action plus générale sur le système immunitaire et peuvent modifier simultanément plusieurs réponses immunologiques.C'est Gaston Ramon qui, en 1925, « instaure le principe des substances adjuvantes et stimulantes de l'immunité, technique qui permet d'obtenir des sérums plus riches en antitoxines en joignant au vaccin une substance irritante pour les tissus ».Divers adjuvants sont ainsi couramment utilisés par les fabricants de vaccins pour « surstimuler » le système immunitaire, afin d'augmenter la réponse à un vaccin.
Dans le cas des vaccins, la notion d'adjuvant immunologique recouvre toute substance ajoutée pour accélérer, prolonger ou renforcer la réponse immune spécifique induite par le vaccin (réponse orientée vers l'antigène ciblé par le vaccin) quand il est utilisé conjointement avec cet adjuvant.Employé de 1911 à 1920 à Garches, à l'immunisation des chevaux et la collecte chez ces animaux de différents sérums, le biologiste Gaston Ramon fait une observation qui lui sera utile plus tard : chez certains chevaux fournisseurs de sérum antidiphtérique il y avait une corrélation entre la présence de réactions inflammatoires au point d'injection de l'antigène et l'augmentation du taux de l'antitoxine dans le sérum.
Quand, avec la réaction de floculation, il disposera d'un procédé commode et rapide de dosage in vitro de l'antitoxine il sera à même de quantifier cette augmentation.En 1923, Gaston Ramon démontre que la toxine diphtérique qui a subi l'action simultanée d'une petite quantité de formol et de la chaleur, se transforme en un dérivé inoffensif mais conserve intact son pouvoir vaccinant.
Il donne le nom d'« anatoxine diphtérique » à cette toxine inactivée.
Or cette anatoxine est un produit chimiquement très pur qui a un pouvoir vaccinal limité.
En 1924 il conceptualise la notion d'adjuvant.
En 1925, il lui trouve un adjuvant : l'addition de pus à cette anatoxine augmente chez les chevaux la production d'anticorps.
Il instaure ainsi le principe des substances adjuvantes et stimulantes de l'immunité, technique qui permet d'obtenir des sérums plus riches en antitoxines en joignant au vaccin une substance irritante pour les tissus.En 1926, Alexander Thomas Glenny (1882-1965) montre les propriétés adjuvantes de l'alun.
Il complète cette étude en 1931.Dès 1927, différentes substances sont testées en tant qu'adjuvant pour leur pouvoir immunostimulant : mie de pain, tapioca, aluminium (sous forme d'un sel : hydroxyde ou phosphate).
En 1937, remarquant que des animaux infectés par la tuberculose avaient parfois des réactions marquées lors d'une vaccination subséquente, Jules T. Freund a l'idée de se servir de la bactérie tuberculeuse mélangée à une émulsion comme d'un adjuvant : cet adjuvant de Freund — alors sous sa forme dite complète — (émulsion d’eau, d’huiles, d’émulsifiants et de morceaux de bactéries tuées) se révèle très puissant mais donne des réactions locales très fortes.L'institut Pasteur a aussi utilisé un adjuvant qui est le phosphate de calcium (substance naturellement présente dans le corps), abandonné dans les années 1990 après sa fusion avec le groupe Mérieux.Dans les années 1940 on distingue deux familles d'adjuvants, ceux à base d'alun, et ceux plus récemment développés à base d'émulsions huileuses.
Les années 1940 à 1970 verront la généralisation et la mise au point de ces deux familles d'adjuvants et la mise à jour de leurs limites.
Par exemple l'alun n'accroît pas de réponse immune pour la diphtérie ou le tétanos tandis qu'il induit une augmentation d'immunoglobuline E potentiellement allergénique.
Au début des années 1980, l'alun était toutefois encore l'adjuvant le plus utilisé en médecine humaine.
Pour ce qui est de l'adjuvant de Freund, c'est la mise au point par Jonas Salk d'huile et d'émulsifiant purifiés qui permit son utilisation dans de vastes essais cliniques, notamment dans le cadre du développement du vaccin contre la grippe puis à la suite du vaccin polio.
Dès lors, l'adjuvant de Freund devint une référence.
Dans les années 1950 et 1960 toutefois la mise en évidence d'inflammations intenses et de lésions granulomateuses amoindriront l'intérêt de cet adjuvant.
Mais c'est surtout la découverte que les huiles minérales, potentiellement carcinogènes, étaient incomplètement métabolisées qui en freineront le développement : l'adjuvant dans sa forme incomplète (IFA) n'obtint pas d'AMM, tandis que l'intérêt pour les adjuvants en général s'en trouva singulièrement affecté.
C'est alors qu'Hilleman et ses collaborateurs de chez Merck met au point l'Adjuvant 65 composé d'huile d'arachide.
Cet adjuvant est présenté comme aussi immunostimulant que celui de Freund bien qu'une étude britannique avec un vaccin contre la grippe montrât le contraire.
Les études de sécurité menées sur dix ans ayant montré l'induction de cancer chez les souris par l’Arlacel A, l’Adjuvant 65 ne put être autorisé.
Cela porta un coup d'arrêt au développement d'adjuvants huileux, qui réapparurent dans les années 1990 avec les produits développés par la société Seppic.Les saponines, dont les propriétés adjuvantes ont été mises en évidence par Ramon, sont redécouvertes lorsqu'elles s'avèrent utiles au vaccin contre la fièvre aphteuse.
Mais c'est après la découverte des propriétés de Quillaja saponaria d'abord et de celles de sa forme purifiée Quil A que les saponines trouvent à être largement utilisées.L'emploi des adjuvants progresse dans la seconde moitié du XXe siècle en raison de son intérêt industriel (les épidémies nécessitent de pouvoir servir un très grand nombre de personnes dans des temps assez courts) et économique (les adjuvants permettent de faire baisser le prix de revient d'un vaccin dont le coût principal est la production des antigènes).La controverse sur la vaccination à la fin du XXe siècle s'est portée également sur certains adjuvants, notamment sur l'innocuité de l'aluminium.Ces substances sont des adjuvants (médicamenteux ou vaccinaux) qui agissent au niveau humoral et/ou cellulaire, avec deux modes d'action possibles (selon la molécule utilisée) :L'inoculation dans un organisme d'un de ces « motifs moléculaires » par une voie anormale (exemples : piqûre, blessure, morsure), puis sa détection par le système immunitaire suffisent à activer certains processus immunitaires qui semblent — si la dose est suffisante, mais non excessive — renforcer l'efficacité vaccinale, la juste dose pouvant varier selon les individus, leur âge et d'autres facteurs encore mal appréciés.Il existe aussi une controverse à propos de l'innocuité de certains de ces motifs moléculaires associés aux pathogènes, ou quant aux risques de problèmes auto-immuns pouvant être induits par ce type de thérapie.L'efficacité thérapeutique de beaucoup de modificateurs biologiques de réponse est liée à leur caractère immunoadjuvant antigène-spécifique.Ce sont surtout les vaccins inactivés qui ont besoin de tels adjuvants.
Alors que certains vaccins sont suffisamment efficaces pour ne pas avoir besoin d'adjuvant (rougeole, rubéole), d'autres provoquent une réponse immunitaire insuffisante (vaccin contre l'hépatite B, contre la coqueluche) et ont besoin d'adjuvants.De nombreuses substances endogènes sont des immunostimulants non spécifiques.Par exemple, les hormones sexuelles féminines sont connues pour à la fois stimuler une réponse adaptative et une réponse immunitaire innée,,,.Certaines maladies auto-immunes comme le lupus érythémateux (qui touche plus souvent les femmes) apparaissent souvent à la puberté quand le corps est soumis à de nouvelles poussées hormonales.D'autres hormones semblent « réguler » le système immunitaire dont la prolactine, l'hormone de croissance et la vitamine D,.Certaines publications pointent un effet immunostimulant du DCA, en particulier concernant l'immunité dirigée contre certains cancers,, via une activation du système immunitaire non spécifique et l'activation de ses principaux acteurs, les macrophages.
Selon les auteurs de ces articles, une quantité suffisante de DCA dans le corps humain serait signe de bonne santé du système immunitaire non spécifique.Ces produits sont utilisés comme :Les vaccins contenant un adjuvant huileux sont largement répandus en médecine vétérinaire principalement pour les porcs et pour la volaille et occasionnellement aussi pour les chevaux et les petits animaux.Il existe de multiples classifications des adjuvants notamment en fonction de leur mode d’action et de leurs effets sur la réponse immune, ce qui s'avère toutefois arbitraire et compliqué.
Les adjuvants possédant souvent plusieurs propriétés, d'ailleurs imparfaitement connues, le classement le plus simple se faits sur la base de leur espèce chimique et de leur origine.On peut distinguer parmi les adjuvants les agents qui ont une stricte fonction d'immunostimulation  de ceux qui sont utilisés afin de contenir l’antigène et qui déterminent la façon dont celui-ci sera présenté au système immunitaire.
Ces adjuvants qualifiés de « véhicules » ont toutefois souvent des propriétés d'immunostimulation.La médecine humaine ou vétérinaire utilise classiquement des antigènes bactériens.Toxines : streptolysine, staphylocoagulase, ...En 1964, Hilleman développa, pour le compte de Merck & Co., l’Adjuvant 65 qui fut ensuite abandonné.
Les adjuvants huileux nécessitent eux-mêmes l'adjonction d'un émulsifiant, comme l'Arlacel A (monooléate de mannitol), Arlacel 80 (monooléate de sorbitol), Span 80 (ND), Span 20 (ND) ou Montanide (ND).
Un stabilisant, comme le monostéarate d'aluminium, peut être également nécessaire.Si les doses sont excessives ou trop fréquentes, des maladies ou réactions auto-immunes semblent pouvoir être déclenchées chez certains patients.
Une association entre la myofasciite à macrophages et l'aluminium utilisé comme substrat pour la préparation de certains vaccins est ainsi établie,.
Le réseau Sentinelles est un réseau de recherche et de veille sanitaire en soins de premiers recours (médecine générale et pédiatrie) en France métropolitaine.
Créé en novembre 1984, il est développé sous la tutelle conjointe de l'Institut national de la santé et de la recherche médicale (Inserm) et de Sorbonne Université.
Les objectifs principaux du réseau Sentinelles sont : Au 1er janvier 2018, le réseau Sentinelles était composé de 1 314 médecins généralistes libéraux (soit 2,1% des médecins généralistes libéraux en France métropolitaine) et de 116 pédiatres libéraux (soit 4,3 % des pédiatres libéraux en France métropolitains), bénévoles et volontaires répartis sur le territoire métropolitain français.
Les praticiens membres sont dits « médecins sentinelles ».
Ce réseau, créé par le professeur ès-sciences Alain-Jacques Valleron, est animé par l'Institut Pierre Louis d'Epidémiologie et de Santé Publique (UMR-S 1136 Inserm - Sorbonne Université).Ce système national de surveillance permet le recueil, l'analyse, la prévision et la redistribution en temps réel de données épidémiologiques issues de l'activité des médecins généralistes libéraux.
Il s'intègre aux dispositifs de surveillance mis en place par Santé publique France (avis favorable de la CNIL no 471 393).Neuf indicateurs infectieux sont recueillis :Ainsi qu'un indicateur non infectieux :Pour la grippe, la gastro-entérite et la varicelle, cette surveillance permet de détecter, d'alerter précocement et de prévoir la survenue d'épidémies nationales et régionales.Les données relatives à la rougeole ont été recueillies entre 1984 et 2008 et celles relatives aux hépatites A, B et C entre 2000 et 2008.Les données, non nominatives, sont transmises par Internet par les médecins Sentinelles et alimentent une base de données (système d'information géographique).
Un bulletin hebdomadaire, SentiwebHebdo, est édité tous les mercredis sur le portail du réseau Sentinelles, www.sentiweb.fr, et diffusé par courrier électronique à plus de 10 000 abonnés ainsi qu'aux grands médias nationaux.
Un Bilan Annuel est également édité avec l'ensemble des données, puis mis en ligne sur le site Internet dans la section « documentation/bilans annuels ».Les données issues du réseau Sentinelles permettent d'élaborer :Des enquêtes épidémiologiques ponctuelles sont réalisées auprès des médecins Sentinelles.
Elles sont effectuées dans le respect des bonnes pratiques d’épidémiologie éditées par l’Association des épidémiologistes de langue française (ADELF).
Elles ont toutes un numéro d’ordre inscrit sur un protocole écrit et font l’objet d’un rapport final d’étude.
Elles sont soumises aux procédures d’audit interne visant à assurer leur qualité et ont reçu un avis favorable de la CNIL (no 471 393).
Les résultats de ces enquêtes sont mis en ligne sur le site du réseau dans la section « documentation/enquêtes ponctuelles ».Antilles-Guyane :Le premier réseau de médecins généralistes sentinelles a été créé en Guadeloupe en 1983 suivi par ceux de la Martinique et de la Guyane.L’objectif de ces réseaux est la surveillance des pathologies considérées comme prioritaires notamment : la dengue, le chikungunya, le Zika, la grippe, la bronchiolite, la gastro-entérite aiguë, la varicelle et la conjonctivite,,.
En économie, on désigne par barrières à l'entrée les obstacles que doit surmonter une entreprise désirant se lancer sur un nouveau marché.
En économie, on désigne par barrières à l'entrée les obstacles que doit surmonter une entreprise désirant se lancer sur un nouveau marché.Les barrières à l'entrée peuvent être établies par les agents déjà en place sur le secteur, l'industrie en question ou par la réglementation.
Un agent établi du secteur a intérêt à ce que les barrières à l'entrée soient les plus grandes possibles, c'est-à-dire à ce qu'un concurrent ait du mal à configurer son organisation et à accéder à des ressources spécifiques ou aux canaux de distribution nécessaires pour entrer sur le marché.
En revanche, l'intérêt pour le consommateur est plutôt que les barrières à l'entrée soient faibles, afin de favoriser les nouveaux entrants et de stimuler la concurrence et la baisse des prix qui en résulte.On peut distinguer deux types de barrières à l'entrée : les barrières naturelles et artificielles.
Les barrières naturelles sont celles qui ne dépendent pas de la volonté des agents, comme des coûts fixes importants qui sont décourageants pour des entrants potentiels, ou comme des coûts de recherche-développement importants pour démarrer, par exemple dans l'industrie aéronautique ou la construction de centrales nucléaires.
Les barrières naturelles peuvent être constituées par la présence de coûts marginaux décroissants, lorsqu'un monopole naturel est présent.
Les barrières artificielles à l'entrée sont celles qui sont le produit d'une stratégie : des dépenses de publicité qui orientent les choix de consommation, des dépenses de marketing ou de développement de l'innovation de produit.Une question majeure est celle de la légitimité de ces barrières, et sur la nécessité de les supprimer ou de les réguler afin d'éviter les situation de monopoles : c'est le rôle de la politique de la concurrence, constitutive de la politique industrielle européenne et des lois anti trusts aux États-Unis.
La théorie des marchés contestables de William Baumol, souligne que les barrières à l'entrée (et à la sortie) sont les obstacles à la « contestabilité » du marché (existence d'une concurrence potentielle).
Autrement dit, la levée de ces obstacles suffit à rendre le marché du secteur concurrentiel, le modèle théorique optimal étant celui de la  concurrence pure et parfaite.Une barrière à la sortie peut également être vue comme une barrière à l'entrée : Une entreprise décidera de ne pas entrer sur un nouveau marché si elle considère qu'une sortie hypothétique de ce marché génère des coûts indésirables.
: document utilisé comme source pour la rédaction de cet article.
Le vaccin contre la diphtérie est un vaccin destiné à prévenir la diphtérie, une maladie causée par une bactérie du genre Corynebacterium.
L'efficacité du vaccin est importante et ses effets secondaires sont le plus souvent sans gravité.
Il fait partie des vaccins recommandés tout au long de la vie.La diphtérie est une maladie toxi-infectieuse affectant essentiellement les voies respiratoires supérieures et la peau, pouvant entraîner une obstruction du larynx, des paralysies ou une myocardite.
Elle est causée par deux catégories de bactérie du genre Corynebacterium : Corynebacterium diphtheriae et Corynebacterium non diphtheriae (essentiellement Corynebacterium ulcerans).Le vaccin contre la diphtérie est composé d'une anatoxine.
On distingue les vaccins à concentration normale avec au moins 30 unités par dose, et les vaccins à concentration dite réduite avec au moins 2 unités par dose.
L'anatoxine est adsorbée sur sels d'aluminium.
Étant donné que le vaccin cible l'anatoxine, il immunise contre les effets de la diphtérie, mais pas contre l'infection,.
Les personnes vaccinées restent donc des porteurs potentiels de la maladie, bien qu'une certaine immunité de groupe inexpliquée soit induite,.En France, le vaccin est disponible uniquement sous forme combinée :Le vaccin est à administrer par voie intramusculaire.En France, la primo-vaccination recommandée des nourrissons se compose de deux injections à deux mois d'intervalle, aux âges de 2 et 4 mois, suivies d'un rappel à l'âge de 11 mois.
Les rappels ultérieurs recommandés sont aux âges de 6 ans puis entre 11 et 13 ans chez l'enfant.
Par la suite chez l'adulte, les vaccinations sont recommandées aux âges de 25 ans, 45 ans et 65 ans, puis tous les 10 ans.La primo-vaccination du nourrisson contre la diphtérie est obligatoire en France depuis la loi du 25 juin 1938 (modifiée le 24 novembre 1940 puis le 7 septembre 1948 et enfin le 12 août 1966).Le seuil de protection est un taux d'anticorps diphtériques supérieur à 0,1 UI/mL.
L'immunité conférée à partir de la deuxième injection persiste au moins 5 ans après le rappel chez l'enfant, avec un taux de conversion de 96 %.Les effets indésirables du vaccin contre la diphtérie sont dans l'ensemble bénins et transitoires.
Une douleur, un œdème et une rougeur du site d'injection sont courants.
Un nodule peut dans certains cas se former.
Parfois, un malaise, une céphalée ou une fièvre peuvent survenir.
Les réactions anaphylactiques graves ou neurologiques sont exceptionnelles.Le risque de réaction locale et fébrile grave augmente avec l'âge, et il est diminué par l'utilisation de vaccin à dose réduite.Le vaccin contre la diphtérie est contre-indiqué en cas d'hypersensibilité à un de ses composants, ou de troubles neurologiques survenus à la suite d'une précédente administration.
La vaccination doit être différée en cas d'affection aiguë, hors infection mineure.
Les leptospiroses sont des maladies infectieuses, de gravité variable, dues à des bactéries du genre Leptospira, ordre des spirochètes.Ce sont des anthropozoonoses, maladies communes aux humains et aux animaux (mammifères).
Les réservoirs principaux sont les rongeurs sauvages (porteurs sains), puis les chiens et les animaux de rente (porc, chevaux, bovins...).
Ces animaux excrètent les bactéries pathogènes dans leur urine, qui contamine le sol et les eaux, source directe ou indirecte des infections humaines (activités en eaux douces ou usées).
Il n'existe pas de transmission interhumaine.La maladie se retrouve partout dans le monde, plus souvent en zone tropicale humide.
En France métropolitaine, elle est relativement peu fréquente chez les humains (autour de 0,5 cas par cent mille habitants et par an), alors qu'en France d'outre-mer elle est beaucoup plus fréquente (jusqu'à 150 cas par cent mille habitants Nouvelle-Calédonie).La grande variété des signes cliniques, la diversité des organes touchés, l'absence ou la lenteur de biologie spécifique rendent le diagnostic difficile.
Il existe un traitement antibiotique efficace, y compris sur les formes graves.
La vaccination des humains n'est recommandée que pour des risques professionnels, au cas par cas.
Chez le chien, la vaccination contre la leptospirose fait en revanche partie des principales recommandées.La forme grave et humaine de la maladie a été décrite par le médecin allemand Adolf Weil en 1886 comme « une forme bruyante d'ictère flamboyant » (jaunisse intense), dans un article médical intitulé « Au sujet d’une maladie infectieuse caractéristique qui provoque splénomégalie, néphrite et ictère », d'où son ancien nom de maladie de Weil.Rétrospectivement, on peut penser à une infection par le sérovar icterohaemorragiae, qui donne les formes graves et complètes de la maladie.
Toutefois, au XXIe siècle, on ne considère plus qu'une forme clinique particulière corresponde à une forme type du leptospire en cause.
N'importe quelle forme clinique peut être due à n'importe quel sérovar ou sérotype, et tout type de sérovar peut être responsable d'une forme bénigne, sévère ou mortelle.
Le premier agent causal L. icterohaemorragiae a été découvert au Japon par Inada et Ido en 1914, qui reproduisent aussi l'atteinte hépatique chez le cobaye.
Presque simultanément, cette découverte est confirmée durant la Première Guerre mondiale sur les fronts de guerre par les Allemands, les Français (Auguste Pettit isole la souche Verdun), et les Britanniques (dans les Flandres).
En 1916, Costa et Troisier montrent que la maladie peut évoluer en atteinte méningée où l'ictère est absent (formes non ictériques).
En 1918, Martin et Pettit mettent au point un séro-diagnostic dont le principe est toujours utilisé de nos jours.Par la suite, de nombreuses autres bactéries proches, également responsables de troubles analogues, ont été découvertes.
Durant la première moitié du XXe siècle, chaque auteur a cru possible d'attribuer une forme clinique particulière à chaque découverte.
Ces variétés cliniques et bactériologiques, sans parallélisme strict et constant entre les deux, et selon les zones géographiques et les circonstances, expliquent la multitude de dénominations historiques des leptospiroses.
Par exemple, Nicolas Petrovitch Wassilieff ou Vassiliev (1852-1891), médecin-chef à Saint-Pétersbourg, traita également du sujet, d'où le nom de maladie de Vassiliev.
Près d'une centaine de dénominations ont été utilisées, parmi les plus connues : leptospirose canicolaire (L. canicola), fièvre des marais (L. grippo-typhosa), fièvre de 7 jours du Japon (L. hebdomadis), maladie des porchers ou des fruitières (L. pomona), fièvre de la canne à sucre (L. australis), fièvre automnale du Japon (L. autumnalis), fièvre de la ferme laitière ( L. Hardjobovis), etc.La biologiste française Berthe Kolochine-Erber, chef de laboratoire à l'Institut Pasteur, a mené pendant plus de 50 ans d'inlassables recherches sur les leptospires.Ces bactéries survivent très bien dans les milieux tels que la boue (la leptospirose comme cause possible des fièvres, ictères et néphrites dites des tranchées de la première guerre mondiale).
Selon Noguchi (1918) ce sont des parasites, qui ne peuvent pas se multiplier dans l'eau, elles meurent en 7 jours dans de l'eau distillée.
Buchanan (1927) en trouve en quantité considérable dans un biofilm boueux formé sur le plafond de galeries de mines ; Alston (1935) dans la vase des égouts.
Dans les années 1940, la question de l'unification ou de la dissociation des leptospiroses se pose.
En effet, un même germe peut provoquer chez l'homme deux affections différentes (ictère infectieux à rechute et une méningite aigüe) ; par ailleurs une même forme clinique peut être provoquée par deux leptospires différents.
Enfin sont répertoriés dans la nature des leptospires non pathogènes, tandis qu'on découvre que la leptospirose du chien due à L. canicola peut aussi toucher l'homme.
Une réponse sera de distinguer entre la leptospirose dite majeure (forme classique) et toutes les autres dites mineures.
À partir des années 1980 cet usage se perd.
La question se pose désormais en termes de génétique moléculaire (recherches toujours en cours).En 1915, le japonais Miyajima retrouve le leptospire d'Inada et Ido chez le rat, qui est alors considéré comme le réservoir des leptospires.
Après la Première Guerre mondiale, en Europe, 40 % des reins du rat gris Rattus norvegicus sont porteurs de leptospires virulents pour l'homme, seuls 8 % du rat noir Rattus rattus en portaient.
Les petits rongeurs apparaissent comme des porteurs sains.
Des études montrent qu'ils représentent 30 à 40 % de la population des rongeurs des villes ou des champs : au Japon, 39,5 % des campagnols Microtus montebelli , en Grande-Bretagne jusqu'à 41 % des rats, de même en Australie, avec le rat indigène Rattus culmorum.En 1931, Klarenbeek découvre L. canicola chez le chien.
De proche en proche, en étudiant des cas humains, on découvre de nouvelles contaminations par de nouveaux variants de leptospire et de nouveaux réservoirs : porc, bœuf, renard.., et on a d'abord cru que chaque leptospire avait son propre réservoir.
En fait, certains leptospires sont plus fréquemment associés à une espèce animale particulière, mais toutes les espèces de mammifères peuvent être infectées par tout leptospire pathogène.Le genre Leptospira (ordre des Spirochætales) comprend des espèces saprophytes, non pathogènes, qui vivent dans le sol et l'eau douce, et qui n'infestent pas les animaux (comme L. biflexa).
Au cours de l'évolution, des espèces ont divergé pour s'adapter aux tubules rénaux des mammifères, d'abord sans provoquer de maladies (micromammifères), puis en provoquant des leptospiroses (homme et animaux domestiques).
L'agent pathogène responsable de la leptospirose est la Leptospira interrogans.
En 2017, le genre Leptospira comprend 22 espèces, dont 10 pathogènes, et plus de 300 sérovars selon leurs antigènes de surface, répartis en 24 sérogroupes.
Les plus importants sérogroupes sont : icterohaemorragiae, canicola, pomona, australis, grippotyphosa, hyos, sejroe..
Cette diversité rend plus difficile la conception de vaccins efficaces contre l'ensemble des leptospiroses.La bactérie Leptospira mesure de 6 à 20 micromètres de long et 0,1 de diamètre.
Elle est aérobie et se cultive lentement à 27-30° sur des milieux spéciaux.
Elle se présente comme un filament spiralé, flexible, mobile, avec des extrémités en crochet, et un endoflagelle terminal fait d'une paire de flagelles périplasmatiques.
Cette structure lui assure mobilité et rapidité expliquant sa large diffusion tissulaire et à sa capacité d'échapper à certains mécanismes de défenses immunitaires comme la phagocytose.Depuis le début du XXIe siècle, une nouvelle classification basée sur le génome tend à se surajouter à la classification basée sur les antigènes.Le réservoir des Leptospira est principalement le rat et les rongeurs sauvages, puis le chien et le porc.
De nombreux autres mammifères peuvent être porteurs : ragondins, furets, renards, chevaux, bovins, porcins, chats.
Les rats sont le réservoir préférentiel de L. Icterohaemorrhagiae, les souris (Mus musculus) de L. Ballum, les campagnols de L. Grippotyphosa...
Les chauve-souris de L. Cynopteri et L. wollfi.
Généralement, les animaux infectés sont des porteurs sains qui hébergent des leptospires dans leurs tubules rénaux.
Durant leur vie entière, ces animaux éliminent des leptospires dans leurs urines en contaminant le sol et l'eau.Chez les animaux domestiques, le chien et le porc sont les plus sensibles, ils peuvent être porteurs ou malades, et transmettre indirectement la maladie à l'homme, comme la fièvre des porchers (L. Pomona).
L'homme et ses animaux domestiques apparaissent comme des hôtes accidentels, venant s'interposer dans un cycle sauvage naturel leptospires-micromammifères-sols humides.
Outre la transmission environnementale comme chez l'homme, il existe chez l'animal d'autres modes de transmission possibles : in utero (de la mère au fœtus), sexuelle, allaitement maternel.
Elle est due classiquement à Leptospira canicola, mais aussi à L. interrogans icterohæemorrhagiæ, L. Australis, L. pomona, L. grippotyphosa...
Les chiens s'infectent par voie cutanée ou muqueuse à partir de l'urine fraîchement émise par un autre chien.Le chien malade présente rapidement une fièvre accompagnée de violents vomissements, sous deux formes :Chez les chiens survivants, la maladie évolue vers des formes subaiguës ou chroniques (atteintes hépatiques ou rénales).
Il existe aussi des formes moins fréquentes (atteintes pulmonaires, oculaires, nerveuses, musculaires...).
Ces chiens, guéris ou pas, peuvent continuer d'excréter des leptospires dans les urines de façon prolongée (des mois à des années).Le traitement repose sur l'antibiothérapie.Il existe un vaccin vétérinaire, très utilisé pour les chiens, dirigé contre L. canicola et L. icterohæmorrhagiæ.
Toutefois cette vaccination n'empêche pas l'état de porteur sain, et ne protège pas forcément contre les autres leptospiroses.
Elle se fait annuellement chez le chien, voire tous les 6 mois chez les chiens exposés.
Ce vaccin peut être associé à d'autres : du bivalent (leptospirose et rage) jusqu'à l'hexavalent (contre 6 maladies du chien).
De nouveaux vaccins protègent contre jusqu'à quatre sérogroupes : L. interrogans canicola, L. interrogans icterohaemorrhagiae, L. interrogans australis et L. kirscheneri grippotyphosa.Chez les bovins et les ovins la leptospirose peut entrainer des pertes économiques pour l'éleveur (troubles de la reproduction du bétail, baisse de production de lait...).
En France, une étude de 2014 montre que les sérovars les plus fréquents à cette date, chez les chiens et les bovins, sont L. Australis et L. Grippotyphosa.
Les moutons sont le réservoir préférentiel de L. hardjo et L. Pomona.Chez les chevaux, la leptospirose se manifeste par des complications oculaires (inflammations).
C'est la plus répandue des anthropozoonoses, car elle est présente partout dans le monde (sauf en Antarctique).
Elle est plus fréquente en zone tropicale et subtropicale, en climat chaud et humide, les bactéries survivant plus longtemps dans l'eau boueuse tiède.
L'Asie est particulièrement touchée (Japon, Viet-Nam, Indonésie, Inde, Thaïlande).
En Afrique (Zaïre, Sénégal, Cameroun, Gabon...) cette maladie semble beaucoup plus répandue que diagnostiquée, et enfin en Amérique latine (Nicaragua, Salvador, Brésil...).
L'OMS estime le nombre mondial de cas annuels à plus de 800 000, dont 48 000 décès en 2013.En Europe occidentale, la France est le pays le plus touché.
L'incidence diagnostiquée en France métropolitaine est de l'ordre de 0,5 cas/100 000 habitants.
Les régions Nouvelle-Aquitaine et Île-de-France sont sur-représentées (50 % des cas), ce qui serait lié à leurs réseaux hydrographiques.
En 2014, 628 cas ont été recensés en métropole, soit 0,98 / 100 000, soit la plus forte incidence enregistrée.
Cette augmentation se retrouve dans d'autres pays européens.La maladie est plus fréquente dans les DOM-TOM : 12,5/100 000 habitants dans le cas de La Réunion, et, respectivement, 9,12 et 13 pour ce qui est de la Guyane, de la Martinique et de la Guadeloupe La Nouvelle-Calédonie accuse une incidence de 150/100 000 habitants, et la Polynésie, de 40/100 000 habitants.
En 2014, 761 cas ont été recensés outre-mer.Dans les pays développés, la maladie touche de sept à neuf hommes pour 1 femme, les cas pédiatriques sont rares.
Il s'agit principalement d'adultes, âgés en moyenne de quarante ans.
La différence s'explique par des activités professionnelles et de loisirs majoritairement masculines.
Les risques sont professionnels (travail en eau douce ou en eaux usées) et de loisirs, entre autres les loisirs internationaux (tourisme d'aventure, compétitions sportives en eau douce...).
Dans les climats tempérés, comme en France, on observe une augmentation des cas en été et en automne, mais la leptospirose peut s'observer tout au long de l'année.
La fréquence est augmentée par les pluies et les inondations.En France métropolitaine, la maladie est due aux loisirs aquatiques dans 75 % des cas : baignades en eau douce, sports nautiques (canoë-kayak, rafting, canyoning, etc.), spéléologie... par projection d'eau contaminée, pêche (blessure par hameçon).
Les professionnels sont exposés à plus de risques mais sont mieux protégés : vétérinaires, agriculteurs, employés des abattoirs, égoutiers, jardiniers..
Dans les pays pauvres, la maladie frappe des communautés rurales en zone humide (riziculteurs, pêcheurs en eau douce) et les quartiers misérables (taudis, égouts à ciel ouvert) des grandes villes.
Les leptospiroses semblent favorisées par le changement climatique (réchauffement), la déforestation, l'extension de l'irrigation, l'aquaculture, la création de lacs artificiels, et le développement des activités de loisirs en eau douce...
Tout ce qui fait la plus grande proximité des rongeurs avec l'homme et ses animaux domestiques en zone humide.La porte d'entrée est généralement cutanée ou muqueuse.
Une effraction cutanée favorise la pénétration du germe, de même qu'une peau saine ramollie par un séjour prolongé dans l'eau.
La contamination se fait par contact avec l'animal (morsure, léchage..) ou à partir d'une eau souillée par les urines ou les tissus morts d'un animal infecté.
La contamination par les muqueuses chez l'homme peut se faire par projection d'eau souillée dans la bouche, le nez ou les yeux (conjonctives).
Après leur pénétration cutanée ou muqueuse, les leptospires passent dans le sang et peuvent migrer dans tous les tissus.
La durée de l'incubation et la gravité de l'infection dépendent de la quantité de leptospires inoculant la maladie.
Plus cette quantité initiale est forte, plus l'incubation est courte et la maladie grave.
La phase septicémique est celle où les leptospires se multiplient dans le sang et lèsent les petits vaisseaux par vascularite (apparition d'une fièvre sévère avec douleurs diffuses), puis survient une phase tissulaire où les leptospires se fixent plus ou moins au niveau de certains organes (foie, rein, cerveau, cœur...), de façon variée et apparemment désordonnée, expliquant la difficulté du diagnostic clinique.L'atteinte rénale entraine une excrétion de leptospires par les urines, mais à un stade trop tardif pour servir d'aide au diagnostic.
La guérison entraine l'arrêt de cette élimination, il n'existe pas de porteur sain chez l'homme, ce dernier n'est pas en lui-même un réservoir de transmission.La maladie se présente sous des formes variées, qui rendent son diagnostic difficile.
Cliniquement, il est plus facilement évoqué si la maladie survient en été, avec la notion d'une exposition professionnelle ou de loisir au cours d'activités en eaux douces ou sur les berges.
L'incubation dure 7 à 14 jours (extrêmes de 2 à 21 jours).
Elle se manifeste comme un ictère fébrile à rechute.
L'ictère est dit « flamboyant », car il associe la rougeur d'une vasodilatation cutanée avec un teint jaune safran.
Sa gravité dépend de l'atteinte aigüe hépatique et rénale (hépatonéphrite) qui peut aller jusqu'à des manifestations hémorragiques sévères et une insuffisance rénale aigüe (cette association définit la maladie de Weil historique).Elle s'observe plus fréquemment que la forme classique.
Le début est brutal avec un état infectieux sévère : fièvre dépassant 39°, frissons, céphalées, accompagné de myalgies et douleurs diffuses prédominant sur les membres inférieurs (douleurs invalidantes des mollets, aggravées à la pression).L'examen peut montrer une hémorragie conjonctivale, un herpès labial, parfois une hépatomégalie douloureuse, plus rarement un exanthème siégeant sur le tronc.Cette phase initiale peut durer de 3 à 7 jours où la fièvre se normalise progressivement.
En l'absence de traitement, une rechute survient.
Les signes initiaux réapparaissent, moins intenses mais accompagnés de signes méningés et de troubles neurologiques.
Des complications oculaires plus tardives peuvent survenir, en particulier l'uvéite d'origine immunologique, par auto-anticorps.Dans tous les cas, les deux formes précédentes peuvent s'accompagner ou non d'atteintes rénales, cardiaques, pulmonaires.
À cela s'ajoute la variété des formes selon la gravité, qui vont des formes inapparentes et bénignes aux formes très graves avec défaillance multiviscérale mortelle.
C'est un des nombreux mystères de cette maladie car on connait mal les raisons de ces différences qui pourraient être : des facteurs de virulence bactérienne, la quantité de bactéries inoculées, les réponses immunitaires propres à l'hôte.
La recherche se porte vers des biomarqueurs fiables et prédictifs de ces évolutions.Depuis 1995, les formes pulmonaires sont apparues comme des formes graves, à la suite d'une épidémie au Nicaragua (en fait exposition commune à un même environnement).
Ces atteintes réalisent des inflammations hémorragiques des alvéoles pulmonaires avec détresse respiratoire gravissime (plus de 50 % de mortalité).
Quelques cas avaient déjà été décrits en Corée et en Chine, sans attirer l'attention.
Depuis cette forme de leptospirose est devenue une des principales causes de fièvre hémorragique dans les pays en voie de développement.
La recherche cherche à déterminer s'il s'agit de bactéries plus virulentes ou d'hôtes plus vulnérables (sujets affaiblis et appauvris en zones suburbaines insalubres).Les signes biologiques montrent, de façon diversement associée, une atteinte rénale, hépatique, musculaire, neurologique.
Il s'agit d'atteintes non spécifiques qui peuvent évoquer une leptospirose sans la prouver.Les signes les plus fréquents sont l'augmentation de la créatininémie, une hématurie microscopique, une augmentation des transaminases, une rhabdomyolyse, une thrombopénie,La recherche directe des leptospires n'a plus qu'un intérêt historique, car ses méthodes (examen direct au microscope, mise en culture, inoculation au cobaye...) sont trop difficiles, lentes ou fastidieuses.
En pratique courante le diagnostic repose sur la sérologie.
Un test ELISA IgM est utilisé en dépistage.
En cas de positivité, il faut confirmer le résultat par la technique de référence : le test de Martin et Pettit, aujourd'hui appelé MAT (Micro-Agglutination Test) qui détecte, en 2016, les 24 sérovars les plus fréquents en France.
Ce dernier examen n'est réalisé que par quelques laboratoires experts.
Son principal inconvénient est de n'être pas utilisable au début de la maladie (le patient n'ayant pas encore développé d'anticorps).
Selon les recommandations, trois sérologies à 15 jours d'intervalle seraient nécessaires pour infirmer un diagnostic de leptospirose ou confirmer et définir la souche responsable.Une nouvelle technique de PCR en temps réel a l'avantage de donner des résultats plus précoces , mais elle est plus coûteuse.
Il existe de nombreuses autres techniques en cours d'évaluation, à la recherche du test le plus proche de l'idéal : précoce, rapide, fiable et peu coûteux.
Ces différents examens ont donné lieu, en France, à une situation conflictuelle.
Depuis 2014, la technique MAT n'est plus remboursée et la PCR et l'Elisa Ig M sont maintenant remboursés par l'assurance maladie.
« Cette modification devrait entraîner, à court terme, une perte d'information sur les souches qui circulent».
En effet seul le MAT peut aujourd'hui permettre d'identifier les sérovars, car on n'a pas retrouvé de parallélisme entre structure génétique et propriétés antigéniques.Toutes les autres méthodes de biologie et d'imagerie peuvent être utilisées, au cas par cas, pour l'aide au diagnostic différentiel.
En pays tropical (ou retour de pays tropical), il faut discuter le paludisme, la dengue, la typhoïde, une rickettsiose, une hépatite virale.
En pays tempéré, et plus particulièrement en France métropolitaine (sans retour de voyage récent), il faut écarter grippe, pyélo-néphrite, méningite, fièvre à Hantavirus (dans les Ardennes).Finalement le diagnostic de certitude est parfois rétrospectif, c'est-à-dire qu'il est fait quand la maladie est terminée.Le traitement de référence fait appel à un antibiotique de la famille de la pénicilline (Peni G ou ampicilline) ou à une cycline comme la doxycycline.
C'est une antibiothérapie probabiliste qui doit être commencée précocement.
La durée de traitement est de l'ordre de 7 à 10 jours.
Cette antibiothérapie précoce a permis aussi de faire quasiment disparaître les formes chroniques, parfois graves, comme les complications oculaires auto-immunes qui pouvaient survenir.Les méthodes de réanimation peuvent être nécessaires pour des complications viscérales et métaboliques (par exemple dialyse si insuffisance rénale persistante) à la phase aiguë de la maladie, parfois mortelle.Une réaction de Jarisch-Herxheimer est fréquente, après le début du traitement, secondaire à la lyse du spirochète.
Le patient récupère en 5 à 6 semaines si la maladie était modérée (bien que des bactéries peuvent encore être trouvées dans l'urine du patient plusieurs semaines après la disparition des symptômes).
Dans le monde, les formes graves de leptospirose auraient un taux de mortalité supérieur à 10 %.
Toutefois, depuis le début du XXIe siècle, dans les pays à infrastructures médicales modernes et équipées, la mortalité des formes graves est proche de zéro, la guérison des formes aiguës se faisant sans séquelles .Dans les formes graves, un traitement par corticoïdes est parfois donné, avec une efficacité qui reste discutée.En France ce n'est plus une maladie à déclaration obligatoire depuis 1986.En France, la leptospirose est reconnue au tableau des maladies professionnelles (no 19A régime général, no 5 régime agricole), pour les personnes travaillant dans les cadres suivants :La prévention générale repose sur les campagnes de dératisation.Les recommandations individuelles sont l'évitement du contact de plaies cutanées avec l'eau, la protection par combinaisons, gants, bottes et lunettes.Dans des situations particulières à haut risques d'exposition sur une courte période (compétition sportive en eau douce, rafteurs, randonneurs en rizières, secouristes en zone d'inondation ou de tremblement de terre, militaires en mission....), une antibiothérapie prophylactique peut être proposée.Pour les activités de loisirs habituelles en eau douce (baignade, pêche, sports nautiques...) les mesures préventives individuelles semblent illusoires (inapplicables).
Seule l'information du grand public sur les risques et la maladie, permettrait une prise en charge médicalisée plus précoce des cas déclarés.Le vaccin disponible en France a été mis au point au cours des années 1970 par l'Institut Pasteur à la demande des délégués du personnel des égouts de Paris (29 cas et 3 décès par leptospirose de 1951 à 1979 chez les égoutiers de Paris).
Il s'agit du spirolept, suspension de 200 millions d'unités de leptospires (L. interrogans sérovar icterohæmorrhagiæ) inactivés par le formol.
Il ne protège que contre ce sérotype qui représente les formes les plus graves de la maladie, et 25-30 % (France métropolitaine) à 40-50 % (France outre-mer) des leptospiroses.Son efficacité est bonne, mais de courte durée (2 ans).
Le schéma vaccinal est 2 injections à 15 jours d'intervalle, un rappel 4 à 6 mois plus tard, puis tous les 2 ans si l'exposition persiste.
C'est un vaccin injectable par voie sous-cutanée (injection lente).
Il n'existe pas de données pour les enfants et les femmes enceintes (utilisation déconseillée pendant la grossesse).Cette vaccination est proposée par le médecin du travail, au cas par cas, après évaluation individualisée du risque.
Cette proposition se fait après mise en œuvre des autres mesures de prévention, informations sur les comportements à risques, la maladie et le vaccin.Dans le calendrier vaccinal 2019 (France, ministère de la Santé), cette vaccination peut être proposée aussi en population générale pratiquant de façon régulière et durable des loisirs à risques (activités en eau douce et sports de nature en milieu humide).Dans les années 2020, les chiens sont généralement vaccinés contre quatre sérogroupes :
La vaccination par ADN est une technique de protection contre les maladies par injection d'ADN génétiquement modifié.
L'ADN injecté entraîne chez les cellules visées une réponse immunologique protectrice par la production d'un antigène.
Les vaccins à ADN présentent des avantages potentiels par rapport aux vaccins classiques, y compris la capacité à induire une plus large gamme de types de réponses immunitaires.Cette approche vaccinale a permis d’obtenir des résultats prometteurs lors d’expérimentations sur des modèles animaux.
La recherche étudie cette approche pour la lutte contre les maladies virales, bactériennes et parasitaires chez l'homme, ainsi que pour la lutte contre plusieurs types de cancers.Les vaccins à ADN sont produits grâce au génie génétique.
Ils prennent la forme de plasmide (ADN circulaire).
L’ADN utilisé est celui qui code l’antigène d’un pathogène.
La vaccination comme les vaccins traditionnels permet à un organisme traité d’être protégé d’une maladie en produisant une réponse immunitaire spécifique.
Les vaccins à ADN sont un développement récent en médecine qui présente un grand potentiel et pourrait éventuellement à terme remplacer les vaccins de deuxième et de première génération.Le vaccin à ADN est constitué de gènes qui codent des protéines spécifiques au pathogène.
Nous ne savons pas comment l’ADN réussit à rentrer dans la cellule; cependant, une fois à l’intérieur de la cellule présentatrice d'antigène, l’ADN est transcrit et puisque ses peptides sont reconnus comme étant étranger; le mécanisme de présentation de l’antigène au niveau du CMH I est déclenché.
La cellule va donc, externaliser l’antigène du vaccin et il y a aura reconnaissance.
Les cellules CD 8+  ou cellules T cytotoxiques reconnaissent le peptide présenté par le CMH I et provoquent soit une cytolyse ou une production de cytosines.
Pour ce qui est de la réponse par le CMH II, elle est déterminée par les cellules présentatrices d'antigènes, que ca soit par phagocytose ou par reconnaissance d'une protéine étrangère, il y a externalisation du peptide à l'aide du récepteur de la CMH II.
Ensuite, il y a transport de l'antigène fixé par les cellules présentatrices d'antigènes dans des tissus lymphatiques où ensuite il y a différenciation des cellules T en cellules aidantes.
Bref, la réaction provoquée par un vaccin à ADN ressemble beaucoup à une réaction provoquée par un virus vivant sans les risques, d’où son utilité.Les vaccins de première génération ou un vaccin vivant pose des problèmes, ce vaccin permet une réponse immunitaire du CMH I et II, il permet l’une des meilleures réponses immunitaires.
Cependant il porte un risque pour l’hôte, particulièrement chez les patients immunodéprimés, dans le cas où il peut se réactiver.La vaccination de deuxième génération consiste à injecter des sous-produits du pathogène, que ce soient des antigènes de celui-ci ou simplement ses toxines.
Ce dernier vaccin est très utilisé, mais son problème est qu’il ne produit qu’une réponse au niveau des cellules T aidantes et pas de réponse au niveau des cellules T cytotoxiques.
Le vaccin à ADN est le vaccin de troisième génération ; il permet d’avoir une réponse immunitaire au niveau du CMH I et II comme le vaccin vivant, mais sans les problèmes liés à celui-ci.
Selon sa confection, il peut influencer le CMH I et II de différentes façons.
Ce vaccin est resté à l’étape expérimentale jusqu'en 2020, où les tests restaient surtout des tests in vivo sur des animaux.
Ces vaccins sont passés au stade opérationnel en 2020 à la suite de l'épidémie de Covid-19.Le vecteur peut être défini comme étant le moyen de transport, ce moyen de transport est un plasmide pour ce vaccin.
Le véhicule étant le plasmide joue un grand rôle dans la réponse immunitaire.
La sélection du plasmide est importante puisque les plasmides n'ont pas tous la même réponse immune et nous recherchons la plus grande réponse immune possible pour avoir la meilleure défense contre le pathogène en question.Pour que la réponse immune soit la plus grande il faut que le vecteur puisse produire une bonne quantité de la protéine à externaliser lors du CMH I, bref plus il y a de protéine étrangère plus la réponse immune est grande.
C’est pourquoi plusieurs modèles de vaccin à ADN utilisent un promoteur viral très fort (promoteur du CMV) pour conduire la transcription et la translation de l’ADN complémentaire à celui du vaccin.
Le plasmide inclut aussi une séquence terminale forte de polyadénylation permettant une exportation de l’ARN messager du compartiment nucléaire au cytoplasme ainsi que le recrutement de ribosome permettant la production de protéines.
L'utilisation d'intron permet aussi de stabiliser la molécule d'ARN lors de l'épissage.
Selon l’antigène choisi, un antigène cytoplasmique (cellule t cytotoxique) ou membranaire, la réponse immunitaire est différente.
Une des techniques utilisées si on recherche à stimuler une réponse des cellules T cytotoxiques, est l’ajout d’un signal ubiquitine au niveau du N terminal qui va donc stimuler le système ubiquitine protéasome et dégrader l’antigène dans le cytoplasme, permettant une externalisation et donc la présentation d’antigène aux cellules cytotoxiques.
Si on utilise un antigène lié à la membrane il sera surtout ciblé par les anticorps.
Normalement un vaccin à ADN contient un à deux antigènes.Voilà un résumé d'une technique de production.Il y a plusieurs méthodes utilisées pour l’injection du vaccin, les deux les plus utilisés sont l’injection par une aiguille hypodermique intramusculaire ou intra-épidermique et injection à l’aide d’un fusil à gène.Ce qu’on recherche est d’envoyer le vaccin dans les espaces extra-cellulaires, c’est possible lors d’une injection par aiguille si on utilise une solution hypertonique de sucre ou de sel.
Par réaction d’osmose le vaccin va se diriger dans le système extra-cellulaire.
Cette méthode d’injection requiert environ 10 μg-1 mg.
Pour ce qui est des avantages, il permet une expression permanente ou semi-permanente du gène, il n’a pas besoin de transport spécial et l’ADN du vaccin se propage facilement dans l’organisme.
Pour les désavantages, il y a bien sûr le nombre d’ADN requis qui est important, il y a une hausse des cellules T aidantes 1 qui n’est pas nécessairement désirable.Cette injection fonctionne comme un fusil puisqu’il produit une explosion de gaz (souvent de l’hélium) qui projette un nuage de microparticules de métaux lourds (souvent de l‘or ou du tungstène) enrobées d’ADN qui pénètrent les cellules.
Cette méthode requiert de 100 à 1000 fois moins de vaccin que celle de l’injection par aiguille.
L'avantage est que l’ADN se rend directement aux cellules et que la quantité d’ADN nécessaire est minime.
L'inconvénient est qu'une hausse des Lymphocytes T auxiliaires de type 2 ou Th2 (en anglais T helper, Th) n’est pas nécessairement souhaitée et que l’addition de particules inertes est nécessaire.L'efficacité du  vaccin à ADN peut être augmentée par l'ajout de cytokine ce qui permet une modulation positive du système immunitaire ; on peut l’incorporer dans l’ADN contenant l’antigène, ou utiliser un autre plasmide contenant l’ADN des cytokines souhaitées.
L’avantage de l’utilisation de plasmide composé de gène est le coût de production, beaucoup plus bas que celui des adjuvants normaux et sans lien avec leur toxicité.
Cependant, l’effet à long terme des cytokines n’a pas encore été défini, et isoler les gènes nécessaires pour chaque espèce est fastidieux.Aujourd'hui, l'étude des vaccins à ADN sur l'humain a commencé, notamment dans le cadre de la lutte contre le SARS-CoV-2.
Selon l'OMS, au 29 juin 2021, seul un vaccin à ADN parmi les 105 vaccins candidats contre le SARS-CoV-2 (toutes technologies confondues) est en phase 3 de développement : il s'agit du ZyCOV-D développé par Zydus Cadila.
Il existe 16 candidats vaccins à ADN en phases pré-cliniques contre le SARS-CoV-2 et 10 en phases cliniques (quatre vaccins en phase 1 ; quatre vaccins en phase 1/2 ; un vaccin en phase 2/3 ; un vaccin en phase 3).
Le vaccin contre la rougeole est un vaccin destiné à prévenir la rougeole, une maladie causée par un virus, le virus de la rougeole.
L'efficacité du vaccin est importante et ses effets secondaires sont le plus souvent sans gravité.
Il fait partie des vaccins recommandés chez le nourrisson.La rougeole est une maladie des voies aériennes dont les complications peuvent être une otite, une pneumonie ou une encéphalite, voire une panencéphalite sclérosante subaiguë.
Elle est due au virus morbilleux.
Elle a aussi pour effet de "remettre à zéro" le système immunitaire de l'enfant, et à le rendre ainsi plus vulnérable face aux infections causées par des bactéries opportunistes.Entre 2017 septembre 2018, la France a fait face à une épidémie de rougeole, avec 2 779 cas déclarés dont 3 morts.
89 % des cas de rougeole sont survenus chez des sujets non ou mal vaccinés.
Cette épidémie a été causée par un taux de couverture vaccinale de la population insuffisant : seulement 79 % de personnes vaccinées (avec deux doses) de vaccin alors que 95 % sont nécessaires.Le vaccin contre la rougeole est un vaccin vivant atténué.
En France, il existe sous forme isolée mais également sous forme combinée aux vaccins contre les oreillons et la rubéole (vaccin ROR).
L'administration est faite par voie sous-cutanée.En France, la vaccination recommandée des nourrissons se compose de 2 injections aux âges de 12 et 16 à 18 mois.Le taux de séroconversion est évalué à 98 %, tandis que le taux de protection réelle est évalué à 95 %.
La durée de protection semble très longue, bien que difficilement évaluable.Les effets indésirables possibles du vaccin contre la rougeole sont une fièvre, parfois associée à une éruption cutanée, pour 5 % des cas, une convulsion fébrile pour 1 cas sur 4 millions, une thrombopénie pour 1 cas sur 50 000, une encéphalite pour 1 cas sur 10 millions.Le vaccin est contre-indiqué en cas d'allergie à un des constituants (néomycine par exemple), et en cas de déficit immunitaire touchant l'immunité cellulaire.
Le vaccin contre la grippe saisonnière (ou influenza) est composé de deux virus de souche A (généralement une souche H1N1 et une autre H3N2) et, depuis 2014, de deux virus de souche B. Les particules virales contenues dans le vaccin sont inactivées chimiquement,.La grippe saisonnière résulte de l'infection par un virus de la famille des orthomixovirus, de la famille des virus ARN simple brin, qui sont naturellement sujets, lorsqu'ils sont dupliqués  dans les cellules de l'hôte, à des erreurs de réplication de leur matériel génétique, ce qui occasionne des mutations permettant au virus d'échapper au système immunitaire de l'hôte (c'est pourquoi un nouveau vaccin est à produire chaque année, pour pallier de nouvelles résistances du virus face aux anticorps produits par l'organisme.
)Ce virus est entouré d'une enveloppe contenant deux protéines spécifiques à ce type de virus : l'hémagglutinine et la neuraminidase, qui sont construites chacune avec plusieurs petites variations lors de la réplication virale, permettant une grande diversité de souches virales.
19 sous-types d'hémagglutinine et 9 sous types de neuraminidases sont connus.
Depuis les dernières pandémies grippales de 1968 et 1977-78, les sous-types circulants les plus courants sont H1 et H3 pour les hémagglutinines et N1 ou N2 pour les neuraminidases, et les combinaisons H1N1 et H3N2 sont les types de virus A qui circulent le plus chez l'humain depuis quelques années.Chaque année, l'OMS publie sur son site internet ses recommandations pour la composition des vaccins diffusés dans les hémisphères nord et sud.
Les recommandations faites pour la saison grippale suivante (hiver) se basent sur la caractérisation des souches qui circulent dans l'autre hémisphère durant la saison courante : ainsi fin septembre 2013, l'OMS, sur la base des observations au démarrage de la saison grippale de l'hiver 2013-2014 de l'hémisphère nord, a publié ses recommandations pour la saison grippale de l'hiver 2014 de l'hémisphère sud (qui a démarré en février-mars 2014, et permettra quant à elle la publication des recommandations pour l'hiver 2014-2015 de l'hémisphère nord).
Ce système vise à détecter l'apparition et/ou la propagation de nouvelles souches et variantes, qui seront susceptibles d'infecter un plus grand nombre de personnes (car n'ayant pas encore été en contact avec les nouveaux antigènes), et sur le fait que chacun des deux hémisphères joue le rôle de réservoir infectieux pour l'autre hémisphère, pendant son été (période de quasi absence de circulation du virus dans la population).Le tableau ci-dessous présente les recommandations de l'OMS :À partir de la saison de l'hémisphère nord 2013-2014, l'OMS recommande l'utilisation de vaccins quadrivalents, associant deux souches B.Chaque changement dans la composition recommandée traduit l'émergence d'une nouvelle souche, susceptible d'infecter une large partie de la population.
On note ainsi sur ce tableau la prise en compte à partir de 2010 du nouveau virus A(H1/N1) pdm09 lié à la pandémie grippale de 2009, souche notée A/California/7/2009, et à partir de 2018, de l'apparition d'une nouvelle souche H3N2 à l'origine de l'épidémie de grippe importante de l'hiver 2017-2018 dans l'hémisphère nord.
Cette souche n'ayant pas été incluse dans les vaccins de la saison 2017-2018, les personnes vaccinées en début de saison grippale 2017-18 n'ont pas bénéficié d'une protection optimale contre ces nouveaux variants (mutation N121K dans l'hémagglutinine, et modifications antigéniques dans la neuraminidase).Le virus est tout d'abord cultivé en grande quantité en l'inoculant dans des œufs embryonnés de poule, qui servent de lieu de reproduction.Le choix des souches virales est effectué par l'Organisation mondiale de la santé (OMS), qui fait un suivi des épidémies mondiales de grippe tout au long de l'année.
Elle choisit ensuite les souches les plus à risque d'émerger et de causer une épidémie.Étant donné que le vaccin contre la grippe ne contient que des virus inactivés (tués), l'ajout d'un adjuvant est de mise afin de permettre la mise en place d'une réponse immunitaire assez forte pour permettre la production d'anticorps et de cellules mémoires.
Le virus lui-même n'est pas capable d'engendrer une réponse immunitaire forte, car il ne peut pas se répliquer dans les cellules qu'il infecte et ne représente donc pas de danger imminent pour l'hôte.
Le rôle de l'adjuvant présent dans le vaccin  est de présenter le virus de façon adéquate aux cellules du système immunitaire afin d'activer à la fois la réponse humorale et la réponse cellulaire.
Cela permet la formation d'une plus grande quantité d'anticorps, majoritairement des anti-hémagglutinines, et il permet également la formation de lymphocytes mémoires (B et T) qui, grâce à leur durée de vie allongée et à leur facilité d'activation, permettront au système immunitaire de réagir plus rapidement et plus efficacement lors d'une rencontre ultérieure avec le même virus ou avec un virus similaire.
Plus la ressemblance entre les deux virus est grande, meilleure sera la réponse immunitaire.Les vaccins actuellement commercialisés en France ne contiennent pas d'adjuvant.Des symptômes peuvent survenir 12 à 48 heures après vaccination.
On peut constater une fièvre et un état grippal qui se dissipe généralement très vite.En France, la vaccination contre la grippe est recommandée pour les personnes de plus de 6 mois appartenant à un groupe à risque de complications (personnes âgées de plus de 65 ans, personnes atteintes d’asthme sévère ou de maladies pulmonaires chroniques, personnes présentant une faiblesse immunitaire grave).Les personnes les plus visées par les campagnes de vaccination saisonnière contre la grippe sont :De plus, la vaccination est fortement recommandée pour les personnes dans l'entourage d'un bébé de moins de 6 mois, car son système immunitaire est encore immature, et pour l'entourage d'une personne immunodéprimée car cette dernière a un système immunitaire affaibli qui serait incapable de s'opposer à une infection virale.
Les travailleurs de la santé devraient également se faire vacciner car ils présentent un risque élevé de contracter le virus sur leur lieu de travail.
Cette vaccination a pour but de diminuer les risques de transmettre le virus à des gens qui sont plus susceptibles de développer de graves problèmes de santé lors d'une infection par le virus de la grippe, car ils ne seraient pas capables de se défendre contre l'infection et pourraient en développer une forme plus grave.
Il a également été prouvé que la quantité d'anticorps antigrippaux dans l'organisme chute rapidement après six mois, d'où, encore une fois, la nécessité de la vaccination chaque année pour rebâtir la mémoire du système immunitaire.Une des questions posées et sans vraie réponse, à ce stade, est l'intérêt de la vaccination des personnels de l'enseignement.
Cette question est posée, car les lieux d'enseignement sont des lieux fréquents d'explosion virale d'une part; d'autre part, depuis la multiplication  des voyages scolaires, notamment à l'étranger, ce peut aussi être un lieu de réarrangement viral.Le vaccin antigrippal ne peut jamais être prévisible ni efficace à 100 %, car les souches virales en circulation évoluent et se recombinent régulièrement ; elles ne seront donc jamais exactement identiques à celles inoculées par la vaccination.
Plus les ressemblances sont grandes, meilleure est l'efficacité de la protection, car les anticorps produits grâce au vaccin ciblent alors mieux les virus qui infectent l'organisme.Faute de temps et de moyens pour réaliser des études randomisées en double aveugle évaluant l'efficacité d'un nouveau vaccin saisonnier sur un échantillon significatif de vrais patients, évaluées sur des critères cliniques, l'autorisation de mise sur le marché (AMM) est chaque année délivrée par les autorités sanitaires sur la base de la seule « efficacité sérologique » estimée d’après le taux d'anticorps titrés au cours d’essais cliniques limités.
L'utilité et l'efficacité écoépidémiologique du vaccin antigrippe pour la population générale ne peuvent donc être évaluées qu'après la vague de grippe saisonnière (...au mieux par rapport aux années précédentes, et à ce jour sans comparaison possible avec un groupe témoin non vacciné ou un groupe exposé à l'effet placebo.
Son efficacité est donc généralement appréciée par des calculs et simulations (dont les résultats dépendent beaucoup des hypothèses choisies).
Dans un cas de figure, l'efficacité vaccinale est plus facile à évaluer : celui de quelques populations mieux suivies ou pour les patients en consultations ambulatoires (hospitalisations courtes où le diagnostic peut être validé par un test permettant d'identifier la souche du virus en cause ; dans ces cas, selon une méta-analyse publiée par The Lancet en 2012, l'efficacité du vaccin varie: elle peut être de 40 à 60% , mais elle peut également être basse comme durant l’hiver 2014-2015, où le vaccin a protégé moins de 10% des vaccinés,.
La protection offerte par ce vaccin dépend d'au moins 3 facteurs :Courant avril 2019, des immunologistes de l'Inserm ont obtenu une amélioration du vaccin en procédant à des injections dudit vaccin par "voie cutanée" et non plus par voie musculaire.Le moment de la vaccination influence aussi son efficacité.
Pour avoir le plus d'anticorps possible durant la saison grippale en Belgique, le Conseil supérieur de la Santé conseille de se faire vacciner entre le 15 octobre et le 15 décembre, et de préférence vers la fin de cette période.
Car la grippe s'y manifeste habituellement en janvier-février-mars, et il faut environ deux semaines pour développer les anticorps, dont le nombre diminue par la suite.Un autre point important en faveur de la vaccination saisonnière est la réémergence d'anciennes souches virales très contagieuses et/ou hautement pathogènes de grippe.
Ainsi a-t-on montré une grande similitude entre l'hémagglutinine du virus de la grippe A (H1N1) de 2009 et celui de la grippe espagnole de 1918, qui a fait des millions de morts à travers le monde.
La population actuelle n'ayant jamais été en contact avec ce virus, elle n'a aucun anticorps ciblant ce virus.
C'est la raison pour laquelle une vaccination de masse fut mise en place.
un autre risque est la réémergence d'un virus H2N2 avec lequel la population n'a pas été en contact depuis la « grippe asiatique de 1957 » (seconde pandémie grippale du XXe siècle, qui a probablement fait 2 millions de morts).Ces réémergences sont possibles grâce à l'existence de réservoirs animaux et/ou de recombinaisons virales (« réassortiment »).
La grippe est une zoonose, c'est-à-dire que ses virus touchent à la fois des humains et certains taxons animaux (oiseaux et certains mammifères non-humains, éventuellement porteurs asymptomatiques).
Dans ces réservoirs (a priori principalement porcins et aviaires), les virus se dupliquent et mutent puis peuvent être retransmis à l'homme qui ne dispose pas toujours des anticorps efficaces contre les virus aux protéines mutées.
La vaccination vise à faire produire, par l'organisme, des anticorps aptes à cibler ces protéines mutées avant que le vrai virus n'infecte l'hôte, afin que ce dernier puisse se défendre adéquatement contre l'infection virale.
Mais cette vaccination ne sera efficace que si la souche du virus qui infecte le patient est l'une de celles prévues par les fabricants du vaccin de l'année, et si le virus n'a pas à nouveau muté de manière signifiante depuis le moment où le vaccin a été produit.Dans les années 2010, les vaccins antigrippaux ne sont encore que relativement efficaces (44% de succès en moyenne ; en raison de l'évolution antigénique rapide du virus et en raison de contraintes de fabrication conduisant souvent à une non-concordance des vaccins et des souches dominantes du moment).
L'idée d'un vaccin universel est évoquée depuis plusieurs années.
Ce sont notamment les recherches de la vaccinologue Sarah Gilbert.
C'est plus précisément d'un vaccin « largement protecteur » (l'Institut national des maladies allergiques et infectieuses (NIAID) estime qu'une efficacité d'au moins 75% contre les symptômes de la grippe suffirait pour un tel vaccin).
Selon une modélisation récente (2019) un vaccin universel efficace à 75% réduirait fortement l'impact épidémiologique de la grippe mondiale, et grâce à une chute de l'incidence et des hospitalisations, ferait économiser 3,5 milliards de dollars/an de frais médicaux directement imputables à la grippe ; soit un bénéfice dépassant le budget de 330 millions de dollars proposé pour atteindre cet objectif, considéré comme une priorité scientifique élevée par le NIAID .
En 2019, le Congrès américain a accordé 130 millions de dollars pour cela, plus un milliard de dollars (sur 5 milliards de dollars) proposé dans la loi sur les vaccins contre la grippe.Mais un tel vaccin devrait reconnaître tous les virus d'une même souche voire ceux de toutes les souches, ce qui reste un défi.
Des recherches portent notamment sur l'utilisation d'un deuxième vaccin pour permettre une activation plus grande du système immunitaire, ou sur un vecteur antiviral qui contiendrait le gène codant une partie constante de la protéine hémagglutinine qui semble concentrer les mutations observables dans certaines zones d'hyper-variabilité au sein de la structure de la protéine, alors que d'autres zones sont hautement conservées.
Ce sont ces zones qui sont encodées dans les vecteurs et contre lesquelles les anticorps sont formés.
Plusieurs anticorps (dont CR9114) capables de neutraliser différents sous-types de virus de la grippe B ont été découverts, mais comme dans les cas du VIH (virus de l’immunodéficience humaine) et du virus de l’hépatite B qui mutent également sans cesse pour échapper au système immunitaire de leur hôte, élaborer un vaccin universel nécessite une meilleure compréhension de toutes les interactions entre le virus et les cellules du système immunitaire.Ce vaccin fait partie de la liste des médicaments essentiels de l'Organisation mondiale de la santé (liste mise à jour en avril 2013).
La notion de Médecine translationnelle (ou médecine traductionnelle) est une discipline scientifique émergente qui applique au domaine médical les principes de la science translationelle et de la « recherche translationnelle » (lesquels visent à traduire en applications concrètes (sciences appliquées) les théories scientifiques et les découvertes de laboratoire afin de réduire le nombre des besoins médicaux et pharmaceutiques encore insatisfaits),.
Initiée en France dans les années 1960 par le cancérologue Georges Mathé , elle s'appuie aussi sur l'épidémiologie interventionnelle.Elle décrit dans les services de santé publique ou individuelle les démarches visant à combler le fossé existant entre la science médicale fondamentale et la pratique médicale clinique réelle.
Dans le domaine pharmaceutique, il s'agit de faire le pont entre les découvertes théoriques et la production effective de médicaments, en s'appuyant éventuellement sur la pharmacie virtuelle, c'est-à-dire une banque de médicaments créés ou rassemblés de manière collaborative, transparente et selon les principes de l'open source, par exemple pour le traitement de maladies tropicales ou de maladies rares jugées  non rentables par l'industrie pharmaceutique.La médecine translationnelle a donc une composante prospective forte.
En France, c'est l'un des quatre thèmes prioritaires retenus par le Pôle de compétitivité Medicen Paris Region.
Ils sont nombreux et concernent par exemple la prévention médicale et le dépistage, la médecine scolaire et du travail, la biogénomique, la nanomédecine, les neurosciences, l'instrumentation médicale, les robots médicaux, les moyens de diagnostic, l'imagerie médicale, la toxicologie et l'écotoxicologie ou encore l'épidémiologie et l'écoépidémiologie,  Il s'agit aussi de mieux prévoir et atténuer les effets indésirables des médicaments et de certains actes médicaux et d'améliorer les soins palliatifs et l'accompagnement humain, social et psychologique des malades ou des mourants (prévention quaternaire), etc.La médecine translationnelle exige :L'enjeu de cette médecine est d'améliorer la qualité des essais cliniques, puis des services de santé en traitant mieux un plus grand nombre de maladies, y compris pour des maladies dites « négligées » (car économiquement non rentables pour l'industrie pharmaceutique).
Elle est souvent aussi présentée comme un moyen de développer l'économie dans le secteur médical et paramédical.De nombreuses publications existent dans ce domaine, et notamment grâce à des revues à comité de lecture dédiées au sujet :
L'immunité cellulaire (ou immunité à médiation cellulaire) est l'un des deux versants complémentaires de l'immunité adaptative — réponse des organismes supérieurs aux agressions.
L'autre versant est l’immunité humorale, plus facile à mesurer.L'immunité cellulaire réagit principalement aux agents qui infectent les cellules, par exemple les virus.
Les lymphocytes T jouent le rôle central dans cette immunité.Ministère de la Santé et des Services sociaux, « Immunologie de la vaccination : Fonctionnement du système immunitaire », sur mss.gouv.qc.ca, 30 avril 2018 (consulté le 18 juillet 2021)Système immunitaire inné
Une anatoxine est une molécule dérivée d'une toxine de micro-organisme caractérisée par la perte de ses propriétés toxiques tout en ayant conservé  sa structure et des propriétés immunisantes.Le premier emploi de vaccins à base d'anatoxines bactériennes (qui se différencient des vaccins à bactéries atténuées ou des vaccins inactivés) est attribué à Gaston Ramon qui travaille sur la toxine diphtérique à partir de 1920.
Il met dès lors au point, simultanément avec les immunologistes britanniques Alexander Glenny (en) et Barbara Hopkins, Les vaccins contre la diphtérie et le tétanos.
Une levure est un champignon unicellulaire apte à provoquer la fermentation des matières organiques animales ou végétales.
Les levures sont employées pour la fabrication du vin, de la bière, des alcools industriels, des pâtes levées, des antibiotiques et d'exhausteurs de goût (les extraits de levure peuvent servir comme agents de sapidité).Le terme « levure » sans spécification peut avoir un emploi générique ou spécifique, dont on vient de donner deux définitions, l'une au singulier et l'autre au pluriel, toutes les deux renvoyant à une classe large d'espèces que la définition spécifie.
Mais « levure » peut aussi désigner en contexte, une espèce particulière, généralement par abréviation (ou ellipse du spécificatif) de « levure de bière », ou de « levure de boulanger », ou de « levure haute » (ou basse) (soit Saccharomyces cerevisiae).
Le terme désigne également, par analogie, le mélange chimique utilisé en cuisine pour faire gonfler la pâte, dite « levure chimique ».La dénomination « levure » découle de l'observation des fermentations et tout particulièrement celle qui a lieu durant la fabrication du pain : on dit communément et depuis longtemps que le pain lève.
Ce n'est pas, à proprement parler, une dénomination scientifique actuelle.
Mais l'importance des levures dans le domaine des fermentations conduit à conserver ce terme générique qui continue à être correctement perçu.Si les Sumériens et les Égyptiens utilisaient déjà la levure pour faire lever leur pain, il a fallu attendre 1857 pour que Louis Pasteur prouve et explique dans "Mémoire sur la fermentation alcoolique" que les levures sont des organismes vivants (effet Pasteur).Le terme courant de levure désigne généralement le genre Saccharomyces (levure de bière ou levure de boulanger).
Il existe beaucoup d'autres genres de levures ; parmi les plus connues, le genre Candida possède un pouvoir pathogène chez l'homme, responsable des mycoses de type candidoses.La plupart s’apparentent aux Ascomycètes (type truffe, pézize), quelques-unes à l’autre grand groupe de champignons supérieurs, les Basidiomycètes (type amanites, bolets) et d’autres enfin sont des formes imparfaites non rattachables clairement à un groupe défini.
La levure de raisin mesure environ 2 à 9 µm.Ces micro-organismes, de forme variable selon l’espèce (sphérique, ovoïde ou elliptique, en bouteille, triangulaire ou apiculée (renflée à chaque bout comme un citron) mais généralement ovales, d'environ 6 à 10 microns et jusqu’à 50 microns, se multiplient par bourgeonnement ou par scission (scissiparité).
Ils sont souvent capables d'accomplir une sporulation soit dans un but de dormance en milieu défavorable, soit dans un but de dispersion.Pour la plupart des levures, la multiplication asexuée (mitotique) est la forme majeure de multiplication.
Il existe deux types de division mitotique chez les levures : par bourgeonnement (cas des Saccharomyces), ou par scission (cas des Schizosaccharomyces).Toutefois dans certaines circonstances de milieu, une reproduction sexuée peut avoir lieu, ce qui permet une classification:Les levures sont des micro-organismes eucaryotes, ainsi possèdent-elles les caractéristiques structurelles propres à ce type cellulaire et d'autres plus spécifiques aux levures elles-mêmes :Une paroi cellulaire entourant la membrane plasmique et protégeant la levure des agressions physico-chimiques du milieu extérieur.
Elle est constituée d'une couche externe de mannoprotéines, associés à des glucanes et une couche interne de glucanes associés à une petite quantité de chitine.Une membrane cytoplasmique composée principalement de phospholipides double couche (partie hydrophile à l'extérieur et partie lipophile à l'intérieur).
Elle contient aussi de nombreux complexes protéiques intrinsèques et extrinsèques dont les rôles sont variés, par exemple des enzymes appelées protéases mènent les transports de substances du milieu extérieur vers le milieu intracellulaire et/ou inversement avec ou non transformation du substrat durant le passage.Un noyau contenant l'information génétique du génome chromosomique de la levure.
(voir le chapitre sur les caractéristiques génétiques pour en savoir plus)Des mitochondries qui jouent un rôle important dans la respiration aérobie de la levure et la production d'ATP.Une ou plusieurs vacuoles, organites à l'aspect homogène, qui servent d'espaces de stockage pour diverses substances.Les levures sont des organismes eucaryotes et possèdent un noyau avec des chromosomes linéaires.
Chez les Saccharomyces, les chromosomes sont au nombre de 16 simples ou 16 paires selon la forme haploïde ou diploïde de la cellule.
Il existe des gènes de structure à information continue comme chez les bactéries, et des gènes à information discontinue (introns et exons) comme chez les organismes supérieurs.
Par ailleurs, les gènes de régulation sont spécifiques des levures.À côté des chromosomes, il existe dans le noyau des petites molécules d'ADN circulaire d'environ 6 000 paires de bases, les plasmides, présents entre 50 et 100 exemplaires par cellule.
Ces plasmides sont autoréplicables et autotransférables sans affecter la viabilité de la cellule.
Ils portent l'information génétique de quelques caractères non essentiels à la viabilité de la levure.
Ils ont un rôle considérable dans toutes les opérations de génie génétique.Chaque mitochondrie renferme plusieurs molécules circulaires d'ADN mitochondrial qui portent l'information de certaines enzymes de la chaîne respiratoire.Certaines souches de Saccharomyces renferment dans leur cytoplasme deux virus à ARN.
Le matériel génétique du « petit virus » code une toxine exocellulaire capable de tuer d'autres levures et une protéine de résistance à cette même toxine pour empêcher les levures « tueuses » de se tuer entre elles.
Le « grand virus » est nécessaire à la multiplication et au maintien du « petit virus » dans le cytoplasme.
Les gènes codant d'autres toxines produites par des « levures tueuses » sont directement inclus dans l'ADN chromosomique.Les levures font partie des premiers organismes à avoir été génétiquement modifiés.
La FAO les considère comme substantiellement équivalents (mais ce concept d'équivalence en substance est encore discuté) à une levure naturelle, et donc « aussi sûrs que le produit traditionnel » et ne nécessitant « donc pas d'autres considérations de sécurité sanitaire que celles appliquées à l'aliment existant ».
En 1998, une levure génétiquement modifiée avec des gènes de la même souche était déjà utilisée en Grande-Bretagne pour la panification.
Hansenula polymorpha est une des levures naturelles du cidre, naturellement présente sur les pommes.
Des souches génétiquement modifiées produisent des phytases, un vaccin anti-hépatite B, des anticoagulants saratine ou hirudine ou d’autres protéines/enzymes.Une publication de 2019 a annoncé qu'une levure génétiquement modifiée produisait maintenant des cannabinoïdes médicinaux dont certains ont des propriétés psychotropes semblables à ceux trouvés dans le cannabis.Les deux principaux processus énergétiques connus chez les hétérotrophes sont la respiration et les fermentations.
Pour leur développement ces levures ont besoin :Toutes les levures sont capables de dégrader le glucose, le fructose et le mannose en présence d'oxygène, par un métabolisme oxydatif, conduisant à la formation de CO2 et H2O.Cette voie métabolique est très énergétique et permet aux cellules de subir une multiplication avec un rendement cellulaire élevé (le rendement étant défini par le quotient de la quantité de cellules fabriquées par le substrat sucré consommé) .
En plus des sucres simples, certaines levures peuvent utiliser d'autres glucides (mono, di ou trisaccharides, voire des polysaccharides comme l'amidon) mais aussi des alcools, des acides ou des alcanes.
D'une manière plus générale, elles ont une capacité hydrolytique bien moindre que les moisissures.En plus du métabolisme oxydatif, certaines levures peuvent privilégier une dégradation des glucides par un métabolisme fermentatif qui conduit à la formation d'éthanol et de CO2 suivant la réaction :En plus de ces composés majoritaires, des alcools supérieurs, des aldéhydes, des esters, des acides… sont formés en plus petites quantités et participent qualitativement de façon importante et complexe à la formation des flaveurs des boissons fermentées.
Ce métabolisme est moins énergétique que le métabolisme oxydatif, et le rendement de la multiplication cellulaire en est affecté bien que la vitesse de croissance puisse être nettement plus rapide que dans le processus oxydatif.
Ce processus de fermentation peut fonctionner en présence d'oxygène (conditions aérobies) ou en absence partielle ou totale d'oxygène c'est-à-dire également en conditions anaérobies.
On évoquera, dans le paragraphe suivant, l'apparition d'un processus fermentatif en présence d'oxygène en excès, décrit comme l'effet Crabtree et très important dans l'industrie de production des levures de boulangerie.Cet effet exprime une tendance au gaspillage du substrat carboné (glucose par exemple) quand ce substrat est présent en grandes quantités.
Cet effet permet de comprendre dans quelles conditions l'une des deux voies métaboliques décrites ci-dessus va être choisie.
Mais avant de poursuivre la description de l'effet Crabtree il nous faut introduire des données indispensables à sa compréhension.Éléments de cinétique de croissance microbienne :La croissance des levures et bactéries dont les cellules filles se séparent des cellules mères (la population est ainsi toujours constituée de cellules individuelles) suit une loi exponentielle dès lors que les conditions nutritives, l'aération et l'homogénéisation sont optimales.
Un modèle simple a été proposé par Jacques Monod pour représenter cette croissance particulière.La population évolue à partir d'une population faible X0 vers une population X selon l'équation suivante :(1) X=X0×exp⁡(μ×t){\displaystyle X=X_{0}\times \exp \left(\mu \times t\right)}où exp{\displaystyle \exp } est la fonction exponentielle, t{\displaystyle t} est le temps et μ{\displaystyle \mu } est défini comme le taux de croissance népérien du microorganisme.
La valeur de ce taux de croissance μ est influencée par de multiples facteurs (température, pH, oxygénation, →concentrations des divers substrats indispensables à la fabrication des cellules, etc.) qui retentissent sur l'activité des enzymes dont la cellule dispose afin d'assurer sa multiplication.
Chacun des enzymes suit les lois décrites pour le fonctionnement général des enzymes (loi de Michaelis-Menten) et Jacques Monod a considéré empiriquement que la valeur du taux de croissance pour un substrat donné, en l'occurrence pour un sucre comme le glucose(1) suivait la loi de Michaélis-Menten et que(2) μ=μmax×SKm+S{\displaystyle \mu =\mu _{max}\times {\frac {S}{K_{m}+S}}}où μmax est la valeur du taux de croissance la plus élevée que le microorganisme puisse atteindre ,(S) la concentration en substrat dans le milieu de culture,Km représentant la concentration en substrat qui détermine μ = μmax/2.La pratique de certains types de culture des unicellulaires, (culture en continu ou en semi-continu) a permis de préciser que le Km de la levure pour le substrat glucose était de l'ordre de 50 mg/litre à 80 voire 100 mg/litre de milieu de culture.
(1)(l'hypothèse peut être étendue aux autres substrats indispensables à la croissance comme l'Azote ou le Phosphore, etc.)La courbe tracée en bleu est la représentation des variations du taux de croissance en fonction de la concentration en substrat et elle illustre l'équation (2) ci-dessus.
On rappelle que les conditions nutritives du milieu, ainsi que l'aération et l'homogénéisation du milieu sont en excès par rapport aux besoins de la levure; seules les concentrations en substrat sucré sont limitantes pour la levure.On constate que le taux népérien maximum de croissance de la levure est de l'ordre de 0.4, ce taux correspondant à un temps de division cellulaire de 1 heure 45 minutesQuand la concentration en substrat est voisine de 100 mg/litre, le taux de croissance est de 0.25 (correspondant à un temps de division cellulaire de 2 Heures et 20 minutes) : dans ces conditions le métabolisme est encore presque totalement oxydatif mais en se déplaçant vers la droite du graphique il devient de plus en plus fermentatif même en présence d'oxygène en excès.
On doit noter que le temps de division cellulaire plus court implique un rendement cellulaire nettement moindre (courbe tracée en vert) !
Le rendement cellulaire s'abaisse en effet vers 12 % c'est-à-dire qu'on fabrique 12 mg de cellules pour 100 mg de sucre consommés alors que dans la partie ascendante de la courbe illustrant les variations du taux de croissance le rendement cellulaire est nettement plus élevé et 55 mg de cellules sont fabriquées avec toujours 100 mg de sucre.
L'explication de ce qui peut apparaître comme paradoxal réside dans la production simultanée de levure et d'éthanol quand la teneur en sucre dépasse un certain niveau.Quotient respiratoire (Qr) = CO2 produit / O2 consommé.Rendement cellulaire = biomasse formée (mg) / masse substrat consommée (mg).La température optimale de culture des levures se situe en général entre 25 °C et 30 °C, mais comme les autres micro-organismes, les levures peuvent être classées en levures psychrophiles, mésophiles et thermophiles.
D'une façon générale, les levures ne sont pas thermorésistantes.
La destruction cellulaire commence dès 52 °C (contre 120 °C pour les bactéries thermophiles hors archées).
Les levures sont aussi sensibles à la congélation et à la lyophilisation avec une grande variabilité selon les genres et espèces, et selon la phase de croissance: les cellules en phase exponentielle résistent moins que les cellules en phase stationnaire.La phase stationnaire se définit par un arrêt de la multiplication cellulaire lors de l'épuisement d'un milieu.
La levure ralentit son métabolisme, modifie la structure de ses parois et stoppe son cycle cellulaire en phase G1.La plupart des souches ne peuvent se développer pour une activité de l'eau inférieure à 0,90 ; mais certaines tolèrent des pressions osmotiques plus élevées, correspondant à une activité de l'ordre de 0.60, en ralentissant leur métabolisme ; ces levures sont dites xérotolérantes.Toutes les levures sont capables de se développer en présence d'oxygène : il n'y a pas de levure anaérobie stricte.
Certaines levures sont aérobie strictes (comme les Rhodotorula).
Les autres sont aéro-anaérobie facultatives avec parmi elles : des levures préférant un métabolisme soit fermentaire soit respiratoire même en présence d'oxygène.Les enveloppes cellulaires sont imperméables aux ions H3O+ et OH−.
Les levures tolèrent donc des gammes de pH très larges, théoriquement de 2,4 à 8,6.Les levures sont également sensibles aux agents chimiques :Le chloramphénicol inhibe la synthèse de protéines mitochondriales mais pas celle des protéines cytoplasmiques.
Seules les levures capables de fermenter peuvent alors être cultivées en présence de chloramphénicol.N'importe quel milieu de culture glucosé convient.
Cependant on utilise de façon préférentielle certains milieux et dans des conditions particulières (incubation à 28 °C pendant 24 à 48 heures) :Pour faire de la levure maison, il est possible d'utiliser de la pomme de terre mélangée à du sucre, du sel et de l'eau.
Le milieu doit être vierge de bactérie.L'utilisation de levures pour la panification et la vinification est connue depuis l'époque préhistorique.
Toutefois, la compréhension des mécanismes microbiologiques mis en œuvre date des travaux de Louis Pasteur au XIXe siècle.
Les connaissances scientifiques et techniques ainsi acquises ont permis de cultiver et d'utiliser de grandes quantités de levures dans les procédés de fermentation industrielle, mais aussi pour la production de vitamines B, de thiamine, des antibiotiques et des hormones stéroïdes.
En tant que sous-produit de procédés de fabrication, les levures sont utilisées comme nourriture animale.
Une autre transformation majeure des levures est leur autolyse et concentration par divers procédés pour produire des extraits de levures qui sont utilisés comme éléments nutritionnels ou agents de sapidité en alimentation humaine.
Ces extraits sont riches en glutamates, glucanes, nucléotides, vitamines du groupe B, etc..Composition en vitamines des levures de boulanger actives sèches :Par extension, le terme de levure est le nom générique donné à tous les organismes vivants unicellulaires eucaryotes appartenant au règne des Mycètes qui provoquent la fermentation.La levure de bière (Saccharomyces cerevisiae) est un sous-produit lavé, tamisé, puis pressé et desséché de la fabrication de la bière.La levure de boulanger (Saccharomyces cerevisiae) est utilisée pour faire lever le pain, grâce à la production de gaz carbonique par fermentation.La levure de paraffine est également très utilisée dans la fabrication de textile.Le terme de « levure chimique » est employé en cuisine pour désigner une poudre, composée principalement de bicarbonate de sodium, il ne s'agit donc pas de micro-organismes.
On s'en sert en pâtisserie et lors de la panification pour faire lever rapidement la pâte et la rendre très légère.Voir l'article Candida.
Les plasmocytes (parfois appelés à tort cellules plasmatiques - un calque du terme anglais plasma cells) sont des lymphocytes B pleinement différenciés, sécréteurs d'anticorps.
Ils sont uniquement présents dans les tissus.
On en trouve aussi beaucoup au niveau des muqueuses où ils produisent notamment des IgA dimériques qui deviendront des IgA secrétoires.
On ne les trouve ni dans le sang, ni dans la lymphe à l'état normal.
Dans les organes lymphoïdes périphériques, ils sont notamment présents au niveau des zones B des ganglions lymphoïdes.
Ce sont des cellules basophiles, hormis à proximité de leur noyau, région qui est nommée archoplasme.
Cette basophilie est due à la présence d'un abondant réticulum endoplasmique, riche en ARN, servant à la production massive d'immunoglobulines ou anticorps.Ces cellules produisent des anticorps et représentent le stade final de différenciation des lymphocytes B. À ce titre, elles participent à l'immunité à médiation humorale.À la différence des lymphocytes B, qui présentent leurs anticorps à leur surface (ancrés dans la membrane), les plasmocytes produisent des anticorps circulants.
De plus, ces cellules se caractérisent par une incapacité à se multiplier (contrairement aux autres stades d'activation des lymphocytes).
Le marqueur les caractérisant est une molécule nommée CD138 ou syndecan-1, un récepteur de molécules faisant partie de la matrice extracellulaire.Les lymphocytes B matures, une fois activés par leur rencontre avec l’antigène, se différencient en plasmocytes responsables de la production des anticorps et en lymphocytes B mémoire.L'archoplasme, du grec archos (« chef, guide ») et de plasmos (« chose »), est la partie juxtanucléaire du plasmocyte.
Seule région non basophile, il n'est donc pas coloré par les colorants usuels en microscopie optique et il apparaît translucide.
En microscopie électronique, on peut y voir l'appareil de Golgi.Certaines maladies cancéreuses impliquent un dérèglement lié aux plasmocytes, notamment les deux suivantes :
Le vaccin bilié de Calmette et Guérin, le plus souvent dénommé vaccin BCG, est un vaccin contre la tuberculose.Il est préparé à partir d'une souche atténuée de bacille tuberculeux bovin (Mycobacterium bovis) vivant qui a perdu sa virulence sur l'homme par culture spéciale sur des milieux artificiels pendant des années.
Ce bacille proche de Mycobacterium tuberculosis, responsable de la tuberculose humaine, confère une antigénicité croisée suffisamment forte pour devenir un vaccin effectif pour la prévention de la tuberculose humaine.
Il a également été utilisé en médecine vétérinaire.Depuis les arrêts d'approvisionnement par Sanofi, le BCG est en France produit par le groupe MEDAC, avec des pénuries périodiques (dont une en 2020).Le développement du vaccin BCG s'est fait dans un cadre de pensée et une pratique influencés par la vaccination antivariolique qui recourait alors à un microorganisme animal (cow-pox) pour se prémunir d'une affection humaine (variole ou smallpox en anglais).
L'agent de la tuberculose bovine, Mycobacterium bovis, qui peut induire des infections tuberculeuses chez l'homme, fut ainsi utilisé dans l'espoir de trouver un vaccin contre la tuberculose humaine.
L'inoculation de Mycobacterium bovis à des humains dans l'Italie de la fin du XIXe siècle eut des conséquences désastreuses.
Dans les années 1920, le Conseil de la recherche médicale tentera de mettre au point son propre vaccin, sans succès.Avant le vaccin mis au point par Calmette et Guérin, Emil Adolf von Behring avait développé un vaccin contre la tuberculose bovine qu'il croyait être la cause des tuberculoses pulmonaires humaines (via l'ingestion de lait de vaches porteuses de Mycobacterium bovis).
Ce vaccin, constitué de bacilles de type humain vivants et desséchés, s'avérera inefficace et même dangereux.
Il n'en inspira pas moins les travaux de Calmette qui, en 1908, partageait les vues de Berhring quant à l'étiologie de la tuberculose humaine ainsi qu'il s'en expliqua à un Congrès international.
Saturnin Arloing avait déjà conduit des travaux très aboutis dans le domaine de la vaccination contre la tuberculose bovine.
À l'Institut Pasteur de Nantes, Gustave Rappin suivait aussi depuis 1894 une piste prometteuse, à des fins tant préventives que thérapeutiques ; n'aboutissant pas avant 1924, ces efforts seront éclipsés par ceux de Calmette et Guérin, tandis que leur simple souvenir aura sans doute eu à pâtir des prises de position ultérieures de Rappin lui-même.En 1888, Pavlovsky réussit à ensemencer la surface de tranches de pommes de terre, milieu riche en amidon, avec des parcelles de culture du Bacille de la tuberculose (humaine) sur gélose glycérinée.
En 1893, Sander montre que l'apport d'air accélère la croissance des cultures ; comme terrain de nutrition, la pomme de terre lui paraît devoir être préférée à la gélose glycérinée, et aux milieux d'origine animale.En 1903, von Behring avance au congrès de Cassel que la tuberculose, quel que soit le siège de ses lésions, serait presque sans exception d'origine intestinale (contredisant ainsi la Baumgarten-Tangl law (en)).En 1890, Grancher et H. Martin réussissent à vacciner quelques lapins par l'inoculation à virulences croissantes de cultures de tuberculose aviaire, tout d'abord affaiblies par le vieillissement.
A. Möller obtient des résultats positifs d'immunisation (sur lui-même et sur des animaux) en se servant des cultures de tuberculose humaine, mais modifiées par un passage préalable sur l'orvet.
Friedmann obtient une vaccination active chez des bovidés au moyen des bacilles tuberculeux de la tortue.À son retour d'Indochine (où il essaya la tuberculine en traitement du lupus tuberculeux et une forme cutanée et muqueuse de la lèpre), et après un court séjour à Paris, Albert Calmette prend la responsabilité du nouvel Institut Pasteur de Lille en 1895.
Rejoint par le vétérinaire Camille Guérin en 1897, il y entame ses recherches sur la tuberculose (mécanisme de l'infection bacillaire, immunité antituberculeuse) en 1900 .« Calmette et Guérin font ingérer des cultures de tuberculose d'origine bovine, humaine, aviaire et phléolique à des chevreaux, à des chèvres et boucs adultes par différents procédés : introduction directe de cultures dans les voies digestives, ou contamination du lait d'alimentation.
Leur conclusion est que dans l'immense majorité des cas, la tuberculose se contracte non par l'introduction des bacilles dans les voies aériennes, mais par l'ingestion de produits bacillifères ».Nocard leur fournit une culture de Mycobacterium bovis isolée d'une vache tuberculeuse en 1902.En 1905-1906, ils constatent que de jeunes bovins guéris d'une tuberculose expérimentalement provoquée ne sont pas réinfectés.
En 1906 les comptes-rendus hebdomadaires des séances de l'Académie des Sciences publient un article de Calmette et Guérin intitulé Sur la vaccination contre la tuberculose par les voies digestives.
Cette même année, les annales de l'Institut Pasteur publiaient leur mémoire – le troisième ainsi nommé – intitulé Origine intestinale de la tuberculose pulmonaire.Le 12 juin 1906, le journal Le Matin fait état des travaux de Calmette et Guérin ; le quotidien, qui évoque d'abord la possibilité prochaine du développement d'un vaccin destiné aux bovins, rapporte la conviction de Calmette que ce vaccin trouvera vite une utilisation en médecine humaine.En 1908, une observation - ainsi peut-être qu'une indication du chercheur norvégien Kristian Feyer Andvord (en) – les met sur la voie de la découverte.
Afin de rendre émulsifiable une culture glycérinée de la souche Nocard, ils y ajoutent de la bile de bœuf ; ils s'aperçoivent que les cultures faites ainsi perdent de leur virulence.
Ils cultivent l'agent de la tuberculose bovine – Mycobacterium bovis – sur des tranches de pommes de terre immergées dans de la bile de bœuf stérile.
En 1909, Calmette dépose sur le bureau de l’Académie des sciences une note décrivant le « bacille tuberculeux bilié ».En 1912, après 96 mises en culture successives, ils parviennent à modifier la souche initiale qui devient inoffensive sur les bovins (elle reste pathogène pour le cheval).
Ce bacille partiellement atténué prend alors le nom de « bilié Calmette-Guérin » (BCG).En 1913, le vaccin est testé sur de jeunes bovins et des singes de différentes espèces.Les recherches deviennent difficiles à poursuivre pendant la Première Guerre mondiale : Lille est alors occupée par les Allemands ; les vaches sont réquisitionnées pour nourrir les troupes d'occupation ; Calmette autopsie les animaux et les déclare sains.En 1919, Albert Calmette reconstitue à l'Institut Pasteur de Paris une équipe de travail (Camille Guérin, Auguste Boquet et Léopold Nègre) sur le bacille tuberculeux (Boquet, Nègre et Jean Valtis auront la responsabilité de la préparation du vaccin BCG jusqu'en 1928, date d'arrivée de Guérin à Paris).
Les expériences de vaccination des bovidés avec la souche biliée, entreprises en 1912, furent reprises entre 1921 et 1927.
Conçu à l'origine pour un usage vétérinaire, le vaccin est testé par Henri Vallée en 1921 dans une ferme expérimentale modèle à Fécamp : Vallée procède par injections intraveineuses ou par insertion sous la peau ; il n'obtient pas un taux de protection à 100 %.La toute première inoculation humaine, en intraveineuse sur un homme adulte, en montre l'innocuité.Le vaccin est aussi essayé sur des nouveau-nés le 18 juillet 1921 à la crèche de la maternelle de l'hôpital de la Charité, à Paris.
Le pédiatre Benjamin Weill-Hallé et le Dr Raymond Turpin vaccinent d'abord un nouveau-né dont la mère était morte de la tuberculose quelques heures après l'accouchement et qui était appelé à vivre dans un milieu contaminé.
La santé de l'enfant étant établie après une période d'observation de six mois, la vaccination est étendue à d'autres nouveau-nés de l'hôpital de la Charité, d'abord de 1921 à 1922 puis de 1922 à 1924.
Les résultats de ces vaccinations sont présentés devant l'Académie de médecine par A. Calmette, C. Guérin et leurs collaborateurs le 24 juin 1924.
Le premier juillet 1924, l'Institut Pasteur créée le premier centre de production et de distribution gratuite de BCG ; le vaccin est distribué gratuitement aux médecins qui en font la demande ; en échange ceux-ci s'engagent à retransmettre un certain nombre d'informations.Le vaccin a aussi été testé sur des singes anthropoïdes sur le site de l'Institut Pasteur établi en Guinée, à Kindia, dont Calmette fut un temps directeur.
C'est en 1922 qu'est signée une convention entre l'Institut Pasteur et le gouvernement général de l'Afrique-Occidentale française fondant en Guinée française l'établissement auquel sera donné le nom de Pastoria.
La direction de l'établissement, qui couvre 35 ha, est confiée au vétérinaire-commandant R. Wilbert en 1923 ; Maurice Delorme en devient l'assistant en 1925.
À partir de 1937 une production de vaccin BCG se fait sur place.La vaccination se développe à partir de 1924, notamment dans les dispensaires.
Calmette distribue alors sa souche à de très nombreux bactériologistes, qui la repiquent de nouveau, donnant ainsi naissance à des centaines de souches « filles ».
Cette même année 1924, les ministères de la Défense nationale et des Colonies décident que les laboratoires de Tananarive, Saïgon et Dakar devront procéder à la vaccination de la population infantile et des troupes indigènes.
Si les vaccinations débutent effectivement dès 1924-1925 à Madagascar et en Indochine, l'Institut Pasteur de Brazzaville ne commence les premiers essais de vaccination qu'en septembre 1930,.Benjamin Weill-Hallé et Raymond Turpin effectuent des vaccinations à l’École de puériculture de Paris.
Entre 1925 et 1927, Couvelaire vaccine à Baudelocque : 305 nouveau-nés.Entre septembre 1926 et août 1927 la Compagnie des mines de Béthune vaccine 850 enfants.
En 1927, Calmette publie une étude faite sur 21 200 enfants vaccinés qui conclut à l'efficacité du vaccin.
Ces publications de l'année 1927 rencontrent très rapidement des critiques, en France d'abord où le Dr José Lignières remet en question l'innocuité totale du BCG, mais aussi à l'étranger avec le Britannique Greenwood et le Suédois Arvid Wallgren qui soulignent, eux, la fragilité des preuves statistiques de Calmette (Wallgren fut cependant un promoteur actif du BCG en Suède).Dès 1925, au Canada, le Conseil de la recherche médicale met en place l'Associate Committee for research on tuberculosis and BCG pour étudier tant l'utilisation humaine que vétérinaire.
A. Baudouin initie des essais cliniques en 1925.
Armand Frappier y conduit également des recherches.En 1927, Petroff affirme avoir réussi à isoler d'une culture BCG une variante virulente.
Les travaux de Petroff reçoivent un écho important et suscitent de nombreuses études en Europe (on objectera aux résultats de Petroff une possible contamination accidentelle ; le décès de Petroff de tuberculose apportera un argument à cette hypothèse).
Entre 1927 et 1941, la Fondation Rockefeller, en lien avec l'Henry Phillips Institute et l'université de Pennsylvanie, conduit un programme en Jamaïque ; y est notamment étudié un vaccin expérimental élaboré à partir de bacilles tués par la chaleur (contrairement au BCG qui est un vaccin dit vivant, c'est-à-dire atténué).
D'abord effectuée sur des malades mentaux, après que son innocuité ait été testée sur des cobayes, l'essai clinique est étendu à 11 000 personnes de Kingston.À partir de 1927, Olaf Scheel et Johannes Heimbeck de l'hôpital de l'école d'infirmière Ullevaal Hospital à Oslo, conduisent deux programmes de vaccinations distincts chez des élèves infirmières (respectivement jusqu'en 1936 et 1939).
C'est la première fois que le vaccin était proposé en injection à des adultes.
Ces études, critiquées pour n'avoir pas recouru à des groupes de contrôle, ont été d'une très grande importance : c'est sur la base de leurs résultats que le programme norvégien de vaccination BCG d'après guerre fut conçu ; il servit de référence à d'autres pays,.La vaccination ne se développe que lentement en France dans les années 1920 (en Scandinavie en revanche elle se généralise plus facilement).
Elles sont à ce moment surtout le fait des dispensaires et des services hospitaliers.En 1928, Ludwik Rajchman le directeur d'une agence sanitaire de la Société des Nations convie à Paris une conférence au sujet du BCG.
Présidée par Émile Roux, elle organise son travail autour de trois commissions, clinique, vétérinaire, bactériologique.
La conférence confirme sans hésitation l'innocuité du vaccin.
Concernant son efficacité en revanche, elle est moins affirmative ; d'après ses conclusions le vaccin engendre seulement « un certain degré d’immunité »,.
La commission, qui a accordé toute son attention aux arguments d'ordre statistique développés par Greenwood, assortit son avis de recommandations devant guider ultérieurement la recherche.
Est notamment recommandée l'introduction, lors des essais, de groupes de contrôle.
La même année, une commission vétérinaire internationale, comprenant l'Italie, les Pays-Bas, l'Autriche, la Pologne, l'Allemagne et la France, préconise d'étendre la vaccination BCG au bétail.En 1930, éclate le drame de Lübeck : sur 251 enfants vaccinés, 72 enfants meurent d'une tuberculose généralisée, 131 autres développent une tuberculose clinique avec guérison et 41 ne présentent aucun symptôme mais font une conversion tuberculinique.
Le gouvernement allemand intente un procès contre l'Institut Pasteur.
Léopold Nègre démontre que le BCG n'est pas en cause : une erreur a été commise par le laboratoire qui a préparé le vaccin sur place : il a été accidentellement contaminé.
Le tribunal exonère le BCG et conclut à une contamination accidentelle.
À l'époque, en l’absence de connaissances génétiques, la question d'un retour à la virulence ne peut toutefois être exclu.Le 19 avril 1932, une circulaire du ministre de la Santé publique rappelle « le grand intérêt » de la vaccination par le BCG.En 1933, les recommandations officielles portant sur la lutte contre la tuberculose bovine n’instituent pas l'obligation de la vaccination BCG.
Celle-ci est laissée à la discrétion des éleveurs.En 1935 est créée la Commission du BCG de l'institut Pasteur dont Antoine Marfan est le directeur (Calmette est décédé en 1933).
Cette même année, en réponse aux objections formulées par la commission internationale en 1928, Calmette conçoit, avec l'aide du statisticien Yves Biraud, un programme randomisé avec groupe de contrôle en Algérie, dans la Kasbah.
C'était une entreprise alors novatrice, qui ne sera surpassée en taille d'échantillon que par l’essai sur la streptomycine après la deuxième guerre mondiale.
En 1935 toujours, Aronson et Palmer organisent les premiers essais, au hasard, du BCG dans des réserves indiennes aux États-Unis et en Alaska,, (R. G. Ferguson (en), directeur de la ligue antituberculeuse de la Saskatchewan, conduit des campagnes de vaccination entre 1933 et 1943 chez des enfants aborigènes et des infirmières).Dans les années 1940, Jörgen Lehmann (en) met en évidence l'activité antituberculeuse de l'acide para-aminosalicylique, qui ne commencera véritablement à être utilisé qu'à compter de 1948.En 1944, la Suède légifère.En 1946, la Croix-Rouge danoise organise la vaccination par le BCG en Pologne, Autriche, Hongrie et Yougoslavie ; l’année suivante, elle étend son action aux zones d’occupation américaine et britannique en Allemagne.En 1947, la Norvège rend la vaccination obligatoire pour les personnes testées négatives à la tuberculine.En lien avec l'UNICEF (décision de Lake Success du 12 mars 1948), les organisations de la Croix-Rouge danoise, norvégienne et suédoise fondent l'International Tubercolisis Campaign ou Joint Enterprise, un programme qui se propose d'aider tout pays européen à mener une vaccination pédiatrique de masse et qui s'étendra ensuite à d'autres parties du monde.
L'OMS apporte une aide technique.En juin 1948, le premier congrès international du BCG, organisé à l'Institut Pasteur, admet que le vaccin occasionne une immunité « relative ».En 1949, le Joint Enterprise, le Danish Statens Seruminstitut et l'OMS coordonnent leurs efforts pour étudier différentes questions soulevées à l'occasion des campagnes de vaccination généralisées.Après la guerre, des études de grande ampleur sont menées, suivant des méthodologies distinctes, en Grande-Bretagne et aux États-Unis.En 1950, la vaccination est rendue obligatoire en France.Dans les années 1950 est mise en évidence l'activité antituberculeuse de l'isoniazide, qui commence à être utilisée à partir de 1952.En 1974, le vaccin BCG est intégré par l'UNICEF dans son programme de vaccination infantile.En 1997, dans un document mettant en avant la Stratégie DOTS, l'OMS attribue l'échec de la lutte mondiale contre la tuberculose à plusieurs raisons, dont une « confiance exagérée dans le BCG », avec ainsi des moyens de lutte moindre mis en oeuvre (dépistage, traitement), sans pour autant remettre en cause l'efficacité du vaccin.Le premier nouveau vaccin utilise un vecteur viral présentant l'antigène 85A porté par la souche Ankara de la vaccine (code de ce vaccin MVA85A).
Cette première tentative a déçu dans un essai conduit en Afrique du Sud chez les enfants.
Deux autres vaccins mettant en œuvre des souches de mycobactéries modifiées génétiquement sont en cours d'étude : VPM1002 et MTBVAC.
Les premières évaluations ont été faites chez des enfants pour améliorer la protection vaccinale.La société GlaxoSmithKline a développé un vaccin antituberculeux constitué d'une protéine recombinante :M72.
Cette protéine est dérivée de deux antigènes immunogéniques de Mycobacterium tuberculosis (Mtb32A et Mtb39A).
On associe à cette protéine antigénique un système adjuvant dénommé  AS01.
Ce candidat vaccin est connu sous son nom de code M72/AS01E.
L'étude de phase II a montré une innocuité acceptable et l'apparition d'immunité humorale et cellulaire aussi bien chez des volontaires sains que chez des personnes atteintes du VIH .Un essai portant sur des personnes porteuses de Mycobacterium tuberculosis mais ne présentant pas de symptômes de la maladie, montre que les personnes vaccinées ont une probabilité plus faible de développer une tuberculose .Le BCG est un germe injecté vivant.
Son efficacité est basée sur le principe de l'immunité de surinfection, c'est-à-dire qu'il n'a d'efficacité que tant qu'il reste vivant dans l'organisme (généralement tapi dans un ganglion lymphatique).
Il s'agit d'une immunité à médiation cellulaire.
Cela explique que le vaccin peut « ne pas prendre ».
Dans ce cas, les tests restent négatifs, et une nouvelle vaccination s'impose.
Cela explique aussi que les tests peuvent devenir négatifs (disparition du BCG vivant dans l'organisme).
Il faut alors vacciner de nouveau.En 1921, Benjamin Weill-Hallé procéda à la vaccination par voie orale.
Ce mode d'administration a les faveurs des médecins français jusqu'après l'instauration de l'obligation vaccinale en 1950 alors que les pays scandinaves préconisent dès avant la Seconde Guerre mondiale l'administration par voie sous-cutanée, voire intradermique.
La voie intradermique est initiée par le Professeur Arvid Wallgren en 1927 à Göteborg.
En 1939, le Dr Sol Roy Rosenthal envisage l'administration du BCG par multi-ponction en raison de l’incidence élevée des réactions indésirables avec la voie intradermique.
La voie sous-cutanée occasionnait de nombreux abcès froids qui devaient être aspirés ou traités chirurgicalement ; à compter de 1935, ce mode d'administration est délaissé.En France, la vaccination se pratique actuellement plutôt par scarification (chez les nourrissons) ou par voie intradermique.Sous sa forme fraîche, le vaccin est très fragile car sensible à la lumière et à la chaleur.
Conditionné sous forme desséchée, il se conserve plusieurs mois à +4 °C mais doit être utilisé dans les 24 heures de sa mise en suspension.L’article 9 du décret du 9 juillet 1951 prévoyait : « les sujets soumis à la vaccination obligatoire et qui vivent dans un milieu comportant un risque de contamination, devront, avant la vaccination, être mis à l’abri de la contamination pendant une durée de 2 mois.
» Inapplicable en pratique, cette disposition fut ensuite abrogée.D'après une méta-analyse de 2014, le BCG conserve une efficacité importante contre la maladie, et souligne l'importance de vacciner les enfants dès la naissance.
D'après cette même méta-analyse, il n'existe pas de différence d'efficacité entre les différentes souches de BCG.
Si on étudie l'évolution de la régression de la tuberculose depuis le XIXe siècle dans de nombreux pays, on constate objectivement qu'elle a régressé avant la découverte des antituberculeux, ou de la vaccination.
Les épidémiologistes l'interprètent essentiellement par l'amélioration des conditions d'hygiène et nutritionnelles,,.Les taux d'effets indésirables varient selon la souche du vaccin, la dose et la méthode d'immunisation, ainsi que l'âge du vacciné.Les effets indésirables sont plus fréquents chez les plus jeunes vaccinés et sont généralement associés à une mauvaise technique d'administration et surtout une dilution insuffisante.
Le vaccin actuel est administré par injection intradermique, et non pas intramusculaire.
En France, le flacon BCG comprend 10 à 20 doses de vaccins.Les effets indésirables du BCG sont habituellement localisés (bécégite), bénins et ne nécessitent pas de traitement :C'est lorsqu'il préexiste un déficit immunitaire que s'observent des complications plus graves.Une enquête parrainée par l'Union internationale contre la tuberculose et les maladies respiratoires, a permis de répertorier 10 371 complications à la suite de 1,5 milliard de vaccinations par le BCG chez des adultes et des enfants.En France, le vaccin est d'abord rendu obligatoire, par voie de circulaire, en 1947 pour certains groupes professionnels (élèvesinfirmières ou assistantes sociales, étudiants en biologie et en médecine et pupilles de l’État).
En 1949 des projets de loi, gouvernementaux puis parlementaires évoquent la généralisation de l'obligation.
Celle-ci intervient en 1950 (Loi no 50-7 du 5 janvier 1950).
De 1950 à 2007 pour les enfants scolarisés.
L’obligation de vaccination par le BCG chez l’enfant et l’adolescent a été suspendue officiellement au cours de l'été 2007 (décret no 2007-1111 du 17 juillet 2007), au profit d’une recommandation de vaccination d'une population plus ciblée.Saisi le 22 janvier 2008 par le directeur général de la santé sur l'opportunité du maintien de l'obligation vaccinale chez les professionnels de santé, le Haut Conseil de la santé publique (HCSP) recommande le 5 mars 2010 la levée de l’obligation de vaccination par le BCG pour les professionnels et étudiants des carrières sanitaires et sociales mentionnés aux articles L.3112-1, R.3112-1 C et 2 du Code de la santé publique, accompagnée d’un maintien du test tuberculinique comme test de référence lors de prise de poste.
Le HCSP recommande une vaccination par le BCG, au cas par cas, après évaluation des risques par le médecin du travail uniquement pour les professionnels de santé très exposés tuberculino-négatifs.
Une évaluation de l'impact épidémiologique de la suspension de l’obligation vaccinale par le BCG et mesure de la couverture vaccinale a été faite par l'INVS (publication 2012).Selon l'avis du CSHPF du 9 mars 2007, les enfants à risque élevé de tuberculose et relevant donc d'une recommandation forte de vaccination, sont les suivants :Le CSHPF recommande également la vaccination de tout enfant dont les parents sont demandeurs, sauf contre-indication.Les zones géographiques à forte incidence tuberculeuse sont, d'après l'OMS :Du fait qu'il s'agit d'un germe vivant, le vaccin est contre-indiqué chez les personnes immuno-déprimées, y compris les personnes porteuses du VIH ou celles traitées par corticoïdes ou autres immuno-dépresseurs, ainsi qu'aux personnes porteuses d'affections malignes.Chez la femme enceinte, le vaccin est déconseillé, même en cas de risque de tuberculose.
Dans cette situation, la surveillance radiologique de la future mère permet de détecter des lésions pulmonaires débutantes, et d'introduire après des prélèvements bactériologiques un traitement antituberculeux si nécessaire.
Le but est d'éviter une contamination du nouveau né.
Cet enfant sera à vacciner dès sa naissance par le BCGLe site d'injection ne doit pas être porteur d'eczéma.Enfin, le vaccin est illogique chez les personnes traitées par médicaments antituberculeux.Plusieurs études expérimentales, sur le modèle animal ou humain, ont mis en avant un rôle immunomodulateur des mycobactéries notamment des études ciblant les mécanismes immunitaires de développement des troubles atopiques dans le cadre de l'«Hypothèse hygiéniste».
Il a été postulé puis démontré que l'exposition précoce à Mycobacterium tuberculosis ou à des mycobactéries non-tuberculeuses comme Mycobacterium vaccae diminue le risque d'atopie,.
Le BCG est lui même utilisé comme adjuvant immunologique.On a aussi remarqué que des« vaccins vivants » autres que le BCG (dont le vaccin contre la rougeole ou celui, oral, contre la polio) provoquent chez l'enfant des changements métaboliques et épigénétiques durables qui améliorent la réaction du système immunitaire inné face à d'autres infections que la tuberculose.
Cet effet collatéral des vaccins vivants, a priori positif, est mal compris.
Il semble passer par un processus dit d'« entraînement immunitaire », ; qui pourrait être une sorte de reprogrammation épigénétique d'une partie du système immunitaire.
Le système immunitaire réagit alors mieux et plus rapidement à un large éventail d'infections (pulmonaires notamment) ; au delà de la seule tuberculose et la convalescence serait moins longue.Ainsi :  Le BCG fausse la réaction à la tuberculine, compliquant le dépistage de la tuberculose.
Cela explique, en partie, le choix de santé publique fait aux États-Unis de ne pas systématiquement vacciner les enfants, puisque cela irait à l'encontre de la politique de détection et de guérison des formes latentes de la tuberculose.Toujours aux États-Unis, lorsque le test tuberculinique est positif et que la personne déclare avoir été vaccinée, une radio pulmonaire est systématiquement réalisée pour écarter l'hypothèse d'une infection réelle.À l'origine, vaccin BCG signifie vaccin bilié de Calmette et Guérin.
Cela vient du fait que la souche bactérienne en question a été obtenue par passage sur un milieu bilié comme mentionné ci-dessus.
Ainsi, on parle du vaccin bilié de Calmette et Guérin lorsque l'on parle du vaccin BCG.
Cependant, beaucoup traduisent « Bacille de Calmette et Guérin ».On ne dispose pas d'échantillons des souches originales du vaccin BCG développé par Calmette en 1921 ni même de la souche de Mycobacterium bovis à partir de laquelle il fut développé.Toutes les souches utilisées pour produire le vaccin sont issues de celle préparée entre 1908 et 1921 par Calmette et Guérin.
Ces souches se sont différenciées jusque dans les années 1960/1965, moment à partir duquel les techniques de stockage par lyophilisation stoppèrent ce processus de différenciation.
En 2001 on comptait 18 fabricants de vaccin pour 7 souches utilisées qui se distinguent par leur immunogénicité et par les procédés industriels dont elles sont issues.
Les souches Copenhague, Tokyo (ou tokyo-172 apportée par Kiyoshi Shiga au Japon en 1924), Glaxo et Pasteur sont les plus utilisées.Mycobacterium microti découvert par Wells dans les années 1930, et nommé par lui, vole bacillus, fut nommé plus tard Mycobacterium tuberculosis var.
muris, faute de pouvoir être distingué alors de Mycobacterium tuberculosis.
Un vaccin atténué fut utilisé en Tchécoslovaquie de 1951 à 1969 tandis que des essais furent conduits en Grande-Bretagne de 1950 à 1952 avec des formes non atténuées.Une étude de 2019 a montré qu'une immunisation par voie intraveineuse pourrait considérablement accroitre l'efficacité du vaccin contre la tuberculose (sur le modèle animal ; macaque rhésus) alors que jusqu'ici, le BCG était placée juste sous la peau (voie sous-cutanée).
Ces résultats aident à mieux comprendre les mécanismes de la protection vaccinale contre la tuberculose.
Reste à montrer que cette voie améliorerait aussi l'efficacité vaccinale chez enfants, adolescents et adultes humains, sans effets secondaires inacceptables.Le BCG fait partie de la liste des médicaments essentiels de l'Organisation mondiale de la santé (liste mise à jour en avril 2013).Un bâtiment de l'École nationale vétérinaire d'Alfort (ENVA), inauguré en 2014, a été nommé en l'honneur des créateurs de ce vaccin.
Ce bâtiment s'appelle bâtiment Camille-Guérin (ou BCG).Le 29 juillet 1981, la poste française émet un timbre pour Wallis-et-Futuna dans le cadre de l'anniversaire de la « 1re inoculation du BCG ».
La dessinatrice du timbre est Huguette Sainson.
Un brevet est un titre de propriété industrielle qui confère à son titulaire une exclusivité d'exploitation de l'invention brevetée à compter, en principe, de la date de dépôt et pour une durée maximale de 20 ans.
Un droit de brevet n'est pas un droit d'exploitation, c'est-à-dire autorisant l'exploitation de l'invention brevetée.
En effet, le droit d’exploitation peut être soumis à un autre formalisme tel que l'obtention d'une autorisation de mise sur le marché, une certification, etc.Certains États peuvent au moment de l'inscription fournir un « brevet provisoire » et accorder un « délai de grâce » qui évite la nullité du brevet pour un inventeur ayant exposé son invention avant le dépôt de brevet, dans un cadre non confidentiel.
Ceci présente l'avantage de permettre la diffusion rapide des connaissances techniques tout en réservant l'exploitation industrielle de l'invention, ainsi que quelques inconvénients.
Selon les pays c'est le premier « inventeur » ou le premier « déposant » (en Europe) qui a priorité pour le brevet.Le brevet n'est valable que sur un territoire déterminé, pour un État déterminé.
Il est possible de déposer une demande de brevet auprès d'un État (auprès de l'USPTO pour les États-Unis, de l'INPI pour la France, du JPO pour le Japon…), ou auprès d'un groupe de pays (auprès de l'Office européen des brevets pour 39 pays européens, dépôt d'une demande internationale de brevet pour les 142 pays signataires du Traité de coopération sur les brevets, dite demande PCT).
À la délivrance, le demandeur recevra autant de brevets nationaux que d'États où une protection est recherchée.En contrepartie du droit, pour le titulaire du brevet, d'interdire à autrui de reproduire l'invention sans son autorisation, l'invention doit être divulguée dans le texte du brevet de manière pleine et entière de manière que quiconque puisse la reproduire.
Dans la majorité des cas, les demandes de brevet sont automatiquement publiées à l'issue d'une période de 18 mois à compter de la date de priorité revendiquée la plus ancienne.En Europe, des brevets sur des dispositifs médicaux, des produits pharmaceutiques ou phytosanitaires peuvent être prolongés de cinq ans au plus sous réserve de l'obtention d'un certificat complémentaire de protection (règlement CE 1768/92).
En décembre 2020, dans le cadre de la pandémie de Covid-19, l'Organisation mondiale du commerce débat exceptionnellement sur la libération des brevets sur les vaccins.C'est à Sybaris, en Grèce, qu’est retrouvé un texte similaire aux brevets, la « Loi de Sybaris », rendant publiques des recettes de cuisine mais en réservant expressément la paternité à leur inventeur.
Ce texte datant du VIe siècle av.
est considéré comme le plus ancien régime de protection de propriété intellectuelle.Le plus ancien brevet technique à vocation industrielle connu en Europe est délivré en 1421 à Florence à l'architecte et ingénieur Filippo Brunelleschi, pour un de ses nombreux appareils de levage destiné à la manutention de marchandises transportées par bateau.À la même époque, en 1469, la ville de Venise octroie à un assistant de Gutenberg, pour la durée de sa vie et à l'exclusion de tout autre, un brevet lui réservant le privilège d'imprimer par un système utilisant des caractères mobiles.Durant l'Ancien Régime, les rois de France accordent une certaine protection juridique aux innovations sous forme de lettres patentes réservant à l'inventeur le monopole de l'exploitation de leur invention.En 1791, le droit de propriété intellectuelle de l’inventeur est consacré par les constituants lors de la Révolution française et se traduit par le régime moderne des brevets, un an après les États-Unis.
Les patentes, au sens moderne du terme, sont introduites en droit français sous la Révolution par la loi du 7 janvier 1791, dont les décrets d'application, votés par l'assemblée nationale, sont fixés par la loi du 25 mai 1791.
Le terme « brevet d'invention » se substitue alors à l'appellation « patente », laquelle désigne soit l'impôt que devra acquitter le bénéficiaire en application du décret d'Allarde (contribution des patentes), soit les patentes anglaises.
Un dépôt général est créé sous le nom de Directoire des brevets d'invention, lesquels sont délivrés sous la surveillance et l'autorité du ministre de l'intérieur.
Le demandeur d'un brevet doit en faire la demande auprès du secrétariat de son département.
La réception des dépêches au directoire fait ensuite l'objet d'un procès-verbal.
L'article 6 de ladite lue le brevet (anciennement patente) doit notamment comprendre la description précise ainsi que les illustrations annexées au procès-verbal.
Ledit brevet est enfin scellé puis renvoyé au département du demandeur.
L'article 1er de l'arrêté du Gouvernement du 27 septembre 1800 (5 vendémiaire de l'an IX) dispose enfin que les brevets d'invention, de perfectionnement et d'importation sont délivrés tous les trois mois, et publiés au bulletin des lois.Le monopole d'exploitation conféré par le brevet à son titulaire est un droit exclusif, lui permettant d'autoriser ou d'interdire à tout tiers de produire, d'utiliser, d'importer, d'exporter ou vendre l'invention couverte par le brevet.
Ainsi, le brevet ne constitue pas un droit qui autorise le titulaire à exploiter l'invention, en particulier lorsque celle-ci présente des caractéristiques couvertes par des brevets appartenant à des tiers.Les systèmes des brevets actuels viennent de la période révolutionnaire : les premières lois concernant des brevets d'inventions proprement dits datent de 1790 pour les États-Unis (loi du 17 août 1790 adoptée conformément aux principes posés par la constitution de 1787) et de 1791 pour la France (loi du 7 janvier 1791 adoptée par l'assemblée révolutionnaire).
Les systèmes arbitraires précédents de privilèges et monopoles sont abolis, influencé par les idées de Benjamin Franklin.L'objectif des brevets est de favoriser les développements techniques et industriels en accordant des droits aux inventeurs qui divulguent leurs résultats à la communauté.
Le système est censé promouvoir la recherche en permettant aux inventeurs de se financer en vendant leurs droits aux producteurs ou encore d'inciter un entrepreneur à innover, en espérant que le monopole du brevet lui permettra de récupérer l'investissement consenti en recherche et développement.Pour être brevetable, une invention doit répondre à trois critères :Une quatrième clause retient que la description complète de l'invention et de la manière de la reproduire doit être incluse dans le brevet, de manière que le contenu technique soit disponible lors de la publication de la demande, et à ce qu'à l'expiration du brevet cette technologie soit effectivement disponible dans le domaine public.En outre, certaines dispositions (qui peuvent différer selon les pays concernés) excluent purement et simplement de la brevetabilité certaines catégories d'inventions ou de créations intellectuelles, par exemple les théories scientifiques, les simples découvertes, les inventions contraires à l'ordre public et aux bonnes mœurs (par exemple un nouveau type de lettre piégée), les méthodes thérapeutiques (procédures chirurgicales…) ou encore (en Europe par exemple) les logiciels en tant que tels.
Ces exclusions sont en général justifiées par le fait que, selon la phrase consacrée, « une invention est une solution technique à un problème technique ».
Toutefois, il reste à définir à quoi correspond le terme « technique ».Initialement, seuls existaient les systèmes nationaux de brevets, avec pour conséquence une duplication des tâches des Offices des brevets.
En effet, dans différents pays, ce sont souvent les mêmes éléments de l'état de la technique et les mêmes arguments qui sont invoqués pour mettre en cause la validité des demandes de brevet et en imposer la limitation au cours des procédures officielles d'examen.
Il en résultait également des coûts accrus pour les déposants.L'idée d'un « brevet mondial » ou d'une reconnaissance mutuelle entre différents pays étant peu envisageable, il s'est développé le système du brevet européen, permettant, par le dépôt et l'examen d'une unique « demande de brevet européen », d'obtenir la délivrance d'un brevet européen pouvant exercer ses effets dans un certain nombre de pays européens (« pays désignés ») : le déposant peut désigner n'importe lequel des (actuellement) trente-huit États contractants (les derniers en date étant l'Albanie depuis le 1er mai 2010, et la Serbie depuis le 1er octobre 2010).
Le brevet européen peut également prendre effet, à compter de la délivrance, dans des États non contractants (Bosnie-Herzégovine et Monténégro) qui reconnaissent la validité du brevet délivré sur leur territoire.Ce système, administré par l'Office européen des brevets (OEB), présente cependant deux inconvénients.
Premièrement son coût, de l'ordre de trois à cinq fois supérieur à celui d'un brevet aux États-Unis, en raison principalement de l'obligation imposée par la plupart des pays concernés (et non par la Convention sur le brevet européen) de traduire intégralement un brevet européen, après sa délivrance, dans la (une) langue nationale du pays.
Afin de pallier cette difficulté, le protocole de Londres a proposé la possibilité de ne pas traduire les brevets européens.
À la fin 2008, seule l'Allemagne, l'Angleterre et la France avaient totalement supprimé la nécessité de déposer des traductions des brevets européens dans leurs langues nationales.
Deuxièmement, après la délivrance d'un brevet européen, celui-ci éclate en un « faisceau » de brevets nationaux dans les pays désignés.
Ces brevets nationaux mènent alors (classiquement) des vies totalement indépendantes les unes des autres, dont une conséquence est qu'en cas de contrefaçon dans plusieurs pays, il est généralement nécessaire d'intenter des actions judiciaires parallèles dans chacun de ces pays, sans aucune certitude quant à l'uniformité des décisions qui seront rendues.
Il en résulte un accroissement des coûts et de l'incertitude juridique.
La Convention sur le brevet européen prévoit toutefois un dispositif simple, efficace et de coût abordable offrant aux tiers la possibilité de contester tout brevet européen de manière « centralisée », c'est-à-dire pour tous les pays dans lesquels il a été délivré.
Ce dispositif est la « procédure d'opposition ».
Une opposition à un brevet donné doit être formée par écrit auprès de l'OEB dans les neuf mois qui suivent la date de la mention de la délivrance du brevet européen considéré.
La décision de validité (ou non) d'un brevet européen rendue dans le cadre d'une opposition est susceptible d'appel devant les Chambres de Recours de l'OEB.
Avec plus de 160 000 dépôts par an, le système du brevet européen est cependant un grand succès, malgré ses imperfections.D'autres systèmes de brevets régionaux (au sens de région du monde) sont en place, notamment l'Organisation eurasienne des brevets (OEAB) et deux systèmes africains : Organisation africaine de la propriété intellectuelle (OAPI) et ARIPO.Au niveau international, l'Organisation mondiale de la propriété intellectuelle (OMPI), qui compte 192 États membres, a développé le traité de coopération sur les brevets (Patent Cooperation Treaty, PCT), permettant à travers le dépôt d'une seule demande internationale, d'obtenir une protection provisoire durant une trentaine de mois dans les 152 États contractants du PCT : la date de dépôt de la demande PCT vaut date de dépôt pour tous les pays désignés dans cette demande.
Durant cette période, une recherche préliminaire et un examen préliminaire sont exécutés, ce qui permet au déposant de se faire une meilleure idée quant à la brevetabilité de son invention.
Aucun brevet international n'est cependant délivré à l'issue de cette « phase internationale » ; si le demandeur souhaite toujours obtenir un brevet dans certains des pays désignés dans la demande initiale, il devra engager la « phase nationale » dans chacun de ceux-ci, selon les procédures respectives.
Ce n'est qu'à l'issue de ces procédures nationales que des brevets nationaux (ou éventuellement régionaux) pourront être délivrés, avec éventuellement des portées différentes (en fonction des règles nationales).Pour l'Europe, diverses tentatives ont visé à la création d'un brevet communautaire (initialement sous la forme d'un système intergouvernemental, dernièrement sous la forme d'un système communautaire).
Ce brevet communautaire présenterait l'avantage notable d'être unitaire y compris après sa délivrance, ce qui permettrait la résolution centrale des litiges, avec une certitude juridique nettement plus élevée que dans le système actuel du brevet européen.
La négociation (au niveau du Conseil) de la proposition de Règlement de la Commission se heurte cependant à des objections purement politiques de certains pays, notamment sur le plan des exigences de traduction (malgré l'approbation très large des utilisateurs potentiels), et rien ne permet de prévoir quand un brevet communautaire pourrait finalement être disponible.La Convention de Paris pour la protection de la propriété industrielle (20 mars 1883) ou convention d'Union de Paris (CUP) a instauré entre les États contractants une union, et elle prévoit que tout ressortissant d'un État contractant jouit des mêmes droits en matière de propriété industrielle qu'un national dans tout autre État de l'Union.
Ainsi, un inventeur/ déposant belge jouit devant l'USPTO américain des mêmes droits qu'un Américain.
Et réciproquement en Belgique ; car Belgique et États-Unis sont parties à la CUP, comme actuellement 177 États.La CUP prévoit également un délai d'un an, dit délai de priorité, pour permettre à un déposant qui a effectué un premier dépôt régulier dans un pays de l'Union d'effectuer des dépôts pour la même invention dans d'autres États contractants.
Ces dépôts ultérieurs seront considérés comme déposés le jour du dépôt de la première demande.
Ce premier dépôt s'appelle le dépôt prioritaire, et sa date la date de priorité.
Pour revendiquer par exemple en France la priorité d'un premier dépôt belge, le déposant indique le pays, le n° du dépôt initial, ainsi que la date de priorité.On dit que ces demandes ultérieures bénéficient d'un « droit de priorité » vis-à-vis d'éventuelles autres demandes qui pourraient avoir été déposées après la date de priorité par d'autres personnes pour la même invention.
On ne pourra pas non plus opposer à ces demandes ultérieures des publications postérieures à la date de priorité.
En effet, on doit se placer, pour apprécier la nouveauté et l'activité inventive d'une demande ultérieure sous priorité, à sa date de priorité.Les récentes avancées en informatique ont posé le problème du brevet logiciel et du brevet essentiel.Le 13 juin 2013, la Cour suprême des États-Unis affirme la non brevetabilté de tout ou partie du génome humain car « existant naturellement ».Si deux personnes réalisent indépendamment la même invention, ou si la seconde fait breveter l'invention de la première, deux moyens permettent d'attribuer sa paternité :Un brevet belge n'est valable qu'en Belgique.
Il en existait deux types : le brevet belge d'une durée de validité de vingt ans et celui d'une durée de validité de six ans.
Cependant, cette dernière possibilité du « mini brevet » a été supprimée en 2009.
En effet, toutes les demandes de brevet déposées depuis le 8 janvier 2009 ne peuvent plus bénéficier de cet « avantage ».Un inventeur peut s'adresser à un mandataire pour obtenir une assistance spécialisée pendant le déroulement de la procédure de demande.
Il s'agit d'un spécialiste qui représente le demandeur durant la procédure de demande et l'assiste ensuite dans le suivi administratif du dossier.En droit français, un « droit de possession personnelle antérieure » permet la poursuite de l'exploitation d'une invention à celui qui peut prouver qu'il détenait l'invention, sur le sol français, avant le dépôt de brevet.
Cette preuve peut par exemple être « une enveloppe Soleau, un dépôt notarié ou encore un cahier de laboratoire certifié ».Si les droits acquis par un tiers sur un brevet ne font pas l'objet d'un début de réalisation dans une période donnée, le breveté reprend tous ses droits sur l'invention.
Le législateur a considéré en effet qu'il n'était pas dans l'intérêt général qu'une invention soit mise sous le boisseau par des intérêts privés.
Cette disposition ne fait pas toujours l'affaire des multinationales, qui préfèrent garder des brevets à disposition pour des échanges de licences avec des concurrents.
Elles effectuent un lobbying important pour que cette exception qui fait obstacle à leurs intérêts particuliers disparaisse sous couvert d'« harmonisation européenne ».Enfin, le système de délivrance des brevets était traditionnellement considéré comme dépourvu d'examen.
Les différentes lois (1791, 1844, 1968, 1978) ont donné lieu à des débats concernant ce qui relevait du périmètre de l'administration.
Le législateur a défini les motifs de rejet d'une demande par l'administration via l'article L.
612-12 du code de la propriété intellectuelle, où figure un examen de la nouveauté (dit « manifeste »).
Depuis la loi PACTE, l'examen des demandes inclut les critères de nouveauté, d'activité inventive et d'application industrielle.La procédure couvre les étapes suivantes, de l'invention au brevet :La violation, ou l'infraction au droit exclusif d'exploitation du titulaire du brevet, relève de la compétence du tribunal national du pays dans lequel le brevet est en vigueur.
C'est au titulaire du brevet qu'il incombe de détecter la violation et de la dénoncer.
Toute violation est sanctionnée par un arrêt immédiat des activités qui portent atteinte au brevet, une amende et l'obligation d'indemniser complètement le titulaire du brevet.Le film Un éclair de génie (Flash of Genius) retrace le combat de Robert Kearns pour faire valoir la paternité de son invention, les essuie-glaces à balayage intermittent, qui équipent quasiment tous les véhicules de nos jours.Tout changement dans le statut d'un brevet, comme le transfert de propriété ou l'octroi d'une licence, doit être communiqué à l'office national des brevets.
Pour un brevet belge, il faut informer l'Office de la Propriété intellectuelle.Le maintien en vigueur d'un brevet est conditionné au paiement annuel de taxes.
Le brevet demeure en vigueur aussi longtemps que l'on paie les annuités de maintien.
Il n'est pas possible de renouveler la validité d'un brevet dont on a cessé les paiements.
Sauf rares exceptions, il n'est pas possible non plus de le prolonger à la fin des 20 ans.Le titulaire d'un brevet peut parfois abuser de son droit, de telle sorte qu'il freine l'innovation.
Il peut ainsi sciemment empêcher la diffusion de perfectionnements, selon le phénomène de la tragédie des anticommuns.
L'inventeur de la draisienne aurait par exemple pu employer un brevet pour interdire la vente de bicyclettes par un tiers.
Cependant, une telle démarche n'est pas commercialement raisonnable ; le détenteur du brevet antérieur a intérêt à ce que la bicyclette se développe afin d'obtenir des licences qu'il est en droit de réclamer.Le blocage de l'innovation, lié à une utilisation excessive des brevets, est particulièrement notable dans le domaine des nouvelles technologies, où les plus grandes entreprises de pointe se sont déclaré une guerre des brevets durant l'année 2011, essentiellement aux États-Unis et en Europe.
La plupart des acteurs du secteur sont concernés (Motorola, HTC, Samsung…), mais une bonne partie des plaintes a été émise par ou contre Apple.
Ainsi, plutôt qu'investir dans l'innovation, ces sociétés engagent des frais importants d'avocats et de rachats d'entreprises possédant des brevets afin de maintenir leur produit sur le marché et d'obtenir le retrait de ceux de la concurrence.
Apple a ainsi réussi à faire retirer en juillet 2011 la tablette Samsung Galaxy Tab en Allemagne pour violation des droits d'auteurs du design de son iPad.Pour prévenir ces abus, le droit des brevets contient dans presque tous les pays des dispositions prévoyant l’octroi de licences obligatoires.
Cet octroi est cependant soumis à des conditions restrictives, que des auteurs proposent de réformer dans le contexte de la pandémie de Covid-19.Il a parfois été proposé d'utiliser le brevet comme indicateur de réussite de laboratoires de recherche, voire comme conditions de subventions aux universités, comme l'a suggéré le 6 août 2014 le ministre australien de l'industrie Ian Macfarlane.
Les détracteurs de ce principe le jugent improductif car freinant l'innovation et étant source d'effets pervers dans le financement de la recherche.
De nombreux chercheurs australiens ont ainsi souligné que la proposition du ministre risquerait de détourner les crédits de la recherche fondamentale vers les projets jugés lucratifs et rentables à court terme.
« L'accent mis sur les brevets pourrait créer des « incitations perverses » », confirme Aidan Byrne, chef de l'Australian Research Council, qui ajoute que le nombre de dépôts de brevets ne doit pas être isolé d'autres indicateurs.
De fait, des pans entiers de la recherche ne débouchent pas directement sur des objets ou recettes brevetables.
L'Histoire a montré que la plupart des grandes découvertes exploitées par l'industrie proviennent de la recherche fondamentale et de trouvailles inattendues, qui n'auraient pas été financées si l'on n'avait financé que ce que l'on pensait commercialement exploitable, a expliqué Les Field (secrétaire chargé de la politique scientifique à l'Académie australienne des sciences et vice-chancelier adjoint de l'Université de New South Wales de Sydney) au journal The World Today.Face à l’urgence sanitaire due à la pandémie de Covid-19, la question de la libération des brevets des vaccins pour le bien commun se pose.
Cette idée fait l'objet de plusieurs appels mais se heurte aux contraintes de la propriété intellectuelle, protégée par les brevets déposés par les entreprises.En décembre 2020, l'Organisation mondiale du commerce (OMC) débat sur le caractère brevetable des vaccins anti-Covid.
Selon Leena Menghaney, de la Campagne d'accès aux médicaments de Médecins sans frontières, cette exemption des droits de propriété intellectuelle sur les vaccins anti-Covid permettrait d'« augmenter la production dans de très nombreux pays en développement qui en ont la capacité ».
A contrario, selon un représentant du groupe d'intérêts des groupes pharmaceutiques, « La propriété intellectuelle encourage un modèle commercial d'innovation fort.
Nous n'aurions pas eu la possibilité d'avancer aussi rapidement dans le développement de traitements ou de vaccins sans le système de propriété intellectuelle.
» En mai 2021, emmenés par l’Inde et l’Afrique du Sud, une centaine d’États demandent à l'OMC la levée des droits de propriété intellectuelle sur les vaccins contre le Covid-19 afin de réduire l’écart qui se creuse entre les pays riches et les nations les plus pauvres pour la vaccination de leurs populations.
Le Parlement européen et, fait marquant, les États-Unis également soutiennent la suspension de ces brevets pour accélérer la production mondiale.Selon l’économiste Philippe Askenazy le débat sur la nationalisation de la propriété intellectuelle sur les vaccins, « biens communs de l’humanité » n’est pas nouveau.
un décret sous Napoléon Ier en 1810 en porte la trace.
Les « inventeurs ou propriétaires de remèdes ou compositions dont ils ont seuls la recette  remettront avec une notice des maladies auxquelles on peut les appliquer, et des expériences qui en ont été déjà faites »...« Un traité avec les inventeurs (…) sera homologué en notre Conseil d’Etat, et le secret publié sans délai.
»Selon l'avocat Matthieu Dhenne, cette « libération » des brevets relatifs aux vaccins constitue un faux débat, dans la mesure où le système de la licence d'office, qui est prévu à l'article 31 de l'accord sur les ADPIC conclu au sein de l'OMC (repris en substance à l'article L.
613-16 du Code de la propriété intellectuelle) permet déjà une limitation de l'exercice du droit de brevet, afin qu'il soit conforme à l'intérêt de la santé publique,.
Il conviendrait cependant d'engager la procédure de la licence d'office, après l'avoir réformée un minimum (afin de la rendre effective).
Une telle réforme de la licence d'office a déjà été recommandée par un rapport de l'Institut de Boufflers de mai 2020 puis par une tribune collective rassemblant 16 spécialistes du droit des brevets et du droit de la propriété.
Une proposition de loi déposée au Sénat le 8 avril 2021 fait suite à ces recommandations.En juin 2022, l’OMC entérine un accord à minima sur la levée des brevets sur les vaccins contre la Covid-19.
Il donne le droit aux pays en développement d'accorder des licences de production pour les vaccins à des fabricants locaux en se passant de l’autorisation des titulaires des brevets.Dans les pays anglo-saxons se développent les patent trolls, ou « chasseurs de brevets » en français, des compagnies, personnes morales ou physiques qui utilisent la concession de licence et le litige de brevets comme principal modèle économique.
Les chasseurs de brevets achètent des brevets non pas pour innover, mais pour multiplier les contentieuxEn France, la profession de conseil en propriété industrielle (CPI) est une profession réglementée.
Le conseil en propriété industrielle propose, à ses clients, des consultations juridiques dans le domaine de la propriété industrielle et peut également les représenter auprès de l'INPI.
Seule une personne inscrite sur la liste des personnes qualifiées en matière de propriété industrielle (mention brevets d'invention et/ou marques, dessins et modèles) peut prétendre à l'exercice de la profession de conseil en propriété industrielle et à l'usage du titre.
L'inscription sur la liste des CPI est conditionnée par la réussite à un examen organisé par l'INPI.
Pour pouvoir s'inscrire à cet examen, le diplôme du CEIPI ou équivalent est obligatoire ainsi que trois années d'exercice professionnel en France sous la tutelle d'une personne ayant déjà réussi cet examen en brevet ou marque selon le cas.
Le CEIPI, situé à Strasbourg, est un des organismes habilités à délivrer un diplôme permettant de s'inscrire à l'examen de CPI de l'INPI, au même titre que les masters de droit en PI (par exemple de Paris-II ou de Paris-13).
Il faut auparavant avoir réussi un diplôme national de second cycle juridique, technique ou scientifique.
En France, le conseil en propriété industrielle ne peut représenter de client devant les tribunaux.En France, l'avocat a le monopole de la représentation, à titre libéral, devant les tribunaux.
Il peut également représenter les intérêts de ses clients auprès de l'INPI ou de l'OEB.
Toutefois, certains avocats font le choix de concentrer leur activité sur les contentieux judiciaires liés aux brevets d'invention : actions en contrefaçon, en annulation de brevets ou encore en revendication de propriété.Il existe plusieurs associations pour les inventeurs dont les activités ont pour but d'aider les nouveaux inventeurs à breveter leurs innovations et de fournir des informations.
Au Canada, il y a la Fédération des Inventeurs du Québec, en France, la Fédération nationale des inventeurs.À chaque brevet sont associées des informations sur la nature de l'invention à protéger (description technique), les dates de dépôt et de publication, la liste des inventeurs et déposants ayant participé au brevet, éventuellement le ou les brevet(s) parent(s), les technologies…Il est possible de « suivre » l'histoire d'une technologie ou d'une invention.
À partir d'un premier dépôt de brevet fixant les principes fondamentaux d'une invention ou amorçant l'embryon d'une technologie, il est fréquent qu'au fil du temps ce premier brevet soit complété ou qu'il soit étendu à d'autres offices afin d'élargir la protection.Les références ainsi construites doivent être mentionnées dans le document du brevet, elles permettent de construire l'historique d'une invention.
Les brevets cités sont des brevets prioritaires (donc antérieur dans le temps au brevet qui mentionne cette priorité).
L'ensemble formé par ce jeu de priorités est nommé une famille de brevets.
Le ou les premiers brevets déposés dans une famille n'ont donc pas de priorité.Face aux millions de brevets déposés et à l'hétérogénéité des procédures administratives, il existe plusieurs méthodes pour construire les familles de brevets :Les familles INPADOC sont un exemple de la seconde catégorie.
INPADOC qui signifie International Patent Documentation Center, a été fondée par l'Organisation Mondiale de la Propriété Intellectuelle (OMPI) et le gouvernement Autrichien en vertu d'un accord le 2 mai, 1972.
Vingt ans plus tard, elles ont été intégrées dans l'Office européen des brevets.L'invention de produit consiste en un objet matériel qui se distingue par les caractéristiques de sa constitution, notamment par sa composition, sa structure ou sa forme.
Exemple : une prothèse de genou.L'invention de procédé concerne tout facteur ou agent qui conduit à l’obtention d’un résultat ou d’un produit.
Exemple : un procédé de fabrication des médicaments.L'invention d'applications consiste à imaginer d'user de moyens connus pour parvenir à un résultat qui peut fort bien être connu mais dans un rapport nouveau.
Exemple : utiliser un produit connu comme insecticide alors qu'il n'était pas prévu pour cela.L'invention de combinaison concerne le groupement non encore réalisé, dans son agencement ni dans ses constituants, de moyens connus en eux-mêmes dès lors qu'ils coopèrent les uns avec les autres pour l'obtention d'un résultat industriel.
Exemple : la brouette est constituée de trois éléments qui coopèrent entre eux pour un résultat unique qui est différent des résultats de chacun des trois éléments: la roue, le caisson et le levier.L'invention d'usage consiste en un effet technique qui apporte un bénéfice d'utilisation.
Cette catégorie, d'ordre stratégique plutôt que juridique, précise les catégories précédentes.
Exemple : produire un effet de zoom par l'écartement de deux doigts sur un écran tactile de tablette informatique.La Classification internationale des brevets (CIB).Initiée par l’Arrangement de Strasbourg de 1971, le 1er juillet 2008, cinquante-huit États en étaient parties prenantes.
Mais « dans la pratique, toutefois, la CIB est utilisée par les offices de propriété industrielle de plus de 100 États, par quatre offices régionaux, ainsi que par le Bureau international de l’OMPI, dans le cadre du Traité de coopération en matière de brevets (PCT) ».Cette classification est un système hiérarchique divisant les technologies en huit sections (le niveau le plus général avec, par exemple : « Techniques industrielles, Transports » ou « Chimie, Métallurgie »…), classes, sous-classes et groupes.
Elle est commune pour les brevets, les modèles d’utilité et les certificats d’utilité, et est utilisée par de nombreux pays.
Son objectif est de faciliter les recherches sur les millions de brevets en proposant une entrée par les technologies.
Le résultat est qu'à partir des listes des codes IPC associées à chaque demande de brevet, il est possible de connaître les technologies reprises par l'invention et de mieux apprécier l'activité inventive.Une étude, visant à simplifier les comparaisons technologiques au niveau national en s'appuyant sur les codes IPC, a produit une classification en cinq domaines technologiques subdivisés en 35 champs.
Elle montre que le domaine le plus représenté en 2005 est celui de la pharmaceutique.
En associant cette classification avec d'autres informations (déposants, localisations des inventeurs, information financière sur les groupes déposants…), les possibilités d'analyses sont importantes.
En allant dans ce sens, une équipe de recherche a publié le classement des 2 400 plus grands groupes mondiaux.
Il apparait que dans le domaine de la chimie, le déposant le plus important en nombre de dépôts de brevets prioritaires est le groupe japonais Hitachi Ltd, suivi par le groupe allemand Bayer AG.
À ce niveau d'analyse, il est également possible de connaître en détail la nature de l'activité inventive d'un État (par ses inventeurs ou déposants, ou par le siège social de ses têtes de groupe) ou d'un groupe à travers les portefeuilles de brevets de ceux-ci.
Par exemple, le groupe français Thales SA, entre 1986 et 2005, s'est spécialisé en technologie de l'informatique (et dans une moindre mesure en télécommunication), par contre la proportion du nombre de brevets prioritaires déposés dans les technologies de l'audiovisuel a diminué, alors que dans le même temps la propension du groupe à déposer dans le domaine des instruments (de mesure et en optique) est restée stable.Lorsqu'une entreprise estime que ses concurrents ont peu de chance de percer l'un de ses secrets de fabrication pendant la durée de couverture d'un éventuel brevet, ou qu'elle ne pourra détecter la contrefaçon et faire valoir ses droits, elle peut choisir de ne pas en déposer, ce qui comporte un risque et un avantage :Pour empêcher une prise de brevet sur une invention qui peut être un dispositif ou un procédé, la seule méthode efficace est la publication éliminant ainsi toute délivrance ultérieure d'un brevet sur l'invention divulguée puisque celle-ci ne remplit plus le critère de nouveauté.
Cela n'empêche toutefois pas forcément un tiers de breveter des améliorations ou des développements de l'idée initiale, pour autant que les critères de brevetabilité (nouveauté et activité inventive) soient remplis.Attention, toutefois : la publication (divulgation) abusive de l'invention d'un tiers n'empêchera pas la prise de brevet, des garde-fous existant dans les législations.En juin 2014, s'inspirant du mouvement open source, Tesla Motors décida d'initier un mouvement analogue consistant à renoncer à poursuivre toutes entreprises ou autres qui décideraient d'utiliser en toute bonne foi, précise-t-elle, ses brevets, lesquels concernent le développement de la voiture électrique, et ce, sans exiger de redevance en retour.Une première qui fut suivie moins d'un an plus tard par Toyota qui annonça, début janvier 2015, au salon de l’électronique de Las Vegas qu'elle faisait de même pour quelque 5 680 brevets liés aux piles à combustible.Quelques acteurs industriels (IBM, Sony, Nokia et Pitney Bowes) ont décidé le 14 janvier 2008 d'offrir certains brevets utiles pour la protection de l'environnement, sur une plateforme appelée Eco-Patent Commons (EPEC).
À cette date, environ trente brevets (portant sur l'environnement, l'énergie ou les déchets) sont offerts à tous, sous l'égide du World Business Council on Sustainable Development (WBCSD), ONG qui va gérer cette plate forme, selon la plaquette de présentation de l'opération.La patentométrie (évaluation du nombre de brevets déposés par un acteur, un laboratoire, une université, une entreprise) est parfois utilisée comme indicateur pour le développement d’un secteur (au moins dans le domaine de la R&D), voire pour certains choix d’attribution de budgets ou subvention,Il y a deux moyens importants de mesurer les dépôts de demandes de brevet dans le monde :Par rapport à 2010, les dépôts ont enregistré une hausse de 10,7 % en 2011.
La Chine, les États-Unis d’Amérique et le Japon ont représenté 82 % de la croissance totale ; l’entreprise chinoise ZTE est le plus grand déposant, totalisant 2 826 demandes publiées, suivie de la japonaise Panasonic (2 463 demandes) puis de la chinoise Huawei (1 831 demandes).En 2019, le classement montre un déplacement des demandes de brevets vers l'Asie (plus de la moitié des demandes).
En 2019, la Chine devient le principal déposant, dépassant pour la première fois les États-Unis.
Le géant chinois des télécommunications Huawei Technologies est, pour la troisième année consécutive, le premier déposant, comptant 4 411 demandes.
Les deux entreprises déposantes suivantes sont également asiatiques : Mitsubishi Electric Corporation (2 661) au Japon et Samsung Electronics (2 334) en Corée.
Au total, parmi les dix principaux déposants, on dénombre quatre entreprises chinoises, deux coréennes et une en Allemagne, au Japon, en Suède et aux États-Unis.Selon l’Office européen des brevets (OEB), la Suisse est de loin le pays qui recense le plus de demandes de brevets par habitants, les principaux déposants étant les universités et certains grands groupes.Les dépôts de brevets à l'Institut national de la propriété industrielle (INPI) ont été de 16 707 en 2008 dont 14 742 déposants français.
En 2004, ce chiffre des déposants français était de 14 230.
La très grande majorité des déposants français sont des personnes morales (entreprises par exemple), le nombre de personnes physiques déposants français est en diminution depuis au moins 2004. l'INPI associe aux dossiers de brevets déposés des codes qui permettent de déterminer leurs statuts :Ainsi, en France, un brevet dont le numéro est suivi par la lettre A1 n'a pas encore été validé.
L'information est disponible sur le site de Institut National de la Propriété Industrielle(INPI).
Des codes équivalents existent dans chaque pays.La loi Pacte, votée en 2019, permet en France de contester, partiellement ou totalement — sans passer par la voie judiciaire, et pour tout tiers —, la délivrance d’un brevet par l'INPI, comme cela se faisait déjà dans d’autres pays ainsi qu'à l’Office européen des brevets.
Dans un contexte de multiplication des demandes de brevet, ceci facilite le repérage et la remise en cause de titres ne respectant pas les conditions de brevetabilité.
L’histologie (du grec ancien ἱστός, « tissu », et λόγος, « discours »), autrefois appelée anatomie microscopique,, est la branche de la biologie et de la médecine qui étudie les tissus biologiques.
Elle se situe au carrefour de la biologie cellulaire, de l'anatomie, de la biochimie et de la physiologie.
Elle a pour objectif d’explorer la structure des organismes vivants, les rapports constitutifs et fonctionnels entre leurs éléments fonctionnels, ainsi que le renouvellement des tissus.
Elle participe à l'exploration des processus pathologiques et de leurs effets.
Aujourd'hui l'histologie est enseignée à travers des lames virtuelles que l'on peut retrouver dans divers sites (ex: Histologie et pathologie des organes).Les prémices de l'histologie adviennent grâce à l'apparition du microscope au XVIIe siècle, bien que ce terme n’advienne que deux siècles après.
Il est utilisé pour la première fois en 1819, par Mayer (en) et Heusinger.L'Italien Marcello Malpighi, professeur de médecine à Bologne et à Pise, est considéré comme le fondateur de l'histologie.
La discipline fut d'abord empirique, grâce au perfectionnement de microscopes simples, alors récemment inventés, permettant l'étude de coupes minces.On doit la notion de tissu biologique à un ouvrage de Xavier Bichat, le Traité des membranes en général et de diverses membranes en particulier (1799).
Les tissus sont alors définis comme des ensembles de cellules ayant des caractères morphologiques analogues.
Leur classification est alors simple :Ces premières études ont permis l’obtention d’une grande quantité d'informations sur les structures biologiques, ce qui a permis l'élaboration de la théorie cellulaire par Matthias Jakob Schleiden et Theodor Schwann, en 1838.
Le terme d'histologie fut utilisé pour la première fois en 1819, par Mayer (en) et Heusinger.La conjonction de la théorie cellulaire et de la mise au point du microscope optique achromatique entraîne la révolution fondatrice de l'histologie.
Après la Seconde Guerre mondiale, les chercheurs du Rockfeller Institute for Medical Research de New York jouent un rôle fondamental avec la description des ultrastructures cellulaires et tissulaires grâce à la microscopie électronique.
Dans les années 1970 et 1980, une histologie moléculaire se met en place, entraînant notamment une rénovation de la nomenclature et un affinement de la description morphologique.Les techniques de biologie cellulaire, de biologie moléculaire, de clonage et de génétique moléculaire ont permis de mieux comprendre le fonctionnement cellulaire et les interactions cellulaires.
Ainsi, si la cellule constitue bien l'unité fondamentale de la structure des organismes vivants, elle se révèle être un ensemble très sophistiqué.
L'histologie moderne considère ainsi la cellule comme une unité fonctionnelle fondamentale.Le règne Animalia contient des organismes multicellulaires qui sont hétérotrophes et mobiles (bien que certains aient adopté secondairement un mode de vie sessile).
La plupart des animaux ont un corps différencié en tissus distincts : ce sont des eumétazoaires.
Ils possèdent une chambre digestive interne, avec une ou deux ouvertures ; les gamètes sont produits dans des organes sexuels multicellulaires et les zygotes comprennent un stade de blastula dans leur développement embryonnaire.
Les métazoaires ne comprennent pas les éponges, qui ont des cellules indifférenciées.Contrairement aux cellules végétales, les cellules animales ne possèdent ni paroi cellulaire, ni chloroplastes.
Les vacuoles, lorsqu'elles sont présentes, sont plus nombreuses et beaucoup plus petites que dans la cellule végétale.
Les tissus de l'organisme sont composés de nombreux types de cellules, notamment celles des muscles, des nerfs et de la peau.
Chacune est composée généralement d'une membrane formée de phospholipides, un cytoplasme et un noyau.
Toutes les différentes cellules d'un animal sont dérivées des couches germinales embryonnaires.
Les invertébrés les plus simples, qui sont formés à partir de deux couches germinales d'ectoderme et d'endoderme, sont appelés diploblastiques et les animaux plus développés dont les structures et les organes sont formés à partir de trois couches germinales sont appelés triploblastiques.
Tous les tissus et organes d'un animal triploblastique sont dérivés des trois couches germinales de l'embryon : l'ectoderme, le mésoderme et l'endoderme.Les tissus animaux forment quatre types fondamentaux : les tissus conjonctifs, épithéliaux, musculaires et nerveux.Les tissus conjonctifs sont fibreux et constitués de cellules dispersées dans un matériau inorganique appelé matrice extracellulaire.
Le tissu conjonctif donne sa forme aux organes et les maintient en place.
Les principaux types sont le tissu conjonctif lâche, le tissu adipeux, le tissu conjonctif fibreux, le cartilage et l'os.
La matrice extracellulaire contient des protéines, dont la principale et la plus abondante est le collagène.
Le collagène joue un rôle majeur dans l'organisation et le maintien des tissus.
La matrice peut être modifiée pour former un squelette destiné à soutenir ou à protéger le corps.
Un exosquelette est une cuticule épaisse et rigide, rigidifiée par la minéralisation, comme chez les crustacés, ou par la réticulation de ses protéines, comme chez les insectes.
Un endosquelette est interne et présent chez tous les animaux développés, ainsi que chez de nombreux animaux à la structure plus simple.Le tissu épithélial se compose de cellules très serrées, liées les unes aux autres par des protéines d'adhésion cellulaire, avec peu d'espace intercellulaire.
Les cellules épithéliales peuvent être squameuses (plates), cuboïdes ou cylindriques.
Elles reposent sur une lame basale, la couche supérieure de la membrane basale.
La couche inférieure est la lame réticulaire située à côté du tissu conjonctif dans la matrice extracellulaire sécrétée par les cellules épithéliales.
Il existe de nombreux types d'épithélium différents, modifiés pour répondre à une fonction particulière.
Dans les voies respiratoires, il se trouve un type de revêtement épithélial cilié ; dans l'intestin grêle, il existe des microvillosités sur le revêtement épithélial et dans le gros intestin, des villosités intestinales.
La peau est constituée d'une couche externe d'épithélium pavimenteux stratifié et kératinisé qui recouvre l'extérieur du corps des vertébrés.
Les kératinocytes représentent jusqu'à 95 % des cellules de la peau.
Les cellules épithéliales de la surface externe du corps sécrètent généralement une matrice extracellulaire sous la forme d'une cuticule.
Chez les animaux simples, il peut s'agir d'une simple couche de glycoprotéines.
Chez les animaux plus évolués, de nombreuses glandes sont formées de cellules épithéliales.Les myocytes forment le tissu contractile actif de l'organisme.
Le tissu musculaire a pour fonction de produire une force et de provoquer un mouvement, qu'il s'agisse d'une locomotion ou d'un mouvement dans les organes internes.
Le muscle est formé de filaments contractiles et se divise en trois types principaux : le muscle lisse, le muscle squelettique et le muscle cardiaque.
Le muscle lisse ne présente aucune strie lorsqu'il est examiné au microscope.
Il se contracte lentement mais se caractérise par une forte extensibilité.
Il s'observe par exemple dans les tentacules des anémones de mer et la paroi corporelle des holothuries.
Le muscle squelettique se contracte rapidement, sa plage d'extension reste cependant limitée.
Il est visible dans le mouvement des appendices et des mâchoires.
Le muscle strié est intermédiaire entre les deux autres.
Constitué de filaments décalés, il permet aux vers de terre de s'étendre lentement ou d'effectuer des contractions rapides.
Chez les mammifères, les muscles striés se présentent en faisceaux attachés aux os pour assurer le mouvement et sont souvent disposés en ensembles antagonistes.
Les muscles lisses se trouvent dans les parois de l'utérus, de la vessie, des intestins, de l'estomac, de l'œsophage, des voies respiratoires et des vaisseaux sanguins.
Le muscle cardiaque est présent uniquement dans le cœur, ce qui lui permet de se contracter et de pomper le sang dans tout le corps.Le tissu nerveux est composé de nombreuses cellules nerveuses appelées neurones qui transmettent des informations.
Chez certains animaux marins à symétrie radiale et à déplacement lent, comme les cténophores et les cnidaires (y compris les anémones de mer et les méduses), les nerfs forment un réseau nerveux, mais chez la plupart des animaux, ils sont organisés longitudinalement en faisceaux.
Chez les animaux simples, les neurones récepteurs de la paroi corporelle provoquent une réaction locale à un stimulus.
Chez les animaux plus complexes, des cellules réceptrices spécialisées, comme les chimiorécepteurs et les photorécepteurs envoient des messages à d'autres parties de l'organisme le long de réseaux neuronaux.
Les neurones peuvent être reliés entre eux dans des ganglions.
Chez les mammifères, les récepteurs spécialisés sont à la base des organes des sens et il existe un système nerveux central (cerveau et moelle épinière) et un système nerveux périphérique.
Ce dernier se compose de nerfs sensoriels qui transmettent les informations provenant des organes des sens et de nerfs moteurs qui influencent les organes cibles.
Le système nerveux périphérique se divise en deux parties : le système nerveux somatique, qui transmet les sensations et contrôle les muscles volontaires, et le système nerveux autonome, qui contrôle involontairement les muscles lisses, certaines glandes et les organes internes, dont l'estomac.Il existe de nombreuses techniques histologiques.Les prélèvements, quels qu'ils soient doivent être effectués avec le plus grand soin, car leur qualité conditionne directement les possibilités d'étude.Il existe également des techniques de prélèvement plus sophistiquées : par excision, microdissection.
Des prélèvements sont fréquemment réalisés au cours d'une opération, et sont étudiés directement au bloc opératoire en extemporané par cryostat.Afin de conserver l'échantillon dans un état le plus proche possible de l'état in vivo, deux moyens de conservation peuvent être utilisés :Les organes, trop gros pour laisser passer la lumière nécessaire à la microscopie optique, doivent encore être découpés en lamelles extrêmement fines par un appareil appelé microtome.
Pour cela, on les enrobe dans de la paraffine ou une résine, selon l'épaisseur souhaitée de la coupe.
On distingue plusieurs types de coupe selon la méthode de conservation et d'amincissement suivie :Les coupes de 0,05 μm seront analysées en microscopie électronique tandis que les autres seront observées en microscopie optique.Les tissus biologiques présentent en eux-mêmes très peu de contraste, aussi bien en microscopie optique qu’en microscopie électronique.
La coloration est utilisée aussi bien pour augmenter le contraste que pour mettre en valeur l’une ou l’autre structure en particulier.De nombreuses techniques de coloration ont été découvertes de façon fortuite.
Dans un certain nombre de cas, le lien spécifique entre la coloration et la nature du tissu n’est toujours pas connu actuellement (charges ioniques des molécules du colorant, taille des molécules du colorant ?
).Parmi ces techniques, on peut citer les trichomes et la méthode de Van Gieson (hématoxiline ferrique, acide picrique, fuchsine acide).On parle d’histochimie quand la coloration se fonde sur des réactions chimiques connues entre des réactifs de laboratoire et des composants des tissus étudiés.
Par exemple lors d’une coloration à l’hématoxiline-éosine, l’éosine qui est un acide se fixe préférentiellement aux molécules basiques et permet donc de colorer le cytoplasme cellulaire (végétal ou animal), alors que l’hématoxyline, qui est une base, colore les noyaux cellulaires en se fixant préférentiellement aux acides nucléiques.
La coloration par le Periodic Acid-Shiff (PAS) permet de colorer de nombreux glucides par rupture des ponts carbone-carbone des 1,2-glycols par l’acide périodique qui est un agent oxydant.
La rupture de ces ponts produit des dialdéhydes qui réagissent avec le réactif de Shiff (fuchsine, acide sulfurique) pour donner un composé magenta vif.La distribution tissulaire de certaines enzymes spécifiques peut être étudiée sur des coupes fraîches en y ajoutant un substrat spécifique de cet enzyme.
L’enzyme réagit alors avec ce substrat pour former un produit de réaction primaire, insoluble et pouvant être mis en évidence par une coloration appliquée d’emblée ou dans un second temps.La plupart des systèmes enzymatiques étant détruits lors de la fixation, les méthodes d’histochimie enzymatique sont le plus souvent réalisées sur coupes en congélation.Ces techniques permettent de détecter un grand nombre d’enzymes s’exprimant de façon pathologique dans certains tissus.Les échantillons de tissus peuvent être colorés par des techniques radiographiques.
Les deux usages les plus courants sont le marquage des cellules en phase S de la mitose par incorporation lors de la réplication de l'ADN de thymidine tritiée et l’hybridation in-situ.Le marquage peut être révélé par visualisation sur microscope à fond noir des grains d’argent formés par réaction du rayonnement radioactif sur une plaque photographique.Cette technique tend à être remplacée par l’immunohistochimie.Des anticorps spécifiques sont utilisés pour venir se fixer à une molécule de la coupe histologique.
Ces anticorps polyclonaux, produits chez l’animal à partir de la protéine purifiée, seront porteurs d’un marqueur, le plus souvent fluorescent.
Cette technique tend à faire disparaître l’historadiographie.Les échantillons sont alors examinés sous microscope à fluorescence.Actuellement, la classification cellulaire repose sur le regroupement des cellules sur la base de leur fonction principale.
Ci-dessous, est exposée la classification fonctionnelle des cellules animales.Un tissu est un ensemble de cellules organisées de manière spécifique.
Un assemblage de cellules ayant toutes la même structure forme un tissu simple.
Dans la majorité des cas, on observe un mélange de différentes cellules et de matrice extracellulaire.
Ceci forme un tissu composé.Les tissus forment ensemble des organes, prenant place dans un appareil (ou système).
Un organe est donc un groupe anatomiquement distinct de tissus de plusieurs types, qui remplissent des fonctions spécifiques.
Un appareil est un groupe de cellules ou d'organes qui ont des fonctions analogues ou proches.
L'Organisation mondiale de la santé (OMS) est une agence spécialisée de l'Organisation des Nations unies (ONU) pour la santé publique créée en 1948.
Elle dépend directement du Conseil économique et social des Nations unies et son siège se situe à Pregny-Chambésy, dans le canton de Genève, en Suisse.Selon sa constitution, l'OMS a pour objectif d'amener tous les peuples des États membres et partenaires au niveau de santé le plus élevé possible, la santé étant définie dans ce même document comme un « état de complet bien-être physique, mental et social et ne consistant pas seulement en une absence de maladie ou d'infirmité ».Depuis le 1er juillet 2017, le directeur général de l’institution est Tedros Adhanom Ghebreyesus,.Vers 1850 différents dispositifs sont pris afin de mettre en place des mesures de quarantaines principalement destinées à protéger les États européens contre la peste.
En 1851, la première conférence sanitaire internationale a lieu à Paris, regroupant 12 États, qui discute d'une convention sanitaire internationale signée en janvier 1852 pour lutter contre la peste, la fièvre jaune et le choléra.
Cependant cette convention n'est ratifiée que par la France et la Sardaigne, puis par le Portugal, avant d'être abandonnée.
Plusieurs autres conférences suivent, sans résultats.En 1892, la septième conférence, à Venise, permet la signature d'une convention sanitaire internationale sur le choléra.
En 1897, une convention sanitaire internationale sur la peste est signée à son tour.
En 1903, une conférence met en place la convention sanitaire internationale regroupant ces deux dernières.
Cette conférence se fixe également pour objectif de créer une institution internationale en matière de santé.
En 1907, « l'Office international d'Hygiène publique » (OIHP) est créé à Rome et doté d'un secrétariat permanent ainsi que d'un « comité permanent ».
Ce comité organise plusieurs conférences au cours des années suivantes.
L'OIHP est à sa création composé de 12 nations, sa langue officielle est le français et son siège à Paris.
Elle a pour fonction d'assurer la surveillance et la lutte de la peste, du choléra et de la fièvre jaune.
Petit à petit l'OIHP obtient des mandats sur des nouvelles maladies, par exemple la tuberculose.
En 1926, la conférence de l'OIHP adopte une nouvelle convention sanitaire internationale étendant ses dispositions à la variole et au typhus.
Durant la Première Guerre mondiale, l'OIHP concentre ses compétences sur les traumatismes liées à la guerre.En 1902, le Bureau sanitaire panaméricain est fondé, notamment pour l'échange de donnés épidémiologiques et pour coordonner la lutte contre les épidémies.
Ses fonctions sont renforcées en 1924 par le Code sanitaire panaméricain.À la fin de la Première Guerre mondiale, un certain nombre de pays, et des personnalités influentes au sein de la communauté internationale comme Camille Barrère, s'opposent à ce que l'OIHP passe sous le contrôle de la toute nouvelle Société des Nations (SDN).
La grippe espagnole de 1918-1919, qui fit, selon les sources, entre 30 et 100 millions de morts (plus que la Première Guerre mondiale), pousse la SDN à créer en 1923 le « comité d'hygiène » de la SDN, considéré comme l'ancêtre de l'OMS.
Dominée par la France et le Royaume-Uni, la surveillance sanitaire du Comité couvre, à la fin des années 1920, 70 % du globe.
Le comité d'hygiène se développe dans les domaines et maladies où l'OIHP n'est pas active comme le cancer, la malaria ou la lèpre, avec des compétences techniques plus importantes que l'OIHP.
Les deux institutions coopèrent sur quelques sujets.Jusqu'à la Seconde Guerre mondiale, trois organismes sanitaires internationaux coexistent : deux en Europe, l'OIHP et l'Organisation d'Hygiène de la Société des Nations, tandis qu'aux États-Unis, l'Organisation sanitaire panaméricaine (PAHO) constitue le troisième organisme international de santé.
Durant la Seconde Guerre mondiale, les Alliés créent un comité inter-allié sur les questions sanitaires et de secours, qui sera en 1943 remplacé par l'Administration des Nations unies pour le secours et la reconstruction, basée à Washington.
Cette dernière institution obtient notamment des compétences sur la formation et l'organisation médicale, la fourniture de matériel médical, avec une approche principalement médicamenteuse.À la Conférence de San Francisco en 1945, l'inclusion de la santé dans les domaines de compétence des Nations unies est abordée, pour rapidement se diriger vers la création une organisation spécialisée dans ce domaine.
En 1946, une commission technique rassemble des experts de certains pays ainsi que des représentants d'autres organisations de santé déjà en place.
En 1946, une conférence internationale met en place la Constitution de l'OMS , adoptée à New York par la Conférence mondiale de la santé le 22 juillet 1946.
Elle a été signée par les représentants de 61 États et est entrée en vigueur le 7 avril 1948, à la suite de la ratification du 26e membre,.
Entre 1946 et 1948, une commission intermédiaire règle l'intégration des organisations de santé au sein de l'OMS, tel que l'OIHP, l'Organisation d'hygiène de la société des nations, l'UNRRA et le Bureau sanitaire panaméricain et gère l'articulation avec l'ONU et ses autres agences, comme la FAO.
Elle prépare également la première assemblée générale qui définit les agences régionales et la localisation du siège de l'OMS.
En juin 1948, la première assemblée générale se tient à Genève, ville choisie comme siège, en regroupant 53 membres, 9 observateurs et de représentants de plusieurs organisations tel que l'ONU ou l'Organisation panaméricaine de la santé.
Les bureaux régionaux sont créés entre 1949 et 1952, celui de l'Europe est créé en 1951.À la différence des institutions qui la précèdent, l'un des objectifs principal de l'OMS à sa création est d'élever le niveau de santé de la population mondiale et non plus uniquement de ses pays membres, notamment les pays occidentaux.
Cet objectif se retrouve dans sa constitution.
À sa création, l'OMS détermine un certain nombre d'axes d'action, tels que : l'assistance technique pour les états en demande, l'organisation d'accords internationaux, de normes et de typologies en matière de santé, le soutien à la recherche et à la formation médicale, le recoupement des données statistiques à l'échelle mondiale.
Ces axes d'actions thématiques doivent répondre aussi à des priorités sanitaires, notamment le paludisme, la santé de la mère et de l'enfant, la tuberculose, l'alimentation et les MST.En 1950, à la suite de la découverte des antibiotiques, l'OMS conseille les pays pour un usage adapté.
La même année, l'ONU effectue une campagne contre la tuberculose avec une inoculation massive du vaccin BCG, s'appuyant sur le service d'information épidémiologique par télex mis en place à partir de 1947.
Entre 1952 et 1964, une campagne portant sur une injection unique de pénicilline contre le pian réduit drastiquement la portée de cette maladie.
En 1952, l'OMS débute les campagnes mondiales de vaccination contre la poliomyélite aboutissant à sa quasi-éradication.
En 1955, l'OMS débute un programme de lutte contre le paludisme, qui n'atteint pas ses objectifs.
À la suite de l'échec relatif attribué au manque de ressources et au défaut d’observance, l’accent a été porté sur les initiatives locales, la santé communautaire ainsi que sur l’implication des usagers et de la société civile .
Les années 1960 sont marquées par les thématiques de la décolonisation et du manque de moyen des pays en développement, qui induit la relocalisation de ressources vers ces besoins, notamment en termes de formations de personnels.
En 1963, un programme de vaccinations contre la rougeole est mis en place.
En 1969, le premier règlement sanitaire international est créé pour la surveillance de 6 maladies infectieuses graves : choléra, peste, fièvre jaune, variole, fièvre récurrente et typhus.
En 1972, un programme est promulgué visant à améliorer la santé sexuelle et reproductive.En 1958, Viktor Zhdanov, vice-ministre de la Santé de l'URSS, demande à l'OMS de lancer une initiative mondiale visant à éradiquer la variole, qui a abouti à la résolution WHA11.54.
À cette époque, 2 millions de personnes mouraient de la variole chaque année.
Lancé en 1959 à l'initiative des pays communistes, avec une accélération à partir de 1967 et jusqu'en 1977, le programme d'éradication de la variole enregistre d'importants progrès,.
En 1979, la variole est éliminée.Dans les années 1970, des programmes de lutte contre le pian, la tuberculose et la bilharziose rencontrent un certain succès, alors que des préoccupations nouvelles apparaissent concernant le choléra, la peste et les MST.Halfdan Mahler élu directeur général en 1973 a donné la priorité à la médecine sociale : considérer la santé plutôt que les maladies, utiliser du personnel médical qui ne soit pas nécessairement titulaire d'un diplôme de médecin dans les interventions sanitaires, inscrire la santé dans un ensemble comprenant l’éducation, la gestion de l’eau et l’alimentation, le tout dans le cadre de la lutte contre la pauvreté.
Les médicaments destinés aux soins de santé primaire ont la priorité.
Cette orientation concerne tant les pays développés, où les frais de médicaments s’envolent souvent, entraînés par une surconsommation ou une mauvaise utilisation, que les pays du Sud.
En 1974, un programme de vaccination mondiale infantile est lancé,.
La même année, une campagne contre l'onchocercose est lancée.
En 1975, une campagne de lutte contre les maladies tropicales est lancée à son tour, ciblant particulièrement 8 de ces maladies.
En 1977, l’OMS publie une liste de substances peu coûteuses permettant de traiter les maladies à forte prévalence.
En 1978, l'OMS, au travers de la déclaration d'Alma-Ata, élabore d'une nouvelle stratégie appelée "Santé pour tous" pour l'an 2000 fixant les bases de la revendication actuelle de l'OMS pour une couverture sanitaire universelle,.
Cette déclaration fixe des principes comme l'égalité des droits au soin, la participation de la population, l'importance de la prévention, d'une approche holistique tant scientifique qu'économique.
Elle définit la notion de soins primaires, qui fonde ses axes d'action sur l'éducation à la santé, une bonne alimentation, l'accès à l'eau potable et à l'assainissement, la santé de la mère et de l'enfant, la vaccination contre les maladies infectieuses, le contrôle des épidémies et des pandémies, les soins médicaux courants et l'accès au matériel médical.
En 1979, la variole est déclarée comme éradiquée.Certains auteurs considèrent qu'à partir des années 1980, l'OMS connut une certaine « traversée du désert » en raison de choix contestables (quasi-démantèlement du Bureau sur la tuberculose) et de l'hostilité de certains pays (États-Unis, Royaume-Uni) opposés à ce qu'ils considéraient être une politique coûteuse.
L’industrie pharmaceutique a contesté tant la composition de la liste de médicaments essentiels que le principe même de son établissement.
Elle la considérait comme un obstacle à l’optimisation des soins médicaux et au progrès.
En 1979, l’OMS augmentait la liste à 300 médicaments et ne la préconisait plus que pour le Sud.
Avant 1987, le premier médicament antirétrovial est homologué par l'OMS.
En 1985, un programme de lutte contre le Sida est mise en route.
En 1986, la charte d'Ottawa pour la promotion de la santé est établie.
La même année, sous l’influence de leurs industries pharmaceutiques, les États-Unis demandent à l’Assemblée mondiale de la santé (AMS) de modifier la politique de l’OMS.
Celle-ci devait se limiter à des programmes verticaux de lutte contre les maladies prioritaires.
À la suite du refus de l’Assemblée, les États-Unis suspendent le paiement de leur cotisation, qui représente 25 % du budget.
En 1988, Mahler n’a pas été reconduit à la direction générale.
Il a été remplacé par le libéral Hiroshi Nakajima.
Les États-Unis ont repris une participation mais sous forme d’une contribution volontaire à des programmes ciblés en dehors du contrôle de l’Assemblée mondiale de la santé.
Les enjeux sanitaires mondiaux étaient alors pris en charge par des fondations privées ainsi que par la Banque mondiale.
Toujours en 1988, un programme pour éradiquer la poliomyélite est lancé.Dans les années 1990, l’OMS est concurrencée par la Banque mondiale.
Celle-ci réagit aux critiques concernant les conséquences des ajustements structurels sur la santé des populations.
Très vite, les moyens qu’elle déploie pour l’amélioration de la santé se trouvent sans commune mesure avec ceux de l’OMS.
Les critères d’action de la Banque mondiale n’étaient pas les mêmes que ceux de l’OMS.
La Banque mondiale utilisait un indicateur d’efficacité (DALY) qui calculait le coût/bénéfice sur la base du nombre d’années de vie perdues par pathologie.
L’OMS en revanche avait une approche clinique plutôt que de rentabilité.
Ainsi, dans la lutte contre la tuberculose, elle appliquait la stratégie DOTS.
L’accent était mis sur le risque de résistance aux antibiotiques et de développement de souches multi-résistantes.
Peu à peu l’OMS est marginalisée dans les politiques de santé.
La Banque mondiale et les Fonds privilégient les partenariats publics-privés et les politiques de santé restent encore largement dans le domaine des États-nations.Lion Murard parle d'une « sorte de seconde naissance » de l'OMS.
Selon l'historien Patrick Zylberman, cela s'explique largement par la recrudescence de maladies épidémiques telles que le sida, la tuberculose (en 1985-1991 à New York), la peste (en Inde en 1994), l'Ébola (au Zaïre en 1995), etc.
L'OMS met en place le programme DOTS visant à contrer le retour de la tuberculose (1995), la Division des maladies transmissibles (1996), le Global Outbreak Alert and Response Network (2001), chargé de signaler à Genève « tous les événements susceptibles de donner lieu à des urgences sanitaires de portée internationale » et non plus seulement les occurrences des trois pathologies quarantenaires traditionnelles (peste, fièvre jaune et choléra).À partir des années 2000, l'OMS gagne un statut de première importance sur les questions des épidémies et des pandémies tel que la grippe aviaire, le SARS, Ebola.
Le 12 mars 2003, l'OMS lance une alerte globale concernant les déplacements à destination de l'Asie et du Canada, sans y avoir été préalablement autorisée par les États, en raison de l'épidémie de SRAS, et s'oppose à la république populaire de Chine concernant les statistiques et le développement de l'épidémie.
La même année, l'OMS met en place une convention cadre pour la lutte antitabac.
En 2005, le Règlement sanitaire international est élargi au-delà des maladies spécifiques précédemment définies, qui dépossède les gouvernements de leur droit de veto sur le renseignement épidémiologique et accompagne le développement dans tous les pays de systèmes efficients de surveillance épidémiologique.En 2009, l'apparition du virus grippal H1N1 pousse l'OMS à collaborer au développement de vaccins contre la grippe.
En 2014, la lutte contre la flambée épidémique sans précédent du virus Ebola met en avant le rôle de l'OMS.Le 31 janvier 2020, l’OMS déclare une « urgence sanitaire mondiale » devant l’épidémie de Covid-19.Pour répondre aux besoins des personnels de santé des États membres qui souhaitent un meilleur accès à la formation continue, l'OMS créé l'Académie de l'Organisation mondiale de la santé inaugurée le 27 septembre 2021 à Lyon (France).
Le 23 juillet 2022, L'OMS déclare l'épidémie de la variole du singe en cours comme une urgence de santé publique de portée internationale.Le fonctionnement de l'OMS s'articule autour du siège situé à Genève, de six groupes géographiques délocalisés et d’un Secrétariat dirigé par le Directeur général.L'Assemblée mondiale de la santé est l'organe décisionnel suprême de l'OMS.
Elle se réunit généralement à Genève en mai chaque année et des délégations de ses 194 États Membres, y siégent.
Elle a pour fonctions principales d'approuver le budget programme de l'OMS pour l'exercice biennal suivant et de statuer sur les grandes orientations politiques de l'Organisation.
Les règlements sont votés par l'Assemblée mondiale de la santé à la majorité simple et entrent en vigueur pour tous les États membres sauf si ceux-ci refusent ou émettent des réserves dans les délais prescrits pour la notification.
Elle adopte à la majorité des deux tiers de nouvelles conventions internationales sur la santé pour combler des lacunes en diverses matières.
Toute convention doit être ratifiée par chaque État pour entrer en vigueur.
Par exemple, elle a adopté la Convention-cadre de l’OMS pour la lutte antitabac, que seulement 6 États n'ont pas ratifiée.
L'Assemblée fixe la politique et le budget de l'OMS.Le Conseil exécutif est l'organe chargé d'administrer l'OMS.
Ses 34 membres sont élus intuitu personæ pour trois ans par l'Assemblée.
Ces membres doivent avoir une compétence sanitaire, être représentatifs des organisations régionales de l'OMS.
Les membres permanents du Conseil de sécurité des Nations unies ont de facto un membre au sein de ce comité.
Le Conseil se réunit au moins deux fois par an.
Ses principales fonctions sont d'appliquer les décisions et les directives de l'Assemblée mondiale de la santé et de lui indiquer des orientations.Le Secrétariat est dirigé par le Directeur général, nommé par les États membres pour une période de cinq ans, sur proposition du conseil exécutif.
L'ensemble du personnel de l'OMS est sous la direction du Secrétariat.Le personnel du secrétariat de l'OMS se compose de professionnels de la santé, d'autres spécialistes ou experts et d'un personnel administratif travaillant au siège à Genève et sur le terrain, dans les six bureaux régionaux et ses 149 bureaux de terrain dans les pays, territoires ou zones.
Les pays qui n’ont pas de bureau de l’OMS dépendent des bureaux de terrain les plus proches ou du bureau régional approprié.Le directeur général non seulement dirige le personnel du secrétariat, mais supervise le programme du conseil et cadre le budget de l'OMS.
Il possède également une fonction de représentation de l'organisation tant envers ses membres que face aux médias.
Ainsi il a une grande importance sur la question de levée de fonds et sur les politiques générales à mener.En raison du décès soudain de son Directeur général, Lee Jong-wook, le 22 mai 2006, l'intérim de la direction est assuré par Anders Nordström, jusqu'à l'élection de son successeur, le Dr Margaret Chan, le 8 novembre 2006.(Av.
Un long immeuble administratif, dû aux architectes Jean Tschumi et Pierre Bonnard, a été construit en 1962-1966 en utilisant verre et aluminium en éléments standardisés.
L’entrée est marquée par un voile de béton.
Au fil des années, le site a progressivement accueilli un campus de 16 édifices, dont le bâtiment A, bloc administratif WHO/UNAIDS ouvert en 2006 et dû aux architectes Baumschlager Eberle.
Cet immeuble a encore été complété d’une tour administrative achevée en 2020 par le bureau d’architectes Berrel Berrel Kräutler.Les États membres sont répartis dans six groupes géographiques qui ont pour but de tenir compte des problèmes sanitaires propres à chaque région de la planète.
Cette organisation régionale et décentralisée est unique au sein des organisations des Nations unies.
Chaque bureau régional élit un directeur régional.
Ces bureaux régionaux ont vocation à servir de liens entre les gouvernements, les actions à l'échelle nationale et le siège de l'OMS.
Ils gèrent également une partie des programmes transversaux et fixent des priorités à l'échelle régionale et nationale.
Ainsi les bureaux régionaux gèrent de manière autonome une grande partie des ressources humaines et techniques de l'OMS, ce qui induire des critiques, des inégalités, des tensions avec le Siège ou avec les bureaux nationaux.
Ils gèrent le recrutement du personnel jusqu'à un certain niveau de direction.Le budget de l'OMS est défini pour une période de 2 ans, depuis 1980.
Ce budget est constitué d'une contribution fixe des états et de contributions volontaires d'organisations publiques ou privées.
Les contributions fixes sont des cotisations que verse chaque État membre.
Elles sont déterminées en fonction du PIB et de la population de chaque État.
Les États-Unis sont le premier contributeur au budget de l'OMS, à la fois en contributions fixes mais aussi en contributions volontaires.
Ces contributions ne sont pas fléchées et peuvent être allouées de manière libre.
Les contributions volontaires sont dans la majorité des cas des sommes fléchées à des actions spécifiques.
Si historiquement, les contributions fixes représentaient la majorité du budget de l'OMS, depuis plusieurs décennies, les contributions volontaires excèdent celui des contributions fixes,.Ces dernières années, l'OMS a multiplié les collaborations avec des organisations non étatiques : elle est actuellement en partenariat avec près de 80 groupes (ONG, industrie pharmaceutique et fondations caritatives telles que la Fondation Bill-et-Melinda-Gates et la GAVI Alliance).En 2006-2007, le budget était de 3,3 milliards de dollars .
En 2014, le budget était d'environ 4 milliards de dollars.En 2016-2017, budget de 5,8 milliards de dollars.
Sur la période 2018-2019, le budget de l'OMS est de 5,62 milliards de dollars.
En mai 2022, l'Assemblée mondiale de la Santé adopte une décision, augmentant les contributions fixes des pays membre à minimum de 50 % du budget de l'OMS à terme, alors que ces contributions fixes ne représentaient plus à ce moment-là que 16 % du budget de l'OMS.En 2005, le total des effectifs était de 3 996 agents dont 1 549 administrateurs, en 2014, ce chiffre est passé à environ 7 000 employés.Le personnel de l'OMS est divisé en deux catégories, des cadres devant être recrutés en respectant une répartition géographique dictée par les États membres et des employés de services généraux composé de secrétaires et employés recrutés par concours localement.
À partir de 1987, l'OMS définit un objectif de répartition de son personnel par nationalité en partie par une répartition homogène entre chaque État membre (40 %) et également en fonction de la contribution financière des États membres (40 %), et dans une mesure très marginale (5 %) par la taille de la population des États membres.
De même, à partir de 1983, un objectif de 20 % de personnels cadres, qui passe à 30 % en 1985.
Le nombre de femmes à ces postes est ainsi passé de 18,2 % en 1984 à 25,1 % en 1992.« Tous les pays Membres des Nations Unies peuvent devenir Membres de l'OMS en acceptant sa Constitution.
Les autres pays peuvent être admis lorsque leur demande a été approuvée par vote de l'Assemblée mondiale de la Santé à la majorité simple.
Les territoires n'ayant pas la responsabilité de la conduite de leurs relations internationales peuvent être admis comme Membres associés sur demande présentée en leur nom par le Membre ou l'Autorité chargée de la conduite de leurs relations internationales ».
En 2020, l’OMS compte 194 états membres.Dans les années 1950, les pays du Bloc de l'Est deviennent des membres inactifs, l'OMS ne reconnaissant pas le départ de membres, avant de redevenir des membres à part entière en 1957.
Dans les années 1960, la décolonisation permet l'entrée de nouveaux pays en développement, changeant les rapports de forces politique.
En 1964, l'OMS retire le droit de vote à l'Afrique du Sud à cause de sa politique de l'Apartheid, puis celui de la Rhodésie du Sud.
En 1972, l'OMS reconnait la République populaire de Chine comme le représentant de la Chine, à la place de Taïwan, dont le délégué est exclu.
La république populaire de Chine ne permet pas l’entrée de Taïwan au sein de l’OMS.
En 1973, la République démocratique allemande devient un membre de l'OMS, après plusieurs essais.
En 1989 et 1990, l'assemblée mondiale de la Santé a rejeté la demande de la Palestine d'être un membre et non plus un membre associé, pour ne pas entrer en conflit avec les États-Unis.
L'éclatement de l'URSS permet l'entrée d'une nouvelle série d’États membres.
Entre 2008 et 2016, Taïwan accède au statut de membre observateur à la suite de l'amélioration de ses relations avec la République populaire de Chine.
En janvier 2021, Joe Biden, revient sur le retrait de l'OMS des États-Unis, retrait démarré par Donald Trump à partir juillet 2020 et qui nécessitait 1 an de délai pour être effectif.Le lundi 31 mai 2021, l’Assemblée mondiale de la Santé a adopté, par consensus, la résolution intitulée Participation du Saint-Siège à l’Organisation Mondiale de la Santé, présentée par l’Italie, qui formalise la participation du Saint-Siège aux travaux de l’Organisation mondiale de la Santé, en sa qualité d’État non membre ayant le statut d’Observateur.L'action de l'OMS a historiquement été déterminée par sa constitution, qui stipule notamment le « droit à la santé de tous les peuples » et « d'amener tous les peuples au niveau de santé le plus élevé possible ».
Les grands domaines d’activité de l’OMS sont :Le budget de l'OMS est critiqué pour sa dépendance aux fonds privés via, notamment le trust de la Fondation Bill-et-Melinda-Gates (10 % du financement en 2021 soit le deuxième plus gros contributeur derrière les États-Unis) et ses investissements parfois contraires à la mission de l'OMS et pouvant être sujets à des conflits d'intérêts.
Selon un reportage d'Arte, l'OMS ferait preuve de complaisance et d'aveuglement vis-à-vis de certains sujets (glyphosate, uranium appauvri, lobby pétrolier, pharmaceutique, nucléaire).Depuis près de vingt ans, une controverse porte sur un accord liant l'OMS et l'Agence internationale de l'énergie atomique (AIEA).
Cet accord est entré en vigueur via la « résolution WHA12.40 » signée le 28 mai 1959.
Ses détracteurs reprochent à cet accord d'avoir comme particularité d'imposer la confidentialité sur des « renseignements spéciaux » et certains sujets (à la discrétion de l'AIEA pour ce qui concerne le secteur du nucléaire), ceci afin de « sauvegarder le caractère confidentiel de renseignements qui leur auront été fournis.
Elles  conviennent donc que rien dans le présent Accord ne peut être interprété comme obligeant l’une ou l’autre partie à fournir des renseignements dont la divulgation, de l’avis de la partie qui les détient, trahirait la confiance de l’un de ses Membres ou de quiconque lui aurait fourni lesdits renseignements, ou compromettrait d’une manière quelconque la bonne marche de ses travaux ».Il est à noter qu'un autre organe de l'ONU étudie l'exposition des populations aux rayonnements ionisants (particules radioactives) et que ses rapports annuels sont publics : le Comité scientifique des Nations unies pour l'étude des effets des rayonnements ionisants (UNSCEAR), d'organisation et fonctionnement similaire au Groupe d'experts intergouvernemental sur l'évolution du climat (GIEC).L'OMS a été dirigée de 2006 à 2017 par Margaret Chan, personnellement très proche du pouvoir chinois, qui a fait d'elle une tribune et un tremplin pour assurer le succès mondial de la médecine traditionnelle chinoise, lui apportant une reconnaissance institutionnelle qui a permis le développement de milliers de centres spécialisés dans des dizaines de pays et l'émergence d'un marché global de plus de 50 milliards de dollars, essentiellement contrôlé par le gouvernement chinois.
Cette instrumentalisation de l'organisation inquiète de nombreux médecins, d'autant que les traitements proposés sont en très large majorité inefficaces voire dangereux, alors que l'Assemblée mondiale de la santé en fait désormais une publicité bien peu nuancée.L'OMS a également été critiquée pour sa gestion de la crise du virus H1N1.
Selon un rapport de l'Assemblée parlementaire du Conseil de l'Europe, « De graves lacunes ont été identifiées en ce qui concerne la transparence des processus de décision liés à la pandémie, ce qui soulève des préoccupations sur l’éventuelle influence que l’industrie pharmaceutique aurait pu exercer aux égards des principales décisions relatives à la pandémie ».
Les conflits d'intérêts d'experts ont aussi été critiqués.L'OMS a été critiquée pour sa gestion de l'Épidémie de maladie à virus Ebola en Afrique de l'Ouest entre 2014 et 2016, notamment pour son manque de réactivité, un déficit en termes de communication et de coordination de l'urgence sanitaire,.
L'urgence de santé publique mondiale n'est émis que le 8 août 2015.
Ces difficultés ont induit certaines réformes au sein de l'OMS concernant les urgences sanitaires, par exemple avec la création d'un fonds de réserve en cas d'urgence.Durant le conflit syrien, démarré en 2011 à la suite de la répression des manifestations, les ONG et les opposants à Bachar el-Assad dénonce une instrumentalisation de l'Organisation Mondiale de la Santé par le régime syrien, qui exerce des pressions sur elle.
L'OMS a notamment dépensé plus de 5 millions de dollars pour soutenir la banque nationale du sang syrienne, qui est contrôlée par le département de la défense d'Assad, malgré les sanctions économiques contre le régime syrien, et malgré les « préoccupations concrètes » de l'OMS quant à savoir si les approvisionnements en sang atteindraient ceux qui en ont besoin, dans un pays où l'accès à la santé est utilisé comme une arme par le régime, qui détourne l'aide humanitaire et prive d'accès aux soins ses opposants et les civils résidant dans des zones aux mains de l'occupation,,.L'OMS est également accusée de complaisance envers le régime syrien.
En 2021, l'élection de la Syrie au comité exécutif de l'OMS suscite une polémique, d'autant que le régime de Bachar el-Assad nomme comme représentant au sein du comité son ministre de la santé, Hassan al-Gabbash, bien qu'il soit placé sous sanctions internationales,.La gestion de la pandémie de Covid-19 par l’OMS est mise en cause, en particulier pour sa « complaisance » vis-à-vis de la république populaire de Chine, notamment en comparaison de la gestion de l’épidémie de SRAS en 2003.
En effet, ce pays est beaucoup plus puissant qu’en 2003 et l’OMS « est une instance qui est dirigée par ses Etats membres, lesquels ont un poids tout particulier au sein de l’organisation et échappent à toute critique de la part d’un secrétariat respectueux de la souveraineté des Etats.
»,.Pour la chercheuse Valérie Niquet, « l'OMS a suivi pas à pas toutes les déclarations chinoises, les répétant comme un perroquet.
L'OMS n'a pas joué son rôle mais c'est exactement ce que voulait Pékin.
De la même manière, elle a refusé de redonner un siège d'observateur à Taïwan, ce qui était une exigence de la direction chinoise ».
Élu directeur de l'OMS grâce au soutien de la Chine, Tedros Adhanom Ghebreyesus est accusé d'avoir repris ses éléments de langage, d'avoir félicité Pékin pour sa transparence alors qu'au même moment la Chine était soupçonnée de cacher des informations et de faire pression pour ne pas déclarer d'urgence internationale, critiquant les États-Unis, qui avaient fermé leurs frontières aux voyageurs venant de Chine.
Plus généralement, Tedros Adhanom Ghebreyesus est accusé d'être un instrument de la stratégie chinoise d'infiltration des organisations onusiennes, via le soft power de la diplomatie humanitaire.Les États-Unis de Donald Trump annoncent en février 2020 leur intention de réduire de 53 % leur contribution au budget de l'OMS, mettant en danger son financement.
En avril 2020, Donald Trump annonce la suspension des financements des États-Unis pour l'OMS.
Les ministres des Affaires étrangères et les diplomates de haut rang des 25 pays membres de l'« Alliance pour le multilatéralisme » indiquent en avril soutenir les travaux de l’Organisation mondiale de la santé (OMS).En réponse aux critiques de Donald Trump contre l'organisation, l'Organisation des Nations unies a apporté son soutien à l'OMS.
Ainsi, le secrétaire général Antonio Guterres a déclaré : « L'Organisation mondiale de la santé, avec des milliers de ses employés, est en première ligne, soutenant les États membres et leurs sociétés, en particulier les plus vulnérables d'entre eux, avec des conseils, des formations, du matériel et des services vitaux concrets dans leur lutte contre le virus ».Le 29 mai 2020, Donald Trump annonce que les États-Unis mettent fin à leurs relations avec l'OMS, avant que Joe Biden, alors récemment élu à la présidence, ne décide de faire marche arrière.Le 28 septembre 2021, The Guardian publie une enquête indépendante selon laquelle plusieurs membres de l'organisme se sont rendus coupables de viols durant leur mission d'éradication d'Ebola en 2018-2020 en république démocratique du Congo.
Le rapport a identifié 21 employés travaillant pour l'organisme mondial de santé des Nations unies parmi les auteurs d'abus graves, dont un certain nombre d'allégations de viol.
Selon le rapport, les abus ont conduit à 29 grossesses, certains des auteurs insistant pour que les femmes avortent.
Le rapport ajoute que l'OMS compte parmi ses auteurs des membres du personnel local et international.
L'OMS s'est dite « le cœur brisé » et a déclaré continuer le combat pour mettre fin à ces abus.
Le vaccin contre la rougeole, la rubéole et les oreillons (vaccin RRO au Québec, ou vaccin ROR en France, ou MMR vaccine (pour Measles-Rougeole Mumps-Oreillons Rubella-Rubéole) aux USA), est un vaccin combiné trivalent contre la rougeole, la rubéole et les oreillons.
Il comprend les vaccins viraux vivants atténués dirigés contre la rougeole, la rubéole et les oreillons.
Il est habituellement administré dans l’enfance.
Ce vaccin est vendu par Merck & Co.
sous le nom de MMR II, par GlaxoSmithKline sous le nom de Priorix, par Serum Institute of India sous le nom de Tresivac et par Sanofi Pasteur sous le nom de MMR Vax Pro en Belgique (également sous le nom de Trimovax dans d'autres pays).
Il est administré au Québec dans les CLSC.
MMR II est un vaccin qui fut développé par la compagnie Merck dans la fin des années 1960.
Il fut licencié sous ce nom en 1971, année où commença son utilisation.
Originellement, il n'y avait qu’une dose administrée, mais en 1989 une deuxième dose fut recommandée par l’American Academy of Family Physicians, l’American Academy of Pediatrics, et le Centers for Disease Control and Prevention’s Advisory Committee on Immunization Practices.
Aujourd’hui, ce vaccin est encore administré dans le monde.Le vaccin a été mis sur le marché en France en 1966 et introduit dans le calendrier vaccinal en 1983, à l’âge de 12-15 mois en association avec la vaccination rubéole.
Trois ans plus tard, la vaccination contre les oreillons y était associée (vaccin triple).Le vaccin MMR II est fabriqué à partir de souches de virus vivants atténués.
Les souches de virus sont produites à l’aide de culture cellulaire.
Pour nourrir les virus, une solution tampon saline de sérum fœtal de bovin est nécessaire.
Le milieu de culture utilisé est le medium 199 qui est composé essentiellement de purines, de pyrimidines et de lipides solubles,.
Les virus seront donc en croissance prolongée dans des conditions non usuelles par passage prolongé.
En se multipliant, ils perdront leur caractère infectieux, sans toutefois perdre leur capacité d’induire une réponse du système immunitaire.Le vaccin est une solution stérile lyophilisée de trois vaccins, soit Attenuvax, Mumpsvax et Meruvax.Le vaccin contient aussi un antibiotique nommé la néomycine.
Cet antibiotique sert à empêcher la contamination par des bactéries lors de la fabrication du vaccin.
Après confirmation de FDA, le vaccin ne contient pas d’agent de conservation comme la thiomersal.En France, le Haut Conseil de la santé publique recommande  que la première dose de vaccin trivalent soit donnée à 12 mois ; la deuxième dose entre 13 et 24 mois (9 mois et rappel 12-15 mois pour les enfants en collectivités).
En Belgique, le Conseil Supérieur de la Santé recommande une première dose de RRO à l’âge de 12 mois et une deuxième dose à l’âge de 10-11 ans (5e primaire) en Flandre et de 11-12 ans (6e primaire) en Fédération Wallonie-Bruxelles.Cette deuxième dose n’agit pas comme un stimulant.
Elle est donnée pour inciter la production d’anticorps chez le faible pourcentage de gens (2-5 %) n’ayant pas développé d’immunité après la première injection.Le vaccin peut aussi être administré aux adolescentes ou femmes qui ne sont pas enceintes, les femmes susceptibles de contracter la rubéole durant la période post-partum et tout autre adulte.
Le vaccin est injecté en sous-cutanée ou intramusculaire; habituellement dans la région externe et supérieure du bras.
Ce vaccin est réalisé par un professionnel de la santé.Le vaccin devrait être gardé dans un milieu réfrigéré et l'abri de toutes sources de lumière.
Le diluant servant à reconstituer le vaccin peut être conservé à température ambiante ou au réfrigérateur.
En revanche, le gel doit être évité.
Après la reconstitution du vaccin avec le diluant, le vaccin devrait être utilisé dans 8 heures suivantes.
Après ce temps, il devrait être jeté.
Le vaccin ne doit pas être jeté dans les ordures ménagères.
Procédure des déchets d'activités de soins à risque (DASRI).Depuis l’introduction du vaccin ROR, les cas de rougeole ont baissé de 75 % dans le monde entre 2000 et 2013.
Dans les vingt premières années suivant l'autorisation du vaccin, le nombre de cas évités aux États-Unis est estimé à 52 millions de cas de contamination, 17 400 cas de retard mental et 5 200 morts.
Depuis 1997, environ 200 cas d’infections ont été répertoriés chaque année confirmant ainsi que la maladie n’était plus considérée comme endémique aux États-Unis.
Il a été constaté une très grande diminution de l'incidence de la maladie dans tous les groupes d'âge, surtout chez les enfants âgés de moins de 10 ans.Dans le monde, la rougeole est encore considérée comme endémique bien qu’elle fût déclarée éliminée aux États-Unis en 2000.
Un rendement élevé de vaccination ainsi qu’une bonne communication avec les gens refusant le vaccin est toutefois nécessaire pour prévenir une épidémie.
Certains facteurs, dont une couverture vaccinale partielle ou un vaccin peu efficace, peuvent permettre la survenue d'épidémies, comme il a été constaté dans des communautés religieuses à New York.Le vaccin ne devrait pas être administré aux gens souffrant d'allergie à certaines composantes du vaccin comme la néomycine.
Les gens immunodéprimés par un déficit immunitaire primaire ou acquis ne devraient pas être vaccinés en raison d'une possible induction de la maladie malgré l'atténuation du virus.
Une telle induction est également possible par l'intermédiaire d'un des membres de leur famille.
Le vaccin n'est pas recommandé pour les gens atteints de troubles sanguins comme la leucémie ou tout autre type de cancer touchant la moelle osseuse ou le système lymphatique.
Les femmes enceintes (ainsi que leur entourage immédiat) ne devraient pas être vaccinées.
Les femmes prévoyant une grossesse devront patienter un mois après la vaccination avant de pouvoir concevoir sans risque.
Le vaccin est aussi déconseillé aux gens sous traitement de corticotrophine, de corticostéroïdes, d'agents alcoylants et d'antimétabolites.
Les personnes ayant une tuberculose non traitée ou sous radiothérapie ne devraient pas être exposées à ce vaccin.1 personne sur 100 ayant reçu ce vaccin s'est plainte d'effets secondaires.
Ces effets secondaires sont généralement une diarrhée, un écoulement nasal, une fièvre, une irritabilité, un sensation de picotement au niveau de l'injection et une douleur dans les articulations.
Certaines personnes, notamment celles ayant des antécédents d'auto immunité peuvent ressentir d'autres effets secondaires que ceux énumérés, comme les thrombopénies ou purpuras thrombopéniques (chute du nombre de plaquettes sanguines), un tel effet restant très rare.La revue médicale britannique The Lancet publie en 1998 une étude dirigée par le Dr Andrew Wakefield laissant craindre un lien possible entre le vaccin et l'autisme, ce qui déclenche une polémique en Grande-Bretagne, et y entraîne une baisse de cette triple vaccination, qui passe de 92 % à 78,9 % entre 1998 et 2003.Le 28 janvier 2010, le General Medical Council britannique (Conseil général de la médecine en Grande-Bretagne) émet un jugement selon lequel certains éléments de l'article de Wakefield et ses coauteurs sont « incorrects » et ses méthodes de recherche « non éthiques ».
Un des points reprochés à l'étude est qu'elle portait sur seulement 12 personnes.
Un conflit d'intérêts révélé par le journaliste britannique Brian Deer, du Sunday Times, contredit aussi l'indépendance de Wakefield, celui-ci ayant été rémunéré comme « expert » à hauteur de 435 643 £ (environ 510 240 €) en prévision d'un procès en recours collectif.The Lancet se rétracte alors le 2 février, et décide de retirer l'article de ses archives.En janvier 2011, le British Medical Journal qualifie cette étude de fraude et accuse Andrew Wakefield d'avoir délibérément falsifié ses données.L'hypothèse du Dr Andrew Wakefield a été reprise dans une étude conduite en 2002 par le Dr Arthur Krigsman, dans des conditions  critiquées et sanctionnées par le Lenox Hill Hospital, à New York, où celui-ci travaillait alors.
Ses résultats, souvent évoqués dans la presse généraliste, en particulier le quotidien britannique The Daily Mail, n'ont jamais fait l'objet d'une publication dans une revue reconnue par la communauté scientifique.
La virulence désigne l'intensité du pouvoir pathogène d'un micro-organisme (bactérie, champignon, virus, protozoaire).La virulence d'un pathogène létal est facilement mesurable mais celle des pathogènes à effets sous-létaux est plus complexe à évaluer.En médecine, la virulence correspond au degré de rapidité de multiplication d'un virus dans un organisme donné, donc à sa vitesse d'envahissement.
Cela ne présume nullement de la gravité de l'affection (éventuellement) engendrée.En écologie, la virulence est mesurée par la diminution de valeur sélective (survie et/ou reproduction) de l'hôte due à l'infection.Des conditions minimales doivent être réunies pour qu'un organisme soit virulent aux dépens de l'hôte qu'il infecte ou parasite.
Tout pathogène l'est ou le devient parce qu'il est adapté à la niche écologique qu'il occupe ou peut occuper, c'est-à-dire qu'il doit notamment :Au cours de l'évolution, la sélection naturelle a doté les agents pathogènes de plusieurs stratégies d'adaptation à leur hôte :Plusieurs de ces stratégies peuvent être utilisées conjointement.Tout comme la résistance aux antibiotiques, la virulence est un trait de l'agent pathogène qui est soumis à la sélection naturelle et qui évolue.
Les organismes traités pour abaisser leur virulence sont dits atténués.
C'est un des principes sur lesquels se fonde la vaccination.Cependant, à moyen et long terme, certaines politiques sanitaires peuvent également sélectionner ou engendrer des hausses de virulence en favorisant des individus plus virulents ou des mutations permettant une virulence accrue.La théorie de la gestion de la virulence, présentée par Paul W. Ewald, a pour but de comprendre pourquoi et comment la virulence évolue afin de faire évoluer les agents pathogènes vers des formes moins nocives ou de les mettre en concurrence avec des formes moins nocives.La théorie « traditionnelle » en épidémiologie stipulait que l’évolution tendrait à modifier les relations entre l’hôte et le parasite vers le mutualisme, c’est-à-dire une relation à bénéfice réciproque, dans laquelle le parasite ménagerait son hôte afin d'assurer sa multiplication et sa transmission.La virulence tendrait alors à diminuer afin d’assurer une meilleure transmission.
Cette hypothèse est connue sous le nom anglais : avirulence hypothesis.Pourtant, très peu d’exemples de parasites devenus avirulents existent.Les premiers à contester cette pensée furent Anderson et May.
En 1982, ils développèrent l’hypothèse du trade-off entre la virulence et la transmission.
Contrairement à la théorie traditionnelle, ils estimaient qu’un parasite ne pouvait augmenter sa virulence (et donc écourter la durée d’infection, en tuant l’hôte) sans en payer le prix.
Autrement dit, en augmentant la virulence, le parasite diminue rapidement la valeur sélective de son hôte (ce qui diminue sa durée d’infection), et donc la durée pendant laquelle l’hôte peut transmettre ce parasite (sa transmissibilité).
Les parasites devraient donc adopter un niveau optimal de virulence.Un parasite développant un taux de transmission plus élevé a donc un coût à payer qui est une durée d’infection moindre.
Il existerait donc une virulence optimale pour laquelle le succès de la transmission est maximum.Le modèle du trade-off, développé par Anderson & May (1982) et Ewald (1983), est basé sur l’idée qu’il n’est pas possible pour le parasite d’accroître la durée de l’infection sans en payer le prix.La valeur sélective d'un parasite peut souvent être approximée par le taux de reproduction R0.
Dans le cas de parasites à transmission directe et horizontale, celui-ci peut être exprimé comme suit :où :Les bases biologiques du trade-off entre virulence et transmission du parasite impliquent que l’auto-réplication du parasite tendrait à maximiser la virulence et la transmission du parasite.
En effet, ces deux paramètres sont positivement liés au taux de réplication du parasite dans l’hôte.
C’est-à-dire que lorsque α augmente, β augmente également.
Il y a alors apparition d’un compromis évolutif entre virulence et transmission, se traduisant par une évolution vers une virulence intermédiaire optimale.On distingue plusieurs forces sélectives pouvant favoriser une diminution de la virulence, par exemple lorsqu'il y a une diminution de la transmissibilité via une baisse des contacts entre hôtes, ou encore lorsqu’il y a une baisse de la densité des hôtes potentiels.
En effet, lorsque le parasite rencontre moins d’hôtes, sa transmissibilité sera moindre, ce qui évolutivement pourrait mener à une baisse de sa virulence.
De plus, une autre force sélective qui peut diminuer la virulence est l’augmentation de la mortalité naturelle de l’hôte.
En effet, si le parasite fait face à un hôte dont le taux de mortalité naturelle (μ) est déjà fort, la sélection favorisera une diminution de la virulence afin de limiter la baisse du nombre d’hôtes potentiels.A contrario, les forces sélectives qui peuvent conduire à une augmentation de la virulence sont l’augmentation de la transmissibilité et l’augmentation de la densité en hôtes potentiels.On peut aussi citer la baisse de la mortalité naturelle de l’hôte.
Car si l’hôte voit son taux de mortalité naturel diminué, la sélection devrait pousser le parasite à tendre vers plus de virulence.Par ailleurs, lors d’infections multiples, une compétition a lieu entre différentes souches pour l’exploitation de la ressource au sein de l’hôte.
Cela donnera lieu à une augmentation de la reproduction du parasite dans l’hôte, donc à une augmentation de la virulence.Les premières critiques de ce modèle sont formulées par Marc Lipstich et E. Richard Moxon en 1997, qui critiquent le manque de preuves empiriques pour étayer la théorie du trade-off.
Dieter Ebert et James Bull en 2003 considèrent eux le modèle comme « trop simpliste ».
En effet, en pratique, les relations entre hôtes et parasites sont caractérisées par bien plus que deux paramètres que sont la virulence et la transmission : par exemple, dans le cas des infections multiples (lorsque l’hôte est infecté par différents parasites), il peut y avoir compétition entre eux pour l’accès aux ressources de l’hôte.
Ou encore la prise en compte de la réponse immunitaire de l’hôte peut diminuer la virulence.
Le modèle trade-off simplifie ainsi la réalité biologique en considérant que la virulence et la transmission du parasite sont indépendantes des caractéristiques de l’hôte.
Or, en réalité, ces paramètres sont le résultat d’interactions multiples au sein de l’hôte, par exemple le comportement que peut adopter l’hôte pour contrer l'infection ou d'autres mécanismes une fois l'infection engagée.
En réponse à la critique d'Ebert et Bull, il est mis en avant le fait que les confusions viennent souvent de ce que la fonction de fitness du parasite utilisée ne correspond pas à son cycle de vie.
Ainsi, Jacobus C. de Roode et alii parviennent à démontrer une relation de trade-off car ils prennent soin d'utiliser une fonction de fitness appropriée au système hôte-parasite étudié.
Un effet indésirable d'un médicament ou d'un soin est un effet défavorable induit ou potentiellement induit par le traitement (gêne, allergie, complications graves, y compris le décès).
Cet effet peut être immédiat ou différé.Selon la définition commune à l'OMS et à la Communauté européenne, on entend une « réaction nocive et non voulue à un médicament, se produisant aux posologies normalement utilisées chez l'homme pour la prophylaxie, le diagnostic ou le traitement d'une maladie ou pour le rétablissement, la rectification ou la modification d'une fonction physiologique ».
L'expression anglaise est Adverse Drug Reaction (ADR).Tous les types de traitements sont susceptibles d'entraîner des effets indésirables, qu'ils soient médicamenteux, mécaniques (plâtre par exemple), chirurgicaux ou même psychothérapeutiques.Tous les médicaments ont des effets et ceux-ci sont jugés indésirables quand ils induisent l'apparition de troubles, gêne ou symptômes supplémentaires à ceux préexistants.Mais cette notion d'effet indésirable reste une question de point de vue.
Par exemple, si vous prenez un produit qui fait baisser la pression artérielle, et que votre problème de départ est que vous avez trop de pression artérielle, la baisse de pression obtenue est bénéfique.
En revanche, si vous prenez ce médicament pour une autre raison, la baisse de la pression artérielle sera probablement néfaste, et l'effet, donc, indésirable.Le degré de gravité et leur fréquence sont extrêmement variables.
Certains sont bénins et modérés,  permettent de poursuivre le traitement sans risque, d'autres sont plus gênants ou plus dangereux, imposant dans les deux cas l'arrêt du médicament.
Ils sont tous stipulés sur la notice du médicament mais, le plus souvent, sans hiérarchisation quant à leur fréquence ou leur réelle importance : ainsi, les 200 médicaments les plus prescrits aux États-Unis comportent une liste d'environ 100 effets indésirables.La constatation d'effets indésirables peut conduire à retirer un médicament du marché, si le risque est fréquent ou grave comparé à l'effet bénéfique attendu ou à la disponibilité d'autres traitements équivalents mieux supportés.C'est la notion de balance bénéfices/risques, qui évalue l'importance respective des avantages et inconvénients du médicament en question, et d'autres traitements éventuels.Les fabricants ont obligation de mentionner dans le résumé des caractéristiques du produit (RCP) tous les faits notés pendant les expérimentations quelles que soient leurs fréquences d'apparition.Au Canada, les fabricants ont obligation de mentionner tous les faits notés pendant les expérimentations, sans être certains qu'ils sont bien liés à ce produit.Les professionnels de la santé (médecin, pharmacien, vétérinaire, infirmière) doivent rapporter les effets indésirables qu'ils observent durant leur pratique quotidienne à un Centre Régional de Pharmacovigilance (CRPV).Ceci peut mener à une modification du RCP.
Toutefois, il faut prendre en considération que l'effet indésirable qui n'a été rapporté que chez seulement 0,001 % des patients consommant le produit et qui ne se produira probablement pas chez des millions de consommateurs se retrouvera quand même dans le RCP.Les effets indésirables d'un médicament peuvent devenir un problème relié à la pharmacothérapie (PRP).
Dans ce cas, le pharmacien assistera le médecin dans l'évolution de la situation clinique, soit en diminuant la dose du médicament, soit en cessant le médicament en cause, soit en éliminant la source de l'interaction médicamenteuse qui pourrait à la source de l'effet indésirable.Une allergie est un phénomène bien particulier, et n'est qu'un cas particulier d'effet indésirable.
40 % des effets secondaires des médicaments sont des réactions cutanées.Il est très difficile d'être certain qu'un symptôme est lié à un médicament.En France, on impute un effet indésirable à un médicament en respectant la méthode française d'imputabilité.
Cette méthode fait un lien chronologique et sémiologique entre l'effet indésirable et le médicament (imputabilité intrinsèque), elle permet également de donner un score bibliographique au lien entre l'effet et le médicament (imputabilité extrinsèque).Une des manières d'approcher, éthiquement douteuse, de la certitude est de pratiquer des épreuves d'arrêt/réintroduction.
S'il y a toujours corrélation entre les prises du traitement et l'apparition des symptômes, il y a de bonnes chances (mais pas une certitude) que celui-ci soit en cause.Si le supposé effet indésirable est connu dans les études scientifiques, il y a de fortes chances que ce ne soit pas un simple hasard.Dans les études, afin de savoir si un symptôme constaté est lié au produit, ou s'il est le fruit du hasard, on utilise des groupes de sujets semblables, une partie servant de témoins et ne prenant pas le traitement, l'autre partie prenant le médicament.Si le symptôme apparaît avec la même fréquence dans les deux groupes, on peut estimer qu'il n'est pas lié au médicament.
Dans le cas contraire, la présomption de causalité est forte.Depuis 2012, l'Agence Nationale de Sécurité des Médicaments et Produits de Santé (ANSM, ex-AFSSAPS) permet aux patients de déclarer en ligne un effet indésirable potentiel.
Des sites internet grand public relaient cette possibilité entre autres fonctionnalités.
Une mutation est une modification rare, accidentelle ou provoquée, de l'information génétique (séquence d’ADN ou d’ARN) dans le génome.Selon la partie du génome touchée, les conséquences d'une mutation peuvent varier.
Une mutation est dite héréditaire si la séquence génétique mutée est transmise à la génération suivante (voir mutations germinales).
Elle est l’un des éléments de la biodiversité et l’un des nombreux facteurs pouvant éventuellement participer dans l'évolution de l'espèce.On peut distinguer plusieurs types de mutations.Une mutation est dite sexuelle lorsqu'elle concerne un chromosome sexuel, par exemple X/Y chez les mammifères ou W/Z chez les oiseaux.Une mutation est dite autosomique lorsqu'elle touche un autre chromosome que les chromosomes sexuels.Une mutation est dite ponctuelle dès lors qu'elle touche un ou plusieurs nucléotides d'un même gène.Les insertions et les délétions sont des mutations décalantes, et sont les deux types de mutations dites indel ou frame-shift.
Une addition ou une suppression de nucléotides non multiple de 3 provoquera un changement de cadre de lecture du code génétique.
Au moment de la traduction, cela générera le plus souvent une protéine tronquée par l'apparition d'un codon-stop prématuré.Cela concerne un grand nombre de nucléotides dans l'ADN de telle sorte que la mutation est observable lorsqu'on fait un caryotype : duplication, translocation, inversion, délétion, insertion.Il peut s'agir aussi d'une perte ou d'un gain de chromosomes : trisomie, monosomie, aneuploïdie.Ces mutations évoluent d'une génération à l'autre, elles correspondent à des répétitions importantes de certains triplets au niveau de l'ADN (CAG et GGG).
Elles sont rencontrées dans certaines maladies génétiques (Syndrome de l'X fragile, dystrophie myotonique de Steinert, chorée de Huntington).Chez les animaux pluricellulaires, les mutations de la lignée germinale peuvent être transmises à la descendance, contrairement aux mutations somatiques.Les mutations naturelles sont aléatoires, mais leur fréquence d'apparition peut être augmentée par des mutagènes, parfois qualifiés d’agents ou de facteurs mutagènes.
Ces agents peuvent être physiques (rayonnements ionisants) ou chimiques (agents alkylants, dérivés réactifs de l'oxygène...).Des procédés permettent aujourd'hui de provoquer des mutations non aléatoires et contrôlées (Type et Nature de la mutation).
Ces procédés sont notamment fortement utilisés dans l'étude du vivant, par exemple pour comprendre les fonctions d'un gène.La mutation se définit traditionnellement comme une modification de l’information génétique, décelable par un changement brusque et d’emblée héréditaire intervenant au niveau d’un ou plusieurs caractères.Cependant, la mise en évidence de l’ADN comme support chimique de l’information génétique et la possibilité d’accéder à la connaissance précise de la séquence des nucléotides qui caractérise chaque chromosome a conduit à proposer une nouvelle définition : tout changement affectant la séquence des nucléotides est une mutation.De plus, au niveau de la génétique des populations la mutation se définit comme une erreur dans la reproduction conforme du message héréditaire.
Elle va transformer un allèle en un autre, nouveau ou déjà présent dans la population.
Le rôle de la mutation dans l’évolution est primordial, car c’est la seule source de gènes nouveaux.
Mais une fois qu’un nouveau gène est apparu par mutation, ce n’est pas plus elle qui va déterminer son devenir : si le nouvel allèle est défavorable, ou s’il est plus favorable que les anciens, c’est principalement la sélection qui va déterminer l’évolution ultérieure de sa fréquence.Au niveau des populations, la croissance n'est pas un problème pour la mutation, elle aide les populations, bien au contraire...
La persistance dépend en général du maintien de l’information génétique.
Pour ce faire, les organismes essayent de réduire le taux de mutation et limiter les mutations délétères.
Cependant, l'adaptation à de nouvelles situations nécessite un certain niveau de variation génétique pour fournir de rares mutations bénéfiques.
Le nombre de mutations générées dans une population est déterminé par la taille de celle-ci ainsi que le taux de mutation des organismes qui la composent.
Par conséquent, pour toute taille de population viable donnée, un organisme devrait développer un taux de mutation qui optimise l'équilibre entre les mutations délétères communes et des mutations plus rares qui augmentent la fitness (chances de survie) à long terme.
Le rapport optimal des coûts aux bénéfices devrait changer avec les circonstances et les habitudes de vie.
Un taux de mutation élevé pourrait être plus coûteux pour un organisme bien adapté dans un environnement constant que pour un organisme mal adapté dans un environnement très variable.Toutefois, les taux de mutations sont contrôlés et minimisés par la sélection.
Des arguments théoriques et expérimentaux montrent que des mutateurs peuvent être sélectionnés positivement lors de la croissance dans certains milieux - lorsque la sélection nécessite des mutations rares répétées et que la variabilité disponible est limitée.
Cela se produit lorsque la population est petite et que les mutants rares peuvent offrir un avantage sélectif (par exemple la résistance aux antibiotiques) plus important que le coût sélectif pour la fitness.Par exemple dans le cas du virus HIV-1 de nombreuses mutations aléatoires surviennent à chaque cycle de réplication virale du fait de la faible fidélité de la transcriptase inverse lors de la transcription.
Certaines de ces mutations seront sélectionnées par la pression qu’exercent les CTL (Lymphocytes T Cytotoxiques) spécifiques des épitopes sauvages.
Or les réponses cytotoxiques précoces semblent avoir une activité antivirale plus efficace, et l’échappement à cette réponse expliquerait la progression virale,.Une partie des maladies (maladies génétiques) ou certains avortements sont liés à des mutations délétères ou mortelles du patrimoine génétique.
Le taux de mutation de l'espèce humaine est mal connu.
Des mutations naturelles et/ou dues à l'exposition à des produits mutagènes d'origine anthropique concernent aussi l'espèce humaine ; L'exposition à certains produits radioactifs (contexte d'essais nucléaires, d'accidents) et à divers produits chimiques mutagènes pourrait avoir augmenté le taux de mutation au sein de l'espèce.
Il a fait l'objet de quelques évaluations, dont récemment par la mesure de l'autozygotie d'une population d'Huttériens généalogiquement bien connue afin d'estimer, au sein de cette population, le taux de mutation de séquences génétiques humaines sur plusieurs générations.
Le séquençage de génomes entiers de 5 trios constitués chacun de deux parents et d'un enfant a permis d'identifier 44 segments concernés par l'autozygosité.
Sur cette base et à partir du polymorphisme nucléotidique les chercheurs ont obtenu un taux de mutation « SNV (single-nucleotide variants) » de 1,20 × 10-8 mutations par paire de base et par génération.
Le taux de mutation pour les bases au sein des dinucléotide CpG (9,72 × 10-8) était de 9,5 fois supérieur à celui des bases non CpG, et ces mutations sont à 85 % d'origine paternelle.
La distribution non uniforme des mutations évoque des « points chauds mutationnels » ou l'existence d'autres sites de conversion génique à long terme.Plusieurs types de mutations peuvent perturber la présentation des molécules du CMHI.
Des mutations au niveau des régions flanquantes des épi-topes vont interférer avec la capacité de clivage des protéines virales par le protéasome ou avec la capacité de transport intracellulaire.
De la même façon, des mutations survenant dans les épi-topes eux-mêmes diminuent la réponse cytotoxique spécifique par les CTL.
Si ces mutations concernent les résidus d’ancrage, elles sont susceptibles d’entraîner une inhibition complète de la liaison du peptide avec les molécules du CMHI.Enfin, les mutations touchant les acides aminés encadrant les résidus d’ancrage dans les épi-topes peuvent également modifier l’interaction du peptide avec la molécule du CMHI pour des raisons conformationnelles.
Si la liaison CMHI-peptide n’est pas stable, le complexe est dissocié avant la rencontre avec le TCR (T cell receptor) et la reconnaissance du peptide viral par le CTL ne peut pas avoir lieu.Le VIH est soumis à trois types de pression : structurale, fonctionnelle et de sélection exercée par la réponse immune spécifique dans les régions immunogènes.
Ainsi, le virus est contraint en permanence à un équilibre entre les mutations des épi-topes, qui permettent l’échappement à la reconnaissance par cette réponse immune spécifique, mais ces mutations pourrait induire un coût fonctionnel pour le virus comme une diminution de sa capacité de réplication ou de son pouvoir infectant.
En outre, dans le cas de la réponse CTL, il a été montré que des mutations survenant dans les régions fonctionnellement importantes conduiraient à la non-viabilité des mutants.
Par exemple des mutations d’échappement dans la région codant Gag p-24 vont produire une diminution significative de la fitness, par contre les mutations dans les régions Env gp 120 n’ont pas d’effet pour la fitness virale,.Si une mutation affecte une cellule germinale participant à une fécondation, elle est transmise à l'individu issu de cette fécondation, et sera présente dans chacune de ses cellules.
Cette mutation peut procurer un avantage sélectif ou au contraire être délétère, voire létale.
C'est la base du processus de l'évolution.
Il est cependant admis que la plupart des mutations interviennent entre les gènes, dans les introns, ou à des endroits où leur effet est minime (mutations synonymes) ; la plupart des mutations sont donc probablement neutres, et ne sont conservées (ou éliminées) que par hasard (dérive génétique).En revanche, comme c'est le cas pour la plupart des mutations accidentelles (provoquées par irradiation ou substances chimiques), si elle affecte les cellules somatiques, la mutation ne se transmet pas et n'affectera donc que le sujet l'ayant subie directement.
Si les cellules se divisent activement, il y a possibilité de création d'une tumeur pouvant évoluer en cancer.
À l'opposé, s'il n'y a pas de division l'effet est négligeable.Les mutations peuvent être classées selon leurs conséquences phénotypiques :Les mutations expliquent l'existence d'une variabilité entre les gènes.
Les mutations qui sont le moins favorables (délétères) à la survie de l'individu qui les porte, sont éliminées par le jeu de la sélection naturelle, alors que les mutations avantageuses, beaucoup plus rares, tendent à s'accumuler.
La plupart des mutations sont dites neutres, elles n'influencent pas la valeur sélective et peuvent se fixer ou disparaître par le jeu de la dérive génétique.
Les mutations spontanées, généralement rares et aléatoires, constituent donc la principale source de diversité génétique, moteurs de l'évolution.
Les causes des mutations spontanées sont inconnues.Les mutations brutales engendrées par le césium 137 (137Cs), lors de l’accident de Tchernobyl par exemple, n’ont aucun effet bénéfique et durable sur le génome d’une espèce, ici l’homme.
Mais les effets du 137Cs ne sont remarquables que sur la descendance du sujet contaminé (malformations cardiaques, troubles de la minéralisation osseuse, troubles cérébraux) pour une exposition à forte dose.Les différentes techniques de détection de mutation sont :Le terme de mutation est introduit en 1869 dans le sens paléontologique (légères variations de formes dans les coquilles d'Ammonites) par le géologue allemand Waagen.
Le botaniste néerlandais Hugo de Vries est le premier à l'employer dans son sens génétique dans le cadre de sa théorie mutationniste élaborée de 1901 à 1903.Le terme scientifique est chargé de connotations négatives, surtout depuis son association dans la presse des années 1950, à l'action mutagène des radiations ionisantes (effet découvert en 1926 par Muller) provenant d'incidents ou accidents nucléaires et des essais nucléaires menés au plus fort de la guerre froide.
L'augmentation ultérieure des connotations négatives semble provenir de sources plus diffuses,.
Le système immunitaire d'un organisme est un système biologique complexe constitué d'un ensemble coordonné d'éléments de reconnaissance et de défense qui discrimine le soi du non-soi.
Ce qui est reconnu comme non-soi est détruit.Il protège l'organisme des agents pathogènes : virus, bactéries, parasites, certaines particules ou molécules « étrangères » (dont certains poisons), mais est responsable du phénomène de rejet de greffe.Il est hérité à la naissance, mais autonome, adaptatif et doué d'une grande plasticité, il évolue ensuite au gré des contacts qu'il a avec des microbes ou substances environnementales étrangères au corps.On dénombre plusieurs types de systèmes immunitaires parmi les espèces animales, et généralement plusieurs mécanismes immunitaires collaborent au sein d'un même organisme.Pour de nombreuses espèces, dont les mammifères, le système est constitué de 3 couches.
Ses principaux effecteurs sont les cellules immunitaires appelées leucocytes (ou globules blancs) produites par des cellules souches, au sein de la moelle osseuse rouge.
Cette séparation en trois couches n’empêche pas une interaction très importante des couches entre elles:On appelle réponse immunitaire l'activation des mécanismes du système immunitaire face à la reconnaissance de non-soi, agressive ou pas, face à une agression ou à une dysfonction de l'organisme.L'ensemble de ces systèmes (y compris lors de la vaccination) permet la résilience immunitaire, notion qui recouvre la somme des mécanismes efficaces de défense d’un organisme vis-à-vis d’un agent pathogène (du grec pathos : souffrance) ; il se dégrade avec l'âge (Immunosénescence).Le système peut entraîner un dysfonctionnement autoimmune.Toutes les cellules du système immunitaire dérivent d'une cellule souche présente dans la moelle osseuse.
Cette cellule souche donne deux lignées de cellule : la lignée lymphocytaire et la lignée myélocytaire.Les cellules de l'immunité innée sont produites par la lignée myélocytaire.
Les cellules de l'immunité adaptative sont produites par la lignée lymphocytaire.Un seul type de cellule est produite par les deux lignées : la cellule dendritique.La cellule souche multipotente donne le progéniteur lymphoïde (lymphoid progenitor) qui se divise en trois types de cellules :Responsable de la production des hématies et plaquettes, cette lignée donne naissance à des cellules impliquées dans le système immunitaire inné et dans le système immunitaire adaptatif en produisant des cellules portant les antigènes des agents pathogènes pour les présenter aux cellules du système immunitaire adaptatif :L'organisme se défend contre les dysfonctions de ses cellules et les agressions, c'est-à-dire des processus qui ont pour conséquence de détruire des êtres vivants.
Ces agressions peuvent revêtir différentes formes :Le système inné est un mécanisme très rapide de défense aux infections: il permet souvent d'arrêter un agent pathogène ou, du moins, de permettre la mise en route du système adaptatif qui a des armes plus puissantes et plus spécifiques pour arrêter l'agent pathogène.
Il a longtemps été considéré comme un système non spécifique, mais la découverte de récepteurs cellulaires spécifiques de plusieurs familles de pathogènes (comme les bactéries gram-négatives) dans les années 2000 a changé notre regard sur le système inné.Le système immunitaire inné est déclenché par des récepteurs cellulaires reconnaissant des structures moléculaires uniques aux agents pathogènes ou par des molécules signifiant les dégâts.Elles dérivent toutes de la lignée myélocytaire de l'hématopoïèse.
Elles sont parfois regroupées sous le terme de leucocytes phagocytaires ou phagocytes.
Ce terme est très réducteur car il laisse à penser que la seule fonction de ces cellules est la phagocytose, alors qu'elles ont d'autres fonctions essentielles.Ce sont des cellules immunitaires qui reconnaissent les microorganismes grâce à de nombreux récepteurs cellulaires présents à leur surface.
Ces récepteurs permettent aux phagocytes de reconnaître certaines structures présentes à la surface des microorganismes infectieux et d'internaliser ces derniers à l'aide d'une vacuole digestive.
Par la suite, ils fusionnent la vacuole contenant les microbes avec un lysosome.
Les lysosomes peuvent contenir des formes toxique d'oxygène comme du monoxyde d'azote (NO) ou du peroxyde d'hydrogène (H2O2), et ils peuvent aussi contenir du lysozyme et d'autres enzymes digestives qui dégradent des structures microbiennes.Les cellules résidentes sont les premières activées en cas de franchissement de la barrière épithéliale (cutanée, respiratoire ou intestinales) par un microbe.Les macrophages ont une plus grande capacité de phagocytose que les granulocytes neutrophiles, et, lorsqu'ils phagocytent un microorganisme, des voies cellulaires internes les stimulent, ce qui les rend plus efficaces dans leurs tâches.Ces cellules contiennent des granules contenant des substances vasodilatatrices comme l'histamine.
Cette substance en vasodilatant le vaisseau entraîne une diminution de la vitesse de circulation du sang permettant au leucocyte neutrophile de traverser la paroi vasculaire.Les cellules dendritiques qui dérivent aussi des monocytes sont des cellules présentatrices d'antigènes.
Leur rôle est de capturer un microbe au site d'infection, de migrer vers les tissus lymphoïdes et de présenter les antigènes du microbe aux lymphocytes T à l'aide d'une molécule de CMH.
Ce type de molécule joue un rôle très important dans la réaction immunitaire primaire.Les granulocytes neutrophiles représentent 60 à 70 % des leucocytes.
Ils pénètrent dans les tissus infectés pour phagocyter les microbes présents et les détruire.
Généralement, les granulocytes neutrophiles s'autodétruisent en même temps qu'ils détruisent les microbes.
Ils ont normalement une espérance de vie de seulement quelques jours.
Ce sont des cellules présentes dans le sang et capables de migrer vers un site où se produit une infection.Les granulocytes éosinophiles sont présents en très petite quantité dans l'organisme.
Ils ont une faible capacité de phagocytose, mais ils sont essentiels dans le combat contre les parasites présents dans l'organisme.
Ils se lient à la paroi du parasite et libèrent des enzymes qui vont causer des dommages importants à celui-ci.Les leucocytes basophiles sont les plus rares des leucocytes.
Leur taux est si faible que l'absence de leucocyte basophile au cours d'une numération formule sanguine ne doit pas être considérée comme anormale.Les monocytes représentent 5 % des leucocytes.
Ils circulent dans le sang et migrent vers un tissu où ils se transformeront par la suite en macrophages.
Les macrophages et les cellules dendritiques sont des cellules résidentes dans les tissus sous-épithéliaux.Il existe quatre grands groupes de molécules intervenant dans l'immunité innée : les peptides anti-microbiens, le système du complément, l'interféron I alpha et I beta et les protéines de la phase aiguë dont la plus utilisée en pratique médicale est la protéine C reactive.L'introduction d'un agent infectieux, comme une bactérie gram négatif, au cours d'une piqûre à travers la peau déclenche dans les minutes qui suivent la libération de peptides anti-microbiens et de cytokines par les cellules de l'épithélium cutané.Les cellules résidentes de l'immunité innée (macrophage, mastocyte, cellule dendritique) reconnaissent le pathogène par des récepteurs appelés pattern recognition receptor (PRR) ou en français récepteurs de reconnaissance de motifs moléculaires, dont il existe 4 types principaux.
Pour les bactéries gram-négatives, il s'agit d'un récepteur de type Toll (TLR ou Toll Like Receptor).
La bactérie contient sur la surface de sa paroi des lipopolysaccharides spécifiques aux bactéries gram-négatives qui sont reconnus par les TLRs.
Les structures biochimiques reconnues par le TLR sont appelées motifs moléculaires associés aux pathogènes.La liaison TLR-PPR va déclencher des événements qui diffèrent selon le type cellulaire.
Au niveau des mastocytes, elle entraînera la libération d'histamine, celle-ci déclenchant la dilatation des vaisseaux aboutissant à un ralentissement de la circulation sanguine.
Au niveau des macrophages et des cellules dendritiques, elle entraînera la libération des cytokines et des chimiokines; les chimiokines vont attirer les leucocytes une fois que ceux-ci ont traversé l’endothélium de la paroi vasculaire.
La liaison TLR-PPR active une voie de signalisation qui va déclencher une synthèse de protéine anti-microbienne.Le ralentissement du débit sanguin secondaire à la vasodilatation permet aux leukocytes de traverser la paroi.
Outre les leucocytes, les facteurs du complément traversent la paroi participant aussi à la réaction du système inné.
Au niveau cutané, la manifestation clinique de l'infection se traduit par quatre signes : rougeur, chaleur, douleur et œdème.
Ces quatre signes caractérisent la réaction inflammatoire.Si le système inné n'arrive pas à contenir l'infection, la cellule dendritique va se diriger vers un ganglion lymphatique par les canaux lymphatique.
Elle va se maturer au cours du voyage.
Dans le ganglion, elle présentera à la cellule T CD4 + auxiliaire des petits morceaux de 30 à 40 acides aminés de la bactérie phagocytée.
Cette présentation de l’antigène se fait par son complexe majeur histocompatibilité de classe II.L'immunité adaptative repose sur 3 acteurs : les organes lymphoïdes, les lymphocytes B et les lymphocytes T.
Ces 3 acteurs vont permettre de reconnaître un agent pathogène, de le signaler et de déclencher soit l'immunité humorale soit l'immunité cellulaire.
Que ce soit l'immunité humorale ou l’immunité cellulaire, l'immunité adaptative ne se déclenchera que si cet antigène porte aussi un récepteur cellulaire de pathogénicité montrant bien la complexité et l'interaction des deux immunités.Les organes lymphoïdes comprennent le thymus, la moelle osseuse, la rate, les amygdales, l'appendice et les ganglions lymphatiques.Le système immunitaire humoral agit contre les bactéries et les virus avant leur pénétration dans les cellules.
Les cellules responsables de la destruction des pathogènes extra-cellulaires sont les lymphocyte B agissant en sécrétant des anticorps.La production et la maturation des lymphocytes B se fait dans la moelle osseuse.
Les lymphocytes B sont le support de l'immunité humorale.
Ils possèdent à leur surface des récepteurs, nommés BCR, B Cell Receptor ou récepteurs des cellules B. Chaque lymphocyte B possédée plusieurs BCRs mais pour un seul agent pathogène.
Ce BCR est une immoglobuline membranaire formée de 2 chaînes légères et de 2 chaînes longues.
Il existe autant de lymphocytes B que de pathogènes.
L'ensemble des lymphocytes B est appelé le répertoire des lymphocytes B. Chaque BCR possède 2 sites de fixations à l'antigène.Le lymphocyte B avant d'être activé est appelé naïf.
L'activation du lymphocyte B par l'intermédiaire des BCR déclenche une expansion clonale du lymphocyte activé, avec production de cellule mémoire, et déclenche à distance des cellules produisant des anticorps.
Ces cellules produisant des anticorps sont appelés plasmocytes.
L'activation du lymphocyte B par un antigène nécessite l'implication des cellules lymphocytaires T CD4.Les lymphocytes B sont nommés B car ces lymphocytes ont été découverts chez l'oiseau dans la bourse de Fabricius ; par la suite le « B » fut conservé car c'est l'initiale de bone marrow (l'anglais de moelle osseuse) qui correspond au lieu de maturation de ces cellules à la suite d'une exposition à une interleukine (molécule chimique permettant le clonage des lymphocytes B et leur différenciation) produite par les lymphocytes T4.Ses principaux moyens d'action sont les immunoglobulines, aussi appelées anticorps.
Les anticorps sont des molécules ayant une forme de « Y » formées de quatre chaînes polypeptidiques : deux chaînes légères (environ 200 acides aminés chacune) et deux chaînes lourdes (environ 450 acides aminés chacune).Les chaines légères ont des régions constantes et des régions variables.
Les régions variables dépendent de la régulation somatique.
Les anticorps ont une forme en Y.
La barre verticale du Y est constituée de deux chaînes lourdes constantes qui vont déterminer la fonctionnalité de l’immunoglobuline.
Les deux barres inclinées du Y sont formées chacune d'une chaîne lourde et d'une chaîne légère, chacune ayant une partie constante et une partie variable qui est responsable de la spécificité de l'anticorps.Il existe 5 classes d'anticorps : les IgM, les IgG, les IgA, les IgE et les IgD.
Les IgM sont les premiers anticorps à être produits lorsque le corps reconnaît un nouvel antigène.
Ceux-ci se retrouvent dans le corps sous forme de pentamère et ils sont très efficaces pour activer le complément.
Les IgG sont la classe d'anticorps la plus retrouvée dans le sang, c'est aussi la seule classe d'anticorps qui peut traverser le placenta et donner au fœtus une immunité passive.
Les IgA se retrouvent dans les sécrétions (salive, larme, mucus, etc.) sous la forme de dimères.
De plus, la présence de ce type d'anticorps dans le lait de la femme permet aux nouveau-nés de recevoir une immunité passive durant la période d'allaitement.
Les IgE sont les anticorps impliqués dans les réactions allergiques puisqu'ils provoquent la libération d'histamine et d'autres substances impliquées dans ce genre de réaction par les granulocytes basophiles.
Finalement, les IgD sont retrouvés à la surface des lymphocytes B dits « naïfs » (qui n'ont pas encore été exposés à un antigène) et servent de récepteurs cellulaires à ceux-ci.
Contrairement aux quatre autres classes d'anticorps, les IgD ont une région transmembranaire qui leur permet de se fixer à la membrane cellulaire des lymphocytes B.Les quatre fonctions principales des anticorps sont :La fonction principale de l'immunité cellulaire est de détruire les agents infectieux intracellulaires.
Les cellules responsables de la destruction des pathogènes intra-cellulaires sont les lymphocytes T qui agissent directement en injectant des substances toxiques dans les cellules infectées.La formation et la maturation des lymphocytes T se fait dans le thymus où le lymphocyte prend le nom de thymocyte.
Le lymphocyte T est aussi porteur d'un récepteur pour reconnaître les antigènes pathogènes : les récepteurs des cellules T ou TCR.
À la différence des récepteurs des cellules B, le récepteurs des cellules T ne reconnaissent qu'un seul type de molécules : les peptides.La reconnaissance de la présence d'un agent infectieux intracellulaire par les lymphocyte T se fait par l'intermédiaire du complexe majeur d'histocompatibilité, nommés aussi CMH ou MHC, présent sur les cellules.Ce complexe majeur d'histocompatibilité a été découvert lors des transplantations d'organes.
Ces MHC recueillent en permanence les peptides formés continuellement par la cellule par la dégradation protéique intracellulaire ; elles sont spécifiques à un individu.Les peptides formés en permanence par la cellule par la dégradation protéique intracellulaire et portés par les MHC à l'extérieur de la cellule permettent aux lymphocytes T de vérifier la « santé » de la cellule.
En cas d'infection virale, les MHC vont présenter à l'extérieur des peptides viraux qui vont être reconnus par les lymphocytes T.
Il en est de même lors d'une greffe d'organe après laquelle les MHC produits seront reconnus comme n’appartenant pas à l'organisme (au soi) risquant de déclencher un rejet de greffe.Le système immunitaire cellulaire s'occupe des cellules infectées par des virus, bactéries, et les cellules cancéreuses.
L'action s'effectue via les lymphocytes T.
Les lymphocytes T sont capables d'interagir avec les cellules de l'organisme grâce à leurs récepteurs cellulaires T ou TCR (T Cell Receptor) formés de deux chaînes polypeptidiques: la chaîne α (alpha) et la chaîne β (bêta).
Ces récepteurs sont tout aussi spécifiques aux antigènes que les anticorps ou que les récepteurs de lymphocytes B, mais, contrairement aux anticorps et aux récepteurs de lymphocytes B, les récepteurs de lymphocytes T ne reconnaissent que de petits antigènes qui doivent être présentés par une molécule de CMH à la surface d'une cellule infectée.Aux lymphocytes T s'ajoutent aussi les lymphocytes NK (natural killer).
Ces cellules sont impliquées dans une réponse à mi-chemin entre spécifique et non spécifique, selon les situations.
Ils jouent notamment un rôle en début de grossesse, le fœtus devant se protéger contre eux pour pouvoir survivre dans le ventre de sa mère.Lorsqu'un agent pathogène pénètre dans une cellule, il reste dans le cytoplasme ou infecte les vacuoles.
Les mécanismes pour détruire l'agent différent selon sa localisation et expliquent en partie l'existence de deux familles de MCH, les MCH I et MCH II.Les MHC I sont produites par les infections cytoplasmiques.
Ils activent les lymphocytes T CD 8 qui possèdent le récepteur CD 8.
Ces cellules jouent un rôle prédominant dans l'infection virale.
Les lymphocytes T CD 8 sont nommés lymphocytes cytotoxiques ou CTL.
En effet, la liaison de CD8 sur la molécule de CMH permet de garder le lymphocyte T et la cellule infectée liés plus longtemps, ce qui favorise l'activation du lymphocyte.
Une fois activé, le lymphocyte T cytotoxique libère des protéines, comme la perforine ou des granzymes qui provoquent la formation de pores dans la paroi cellulaire de la cellule infectée, entraînant sa mort.
Cela a pour effet de priver le pathogène d'un lieu de reproduction et de l'exposer aux anticorps et aux leucocytes phagocytaires qui circulent dans la région infectée.
Les MHC I sont présents sur toutes les cellules nuclées de l'organisme.
Les hématies ne possèdent donc pas de MHC I.Les MHC II sont présents sur un nombre très restreint de cellules : cellules dendritiques, macrophages et lymphocytes B.Les MHC II sont produits par les infections vacuolaires ou la phagocytose.
Ils activent les lymphocytes T CD 4 qui possèdent le récepteur CD 4.
Les lymphocytes T CD 4 sont nommés lymphocytes helpers ou auxiliaires.
En activant les TCD4, ceux-ci libèrent des cytokines transformant les lymphocytes B en plasmocytes sécrétant des immunoglobulines.Vidéo de la réponse adaptativePour que la cellule lymphocytaire B produise des anticorps spécifiques et que le lymphocyte T CD8+ naïf se transforme en lymphocyte T CD8 tueur, il faut deux signaux :La cellule dendritique est une cellule immunitaire résidant dans le derme ou dans le tissu conjonctif sous-épithélial des bronches ou de l'intestin.
Dès l’introduction d'un pathogène, elle va être activée par les molécules émises par les cellules de l'épithélium (les peptides anti-microbiens et les cytokines pro-inflammatoires : l' interleukine-1, l' interleukine-6 et l'interféron-1 alpha et beta).La cellule dendritique immature possède des récepteurs de reconnaissance de motifs moléculaires qui reconnaissent la famille du microbe porteur d'un motif moléculaire associé aux pathogènes.
Elle va internaliser le microbe, le transporter vers un ganglion lymphatique par la lymphe.
Au cours du transport, elle va devenir une cellule dendritique mature avec apparition de molécules qui vont lui permettre de se fixer à un lymphocyte T CD4+ auxiliaire naïf.Durant son transport et dans le ganglion, la cellule dendritique coupe le microbe en morceaux compris entre 30 et 50 acides aminés.
Ces morceaux vont être présentés aux lymphocytes T CD4+ auxiliaires grâce au complexe majeur d'histocompatibilité de type II (MCH II).
C'est la présentation de l'antigène.L'activation de la cellule T CD4+ se fait grâce à la synapse immunologique.
Des molécules d'adhésion immobilisent la cellule dendritique au lymphocyte TCD4+.
La cellule dendritique présente un peptide à la cellule T CD4+.
La protéine CD4 se fixe sur un domaine du MCH II.
Enfin, des co-récepteurs sont produits par la cellule dendritique après stimulation des récepteurs de reconnaissance de motifs moléculaires.
L'ensemble représente la synapse immunologique : la cellule T CD4+ est avertie d'une espèce particulière de microbe par le MCH II de la cellule dendritique à travers les récepteurs de reconnaissance de motifs moléculaires de cette cellule dendritique.En fonction du signal de famille de pathogène donné par la cellule dendritique lors de la présentation de l'antigène, des cytokines de types différentes vont être émises par la cellule dendritique et activent de façon spécifique les lymphocytes T CD4+ notamment en Th1, Th2.
Chaque groupe est spécialisé d'une famille de pathogènes (virus, ver, bactérie, etc.).Le même microbe qui a été reconnu par la cellule dendritique se fixe sur les récepteurs des cellules B. Cette fixation va entraîner une activation et un processus aboutissant à la présentation de peptides microbiens par les complexes majeurs d'histocompatibilité de type II (MCH II) au récepteur du T CD4+ : c'est le premier signal.Le lymphocyte T CD4+ va reconnaître que ce peptide est le même que celui présenté par la cellule dendritique : c'est le deuxième signal.En fonction du type de CD4+ (Th1, Th2), le TCD 4+ va synthétiser des cytokines, principalement des interleukines, qui à leur tour vont déterminer le type d’anticorps sécrétés.
Le lymphocyte B naïf se transforme en lymphocyte B activé.
Il va commencer à produire des anticorps A, G ou E. Ces anticorps vont rejoindre le site de l'infection par les canaux lymphatiques aboutissant au canal thoracique se jetant dans l'aorte et vont atteindre le site de l'infection.
Un groupe de lymphocytes à mémoire est aussi créé.L'introduction d'un agent infectieux, comme un virus, déclenche dans les minutes qui suivent la libération de peptides anti-microbiens et de cytokines par les cellules de l'épithélium cutané.Les molécules citées ci-dessus vont aller se fixer sur les récepteurs PRR des macrophages, des mastocytes et de la cellule dendritique.
Les mastocytes vont relâcher des granules d'histamine qui ont des capacités vasodilatatrices, ce qui va dilater les parois des vaisseaux sanguins et donc ralentir la vitesse de la circulation sanguine pour permettre au granulocytes de traverser la paroi vasculaire.
Les macrophages eux, vont relâcher des chimiokines qui vont se fixer sur les récepteurs PRR des granulocytes et vont les attirer dans le vaisseau sanguin.
Les cellules dendritiques vont capturer un microbe et migrer jusqu'aux vaisseaux lymphatiques et aux ganglions, où ils vont présenter une molécule MHC II au lymphocyte T4.Grâce à la dilatation des vaisseaux produite par les mastocytes et grâce aux chimiokines, les granulocytes présents dans les tissus vont traverser la paroi vasculaire.
Les granulocytes neutrophiles vont phagocyter, les ganulocytes basophiles vont relâcher de l'histamine, qui va déclencher la réaction inflammatoire, et les granulocytes éosinophiles vont se lier à la paroi du parasite et libérer des enzymes qui vont causer des dommages importants à celui-ci.Les cellules dendritiques capturent un microbe et migrent jusqu'aux vaisseaux lymphatiques et aux ganglions, où ils vont présenter une molécule MHC II au lymphocyte T4.Si l'inflammation n'est pas contrôlée par le système inné, les lymphocyte T4 vont activer les lymphocytes B spécifiques au microbe à l'aide d'une cytokine, l'interleukine 2.
Les lymphocytes B vont alors produire des anticorps.Les peptides anti-microbiens qui sont libérés en premier par les cellules de l'épithélium cutané vont se fixer aux récepteurs du lymphocyte qui va alors s'activer.
Il va libérer tout d'abord de la perforine, une protéine qui va créer des pores dans la paroi des cellules infectées.
Il va ensuite libérer du granzime, une protéase à sérine qui va pénétrer par ces pores et induire l'apoptose (mort de la cellule).Les anticorps vont se fixer sur les antigènes de la bactéries ou de virus.
Ensuite les anticorps présentent le microbe aux macrophages.
Les macrophages activent la phagocytose grâce aux récepteurs FCR.Chaque individu acquiert en vieillissant une « mémoire immunologique ».
Elle conserve un certain temps les traces de « lutte » passée contre des pathogènes ou parasites, et des cellules spécifiques, permettant une réaction immunitaire plus rapide et efficace.
Cette mémoire se constitue de manière naturelle, ou à l'aide de vaccins mais semble se dégrader avec l'âge (phénomène d'immunosénescence).En effet, l'exposition antérieure à un antigène modifie la vitesse, la durée et l'intensité de la réaction immunitaire.
La réaction immunitaire première consiste en la production de cellules effectrices des lymphocytes lors d'une première exposition à l'antigène.
Lors d'une seconde exposition au même antigène, la réaction immunitaire secondaire sera plus rapide et efficace car l'organisme aura conservé en mémoire certains lymphocytes de la première attaque.C'est le principe de la vaccination : on injecte un antigène à la personne pour qu'elle se crée une « mémoire humorale », qui sera directement efficace lors d'une éventuelle attaque ultérieure.Une étude en 2015, basée sur la comparaison de la santé de « vrais » et « faux » jumeaux (210 jumeaux au total, de 8 à 82 ans, suivis pour plus de 200 paramètres de leur système immunitaire, ce qui est une première en nombre de paramètres d'intérêt immunologique), confirme qu'après la naissance, l'environnement a plus d'effets que nos gènes sur le fonctionnement et l'efficacité de notre immunité, notamment via l'exposition antérieure de l'organisme à des agents pathogènes (et/ou à des vaccins).
Les réponses différentes des vrais jumeaux à la vaccination anti-grippale montrent aussi que les réactions (production d'anticorps) ne dépendent pratiquement pas des traits génétiques mais presque entièrement de l'éducation immunitaire de chacun, et donc de nos relations antérieures à l'environnement microbien et parasitaire (dans ce cas liées à des contacts précédents avec diverses souches du virus de la grippe).
Face au cytomégalovirus, qui sommeille dans une fraction importante de la population humaine (ne causant que rarement des symptômes), les conclusions sont les mêmes.La meilleure compréhension des mécanismes globaux de l'immunité pourrait peut-être à l'avenir permettre de réduire les problèmes de rejet de greffe car la compatibilité entre un receveur et un donneur ne provient pas que de l'ADN, mais aussi d'enzymes et de facteurs d'immunité qu'on commence à rechercher dans le domaine de la biologie adaptative (via l'immunoséquençage notamment,,).
À l'échelle d'une vie, l'évolution du système immunitaire peut être comparée aux mécanismes complexes en jeu à d'autres échelles dans l'évolution adaptative.
De même, des vaccins plus personnalisés pourraient être imaginés.Le système immunitaire peut se dégrader en réagissant excessivement ou insuffisamment.L'absence de régulation du système inné peut aboutir au choc cytokinitique.S'il s'attaque aux cellules de l'organisme qui ne sont pas pathologiques (par mauvaise reconnaissance), il va alors se créer une maladie auto-immune qui va se caractériser par une inflammation continue de certains tissus ou par la nécrose complète de certains tissus (par exemple le diabète de type I).S'il y a un défaut du système immunitaire, dans ce cas les pathogènes ou les cancers pourront se développer plus aisément.Notons l'existence d'une maladie impliquant le système immunitaire adaptatif.
Il s'agit du Bare Lymphocytes Syndrome (BLS).
Les patients souffrant de cette maladie ne peuvent présenter d'antigène à la surface des cellules présentatrices d'antigène et il ne peut donc pas y avoir production d'anticorps.
Cette maladie a notamment permis des avancées en biologie moléculaire en permettant l'identification par complémentation d'un facteur de transcription essentiel, le transactivateur de classe II (CIITA).
Le terme tumeur (du latin tumere, enfler) désigne, en médecine, une augmentation de volume d'un tissu, sans précision de cause.C'est une néoformation de tissus corporels (néoplasie) qui se produit à la suite d'un dérèglement de la croissance cellulaire, de type bénin ou malin (quand il s'agit d'une tumeur maligne, on parle de cancer).Une néoplasie peut concerner n'importe quel type de tissu.
En fonction de la localisation de la tumeur et de la fonction du tissu affecté, elle peut conduire à un dysfonctionnement des organes et nuire à l'ensemble de l'organisme, voire causer sa mort.Les tumeurs peuvent survenir chez tous les organismes multicellulaires, y compris les plantes.On distingue les tumeurs bénignes et malignes :Le nom de la tumeur est formé généralement en ajoutant le suffixe -ome au nom du tissu.
On parle cependant d'un épithélioma et non d'un épithéliome.
Certains termes sous-entendent la nature cancéreuse de la lésion (carcinome, sarcome), d'autres non (adénome, fibrome).Les tumeurs sont classées selon leur localisation et surtout selon leur aspect morphologique microscopique, leur différenciation, leur ressemblance avec les tissus normaux.Les tumeurs bénignes se développent en général lentement et ne nuisent pas à l'organisme.
Certaines d'entre elles peuvent néanmoins par la suite dégénérer et muter en tumeurs malignes.
On peut citer notamment les polypes de l'intestin (adénome du côlon), qui dégénèrent souvent en adénocarcinomes (séquence adénome-carcinome).
Les adénomes producteurs d'hormones peuvent provoquer à travers celles-ci des maladies graves.Les tumeurs, bénignes ou malignes, peuvent également entraîner les complications suivantes :Elle dépend du type de la tumeur : bénigne ou maligne.Dans le premier cas, son ablation chirurgicale, appelée  tumorectomie, permet d'obtenir une guérison, en règle, sans récidive.
Elle n'est proposée que si la tumeur est gênante pour le ou la patiente ou si elle comporte un risque de compression d'une structure adjacente.
La lumpectomie est la tumorectomie de la tumeur du sein.Le traitement d'un cancer pose des problèmes beaucoup plus spécifiques.Les médicaments utilisés par la chimiothérapie sont dits anti-tumoraux ou anticancéreux ; ils comprennent notamment des dérivés toxiques du platine (cisplatine, carboplatine, nédaplatine (en) et lobaplatine).La thermoablation par échothérapie est un procédé qui permet, selon les premiers résultats, de retirer 70 à 80 % des cellules de tumeurs bénignes sans toucher d'autres organes que ceux touchés par la tumeur.Les tumeurs sont renseignées dans leur nom par le suffixe -ome ( du grec ancien -ωμα, -ôma).
La 1re partie de l'expression désigne soit le tissu atteint, soit l’aspect de la tumeur ou son origine.
La controverse sur la vaccination concerne la mise en cause de la pertinence, l'efficacité et la sécurité des vaccins et de la vaccination.
Historiquement au cœur d'une controverse scientifique, la sécurité et les bienfaits de la vaccination font maintenant l'objet d'un solide consensus scientifique, notamment basé sur le fait que la vaccination a permis, depuis le milieu du XXe siècle, de faire disparaitre de grands fléaux infectieux et de réduire le taux de mortalité.
Le mouvement anti-vaccination, également appelé antivax, fait souvent appel aux théories du complot.En dépit du consensus scientifique en faveur de la vaccination, elle demeure aujourd'hui contestée par des mouvements antivaccins, qui entretiennent une controverse fabriquée selon laquelle la vaccination serait inutile ou nuisible, et qu'elle pourrait même déclencher certaines maladies comme la sclérose en plaques ou certains troubles comme l'autisme.
Dans les faits, la méfiance à l'égard de la vaccination a mené à plusieurs reprises à un déclin des taux de vaccinations ainsi qu'à une augmentation des cas des maladies y correspondant.
Dans certains cas, ces peurs ont eu de graves conséquences sur la santé publique, comme au Royaume-Uni où la baisse de la couverture vaccinale, dans le cadre de la controverse sur le rôle de la vaccination dans l'autisme, a occasionné de sérieux troubles de la santé ainsi que plusieurs décès,.
Une vaccination insuffisante des enfants engendre notamment une recrudescence mondiale de la rougeole.En juin 2021, un sondage réalisé par Gallup observe que la France est le premier pays au monde pour les idées pro « anti-vax ».Au demeurant, la légitimité de l'obligation vaccinale suscite des controverses.
Perçue comme un affront aux libertés fondamentales par les associations antivaccinales ou libertaires, elle est considérée dans les pays démocratiques qui l'instaurent comme une nécessité au nom du bien commun.Au début du XVIIIe siècle, les médecins ont pris note des méthodes populaires de la variolisation.
Mais l'ignorance médicale (les partisans de l'inoculation n'ont à opposer à leurs adversaires que de vagues statistiques) reste telle que les controverses sur l'inoculation sont légion.
Les camps pour et contre la variolisation luttent tous deux avec leurs armes idéologiques, plus politiques que scientifiques.
En effet, selon les adversaires, la variole serait un destin divin auquel on ne peut échapper et la variolisation serait un remède de bonne femme puisqu'il s'agit d'une méthode empirique exotique, importée de l'Empire ottoman en 1722 par une femme, Lady Montagu.
La pratique, accompagnée par des succès signifiants, mais aussi par des adversités, est revendiquée dans la seconde moitié du XVIIIe siècle par la politique populationniste des gouvernements du siècle des Lumières et comme moyen de conservation des vies individuelles par les médecins-humanistes.En 1796, le médecin de campagne anglais Edward Jenner met au point le vaccin contre la variole.
Il s'agit d'une nouvelle méthode plus efficace et moins dangereuse de lutte, consistant en l'inoculation d'une maladie apparentée à la variole, mais bénigne.
Bien que la vaccine jennerienne (communément appelée « variole de la vache ») ne soit pas contagieuse d'homme à homme, elle ne fait pas taire les critiques.
La Royal Society présente des réticences, Pasteur note des échecs dus à des défauts d'inoculation.
Si l'inoculation a moins de complications que la variolisation, elle suscite des doutes et entraîne des risques de contaminations d'autres maladies, et notamment la syphilis.
L'utilisation de lymphes vaccinales inefficaces ou contaminées, provenant de pustules, expose à de nombreux risques de varioles ou de transmission d'autres maladies.
De plus, une partie du corps médical (notamment les inoculateurs de la variole qui voient leur profession menacée) est réticente à inoculer une humeur animale considérée comme un poison, certains antivaccinistes brandissant la hantise de la minotaurisation (transformation en minotaure, monstre mi-homme, mi-taureau) de la race humaine.
Enfin, le discours vaccinophobe propage le mythe de l'insuffisance des vertus dépuratoires du vaccin.En 1800, l'introduction du vaccin antivariolique en France provoque une grande controverse quant aux conséquences individuelles (accidents vaccinaux) ou sur la population (théorie de la dégénérescence).
Un comité central de vaccine créé par Napoléon et Chaptal organise de manière très stricte la circulation de l'information médicale, allant jusqu'à censurer les journaux, afin de créer l'image d'un vaccin parfaitement bénin préservant à jamais de la petite vérole.
Il répond ainsi aux caricaturistes anglais, qui représentaient des vaccinés, auxquels poussaient deux cornes et une queue (peur de la minotaurisation).Si la vaccination a joué un rôle considérable dans la diminution de la variole, il est vrai que la technique de vaccination promue par le comité de vaccine puis par l'Académie de médecine (de bras à bras à partir d'une lymphe humaine, et qui était celle communément employée dans toute l'Europe) comportait des risques importants de transmission de maladies.
Ce risque a d'abord été reconnu en Italie dès 1814, et surtout après un accident dramatique survenu dans ce même pays en 1861.
Il faut attendre 1864 pour que le Congrès Médical de Lyon reconnaisse enfin le risque de contamination vaccinale et promeuve la vaccination animale par l'Académie de Médecine.
Toutefois, la France est bien l'un des premiers pays, avec l'Italie, à abandonner la vaccination bras-à-bras avant la Belgique (1865), l'Allemagne (1884), suivis par les Pays-Bas et les États-Unis, l'un des derniers pays étant la Grande-Bretagne (1898).Ce traumatisme engendré par l'apparition de variole après vaccine vers le milieu du XIXe siècle est suivi par une nouvelle vague d'antivaccinateurs qui trouve son origine, à partir de 1880, dans les milieux hygiénistes, adversaires de toute vaccination, tel l'ophtalmologue belge, Hubert Boëns (1825-1898), qui fonde en 1880 la Ligue universelle des antivaccinateurs.
Ils s'appuient sur un discours scientiste anti-vaccinal et la théorie des germes pour émettre des recommandations en matière de salubrité publique, de conditions de logement et de travail, privilégiant la désinfection et l'isolement des varioleux aux campagnes de vaccination,.
Les épidémies continuent ainsi à faire des ravages : alors que la variole tue une fois sur cinq, et jusqu'à 40 % pendant les épidémies, les rares études épidémiologiques au XVIIIe siècle montrent que la variolisation tue une fois sur cinquante et, lorsque la méthode jennerienne de vaccination est appliquée, « on cite des chiffres de 1 mort pour 400 inoculés, 3 pour 1 000, 5 pour 1 000 ».Le XXe siècle voit la santé publique supplanter l'hygiène publique, ce qui se traduit par le développement de l'obligation de la vaccination antivariolique.
En 1904, à Rio de Janeiro (Brésil), au cours de la révolte du vaccin, des manifestants organisés autour de la Liga Contra a Vacina Obrigatória demandent la fin de la vaccination antivariolique obligatoire et de la destruction des logements insalubres qui avaient été institués par le gouvernement.En 1958 l'OMS (Organisation mondiale de la santé) lance une grande campagne de vaccination mondiale pour éradiquer la variole.
Mais l'OMS remarque que, dans certains pays , comme l'Afrique sub-saharienne ou le sous-continent indien, les vaccinations de masse n'ont pas d’effets sur la propagation de la maladie, même lorsque plus de 80 % de la population est vaccinée.
« Toutefois, dans certains pays, même lorsque la couverture de vaccination atteignait 80 ou même 90 %, les sujets sensibles non vaccinés, regroupés en certains secteurs particuliers du pays ou dans les zones de faible niveau socio-économique des villes, constituaient une population suffisamment importante pour que la transmission de la variole se perpétue ».En 1967, l'OMS décide donc de changer de stratégie en associant aux vaccinations la méthode dite de surveillance/endiguement.
Cette méthode porte ses fruits puisque la transmission de la variole dans ces pays a été interrompue en trois ou quatre ans.
Cette politique visait à ré-orienter la vaccination vers des cibles plus précises, selon les poussées épidémiques et vers ceux qui n'avaient jamais été vaccinés auparavant.
On accordait ainsi un niveau de priorité plus élevé à la surveillance active et à l'endiguement.En décembre 1929, l'Hôpital de Lübeck (Allemagne) lance une campagne de vaccination des nouveau-nés contre la tuberculose, par le BCG (bacille de Calmette et Guérin) par voie orale dans le lait maternel.
En quatre mois, 251 enfants sont vaccinés.
Dans les mois qui suivent, on constate un nombre inhabituel de décès.
Une enquête de surveillance est mise en place avec un suivi de trois ans des enfants vaccinés.
En 1932, il est établi que 72 enfants (30 %) sont décédés de tuberculose, 127 (53 %) ont fait une tuberculose clinique ou radiologique avec guérison et 41 (17 %) n’ont eu aucun signe, sinon une conversion tuberculinique (virage de cuti, attendu après vaccination).
Les interrogations se sont portées sur la responsabilité du BCG (M. Bovis souche 374, de l'Institut Pasteur de Paris).L'enquête a établi que la souche de BCG utilisée avait été contaminée par une souche virulente de M. tuberculosis (souche Kiel) cultivée dans le laboratoire de l'hôpital de Lübeck, la dernière préparation du vaccin BCG se faisant dans le même local.Malgré l'exclusion de la responsabilité du BCG en tant que vaccin, cette erreur de préparation a retardé son introduction en Allemagne,.
Cette tragédie a aussi accéléré l'intervention des États dans le contrôle et la production de vaccins, ainsi que l'abandon de la voie orale pour le BCG remplacée par l'injection intra-dermique (datant de 1927), la multipuncture (1939) ou la scarification (1947).En 1992, l'OMS recommande aux États membres la vaccination universelle des enfants contre l'hépatite B. En juillet 1994, la France décide de proposer, dès la rentrée suivante, cette vaccination gratuite pour les enfants des classes de 6e.
Ce programme scolaire est appuyé par une campagne intense de publicité (presse et télévision), non scientifiquement contrôlée et parfois dramatisante.
En trois mois, près de 500 000 élèves sont vaccinés.
Des millions de jeunes adultes se font vacciner chez leur médecin au-delà des objectifs initiaux.
Ils sont estimés à six ou sept millions durant la seule année 1995.
Fin 1995, des cas de sclérose en plaques chez des personnes vaccinées sont notifiés et une controverse sur la responsabilité du vaccin dans l’apparition de la maladie éclate.
Cent-six malades sont recensés en décembre 1996, regroupés au sein de l'association REVAHB, (ils seront plus de mille en 2001).
La presse évoque alors un nouveau scandale sanitaire, du type de l’affaire du sang contaminé.Le 1er octobre 1998, le ministre de la Santé Bernard Kouchner décide de suspendre la vaccination dans les collèges, tout en la maintenant pour les nourrissons, en laissant familles et médecins en décider par eux-mêmes.
Ce changement de politique vaccinale est critiqué par l'OMS dans un communiqué, comme scientifiquement injustifiée et mettant en danger les programmes mondiaux de vaccination contre l'hépatite B. De nombreuses études se succèdent de 1999 à 2011, aucune ne détecte un sur-risque significatif, à l'exception de celle d'Hernan (2004).En 2012, l'AFSSAPS (Agence de sécurité sanitaire Française) indique qu'aucun élément nouveau n'est apparu pour mettre en cause cette vaccination, l'OMS et les agences sanitaires des principaux pays ayant la même position.
En France, la vaccination des nourrissons contre l'hépatite B s'établit à 88 % après avoir stagné à 25 % jusqu'en 2004, principalement, en raison des vaccins hexavalents (vaccinant contre six maladies et intégrant celui contre l'hépatite B).En 2017, plus de 20 ans après les faits, de nombreuses études à long terme n’ont relevé aucune manifestation indésirable grave imputable à la vaccination contre l’hépatite B. L'Organisation mondiale de la santé (OMS) précise que "les données n’indiquent pas de lien de causalité entre le vaccin anti-hépatite B et les affections neurologiques (y compris le syndrome de Guillain-Barré et la sclérose en plaques), le diabète sucré, les troubles démyélinisants, le syndrome de fatigue chronique, l’arthrite, les maladies auto-immunes, l’asthme, la chute de cheveux ou le syndrome de mort subite du nourrisson.
".En 2019, l'OMS indique sur son site que 189 États Membres avaient introduit à l’échelle nationale le vaccin contre l’hépatite B pour les nourrissons.
La couverture mondiale par trois doses de vaccin anti-hépatite B est estimée à 85 % des nourrissons.En 2020, l'OMS rappelle qu'on dispose de vaccins sûrs et efficaces pour prévenir l’hépatite et estime possible d'éliminer l’hépatite à l’horizon 2030.En juin 2009 sur la base de « présomption d'imputabilité » (et non une preuve de causalité), et dans le strict cadre du droit du travail, le laboratoire fabricant GSK a été condamné pour ne pas avoir mentionné sur la notice du vaccin les risques de sclérose en plaques, mentionnés dès 1994 dans le dictionnaire Vidal comme un effet indésirable "rapporté mais non démontré".
Le tribunal de Nanterre décide que "l'imputabilité de la pathologie (…) à l'injection du vaccin (…) est établie".
Une centaine de victimes ont aussi été indemnisées par l’État, sélectivement et à l'amiable : il s'agissait des professionnels de santé ayant reçu la vaccination à titre obligatoire et ayant développé certaines maladies.
Les tribunaux administratifs ont parfois augmenté ces indemnisations.
Précisons qu'en France, le droit du travail est différent du droit commun.
Dans le droit du travail, il suffit d'une « présomption d'imputabilité », aucune preuve de causalité n'est nécessaire.
En droit commun, la Justice a conclu par un non-lieu, le 9 mars 2016, après une enquête de 17 ans sur cette affaire de vaccination.
Ces différences, de même que les décisions judiciaires successives sur chaque dossier, ont généré une forte incompréhension pour les personnes s'estimant victimes du vaccin.
Depuis, en France, pour tous les vaccins, il existe un système d'autorisation et de contrôle des publicités, ainsi que, pour les nouveaux vaccins, leur inscription systématique sur la liste des produits faisant l'objet d'un plan de gestion des risques coordonné par l'ANSM.Des sels d'aluminium (particules de l'ordre du µm) sont utilisés comme adjuvant immunologique dans de nombreux vaccins.
L'alun de potassium fut le premier employé, puis il fut progressivement remplacé par d'autres formulations tel que l'oxy-hydroxyde d'aluminium, l'hydroxy-phosphate d'aluminium et le sulfate d'hydroxy-phosphate d'aluminium.
Il est estimé qu'environ 2/3 des vaccins contiennent au moins l'un de ces adjuvants,.Dans quelques cas, il a été rapporté des rougeurs, des irritations allergiques et des nodules au point d'injection, mais leur sûreté est démontrée depuis 1926,.
En 2005, un groupe international d'experts réuni pour tenter d'établir un consensus scientifique a estimé qu' « il n'y a pas de données permettant de conclure » que les vaccins contenant de l’aluminium constituaient une menace de santé.La question de leur innocuité s'est posée en 2001, en France : les vaccins contenant des sels d’aluminium pourraient être à l'origine de myofasciite à macrophages, définie comme une lésion inflammatoire microscopique au point d'injection.
Une synthèse des études épidémiologiques est réalisée en 2003 par l’expertise collective des trois agences françaises l'InVS, l'Afssa et l'Afssaps et détaille les effets de l'exposition à l'aluminium, en rappelant que hors vaccination, et même injecté à faible dose, « peut induire une accumulation à long terme des effets neurotoxiques ».Le Comité consultatif mondial sur la sécurité des vaccins et l’ANSM estiment que cette entité correspond à un « tatouage vaccinal » sans rapport avec un ensemble de troubles cliniques allégués.
Cependant, les cas étant rares et n'étant observés qu'en France, d'autres études sont nécessaires pour établir un lien de cause à effet, et l'OMS indique en octobre 1999 ne pas disposer d'éléments pour recommander la modification des pratiques vaccinatoires dans le cas de vaccins contenant de l’aluminium.Le 28 juin 2012, l'Académie de médecine s'oppose dans un communiqué à tout moratoire sur les vaccins contenant de l'aluminium et relève « qu'aucune preuve de toxicité neurologique imputable à l'aluminium de l'alimentation ou des vaccins n'a pu encore être fournie à ce jour » et que « la résurgence des maladies prévenues par ces vaccins entraînerait de façon certaine une morbidité très supérieure à celle, hypothétique, des maladies neurologiques ou auto-immunes imputées à la vaccination ».Le Conseil d'État a reconnu (en dernière instance de 8 affaires judiciaires) que « dans le dernier état des connaissances scientifiques, l'existence d'un lien de causalité entre une vaccination contenant un adjuvant aluminique et la combinaison de symptômes constitués notamment par une fatigue chronique, des douleurs articulaires et musculaires et des troubles cognitifs n'est pas exclue et revêt une probabilité suffisante pour que ce lien puisse, sous certaines conditions, être regardé comme établi ; que tel est le cas, lorsque la personne vaccinée, présentant des lésions musculaires de myofasciite à macrophages à l'emplacement des injections, est atteinte de tels symptômes ».Parmi le peu d'études s'étant intéressées au devenir de l'aluminium vaccinal dans l'organisme, à son mode d'action comme adjuvant et à son élimination, une étude présentée en mars 2017 au conseil scientifique de l’ANSM (Agence nationale de Sécurité du Médicament) indiquait que la sensibilité toxique à l'aluminium pouvait être liée à certains profils génétiques.
En septembre 2017, une note interne fuitée au Parisien dévoile les résultats de l'étude : ces travaux apportent de nouveaux éléments tendant à expliquer le lien entre les adjuvants aluminiques et la myofasciite à macrophages.
Grâce à des tests menées en laboratoires entre 2014 et 2016 sur des souris, il a pu être démontré que l'aluminium injecté via un vaccin peut remonter au cerveau, provoquant ainsi des troubles neuro-musculaires.
Une prédisposition génétique expliquerait néanmoins la rareté des cas diagnostiqués parmi la population humaine.
Les médias reprennent largement le passage suivant de l'ANSM, : « L’apport de l’étude aux connaissances sur la sécurité des vaccins semble significatif, sans être encore déterminant ».
L'ANSM fait usage d'un droit de réponse qui rectifie un nombre d'éléments factuels et « tient à rassurer les patients sur le fait qu’aucun signal lié à l’aluminium contenu dans les vaccins n’a conduit à ce jour à remettre en cause le rapport bénéfice / risque des vaccins contenant de l’aluminium.
Les résultats des études de l’équipe du Pr Gherardi ainsi que l’ensemble des rapports et publications disponibles à ce jour, ne modifient pas le rapport bénéfice / risque positif des vaccins contenant de l’aluminium, pour lesquels il existe un recul d’utilisation avec des centaines de millions de vaccins administrés dans le monde depuis près d’un siècle.
(…) ».Selon le professeur Daniel Floret, pédiatre et vice-président de la commission technique de vaccination, la dose d'aluminium apportée par les vaccins est bien plus faible que celle apportée par notre environnement : nous sommes exposés à des doses bien plus importantes par le biais de l'alimentation, des cosmétiques, des médicaments, etc..En 2018, la FDA juge les risques des vaccins aluminés comme « extrêmement faibles » au regard des avantages des vaccins chez les enfants, en soulignant que l'exposition principale de l'aluminium est celle par la nourriture et la boisson.En octobre 2019, malgré un faisceau d'indices scientifiques significatifs, aucun lien de maladie due à l'aluminium n’a pu être officiellement établi avec les vaccins par les autorités sanitaires ni de façon déterminante par le consensus scientifique,.Le phosphate de calcium fait l'objet d'une campagne menée par des associations de patients opposés à la présence d'aluminium vaccinal.L’Institut Pasteur a utilisé dans les années 1960 le phosphate de calcium comme adjuvant de ses vaccins anti-diphtérique et anti-tétanique avant qu'il soit abandonné dans les années 1980.En 1985, la branche vaccins de l’Institut Pasteur, Pasteur Production, fut rachetée par l’Institut Mérieux, donnant naissance à Pasteur Vaccins.
L’Institut Mérieux arrêta la production de vaccins à base de phosphate de calcium.
L’utilisation de l’hydroxyde d’aluminium fut généralisée, par souci d’harmonisation de la production vaccinale française, afin d’être plus compétitif sur les marchés étrangers : « Cela ne vaut pas la peine de se pencher sur le phosphate de calcium, alors que l’aluminium est universellement accepté », expliquait le Dr Roumiantzeff, directeur médical de Mérieux, le 4 novembre 1986.Selon le rapport de l'Académie de Médecine publié en 2012, le phosphate de calcium paraît avoir un pouvoir adjuvant beaucoup plus faible que les sels d'aluminium.
Une nouvelle formulation nanoparticulaire pourrait pallier cet inconvénient, mais les études publiées restent fragmentaires et ne donnent pas de renseignement sur la réponse immunitaire à long terme.
Le débat reste ouvert et des travaux supplémentaires sont indispensables.La controverse sur le rôle de la vaccination dans l'autisme est à l'origine une controverse scientifique portant sur la vaccination, particulièrement forte dans les pays anglo-saxons.
En 2004, il s'avère que l'étude suggérant un tel lien était frauduleuse.
Cependant pour les parents américains des enfants concernés et leurs avocats, il existerait trois théories provoquant l'autisme : celle du vaccin contre la rougeole, la rubéole et les oreillons (ROR) qui endommagerait les intestins (étude frauduleuse d'Andrew Wakefield), celle du thiomersal toxique pour le système nerveux central, enfin celle de l'injection combinée de plusieurs vaccins qui affaiblirait le système immunitaire.Le consensus scientifique, appuyé notamment par une méta-analyse de 2014 sur un million et demi de dossiers médicaux, conclut à l'absence de preuve d'un rôle quelconque de la vaccination dans l'autisme, et ce dans tous les cas incriminés.La controverse a pris une dimension judiciaire, avec de nombreuses plaintes de familles américaines via le recours collectif Omnibus Autism Proceeding, qui ont été déboutées en 2009.
Quelques actions de même type ont lieu en Europe.
Un problème de santé publique se pose en raison de la baisse de la couverture vaccinale, et du retour d'épidémies de rougeole dans des pays occidentaux.Le Gardasil est un vaccin contre le papillomavirus humain (HPV, responsable du cancer du col de l'utérus).
Accueilli en 2006 comme une bonne nouvelle dans plusieurs pays, ce vaccin très utilisé aujourd'hui est une source de controverses.
En effet des jeunes filles ont souffert, postérieurement à leur vaccination, de développement d'une maladie auto-immune comme la Sclérose en plaques (SEP) , mais aussi le Lupus par exemple.Des associations luttent pour obtenir un moratoire sur le Gardasil, il s'agit notamment de Revahb qui regroupe les victimes du vaccin contre l'hépatite B, E3M qui rassemble les personnes atteintes de myofasciite à macrophages et Amalyste, une association de patients souffrant des syndromes de Lyell et de Stevens-Johnson, ainsi que « les filles et la gardasil », une association dédiée.Pour les scientifiques, la relation entre ces maladies et la vaccination ne peut être envisagée que si l'apparition des maladies est plus fréquente sur les populations vaccinées que sur les autres, ce qui n'est pas ce qui est observé :En 2009, le vaccin en préparation pour le virus A (H1N1) a provoqué une controverse avant même sa distribution,,.Du fait, le suivi des personnes vaccinées et la détection des effets secondaires ont été des plus exhaustifs,.En août 2010, après la fin officielle de la pandémie, 4 428 effets indésirables, principalement bénins, avaient été enregistrés.
Dans un bulletin de pharmacovigilance l'Afssaps conclut : « Au 28 mars 2010, les données de sécurité issues de la notification spontanée et des résultats préliminaires des études pharmaco-épidémiologiques en cours, tant sur le plan national qu’européen ne montrent pas de signal d’alerte particulier pouvant remettre en cause le profil de tolérance de ces vaccins.
».Le Figaro fit un article sur 22 cas de narcolepsie cataplexie relevés parmi 5,7 millions de personnes vaccinées.
La prévalence de cette maladie est estimée être entre 1/3300 à 1/5000, ce qui indique qu'au moins un millier de personnes étaient porteuses de cette maladie parmi les personnes vaccinées.Le 29 mars 2011, l’agence suédoise du médicament a indiqué que le risque de narcolepsie a été quatre fois plus élevé chez les moins de 20 ans ayant reçu le vaccin Pandemrix contre la grippe H1N1 ,.Le 21 juillet 2011, l'EMA, l'agence européenne du médicament restreint sévèrement l’utilisation du vaccin contre la grippe H1N1 chez les jeunes de moins de 20 ans, justement les plus touchés par le risque de narcolepsie.En 2013, l'origine des cas de narcolepsie a été médicalement élucidée, par un mécanisme d'auto-immunité.En septembre 2013, l'agence française ANSM confirme au sujet du vaccin Pandemrix que « plusieurs études (…) montrent qu’il existe une augmentation du risque de narcolepsie chez l’enfant, l’adolescent et l’adulte jeune ».
Parallèlement, le Royaume-Uni indemnise les victimes.En 2015, en France trois adolescents reçoivent plus de 600 000 euros d'indemnisation de l'ONIAM pour leur narcolepsie survenue après la campagne de vaccination de 2009.
L'ANSM a recensé 61 cas de narcolepsie post-vaccinale.En mai 2016, le parlement suédois vote un budget pour l'indemnisation de plus de 300 victimes de narcolepsie, principalement des enfants.Lisa Brouwers, de l'institut suédois de contrôle des maladies infectieuses, citée en mars 2012 par Courrier International, estimait que le vaccin, administré à cinq millions de Suédois, avait dû épargner six décès.Les États-Unis ont utilisé un vaccin différent, sans adjuvant.
Aucune corrélation n'a été relevée avec la narcolepsie.Fin 2014 au Kenya, l'association des médecins catholiques du Kenya a affirmé avoir trouvé un antigène, l'hormone chorionique gonadotrope humaine, qui provoquerait des fausses couches, dans un vaccin antitétanique injecté durant la campagne de vaccination soutenue par le gouvernement kényan.
L'association a rappelé que l'Église catholique gère 54 hôpitaux, 83 centres de santé, 17 écoles de médecins et d'infirmier au sein d'un réseau de soins et que ce réseau procure également des vaccinations.Le gouvernement a catégoriquement démenti la présence d'une telle hormone dans les vaccins, qui n'aurait de toute manière pas eu d'effet stérilisateur ; l'UNICEF a elle aussi remis en cause ces accusations émanant de l’Église catholique kényane sans argument scientifique ou factuel à l'appui.
Une enquête des « Décodeurs » pour LeMonde.fr confirme qu'il s'agit d'une fake news complotiste.Toujours selon les décodeurs du Monde, « Des affirmations similaires ont ainsi été véhiculées dans les années 1990 au Mexique, en Tanzanie, au Nicaragua et aux Philippines pour tenter de discréditer les programmes de vaccination de l’OMS.
Au Pakistan, c’est le vaccin contre la poliomyélite qui a été accusé de rendre stérile ou d’inoculer le virus du sida, fantasmes qui ont conduit à une série d’assassinats de plusieurs vaccinateurs en 2012.
».Aux États-Unis, les sentiments antivaccins sont corrélées avec l'orientation politique des Américains.
Ainsi, à l’échelle nationale, 41% des sympathisants républicains déclarent ne pas vouloir se faire vacciner, contre 11% des démocrates (mars 2021).Les données diffusées au début de la pandémie de Covid-19 montrent que la controverse sur la vaccination est moins présente au Canada qu'aux États-Unis, mais on note tout de même qu'une personne sur quatre considère la vaccination comme risquée et on constate que la « méfiance vis-à-vis de la vaccination est nettement surreprésentée chez les gens ayant des enfants, chez les moins de 35 ans, chez ceux qui ont les revenus et les niveaux d'éducation les plus faibles de la société ainsi que chez les ouvriers.Selon un rapport américain du Centre for Countering Digital Hate (CCDH) les deux tiers de la propagande antivax remontent aux activités de 12 personnes : Joseph Mercola (en), Robert F. Kennedy, Jr.
, Ty et Charlene Bollinge, Sherri Tenpenny (en), Rizza Islam (en), Rashid Buttar (en), Erin Elizabeth (en), Sayer Ji, Kelly Brogan (en), Christiane Northrup (en), Ben Tapper (en) et Kevin Jenkins (en),.L’hésitation vaccinale est un concept désignant un très large spectre de comportements, qui se situent dans l’intervalle allant de l’acceptation sans condition de la vaccination et son rejet complet.
Entre ces deux extrêmes, la réticence à la vaccination peut être plus ou moins forte.Le groupe de travail du Groupe stratégique consultatif d’experts (SAGE) sur l’hésitation à l’égard des vaccins de l’Organisation mondiale de la Santé (OMS) a défini l’hésitation à la vaccination comme « le retard dans l’acceptation ou le refus des vaccins malgré la disponibilité de services de vaccination »,.Certaines controverses publiques installent une défiance vis à vis des vaccins qui demeurent lorsque la controverse disparaît.
Des controverses dans les médicaments conduisent également à une méfiance à l'égard des vaccins,.Selon le site du gouvernement canadien, le discours négatif sur l’innocuité et l’efficacité des vaccins demeure omniprésent dans les médias traditionnels et sociaux, même si les avantages de la vaccination font consensus dans le milieu scientifique et médical.Gary R. VandenBos conseille d'aborder le thème de l'hésitation vaccinale lors des séances avec un patient en psychothérapie et d'utiliser les techniques d'entretien motivationnel pour réduire la résistance à la vaccination.Les sociétés pharmaceutiques développant les vaccins bénéficient d'une immunité juridique dans différents pays, dont les États-Unis, afin d'éviter d'être poursuivies en justice en cas d'effets secondaires, à l'exception des « fautes volontaires » (« willful misconduct »),.
En Europe, la Commission européenne a rappelé que les règles de l’UE « exigent que cette responsabilité incombe toujours à l’entreprise » :  si un produit est défectueux, ou en cas de négligence, c’est bien le laboratoire qui est responsable, mais en cas d'effet secondaire inconnu avec poursuites judiciaires l'UE peut contribuer à l'indemnisation.En 2020, la pandémie de Covid-19 attise les théories du complot de groupes antivaccins actifs dans de nombreux pays comme les États-Unis et le Canada.Alain Fischer, pédiatre, professeur d'immunologie et président du Conseil d'orientation de la stratégie vaccinale, indique que ces fausses nouvelles ne viennent "que d'une toute petite minorité qui vient du milieu médical et scientifique, qui a dévoyé le discours scientifique".
Cette information ressort également du rapport du Center for Countering Digital Hate résultant de l'analyse de près de 812 000 publications sur des réseaux sociaux.Selon le spécialiste en santé publique Tim Caulfield, la pandémie de Covid-19 contribue à discréditer le mouvement antivaccin et à diminuer certaines controverses sur la vaccination, car elle permet à de nombreux sceptiques de constater par eux-mêmes à quoi ressemble un monde sans vaccin.De nombreux arguments sont invoqués :Paradoxalement, le succès des vaccins à réduire les maladies vaccinables laisse apparaitre au grand jour des effets indésirables.
Le vaccin étant administré à des personnes saines, et le risque de maladie étant moins perceptible, la population est moins encline à tolérer ces effets indésirables.
Les vaccins sont ainsi « victimes de leurs succès ».De plus les opposants à la vaccination attribuent au vaccin toute affection qui suit une vaccination, même lorsque des études épidémiologiques de plus en plus robustes ne montrent pas de rapport de causalité.
Devant la persistance de fausses allégations (par exemple vaccin/autisme), c'est devenu un défi pour les autorités de conserver le soutien des populations pour les campagnes de vaccination.De nombreux autres arguments sont régulièrement évoqués : la population peut avoir l'impression d'une densité excessive du calendrier vaccinal ; elle a une méconnaissance des éléments de base de la santé publique et il y a une perte de mémoire générationnelle de la gravité des grandes endémies ; elle pâtit d'une mauvaise communication des pouvoirs publics et du corps médical.Selon une enquête de l'INPES en 2004, 40 % des personnes interrogées déclarent ignorer de quelle façon agissent les vaccins, une méconnaissance qui, selon Science&Santé, « fait le lit de la méfiance ».Les vaccins sont inutiles puisque la régression des maladies infectieuses serait due aux progrès de l'hygiène et des soins.Selon Figaro santé, cet argument repose sur le fait que les décès dus à certaines maladies infectieuses ont régressé avant l'apparition du vaccin dédié.
Mais le Figaro santé affirme qu'il est plus pertinent d'observer le nombre total de personnes malades que les décès : les données montrent alors la diminution voire la disparition de la maladie après le démarrage de la vaccination.
Le Figaro santé donne un exemple « éloquent » : après une suspension du vaccin contre la coqueluche au Japon, le nombre de malades annuels passe de 373 en 1974 à 13 000 en 1979.
Lorsque le programme de vaccination redémarre en 1981, le nombre de malades diminue, alors que le Japon n'a pas amélioré l'hygiène dans ces années là.
Le Figaro santé affirme également que la coqueluche n'est pas sensible à l'hygiène, la bactérie se transmettant uniquement par voie aérienne.Anny Poursinoff avance que pour la rougeole, « en 1987, avec une couverture vaccinale d'à peine 10%, il y eut dix décès » et appelle à procéder à un bilan des politiques vaccinales mises en place depuis des décennies.
En France, en 1987, la couverture vaccinale contre la rougeole était de près de 60 %.
Le bilan de la politique vaccinale a été fait puisqu'au cours des années 1960-1970, il y avait plus de 600 000 cas annuels de rougeole (avec 10 à 30 décès chaque année), contre 331 000 cas en 1986 et 4 448 cas en 2004.La communauté scientifique et l'OMS reconnaissent que l'hygiène de l'eau permet de faire régresser des maladies infectieuses.
L'OMS indique cependant que les vaccins sont nécessaires, car l’hygiène, l’assainissement, la qualité de l’eau et la nutrition ne sont pas suffisants à eux seuls pour stopper les maladies infectieuses.
L'OMS a réuni les études scientifiques qui montrent l'efficacité des vaccinations, et affirme que des maladies devenues rares, comme la coqueluche, la poliomyélite et la rougeole réapparaîtraient rapidement sans les vaccins.
Aussi les vaccinations, comme l'hygiène de l'eau, sont régulièrement classées dans la liste des dix plus grandes réalisations de santé publique.Le profit financier expliquerait l'obligation vaccinale.
Pourtant l'obligation vaccinale s'imposait alors que le secteur économique des vaccins restait marginal, du fait de la complexité de développement et du faible coût de revient (contrairement à un médicament, un vaccin n'est pas administré en continu).Au début du XXIe siècle, le marché du vaccin s’est cependant élargi avec de nouvelles spécialités, vaccins monovalents ou combinés, comme le Prevnar (en) (en France Prévenar), le Gardasil, le Pediarix, etc., qui rapportèrent chacun plus d’un milliard de dollars en 2008, sans être obligatoires.Le LEEM évalue le marché mondial des vaccins à 42,3 milliards d'euros en 2016, avec une croissance constante qui l'amènerait à 80 milliards en 2025.
Ces vaccins représentent une part de plus en plus grande du marché pharmaceutique mondial en raison de la demande croissante des pays en développement, par le prix de vente plus élevé de produits issus de technologies plus onéreuses, et par la mise à disposition de nouveaux vaccins pour un plus grand nombre de maladies.Ces nouveaux profits générés sont un des arguments les plus courants contre les nouvelles obligations vaccinales françaises 2018 (« jackpot pour les laboratoires »).
Elles représenteraient un surcoût annuel estimé de 10 à 20 millions d'euros, que les laboratoires se partageront en effet mais qui sont à relativiser, par exemple, avec les bénéfices totaux de Sanofi (5 milliards d'euros en 2016) pour des ventes (produits pharmaceutiques, dont vaccins) de 33,8 milliards d'euros en 2016.
Pour 2017, ces chiffres sont respectivement 5,1 milliards et 35 milliards, représentant des ventes mondiales,.Ces nouvelles obligations vaccinales françaises sont de 11 vaccins, mais applicables seulement aux enfants de moins de deux ans, nés après 2018.En France, la première loi d'obligation vaccinale est celle contre la variole en 1902.
En 1938, les vaccins obligatoires scolaires sont le BCG, la diphtérie, la variole, le tétanos, auxquels s'ajoutent la typhoïde et le typhus au service militaire.
Mais ces lois sont très mal appliquées.
L'opposition est menée par le médecin Paul Chavanon (1898-1962), auteur prolifique antivaccinaliste, qui dénonce le « siècle de la seringue », les « cobayes soumis » et incite à la « grève des écoles ».En novembre 1941, le gouvernement de Vichy annonce vouloir rendre cette obligation stricte dès la rentrée prochaine, date toujours repoussée jusqu'en 1944.
L'obligation vaccinale sera effective durablement à partir de 1946.Pour les associations qui luttent contre la vaccination obligatoire, l’obligation vaccinale est considérée comme une atteinte à la liberté individuelle même quand la vaccination est jugée légitime au nom du bien commun.Les défenseurs de l'obligation rétorquent que « la coercition légale, dans la limite où elle est démontrée nécessaire à la protection de la santé publique du plus grand nombre, non seulement est nécessaire mais s’impose aux sociétés ».Des mouvements citoyens se sont toutefois mobilisés pour demander la fin de la vaccination obligatoire et l'arrêt des mesures de rétorsion envers ceux qui ne la respectent pas, notamment aux États-Unis et en Pologne,,.
À la suite d'un décret publié le 8 juin 2017 rendant obligatoire en Italie la vaccination des écoliers pour l'inscription à l'école, sous peine d'une amende et de l'exclusion des élèves en question, des manifestations sont organisées dans plusieurs villes du pays.Aux États-Unis, la Cour suprême a délégué le choix des obligations vaccinales depuis (au moins) l'arrêt de la Cour suprême des États-Unis Jacobson v. Massachusetts (en) (1905) au niveau des États, au nom du pouvoir de police attribué aux États fédérés lorsqu'il en va de la santé et du bien-être général de la population.Les oppositions religieuses à la vaccination ont été historiquement importantes lors des débuts de la vaccination en Europe.
Ces raisons religieuses se basaient essentiellement sur la providence divine ; certains croyants considéraient la maladie comme une fatalité ou un destin voulu par Dieu.
En fait, des oppositions revendiquées comme liées à la religion peuvent aussi masquer d'autres motifs (politiques, moraux, culturels…).Il faut donc distinguer entre les prises de positions officielles des représentants des grandes religions, et la réalité diverse des croyants : unis par une même religion, les croyants peuvent se différencier selon leur contexte national, leur histoire socio-politique ou socio-culturelle.Si l'on excepte quelques sectes et courants intégristes, il semble que la foi religieuse soit rarement à l'origine, ou la seule raison, du refus de vaccination.
Le discours religieux anti-vaccin apparaît plutôt comme la défense de valeurs traditionnelles et morales concernant le corps (la sexualité et la procréation) et la famille (rôle du père, place de la femme et des enfants).
Plus que le vaccin, c'est la vaccination elle-même qui est visée en étant perçue comme une intrusion immorale et étrangère (l'État, le médecin…) dans un domaine intime (comme la vaccination des jeunes filles).
Le refus vaccinal serait alors une inquiétude devant la transformation des mœurs et de la famille dans le monde moderne.En juillet 2021, pendant la pandémie de covid-19, les instances religieuses de France — juives, musulmanes, catholiques et protestantes — appellent leurs fidèles à se faire vacciner massivement et à lutter contre les théories complotistes.Un sermon de 1772 intitulé « la pratique dangereuse et pécheresse de l’inoculation » par le théologien Edward Massey laissait entendre que la variolisation était une « opération diabolique » quand les maladies de Dieu étaient là pour punir leurs victimes du péché.
Les autorités pontificales n'ont toutefois jamais émis d'avis négatif concernant cette pratique.Cependant, selon Pierre Burney « Il n'est pas douteux qu’il y ait eu des croyants pour considérer la vaccination comme une innovation suspecte et impie mais cette opposition semble avoir été grossie (…) pour les besoins de lutte anticléricale ».Il n'existe pas d'opposition canonique aux vaccinations, mais certains vaccins ont pu être soupçonnés, notamment sur la base de rumeurs ou de malentendus.Par exemple le vaccin antitétanique rendrait stérile, il s'agissait de recherches sur un vaccin contraceptif injectable, où l'hormone de grossesse était « complexée » (liée-transportée) par l'anatoxine tétanique, mais sans visée antitétanique.
Cette confusion ou fausse information d'un réseau catholique du mouvement pro-vie Human Life International a rendu suspect l'ensemble des vaccins dans des pays comme les Philippines, le Nicaragua, le Mexique, la Tanzanie, le Kenya… où des cardinaux et des évêques se sont opposés à des campagnes de vaccination.
Les analyses commandées à Rome ont clairement innocenté le fabricant, mais sans convaincre définitivement les populations concernées.Le Vatican a exprimé en 2005 des inquiétudes au sujet de la composition du vaccin contre la rubéole cultivés sur cellules diploïdes humaines issues de lignées de cellules de fœtus avortés (avortements thérapeutiques des années 1960).
Le Vatican a conclu cependant que tant qu’il n’existait pas de choix alternatif, il était acceptable que les catholiques utilisent le vaccin existant mais en précisant que c'était « un choix injuste qui devait être éliminé rapidement » lorsqu'une alternative serait possible.
En 2008, l'instruction Dignitas Personae du Vatican concluent aussi sur l'argument de « moindre mal » : le vaccin existant est acceptable face au danger pour la santé des enfants.En 2021, le pape François encourage les fidèles à se faire vacciner et affirme que la vaccination contre le covid-19 est un "acte d'amour"La plupart des protestants ne s'opposent pas à la vaccination, en soutenant que « Dieu a donné la connaissance des médicaments et des vaccins » , mais il existe des minorités qui les refusent.Un groupe protestant fondamentaliste influent aux États-Unis est le Family Research Council, qui déconseille le vaccin contre le papillomavirus humain aux jeunes filles parce qu’il risquerait de favoriser la « promiscuité sexuelle » en laissant penser qu’avec ce traitement « le sexe serait sans risque ».
La vaccination étant perçue comme une incitation à détourner les jeunes femmes de la voie de la chasteté jusqu'au mariage.Les Congrégations réformées hollandaises (en), présentes aux Pays-Bas et en Amérique du Nord, sont connues pour leur refus traditionnel de vaccination, notamment celles qui se situent dans le Bijbelgordel.
Toutefois on constate une augmentation de la couverture vaccinale dans ces communautés aux Pays-Bas, lorsque la pratique vaccinale est comparée avec la construction des digues.La plupart des communautés Amish refusent la vaccination, mais en situation épidémique, les leaders locaux sont plutôt enclins à la tolérer.Parmi les courants à la marge du christianisme opposés à la vaccination, on trouve la très radicale Science chrétienne (à ne pas confondre avec l'Église de Scientologie) qui est la seule secte chrétienne à tenir officiellement un discours anti-vaccin en toutes circonstances : une maladie ne se soigne, ou ne se prévient, que par la prière.Les Témoins de Jéhovah furent longtemps de farouches opposants à la vaccination (et le demeurent pour la transfusion sanguine), mais ils sont devenus neutres dans les années 1950, et leur journal officiel a reconnu le bien-fondé de la plupart des vaccinations dans les années 1990.Les mormons se distinguent par un soutien clair et net à la vaccination, par des dons, soutiens logistiques et partenariat avec les grandes organisations internationales.L'Islam est dépourvu de pouvoir central pouvant émettre des avis généraux, ce qui empêche une vision homogène des problèmes de société.
Il n'existe pas de rejet purement théologique de la vaccination, les différentes approches se situent dans un contexte politique : rapport des citoyens aux autorités civiles et religieuses, histoire coloniale et post-coloniale.En Afghanistan et au Pakistan, dans les zones tribales des Talibans, des mollahs ont émis des fatwas contre la vaccination qu'ils percevaient comme une tentative de s'opposer à la volonté d'Allah et un moyen pour les Américains de stériliser les femmes musulmanes.
Ils ont même assassiné le directeur de la campagne de vaccination de la Bajaur Agency au Pakistan.
Les arguments sont d'ordre complotiste plus que religieux : il est question de l'inefficacité des vaccins, de leur dangerosité, et d'un stratagème des juifs et des américains, ce dernier point s'appuyant sur le fait que la CIA s'est servi de campagnes de vaccinations pour retrouver la trace de Ben Laden en 2011,.Depuis 2003, une situation analogue se retrouve dans le nord du Nigéria, dans des zones contrôlées par le Boko Haram.
La rumeur de vaccin rendant stérile et donnant le sida est aussi répandue en Inde dans des populations musulmanes sous-médicalisées.Cependant, l'Organisation de la Conférence Islamique et la 15e conférence annuelle du Conseil International Fiqh ont toutes deux conclu que la vaccination n'était pas opposée aux principes de la foi musulmane.
Certains muftis considèrent même la vaccination comme une obligation morale quand elle permet de préserver les populations de maladies dangereuses.Une grande enquête mondiale de la London School of Hygiene & Tropical Medicine sur la vaccination et la religion (enquêtes d'opinions) montre que la moyenne mondiale des personnes déclarant une incompatibilité entre leur foi et les vaccins (toutes religions confondues) est de l'ordre de 15%.
Pour des pays musulmans comme l'Afghanistan, le Pakistan, ou le Nigeria, cette proportion est inférieure à 10 %.
Les populations musulmanes qui dénoncent plus souvent les vaccins sont celles d'Algérie et du Kosovo (27% des interrogés).
Les données sont manquantes pour l'Égypte.Le cas de l'Iran montre l'engagement des autorités chiites en faveur de la vaccination, décrétée comme un devoir religieux obligatoire, et vécue comme une aumône religieuse.
De même les autorités wahhabites d'Arabie Saoudite, ont instauré depuis 2001 la vaccination obligatoire contre le méningocoque (vaccin tétravalent contre A, C, Y et W135) pour le pèlerinage à la Mecque.Dans la religion juive traditionnelle, vers 1850, le rabbin Lipshutz (1782-1860) autorise la vaccination et qualifie Edward Jenner de « juste parmi les nations ».
En Israël, la vaccination est imposée et les allocations familiales retirées aux parents qui la refusent pour leurs enfants.Ces parents appartiennent à des communautés juives ultra-orthodoxes de Jérusalem, présentes aussi aux États-Unis (Brooklyn) et en Grande-Bretagne (Londres).
Toutefois, il ne s'agit pas de raisons toujours religieuses, mais aussi d'opposition politique (rejet de la couleur politique du gouvernement en place).Le bouddhisme, le jaïnisme et l'hindouisme ne s'opposent pas à la vaccination.
Ce qui serait en partie lié au fait que l'inoculation de la variole a été une pratique traditionnelle de médecine préventive populaire en Inde et en Chine.Cependant Gandhi (1869-1948) était, à titre personnel, défavorable à la vaccination, jugée comme une pratique sauvage et étrangère et détournant l'Inde de la recherche d'autres solutions basées sur l'hygiène.
L'antivaccinisme en Inde contemporaine est porté par une « contestation post-coloniale » qui considère les maladies comme le résultat des inégalités nord-sud et de la misère sociale.S'il n'y a pas d'opposition officielle du bouddhisme à la vaccination, il n'empêche que les populations bouddhistes de trois pays y sont les plus opposées (incompatibilité entre les vaccins et leur religion) : Mongolie, Thaïlande et Vietnam.
Les raisons de cet état de fait ne sont pas claires, mais il se pourrait qu'il s'agisse de revendications d'autonomie ou d'individualisme (poids d'un passé, colonial ou communiste) qui s'expriment par la religion.La vaccination est fermement rejetée par de nombreux mouvements religieux alternatifs et sectes.En particulier, l'influent mouvement anthroposophique, tradition mystique fondée par l'occultiste allemand Rudolf Steiner, voit dans les vaccins un « handicap karmique », les maladies étant perçues comme de justes punitions divines, qui ne tolèrent que la médecine anthroposophique - elle-même inventée par Steiner.
En conséquence, les écoles pratiquant la Pédagogie Steiner s'opposent catégoriquement à la vaccination des enfants, ainsi qu'à plusieurs autres traitements non issus de leur médecine anthroposophique.
Ce refus en bloc de la vaccination constitue l'une des principales menaces légales pesant sur ces écoles, par ailleurs très décriées pour leur risque de dérive sectaire.D'autres mouvements contemporains comme l'Église de Scientologie ne semblent pas opposées à la vaccination.Selon Homéopathes sans frontières les maladies infantiles jouent un rôle bénéfique dans le développement d’une immunité correcte, alors que les vaccins ne donneraient qu'une protection de durée limitée en affaiblissant par leur nombre (vaccins polyvalents) le système immunitaire.
Cette opinion n'est pas étayée scientifiquement, et plusieurs études contredisent cette thèse,.Plusieurs courants de médecines non conventionnelles s’opposent à la vaccination, comme certains homéopathes, certains chiropracteurs ainsi que la médecine anthroposophique pour les maladies infantiles,,.Daniel David Palmer, le fondateur de la chiropraxie, écrivait : « c’est le sommet de l’absurdité que de tenter de protéger une personne de la variole en lui administrant un poison animal dégoûtant.
»En France, le sociologue Jocelyn Raude distingue trois principaux courants parmi les antivaccins : « ceux qui appartiennent à des mouvements politiques, en particulier d’extrême droite et d’extrême gauche, ceux proches des sphères conspirationnistes et les adeptes des médecines alternatives.
» Les réseaux d'écoles liées à une spiritualité semblent également très actifs dans l'opposition à la vaccination : cela concerne notamment la pédagogie Steiner-Waldorf (fondée par un occultiste autrichien pendant l'entre-deux-guerres), mais aussi les écoles catholiques affiliées au courant intégriste de la Fraternité sacerdotale Saint-Pie-X.D'après un sondage Ifop initié par Conspiracy Watch et la fondation Jean-Jaurès, 43 % des sondés adhèrent à l'énoncé complotiste suivant : « le ministère de la Santé serait de mèche avec l’industrie pharmaceutique pour cacher au grand public la réalité sur la nocivité des vaccins ».Les thèmes des militants opposés à la vaccination sont de plusieurs types :L'influence de cette rhétorique, et l'exposition aux polémiques médiatiques, expliquent les résultats du baromètre Santé de l'Institut national de prévention et d'éducation pour la santé .
Par exemple, à la question posée aux Français âgés de 15 à 75 ans « Êtes-vous très, plutôt, plutôt pas ou pas du tout favorable à la vaccination ?
», 8 % se déclarent plutôt pas ou pas du tout favorable en 2000, 38 % en 2015.Les milieux antivaccinalistes utilisent internet pour diffuser leurs théories.
Internet permet un accès direct à de nombreuses informations de santé, jusqu'alors peu disponibles pour le grand public (livres et revues médicales).
Ces militants investissent les réseaux sociaux sur internet où ils diffusent des discours anxiogènes sans fondement scientifique.Le médecin Henri Joyeux, professeur de cancérologie à la retraite, et selon l'AFP l'un « des principaux avocats des anti-vaccins en France, bien qu'il s'en défende », lance une lettre-pétition « antivax » le 19 mai 2015, qui a recueilli plus d'un million de signatures au 30 janvier 2018.
Cette pétition est diffusée par une association intitulée Institut de Protection de la Santé Naturelle (ISPN), consacrée à la promotion et à la commercialisation de médecines alternatives.Les créations de groupes prônant la « liberté vaccinale » permettent un accès large et un recrutement facile de profils.
Les sites de partages en ligne contenaient auparavant une partie non negligeable de vidéos antivaccinalistes (25,3 % des vidéos en lien avec la vaccination sur YouTube la décrivaient négativement).
Cela peut orienter les décisions de vaccination vers des informations non scientifiques sur la vaccination, et faire passer les informations scientifiques validées au second rang.
Les anti-vaxx sont aussi plus actifs: selon les auteurs d'une enquête sur les publications dans les réseaux sociaux concernant la vaccination, lancée par une agence de communication spécialisée dans l'analyse de l'opinion en ligne, et un cabinet de conseils en politique de santé, « les « antivax » sont de loin les plus actifs sur les réseaux sociaux lorsqu’il s’agit de dénoncer le bien-fondé et la sécurité de la vaccination : ils publient et relaient des messages bien plus régulièrement que les « provax » »,.Début 2019, les médias sociaux ont pris des mesures pour limiter la désinformation antivaccinaliste.
Pinterest cesse de renvoyer les résultats des recherches liées à la vaccination.
De son côté, YouTube ne monétise plus les vidéos anti-vaccin et supprime les publicités associées à ces vidéos.
En mars 2019, Facebook annonce sa volonté de diminuer la diffusion de fausses informations sur les vaccins et la visibilité des groupes et des pages publiant ce type d’information.
Amazon supprime de son catalogue plusieurs documentaires complotistes sur la vaccination.Le journaliste Damien Leloup déclare « ironiquement, pour un mouvement qui prétend souvent dénoncer les vaccins comme la création rémunératrice d’un lobby pharmaceutique, l’opposition aux vaccins peut aussi rapporter de l’argent.
Une poignée d’entreprises et d’« experts » cherchent depuis plusieurs années à rentabiliser la méfiance à l’égard des vaccins, en utilisant tous les outils qu’offre le Web ».La première monétisation de la propagande anti-vax est l'affichage de publicités sur des sites, qui apporte une rémunération proportionnelle à la fréquentation du site.
Le groupe Facebook « Vaccins, alternatives, protection et défense des enfants en France !
», qui compte 10 000 abonnés en France, diffuse sur le réseau social des articles « mensongers et « attrape-clics » », dont les liens conduisent les internautes vers un site où est affiché de la publicité.
Une autre source de rémunération est l'abonnement payant à des newsletters, comme celles de « Santé Nature Innovation ».Une autre forme de monétisation consiste à vendre à ces communautés virtuelles des traitements « alternatifs » en ligne.
De nombreux sites consacrés aux « médecines non conventionnelles » et très critiques vis-à-vis de la vaccination, vendent divers produits comme les huiles essentielles et les extraits de plantes, et peuvent parfois proposer des stages payants, comme l'association Régenère.
Le site « Santé Nature Innovation » a été épinglé fin 2017 par l'UFC-Que choisir « pour ses prétendus remèdes miracles et ses pratiques commerciales ultra-agressives ».Toujours selon le journaliste Damien Leloup, la plupart de ces sites sont adossés à des petites structures associatives ou entrepreneuriales qui dans leur grande majorité, lorsqu'elles adoptent une ligne anti-vaccinale, « semble le faire par conviction plus que pour l’appât du gain ».
Mais ce mouvement possède ses best-sellers, livres ou vidéos, comme le documentaire Vaxxed qui repose sur le travail discrédité du médecin désormais radié Andrew Wakefield, qui a produit une étude frauduleuse dénonçant à tort un lien entre vaccination et autisme.
Andrew Wakefield a créé une fondation, Strategic Autism Initiative, qui l'a rémunéré 300 000 euros sur cinq ans.
L'anti-vaccination n'est cependant pas toujours profitable à ses promoteurs, avec par exemple l'échec du financement participatif de la suite du documentaire Vaxxed, et ce dernier a été supprimé du catalogue de vente d'Amazon.
De plus, les réseaux sociaux semblent désormais prendre conscience de leur responsabilité dans la propagation d'informations fausses concernant les vaccins et s'engagent à lutter contre.Les fêtes du virus provoquent de manière récurrente des controverses et sont découragées par les responsables de la santé publique, en faveur de la vaccination.Selon certaines études, la réduction (volontaire ou non) de l’utilisation de vaccins dans certains pays a provoqué une recrudescence des maladies et une augmentation de la mortalité,.
En 1873, une campagne religieuse contre la vaccination a fait chuter la vaccination de 40 % à Stockholm au XIXe siècle provoquant une réapparition de la variole qui fut à nouveau éradiquée par le vaccin ensuite.En 1974, l’utilisation du vaccin contre la coqueluche chuta de 77 à 30 % en Grande-Bretagne.
Dans les années qui suivirent, le nombre de cas rapportés augmenta et plusieurs épidémies importantes se déclarèrent.
De même, de 1979 à 1996, la Suède interrompit la diffusion du vaccin contre la coqueluche à la suite de quoi 60 % des enfants furent contaminés, la mortalité ne dépassant cependant pas un individu par année.
L’OMS a estimé à 294 000 le nombre de décès en 2002 dus à la coqueluche dans les pays ne pratiquant pas la vaccination.En 1999-2000, un épisode épidémique de rougeole dans une communauté religieuse aux Pays-Bas a démontré les conséquences de la non-vaccination.
Parmi 2 961 cas recensés, environ 95 % des personnes atteintes n'étaient pas vaccinées.
Trois personnes sont mortes et 68 ont dû être hospitalisées pour des complications sévères.
Une résurgence de la rougeole en 2005 dans l'État d'Indiana aux États-Unis fut attribuée à des parents qui avaient refusé la vaccination pour leurs enfants.
En 2014, il y a eu également plusieurs épisodes de rougeole aux États-Unis, en particulier 383 cas dans une communauté Amish de l'Ohio qui refusait la vaccination (par comparaison, en 2012, le nombre total de cas de rougeole pour l'ensemble des États-Unis était de 55 seulement, la plupart importés de l'étranger).Au début des années 2000, un groupe de religieux conservateurs au Nigeria, rejetant la médecine occidentale, conseilla à ses adeptes de ne pas vacciner leurs enfants avec le vaccin oral contre la poliomyélite.
Le boycott fut adopté par le gouverneur de la province de Kano et aucun vaccin ne fut administré pendant plusieurs mois.
La polio réapparut dans une douzaine de provinces qui ne présentaient pas de cas de la maladie auparavant.
En 2006, le Nigeria avait la moitié des cas de polio du monde.La majorité des cas de tétanos chez des enfants surviennent dans les familles où les parents ont refusé de faire vacciner leurs enfants.En France, le célèbre médecin et vulgarisateur scientifique Michel Cymes s'est engagé contre les discours anti-vaccination, notamment pour avoir vu un enfant mourir de la rougeole.En France, au 20 février 2018, une épidémie de rougeole est signalée.
On dénombre 2 500 cas entre novembre 2017 et juin 2018 dont 2 décès.
Les données mettent en évidence des cas groupés dans « des communautés incomplètement ou non vaccinées, telles les gens du voyage, les Roms ou des populations précaires fréquentant les centres d’hébergement, populations peu ou non vaccinées qui devraient pouvoir bénéficier de mesures de prévention ciblé ».
La non vaccination de certaines populations a été mise en évidence dans cette épidémie, notamment les personnes entre 20 et 40 ans.
Selon The Lancet, au cours du premier semestre 2018, en Europe, 41 000 cas de rougeole ont été signalés, faisant 37 morts, dont 14 en Serbie.En janvier 2019, l'Organisation mondiale de la santé a listé « l'hésitation vaccinale », c'est-à-dire le refus ou la réticence à être vacciné, comme une des 10 menaces contre la santé mondiale en 2019.En novembre et décembre 2019, une épidémie de rougeole fait soixante-deux morts aux Samoa, dont cinquante-sept enfants âgés de moins de quinze ans, parmi lesquels vingt-six bébés âgés de moins d'un an.
La rougeole atteint également les Tonga et les Fidji, mais sans y faire de morts ; dans ces deux pays, plus de 90 % de la population est vaccinée, alors qu'aux Samoa le taux de vaccination est d'environ un tiers.
Le gouvernement samoan décrète un état d'urgence et introduit la vaccination obligatoire,.
Les 5 et 6 décembre, les commerces sont tenus de fermer et presque toute activité est suspendue dans le pays ; les « services de vaccinations sont les seuls autorisés à se déplacer,  passent de maison en maison pour administrer les vaccins ».
Selon le gouvernement, le faible taux de vaccination avant ces dates serait du notamment aux « campagnes anti-vaccin qui abondent sur les réseaux sociaux », alimentées par des Samoans expatriés en Australie et aux États-Unis.En novembre 2020, l'Organisation mondiale de la santé indique une augmentation de 50% des décès dus à la rougeole, avec 207 500 morts en 2019, "principalement par une vaccination insuffisante des enfants".
Les polysaccharides (parfois appelés glycanes, polyosides, polyholosides ou glucides complexes) sont des polymères de la famille des glucides constitués de plusieurs oses liés entre eux par des liaisons osidiques.Les polyosides les plus répandus et connus dans le règne végétal sont la cellulose et l’amidon, tous deux polymères du glucose.De nombreux exopolysaccharides (métabolites excrétés par des microbes, champignons, vers (mucus du ver de terre) jouent un rôle majeur — à échelle moléculaire — dans la formation, qualité et conservation des sols, de l'humus, des agrégats formant les sols et de divers composés « argile-exopolysaccharide » et composites « organo-minéraux » (ex.
: xanthane, dextrane, rhamsane, succinoglycanes).De nombreux polyosides sont déjà utilisés comme des additifs alimentaires sous forme de fibre (ex.
: inuline) ou de gomme naturelle et les polysaccharides d'origine végétale suscitent depuis la fin du XXe siècle beaucoup d'attention pour leurs applications actuelles ou potentielles, biomédicales, alimentaires et industrielles en raison de leur variabilité structurelle, de leur large spectre de propriétés et d'une toxicité généralement relativement faible.Ce sont des polymères formés d'un certain nombre d'oses (ou monosaccharides) ayant pour formule générale :Ils constituent une famille très importante de molécules, souvent ramifiées.Ils ont tendance à ne pas prendre de forme particulière, on les dit « amorphes ».Ils sont insolubles dans l'eau et n'ont pas de pouvoir sucrant.On distingue deux catégories de polysaccharides :Les constituants participant à la construction des polysaccharides peuvent être très divers : hexoses, pentoses, anhydrohexoses, éthers d'oses et esters sulfuriques.Selon l'architecture de leur chaîne, les polysaccharides peuvent être :On peut aussi classer les polysaccharides selon leur fonction biologique en deux groupes :Les polysaccharides jouent aussi un rôle important dans la structuration de forme complexe de vie chez les bactéries comme Myxococcus xanthus.Des recherches récentes sur les polysaccharides constituant la capsule d'une souche d'Escherichia coli uropathogène ont montré que ces polysaccharides empêchent la formation de biofilm ; en leur présence les bactéries comme le staphylocoque doré, deviennent incapables de s'organiser en biofilm.
Ils jouent le rôle d'« antiadhésif » et empêchent les contacts entre les micro-organismes.Les polysaccharides de formule (C6H10O5)n, comme l'amidon, la cellulose, l'inuline, sont des substances de réserve exclusivement végétales.
On rencontre l'amidon dans les tubercules (pomme de terre, manioc) et dans les céréales, la cellulose dans les légumes, les herbes, et l'inuline dans les bulbes (d'ail, d'oignon, etc.) ainsi que les racines de radis, de dahlia, d'astragale, etc.Divers polysaccharides d'origine végétale et fongique, trouvés dans un large éventail d'espèces chez les plantes supérieures, les champignons, les lichens et les algues montrent des propriétés thérapeutiques bénéfiques, qui semblent liées à leur capacité à moduler l'immunité innée (et, plus spécifiquement, la fonction des macrophages).Certains de ces polysaccharides dits « botaniques » sont capable d'activer ou de renforcer la réponse immunitaire des macrophages (immunomodulation), avec parfois comme effet une activité anti-tumorale, cicatrisante.Certains polysaccharides microbiens ou d'origine végétale se lient aux récepteurs de surface communs et induisent des réponses immunomodulatrices similaires dans les macrophages.
Ceci invite à penser que leurs caractéristiques structurelles ont été conservées au cours de l'évolution et restent partagées entre un grand nombre d'organismes.Leur étude est donc une opportunité pour découvrir de nouveaux médicaments et adjuvants immunomodulateurs.Le polysaccharide GY785 produit par la bactérie extrêmophile Alteromonas infernus, obtenu par précipitation à l'éthanol peut réparer une lésion de tissu humain en complément de l'injection de cellules souches du patient.
Le recours a des greffes exogènes risquées peut être évité ainsi que des interventions chirurgicales invasives.
Les polysaccharides sont une ressource renouvelable de substitution aux dérivés pétroliers pour créer des polymères biologiques.En mai 2005, le réseau européen de laboratoires de recherche travaillant sur les polysaccharides a été constitué, qui fédère seize laboratoires travaillant dans neuf pays.
En France, l'Office national d'indemnisation des accidents médicaux, des affections iatrogènes et des infections nosocomiales (ONIAM) est un organisme public créé par la loi du 4 mars 2002 relative aux droits des malades et à la qualité du système de santé.
Placé sous la tutelle du Ministère de la santé, il a pour mission d'organiser le dispositif d'indemnisation - amiable, rapide et gratuit - des victimes d'accidents médicaux.
L'ONIAM organise l'indemnisation amiable, rapide et gratuite des victimes d'accidents médicaux, non fautifs (et fautifs en cas de défaillance de l'assurance), sans passer par une procédure en justice.Grâce à ce dispositif, la victime d'un accident médical grave peut être indemnisée :Il s'agit des dommages occasionnés par :La victime peut ainsi être indemnisée rapidement grâce au traitement amiable de son dossier sachant qu'elle peut toujours, si elle le préfère, saisir les tribunaux.Après sa création par la loi du 4 mars 2002, la mission d'indemnisation de l'ONIAM a été progressivement élargie aux victimes :Le Conseil d’administration comprend, outre son président : onze membres représentant l’État,  neuf membres désignés par arrêté du ministre chargé de la santé, pour une durée de trois ans renouvelable (deux personnalités qualifiées en matière de responsabilité médicale et de réparation du risque sanitaire ; deux représentants des usagers proposés par les associations des personnes malades et des usagers du système de santé ayant fait l’objet d’un agrément au niveau national ;un représentant des organisations d’hospitalisation publique les plus représentatives ; un représentant des organisations d’hospitalisation privée les plus représentatives ;un représentant de la Caisse nationale de l’assurance maladie des travailleurs salariés ; un représentant des professionnels de santé exerçant à titre libéral proposé par le Centre national des professions de santé ; un représentant des professionnels de santé exerçant dans les établissements publics de santé, désigné après avis des organisations syndicales représentatives au plan national) ; deux représentants du personnel de l’office.Le président du conseil d'administration est nommé pour une durée de trois ans, renouvelable une fois, par décret pris sur proposition du Ministre chargé de la Santé.Un conseil d'orientation,  présidé par le président du conseil d'administration de l'office, :assiste le conseil d'administration de l'ONIAM.
Il comprend, outre des représentants de l'Etat et des administrations sociales et de santé des représentants des usagers du système de santé et des personnes qualifiées.Ce dispositif s’appuie sur trois acteurs distincts mais qui œuvrent pour un même objectif dans le cadre d’une même procédure : indemniser, de la façon la plus équitable possible, les victimes d’accident médical sur tout le territoire français.L’ONIAM prend en charge les frais d’expertise nécessaires à l’instruction des dossiers suivis par ces Commissions de conciliation et d’indemnisation (CCI).
Il leur apporte un soutien administratif et technique en mettant à leur disposition les personnels nécessaires.
Il s’appuie sur les avis émis par les Commissions de Conciliation et d’indemnisation (CCI).Elles sont chargées de :Dans chaque région, une ou plusieurs de ces commissions sont chargées de faciliter le règlement amiable des litiges.Elle est chargée de prononcer l’inscription d’experts en accidents médicaux sur une liste nationale, d’établir des recommandations sur la conduite des expertises, de veiller à l’application homogène du dispositif et d’en évaluer le fonctionnement dans un rapport annuel.
Chaque type d’accident médical donnant droit à une indemnisation bénéficie d’une procédure spécifique.Pour être indemnisées, les victimes peuvent saisir les Commissions directement sans passer par un avocat.
Dans chaque région, une ou plusieurs commissions de conciliation et d’indemnisation sont chargées de faciliter le règlement amiable des litiges relatifs aux accidents médicaux, aux affections iatrogènes (effets secondaires liés à un traitement médical), et aux infections nosocomiales (infections contractées dans un établissement de santé).
Selon le Canard Enchaîné, une enquête de gendarmerie est en cours à la suite d'un rapport de la Cour des comptes.
Vingt-cinq millions d'euros se seraient évaporés.
La médecine expérimentale (ou médecine scientifique) désigne une connaissance médicale fondée sur la méthode expérimentale.Le physiologiste français Claude Bernard est le premier théoricien de la médecine expérimentale qu'il a pratiqué avec succès tout au long de carrière.
Son Introduction à l'étude de la médecine expérimentale, parue en 1865, en expose les principes théoriques et en fait la promotion.
Bernard élabore la médecine expérimentale notamment à partir du positivisme d'Auguste Comte, qui prévaut dans la philosophie français de la seconde moitié du XIXe siècle.A la fin du XIXe siècle et au début du XIXe siècle, la médecine scientifique connaît un essor important grâce à la création et au développement d'institutions dédiées à la recherche médicale, telles que en France l'Institut Pasteur et son réseau international (institut Pasteur de Lille, de Tunis, Dakar, etc) ainsi que l'Office national d’hygiène sociale crée en 1924 et préfigurant l'INSERM (crée en 1964).Basée sur la distinction entre différents niveaux de preuves, la médecine fondée sur les preuves (evidence based medicine en anglais) est un prolongement de la médecine expérimentale au XXe et XXIe siècles.
La différence principe réside dans l'usage d'outils statistiques, inexistants à l'époque de Claude Bernard.
La médecine expérimentale compare en effet les valeurs de différents paramètres physiologiques dans l'état normal et dans l'état pathologique chez un faible nombre de sujets sans se soucier de la signification statistique de l'écart mesuré tandis que la  médecine fondée sur les preuves recourt à des essais comparatifs randomisés et à des tests statistiques pour corroborer ou rejeter ses hypothèses.
En médecine et pharmacologie, les voies d'administration désignent l'ensemble des moyens d'administration d'un médicament ou, plus généralement, d'une substance chimique.Les voies d'administration sont essentiellement fonction de la forme galénique du médicament, et sont typiquement divisées en trois grandes catégories.D'une manière générale, une administration par voie cutano-muqueuse désigne une absorption par la peau, les muqueuses ou les membranes.
Ces voies peuvent être utilisées pour des traitements à visée locale ou générale (systémique).
Les médicaments administrables par cette voie sont les patchs, les gels, les crèmes, les pommades, les lotions, les collyres, les sprays, les gouttes ou encore les ovules.L'absorption se fait :D'une manière générale, une administration par voie entérale désigne une absorption par le tube digestif.
Les médicaments administrables par voie entérale peuvent être administrés :L'absorption peut se faire par plusieurs biais :D'une manière générale, une administration par voie parentérale désigne les formes d'introduction d'un médicament dans l'organisme autre que par la voie digestive.
L'introduction est corollaire d'une effraction d'un tissu biologique.
Cela désigne par exemple une administration par perfusion.Les médicaments administrables par voie parentérale sont les solutions physiologiques, suspensions injectables pour la voie générale, ou encore d'autres types de fluides en injection locale.L'introduction du médicament se fait en employant une méthode de cathétérisme et peut se réaliser sur plusieurs sites :
Un antigène est une macromolécule naturelle ou synthétique qui, reconnue par des anticorps ou des cellules du système immunitaire d’un organisme, peut déclencher une réaction immunitaire.
Les antigènes sont généralement des protéines, des polysaccharides et leurs dérivés lipidiques.
Des fragments d'antigènes appelés haptènes peuvent aussi provoquer une allergie.Les antigènes (de l'acronyme anglais antigen, pour antibody generator) et les anticorps, dont la combinaison est à la base de la réaction immunologique d’un organisme contre un agent extérieur, n’ont pas de définition intrinsèque, mais se définissent l’un par rapport à l’autre :Ainsi toute substance étrangère, tout microbe, introduit dans le corps, peut se comporter en antigène, c’est-à-dire y provoquer la fabrication de protéines spéciales, les anticorps qui ont la propriété de neutraliser les effets nocifs de la substance étrangère ou du microbe et des toxines qu’ils produisent.
Ce faisant, le corps devient réfractaire à l’agent envahisseur ; on dit qu'il s’immunise.Les antigènes, en tant que marqueurs d'agents étrangers à l'organisme, sont à la base de la réaction immunitaire adaptative.
C'est la reconnaissance de l'antigène par les cellules immunocompétentes, directement ou via les cellules présentatrices d'antigène (CPA), qui active l'immunité spécifique.Dans le cas d'antigènes protéiques, on nomme « épitope » ou « déterminant antigénique » la partie de l'antigène reconnue par un anticorps ou un récepteur lymphocytaire.
Un même antigène peut comporter plusieurs épitopes (identiques ou différents) et ainsi provoquer une réaction immunitaire variée.
Il existe des épitopes séquentiels, correspondant à une séquence d'acides aminés, et des épitopes conformationnels, liés à la structure de la protéine et donc sensibles à la dénaturation.
La reconnaissance de l'antigène par les lymphocytes dépend de la nature de l'épitope.
Les lymphocytes B se lient directement aux épitopes conformationnels grâce aux immunoglobulines de leur membrane.
Les lymphocytes T reconnaissent les épitopes séquentiels présentés par les cellules présentatrices d'antigènes.C’est le potentiel d’un antigène à provoquer une réaction immunitaire.
Elle dépend :C’est la capacité de l’antigène à être reconnu par le système immunitaire.
Une substance peut être antigénique mais pas immunogène.Ils sont étrangers à l’individu et peuvent être :Ce sont des antigènes propres à l’hôte (auto-antigènes) et pouvant être considérés comme étrangers (dans le cadre de maladies auto-immunes notamment ; ces antigènes sont dits cryptiques, c'est-à-dire qu'ils ne sont pas reconnus par le système immunitaire en situation normale.
Du grec ancien κρυπτικός, kriptikós : "caché").
Ils sont présentés par les molécules HLA de classe 1 aux CD8.Les antigènes de type protéique sont très immunogènes et souvent utilisés pour fabriquer des vaccins (pour cela, il faut un PM minimum de 1 500 Da).Ce sont des polymères à structure ordonnée constitués d’épitopes identiques se répétant.Deux types :Les polyosides sont des constituants ubiquitaires à la surface cellulaire, ils sont également très immunogènes.Ils sont généralement très peu immunogènes sauf s’ils sont associés à des protéines.Leur immunogénicité est très faible même s’il existe des anticorps anti-ADN.
De la même manière que pour les lipides, on peut augmenter leur pouvoir immunogène en les associant à des protéines.Quand une molécule fait moins de 1 500 Da, elle ne présente qu’un seul déterminant antigénique, on l’appelle alors : haptène.Un haptène est non immunogène.
En l’associant à une protéine porteuse (carrier) qui apporte au moins un déterminant supplémentaire, le complexe devient immunogène.Il s’agit de macromolécules de synthèse obtenues par polymérisation d’acides aminés.C’est le nombre d’anticorps capables de se lier simultanément sur une molécule.
La valence est donc proportionnelle à la surface de la molécule mais ne reflète pas le nombre d'épitopes à cause de l’encombrement stérique que peuvent occasionner les anticorps.Il existe aussi des réponses immunitaires dites indépendantes de l'interaction avec des lymphocytes T auxiliaires.
Ces réponses sont très faibles voire absentes chez le nourrisson avant 2 ans.
Toutefois la plupart des antigènes sont thymo-dépendants.Ils sont impliqués dans une coopération avec les lymphocytes T.
La CPA doit dégrader l’antigène (structure complexe, ex : protéine) et le présenter à sa surface par les molécules CMH de classe II.
Les antigènes thymo-dépendants impliquent toutes les Immunoglobulines.
Le lymphocyte B peut en effet commencer sa maturation après le contact avec le lymphocyte T auxiliaire, il rejoint un centre germinatif dans l'organe lymphoïde secondaire où il se trouve et entame son processus de maturation : hypermutations somatiques, commutation isotypique, maturation d'affinité.
Ainsi une telle réponse immunitaire est de plus grande qualité, mais plus longue à mettre en place par le corps (temps de latence).L’agrégation de l’antigène à motifs répétés (par exemple des antigènes exogènes de nature polyosidiques) à la surface des lymphocytes B suffit à activer ces LB.
Ce type d’antigène n’implique que les Immunoglobulines M puisqu'il n'y a pas maturation de ces lymphocytes B et donc pas de commutation isotypique, qui normalement a lieu pendant la maturation des lymphocytes B après un contact entre le lymphocyte B et le lymphocyte T auxiliaire et la migration des lymphocytes B dans un centre germinatif de l'organe lymphoïde secondaire en question, où il mature.
Ces antigènes induisent donc une réponse immunitaire plus rapide, mais de moins grande qualité.Il faut noter que la réponse thymo-indépendante est de deux types : un type I et un type II, selon le mode d'activation des lymphocytes B impliqués (et donc selon la nature de l'antigène TI).
La réponse TI-1 implique une voie commune d'activation parmi plusieurs lymphocytes B différents, la réponse n'est donc pas spécifique et l'activation est polyclonale (ce qui est différent de la notion d'anticorps polyclonaux).
Une réaction analogue, mais toutefois non comparable, se produit lors de la réponse immunitaire avec un superantigène.
Une telle réponse immunitaire s'explique parce que ces antigènes peuvent être reconnus par des récepteurs communs à plusieurs lymphocytes B, et donc plusieurs types de lymphocytes B différents réagissent.
La réponse immunitaire est régulée par le phénomène de tolérance périphérique, médié principalement par les lymphocytes T régulateurs et B régulateurs (découverts récemment).La réponse TI-2, quant à elle, provoque une stimulation monoclonale (ce qui est différent de la notion d'anticorps monoclonaux) des lymphocytes B. Comme dans une réponse immunitaire classique seuls les lymphocytes B capables de reconnaître l'antigène dont ils sont spécifiques vont être activés et réagir.
Cette fois-ci la reconnaissance de l'antigène passe par le récepteur des cellules B (BCR), qui est spécifique d'un seul type de lymphocyte B, ce qui explique pourquoi la réponse est cette fois-ci spécifique et donc monoclonale.Un état immunodépressif caractérise un organisme dont le fonctionnement du système immunitaire est altéré de façon négative, la personne immunodépressive voit ses défenses immunitaires affaiblies.
Plusieurs causes sont possibles : des médicaments immunosuppresseurs (dans ce cas l'immunodépression est réversible), des infections par certains virus (comme le VIH-1), un état de fatigue transitoire, la malnutrition ou encore la présence de maladies qui ne concernent pas obligatoirement directement le système immunitaire, mais qui jouent un rôle dans son affaiblissement (soit directement soit par les traitements médicamenteux lourds).Pour une personne immunodéprimée au niveau de la lignée des lymphocytes T (T CD4+ par exemple) les antigènes thymo-dépendants peuvent être un facteur de risques, celui-ci évoluant selon le niveau de gravité de cette immunodépression.
Ces antigènes nécessitant une coopération des lymphocytes B avec les lymphocytes T auxiliaires, si ces derniers ne sont pas en nombre suffisant le corps peut avoir du mal à se défendre, voire en être incapable et être agressé par des maladies opportunistes causant la mort (par exemple dans le cas de la phase SIDA de l'infection par le VIH-1 où la lignée CD4+ est gravement touchée).
Une personne immunodéprimée au niveau de cette lignée peut tout de même réagir de façon convenable aux antigènes TI.
Cependant rares sont les antigènes induisant une réponse de type TI.
De plus cela ne change rien à la gravité d'un état immunodépressif prononcé, puisque c'est le corps lui-même qui développe des affections, soit parce qu'il ne maintient plus son intégrité (il ne supprime plus les cellules anormales, ce qui débouche sur des cancers), soit parce qu'il est beaucoup plus fragile à des agents pathogènes externes (virus, bactéries…).Dans le cas d'une immunodépression touchant la lignée humorale, les conséquences sont tout aussi graves mais l'immunité à médiation cellulaire reste active.
Dans le cas de personnes immunodéprimées il convient donc de rechercher la cause de cette immunodépression et la lignée touchée, pour adapter les traitements et les vaccinations, qui sont différentes des personnes en bonne santé
La voie intramusculaire d'injection (IM) est utilisée en médecine pour l'administration de certains médicaments.
Elle sert pour injecter des vaccins, certains antibiotiques, pour lutter contre les douleurs aiguës (colique néphrétique - colique hépatique) avec des antalgiques, et en psychiatrie pour injecter des neuroleptiques ou sédatifs souvent sans consentement.
Les sites d'injection préférentiels sont : le quadrant supéro-externe du muscle grand fessier, le deltoïde, plus rarement le quadriceps.Le produit injecté peut être absorbé plus ou moins rapidement en fonction de ses propriétés chimiques.Exemples de produits administrés par voie IM :Afin de ne pas être accidentellement injecter en intraveineux, l'opérateur tire sur le piston de la seringue pour vérifier l'absence de reflux avant d'injecter.C'est une voie contre-indiquée en cas de risque hémorragique (trouble de la coagulation ou traitement anticoagulant : héparine ou coumarinique), possibilité d'apparition d'un hématome important, parfois compressif.
La voie nasale est la voie d'administration de médicaments au niveau du nez et des cavités nasales.Différentes formes galéniques sont possibles : goutte nasale, spray nasal, pommade nasale, solution pour lavage nasal, poudre nasale, crème nasale, etc.L’action des médicaments pris par voie nasale peut être locale ou générale (systémique).L'utilisation de la voie nasale comme voie permettant au principe actif d'avoir une action systémique dans tout le corps a les avantages et les inconvénients suivant :La cavité nasale est recouverte d'une muqueuse mince qui est bien vascularisée.
Par conséquent, une molécule de médicament peut être rapidement transférée à travers la couche cellulaire épithéliale unique directement dans la circulation sanguine systémique sans subir l’effet de premier passage hépatique et le métabolisme intestinal.
L'effet est souvent atteint en 5 min pour les petites molécules de médicaments.
La voie nasale peut donc être utilisée comme une alternative à la voie orale si un effet rapide est souhaité ou si le médicament est fortement dégradé dans l'intestin ou le foie.
Les médicaments qui présentent une faible capacité d'absorption peuvent aussi être administrés par cette voie.La voie nasale est principalement appropriée pour des médicaments puissants puisque seul un volume limité peut être pulvérisé dans la cavité nasale.
Les médicaments pour une administration continue et fréquente peuvent être moins appropriés en raison du risque d'effets nocifs à long terme sur l'épithélium nasal.La voie nasale a également été associée à une grande variabilité dans la quantité de médicament absorbé.
Cette variabilité peut être liée aux infections des voies respiratoires supérieures, à l'irritation sensorielle de la muqueuse nasale, aux différences dans la quantité de pulvérisation de liquide et aux différences dans le processus de pulvérisation.
Cependant, la variabilité de la quantité absorbée après administration par voie nasale devrait être comparable à celle absorbée par voie orale,.
Un vaccin à ARN, ou vaccin à ARN messager, est un type de vaccin activant le système immunitaire adaptatif au moyen d'ARN messagers dont la séquence nucléotidique code une protéine identique ou semblable à un antigène d'agent pathogène ou à un antigène tumoral (en).
Cette protéine est produite directement dans les cellules cibles par traduction de l'ARN messager contenu dans le vaccin, et est reconnue par le système immunitaire de l'organisme, qui réagit en produisant des anticorps dirigés contre l'agent pathogène ou le cancer qu'on cherche à neutraliser.
L'ARN messager peut être nu, c'est-à-dire délivré directement en solution, ou bien encapsulé (en) dans des nanoparticules lipidiques ; des virus à ARN sont également étudiés comme vecteurs possibles de vaccins à ARN.Ce type de vaccins présente certains avantages sur les vaccins à ADN du point de vue de la fabrication, du mode d'administration aux patients et de la sécurité d'utilisation,, et a pu montrer des effets prometteurs lors d'essais cliniques sur les humains.
Les vaccins à ARN pourraient également présenter un intérêt contre certains cancers.
Plusieurs laboratoires pharmaceutiques tels que CureVac et Moderna développent de tels vaccins, dont plusieurs depuis début 2020 contre la COVID-19.
Le vaccin Tozinaméran, développé par BioNTech et Pfizer, a reçu le 2 décembre 2020 au Royaume-Uni la première autorisation pour l'utilisation grand public d'un vaccin à ARN de la part d'un organisme national de régulation des médicaments.Un vaccin à ARN est généralement fabriqué par transcription in vitro.
L'ARN peut être injecté dans la cellule par transfection, électroporation (électroperméabilisation), biolistique ou transfert adoptif de cellules ex vivo.
La transfection peut être réalisée à l'aide de nanoparticules lipidiques,, de peptides de pénétration cellulaire, de protéines et de polymères.
On peut également utiliser des nanoparticules d'or d'environ 80 nm de diamètre,,.
Ces structures sont nécessaires pour favoriser l'absorption par les cellules de l'ARN, qui est instable in vivo.
L'ARN absorbé par transfection pénètre dans la cellule par endocytose médiée par des récepteurs,.
L'absorption cellulaire en culture ne permet de présager que faiblement de l'absorption cellulaire in vivo et il n'y a aucune corrélation entre l'absorption en culture cellulaire et l'effet vaccinal observé in vivo, de sorte que ce dernier ne peut être évalué avant la phase d'essais cliniques.Au sein de l'Union européenne, les vaccins à ARN luttant contre les maladies infectieuses sont considérés comme des médicaments biologiques et plus précisément comme des médicaments immunologiques au sens de la directive 2001/83/CE consolidée.La production d'antigène dans le cytosol de la cellule conduit, après clivage par des protéases, à présenter les épitopes de l'antigène au complexe majeur d'histocompatibilité de classe I, qui active l'immunité cellulaire, et au complexe majeur d'histocompatibilité de classe II, qui active l'immunité humorale.Un ARN messager peut être traduit en un nombre de protéines d'autant plus élevé que cet ARNm est stable.
La demi-vie biologique d'un ARNm peut varier de quelques minutes, par exemple pour des protéines régulatrices, à quelques heures.
Elle peut être allongée par la présence d'une coiffe à l'extrémité 5’, de régions non traduites 5'-UTR et 3'-UTR, et d'une queue Poly(A) qui retardent l'action des ribonucléases et augmentent donc la quantité d'antigène produite.Une extension limitée de la demi-vie biologique, et donc de la quantité d'antigène produite, peut être obtenue à l'aide d'ARN auto-amplificateurs qui stimulent leur propre expression génétique,,.
Ceci doit permettre de réduire la quantité d'ARN utilisée pour la vaccination sans réduire l'effet vaccinal, 50 ng d'ARN ayant été décrits comme suffisants pour produire une vaccination effective.Les ARN auto-amplificateurs étant sensiblement plus grands que les ARN messagers, le mécanisme d'absorption cellulaire de tels ARN peut être différent.
Des adjuvants peuvent améliorer la réponse immunitaire, et ces vaccins sont plus efficaces lorsqu'ils sont formulés avec l'adjuvant MF59 dans une nanoémulsion cationique ayant un diamètre de gouttelettes inférieur à 100 nm.Les modes d'administration peuvent grossièrement être classés en ex vivo et in vivo selon que le transfert de l'ARNm aux cellules est réalisé respectivement à l'extérieur de l'organisme ou à l'intérieur de celui-ci.Les cellules dendritiques sont des phagocytes du système immunitaire qui présentent des antigènes sur leur membrane plasmique, d'où des interactions avec les lymphocyctes T qui déclenchent une réponse immunitaire.
Il est possible d'introduire l'ARNm vaccinal dans les cellules dendritiques prélevées sur un patient puis de réinjecter ces cellules dendritiques ainsi modifiées pour qu'elles expriment l'antigène et sollicitent le système immunitaire afin de réaliser la vaccination.L'intérêt pour le mode d'administration in vivo croît progressivement depuis la découverte de l'expression in vivo d'ARN messagers transcrits in vitro  après administration directe au patient.
Ces techniques présentent plusieurs avantages par rapport à l'administration ex vivo, principalement en évitant la collecte coûteuse des cellules dendritiques des patients et en imitant une infection par un agent infectieux.
Il reste cependant plusieurs obstacles à franchir avant de pouvoir faire de cette approche un mode d'administration efficace et sûr.
Il faut commencer par limiter la dégradation de l'ARN vaccinal par les ribonucléases destinées à protéger les cellules des acides nucléiques étrangers.
Il faut ensuite permettre à l'ARN vaccinal de diffuser dans les cellules afin qu'il ne soit pas éliminé par les processus cellulaires avant d'avoir pu être traduit en antigène.L'absorption d'ARNm est connue depuis 2007, et l'utilisation d'ARN comme vaccin a été découverte dans les années 1990 sous forme d'ARNm auto-amplificateur.
Il est apparu que les différentes voies d'injection (sous-cutanée, intraveineuse, intramusculaire, etc.) se traduisent par des niveaux d'absorption d'ARNm différents, ce qui fait du mode d'injection un choix déterminant de l'administration du vaccin.
On a pu montrer que l'injection dans les ganglions lymphatiques conduisent à la réponse aux lymphocytes T la plus élevée.
L'administration des ARNm auto-amplificateurs peut cependant différer sensiblement de cette approche car ce sont en pratique des molécules bien plus grosses.L'encapsulation de l'ARN messager dans des nanoparticules lipidiques est intéressante à plusieurs titres.
Tout d'abord, la couche lipidique protège l'ARN de la dégradation, ce qui accroît la quantité d'antigène produit.
De plus, sa composition permet de cibler des cellules précises de l'organisme à l'aide de ligands.
La mise au point de tels vaccins est cependant difficile, avec une absence de corrélation entre l'absorption cellulaire d'ARNm observée in vitro et celle observée in vivo.
Les nanoparticules peuvent être administrées et véhiculées dans l'organisme par différentes voies, comme la perfusion intraveineuse ou par le système lymphatique.Outre les méthodes d'administration non virales, on a également modifié des virus à ARN pour induire un effet vaccinal.
Les virus généralement utilisés à cette fin sont par exemple des rétrovirus, des lentivirus, des alphavirus et des rhabdovirus, chacun ayant ses spécificités.
Plusieurs essais cliniques ont employé de tels virus contre diverses maladies sur des modèles animaux tels que les souris, les poulets et les primates,,.Par rapport aux vaccins à ADN, l'intérêt des vaccins à ARN est qu'ils sont traduits dans le cytosol des cellules, ce qui les dispense de devoir pénétrer dans les noyaux cellulaires et écarte le risque de voir leur matériel génétique être incorporé au génome de l'hôte,.
Il est en outre possible d'optimiser le cadre de lecture ouvert (ORF) et les régions non traduites (UTR) des ARN messagers, par exemple en augmentant leur taux de GC ou en sélectionnant des régions non traduites connues pour favoriser la traduction.
Un cadre de lecture ouvert supplémentaire peut également être ajouté pour fournir un mécanisme de réplication amplifiant la traduction en antigène, ce qui donne un ARN auto-amplificateur qui réduit la quantité initiale d'ARN nécessaire pour obtenir l'effet désiré.Le principal risque des vaccins à ARN est celui du déclenchement d'une réponse immunitaire excessive par activation du système immunitaire inné,.
La réponse immunitaire innée est activée par liaison de l'ARN aux récepteurs de type Toll, comme la protéine TLR7, à la protéine RIG-I (en) et la protéine kinase R (en).
On atténue ce risque en concevant des ARN messagers ayant des séquences semblables à celles produites par les cellules de mammifères et en introduisant, dans l'ARN messager, des nucléosides modifiés, comme la pseudouridine, la 5-méthylcytidine ou des nucléosides 2’-O-méthylés,, comme la 2’-O-méthyladénosine, ce qui a pour effet de limiter la réponse immunitaire contre cet ARN étranger, et donc de retarder sa dégradation, d'où un meilleur taux de traduction en antigène.
On peut également optimiser les codons et utiliser certaines régions non traduites,, ce qui ralentit également la dégradation de l'ARN.
Par ailleurs, la présence de traces d'ARN bicaténaire contaminant les préparations d'ARNs produits in vitro peuvent déclencher une interférence par ARN, ce qui peut conduire à la dégradation prématurée de l'ARN vaccinal et réduire sa durée d'action, imposant une purification en plusieurs étapes,.
L'ARN bicaténaire indésirable peut être éliminé par traitement à la RNAse III ou à moindre frais par adsorption sur la cellulose.Certains vaccins à ARN peuvent également produire une forte réponse immunitaire avec des interférons de type I, associés à l'inflammation ainsi qu'à des manifestations auto-immunes, ce qui fait des personnes sujettes aux maladies auto-immunes des sujets potentiellement à risque pour ces vaccins.Par ailleurs, l'ARN extracellulaire est connu pour être un facteur favorisant la coagulation sanguine et augmentant la perméabilité de l'endothélium.
L'accroissement de la perméabilité endothéliale peut entraîner un œdème et stimuler la coagulation sanguine ce qui entraîne un risque de formation de thrombus, d'où des risques d'infarctus (notamment d'infarctus cérébral), de thrombose ou encore d'embolie pulmonaire.
L'ARN qui se retrouve dans le sang est toutefois détruit très rapidement par des RNases et il n'est pas internalisé efficacement dans les cellules.Plusieurs vaccins à ARN potentiels pour protéger du SARS-CoV-2 et de la COVID-19 sont étudiés depuis le début de l'année 2020.D'autres vaccins à ARN sont à l'essai clinique contre des cancers,, depuis 2008, contre la grippe  depuis 2018 et contre la rage depuis 2009 (CV7201).Des campagnes de désinformation soutiennent que les vaccins à ARNm pourraient altérer l'ADN du noyau cellulaire.
En fait, l'ARNm présent dans le cytosol se dégrade très rapidement avant d'avoir le temps de pénétrer dans le noyau cellulaire.
(On rappelle que les vaccins à ARNm doivent être conservés à très basse température pour éviter la dégradation de l'ARNm.)
Un rétrovirus, qui peut lui aussi être constitué d'un ARN simple brin, pénètre dans le noyau cellulaire et utilise la transcriptase inverse pour y produire de l'ADN à partir de son ARN.
Mais ce rétrovirus dispose de mécanismes spécifiques lui permettant d'entrer dans le noyau, alors que les ARNm vaccinaux n'ont pas ces mécanismes.
À l'intérieur du noyau, la création d'ADN à partir d'ARN ne peut pas se produire sans une amorce, présente dans les rétrovirus, mais qui manquerait à l'ARNm vaccinal dans l'hypothèse où il serait rentré dans le noyau.
En médecine humaine, une pustule est une lésion inflammatoire dermatologique courante caractérisée par un soulèvement épidermique contenant d'emblée du pus.
Le système immunitaire adaptatif comprend les lymphocytes T, qui contribuent à l'immunité à médiation cellulaire, et les lymphocytes B, qui sont responsables de l'immunité à médiation humorale.
Ces deux populations cellulaires ont des propriétés et des fonctions distinctes des cellules du système immunitaire inné.Il existe deux caractéristiques majeures propres à l'immunité adaptative :Le système immunitaire adaptatif permet de construire au cours de la vie une immunité acquise qui, avec le système immunitaire inné, constitue le phénotype immunitaire des individus.Apparu chez les poissons cartilagineux il y a 500 millions d'années, le système immunitaire adaptatif n’existe que chez les agnathes (vertébrés dépourvus de mâchoires) et les gnathostomes (vertébrés à mâchoires).L'immunité adaptative est activée à la suite de la reconnaissance d'agents infectieux par le système immunitaire inné.
Bien que l'immunité innée permette de reconnaître des familles de pathogènes grâce à des récepteurs spécifiques dont il existe plusieurs types correspondant à plusieurs classes de pathogènes, elle ne peut pas reconnaître une espèce particulière : par exemple, elle peut reconnaître les bactéries Gram négatives, mais elle ne peut pas distinguer quelle espèce de Gram négative provoque l'infection.L'immunité adaptative est spécifique pour une espèce donnée et a un mécanisme de mémoire.
Le système immunitaire adaptatif permet d'amplifier la réponse immunitaire et confère à la fois une réponse spécifique à l'antigène, et donc particulièrement adaptée à l'agent infectieux, et une réponse mémoire permettant une élimination plus efficace du même agent infectieux si l'organisme y est de nouveau confronté.
Les cellules de l'immunité adaptative constituent ainsi un complément essentiel de la réponse immunitaire innée.Spécificité et mémoire sont les deux caractéristiques principales du système immunitaire adaptatif.Une autre caractéristique importante de l'immunité adaptative est la nécessité de mettre en jeu un nombre important de cellules spécifiques pour combattre un agent pathogène spécifique.
Cette multiplication spécifique est l'expansion clonale.
Elle nécessite plusieurs jours, ce qui explique que les effets de l’immunité adaptative n'apparaissent qu'au bout d'environ sept jours.Au début du XXe siècle, les biologistes pensaient que, au vu du nombre très important de pathogènes possibles, il n'était pas possible pour l'organisme de produire, à l'avance, des récepteurs pour tous les antigènes pathogènes.
Les biologistes pensaient que la pénétration d'un microbe entraînait une production par l'organisme de récepteurs capables de reconnaître le microbe, puis que dans un second temps ces récepteurs nouvellement synthétisés signalaient la présence d'un microbe aux lymphocytes qui produisaient enfin des anticorps.
Cette théorie était nommée la théorie interventionniste.
Cette théorie est fausse.L'organisme produit à l'avance des récepteurs pour tous les microbes présents et à venir.
Si cette production dépendait du génome présent dans les lymphocytes, la taille du génome lymphocytaire contenant moins de 25 000 gènes serait insuffisante.
Il faudrait des millions de gènes pour stocker autant d'information.L'organisme peut fabriquer des milliards de récepteurs grâce à un mécanisme nommé la recombinaison somatique qui se produit dans l'ADN des lymphocytes B et T se trouvant dans les ganglions.
La production des récepteurs des lymphocytes B et T s’accompagne de modifications de l'ADN de ces lymphocytes.Le répertoire immunitaire est l'ensemble formé par les lymphocytes B et T ayant un récepteur membranaire spécifique pour un pathogène.
Seule une partie du répertoire des lymphocytes peut reconnaître un antigène donné, par conséquent seule une partie du répertoire des lymphocytes est activée par un antigène donné dans un contexte infectieux.Les immunoglobulines sont des structures protéiques dont il existe deux formes : les immunoglobulines membranaires au niveau des lymphocytes B naïfs qui vont recevoir l’antigène du pathogène et les immunoglobulines solubles qui sont sécrétées dans le plasma par les plasmocytes (cellules dérivant des lymphocytes B).
Les immunoglobulines solubles sont nommées anticorps et vont se fixer sur le pathogène.L'immunoglobuline est formée de deux chaînes protéiques : la chaîne lourde et la chaîne légère.
Il existe cinq classes, parfois nommées isotypes, d'immunoglobulines désignées par une lettre de l'alphabet (cette lettre de l’alphabet est en fait la première lettre du nom de la lettre grecque donnée par les biologistes à chaque chaîne lourde) : immunoglobuline A, immunoglobuline D, immunoglobuline E, immunoglobuline G, immunoglobuline M.Les immunoglobulines membranaires se fixent au niveau des lymphocytes B naïfs par une petite zone : la zone d'ancrage membranaire (B Cell Receptor).
La portion verticale d'une immunoglobuline, constituée uniquement de chaîne lourde, est nommée domaine Fc.
Le domaine Fc détermine la fonction de l'immunoglobuline : c'est par exemple sur cette partie que se fixent les protéines du système de complément et les cellules ayant une action phagocytaire comme les récepteurs Fc d'un macrophage (Fc Receptor).
C'est sur l’extrémité des portions variables que sont reconnus les antigènes du pathogène.L’immunoglobuline se divise en deux régions : la région constante (en violet sur le schéma) identique pour toutes les immunoglobulines de la même classe et une région variable (en vert sur le schéma).
La synthèse (formation) de la partie variable est un processus complexe car elle comporte une région hypervariable (à l’extrémité de la région variable) nommée CDR (Complementary Determining Regions) où se fixe l’antigène.Un antigène est toute molécule reconnue par les lymphocytes B ou T par l'intermédiaire des immunoglobulines sécrétoires et/ou membranaires.
Les parties de l'antigène qui sont reconnues par un anticorps sont appelées épitopes et la partie de l'anticorps reconnaissant l'épitope est appelée paratope.
La plupart des antigènes comportent plusieurs épitopes.La plupart des molécules, protéines, glycoprotéines, polysaccharides, lipoprotéine, lipopolysacharide, acides nucléique peuvent être des antigènes.
C'est même le cas pour des substances chimiques comme les métaux lourds ou les narcotiques.Les auto antigènes sont des antigènes qui font partie de son propre corps : ce sont les antigènes du soi.Les antigènes qui n'appartiennent pas à son propre corps sont les antigènes du non soi dont il existe deux catégories :L'immunogénicité est la capacité d'un antigène à produire une réponse par le système adaptatif.
Certains antigènes ne produisent pas de réponse immunitaire.
On nomme haptène un antigène de faible masse moléculaire qui a besoin d'un porteur pour provoquer une réponse immunitaire du système adaptatif.Pour que la réponse immunitaire adaptative reconnaisse, élimine, et se « rappelle » les multiples antigènes exprimés par les multiples agents infectieux rencontrés au cours de l'existence, le système immunitaire doit pouvoir reconnaître un très grand nombre d'antigènes différents.
Un être humain est à priori capable de produire près de mille milliards d'anticorps différents.La multitude des récepteurs antigéniques est produite par un processus appelé sélection clonale.
Selon la théorie de la sélection clonale, à la naissance, un animal génère de façon aléatoire une immense diversité de lymphocytes dont chacun exprime un récepteur antigénique unique à partir d'un nombre limité de gènes.
Afin de générer des récepteurs antigéniques uniques, ces gènes sont soumis au processus de recombinaison somatique, durant lequel chaque segment de gène se recombine avec l'autre pour former un gène unique.
Le produit de ce gène donne ainsi un récepteur antigénique ou un anticorps unique pour chaque lymphocyte, avant même que l'organisme soit confronté à un agent infectieux, et prépare l'organisme à reconnaître un nombre quasiment illimité d'antigènes différents.Il existe cinq classes ou isotypes d'immunoglobulines.
Cette classification dépend de la zone constante de l'immunoglobuline (violet).L'immunoglobuline D n’existe que sous forme membranaire.
Il n’existe pas d'immunoglobulines D solubles (dans le sang).L'immunoglobuline M présente une forme sécrétée différente de la forme membranaire.
L'immunoglobuline M soluble est formée de cinq immunoglobulines M, ou pentamères.
Chaque pentamère a donc dix sites de reconnaissance antigénique, ce qui rend cette immunoglobuline particulièrement efficace pour la reconnaissance des antigènes pathogènes.Les immunoglobulines D et les immunoglobulines M sont les immunoglobulines retrouvées à la surface des lymphocytes B naïfs.L'immunoglobuline A dans sa forme soluble est un dimère.
La liaison reliant les deux immunoglobulines se nomme la chaîne J.
C'est l'anticorps le plus présent dans les muqueuses respiratoires, digestives et génitales.Les immunoglobulines E et G sont sécrétées sous forme de monomères.L'avidité des anticorps est une notion très importante.
L’avidité est la capacité (force de liaison) d'un anticorps à se fixer sur un antigène.L’avidité de l'anticorps dépend de deux facteurs :L'avidité des immunoglobulines G est très utilisée pour déterminer la datation d'une infection virale (rubéole, varicelle, etc.) ou parasitaire (toxoplasmose) chez la femme enceinte.
Une avidité forte signale une infection ancienne.
On élimine ainsi l'hypothèse d'une infection en début de grossesse en situant l'infection avant la grossesse.
L'apparition d'une avidité forte des immunoglobulines varie en fonction de l'infection.
Par exemple, pour les anticorps toxoplasmiques, l'avidité devient forte 4 mois après l'infection.
Une avidité forte des anticorps toxoplasmiques chez une femme enceinte de 10 semaines (2,5 mois) suspectée d'infection toxoplasmique en début de grossesse indique que cette infection a eu lieu avant la grossesse.Rappelons que les lymphocytes B sont responsables de l'immunité humorale par production d'anticorps.
Cette immunité s'attaque surtout au microbe extracellulaire ou avant que celui-ci pénètre dans la cellule comme les virus.Le BCR est le récepteur situé à la surface des lymphocytes B naïfs (avant toute stimulation par un microbe).
Le site de fixation de l’antigène est une immunoglobuline membranaire fixée par une petite zone : la zone d'ancrage membranaire (B Cell Receptor).
Cette zone ne pénètre pas dans la cellule.
Le BCR est incapable à lui seul de signaler à la cellule qu'un microbe s'est fixé sur lui.
Les immunoglobulines des BCR des lymphocytes B naïfs sont des immunoglobulines M et D.L'immunoglobuline membranaire a besoin d'un corécepteur pour signaler la présence d'un microbe : le CD79.
Il est formé de deux chaînes : alpha et bêta.
À l'intérieur de la cellule, le CD79 possède une zone nommée ITAM (motif d'activation des récepteurs immuns basé sur la tyrosine ou (Immunoreceptor Tyrosine-based Activation Motif) qui permet de signaler la présence d'un microbe par phosphorisation,,.Rappelons que les lymphocytes T sont responsables de l'immunité cellulaire.
Cette immunité s'attaque surtout au microbe intracellulaire.Le TCR est composé de deux parties :Une organisation particulière des gènes au niveau des chromosomes et un processus particulier nommé recombinaison somatique permettent la formation d'un répertoire immense de récepteurs.
La recombinaison somatique est un processus qui permet de joindre différents gènes localisés sur un chromosome.
Cette recombinaison est sous le contrôle de deux enzymes : les recombinases RAG1 et RAG2.La question de l'immunologie adaptative est de savoir comment les immunoglobulines et les lymphocytes T n'attaquent par les antigènes de la personne qui les produit.
Les mécanismes éliminant les cellules pouvant attaquer la personne qui les fabrique se font au cours de la maturation.La maturation des cellules B se produit dans la moelle osseuse.
La cellule souche donne un lymphocyte B selon des étapes bien définies :Ce processus de formation du répertoire des lymphocytes B par élimination est appelé sélection négative.La formation des récepteurs nécessite aussi un contrôle allélique, c'est-à-dire que les gènes impliqués dans la formation des chaînes lourdes et légères soient toujours d'origine maternelle ou paternelle.La maturation des cellules T se produit dans le thymus.
Elle obéit aux mêmes règles que celles du lymphocyte B pour la formation du récepteur des lymphocytes T.
La seule exception est que dans cette maturation, à côté de la sélection négative, il existe une sélection positive.
Cette sélection consiste à faire reconnaître par l'organisme les lymphocytes T réagissant à la présentation d'un peptide présenté par un MHCLe récepteur TCR se doit de reconnaître à la fois le peptide présenté par le MHC et le type de MHC : le type I pour les MHC que possèdent toutes les cellules de l'organisme et le type II qui existe seulement dans les macrophages, les lymphocytes B et les cellules dendritiques.
Cette reconnaissance du type de MHC se fait grâce à des corécepteurs présents à la surface des lymphocytes T, le corécepteur CD4 pour les MHC de type II, le corécepteur CD8 pour les MHC de type I.
La maturation des cellules T au niveau du thymus est régie par l'expression des corécepteurs CD4 et CD8 au niveau des lymphocytes T : les cellules n'exprimant ni CD4 ni CD8 sont nommées doubles négatives CD4− CD8−.
Les cellules exprimant CD4 et CD8 sont nommées doubles positives CD4 CD8 :Le processus de sélection aboutit à des lymphocytes T matures.La sélection négative détruit les cellules réagissant aux cellules du moi.La sélection positive assure que le lymphocyte T reconnaît un peptide présenté par une cellule dendritique :Il faut souligner que cette sélection se fait avec les peptides du soi, c'est pourquoi la sélection se fait sur la faible attractivité.Les organes lymphoïdes se divisent en organes lymphoïdes primaires et secondaires.Les organes lymphoïdes primaires comprennent la partie rouge de la moelle osseuse et le thymus.
La moelle osseuse est le siège de l'hématopoïèse chez l'adulte et de la génération des lymphocytes B. Les lymphocytes se multiplient, se différencient et maturent dans le thymus.
Dans la partie rouge de la moelle osseuse se trouvent les cellules souches hématopoïétiques ainsi que les souches des lymphocytes B et T.Les cellules souches se différencient en lymphocytes B, se multiplient, produisent le récepteur BCR, subissent la sélection négative et rejoignent la circulation sanguine.
Les cellules souches produisent aussi des progéniteurs des lymphocytes T qui vont se diriger immédiatement dans la circulation sanguine pour rejoindre le thymus où la maturation va se poursuivre.Le thymus comprend deux zones : la zone corticale et la zone médullaire.
Les progéniteurs des lymphocytes T prennent le nom de thymocytes quand ils pénètrent dans le thymus.
Dans la zone corticale, le thymocyte est d'abord doublement négatif, ne produisant ni le CD4 ni le CD8, puis le TCR est produit par réarrangement successif de gène TCRTK et du gène TCR alpha et le thymocyte devient CD4 positif et CD8 négatif.
La sélection positive TCR arrive ensuite, sélectionnant les thymocytes capables de reconnaître un MHC du soi.
Les thymocytes qui reconnaissent avec une faible affinité les MHC classe I deviennent positifs TCD8.
Les thymocytes qui reconnaissent avec une faible affinité les MHC classe II deviennent positifs TCD4.
Ce processus s'accompagne d'un nombre très important de déchets correspondant aux thymocytes pour lesquels le TCR est incapable de reconnaître un MHC du soi : ceux-ci meurent par négligence en l'absence d'un signal de survie.
Les thymocytes qui reconnaissent trop fortement un peptide sont également éliminés : c'est la sélection négative.A la fin du processus de maturation, les thymocytes sont libérés dans la circulation sanguine et deviennent des lymphocytes T.Les organes lymphoïdes secondaires sont les ganglions lymphatiques, la rate et les tissus lymphoïdes associés aux muqueuses.Le ganglion lymphatique comporte trois zones : la zone corticale pour les lymphocytes B, la zone paracorticale pour les lymphocytes T et les cellules dendritiques et la zone médullaire où se trouvent les plasmocytes secrétant les immunoglobulines.Le ganglion lymphatique bénéficie d'une double irrigation, une irrigation sanguine et une irrigation lymphatique par les vaisseaux lymphatiques.
Cette irrigation lymphatique permet aux cellules dendritiques de voyager du lieu de l'infection vers le ganglion pour présenter l’antigène.
Les lymphocytes B et T sont apportés par le sang.
Ils migrent dans le stroma lymphatique au niveau des veinules à endothélium épais (High Epithelium Venules ou HEV) qui se trouvent principalement dans la zone corticale.Les lymphocytes T et les cellules se trouvant dans la zone corticale, la présentation de l’antigène peut commencer.C'est la pulpe blanche de la rate qui est l’organe lymphoïde secondaire.
La pulpe blanche entoure les artérioles terminales de l'artère splénique formant l'enveloppe lymphoïde péri artériolaire (Peri Arterial Lymphatique Sheaths) où se trouvent des lymphocytes B.Comment le système immunitaire peut-il reconnaître un agent pathogène alors que le répertoire des lymphocytes comporte des milliards de cellules B et T porteuses d'un récepteur antigénique adéquat capable de reconnaître un antigène pathogène venant de pénétrer dans l'organisme ?
La réponse est que le système immunitaire a développé un mécanisme permettant de capter et de présenter l’antigène aux lymphocytes.La cellule dendritique est la cellule du système immunitaire spécialisée dans la présentation d’antigène,.
Elle prépare l’antigène et le présente aux récepteurs d’antigène des lymphocytes T et B. Il existe plusieurs types cellulaires pouvant présenter l’antigène mais les cellules dendritiques sont les seules à pouvoir initier la réponse des lymphocytes T.
Les cellules dendritiques sont présentes dans la peau, les muqueuses bronchiques, intestinales et de l'appareil urogénital.
Elles sont aussi présentes dans les ganglions lymphatiques pour les pathogènes ayant réussi à échapper aux cellules dendritiques périphériques et dans la rate pour les pathogènes pénétrant directement dans le sang,.La cellule dendritique existe sous deux formes : la forme immature et la forme mature.La forme immature réside dans les tissus périphériques et la rate.
Ces celules ont une capacité élevée de captation d'un antigène.
Elles portent plusieurs récepteurs à leur surface :La cellule dendritique devient mature lorsqu'elle capture l’antigène et migre dans le ganglion lymphatique.
Elle a une capacité élevée à présenter l’antigène et à activer des lymphocytes T mais elle perd sa capacité de captation de pathogènes (perte des FcR pour capter les immunoglobulines et des récepteurs du complément).
Ses récepteurs de surface changent :La cellule dendritique, en plus de la fonction de présentation de l'antigène, a une fonction costimulatrice par les récepteurs de pattern.Les cellules B et les cellules T ne reconnaissent pas les antigènes (microbes) de la même façon :Il existe deux modes de reconnaissance de l’antigène par les cellules B : le mode TD ou thymus-dépendant ou le mode TI ou thymus-indépendant.
Le mode TD nécessite une cellule T porteuse du corécepteur CD4 (lymphocyte T helper; ou T CD4+).
Le mode TI ne nécessite pas de T CD4+.Le mode TD est l'activation de la cellule B par une cellule CD4+ ayant été activée par le même antigène : la plupart des antigènes activant le mode TD sont des protéines.Le T CD4+ doit donc être stimulé par une cellule dendritique qui aura transmis un épitope (partie de l'antigène) de l'antigène au récepteur de la cellule T CD4+.L’antigène entier se fixe sur le récepteur de la cellule B, déclenchant un premier signal.Le T CD4+ va déclencher un deuxième signal en présentant l'épitope fixé sur son récepteur au CMH de type II du lymphocyte B. Cette présentation nécessite l'interaction du ligand CD40 du T CD4+ avec le CD40 de la cellule B,Le mode thymo-dépendant permet une réponse spécifique avec la production d'immunoglobulines G, A et E et la mémorisation de l'infection par le système immunitaire.Le mode TI est un mode qui ne nécessite pas de CD4+ et aboutit à la production d'immunoglobuline M durant quelques jours.
Ce mode est un mode peu spécifique contre un pathogène et sans mémorisation.
C'est un processus primitif de lutte contre l'infection.Ce mode nécessite la stimulation simultanée des récepteurs de la cellule B  et des récepteurs de pattern présent sur les cellules B.Ce mode nécessite uniquement la stimulation simultanée des récepteurs de la cellule B. Les antigènes sont dans des grosses molécules présentant des épitopes répétés.Le T CD4+ reconnaît des polypeptides de 10 à 30 acides aminés présentés par le MCH de classe II de la cellule dendritique.
Le T CD8+ reconnaît des polypeptides de 8 à 10 acides aminés présentés par le MCH de classe I présent sur toutes les cellules du corps humain à l'exception des cellules anuclées (hématie, plaquette).
Les peptides présentés par la cellule dendritique sont le résultat de la destruction du pathogène par la cellule dendritique.Le mode de reconnaissance de l’antigène diffère selon qu'il s'agit d'une reconnaissance par une cellule T naïve ou par une cellule T à mémoire.En immunologie, les cellules présentatrices de l’antigène (Antigen Processing Cell ou APC) sont les macrophages, la cellule dendritique et la cellule B. Ces trois cellules sont nommées APC professionnelles.
Mais la cellule dendritique est la seule capable d'activer in vivo les cellules T naïves.La cellule T naïve nécessite la présentation d'un peptide par la cellule dendritique sur le MHC de type II et un cosignalisateur CD80/86 sur la cellule dendritique reconnu par un corécepteur CD28 de la cellule T.Si la cellule présente le peptide à la cellule T sans activation par le corécepteur CD80/86, cela conduit à une inactivation de la cellule T appelée anergie.
C'est une forme de tolérance car l'absence du corécepteur signale l'absence de danger.
Cette tolérance est appelée tolérance périphérique si elle se situe dans les tissus périphériques ou tolérance centrale si elle se situe dans la moëlle osseuse ou le thymus.La cellule T mémoire nécessite uniquement la présentation d'un peptide par la cellule dendritique sur le MHC de type II sans cosignalisateur.La présentation de l'antigène se fait en deux étapes : la préparation de l’antigène et sa présentation.Le MHC est la molécule principale de présentation de l'antigène, mais il existe d’autres molécules pouvant présenter des antigènes, notamment la molécule CD1, qui ne présente que des antigènes lipidiques et des glycolipides.
Les cellules se fixant sur les CD1 sont certains TCD8, les lymphocytes NK et les lymphocytes T ayant des récepteurs gamma delta.La préparation de l'antigène est le clivage de l’antigène en plusieurs peptides.La présentation de l’antigène est la synthèse des molécules MHC par la cellule infectée, la capture des peptides viraux par le MHC et la migration du MHC à la surface de la cellule infectée ou de la cellule présentatrice d’antigène.La MHC de classe I est formé d'une chaîne alpha et d'une microglobuline.
La MHC de classe II est formé de deux chaînes alpha.La synthèse des MHC est sous la dépendance d'un locus 6p21,31 présent sur le chromosome 6 d’environ quatre millions de bases nommé locus HLA (Human Leucocyte Antigen).
Il existe plus de 220 gènes identifiés sur ce locus dont 40 pour la synthèse des MHC.Le locus HLA est divisé en 3 parties : les classes I, II et III.
La partie HLA I code la chaîne alpha des MHC de classe I.
La partie HLA II code les chaînes alpha et beta des MHC de classe II.
La synthèse des MHC est codominante, c'est-à-dire que les deux allèles des gènes participent à la formation des MHC : l’allèle maternel et l'allèle paternel.Les molécules MHC sont polymorphiques, contrairement aux autres protéines du corps humains.
Ce polymorphisme explique pourquoi certains individus résistent mieux aux infections en ayant des MHC plus performants pour présenter des peptides viraux : ainsi les individus porteurs du locus HLA B 2757 résisteront mieux au virus du SIDA car ils ont une meilleure capacité à présenter les antigènes de ce virus.Il existe trois voies de présentation de l'antigène :Les cellules du système immunitaire adaptatif sont les lymphocytes, dont les deux principaux types sont les lymphocytes T et les lymphocytes B. Le corps humain contient près de mille milliards de lymphocytes (10¹²) qui sont présents majoritairement dans le sang mais également dans la lymphe, les organes lymphoïdes et les tissus.Chez l'adulte, les organes lymphoïdes secondaires contiennent des lymphocytes T et des lymphocytes B pouvant être dans au moins trois stades de différenciation :Les cellules T sont au cœur de la réponse immunitaire adaptative.
Les cellules T assurent trois fonctions dans la lutte contre les infections :Les lymphocytes T auxiliaires, ou lymphocytes T CD4, jouent un rôle important dans l'établissement et le maintien de la réponse immunitaire adaptative.
Ces cellules n'ont ni capacité cytotoxique ni capacité de phagocytose et ne peuvent pas directement tuer des cellules cibles ou éliminer des agents infectieux, mais elles jouent un rôle essentiel dans l'orchestration de la réponse immunitaire.
Les lymphocytes T auxiliaires possèdent un récepteur antigénique qui reconnaît des peptides présentés par le CMH de classe II exprimé par les cellules présentatrices d'antigène professionnelles.
Les lymphocytes T auxiliaires activés relarguent des cytokines qui influencent l'activité de nombreux types cellulaires, y compris les cellules présentatrices d'antigène.
Les lymphocytes T auxiliaires peuvent activer d'autres cellules comme les lymphocytes T cytotoxiques ou les lymphocytes B.L'activation du lymphocyte T se fait par la formation de la synapse immunologique entraînant l'activation avec une phase de prolifération nommée expansion clonale par l'action de l'interleukine 2.
La prolifération s'accompagne d'une différenciation en lymphocytes cytotoxiques T CD8 et en cellules T à mémoire.L'activation des cellules T nécessite deux évènements : la reconnaissance de l’antigène par le récepteur de la cellule T (TCR) et une costimulation.
Le contact initial entre la cellule dendritique et la cellule T se produit avec des molécules d'adhésion cellulaire.
Après la reconnaissance du peptide montré par le MHC de classe II par le récepteur du lymphocyte T, un corécepteur va se former.
La synapse immunologique comprend :Un superantigène est une protéine virale qui se fixe simultanément sur le récepteur du lymphocyte T et sur le récepteur MHC, entraînant une libération brutale et massive de cytokines et une expansion clonale de cellules T incompétentes.Il existe deux classes de molécules costimulatrices :En l'absence de costimulation, la cellule T n'a pas d'expansion clonale.
La cellule T est incapable de lutter contre l'infection.
La costimulation est un mécanisme qui assure que la cellule T ne s'active que pour des pathogènes.Les molécules d'adhésion permettent à la cellule dendritique de rester suffisamment longtemps pour transmettre les signaux de reconnaissance de peptide et de danger au lymphocyte T.
Les molécules d'adhésion se trouvent sur les cellules T avec les ligands sur la cellule dendritique.Les molécules d'adhésion appartiennent à la famille des protéines hétérodimériques nommée intégrine, par exemple la protéine LFA-1 (Leucocyte Function Associated Antigen 1) qui se fixe avec une protéine ICAM 1 (Intracellular Adhesion Molecule 1) de la cellule dendritique.L'activation du T CD8 par une infection peut se faire de deux façons : soit la cellule dendritique est elle-même infectée (par un virus par exemple) ; dans ce cas la cellule dendritique va stimuler directement le T CD8 en lui présentant les peptides viraux via les MHC de type II aux récepteurs des cellules T CD8 naïves, ceux-ci se transformant en lymphocyte killer.
Donc, une activation des T CD8 en lymphocyte killer est possible sans intervention des T CD4Soit la cellule dendritique va phagocyter une cellule quelconque infectée par le virus, présenter le peptide viral aux cellules T CD4 et aussi aux cellules T CD8.
L'activation du T CD8 va nécessiter l'augmentation de l'activité des costimulateurs CD40/CD40L et la libération de cytokines.Le récepteur CD40 est présent dans les cellules B, les macrophages et les cellules dendritiques.Le complexe MHC-peptide/ TCR et les corécepteurs CD4/CD8 vont déclencher la voie de signalisation aussi nommée voie de transduction.
En biologie cellulaire, on appelle ainsi les cascades de protéines déclenchées par un récepteur de surface qui vont modifier le propriétés de la cellule le plus souvent à travers l'expression des gènes :Les cellules T sont au repos dans le thymus.
L'activation par la cellule dendritique va réveiller la cellule T qui va se multiplier en produisant un ensemble de cellules rigoureusement identiques et spécifiques pour attaquer le pathogène incriminé.
La molécule responsable de l'activation et de la prolifération des cellules T est la cytokine interleukine-2.
L' interleukine-2 va agir par voie autocrine (sur la cellule qui la produit)  ou par voie paracrine (sur les cellules proches d 'elle).
Les traitements immunosuppresseurs utilisés dans les greffes d'organes agissent en perturbant le fonctionnement de l'interleukine-2.
L'amplitude de la réponse diffère selon le type de cellule T.
Le nombre de cellules T CD8 va être multiplié par 100 000, le nombre de cellules T CD4 va être multiplié par un facteur compris entre 100 et 1000.
La division lymphocytaire est un processus long: la division d'une cellule lymphocytaire dure 6 heures environ.
Enfin, un clone cellulaire est spécifique pour un petit nombre de peptides immunodominants de l'agent infectieux.La réponse Th1 est caractérisée par la production d'interféron γ qui active l'activité bactéricide des macrophages et induit la production d'immunoglobulines IgG par les lymphocytes B. La réponse Th1 permet notamment une réponse efficace contre les bactéries intracellulaires et les virus.La réponse Th2 est caractérisée par la production d'interleukine 4, qui induit la production d'immunoglobulines IgE par les lymphocytes B.La réponse Th17 est caractérisée par la production d'interleukine-17 qui induit le recrutement de neutrophiles.
La réponse Th17 permet notamment une réponse efficace contre les bactéries extracellulaires et les levures comme Candida albicans.Il existe d'autres sous-populations de lymphocytes T effecteurs, comme les lymphocytes Th9 caractérisés par la production d'interleukine 9 ou les lymphocytes Th22 caractérisés par la production d'interleukine-22 ou les lymphocytes T folliculaires.
Les lymphocytes T régulateurs peuvent être préprogrammés ou être inductibles en périphérie comme les populations décrites ci-dessus et jouent un rôle important dans la régulation des réponses immunitaires.Comme pour les lymphocytes T cytotoxiques, une partie des lymphocytes T auxiliaires sont conservés après l'élimination d'un agent infectieux et constituent une population de lymphocytes T mémoire.Le virus de l'immunodéficience humaine infecte et élimine progressivement les lymphocytes T auxiliaires, ce qui a pour effet de compromettre l'efficacité de la réponse immunitaire contre les virus mais également contre d'autres classes de microorganismes et conduit au syndrome d'immunodéficience acquise.À côté de la fonction d'activation de la cellule T CD8 en T Killer et de la fonction de stimulation de la cellule B indispensable pour la sécrétion d’antigène, la cellule B CD4 peut se différencier en cellule directement active en exprimant des molécules de surface et des cytokines différentes.
Un des récepteurs de la cellule B activée est le ligand CL40L, Ce ligand CD40 L peut se fixer sur les macrophages au récepteur CD40.
Le système immunitaire répond de façon différente à des pathogènes différents comme les virus, les parasites, les bactéries, les helminthes ou les champignons.Par exemple, comme les helminthes sont trop gros pour être phagocytés, la réponse immunitaire à une infection par helminthes est dominée par la sécrétion d'immunoglobulines de type E et l'activation des éosinophiles.
Pour un microbe intracellulaire comme celui de la tuberculose, qui résiste à la destruction intracellulaire, le système adaptatif consiste à activer les phagocytes par les T CD4 pour tuer les cellules infectées.Cette réponse fait appel aux T CD4.
En créant des T CD4 spécialisés, le système immunitaire peut répondre à différents type d'infection.
Cette spécialisation est nommée la polarisation des cellules T.Les groupes les mieux étudiés sont les groupes spécialisés pour les infections intracellulaires (virus, mycobactérie, listéria) de type Th 1 et le groupe pour les infections des vers parasites.Tableau des cytokines impliquées dans le développement des CD4 Th1 et CD4.Cette différenciation se fait principalement par le type de cytokine produite.Les cellules Th1 produisent l'interféron gamma et l'interleukine-12 qui permet après activation du facteur de transcription T-Bet de :La réponse Th2 permet notamment une réponse efficace contre les parasites; Les réactions allergiques sont des réactions de type Th2Les cellules Th2 produisent l'interleukine-4, l'interleukine-5, l'interleukine-13 qui stimule, après activation du facteur de transcription GATA-3:Certaines populations de lymphocytes T auxiliaires ont une fonction prédéterminée, comme les lymphocytes T régulateurs qui se développent dans le thymus, alors que d'autres populations ont des fonctions inductibles.
Au cours d'une infection, les cellules présentatrices d'antigène professionnelles détectent des signaux microbiens caractéristiques de l'agent infectieux.
En fonction de ces signaux, les cellules présentatrices d'antigène peuvent produire différentes cytokines et exprimer différentes protéines à leur surface.
Lorsque ces cellules interagissent avec les lymphocytes T auxiliaires naïfs dans les ganglions lymphatiques, différents programmes de différenciation sont induits en fonction des cytokines produites.
Ainsi, des lymphocytes T ayant une spécificité donnée peuvent exercer des effets différents en fonction des signaux perçus par les cellules présentatrices d'antigène.Les cellules effectrices augmentent l'expression des molécules d’adhésion à leur surface afin de favoriser et d'étendre le contact avec les cellules présentatrices d'antigènes pour les CD4 et avec les cellules cibles dans le cas des lymphocytes cytotoxiques CD8+.
Les cellules effectrices modifient les récepteurs aux chimiokines nommés aussi récepteurs d’adressage qui permettent aux cellules T de quitter les ganglions lymphatiques et de migrer vers les sites d'infection (récepteur CCR5 et CXCR3).
Le récepteur CCR5 est utilisé par le virus VIH pour pénétrer dans les lymphocytes.
Une autre caractéristique des cellules T effectrices est la production de cytokines (IL-4) et d'enzymes (perforine et granzyme).En résumé, une cellule T effectrice produira des cytokines, des récepteurs de chimiokines, des protéines d'adhésion et des molécules spécifiques pouvant agir sur les cellules cibles.L'activation du macrophage nécessite l'action des lymphocytes T CD4+ Th1 par la production d'interférons gamma et l’interaction CD40:CD40L.
Le macrophage va présenter les peptides, grâce à son MHC, aux récepteurs du T CD4+ qui vont reconnaître ce peptide comme étant le même peptide présenté par la cellule dendritique alors que le T CD4 était naïf.
Le macrophage va produire des réactifs oxygénés et nitrogénés, des enzymes lysosomales qui rendent le macrophage beaucoup plus agressif.
La réaction du macrophage est proinflammatoire avec risque d'endommager les tissus cellulaires.
Le macrophage va à son tour libérer du TNF, de l' IL-1 et IL-12 et chemokines.
L'IL-12 va par un rétrocontrôle positif stimuler le Th1.Les actions des cellules Th2 se font grâce à la sécrétion des interleukines 4 et des interleukines 5.Les cellules Treg sont des cellules qui expriment le récepteur Foxp3.
Elles sont générées soit dans le tissu, soit dans les organes lymphoïdes secondaires.Elles participent à la tolérance périphérique en inhibant les réponses des cellules T par inhibition de l'interleukine 12.Les lymphocytes T cytotoxiques sont un sous-groupe de lymphocytes T qui sont capables d'induire la mort par apoptose des cellules infectées par des virus (ou par d'autres agents infectieux) ou des cellules cancéreuses.Les lymphocytes T cytotoxiques naïfs sont activés lorsque leur récepteur antigénique reconnaît un complexe peptide-CMH de classe I présenté à la surface d'une cellule cible.
L'interaction de haute affinité permet au lymphocyte T cytotoxique de rester en contact avec la cellule cible.
Une fois activés, les lymphocytes T cytotoxiques prolifèrent.
Ce processus, appelé expansion clonale, aboutit à un clone de cellules ayant une même affinité ce qui amplifie la réponse immunitaire spécifique de l'antigène reconnu.
Les lymphocytes T cytotoxiques activés recirculent ensuite dans l'organisme afin de contrôler les cellules présentant le même antigène que celui pour lequel ils sont spécifiques.Lorsqu'ils reconnaissent une cellule infectée ou une cellule cancéreuse, les lymphocytes T cytotoxiques relarguent des perforines qui induisent la formation de pores dans la membrane plasmique des cellules cibles, ce qui conduit à l'entrée d'ions et d'eau dans les cellules cibles et conduit à leur lyse.
Les lymphocytes T cytotoxiques relarguent également des granzymes qui entrent dans les cellules à travers les pores et induisent la mort des cellules par apoptose.
Afin d'éviter une dégradation tissulaire trop importante, l'activation des lymphocytes T cytotoxiques nécessite à la fois une interaction forte entre le récepteur antigénique et le complexe CMH-antigène de la cellule cible et l'interaction avec des lymphocytes T auxiliaires.Une fois que l'infection est endiguée, la plupart des lymphocytes T cytotoxiques meurent par apoptose et sont éliminés par les phagocytes mais un petit nombre de lymphocytes deviennent des lymphocytes T cytotoxiques mémoire.
Au cours d'une infection ultérieure par un même agent infectieux, ces lymphocytes T cytotoxiques mémoire prolifèrent plus rapidement et permettent donc une réponse immunitaire plus efficace.La réponse des lymphocytes B est la réponse humorale, c'est-à-dire la réponse du système immunitaire permettant à l'organisme de se défendre contre des microbes qui sont à l'extérieur des cellules et aussi contre les toxines sécrétées par ces microbes.
Les cellules B reconnaissent les microbes par leur récepteur (BCR) qui sont des immunoglobulines fixées sur la membrane des cellules B ou immunoglobulines membranaires.
La stimulation des immunoglobulines membranaires par un antigène microbien va entraîner une modification de la cellule B en plasmocyte et ces plasmocytes vont sécréter les immunoglobulines dans le sang: ces immunoglobulines sont appelées immunoglobulines solubles ou anticorps.
Les plasmocytes peuvent sécréter entre 500 et 1 000 anticorps par seconde qui sont capables d'agir à distance.Les cellules B sont formées dans la partie rouge de la moëlle osseuse et une sélection négative élimine les cellules B réagissant aux protéines de l'organisme, c'est-à-dire possédant des immunoglobulines membranaires M autoréactives.Les cellules B sont alors secrétées dans le sang par lequel elles rejoignent les ganglions lymphatiques ou la rate.
Ce sont des cellules B naïves car elles n'ont jamais été en contact avec un antigène.
Les cellules B naïves ne possèdent que des immunoglobulines membranaires de type M ou D.
La formation des immunoglobulines D membranaires se fait par épissage.Dans le ganglion lymphatique, les cellules B rejoignent les follicules ganglionnaires ou la rate.L'activation des cellules B nécessite deux signaux comme pour les cellules T :Il existe plusieurs types de cellules B :La réponse B aux antigènes T-indépendante est la réponse des cellules B qui ne nécessitent pas l'intervention d'un lymphocyte T CD4+ (lymphocyte auxiliaire).
Les cellules B de la zone marginale et les cellules B-1 présentes dans les muqueuses contribuent aux réponses cellule T-indépendante.
La réponse est une sécrétion d'immunoglobuline M non spécifique, de courte durée et ne produisant pas de cellule mémoire.Antigène qui engage le récepteur cellulaire B pour le premier signal et un récepteur de pattern pour le second signal.Antigène qui engage uniquement le récepteur cellulaire B pour le premier signal et pour le second signal.
Cette réponse B thymus-indépendante est la source continue d'anticorps naturels produits par le corps humain en réponse aux antigènes de la flore intestinale.Les lymphocytes B sont les cellules produisant les anticorps, qui circulent dans le sang et la lymphe, et sont donc responsables de l'immunité à médiation humorale.
Les anticorps, ou immunoglobulines (Ig), sont des protéines permettant la reconnaissance et la neutralisation de corps étrangers comme les agents infectieux ou les toxines.
Chez les mammifères, il existe différents isotypes d'immunoglobulines : les IgA, IgG, IgE, IgD et IgM, dont les propriétés sont différentes.Comme les lymphocytes T, les lymphocytes B ont un récepteur antigénique à leur surface.
Toutefois la nature de ce récepteur est différente de celui des lymphocytes T puisqu'il s'agit d'un anticorps fixé à la surface de la cellule et non d'un récepteur pouvant reconnaître un complexe peptide-CMH.
L'une des différences entre les lymphocytes T et les lymphocytes B est que les lymphocytes T reconnaissent un antigène présenté par le CMH à la surface d'une cellule alors que les lymphocytes B reconnaissent un antigène dans sa forme native.
Lorsqu'un lymphocyte B reconnaît un antigène spécifique et qu'il est activé par un lymphocyte T auxiliaire, il se différencie en plasmocyte.
Les plasmocytes sont des cellules dont la durée de vie est de quelques jours et qui sécrètent des anticorps.
Ces anticorps peuvent se fixer aux microorganismes, et fournissent ainsi des repères aux cellules phagocytes et au système du complément.
Près de 10 % des plasmocytes survivent à l'issue d'une infection et deviennent des lymphocytes B mémoire à longue durée de vie.
Au cours d'une infection ultérieure par un même microorganisme, ces cellules produisent des anticorps plus rapidement et leur efficacité est plus importante.Les cellules B reconnaissent directement l'antigène par le complexe du récepteur des cellules B (BCR) dans l'organe lymphoïde secondaire (rate ou ganglion).
Ces antigènes sont:La reconnaissance de l’antigène par le BCR assure deux fonctions :Le BCR est formé d'une immunoglobuline membranaire de type D ou M et d'un co récepteur (CD79) qui est hétérodimére de deux polypeptides (Ig alpha et Ig beta).
Ce sont des corécepteurs transmembranaires de type 1 de la super famille des immunoglobulines qui possèdent des motifs ITAM.L'activation de la cellule B nécessite deux signaux.Le premier signal nécessite la reconnaissance du microbe par le complexe BCR et les corécepteurs activateurs CD21/CD2 qui fixent le complément C3d lui même fixé sur le microbe.
Le complément C3d appartient au système immunitaire inné.
Cet ensemble permet l'activation par des mécanismes de transcription dont il existe trois voies principales nommées par une des enzymes participant à la transcription (la voie NfkappaB, la voie NF-AT, la voie MAP kinase).La reconnaissance de microbe par le complexe BCR va entraîner :Le deuxième signal implique le lymphocyte T auxiliaire CD4+ qui aura avant était sensibilisé aux mêmes épitopes présentés par une cellule dendritique.
Le deuxième signal va être déclenché par la formation de la synapse immunologique décrit précédemment puis la libération de cytokine.Les conséquences de l'activation de la cellule B lymphocytaire sont :Trois évènements majeurs se déroulent dans le centre germinatif :L'hypermutation somatique ou mutation d'affinité est le changement de quelques acides aminés dans la partie variable de l'immunoglobuline membranaire du complexe récepteur.
Ce changement intéresse autant la chaîne lourde que la chaîne légère.
Comme une division de lymphocyte dure 6 heures, au bout d'une semaine, une cellule B produit environ 5000 lymphocytes B. Ce processus est encore mal connu, mais dépend de l'enzyme désaminase activation dépendante.
Le but de ce processus est de produire des immunoglobulines de plus en plus efficaces contre un microbe.
Durant ce processus interviennet des mécanismes de sélection positive pour empêcher l'apparition d'anticorps attaquant l'organisme.La recombinaison de commutation de classe (class switch recombination, CSR) permet aux cellules B de changer leur isotype d'immunoglobuline M en d'autres isotypes sans pour autant modifier leur spécificité de fixation d'antigène.
La CSR est une réaction de recombinaison-délétion au niveau de l'ADN.
La commutation de classe est régulée par des cytokines qui ouvrent la chromatine des deux régions participantes.
Les cytokines induisent les anticorps les mieux adaptés pour combattre l'infection.À l'issue d'un épisode infectieux, une partie des lymphocytes B et T qui ont été activés deviennent des lymphocytes mémoire.
Lors d'une infection par le même agent infectieux, ces cellules agissent plus rapidement et plus efficacement que lors de la première infection par cet agent infectieux.
C'est l'une des raisons pour lesquelles on parle d'immunité « adaptative », en cela que l'organisme s'adapte à son environnement en se préparant à des infections répétées par un même microorganisme.
La mémoire immunitaire peut s'acquérir de façon passive ou de façon active.La mémoire immunitaire acquise passivement peut durer entre plusieurs jours et plusieurs mois.
Les nouveau-nés n'ayant pas été confrontés à des agents infectieux, et n'ayant donc pas eu l'occasion de se constituer un pool de cellules mémoire, sont particulièrement vulnérables aux infections.
Plusieurs mécanismes de mémoire immunitaire passive leur sont transmis par la mère durant la vie fœtale.
Les IgG maternelles sont transportées à travers le placenta et permettent ainsi aux nouveau-nés d'avoir un répertoire d'IgG circulantes dont la spécificité et l'efficacité correspondent à une réponse mémoire de la mère.Le lait maternel contient également des anticorps permettant de protéger les nouveau-nés contre les infections intestinales.La mémoire immunitaire peut s'acquérir naturellement au cours d'une infection ou artificiellement par la vaccination.Les maladies infectieuses ont toujours été, et sont toujours, une cause majeure de mortalité dans la population humaine.
Durant les derniers siècles, deux principes essentiels ont permis de réduire la mortalité liée aux infections : l'hygiène et la vaccination.
La vaccination est l'induction délibérée d'une réponse immunitaire et représente le moyen le plus efficace de prévenir une infection en agissant sur les mécanismes naturels de mise en place d'une réponse immunitaire mémoire.
Le principe sous-jacent à la vaccination est d'administrer dans l'organisme un agent infectieux dont le potentiel pathogène est au préalable atténué pour éviter l'infection, mais suffisant pour induire l'immunisation et la mise en place d'une réponse mémoire.
La vaccination peut également s'effectuer par administration d'antigènes dérivés d'organismes infectieux, et s'accompagne généralement de l'injection d'adjuvants permettant d'induire une réponse immunitaire suffisamment forte.
Un micro-organisme ou microorganisme (du grec μικρός, mikrós, « petit » et de ὀργανισμός, organismós, « organisme ») ou microbe (du grec μικρός, mikrós, « petit » et βίος, bíos, « vie ») est un organisme vivant qui, invisible à l'œil nu, ne peut être observé qu'à l'aide d'un microscope.
Ce sont tous des organismes unicellulaires.Les trois domaines du vivant sont représentés parmi les microorganismes : bactéries, archées et eucaryotes unicellulaires (protistes et champignons).
Certains microbiologistes y ajoutent les virus alors que d'autres ne les considèrent pas comme des êtres vivants à part entière,, puisqu'ils ne peuvent métaboliser ni se répliquer de manière autonome, hors d'une cellule-hôte.
Quoi qu'il en soit, le monde vivant est essentiellement microbien.En améliorant le microscope et en mettant en évidence dès le XVIIe siècle l'existence des bactéries, Antoni van Leeuwenhoek apparaît comme le précurseur de l'étude des micro-organismes et de la biologie cellulaire.
Depuis 1872 (Ferdinand Julius Cohn) les « bactéries » sont différenciées des levures, des moisissures, des infusoires ou des parasites.Le mot « microbe » (littéralement « petite vie ») est introduit par le chirurgien français Charles-Emmanuel Sédillot en 1878 pour désigner tous ces êtres vivants infiniment petits un mois avant que Louis Pasteur et ses collaborateurs ne fassent une communication à l'Académie de médecine sur la « théorie des germes » et ses applications à la médecine et à la chirurgie : des êtres vivants microscopiques y sont déclarés responsables de maladie.
Cette approche pasteurienne des microbes, dont les plus grandes réussites concernent des microbes pathogènes et la surreprésentation du phénomène parasitaire microbien au XIXe siècle, expliquent que le terme « microbe » comporte encore une forte connotation négative, alors que les micro-organismes participent au cycle du carbone et à celui de l'azote, et jouent un rôle essentiel dans presque tous les écosystèmes.
Les plantes et les animaux en bonne santé abritent une impressionnante diversité de micro-organismes (microbiote des végétaux, microbiote intestinal, cutané, etc.).L'hypothèse que certaines maladies pourraient provenir de micro-organismes invisibles à l’œil nu existe dès l'Antiquité, même si elle n'est pas privilégiée par médecins les plus influents comme Hippocrate ou Galien.
On la trouve cependant sous la plume de Varron dans son Économie rurale : — Varron, Économie rurale, I, 11-12 (1er siècle).Cette hypothèse est cependant négligée pendant l'essentiel de l'histoire européenne au profit de la théorie des humeurs, et il faudra attendre les progrès de la microscopie pour la rétablir.Au XVIIe siècle, le drapier hollandais Antoine van Leeuwenhoek observe les micro-organismes — microbes, levures, globules du sang — à l'aide d'un microscope de sa conception.
Il fait ainsi l'une des plus importantes contributions à la biologie en ouvrant la voie aux domaines de la microbiologie et de la bactériologie.Au XIXe siècle, Agostino Bassi prouve l'origine microbienne du mal del segno, une maladie (muscardine) des vers à soie, Filippo Pacini celle du choléra, Casimir Davaine celle du charbon et les découvertes de micro-organismes se multiplient.
Louis Pasteur participe au mouvement et découvre lui aussi quelques micro-organismes pathogènes.
En 1867, Joseph Lister (qui déclare une dette envers Pasteur) révolutionne la chirurgie avec l'antisepsie.
Divers scientifiques de l'époque, dont le plus connu est Pasteur, travaillent sur des vaccins.En 1878, le médecin militaire Charles-Emmanuel Sédillot propose, dans une note des Comptes rendus de l'Académie des sciences, le terme « microbe » (signifiant mot à mot : petite vie) pour désigner tous les agents microscopiques pathogènes.
Les scientifiques hésitaient sur la place à leur donner dans le monde du vivant, si bien qu'ils les désignaient sous les termes de microphytes, microzoaires, microgermes ou germes, vibrions, leptothrix, bactéries, etc.
Frappé des inconvénients d'une synonymie qui soulevait à chaque instant des contestations entre savants, Sédillot, propose le terme de microbes, agents visibles au microscope et susceptibles d'être cultivés.La liste de ces agents est rapidement complétée : le staphylocoque (Pasteur, 1878), le gonocoque (Neisser, 1879), la typhoïde (Koch en 1880), la tuberculose (Koch en 1882), le pneumocoque (Talamon, 1883), le choléra (Koch, 1883), le streptocoque (Fehleisen, 1883), la diphtérie (Löffler, 1884), le tétanos (Nicolaier, 1886), le méningocoque (Weichselbaum, 1887), la peste (Yersin, 1894), la dysenterie (Shiga, 1898), la coqueluche (Bordet et Gengou, 1906), etc.
Ainsi, le terme microbe est surtout employé au XIXe siècle par les médecins qui le considèrent uniquement comme un agent pathogène, d'où sa connotation négative.
Celui moins connoté de micro-organisme, forgé en 1876 par Henri de Parville, rédacteur scientifique au Journal Officiel se substitue très progressivement à microbe au XXe siècle.Les micro-organismes sont présents dans toute la structure de la taxonomie.
Il est possible de distinguer d'une part les micro-organismes procaryotes qui ne possèdent pas de noyau comme les bactéries et les Archaea, et d'autre part les micro-organismes eucaryotes possédant un noyau.
Les eucaryotes microscopiques comprennent les champignons comme les levures et les deux types de protistes, algues et protozoaires.Les micro-organismes sont souvent décrits comme unicellulaires, quelques protistes unicellulaires sont visibles à l'œil nu et quelques espèces multicellulaires sont microscopiques.La taille moyenne des cellules bactériennes est de 0,5  à   1 μm, mais il existe certaines bactéries ayant une taille de plus de 50 μm.
Les cellules eucaryotes ont un diamètre allant de 5  à   20 μm.Les micro-organismes auraient été les premières formes de vie à se développer sur Terre, il y a environ 3,4 à 3,7 milliards d'années.
Le transfert horizontal de gènes, de pair avec un haut taux de mutation et de nombreux autres moyens de la variation génétique, permet aux micro-organismes d'évoluer rapidement (par sélection naturelle), de survivre dans des environnements nouveaux et répondre à des stress environnementaux.Cette évolution rapide est importante dans la médecine, car elle l'a conduite à l'évolution récente de « super-microbes » — des bactéries (notamment pathogènes) rapidement devenues résistantes aux antibiotiques modernes.Les micro-organismes sont indispensables à l'homme et à l'environnement.
Ils participent au cycle du carbone et au cycle de l'azote et accomplissent un rôle vital dans presque tous les écosystèmes, tels que la biodégradation et le recyclage d'autres organismes.
Un monde sans microbes est donc possible mais l'histoire des animaux axéniques et gnotobiotiques met en lumière que l’absence de microbes entraîne une réduction massive des fonctions physiologiques fondamentales assurant croissance/développement, survie des êtres vivants.On trouve les micro-organismes dans tous les types d'environnement présents dans la nature : ils colonisent tous les écosystèmes, comme les sols, les eaux douces et les eaux marines, l'air, mais aussi des environnements plus hostiles tels que les pôles, les déserts, les geysers, le fond des océans, etc.
Les micro-organismes rencontrés dans des environnements extrêmes sont qualifiés d'extrêmophiles.
De nombreux micro-organismes sont associés aux plantes ou aux animaux avec lesquels ils peuvent entretenir des relations de symbiose, de commensalisme ou de parasitisme.
Certains micro-organismes peuvent être pathogènes, c’est-à-dire entraîner une maladie chez les plantes ou les animaux.Les interactions entre l'homme et les microbes (en) sont nombreuses et variées, aussi bien négatives (maladies) que positives : conservation des aliments, fermentation alimentaire, apports de vitamines quand celles des aliments stockés ont disparu (croûtes de fromages orangés à brévibactéries riches en carotène, un précurseur de la vitamine A, Lactobacillus et Streptococcus des yaourts apportant des vitamines du groupe B, les bactéries lactiques des choux fermentés sont une source de vitamine du groupe C, Bacillus subtilis natto dans le soja fermenté apporte de la vitamine K).
Dans un être humain en bonne santé, il y a plus de cellules microbiennes que de cellules humaines.Certains microbes dont ceux dits extrêmophiles auraient acquis au cours de l'évolution des moyens de résistance face au système immunitaire de leur hôte ou face au stress environnemental (acides, pression, température, froid, oxydants, métaux lourds, radioactivité, etc.), soit en s'adaptant à l'un ou l'autre de ces « facteurs de stress », soit en entrant en sommeil ou en se protégeant par « enkystement ».Un même microbe peut ainsi se présenter sous plusieurs formes, Toxoplasma gondii offre par exemple — selon le contexte — trois formes :Dans les milieux fréquentés par l'homme, le taux de micro-organismes dans l'air peut fortement varier.
Il est notamment lié à la poussière et à l'humidité contenues dans l'atmosphère.Les rayons UV du soleil désinfectent l'air quand il est humide et riche en particules, telles que les poussières, les pollens, les suies, etc. car ces particules servent de support à de nombreuses bactéries, virus, micro-organismes, spores de champignon, et sont facilement mis en suspension dans l'air par le vent, les turbulences, le balayage, ou encore le flux des véhicules.C'est dans les villes denses que le taux de microbes était le plus élevé au XXe siècle.
Lablokoff, naturaliste qui travaillait sur les forêts et leur naturalité, a comparé le taux de microbes contenu dans l'air de différents lieux plus ou moins pourvus d’arbres et de végétation.
Il a alors obtenu les résultats suivants :En 1956, d'autres mesures ont donné :Les micro-organismes peuvent aussi être la cause de nombreuses maladies infectieuses.
On distingue ainsi : les bactéries pathogènes qui provoquent des maladies comme la peste, la tuberculose et le charbon, les protozoaires responsables de maladies comme le paludisme, la maladie du sommeil et la toxoplasmose et enfin les champignons qui provoquent des maladies telles que la teigne, la candidose ou histoplasmose.
D'autres maladies comme la grippe, la fièvre jaune ou le SIDA sont causées par des virus pathogènes qui ne sont généralement pas classés comme des organismes vivants et ne sont donc pas des micro-organismes au sens strict du terme.
Heureusement, nous possédons des barrières naturelles (la peau et les muqueuses) dont le rôle est d'empêcher la contamination.
Elles évitent que les micro-organismes ne pénètrent dans le milieu intérieur, évitant ainsi l'infection.Aux échelles microscopiques, les organismes sont confrontés à une physique et à des besoins particuliers.Pour se nourrir, les micro-organismes ont besoin de :Par le froid, on stoppe la croissance de la majorité des micro-organismes qui vont se maintenir en état de dormance, sans multiplication.L'importance du temps de chauffe permet, pour une température donnée, de parvenir à une destruction plus ou moins complète ; une augmentation de température impliquant une diminution du temps de chauffe.
Les principaux traitements thermiques sont la pasteurisation et la stérilisation.À une température favorable adaptée et optimale, on permettra le développement de certaines espèces :L'interaction de micro-organismes différents peut varier :L'activité des micro-organismes dans la biosphère et leur rôle dans les cycles biogéochimiques sont essentiels pour toutes les formes de vie sur Terre.La microbiologie est la science qui étudie les micro-organismes.
L'immunocompétence est la capacité du corps à produire une réponse immunitaire normale, après exposition à un antigène.
L'immunocompétence est le contraire de l'immunodéficience, de l'immuno-incompétence et de l'immunosuppression.
Bordetella bronchiseptica est un bacille mobile à ciliature péritriche, capable de réduire les nitrates en nitrite (si le milieu est supplémenté en NAD) et possède une uréase très active (agit en 1 à 4 h).Cette espèce de Bordetella est particulière car elle n'est pas exigeante : elle pousse facilement et rapidement sur gélose ordinaire (voir discussion), milieu de Mac Conkey et même sur le milieu au citrate de Simmons.L'homme n'est qu'un hôte occasionnel pour B. bronchiseptica.
Mais fréquemment rencontré en médecine vétérinaire, c'est aussi un saprophyte des muqueuses respiratoires d'animaux domestiques et d'animaux sauvages.
Albert Calmette est un médecin et bactériologiste militaire français, né le 12 juillet 1863 à Nice et mort le 29 octobre 1933 à Paris.
Sa renommée tient à la mise au point entre 1904 et 1928, avec Camille Guérin, de la vaccination contre la tuberculose grâce au BCG.Fils de Guillaume, 40 ans, avocat, chef de division à la Préfecture, et d'Adèle Charpentier, 35 ans, Albert Calmette est né à Nice le 12 juillet 1863.
Il fait ses études dans différents lycées à Clermont-Ferrand, au lycée Saint-Charles à Saint-Brieuc et à Brest, ainsi qu'au lycée Saint-Louis à Paris.
De 1881 à 1883, il est élève de l'École de médecine navale de Brest, où il suit l'enseignement d'Armand Corre.
En 1883, il commence à exercer à Hong Kong, dans le corps des médecins de marine, où il étudie la malaria, sujet de sa thèse de doctorat qu’il soutient en 1886.
Il est ensuite envoyé à Saint-Pierre-et-Miquelon, puis il exerce en Afrique occidentale, au Gabon et au Congo, où il continue d'étudier non seulement la malaria mais aussi la maladie du sommeil et la pellagre.En 1890, il suit un stage de bactériologie dans le laboratoire du docteur Émile Roux à Paris.
Associé aux recherches de Louis Pasteur, il est chargé par ce dernier de fonder l'Institut Pasteur de Saïgon où il organise la production de vaccins contre la rage.
Il se consacre à la toxicologie, qui vient de naître, en liaison étroite avec l’immunologie, et il étudie le venin des serpents et des abeilles, les poisons issus des plantes et le curare.
Il organise également la production de vaccins contre la variole et la rage, et mène des recherches sur le choléra et sur la fermentation de l'opium et du riz.
Il côtoïe à Saïgon Alexandre Yersin.En 1894, il revient en France et met au point les premiers antivenins contre les morsures de serpent en utilisant des sérums de chevaux vaccinés et immunisés (sérum de Calmette).
Ces travaux sont repris plus tard à l'Institut Butantan de São Paulo par le médecin brésilien Vital Brazil qui met au point plusieurs autres antivenins contre les serpents, les scorpions et les araignées.
Calmette participe également à la mise au point du premier sérum immunisateur contre la peste bubonique (la peste noire), en collaboration avec Alexandre Yersin (1863-1943), qui avait découvert son agent pathogène, Yersinia pestis, et il se rend au Portugal pour étudier une épidémie à Porto et aider à la combattre.À partir de 1895, il poursuit d'autres recherches à l'Institut Pasteur de Lille, dont Roux lui avait confié la direction qu'il assumera pendant 25 ans.
En janvier 1901, il y fonde le dispensaire alors appelé Émile-Roux (il s'appelle aujourd'hui dispensaire Calmette) qui était le second à avoir été créé en France spécifiquement pour lutter contre la tuberculose.
Ce dispensaire servira de modèle à ceux préconisés par la loi Léon Bourgeois en 1916.
En 1904, il fonde la Ligue du Nord contre la Tuberculose, qui existe toujours.
En 1905 il fait partie, avec Édouard Imbeaux, des membres fondateurs de l'Association générale des ingénieurs, architectes et hygiénistes municipaux devenue quelques années plus tard l'Association générale des hygiénistes et techniciens municipaux (AGHTM) puis l'Association scientifique et technique pour l'eau et l'environnement (ASTEE).
À la même époque, il estime que les vaccins ont rendu « l'œuvre de colonisation éminemment humanitaire et civilisatrice ».En 1908, il fait partie des membres fondateurs de la Société de pathologie exotique et en 1909, il participe à la fondation de l'antenne d'Alger.Au cours de la Première Guerre mondiale, il est nommé adjoint du directeur du service de santé de la 1re région militaire à Lille, mais ne peut rejoindre la ville occupée par les troupes allemandes.
Il organise les hôpitaux militaires auxiliaires.En 1917, il est nommé sous-directeur adjoint de l'Institut Pasteur de Paris, institut qu'il ne peut rejoindre avant la fin de la guerre du fait de l'occupation de Lille par les troupes allemandes.
Il est élu à l'Académie de médecine en 1919, à l'Académie des sciences d'outre-mer en 1922 et à l'Académie des sciences en 1927.Il est inhumé à Jouy-en-Josas, dans la propriété Bourget-Calmette.Le principal travail scientifique de Calmette, celui qui devait lui apporter une gloire mondiale et attacher son nom à l'histoire de la médecine, fut la mise au point d'un vaccin contre la tuberculose qui, à cette époque, faisait des ravages.
En 1882, le microbiologiste allemand Robert Koch avait découvert que l'agent pathogène de cette maladie était le Mycobacterium tuberculosis (bacille de Koch), découverte qui avait intéressé Pasteur.En 1906, Camille Guérin, vétérinaire et immunologiste, avait établi que l'immunité contre la tuberculose était liée à des bacilles tuberculeux vivant dans le sang.
En utilisant la méthode pastorienne, Calmette voulut savoir si cette immunité se développerait comme réponse à l'injection, chez les animaux, de bacilles bovins atténués.
Cette préparation reçut le nom de ses deux découvreurs (Bacillum Calmette-Guérin, ou en abrégé BCG : vaccin bilié de Calmette et Guérin).
L'atténuation était obtenue en cultivant les bacilles dans un substrat contenant de la bile, d'après une idée émise par un chercheur norvégien, Kristian Feyer Andvord (1855-1934).De 1908 à 1921, Guérin et Calmette s'efforcent de produire des souches de bacilles de moins en moins virulentes, grâce à des transferts dans des cultures successives.
Enfin, en 1921, ils utilisèrent le BCG avec succès sur des nouveau-nés à l'hôpital de la Charité de Paris.Le programme de vaccination sembla cependant connaître un sérieux revers quand, en 1930, 72 enfants vaccinés contractèrent la tuberculose, à Lübeck.
Mais l'enquête prouva que l'Institut Pasteur avait fourni des souches saines et que c'étaient les médecins de Lübeck qui avaient été coupables de négligences scandaleuses ; ils furent d'ailleurs condamnés à de la prison ferme tandis que l'Institut Pasteur était mis hors de cause.
La vaccination massive des enfants fut réintroduite dans beaucoup de pays après 1932 avec des techniques de production plus sûres.
Calmette n'en avait pas moins été profondément affecté.
Il mourut un an plus tard à Paris.Albert Calmette était le frère d'Émile Calmette (1851-1934), médecin inspecteur général des Armées, et de Gaston Calmette (1858-1914), directeur du Figaro de 1903 à 1914, assassiné en 1914 par Henriette Caillaux, l'épouse du ministre des Finances Joseph Caillaux.De nombreux établissements scolaires et hôpitaux, ainsi que de nombreuses voies, portent son nom.
Si l'on fait abstraction des innombrables rues Calmette et écoles primaires Calmette, son nom a été donné dans les villes suivantes, classées de manière alphabétique (liste non exhaustive) :Les Messageries maritimes donnèrent son nom à un de leurs navires.
Un agent infectieux est un agent biologique pathogène responsable d'une maladie infectieuse.Les agents infectieux sont majoritairement des micro-organismes, notamment des bactéries et des virus.
Cependant, certains agents pathogènes ne sont pas des organismes (les prions), d'autres ne sont pas microscopiques (les vers parasites).Le pouvoir pathogène d'un agent infectieux mesure sa capacité à provoquer une maladie chez un organisme hôte.La virulence d'un agent infectieux mesure sa capacité à se développer dans un organisme (pouvoir invasif) et à y sécréter des toxines (pouvoir toxique).Chez les humains, 1 415 espèces infectieuses ont été inventoriées,.
Environ 600 sont connues pour le bétail et environ 400 pour les chats et les chiens.
Les données concernant la faune sauvage sont trop parcellaires pour qu'un chiffre puisse être donné.
Parmi ces agents infectieux on compte :Le pouvoir pathogène (grec ancien πάθος , « souffrance » ; id.
γένος , « naissance ») — ou pathogénicité — d'une bactérie mesure sa capacité à provoquer des troubles chez son hôte.
Il varie selon la souche (sérovar) et dépend de son pouvoir invasif (capacité à se répandre dans les tissus et à y établir un ou des foyers infectieux), de son pouvoir toxicogène (capacité à produire des toxines) et de sa capacité à se reproduire.On distingue trois catégories de bactéries pathogènes :Le pouvoir invasif d'une bactérie (ou d'une souche bactérienne) est sa capacité à se multiplier et à se répandre dans un organisme hôte, malgré les défenses immunitaires.La température de l'eau, de l'air et du sol, le pH, le taux d'oxygène, la teneur en certains nutriments de l'environnement, l'exposition aux UV solaires, à certains toxiques ou polluants ou à la radioactivité, la présence d'un vecteur biologique, d'une lésion ou d'une primo-infection, etc. peuvent ou non favoriser l'agent infectieux.Par exemple le réchauffement climatique pourrait permettre à des microbes d'être plus présents et infectieux plus haut en altitude, plus près des pôles nord et sud ou plus fréquemment dans les eaux douces, estuariennes ou salines.La radioactivité ambiante, l'augmentation des UV induite par le trou de la couche d'ozone, la dispersion de biocides et d'antibiotiques dans l'environnement, ou encore l'exposition à l'ozone troposphérique pourraient être de nouveaux facteurs de mutation et donc d'apparition de souches plus agressives ou plus résistantes, ou de maladies émergentes.
De même de nombreux agents mutagènes dispersés par l'Homme dans l'environnement (radionucléides, certains métaux lourds et divers produits chimiques) pourraient favoriser l'apparition de nouvelles souches pathogènes.La constitution et le métabolisme de la bactérie définissent en partie son pouvoir invasif ; ainsi, celui-ci dépend :Le pouvoir invasif dépend également du terrain infecté (c'est-à-dire le milieu environnant la bactérie), à savoir :Une toxine est une molécule synthétisée par un organisme vivant, ayant un effet nocif ou létal pour l'organisme hôte.Les toxines protéiques sont les poisons les plus actifs : 250 g de toxine (tétanique ou botulinique) suffirait à tuer toute la population humaine.Le pouvoir pathogène peut être quantifié par trois données : la dose minimale mortelle (DMM), la dose létale 50 (DL50) et la dose minimale infectante (DMI).Les toxines peuvent agir de plusieurs manières : sur le système immunitaire, en provoquant une allergie (effet allergène), ou encore un choc septique ; sur le système nerveux (effet neurotoxique) ; sur le système musculaire (effet myotoxique) ; sur le système reproductif (effet reprotoxique) ; etc.
Une toxine peut agir seule ou en synergie avec d'autres.
Selon la bactérie en cause et le mode de contamination, la production et l'action de la toxine se feront différemment.Les toxines protéiques ont souvent un pouvoir toxique très élevé.
Elles provoquent l'apparition d'anticorps dans l'organisme : les anti-toxines.Certaines peuvent être transformées en anatoxines par un traitement au formol, et une incubation à 40 °C (Méthode de Ramon).
Ces anatoxines sont utilisées pour :L'eau épurée doit donc être débarrassée de ces germes pathogènes lorsqu’elle est rejetée dans le milieu naturel pour ne pas contaminer celui-ci et causer une épidémie pouvant être mortelle au sein des populations en aval.
Le vaccin contre les infections invasives à pneumocoque est un vaccin destiné à prévenir les infections dues à Streptococcus pneumoniae, une bactérie.
Il en existe plusieurs, ciblant différents sérotypes et pouvant être conjugués à des protéines.
L'efficacité du vaccin est importante et ses effets secondaires sont le plus souvent sans gravité.
Il fait partie des vaccins recommandés chez le nourrisson.Streptococcus pneumoniae est une bactérie responsable d'otites, de sinusites et surtout de pneumonies, dont la mortalité peut atteindre 25 % en cas de bactériémie associée, et de méningites, dont la mortalité est de 10 % et le taux de séquelles neuropsychiques est de 30 %.Les vaccins contre les infections invasives à pneumocoque contiennent des polyosides de la capsule bactérienne.
On distingue les vaccins non conjugués et les vaccins conjugués à une protéine.
En France, les vaccins disponibles sont le vaccin non conjugué composé de 23 valences (dirigé contre les sérotypes 1, 2, 3, 4, 5, 6B, 7F, 8, 9N, 9V, 10A, 11A, 12F, 14, 15B, 17F, 18C, 19A, 19F, 20, 22F, 23F et 33F), et le vaccin conjugué à la protéine CRM 197 composé de 13 valences (dirigé contre les sérotypes 1, 3, 4, 5, 6A, 6B, 7F, 9V, 14, 18C, 19A, 19F et 23F).
Ils sont injectables par voie intramusculaire.En France, la vaccination recommandée du nourrisson par le vaccin conjugué à 13 valences consiste en 2 injections à 2 mois d'intervalle, aux âges de 2 et 4 mois, suivies d'un rappel à l'âge de 11 mois.Aux États-Unis, la vaccination systématique des adultes de plus de 65 ans est également recommandée.Le vaccin non conjugué à 23 valences est peu efficace chez le nourrisson.
Après l'âge de 2 ans, le taux de protection théorique est estimée entre 85 et 90 %, en sachant que l'immunogénicité est souvent faible pour les valences 6, 10A, 18C, 19F, 22 et 23F.
Les anticorps sont détectables pendant 5 ans chez l'adulte.
L'efficacité clinique semble être de 50 à 70 %.Le vaccin conjugué à 13 valences induit une réponse immunitaire satisfaisante pour 12 valences, et faible pour la valence 3.
Son efficacité sur la survenue des infections invasives n'est pas connue, mais elle peut être extrapolée à partir d'un vaccin antérieurement disponible à 7 valences (contenues dans le vaccin à 13 valences), dont l'efficacité est évaluée à 94 %.
Le vaccin à 13 valences induit une immunogénicité plus importante que le vaccin à 23 valences pour les sérotypes concernés.Chez l'adulte, le vaccin est efficace dans la prévention de la pneumopathie à pneumocoque, mais sans effet démontré sur la mortalité.Au niveau santé publique, la vaccination des enfants permet de réduire les infections à pneumocoque chez l'adulte au sein de la même population, ainsi que le portage du germe.Les effets indésirables observés après l'injection du vaccin contre les infections invasives à pneumocoque peuvent être une douleur, un érythème, une induration ou un œdème au site d'injection, une irritabilité, une hypersomnie ou une fièvre ou des myalgies.
Des réactions allergiques sévères, telles qu'une urticaire, un angiœdème ou une réaction anaphylactoïde, ont été rarement rapportés.Le vaccin est contre-indiqué en cas d'hypersensibilité à l'un des composants.
Camille Guérin est un vétérinaire et biologiste français, né le 22 décembre 1872 à Poitiers et mort le 9 juin 1961 à Paris.
Avec le docteur Calmette, il est l'inventeur du BCG, vaccin antituberculeux.Né à Poitiers, en 1872, Camille Guérin est le fils d'un entrepreneur de travaux publics, mort de la tuberculose en 1882.
Il étudie la médecine vétérinaire de 1892 à 1896 à l'École nationale vétérinaire d'Alfort, tout en servant d'assistant au pathologiste Edmond Nocard (1850-1903).Diplômé en 1896, il rejoint l'Institut Pasteur de Lille en 1897 et commence à travailler avec Albert Calmette.
D'abord préparateur, il est chargé de préparer le sérum antivenin de serpent et le vaccin contre la variole.
Il améliore grandement les techniques de production de ce dernier en utilisant des lapins porteurs, et il met au point une méthode pour évaluer la virulence latente du vaccin.
En 1900, il se consacre presque exclusivement aux deux sujets d'études qui occuperont la majeure partie de sa carrière scientifique  : la vaccine jennérienne et la tuberculose.
En 1905, il est nommé chef de laboratoire.
Il poursuit alors les travaux sur la prévention de la variole, menés un siècle plus tôt par Edward Jenner, médecin anglais.Il découvre d'abord, en 1905, que le bacille de la tuberculose bovine (Mycobacterium bovis) peut immuniser les animaux sans déclencher la maladie.
Par la suite, il s'emploie avec Calmette à développer des stratégies de réduction de la virulence de Mycobacterium par des cultures successives.
En 1908, après avoir obtenu une préparation immunologique active, Calmette et lui publient les résultats de leurs travaux sur ce qu'ils nomment le vaccin Bilié de Calmette et Guérin (BCG).
En 1915, leurs recherches sont interrompues par l'occupation de Lille.
Ils ne les reprennent qu'en 1918, après la libération.
Finalement, en 1921, après 230 passages de culture du BCG, ils obtiennent un vaccin utilisable chez l'homme.
En 1924, les pouvoirs publics autorisent l'extension de l'usage du BCG sur les nouveau-nés.En 1919, Guérin est devenu chef de service à l'Institut Pasteur de Lille.
Il prend en 1928, la direction du service de la tuberculose à l'Institut Pasteur de Paris.
En 1939, il devient vice-président du Comité national de défense contre la tuberculose.
En 1948, il est président du premier congrès international du BCG et, en 1951, président de l'Académie de médecine.
En 1955, il reçoit le grand prix de la recherche scientifique de l'Académie des sciences.Il meurt en 1961, à l'âge de 88 ans, à l'hôpital Pasteur de Paris et est inhumé, aux côtés de son épouse Marie, à Châtellerault.Divers établissements publics portent le nom Camille Guérin, dont notamment :De nombreuses communes françaises lui attribuent des noms de rues, notamment à Poitiers, Limoges, Nantes, Cholet, La Roche-sur-Yon, Le Château-d'Olonne, Lille, Caen, Beauvais, Bourges, Bétheny, Sailly-sur-la-lys et Thouars.
Le Code de la santé publique français (CSP), créé en 1953, a été refondu par ordonnance en 2000 pour la partie législative et par cinq importants décrets pour la partie réglementaire entre 2003 et 2005.
Sa publication a entraîné l'abrogation simultanée de plusieurs centaines de textes désormais codifiés.
Il est emblématique du renouveau de la codification française depuis la mise en place de la Commission supérieure de codification en 1989.Le Code de la santé publique contient notamment le Code de déontologie médicale que doivent respecter les professionnels de la santé lors de l'administration des soins de santé en France.Ce « Code de grande ampleur » (sa publication récente a occupé 804 pages au Journal Officiel et il compte plus de 10 000 articles) détermine matériellement le champ du droit de la santé publique.Il comporte en six parties, elles-mêmes divisées en livres, titres, chapitres et articles :Chacune des parties se termine par un livre consacré au droit applicable aux collectivités d'outre-mer soumises au principe de la spécialité législative avec les adaptations correspondantes.Sans cesse modifiée du fait du progrès des idées et des techniques et de l'évolution du droit communautaire, la partie législative a été enrichie par 84 lois (dont la loi du 4 mars 2002 relative aux droits des malades et à la qualité du système de santé) et ordonnances en 72 mois depuis juin 2000.Le code est accessible gratuitement sur Légifrance qui met à disposition une édition constamment mise à jour, indispensable pour vérifier la dernière version d'un article.
Une édition papier, permettant une approche plus générale, est aussi publiée périodiquement par les Journaux Officiels.Plusieurs éditeurs privés proposent des éditions utiles du code de la santé publique.
Le virus de la mosaïque du concombre (CMV, Cucumber mosaic virus) est un phytovirus pathogène du genre Cucumovirus appartenant à la famille des  Bromoviridae.C'est l'espèce-type du genre Cucumovirus.
Ce virus a une répartition cosmopolite et peut infecter une très vaste gamme de plantes-hôtes.
En fait, il est considéré, parmi tous les virus de plantes connus, comme celui qui a la plus grande gamme d'hôtes : plus de 1 200 espèces de végétaux.La transmission du CMV se fait par l'intermédiaire de nombreuses espèces de pucerons,  en particulier Aphis gossypii et Myzus persicae, qui le transportent dans le stylet, selon un mode non persistant.La transmission se fait également par les graines, par inoculation mécanique par la sève et par des plantes parasites du genre Cuscuta.Dans les tissus de la plante, ce virus produit des corps d'inclusion (en) viraux caractéristiques  qui peuvent être diagnostiqués.
De forme hexagonale, ils se colorent tant avec des réactifs de coloration pour protéines que pour acides nucléiques.
Les inclusions peuvent aussi être rhomboïdales, apparaître en creux et former de plus grands agrégats.
Les inclusions ne sont pas uniformément distribuées et peuvent se trouver dans des cellules de l'épiderme, du mésophylle, et des stomates.
Ces inclusions sont formées de particules virales.Ce virus a été découvert en 1934 sur le concombre (Cucumis sativus) sur lequel il se manifeste par des symptômes de mosaïque, d'où son nom de « virus de la mosaïque du concombre ».
Il a par la suite été identifié chez un grand nombre d'autres espèces de plantes virosées.
Parmi celles-ci figurent des plantes maraîchères telles que courges, melons, piments, haricots, tomates, carottes, céleris, laitues, épinards et betteraves et beaucoup de plantes ornementales et de plantes à massifs.
Ce virus infecte également les cultures de pomme de terre, sans toutefois que cela représente un problème économique important.Ce virus infecte aussi diverses plantes adventices, qui constituent des réservoirs lui permettant souvent d'hiverner alors que les plantes cultivées ont disparu.Les symptômes exprimés par ce virus peuvent être une mosaïque ou marbrure foliaire, un jaunissement du feuillage, des anneaux nécrosés, le rabougrissement de la plante et des déformations des fleurs, des fruits et des feuilles.
La rage est une encéphalite virale grave touchant principalement les mammifères.
Après apparition des symptômes, elle est mortelle dans la quasi-totalité des cas.
Cette infection est hautement contagieuse par morsure et transmissible de l'animal à l'être humain.
Selon l'OMS, la maladie cause environ 59 000 décès humains chaque année dans le monde, pour la plupart dans les zones rurales d'Afrique et d'Asie, 40 % des victimes ont moins de 15 ans.Causés par un virus neurotrope, les symptômes sont principalement neurologiques accompagnés de désordres comportementaux.
Classiquement, le sujet atteint peut présenter une agressivité impressionnante qui donne son nom à la maladie, bien qu'il existe aussi des formes plus frustes où le comportement est particulièrement calme.La rage est une zoonose assez commune qui touche beaucoup les carnivores de certaines régions du monde, et il est impératif de faire vacciner son animal de compagnie pour des destinations où le risque, même faible, est avéré, ainsi qu'en cas de risque d'épizootie dans les régions où la maladie humaine n'est plus endémique.De même, des autorités comme l'Office national des forêts en France usent de moyens de vaccination de la faune sauvage lors d'épisode épidémique, d'abattage des animaux suspects et éliminent les cadavres suspects.
En Europe, la rage du renard a été efficacement éliminée de certains pays par distribution d'appâts imprégnés de vaccin dispersés dans la nature.La rage est causée par un virus de la famille des Rhabdoviridae et du genre Lyssavirus .
Ce sont des virus enveloppés, leur génome est une molécule d'ARN monocaténaire (à un seul brin), de polarité négative, non segmenté, et de forme hélicoïdale, dans une enveloppe ayant la forme d'un obus ou d'une balle de révolver.Ces caractéristiques leur confèrent une grande sensibilité aux agents physico-chimiques de désinfection et donc une faible résistance dans le milieu extérieur.
De même, ils ne disposent pas de moyen de contrôler les erreurs de réplication, ils sont donc capables d'évoluer très rapidement par mutation, d'échapper aux mécanismes de défense, et de franchir plus facilement les barrières d'espèces.Le virus de la rage est un virus neurotrope, en particulier du système nerveux central.
Il se multiplie dans le cytoplasme des cellules nerveuses où il forme des inclusions visibles en microscopie optique : les corps de Négri.
Ce neurotropisme explique pour partie les troubles observés, comme l'hydrophobie, appellation historique de la rage, et présente dans 95 % des cas humains.Le virus de la rage infecte tous les animaux à « sang chaud » comme les mammifères, mais la température centrale de ceux-ci varie selon les espèces.
Celle des mammifères placentaires est autour de 37–38 °C, supérieure à celle des marsupiaux (36 °C) et des monotrèmes (30 °C), aussi la sensibilité à la rage varie selon les espèces.
Par exemple, l'oppossum est relativement résistant à la rage, alors que les mammifères placentaires sont plus sensibles, surtout les carnivores.Le réservoir primitif du virus de la rage parait être celui de certaines chauves-souris qui peuvent être porteuses saines, ou malades selon les espèces.
D'après une étude phylogénétique, le virus rabique aurait évolué à partir de rhabdovirus d'insecte, il y a environ dix mille ans.
Le virus rabique actuel serait passé des chauves-souris aux carnivores, il y a près de 900 à 1 500 ans, ce qui n'exclut pas que d'autres passages aient eu lieu auparavant,,.Les réservoirs-vecteurs de la rage humaine sont essentiellement les carnivores sauvages (rage sylvatique) et domestiques (rage urbaine ou rage des rues).Le temps d'incubation est variable selon les espèces.
Chez les chiens et les chats, il est en moyenne de 38 jours.Après morsure, le virus se multiplie localement dans le tissu musculaire, d'où l'importance de soins locaux immédiats.
Pendant cette phase initiale, le virus ne peut pas être facilement détecté par le système immunitaire de l'hôte, et la vaccination peut toujours conférer une immunité.Le virus a un tropisme prononcé pour le système nerveux, en particulier les neurones mais aussi d'autres cellules comme les astrocytes.
Après atteinte d'une densité locale suffisante dans le tissu musculaire, le virus diffuse  jusqu'à une terminaison nerveuse (par exemple : motoneurone de plaque motrice), le virus va migrer à une vitesse de 8 à 20 mm par jour du système nerveux périphérique vers le système nerveux central via les synapses.Il infecte notamment la cellule pré-synaptique par bourgeonnement de la membrane cellulaire, en particulier par la glycoprotéine RABV-G de surface qui facilite l'entrée dans la nouvelle cellule hôte,.Le virion se lie en particulier au récepteurs p75NTR et est ainsi internalisé dans un endosome puis transporté le long de l'axone jusqu'au corps cellulaire, lieu de sa réplication.
Ce transport en apparence anodin engendre cependant un stress oxydatif supplémentaire dans la cellule et la détérioration de l'axone.Une fois que le virus atteint le cerveau, une deuxième multiplication massive a lieu dans les neurones.
Ce qui provoque rapidement une encéphalite avec apparition des symptômes.
Les troubles comportementaux (en particulier l'agressivité) seraient en rapport avec une atteinte des circuits sérotoninergiques.
Il peut aussi infecter la moelle spinale, provoquant une myélite.Toujours par voie nerveuse, le virus se dissémine ensuite dans tout l'organisme, pour être excrété vers les glandes salivaires, les yeux (rétine, glandes lacrymales…), la peau et les follicules pileux, les muqueuses nasales et digestives.La mort survient par destruction des zones cérébrales contrôlant l'automatisme de la respiration.La rage est avant tout une zoonose des vertébrés à sang chaud (mammifères), et plus rarement, des oiseaux, accidentellement transmise à l'homme, et dont le réservoir évolue selon les époques et d'un continent à l'autre.La rage se transmet le plus souvent par morsure directe avec blessure (et non par une morsure qui ne transperce pas les vêtements).
Elle peut être aussi transmise par griffure, ou léchage sur une peau lésée (le virus ne pénètre pas une peau saine et intacte) ; plus rarement par projection de salive contaminée sur une muqueuse (conjonctive par exemple).
L'inhalation d'aérosols de gouttelettes ou de poussières infectées est exceptionnelle, mais possible dans des circonstances particulières, comme dans les grottes habitées par des chauves-souris infectées.Les virus rabiques évoluent dans trois grands cycles naturels : la rage des mammifères terrestres (qui se subdivisent en sauvages et domestiques), et la rage des mammifères volants (chauves souris).
Les espèces-réservoirs de virus rabique le transmettent le plus souvent par morsure, ce sont donc à la fois des réservoirs et des vecteurs de la rage.Le virus de la rage circule d'abord chez les carnivores sauvages qui jouent le rôle de réservoir primaire, c'est la rage sylvatique ou rage des animaux sauvages.
Le principal réservoir mondial est celui des canidés sauvages (loup, renard, chacal, coyote.).
Les autres carnivores sauvages de plus petite taille, comme les mustélidés, peuvent être aussi des réservoirs significatifs : mouffette, raton laveur, blaireau.La rage animale sauvage survient à intervalles irréguliers, par vagues s'étendant sur des milliers de kilomètres en quelques décennies, à raison de quelques kilomètres à quelques dizaines de kilomètres par an.Ces carnivores sauvages peuvent transmettre la rage, selon l'occasion, aux carnivores domestiques, principalement le chien, puis le chat.
La rage est alors dite rage urbaine ou rage des rues.
D'autres mammifères, en élevage domestique ou servant de gibier, ainsi que les rongeurs, peuvent être atteints et mourir de la rage.
Les analyses moléculaires des différents virus suggèrent que la transmission entre espèces sauvages et domestiques peut se faire dans les deux sens.Les chauves-souris (chiroptères) d'Amérique et d'Europe peuvent être infectées.
Le cycle de la rage des chiroptères est indépendant du cycle des carnivores, mais à l'exception des chauves-souris hématophages d'Amérique, leur rôle épidémiologique (rage humaine, ou animale domestique) parait limité, mais reste très surveillé.Les premières recherches modernes concernant la rage des chauves-souris transmissible au bétail ont lieu au Brésil au début du XXe siècle.
En 1931, le virus rabique est isolé de chauves-souris hématophages comme les chauves-souris vampires des genres Artibeus, Desmodus et Hemiderma.Dans les années 1950, le virus rabique a été retrouvé chez des chauves-souris insectivores du sud des États-Unis,.
En Guyane, des anticorps antirabiques ont été détectés sur des animaux ne présentant pas de symptômes et chez qui le virus ne pouvait pas être mis en évidence.En Amérique latine, la rage des bovidés par chauve-souris hématophage tue 30 à 40 % des animaux non vaccinés.
Les pertes annuelles au cours des années 1960-1970 seraient de l'ordre d'un demi-million de têtes.
Elles demeurent une charge économique significative en 2018.La rage de chauve-souris autochtone est documentée en Europe depuis 1954 en Allemagne, puis dans les autres pays européens (France en 1989).
L'espèce majoritairement en cause est une chauve-souris insectivore, la sérotine commune.
Une chauve-souris enragée se caractérise par une activité diurne, un vol impossible, une paralysie ou une agressivité.
Il est déconseillé de manipuler une chauve-souris à terre, trouvée en plein jour,.En Europe, les cas de chauve-souris enragées sont très rares : 10 à 50 cas par an de 1988 à 2000, en France 10 cas sur toute la période 1989 à 2000,.L'homme est un hôte accidentel et terminal (en impasse), la transmission interhumaine étant quasi inexistante.
Les cas humains surviennent rarement et de façon sporadique, soit en cas isolé, soit en petits groupes de quelques cas.La quasi-totalité des cas humains (près de 98 %) proviennent de morsures de chien enragé, plus rarement directement d'animaux sauvages (chasseurs, trappeurs et bergers exposés).La morsure d'un chat enragé est grave, car le plus souvent multiple et très pénétrante.
L'attaque de loup enragé est la plus dangereuse, à cause de la taille, de la force, et de la capacité de l'animal à infliger des morsures multiples.La transmission par herbivores domestiques est très rare, mais reste potentiellement dangereuse.
En Afrique du Sud un cas de morsure par un cheval enragé a été signalé.La transmission par chauve-souris est exceptionnelle en Europe : 4 cas humains en Europe de 1977 à 2012, et aucun en France métropolitaine (à la date de 2018).
Un cas est survenu en Guyane française en 2008.
Un homme âgé d'une soixantaine d'années est décédé de la rage à la suite d'un contact avec des chauves-souris qui nichaient dans son grenier, à Limoges, en août 2019.
C'est le premier décès de ce genre détecté en France.À la date de 2018, aucun cas de rage humaine par morsure de rongeur n'a été rapporté dans le monde ; ni par ingestion de viande crue d'un animal enragé, ou de lait cru de vache enragée.La transmission interhumaine est théoriquement possible, mais en pratique elle est rarissime, elle a été décrite notamment lors de greffes de cornée.Pour l'épidémiologie historique, voir Selon l'OMS, la maladie cause environ 59 000 décès chaque année dans le monde, pour la plupart dans les zones rurales de l'Afrique et de l'Asie.
40 % des victimes sont des enfants de moins de 15 ans.
Le chiffre des décès est probablement sous-estimé, les pays les plus touchés étant ceux qui disposent du moins de moyens de diagnostic.
Le coût global de la maladie reviendrait à plus de cinq milliards d'euros par an ou même à plus de huit milliards.La rage n'est pas une maladie éradicable mondialement, le virus pouvant circuler dans la faune sauvage, mais elle peut être éliminée localement.
L'objectif de l'OMS est de parvenir à des éliminations régionales de rage terrestre (la rage des chiroptères n'entre pas dans ces définitions), avec zéro décès de rage humaine dans le monde, d'ici 2030 (élimination mondiale de la rage humaine transmise par les chiens).Selon l'OMS, un pays est dit indemne ou libre de rage, lorsque aucun cas de rage humaine ou animale, transmise par le chien, n'a été confirmé depuis au moins deux ans.
L'OMS publie régulièrement une carte réactualisée des pays à risques selon 4 catégories : absence de risque, à risque faible, modéré, et élevé.Le processus d'élimination se fait en 4 phases : « endémique » pays avec cas humains confirmés notifiés chaque mois, « contrôle » forte diminution des cas humains après mesures collectives, « zéro décès humain » indique l'interruption de la transmission à l'homme de rage canine, « élimination » indique l'arrêt de toute transmission de rage avec absence de cas de rage canine et humaine.La situation d'un pays où la rage est éliminée (éradiquée localement) reste toujours fragile.
C'est une phase de « maintenance » qui se réfère à la surveillance et à la prévention d'une nouvelle introduction de rage avec cas de rage canine ou humaine.Selon les critères de l'OMS et de l'OIE, la France remplit les conditions de pays indemne de rage depuis 2010, mais compte tenu des risques de réintroduction, la situation française fait l'objet d'une surveillance permanente,.En France, la rage du renard a été éradiquée (arrêté du 30 avril 2001 du ministre de l'agriculture).
L'éradication a été menée, entre autres, grâce à la vaccination préventive des animaux de compagnie et des personnes potentiellement exposées au virus de la rage (chiroptérologues, vétérinaires, etc.) et par un plan de surveillance de cette maladie au niveau national.Dans le domaine vétérinaire, écosystémique, éco-épidémiologique et cynégétique, cette zoonose est suivie par l'ONCFS avec le réseau SAGIR et l'appui de laboratoires spécialisés, dont le LERPAS (Laboratoire d'études sur la rage et la pathologie des animaux sauvages).De 1968 à 2018, 42 chiens et 3 chats ont été diagnostiqués atteints de rage, tous ont été importés.
L'apparition de ces cas a donné lieu à des prises en charge des personnes exposées, allant de 2 à 187 personnes (selon le déplacement de l'animal).Des cas en provenance du Maroc, survenus en 2008, ont donné lieu à une procédure judiciaire à propos de l'euthanasie de chiens suspects en contact avec les animaux enragés.
Les propriétaires ont obtenu gain de cause en portant plainte du fait que la rage de leurs chiens n'a pas été vraiment diagnostiquée,.À la date de septembre 2020, le dernier  cas de rage de chat est survenu fin octobre 2013 dans le Val-d'Oise.
Le dernier cas de rage du chien date de mai 2015 (chiot revenant d'Algérie).La France était indemne de rage (mammifères terrestres) depuis le début de l'année 2001, elle a perdu ce statut en 2008 pour le retrouver en 2010.Il existe un risque résiduel provenant des animaux importés illégalement, en particulier les chiens des pays de l'Europe de l'Est et d'Afrique du Nord (malgré la sanction prévue d'être condamné à cinq ans de prison et 75 000 euros d'amende).La rage humaine est surveillée par la déclaration obligatoire et le Centre national de référence à l'Institut Pasteur.De 1970 à 2018, 23 cas de rage humaine ont été diagnostiqués en France, dont 8 cas âgés de 5 ans ou moins.
22 étaient des cas importés, contaminés pour la majorité en Afrique, dont un avait été contaminé par une greffe de cornée issue d’un donneur de retour d’Égypte.
Le cas non importé est survenu en 2008 en Guyane, probablement lié à une contamination par une chauve-souris.Le dernier cas importé est décédé en France (Rhône) en octobre 2017, un enfant de 10 ans mordu par un chiot avec qui il jouait au Sri Lanka.48 cas positifs de chauve-souris enragée ont été identifiés de 1989 à 2014.
Ces chiffres sont une sous-estimation, les chauve-souris étant une espèce protégée, la surveillance ne se fait pas par prélèvement actif dans la nature.Cette rage est lié à un virus différent de celui de la rage vulpine, c'est un virus cousin avec de notables différences tant dans son expression (il peut rester à l'état latent pendant très longtemps) que dans ses espèces cibles.
La seule recommandation est de ne toucher les chauves-souris qu'en cas de nécessité absolue et de le faire avec des gants, les professionnels exposés faisant l'objet d'un suivi particulier.De façon générale, la rage terrestre est éliminée ou contrôlée dans les pays de l'Union européenne, mais des cas occasionnels de rage canine surviennent encore en Europe de l'Est.
La rage peut franchir les frontières en touchant les populations de renards Vulpes vulpes, ou par transport d'animaux de compagnie provenant de pays endémiques.La Finlande et les Pays-Bas sont déclarés exempts de rage depuis 1991.L'Allemagne n'a pu se débarrasser de certains foyers persistants qu'en 2008, notamment dans le Land de Hesse.
Ce foyer était la source de différentes infections épisodiques constatées dans d'autres länder.
Ainsi, le Bade-Wurtemberg (décembre 2004), le Rhénanie-Palatinat (janvier 2005) et le Kreiz de Kussel (mai 2005) ont révélé une progression de la rage vers l'Ouest.
Ce « front » progressait selon diverses estimations à une vitesse de 20 à 60 km par an.
D'autres estimations plus récentes faisaient état d'une progression encore plus rapide, et dans toutes les directions à partir de ce Land de Hesse.Dans chacun des Lands touchés, l'Allemagne a entrepris des campagnes de vaccinations orales des renards.
Vu l'absence de cas enregistrés en 2008 et 2009, l'Allemagne a déposé la demande de déclaration d'État « libre » de rage, tout comme son voisin l'Autriche.Depuis 1998, l'Allemagne a détecté 642 animaux atteints par la rage, dont quarante-quatre animaux domestiques, 422 renards et 115 chauves-souris.
Cependant, depuis 2001, seuls huit cas d'animaux domestiques ont été confirmés.
Cinq humains sont morts de la rage.Le 28 septembre 2008, l'Allemagne a déclaré à l'Organisation mondiale de la santé animale avoir vaincu la rage sur son territoire.En Belgique et au Luxembourg, la rage est déclarée éliminée en 2001.
Mais en mai 2013, au Luxembourg, un homme a été mordu dans sa chambre par une chauve-souris tombée sur son lit durant la nuit.
L'animal s'est révélé être porteur du virus.La Suisse est reconnue indemne de rage depuis le 1er janvier 1999.
L'apparition de la maladie par voie terrestre de cas provenant d'animaux sauvages est très rare.
Cependant, le cas de chauves-souris ou d'animaux importés porteurs n'est pas exclu.
D'ailleurs, depuis cette date, trois cas ont été constatés : un cas de chauve-souris infectée a été reporté en 2002 dans le canton de Genève, le cas d'un chien importé d'Afrique du Nord en 2003, dans le canton de Vaud, ainsi qu'un cas de morsure de chauve-souris en août 2017 dans le canton de Neuchâtel.L'Italie a réussi à éradiquer la rage en 1997, mais une épizootie en provenance des Balkans et touchant également l'Autriche se développe en 2011.
Une campagne de vaccination des animaux est mise en place, et après un dernier cas sauvage détecté en 2011, l'Italie est de nouveau classée comme exempte en 2013,,.Fin 2011, des cas de rage vulpine avaient été identifiés en république de Macédoine à 3 km de la frontière grecque.
Une surveillance de la rage vulpine a été mise en œuvre en Macédoine.En octobre 2012, les premiers cas grecs de rage vulpine ont été identifiés à proximité de la frontière macédonienne.
Depuis, 16 cas de rage chez des animaux ont été notifiés à l’Organisation mondiale de la santé animale en Grèce dans les régions de Macédoine de l’Ouest et Macédoine Centrale.
Le 1er mars 2013, les autorités grecques ont rapporté la survenue d’un cas de rage chez un chat domestique d’une ferme de la région de Thessalie.
« Selon l’OMS, les pays voisins de la Grèce sont considérés comme à haut risque de rage.
La Grèce est indemne de rage depuis 1987.
Les événements survenus depuis octobre 2012 et l’extension du foyer devraient rapidement entraîner la perte du statut indemne.
»La Tchéquie, après de vastes campagnes de vaccination des renards, a vu son dernier cas de rage en 2002, et a été déclarée exempte en août 2004.En Pologne, des vaccinations massives des renards sont organisées, les cas sont concentrés dans le sud-est du pays, au niveau de la zone frontalière avec l'Ukraine.
Seule une vingtaine de cas est relevée en 2016.En Afrique, le nombre de décès par rage transmise par le chien est estimé à plus de 20 000 par an, soit près de 36 % des cas mondiaux.
De nombreuses vies pourraient être sauvées avec une amélioration de l'accès au PPE (prophylaxie post-exposition) et une réduction de la rage canine.Au Moyen-Orient, ces décès ont été estimés à 229 en 2015.L'inde est le pays le plus touché avec près de 60 % des 35 000 décès annuels en Asie, représentant près de 35 % des cas mondiaux.En Asie centrale, on compte près de 1875 décès par rage chaque année.Depuis 2007, l'ONG tibétaine Tibet Charity organise des campagnes de vaccination de chiens et de chats à Dharamsala et dans des régions voisines comme Chauntra, Gopalpur et Trilokpur.
Aucun cas de rage n'a été enregistré en 2007.La République populaire de Chine recensait un pic de 3 279 cas de rage humaine en 2006.
Les provinces du sud et du sud-est sont les plus touchées.
La rage est parmi les trois premières causes de décès par maladie infectieuse notifiée, derrière le sida et la tuberculose,.
Depuis les années 2010, la Chine notifie de 2000 à moins de 1000 cas humains par an,.
La situation chinoise se caractérise par un développement économique rapide, avec plus d'animaux de compagnie et de l'industrie qui va avec, mais avec un défaut de surveillance et de contrôle, et un manque de vaccins antirabiques vétérinaires de qualité.La République de Chine (Taïwan) est exempte de la rage de 1961 à 2013, mais la maladie ressurgit en 2013 parmi les Melogale,.La rage était endémique au Japon, avec un pic dans les années 1920, mais la vaccination des chiens et la lutte contre les chiens errants ont fait diminuer les cas.
En 1950, une loi a été votée pour lutter contre la rage, et les derniers cas sont recensés en 1954 et 1957,.Depuis cette date, le Japon est considéré comme étant exempt de rage, même si des cas contractés à l'étranger, notamment aux Philippines, sont parfois encore déclarés,,.L'Australie est officiellement exempte de rage.
Un premier cas aurait été signalé en 1867.
Deux morts ont été constatées, en 1987 et 1990, la maladie ayant été contractée à l'étranger.
Des craintes existent quant à l'introduction de cette maladie par des animaux en provenance de l'Indonésie voisine.Au Canada, la rage est une maladie qui doit obligatoirement être signalée.
Chauve-souris, renard arctique ou roux, mouffette, raton-laveur ou animaux domestiques sont généralement la cause des infections.
L'Ontario est la province la plus touchée.Aux États-Unis, en 2007, la rage canine a été déclarée éradiquée.
Chauves-souris, mouffettes et ratons-laveurs restent les principaux vecteurs d'infection.L'épidémie de rage s'est déclarée chez les mouffettes dans le nord-est des États-Unis à partir des années 1970, et se répand dans les autres États.
Le contrôle par vaccination orale, est plus difficile qu'en Europe, à cause de la diversité des vecteurs, de l'étendue des territoires à traiter, et du coût plus élevé de ces campagnes.En Amérique centrale et du sud, les campagnes soutenues de contrôle de la rage canine ont réduit les cas humains de façon très significative.
En 2016, les cas humains transmis par le chien sont au nombre de 10 dans deux pays Haïti (8) et Guatemala (2).
On compte toutefois 23 décès humains de rage transmise par des animaux autres que le chien : Brésil (3), Colombie (2), Guatemala (1), Mexique (2), Pérou (15).Chez l'animal, les symptômes dépendent de l'espèce concernée.
Il s'agit le plus souvent de troubles du comportement (forme furieuse, léthargique, paralytique… ou formes intriquées, intermédiaires, évoluant l'une en l'autre), ou encore activité diurne d'un individu appartenant à une espèce nocturne.Chez le chien, la rage évolue en trois phases :Le vétérinaire cherche ainsi systématiquement à écarter en première intention la rage lorsqu'un chien vient en consultation avec des troubles nerveux.Les bovidés sont très sensibles à la rage, de même les ovidés et caprinés peuvent présenter des formes furieuses de rage.
Mais habituellement ils ne mordent pas et vont plutôt charger.La rage du cheval est rare, mais elle est furieuse et dramatique : le cheval enragé se précipite sur tout animal à proximité, y compris l'homme, et sur tout objet jusqu'à se briser la mâchoire.
Il peut aussi se déchirer et se mordre lui-même.L'incubation est variable, habituellement comprise entre un et trois mois (extrêmes de quelques jours à plus d'un an).
Ce temps long d'incubation rend possible la prévention vaccinale de la rage, même après morsure.Ce temps d'incubation varie selon l'importance de la dose infectieuse (quantité de virus inoculé), du lieu d'inoculation et de sa richesse en terminaisons nerveuses.
Par exemple une morsure rabique délabrant la face a une incubation plus courte qu'une morsure égratignant le mollet ; ou une morsure à la main qu'une morsure au tronc.Les premiers signes sont non spécifiques, à type de douleurs au niveau du point d'inoculation.
Il peut exister un prurit, une réaction locale.
La maladie se poursuit par l'apparition de signes neurologiques : anxiété, confusion, agitation avec troubles du comportement avec insomnies, troubles des fonctions cérébrales supérieures.
Ces troubles évoluent vers une encéphalite qui peut se présenter sous deux formes : la forme furieuse (70 à 90 % des cas) et la forme paralytique (10 à 30 % des cas).L'hydrophobie rabique serait présente plus fréquemment lorsque la transmission a été faite par un chien.
C'est un signe classique de rage, elle consiste en un spasme à la déglutition des liquides, avec risque d'étouffement et de fausse route.
Ce spasme est lié à une hyperesthésie du pharynx et du larynx (sensation de brûlures insoutenable à l'ingurgitation d'eau).
Par réflexe pavlovien, les spasmes de l'hydrophobie rabique se déclenchent à la seule perception (vision, audition…) ou évocation de l'eau.Beaucoup moins fréquentes sont l'aérophobie réalisant un spasme facial extensif déclenché par un souffle d'air derrière l'oreille, avec peur réflexe des situations à courants d'air ou air frais,, et la photophobie qui se retrouve dans de nombreuses affections autres que la rage.L'encéphalite proprement dite se manifeste par des hallucinations, doublement de vision et d'éventuels délires avec état d'agitation, pouvant être compliquées par des convulsions, une fièvre.
Le décès survient en quelques jours par arrêt cardio-respiratoire.Selon des chroniqueurs du XVIIe siècle, « À Sewen, dans la vallée de Masevaux, à l’automne en 1672 un loup mord beaucoup de personnes, chacune est prise d’un fou rire et en mourait après la morsure.
»Dans 10 à 30 % des cas, la maladie prend la forme d'une paralysie ascendante ressemblant au syndrome de Guillain-Barré.
L'évolution est plus longue, moins dramatique, sans hydrophobie, mais finalement presque toujours mortelle.
Ces cas sont souvent mal diagnostiqués, d'où une sous-notification des cas de rage dans le monde.Le diagnostic est fait soit par la recherche d'ARN viral dans une biopsie cutanée au niveau de la nuque, soit par diverses techniques détectant tout ou partie du virus dans les tissus infectés (peau, urines ou salive) avant ou après la mort.La présence d'anticorps anti-rabique est inconstante et retardée.
Leur dosage par immunofluorescence dans le tissu cérébral, après la mort, est la méthode de référence de confirmation.En France, le diagnostic chez l'animal repose sur la mise en évidence de l'antigène viral et de l'isolement du virus à partir de tissus cérébraux.
Toutes les demandes de diagnostic sont traitées par le CNRR (Centre National de Référence de la Rage).
Chaque année, ce centre reçoit 1 300 prélèvements issus d'animaux suspects décédés ou euthanasiés sous surveillance vétérinaire.Le traitement antirabique à visée curative, dit aussi de prophylaxie post-exposition (PPE), doit être réalisé aussitôt que possible après une plaie ou morsure à risque.
La rage diffère de nombreuses infections par la longue durée de son incubation, et du fait qu'elle peut être prévenue à temps par une vaccination, même après une exposition aux virus rabiques.Le traitement antirabique PPE correspond à une « course de vitesse » entre la diffusion du virus et le système immunitaire du sujet contaminé, avant l'apparition des signes cliniques.
Le but est alors d'accélérer la production d'anticorps neutralisant le virus, par vaccination (immunisation active), et selon les cas par immunoglobulines spécifiques (immunisation passive).Selon l'OMS, un traitement PPE réalisé rapidement est efficace à 100 % même en cas d'exposition grave.
Les principales causes d'échecs et les décès qui s'ensuivent sont liées à une prise en charge tardive, une plaie mal soignée ou passée inaperçue, une atteinte directe des nerfs, et un traitement PPE incomplet ou mal suivi.C'est la première étape et elle consiste à traiter localement afin d'éliminer un maximum d'agents pathogènes au niveau du point d'entrée de l'infection par des moyens à la fois mécanique (lavage) et chimique (antisepsie).
En ce sens la plaie de la morsure doit être immédiatement lavée abondamment à l'eau savonneuse puis rincée à l'eau pure, et enfin désinfectée avec un antiseptique (alcool à 70°, dérivé iodé…).Les plaies importantes font l'objet d'une prise en charge aux urgences, où elles sont explorées et réparées chirurgicalement.
L'antibiothérapie est indiquée selon les circonstances.
La prévention du tétanos est systématique.Le risque de contamination rabique dépend de nombreux facteurs.Il y a déjà le facteur territorial, avec une emphase sur les pays endémiques de rage des animaux terrestres.
Dans d'autres pays, comme en France métropolitaine, la rage des animaux terrestres est considérée comme étant éliminée.
Toute morsure de chauve-souris sur le territoire, ainsi que toute morsure survenue à l'étranger en pays endémique de rage, sont potentiellement à risque et doivent être traitées.
Un risque exceptionnel persiste également en cas de morsure ou léchage par un chien illégalement importé.Cela dépend aussi du sort de l'animal mordeur selon que l'animal est retrouvé vivant (mis en surveillance) ou mort, ou non retrouvé.
Sur le territoire français (sauf Guyane et Mayotte), il n'est plus recommandé de vacciner les personnes mordues par un mammifère terrestre, quand l'animal n'est pas disponible (non retrouvé) ; le risque résiduel d'un animal importé infecté étant considéré comme négligeable à l'échelle nationale française, estimé à 7,52 × 10−10.Il y a aussi la nature du contact : avec les plaies par morsures, griffures, etc, le risque est élevé tandis qu'il sera plus faible par contact direct simple (léchage, attouchement de la face de l'animal) ou indirect (objets souillés, animal qui vient d'être mordu par l'animal suspect).Entre aussi en compte le siège de l'éventuelle morsure (à la face, au cou, et aux extrémités, elles sont plus dangereuses).
En l'absence de traitement, la probabilité moyenne de développer la rage après morsure d'un animal enragé est de 55 % pour une morsure à la tête, 22 % au membre supérieur, 9 % au niveau du tronc et 12 % au membre inférieur.
L'interposition de vêtements intacts (non déchirés) est considérée comme protectrice.L'OMS distingue trois niveaux de risques avec un animal enragé ou présumé enragé, ces recommandations s'appliquent en France : Le traitement post-exposition est réalisé dans un centre antirabique.
Il repose sur plusieurs injections rapprochées de vaccin, associées selon les cas à des immunoglobulines spécifiques.Les immunoglobulines antirabiques sont d'origine équine ou humaine, ces dernières étant plus chères.
Si possible, elles sont injectées au niveau des morsures, et en même temps que la première injection de vaccin.
Elles ne doivent pas être injectées après le septième jour du traitement vaccinal.En France, on utilise des vaccins inactivés, produits sur cultures cellulaires soit cellules Vero, soit sur cellules d'embryon de poulet.
Il existe différents protocoles par injections intramusculaires :En 2018, les données disponibles indiquent que la voie intradermique est d'une efficacité équivalente à la voie intramusculaire en réduisant les coûts et la dose nécessaire.Dans tous les cas, le patient doit être hospitalisé, avec des précautions d'hygiène simples pour le personnel, le virus ne se transmettant au soignant que si la peau est lésée.La rage déclarée, c'est-à-dire la rage qui a déjà produit ses premiers symptômes (ce qui indique que le virus est parvenu aux centres nerveux), est une maladie presque toujours mortelle chez l'humain.
L'accent est mis sur les soins palliatifs pour les patients à rage confirmée, respectant l'intimité, la dignité et les besoins culturels du patient et de sa famille.Les principaux soins sont l'hydratation, des tranquillisants comme les benzodiazépines, et des sédatifs comme la morphine.
Les soins invasifs sont à éviter.Les cas de survie sont tout à fait exceptionnels.
Fin 2004, à Wauwatosa dans le Wisconsin, un traitement expérimental a permis de sauver sans vaccination une jeune adolescente américaine, nommée Jeanna Giese, contaminée par une chauve-souris.
Le traitement, depuis connu sous le nom de protocole de Milwaukee, consiste à plonger le patient dans un coma artificiel pour ralentir la progression de la maladie et à lui administrer un traitement médical intensif.
Un article paru en 2009 a recensé 25 tentatives d’application de ce traitement dans sa première version avec un taux de survie de 8 % (soit 2 sur les 25), et 10 dans sa seconde version avec deux survivants, soit 20 %.
Un article scientifique de 2016 et un rapport d'experts de l'OMS de 2018 recommandent de ne plus utiliser ce protocole, en raison du taux d'échecs et des séquelles graves en cas de survie.Selon ce rapport, les traitements dits agressifs ou expérimentaux devraient être soumis et approuvés par des comités d'éthique, après discussion avec les familles.Il faut signaler immédiatement tout cas de rage au chef technique ou à l'autorité administrative locale.
Tout chien mordeur doit être considéré comme suspect de rage, car un chien infecté peut transmettre le virus avant l'apparition des premiers symptômes.Aussi est-il nécessaire, si le diagnostic est incertain, de le garder en quarantaine en observation pendant au moins quinze jours, avec trois examens de vétérinaire aux jours 0, 7 et 15.
Le chien doit être nourri et abreuvé.
Si le chien est enragé, et si les signes progressent après les premiers symptômes, il peut être euthanasié, car il mourra au bout de dix jours.En Belgique, en France et en Suisse, la rage est sur la liste des maladies infectieuses à déclaration obligatoire.Surtout dans les pays où la rage est endémique, il est conseillé d'éviter tout contact avec un animal inconnu, domestique ou sauvage, vivant ou mort.Un vaccin préventif contre la rage existe et reste recommandé en France pour les voyageurs, professionnels et chiroptérologues risquant d'être exposés au virus.
Il est inoculé aux personnes dont l'activité est un facteur de risque d'infection.
Les vétérinaires ou les personnes se rendant dans les pays où la maladie est endémique en sont des exemples.À noter que la chloroquine, médicament antipaludéen diminue l'efficacité du vaccin intramusculaire contre la rage et ce, en prophylaxie, comme en pré-exposition.La vaccination préventive utilise les mêmes vaccins que ceux de la vaccination curative.
En France, les deux vaccins humains disponibles appartiennent aux vaccins, dits de 3e génération, préparés sur cultures cellulaires, :Il existe d'autres vaccins, produits sur d'autres cultures cellulaires, telles que sur cellules diploïdes humaines (HDCV, « Human diploid cell culture rabies vaccine ») .Le protocole est celui recommandé par l'OMS, en 3 injections aux jours 0, 7 et 28.
Les rappels éventuels ultérieurs se font en fonction d'un suivi sérologique tous les 2 ans en situation à faible risque et tous les 6 mois en risque élevé.
Ce vaccin préventif ne dispense pas d'une vaccination curative en cas de morsure : chez le sujet déjà vacciné, non immunodéprimé, elle est réduite à deux injections aux jours 0 et 3.Ces vaccins sont très supérieurs aux anciens vaccins préparés sur tissus nerveux, aussi bien du point de vue de l'efficacité que de l'innocuité.
Depuis 1984, l'OMS recommande l'abandon complet de ces anciens vaccins.
En 2018, ce type de vaccin sur tissu nerveux reste encore utilisé en usage humain dans quatre pays : Algérie, Argentine, Bolivie et Éthiopie.Les effets indésirables des vaccins antirabiques sur cultures cellulaires sont des douleurs et inflammations mineures chez 35 % à 45 % des sujets vaccinés, et des manifestations bénignes telles que réaction fébrile, maux de tête, malaises et troubles digestifs chez 5 à 15 % des vaccinés.
Les manifestations graves sont rares et la survenue de troubles neurologiques n'a pas été démontrée.Le commerce international d'animaux domestiques et sauvages obéit à une réglementation incluant la présentation d'un certificat vétérinaire international validé.
La règlementation de chaque pays pour l'importation d'animaux vivants doit être conforme aux standards de l'OIE.Les épizooties de rage sauvage terrestre se traitent par vaccination, notamment par voie orale.
La réduction des populations sauvages n'est pas recommandée.Les campagnes de vaccination de masse ciblent principalement les chiens.
Cette stratégie s'est avérée efficace sur tous les continents, en arrêtant la transmission entre les chiens, et en réduisant la transmission du chien à l'homme et à d'autres mammifères, avec une couverture vaccinale minimum de 70 %.
Cette vaccination doit s'accompagner, selon le contexte, d'un contrôle des chiens errants, mais pas de leur abattage qui est inefficace à long terme, et contre-productive (le ciblage des chiens errants fait négliger la vaccination des chiens domestiques).De même une stratégie de stérilisation des chiens peut être envisagée dans des situations particulières, mais la priorité est à la vaccination, moyen le plus efficace pour réduire la rage canine, et indirectement la rage humaine.Au cours de la Seconde Guerre mondiale, une rage des renards réapparait en Europe de l'Est (probablement à la suite de l'élimination des loups de ces régions).
Signalée en Pologne en 1945, elle progresse vers l'Ouest à une vitesse moyenne de 40 km par an et parvient en France (Moselle) en 1968,.
Dans les années 1970, la rage des renards s'étend sur le quart nord-est du territoire français.
Le maximum est atteint en 1989 (27 départements touchés, et 4212 cas de rage animale confirmés en laboratoire).Le Danemark s'est protégé sur sa frontière, par la destruction systématique des renards sur une bande de 30 km de large.
Cette méthode a été critiquée pour son efficacité de courte durée, les renards des régions voisines venant réoccuper les zones traitées.
En Suisse et en Allemagne, des essais de capture de renards, vaccinés comme les chiens (injection intra-musculaire) puis relâchés, sont des échecs, car trop difficiles à réaliser.À partir de 1971, des chercheurs américains démontrent qu'il est possible de vacciner les renards par voie orale par virus vivant atténué.
En 1978, les Suisses sont les premiers à appliquer cette méthode sur le terrain, en utilisant comme appâts des têtes de poulets contenant une capsule de vaccin.On a montré en laboratoire que le virus peut être transmis par voie orale à des rongeurs.
Aussi les autres pays, appuyés par l'OMS, préfèrent garder une attitude prudente.
C'est seulement à partir de 1983, que d'autres essais ont lieu en utilisant d'autres appâts et d'autres vaccins améliorés grâce à la technique des anticorps monoclonaux.
C'est notamment le cas de pays comme le Luxembourg, la Belgique, l'Allemagne, l'Autriche et l'Italie.La France adopte cette méthode d'appâts vaccinant en 1986, par largage à partir d'hélicoptères en 1988.
À partir de 1990, la rage du renard diminue régulièrement et fortement chaque année, jusqu'à atteindre des niveaux négligeables en 1998 (4 cas de rage animale, chacun sur une espèce différente : un renard, une chauve-souris, un chien et un chat).La vaccination des renards a lieu lors de la lutte contre la rage vulpine.
Des appâts contenant une dose du vaccin dans une capsule sont mis en place, généralement par hélicoptère, et sont mangés par les renards, permettant la libération du vaccin.
La vaccination orale a été expérimentée la première fois en Suisse en 1978.Des vaccinations massives de ce type permettent l'éradication de la maladie chez les renards.
Le taux de vaccination des renards doit être d'au moins 75 %.En ce qui concerne la rage des chauves-souris, celles-ci sont peu accessibles.
Dans des zones où des chauves-souris vampires sont porteuses de rage de manière endémique (Amérique du Sud), il est recommandé de se protéger des morsures de chauves-souris pendant la nuit.
Ainsi, les voyageurs en forêt dormiront sous moustiquaire même en l'absence de moustiques.
La moustiquaire devra être disposée de façon suffisamment ample pour qu'il soit impossible à une chauve-souris de mordre la personne au travers de la moustiquaire.En Europe, la rage de chauve-souris autochtone est documentée depuis 1954 en Allemagne, puis dans les autres pays européens (France en 1989).
L'espèce majoritairement en cause est une chauve-souris insectivore, la sérotine commune.
Une chauve-souris enragée se caractérise par une activité diurne, un vol impossible, une paralysie ou une agressivité.
Il est déconseillé de manipuler une chauve-souris à terre, trouvée en plein jour,.
L'année 2001, est une année commune qui commence un lundi.
C'est la 2001e année de notre ère, la première année du IIIe millénaire, du XXIe siècle,, et la 2e année de la décennie 2000-2009.Les attentats du 11 septembre, ainsi que le début de la seconde guerre d'Afghanistan, constituent les événements marquants de l’année et même des vingt dernières années.
Les attentats du 11 septembre sont parfois considérés comme le fait déclencheur de la guerre contre le terrorisme et mis en parallèle avec la chute du mur de Berlin en 1989 qui a marqué la fin de la guerre froide.L'année 2001 du calendrier grégorien correspond aux dates suivantes :Les lauréats du Prix Nobel en  2001 sont :
Un acide nucléique (désoxyribonucléique ou ribonucléique) est un assemblage de macromolécules, un polymère, dont l’unité de base, ou monomère, est un nucléotide et dont les nucléotides sont reliés entre eux par des liaisons phosphodiesters.Ces acides nucléiques sont d'une importance fondamentale chez tous les êtres vivants, en étant le support de leur information génétique.Il existe deux types d’acides nucléiques : l'acide désoxyribonucléique (ADN) et l'acide ribonucléique (ARN) : Les acides nucléiques absorbent à 260 nm du fait de l'aromaticité des bases azotées.
On peut donc utiliser le rapport des absorbances à 260 et 280 nm A260/280 pour évaluer la contamination de protéines dans une solution d'acides nucléiques.
La pureté de la solution est jugée satisfaisante lorsque ce rapport est de 1,8 à 2,0 pour l'ADN et de 2,0 à 2,2 pour l'ARN.Le rapport A260/280 peut quant à lui être utilisé pour évaluer présence d'autres contaminants tels que l'EDTA, l'urée, les polyholosides, le phénol, et l'isothiocyanate de guanidinium.
Celui-ci indique une pureté satisfaisante lorsqu'il est compris entre 2,0 et 2,2.
On trouve des acides nucléiques (ADN et ARN) dans les cellules de presque chaque organisme.
Toute cellule eucaryote ou procaryote, soit les cellules animales, les cellules végétales, les bactéries, les mycètes (ou champignons) et même les mitochondries et les chloroplastes contiennent les deux types d’acide nucléique.
Toutefois, les virus peuvent contenir de l’ADN ou de l’ARN, mais jamais les deux en même temps.Chez les eucaryotes, l’ADN se trouve dans le noyau cellulaire, dans la matrice des mitochondries et dans le stroma des plastes.
Il s’associe à des protéines comme des histones (sauf pour l'ADN mitochondrial → non associé a des histones).
Cet agencement d’ADN et de protéines forme la chromatine que l’on retrouve sous forme de chromosomes linéaires chez les eucaryotes (bien visibles durant la mitose) et sous forme de chromosome circulaire unique chez les procaryotes.Pour sa part, l’ARN se trouve dans le noyau et dans le cytosol.L'ARN est souvent en un seul brin alors que l'ADN est constitué par l'enroulement de deux chaînes pour former une double hélice = deux brins.Les acides nucléiques sont constitués d'un enchaînement de nucléotides reliés par des liaisons phosphodiesters.
Les nucléotides se composent toujours de trois éléments fondamentaux :Le tableau ci-dessous compare l'ARN à l'ADN selon leur structure et leur composition : On trouve différents types de liaisons dans les acides nucléiques : les liaisons fortes permettent la stabilité de la molécule, tandis que les liaisons faibles assurent la flexibilité nécessaire aux processus cellulaires comme la réplication, la transcription ou la traduction.Dans les acides nucléiques, les différents nucléotides sont placés bout à bout et liés les uns aux autres par des liens 5’- 3’ (prononcé 5 prime – 3 prime) phosphodiester (PO4) : ces chiffres donnent le sens de la liaison : 5' - Nucléotide 1 - PO4 - Nucléotide 2 - PO4 - ... - 3'.Le phosphate se lie au carbone 3 du sucre du premier nucléotide et au carbone 5 du sucre du nucléotide suivant ; tout ceci par l'intermédiaire de deux liaisons ester.
Les liaisons phosphodiester sont des liaisons covalentes.
Le phosphate est donc le lien entre chaque sucre.Les bases nucléiques sont attachées sur le carbone 1' des sucres par des liaisons covalentes.Les sucres du squelette sont reliés par des liaisons phosphodiester.
Ce sont des liaisons ester covalentes entre une fonction alcool du sucre (5'-OH ou 3'-OH) et l'acide phosphorique.L’alternance des phosphates et des sucres produit le squelette de l’acide nucléique sur lequel s’attachent les bases nucléiques.
Le polymère formé se nomme un brin et a l’allure schématique d’une « corde ».Le squelette est une partie relativement rigide puisqu'il est composé de liaisons covalentes, des liens chimiques très forts.Dans le cas de l’ADN, les deux brins sont disposés de telle sorte que toutes les bases nucléiques se retrouvent au centre de la structure.
Cette structure dite en double hélice est maintenue par des liaisons hydrogène qui se forment entre les bases nucléiques complémentaires, des liaisons faibles que la cellule peut aisément défaire.Les deux brins (plus souvent retrouvés dans l'ADN, rares dans l'ARN) prennent la forme d'une double hélice (structure hélicoïdale).
Cette structure souple est idéale pour permettre aux protéines telles les polymérases, les primases et les ligases, de dupliquer l'ADN.Ensemble, l’ADN et l’ARN jouent un rôle fondamental : ils sont le support de l’information génétique.L’ADN est le support de l’information génétique et détermine l'identité biologique de l’organisme (plante, grenouille ou humain).La préservation de cette information génétique se fait grâce à une duplication des molécules d'ADN avant la mitose (création de deux cellules filles identiques).L’ARN possède de nombreux rôles.
Il existe différents types d’ARN et chacun d’entre eux joue un rôle spécifique.Les miARN peuvent réguler l'expression de plusieurs gènes (peut-être une centaine pour certains d'entre eux).Les cellules eucaryotes et procaryotes possèdent à la fois de l’ADN et de l’ARN.
À l'inverse chez les virus, il n’y a qu’un seul type d'acide nucléique : soit de l’ADN soit de l’ARN, qui peuvent être monocaténaire ou bicaténaire.On sépare les virus en plusieurs classes, selon la forme sous laquelle est présenté leur matériel génétique.
Par exemple le génome du VIH est sous forme d'ARN.
La vaccination est l'administration d'un agent antigénique, le vaccin, dans le but de stimuler le système immunitaire d'un organisme vivant afin d'y développer une immunité adaptative contre un agent infectieux.
La substance active d’un vaccin est un antigène dont la pathogénicité du porteur est atténuée afin de stimuler les défenses naturelles de l'organisme (son système immunitaire).
La réaction immunitaire primaire permet en parallèle une mise en mémoire de l'antigène présenté pour qu'à l'avenir, lors d'une vraie contamination, l'immunité acquise puisse s'activer de façon plus rapide et plus forte.La vaccination s'effectue sur un individu sain soit par injection sous-cutanée ou intramusculaire soit par voie orale, selon des pratiques le plus souvent réglementées.
En général, chaque acte de vaccination est documenté (exemple : dans un carnet de vaccination).L'Organisation mondiale de la santé estime que la vaccination est l’une des interventions sanitaires les plus efficaces et les plus économiques.
Elle a permis d’éradiquer la variole, de réduire de 99 % à ce jour l’incidence mondiale de la poliomyélite, et de faire baisser de façon spectaculaire la morbidité, les incapacités et la mortalité dues à la diphtérie, au tétanos, à la coqueluche, à la tuberculose, et à la rougeole.
Pour la seule année 2003, les autorités sanitaires estiment que la vaccination a évité plus de deux millions de décès.Des méthodes empiriques de variolisation sont apparues très tôt dans l'histoire de l'humanité, grâce à l'observation du fait qu'une personne qui survit à la maladie est épargnée lors des épidémies suivantes.
L'idée de prévenir le mal par le mal se concrétise dans des pratiques populaires sur les continents asiatique et africain,,.
La pratique de l'inoculation était en tout cas connue en Afrique depuis plusieurs siècles et c'est de son esclave Onesimus que l'apprit le pasteur américain Cotton Mather.
La première mention indiscutable de la variolisation apparaît en Chine au XVIe siècle.
Il s'agissait d’inoculer une forme qu’on espérait peu virulente de la variole en mettant en contact la personne à immuniser avec le contenu de la substance qui suppure des vésicules d'un malade (le pus).
Le risque n'était cependant pas négligeable : le taux de mortalité pouvait atteindre 1 ou 2 %.
La pratique s’est progressivement diffusée le long de la route de la soie.
Elle a été importée depuis Constantinople en Occident au début du XVIIIe siècle grâce à lady Mary Wortley Montagu.
Voltaire lui consacre en 1734 sa XIe lettre philosophique, « Sur la petite vérole », où il la nomme inoculation, lui attribuant une origine circassienne et précisant qu'elle se pratique aussi en Angleterre : En 1760, Daniel Bernoulli démontra que, malgré les risques, la généralisation de cette pratique permettrait de gagner un peu plus de trois ans d’espérance de vie à la naissance.
La pratique de l'inoculation de la variole a suscité de nombreux débats en France et ailleurs.Pour la première fois, des années 1770 jusqu'en 1791, au moins six personnes ont testé, chacune de façon indépendante, la possibilité d'immuniser les humains de la variole en leur inoculant la variole des vaches, qui était présente sur les pis de la vache.
Parmi les personnes qui ont fait les premiers essais, figurent en 1774 un fermier anglais nommé Benjamin Jesty et, en 1791, un maître d'école allemand nommé Peter Plett.
En 1796, le médecin anglais Edward Jenner fera la même découverte et se battra afin que l'on reconnaisse officiellement le bon résultat de l'immunisation.
Le 14 mai 1796, il inocula au jeune James Phipps, âgé de 8 ans, du pus prélevé sur la main de Sarah Nelmes, une fermière infectée par la vaccine, ou variole des vaches.
Trois mois plus tard, il inocula la variole à l'enfant, qui s'est révélé immunisé.
Cette pratique s'est répandue progressivement dans toute l'Europe.
Le mot vaccination vient du nom de la « variole des vaches », la vaccine, elle-même dérivée du latin : vacca qui signifie « vache ».
Un auteur récent – reprenant en cela un débat ancien qui avait commencé dès Jenner – fait remarquer que la pratique aurait pu s'appeler « équination » vu l'origine équine de la vaccine.
Il est par ailleurs attesté qu'en de multiples occasions des lymphes vaccinales ont été produites à partir de chevaux (l'un de ses premiers biographes rapporte même que Jenner a inoculé son fils aîné, en 1789, avec des matières extraites d'un porc malade du swinepox,).Le principe de la vaccination a été expliqué par Louis Pasteur et ses collaborateurs Roux et Duclaux, à la suite des travaux de Robert Koch mettant en relation les microbes et les maladies.
Cette découverte lui permit de développer des techniques d'atténuation des germes.
Sa première vaccination fut la vaccination d'un troupeau de moutons contre le charbon le 5 mai 1881.
La première vaccination humaine (hormis la vaccination au sens originel de Jenner) fut celle d'un enfant contre la rage le 6 juillet 1885.
Contrairement à la plupart des vaccinations, cette dernière fut effectuée après l'exposition au risque — ici, la morsure du jeune Joseph Meister par un chien enragé et non avant (le virus de la rage ne progressant que lentement dans le système nerveux).Le terme vaccinologie a été créé en 1976 par Jonas Salk (1914-1995), pour désigner une branche de médecine de santé publique consacrée aux vaccins (statut de médicament) et à la vaccination (action d'immunisation préventive).
La vaccinologie est pluri-disciplinaire avec un double aspect biomédical et politique (de santé publique).La vaccinologie fait appel aux disciplines suivantes :La dimension économique de la vaccinologie est celle de l'activité industrielle liée aux vaccins : le coût recherche-développement d'un vaccin est comparé au coût de la maladie infectieuse évitable, certes dans le cadre général d'une économie libérale (recherche de profits) mais aussi de gestion budgétaire (limitation ou contrôle des dépenses d'un système de santé).Les dimensions sociologiques et éthiques sont représentées par les problèmes posés par l'obligation vaccinale et les droits individuels (information, liberté de choix…), les résistances et les oppositions aux vaccinations, les problèmes de communication et de gestion de crise face à des rumeurs ou des évènements médiatisés.Un vaccin est une préparation d'un ou plusieurs antigènes microbiens utilisés pour induire une immunité protectrice et durable de l'organisme, en faisant appel à l'immunité adaptative, par opposition à l'immunité innée.
Le but principal des vaccins est d'obtenir, par l'organisme lui-même, la production d'anticorps et l'activation de cellules T (lymphocyte B ou lymphocyte T à mémoire) spécifiques à l'antigène.
Une immunisation réussie doit donc procurer une protection contre une future infection d'éléments pathogènes identifiés.
Un vaccin est donc spécifique à une maladie mais pas à une autre.La vaccination est une technique d'immunisation active, par opposition à l'immunisation passive par transfert d'anticorps (par exemple, la sérothérapie).Le schéma vaccinal définit le nombre et l'intervalle des injections nécessaires à l'obtention d'une immunité protectrice suffisante.
La primo-vaccination est celle qui induit cette protection, et les rappels de vaccination sont celles qui l'entretiennent.À l'échelle nationale, le calendrier vaccinal est l'ensemble des schémas vaccinaux, réactualisés chaque année, par et pour un pays donné.
Ces schémas peuvent être recommandés ou obligatoires, selon l'âge ou la profession, en population générale ou particulière.La couverture vaccinale correspond au taux de personnes ayant reçu un nombre donné d'injections vaccinales à une date donnée.Deux grandes familles : vaccins issus d'agents infectieux et ceux sans agent infectieux.La première famille (vaccins classiques) se détaille en deux grandes catégories :Avec les vaccins vivants atténués, on injecte au patient une version modifiée du pathogène contre lequel on veut qu’il soit protégé.
Cette modification de l’agent infectieux sert à réduire son efficacité sans le tuer.
Notre corps va se défendre comme s’il combattait le virus ou la bactérie non-modifiée et produire des cellules mémoires pour le combattre plus efficacement la prochaine fois qu’il sera en contact avec ce même pathogène.
Ce type de vaccination est efficace sur le long terme.
Cependant, comme il s’agit d’inoculer la forme vivante du pathogène, même atténuée, il existe un faible risque infectieux qui constitue une contre-indication pour les personnes immunodéprimées.Les vaccins inactivés contiennent l’agent infectieux mort, ou alors fragmenté.
Cette méthode de vaccination est moins efficace sur le long terme et nécessitera des rappels.La deuxième grande famille est produite sans agent infectieux.
Parmi ceux-ci, les vaccins à ARN d'utilisation récente (même si le principe est connu depuis plus d'une dizaine d'années) se révèlent très prometteurs et très adaptables face aux mutations des virus.Les vaccins multivalents ou combinés, associent des combinaisons d'antigènes, permettant de cibler plusieurs maladies différentes en un seul vaccin (par exemple Rougeole-Oreillons-Rubéole ou Diphtérie-Tétanos-Poliomyélite-Coqueluche-Hib-Hépatite B).
Ces vaccins permettent de diminuer le nombre d'injections et d'augmenter la couverture vaccinale.La vaccination est un acte médical qui engage la responsabilité du vaccinateur, elle doit être expliquée et consentie.
Le sujet à vacciner a le droit de recevoir une information personnalisée, adaptée à son niveau de compréhension.En principe, l'acte vaccinal comporte des règles à respecter.
Il est effectué par un médecin ou un(e) infirmièr(e), ou selon des cas règlementés par une sage-femme ou un pharmacien.
En France, 90 % des vaccinations sont effectuées en médecine libérale, dans d'autres pays (comme les pays scandinaves) les vaccinations sont faites dans un cadre collectif (médecine scolaire, ou d'autres services publics).Elle doit être précédée d'un interrogatoire à la recherche d'éventuelles contre-indications (antécédents d'allergie, déficience immunitaire, grossesse ou projet en cours de grossesse…) ; de la vérification du vaccin (conditions de conservation du vaccin, date de péremption) et de ses conditions d'utilisation (selon la présentation du vaccin, le calendrier vaccinal, l'âge du sujet…).Chez le nourrisson et le petit enfant, l'utilisation de patch anesthésique ou d'une solution sucrée avec tétine est possible pour diminuer la douleur ou la peur.Le vaccinateur doit être en mesure de prendre en charge un malaise vagal ou une réaction allergique dans les minutes qui suivent une injection.La plupart des vaccins sont injectés par voie sous-cutanée ou intramusculaire, dans les conditions habituelles d'hygiène et d'asepsie.
Les principaux sites d'injection se font dans la région du deltoïde, du sus-épineux chez l'enfant et l'adulte, et la face antéro-latérale de la cuisse chez le nourrisson.
L'injection dans la fesse n'est pas recommandée, outre la proximité du nerf sciatique, l'épaisseur du tissu graisseux peut réduire l'efficacité vaccinale.La voie intradermique (injection superficielle et tangentielle à la peau) est pratiquement réservée au BCG, au niveau de la face externe du bras.
Elle est de réalisation plus délicate.Quelques vaccins sont administrés par voie orale, comme le vaccin oral contre la poliomyélite, ou les vaccins contre le rotavirus.
Des vaccins par spray nasal sont en cours d'essai (ex.
: vaccin antigrippal NasVax en Israël), voire déjà utilisés (vaccins contre la grippe saisonnière ou contre la grippe pandémique aux États-Unis).Les vaccinations sont notées et documentées (date, lot, fabricant, vaccinateur…) dans un carnet de vaccination et dans le dossier médical du patient.L'administration de paracétamol pour limiter des symptômes généraux (fièvre, douleur…) est à l'appréciation du prescripteur.Par abus de langage, le terme de vaccination s'applique parfois à diverses inoculations et injections sans vaccin.
Ainsi l'immunocastration des porcs est souvent présentée comme un vaccin (contre l'odeur de verrat).
En 1837, Gabriel Victor Lafargue parla de « vaccination morphinique » pour ce qui n'était qu'une injection sous-épidermique.
Dans cette catégorie se place également le vaccin de Coley (qui génère une hyperthermie destinée à détruire des tumeurs).La vaccination préventive est une forme de vaccination visant à stimuler les défenses naturelles de façon à prévenir l'apparition d'une maladie.
Elle ne cesse de voir son domaine s'élargir et peut prévenir les maladies suivantes :Au Québec, depuis le 1er janvier 2006, un vaccin contre la varicelle est offert à tous les enfants à partir de l'âge de un an.
De plus, il est maintenant combiné avec le vaccin contre la rubéole-rougeole-oreillons.La vaccination à large échelle permet de réduire de façon importante l'incidence de la maladie chez la population vaccinée, mais aussi (si la transmission de celle-ci est uniquement inter-humaine) chez celle qui ne l'est pas, le réservoir humain du germe devenant très réduit.
L'éradication de la poliomyélite de type 2 en 1999 est la conséquence des campagnes de vaccinations.
De même, pour l'éradication de la variole qui est effective depuis 1980, l'OMS avait mis en place une stratégie de vaccination de masse, alliée à une approche reposant sur la surveillance et l’endiguement (dépistage des cas, isolement des malades et vaccination des sujets contact).Aussi appelée « immunothérapie active » (ou, plus anciennement (?
), « thérapie vaccinale », « vaccinothérapie »), cette technique consiste à stimuler le système immunitaire de l'organisme pour favoriser la production d'anticorps.
Il ne s'agit donc plus de prévenir l'apparition d'une maladie mais d'aider l'organisme des personnes déjà infectées à lutter contre la maladie en restaurant ses défenses immunitaires.On a pu créditer Auzias-Turenne d'être à l'origine de la vaccination thérapeutique avec sa méthode de syphilisation, Pasteur prenant le relais avec son vaccin contre la rage.
Contrairement à une idée reçue cependant, la vaccination contre la rage n'est pas thérapeutique.
En fait, en pré-exposition (chez les personnes susceptibles d'être atteintes du fait de leur activité professionnelle par exemple) il s'agit d'une vaccination habituelle (injection de l'antigène qui va stimuler la fabrication de défenses spécifiques).
En post-exposition, c'est-à-dire après une morsure par un animal susceptible d'être enragé, il s'agit d'une immunisation passive et active.
Passive parce qu'il y a injection d'immunoglobulines (anticorps) spécifiques contre la rage et, au même moment, injection du vaccin antirabique.
Contrairement au SIDA ou au cancer, la vaccination antirabique n'est largement plus au stade expérimental.En août 1890, Robert Koch annonça avoir découvert une substance capable de guérir la tuberculose ; ce traitement à la tuberculine ne devait pas tenir ses promesses.
Un article d'Almroth Wright, publié en 1902 et intitulé Généralités sur le traitement des infections bactériennes localisées par inoculation de vaccins à base de bactéries, expliqua pour la première fois sans ambiguïté la théorie de la thérapie vaccinale.L'Organisation mondiale de la santé estime que la vaccination est l’une des interventions sanitaires les plus efficaces et les plus économiques.
Elle a permis d’éradiquer la variole, de réduire de 99 % à ce jour l’incidence mondiale de la poliomyélite, et de faire baisser de façon spectaculaire la morbidité, les incapacités et la mortalité dues à la diphtérie, au tétanos, à la coqueluche et à la rougeole.
Pour la seule année 2003, on estime que la vaccination a évité plus de deux millions de décès.Le tableau suivant montre la diminution de la mortalité en France entre avant 1950 et après 1990.
Il s'agit d'un taux de mortalité, c'est-à-dire du nombre de morts pour un million de personnes.Un plan de reconstruction au Japon ainsi qu'un plan de vaccination sont mis en place après la Seconde Guerre mondiale.
La coqueluche ravage un pays qui sort d'une guerre dévastatrice, on compte à la même année 152 072 personnes infectées par cette maladie et 17 001 morts.
À partir de 1951, le nombre de cas par an baisse tout comme le nombre de morts à la suite de la loi de vaccination préventive promulguée en 1948 et les exigences relatives au vaccin contre la coqueluche mises en place en 1949.
En 25 ans, le nombre de personnes infectées passe à moins de 400 cas par an et le nombre de morts à moins de 5 grâce à cette politique de santé.Pourtant, en décembre 1974 et janvier 1975, le gouvernement est notifié que deux enfants sont victimes d'accidents de vaccination.
Le rapport signale que l'un a contracté une encéphalopathie et que l'autre a fait un choc allergique qui lui est fatal.
À la suite de la pression de l'opinion publique, le gouvernement gèle temporairement l'obligation de vaccination pour la population japonaise.
Les effets de l'arrêt de la vaccination ne sont pas directement visibles à court terme.Néanmoins, dès 1979, le gouvernement japonais était mis au courant de 13 092 nouveaux cas.
Il s'agit ainsi d'une augmentation constante du nombre de personnes infectées par la coqueluche qui ne s'était jamais produite avant le gel du plan de vaccination, prouvant son efficacité.
Peu de temps après cet épisode épidémique, le taux de vaccination dans le pays retourne progressivement à 80 % et le nombre de nouveaux cas et le nombre de morts par an baisse à nouveau.Les effets indésirables de la vaccination dépendent d'abord de l'agent infectieux combattu, du type de vaccin (agent atténué, inactivé, sous-unités d'agent, etc), du mode d'administration (injection intramusculaire, injection intradermique, prise orale, vaporisateur intranasal, etc.) ainsi que de la nature du solvant, de la présence éventuelle d'adjuvants destinés à renforcer l'efficacité thérapeutique du vaccin et de conservateurs chimiques antibactériens.Il n'existe donc pas d'effet secondaire commun à tous les modes de vaccination.
Néanmoins, suivant les vaccins, certains effets indésirables, en général bénins, se retrouvent de manière plus ou moins fréquente.
L'une des manifestations les plus courantes est la fièvre et une inflammation locale qui traduisent le déclenchement de la réponse immunitaire recherchée par la vaccination.
Dans de très rares cas, la vaccination peut entraîner des effets indésirables sérieux et, exceptionnellement, fatals.
Un choc anaphylactique, extrêmement rare, peut par exemple s'observer chez des personnes susceptibles avec certains vaccins (incidence de 0,65 par million, voire 10 par million, pour le vaccin rougeole-rubéole-oreillons (RRO)).En France, la loi prévoit le remboursement des dommages et intérêts par l'Office national d'indemnisation des accidents médicaux lorsqu'il s'agit de vaccins obligatoires.La variole est considérée comme éradiquée depuis 1977.
La vaccination n'est donc plus du tout pratiquée même si des stocks de vaccins sont conservés en cas de résurgence.
Les complications suivantes ressortissent donc plutôt à l'histoire de la médecine :Les effets indésirables pouvant avoir lieu dans de rares cas sont surtout dus au vaccin anti-coqueluche (Per), :La première campagne de vaccination de masse anti-poliomyélite, dans les années 1950, a été marquée par la fourniture par les Laboratoires Cutter d'un important lot défectueux (virus vivant non atténué) aboutissant à près de 220 000 contaminations dont 70 000 malades, 164 paralysies sévères et 10 décès.Avant que la cause génétique de l'autisme ne soit établie, une publication a affirmé un lien entre ce vaccin et l'autisme.
Quelques années plus tard, cette étude a été récusée, son auteur Andrew Wakefield ayant reconnu la fraude sur fond de conflits d'intérêts.
Une étude de 2015 confirme qu'il n'y a aucun lien de cause à effet entre ce vaccin et l'autisme.Les effets indésirables de la vaccination contre l'hépatite B peuvent être, :Les réactions suivantes ont été observées :Cette vaccination est recommandée aussi bien chez les jeunes filles que chez les garçons.Au niveau international, l'OMS élabore des recommandations de vaccination.
Ces recommandations, non contraignantes, sont des indications de base en vue d'aider les pays membres à dresser leur propre calendrier national de vaccination, en fonction de leur situation, besoins et priorités.Ces recommandations sont explicitées par des notes de synthèse sur chaque vaccination, régulièrement actualisées.Le Plan d’action mondial pour les vaccins de 2011 à 2020 par l'Organisation Mondiale de la Santé fixe comme recommandation un taux national de 90 % de vaccination DTCoq chez les enfants.
L'Organisation des Nations unies indique que 139 des 194 États membres de l’OMS ont atteint, voire dépassé ce taux.
Malgré un progrès notable de la vaccination dans le monde, avec généralement moins d’inégalités au sein même d'un pays qu’il y a dix ans, en 2016, 10 millions d’enfants répartis dans 64 pays auraient besoin d’être vaccinés pour atteindre une couverture de 90 %.
L'ONU estime que 7,3 millions de ces enfants vivent dans un environnement précaire, de crise humanitaire ou dans un pays touché par des conflits.
C'est le cas de 4 millions d'enfants vivent en Afghanistan, au Nigeria et au Pakistan.Parmi les États membres de l’OMS, huit pays n'atteignent pas une couverture vaccinale DTCoq de 50 % : la Guinée équatoriale, le Nigeria, la République centrafricaine, le Somalie, le Soudan du sud, la Syrie, le Tchad et l'Ukraine.
Selon l'OMS et l'UNICEF, depuis 2010, le nombre d’enfants ayant une vaccination complète stagne.Au début du XXIe siècle, le plan de vaccination du pays comprend la coqueluche, la rougeole, la diphtérie, la tuberculose, le tétanos, l'hépatite B et la poliomyélite.En France, la vaccination est encadrée par différentes autorités qui ont chacune un rôle précis.
Ainsi, le ministère de la Santé élabore la politique vaccinale.
Ensuite, le Haut Conseil de la santé publique (HCSP), avec le comité technique des vaccinations, donnent des avis et des recommandations sur les vaccinations en se basant sur les connaissances scientifiques les plus récentes.
L'institut de Veille sanitaire assure la surveillance des maladies pour lesquelles il existe des vaccins.
L’agence nationale de sécurité du médicament et des produits de santé (ANSM) contrôle la qualité des vaccins et surveille le rapport bénéfice/risque des vaccins en collectant tous les effets indésirables déclarés.
Elle travaille en collaboration avec l’Agence européenne des médicaments (AEM).
La HAS, haute Autorité de santé évalue le service rendu des vaccins autorisés si le laboratoire qui les produit souhaite qu’ils soient remboursés par l’Assurance maladie.
Santé publique France (SPF), ex-INPES, placée sous la tutelle du ministère de la Santé, informe le public et les professionnels de santé sur les vaccinations nouvelles, existantes et obligatoires.En France, c'est le comité technique des vaccinations, une composante du Haut Conseil de la santé publique, qui est chargé de donner un avis sur le « calendrier vaccinal » mis à jour chaque année.
Ce dernier est établi par le ministère de la Santé et publié dans un des bulletins épidémiologiques hebdomadaires (BEH)de l'Institut de veille sanitaire (InVS) accessibles en intégralité.Plusieurs vaccins sont ainsi recommandés ou obligatoires, pour la population en fonction du lieu d'habitation, du sexe, de l'âge, des pathologies et d'autres facteurs de risque tels que la profession.
Ainsi, pour la population française, saine et non exposée à des facteurs de risque particuliers, le tableau suivant mentionne la situation en 2018, hors situation de rattrapage.Certains vaccins sont recommandés en fonction de la situation géographique, c'est le cas du BCG et du vaccin contre la fièvre jaune.
Concernant le BCG, le vaccin contre la tuberculose, une dose est conseillée pour les enfants résidant en Guyane ou à Mayotte, entre la naissance et 14 ans.
Concernant le vaccin contre la fièvre jaune, une dose est recommandée pour les enfants résidant en Guyane, à l'âge de 12 mois en lieu et place de la vaccination contre l'infection à méningocoque qui est déplacée à 16-18 mois ; par la suite, une dose de vaccin contre la fièvre jaune doit être administrée tous les 10 ans.Le calendrier vaccinal ayant fait l'objet de remaniements en 2013 et 2018, les situations de transition ou rattrapages sont prises en compte dans le document.
C'est en particulier le cas pour les vaccins les plus récemment introduits.
Ainsi, celui contre le papillomavirus humain (3 doses) peut être administré chez la fille jusqu'à 19 ans, et celui contre les infections à méningocoque (1 dose) peut être administré jusqu'à 24 ans.Pour rétablir la confiance des Français envers les vaccins, Marisol Touraine, alors ministre des affaires sociales, de la santé et des droits des femmes, a mis en place un plan d'action en septembre 2016.
Les objectifs principaux de son action sont d'informer la population des objectifs de la vaccination, de coordonner les actions pour améliorer la couverture vaccinale et d'éviter les conflits concernant l'approvisionnement des vaccins ainsi que les pénuries de ces derniers.
Le but ultime est de rendre le sujet de la vaccination important au sein des discussions citoyennes.Le calendrier est adapté à la situation chronique de pénurie de vaccins en France, toujours en 2019.Des tableaux synoptiques reprennent ce cadre et des résumés,.La Semaine européenne de la vaccination est mise en place sous l'initiative de l’Organisation mondiale de la santé en Europe depuis 2005.
Elle est un temps fort de mobilisation et d'actions pour promouvoir la vaccination et augmenter la couverture vaccinale.En France, la Semaine de la vaccination est coordonnée par le ministère chargé de la Santé publique France, et pilotée en région par les agences régionales de santé (ARS).
À cette occasion, des actions très diverses sont organisées à des endroits clés tels que les établissements scolaire et les Halles : expositions, séances d’information du public, conférences, jeux, animations, séances de vaccination gratuites, portes ouvertes, formations de professionnels… La Semaine de la vaccination est l'occasion de faire connaître le calendrier des vaccinations et pour chacun de s’informer sur ses vaccinations qui auront des bénéfices personnels et collectifs pour se protéger contre certaines maladies infectieuses.Au cours du XXIe siècle, des dizaines d'agents de santé ont été tués par des militants antivaccination ; les visites à domicile en vue d'une vaccination se font depuis sous escorte policière.À la fin des années 1980, les autorités sanitaires du Bangladesh ont décidé d'un plan de communication en faveur de la vaccination contre la polio porté par les chefs religieux du pays, appelé « mosquées porte-voix ».
Des publicités télévisées mettant en scène des célébrités bangladaises incitent la population à se vacciner.Le réseau électrique du pays n'est pas fiable et le climat est chaud, provoquant un risque de rupture de la chaîne du froid : pour pallier cela, tous les centres de santé sont équipés de panneaux solaires.
Le relais dans les espaces reculés se fait par cyclistes ou mariniers lorsque les rivières sont en crue.À noter que certaines professions (égoutiers, professions médicales, etc.) doivent avoir des vaccins supplémentaires par rapport au reste de la population.En 2010, sur 30 pays incluant les 27 pays de l'Union Européenne plus l'Islande, la Norvège et la Suisse, pour les enfants de moins de 13 ans, 16 pays n'ont aucune vaccination obligatoire : ce sont l'Allemagne, l'Autriche, Chypre, le Danemark, l'Espagne, l'Estonie, la Finlande, l'Irlande, l'Islande, la Lituanie, le Luxembourg, la Norvège, les Pays-Bas, le Royaume-Uni, la Suède et la Suisse.
Les 14 autres ont au moins une vaccination obligatoire.
Ce sont la Belgique (1 vaccin obligatoire), Bulgarie (9), France (11), Grèce (4), Hongrie (8), Italie (4), Lettonie (12), Malte (3), Pologne (8), Portugal (2), Roumanie (8), Slovaquie (9), Slovénie (7), République Tchèque (7).La vaccination contre la polio est obligatoire pour les enfants et les adultes dans 12 pays, contre la diphtérie et le tétanos (11 pays), contre l'hépatite B (10), l'hépatite A (2), HPV (1), pneumocoque (4), ROR (8), coqueluche (8), rotavirus (1), BCG (7), varicelle (1).
L'obligation vaccinale est considérée comme un moyen d'améliorer les programmes de vaccinations.
Toutefois, de nombreux pays atteignent les objectifs requis uniquement par recommandations.
Ainsi, il n’y a pas de différence significative de couverture vaccinale (taux de vaccinés) entre les pays qui recommandent et ceux qui obligent.Dès lors, le label « obligatoire » n'est pas le seul facteur permettant d'atteindre une forte couverture vaccinale en Europe.
D'autres facteurs peuvent entrer en jeu, comme l'utilisation de vaccins multivalents, le coût financier pour le pays destinataire, le type d'offre (gratuité ou remboursement, par médecin personnel ou de collectivité), les campagnes d'information et de promotion.
La diversité des politiques vaccinales en Europe tient plus à des facteurs historiques et culturels, qu'à des raisons scientifiques de santé publique.De meilleures informations sur la diversité de l'offre vaccinale au niveau européen pourraient aider les pays à adapter leurs stratégies vaccinales, en se basant sur l'expérience des autres pays.
Toutefois, cette adaptation devrait se faire aussi en tenant compte du contexte national local.En 2017, la France envisage de porter à 11 le nombre de vaccins obligatoires pour les enfants, tandis que l'Italie les porte à 12.L'arrêté du 28 février 1952 « fixant les obligations des médecins chargés des vaccinations antidiphtérique, antitétanique et antityphoparathyphoïdique et des examens médicaux préalables » — qui prolongeait l'arrêté ministériel du 20 août 1941 (JO du 10 septembre 1941) — avait instauré en France l'examen systématique des urines avant toute vaccination.
Ces dispositions, après avoir été étendues à la vaccination antipoliomyélitique par l'arrêté du 19 mars 1965 tel que paru au JO du 23 mars, ont été abrogées par la circulaire no 503 du ministère des Affaires Sociales et de la Solidarité du 3 octobre 1984.La loi du 9 août 2004 relative à la politique de santé publique, qui a créé le Haut Conseil de la santé publique (HCSP), précise que « la politique de vaccination est élaborée par le ministre chargé de la santé qui fixe les conditions d’immunisation, énonce les recommandations nécessaires et rend public le calendrier des vaccinations après avis du HCSP ».Les vaccins obligatoires sont remboursés par la sécurité sociale.
Les autorités sanitaires assurent que le rapport bénéfice/risque est suffisamment significatif.
L'inobservation des prescriptions vaccinales expose à des sanctions pénales ou administratives, notamment au retrait de l'autorité parentale, à la déscolarisation, au renvoi d'une administration, à une amende ou à une peine privative de liberté.
L'obligation de vaccination a entraîné la création de groupements de personnes opposées à son aspect systématique, par exemple la Ligue nationale pour la liberté des vaccinations qui invoque la Charte des droits fondamentaux de l'Union européenne qui instaure une clause de conscience.Depuis janvier 2018, huit vaccinations, auparavant recommandées, sont devenues obligatoires : les vaccinations contre coqueluche, Haemophilus influenzae de type b, hépatite B, pneumocoque, méningocoque de sérogroupe C, rougeole, oreillons et rubéole (les vaccinations contre diphtérie, tétanos et poliomyélite étant antérieurement seules obligatoires).
Ces 11 injections sont pratiquées, sauf contre-indication médicale reconnue, dans les 18 premiers mois, selon le calendrier vaccinal et sont exigibles pour l’entrée ou le maintien en collectivité à partir du 1er juin 2018 pour tout enfant né à partir du 1er janvier 2018.Le seul vaccin « DTP » n'est plus commercialisé par son fabricant depuis 2008, à la suite d'une recrudescence d'allergies dont il serait responsable.Les vaccins à 2, 4 et 11 mois sont en général injectés en même temps au sein d'un vaccin dit « hexavalent ».Le plan de vaccination suisse est élaboré par des experts indépendants (Commission fédérale pour les vaccinations, CFV), en collaboration avec l’Office fédéral de la santé publique (OFSP), il s'agit de recommandations qui ne sont pas obligatoires.En Suisse, la vaccination est libre ; si un vaccin est obligatoire dans un canton, pour un enfant seulement, les parents doivent justifier par écrit un refus.Depuis 2016, l'Australie prive d'une partie des allocations familiales les parents qui refusent de faire vacciner leur enfant.À la suite de l'éradication totale de la variole dans le cadre d'un programme mondial de l'OMS, le vaccin contre cette maladie n'est plus requis.
Deux souches sont cependant conservées dans des laboratoires américain et russe dans un but de recherche.La vaccination par le BCG (Vaccin bilié de Calmette et Guérin : tuberculose) n'est plus obligatoire depuis 2007.La prévalence de la tuberculose a fortement diminué en Europe entre le XIXe et le XXe siècle,.
Ce recul de la maladie serait largement dû à des facteurs autres (éloignement des malades en sanatorium, sélection naturelle des souches, amélioration des conditions de vie et d'alimentation, etc.),,.
Des études épidémiologiques d'efficacité vaccinale n'ont pas montré de recul de la maladie après des campagnes de vaccinations en Inde du sud,.
De même, on observe que la régression de la tuberculose est antérieure à la mise en place des campagnes de vaccination.Les études rétrospectives montrèrent que ces campagnes de vaccinations ne furent pas aussi systématiques que programmées.
Il est aujourd'hui admis que le vaccin BCG offre une immunisation variable, en particulier chez les jeunes adultes dans les régions tropicales.
Selon l'OMS, les études disponibles montrent que la vaccination par le BCG donne un degré élevé de protection contre les formes graves de la maladie (tuberculose méningée et miliaire).Selon les recommandations 2018 de l'OMS, dans les pays d'incidence élevée de tuberculose ou de lèpre, une dose unique de vaccin BCG doit être administrée à tous les nouveau-nés en bonne santé à la naissance.
Les pays à faible incidence de tuberculose ou de lèpre peuvent choisir de vacciner sélectivement les nouveau-nés au sein de groupes à risque.
Les pays dans lesquels les taux de tuberculose diminuent sont encouragés à passer d’une vaccination universelle à une vaccination sélective des groupes à risques.
Lors de ce passage, il est recommandé de mettre en place un système efficace de surveillance.En ce qui concerne d'autres pathologies infectieuses (comme la diphtérie, le tétanos, la poliomyélite, les oreillons, la rubéole ou la rougeole) le bénéfice de la vaccination ne fait aucun doute et les recommandations internationales maintiennent la vaccination systématique.Chercheurs à l'INED, Jacques Vallin et France Meslé précisent le bénéfice de la vaccination sur ces maladies :En 2005, les décès par pneumonie sont estimés à 2 millions d'enfants selon l'OMS.
Cela représente 18 % de la mortalité infantile totale annuelle.
L'OMS accueille favorablement le développement de vaccins efficaces pour prévenir les pneumococcies dont l'un des principaux agents sont les bactéries pneumocoques.
Selon une étude, un vaccin antipneumococcique conjugué peut réduire la mortalité et les hospitalisations pour pneumonie.Les deux principales maladies qui pourraient bénéficier d'une vaste campagne de vaccination sont la rougeole et l'hépatite virale B (chaque année, 112 000 décès pour la rougeole, 600 000 décès pour l'hépatite B).La mortalité liée à la grippe a fortement chuté depuis l'arrivée d'un vaccin plus efficace mélangeant diverse souches virales au début des années 1970 : en France, on comptait environ 1 000 morts en 2005, contre 10 000 à 20 000 (voire le double avec les complications) dans les années 1970.
En France, l'Assurance maladie prend en charge à 100 % le vaccin contre la grippe chez les personnes de plus de 65 ans (90 % des cas mortels) depuis 2003 (75 ans en 1985, date du début de la gratuité du vaccin pour cette partie de la population).Les résistances et l'opposition à la vaccination débutent dès le tournant des XVIIIe et XIXe siècles contre le vaccin d'Edward Jenner (1749-1823).
D'abord d'ordre religieux, l'opposition devient politique (défense de la liberté individuelle) lors de l'extension de l'obligation du vaccin anti-variolique au cours du XIXe siècle.
À partir de la fin du XIXe siècle, des raisons « naturelles » (de médecines alternatives) s'opposent au « pasteurisme » et à la multiplication de nouveaux vaccins (le vaccin comme inutile ou anti-naturel).Avec le consumérisme et la mondialisation des réseaux d'information, l'opposition vaccinale se manifeste entre autres, par la dénonciation de l'industrie pharmaceutique, la crainte et la polémique des effets indésirables, ainsi que par une tendance au complotisme (associant la vaccination à des volontés de profits ou de malfaisance).
Cependant, les grands arguments de fond de l'opposition ou de la résistance aux vaccins n'ont guère changé depuis le XIXe siècle ; ces arguments se perpétuent sous une forme plus moderne selon les progrès technologiques.En France, la défiance vaccinale est devenue la première au monde (45 % des Français interrogés estiment que les vaccins ne sont pas sûrs), elle est suivie par la Bosnie-Herzégovine, le Japon et la Russie « pays dont on ne voit pas immédiatement les points communs », alors que les Anglais et les Allemands ne sont que 10 %.
Cette proportion est de 13 % pour 65 000 citoyens interrogés de 67 pays.De même 20 % des Français interrogés estiment que les vaccins ne sont pas efficaces, ce qui les classe parmi les plus sceptiques avec les Italiens, les Grecs et les Russes, alors que les Anglais, les Allemands et les Américains du nord représentent 8 à 10 %, selon une vaste étude anglaise parue en 2016.La proportion de personnes opposée aux vaccinations tend à croître aux États-Unis mais reste marginale (moins de 3 % des parents aux États-Unis en 2004, avec une grande disparité régionale, cette proportion pouvant atteindre près de 20 % dans certains endroits).
Les croyances et les représentations individuelles jouent un rôle important dans la décision de se faire vacciner.
Il semble que la conviction des professionnels de santé sur l'importance de la vaccination joue un rôle important sur la perception du public à ce sujet.Les sites de vulgarisation médicale sont souvent visés via leurs forums (doctissimo, etc.).
Les activistes anti-vaccinalistes profitent de discussions pour aiguiller certaines personnes vers leurs sites web (nombreux liens hypertextes utilisés dans les signatures et se répétant sur tous leurs messages).
Un petit nombre d'activistes intervient alors dans les sections « vaccinations » de différents sites web d'informations anti-vaccinalistes, faisant alors penser aux utilisateurs que leurs références sont nombreuses et légitimes.Les réseaux sociaux sont aussi largement utilisés, ils permettent un accès large et un recrutement facile de profils.Les sites de partage en ligne sont également largement inondés de vidéo anti-vaccinalistes.
Cette technique permet de submerger les décideurs (les parents) d'informations négatives sur la vaccination, faisant passer les informations médicales validées au second rang.
Ainsi, la mise en avant des effets secondaires négatifs par les médias n'incitent pas les consommateurs à se faire vacciner.Ces discours anti-vaccinalistes sont de plusieurs types, correspondant à des niveaux différents de débats.
Le discours politique met en avant la liberté vaccinale (refus des obligations vaccinales), la corruption financière, et l'inutilité des vaccins mis en opposition avec les autres moyens de santé publique.
Ce discours rejoint des thèmes naturalistes de dénigrement de la science et de la médecine, de négation des progrès de santé attribuables à la vaccination, en matière de santé des dernières décennies, ou sur le caractère bénin des maladies infantiles d'où il découle qu'il est plus sûr, ou plus naturel, de les contracter que de faire vacciner.Un discours pseudo-scientifique liste des ingrédients potentiellement toxiques (en dénigrant/niant les études de sécurité réalisées) ; ou détourne les résultats des études scientifiques par un biais de confirmation (cherry picking) par exemple en mettant en exergue un article qui alerte sur un risque potentiel en niant les dizaines d'autres qui le démentent par la suite.Depuis la fin du XIXe siècle, les méthodes utilisées par l'antivaccinalisme sont le témoignage, les arguments basés sur photographies ou vidéo, sur l'émotion, le simplisme et le « bon sens » (coïncidence confondue avec la causalité).
Sur le net, une nouvelle forme de discours tactique est apparue qui consiste à se soustraire de l'étiquette « antivaccin » en se présentant comme un partisan de vaccins plus sûrs, seulement soucieux de questions légitimes, comme le fait que les vaccinations ne seraient pas suffisamment étudiées.Il y aurait ainsi des « antivax » radicaux (qui condamnent la vaccination) et des antivax « opportunistes » ou de circonstance qui refusent les recommandations vaccinales, à propos de tel ou tel vaccin, ou telle modalité, en arguant de leur liberté personnelle de choisir leurs risques.
Cette attitude individualiste s'oppose au principe de responsabilité collective.L'antivaccinisme se présente alors comme un discours irréfutable, inexpugnable dans sa logique interne.
Il révèle toutefois d'importantes problématiques sociales contemporaines comme les rapports individu/société, nature/culture, résistance/soumission au biopouvoir, les places respectives public/privé, les rapports à l'information…« Reste à savoir où et comment se règleront les questions d'autorité et de légitimité  Reste à trouver une gouvernance acceptable et efficace pour la vaccination du XXIe siècle ».
Le vaccin contre les infections invasives à Haemophilus influenzae de type b est un vaccin destiné à prévenir les infections dues à la bactérie Haemophilus influenzae de type b. L'efficacité du vaccin est importante et ses effets secondaires sont le plus souvent sans gravité.
Il fait partie en France des vaccins obligatoires chez le nourrisson.Haemophilus influenzae de type b est une bactérie responsable d'infections à types d'otites ou de surinfections bronchiques, et surtout de formes invasives telles que méningites, épiglottites, bactériémies, cellulites, arthrites, pneumonies et ethmoïdites.Le vaccin contre les infections invasives à Haemophilus influenzae de type b contient du polyribosyl-ribitol-phosphate, un polyoside spécifique de la capsule bactérienne, conjugué à des protéines.
En France, le vaccin disponible est conjugué à l'anatoxine tétanique ; il existe sous forme isolée ou sous forme combinée :Les vaccins doivent être administrés par voie intramusculaire.En France, la vaccination obligatoire du nourrisson consiste en 2 injections à 2 mois d'intervalle, aux âges de 2 et 4 mois, suivies d'un rappel à l'âge de 11 mois.En Belgique le vaccin est recommandé chez les nourrissons selon un schéma à 4 dose à 2, 3, 4 mois puis un rappel à 15 mois.L'efficacité du vaccin est de l'ordre de 100 %.À la suite de l'injection du vaccin contre les infections invasives à Haemophilus influenzae de type b, une douleur, une rougeur ou une tuméfaction du site d'injection survient dans 5 à 30 % des cas.
Une fièvre s'observe dans 5 % des cas.
De rares cas d'œdèmes des membres inférieurs ont également été rapportés.Le vaccin est contre-indiqué en cas d'hypersensibilité à l'un des composants.
Le choc anaphylactique est une réaction allergique exacerbée, entraînant dans la plupart des cas de graves conséquences et pouvant engager le pronostic vital.Il s'agit d'une manifestation d'hypersensibilité immédiate (type I) due à la libération de médiateurs vasoactifs chez un sujet au préalable sensibilisé.Le choc anaphylactique peut également être non allergique.Le néologisme « anaphylaxie »créé par Charles Richet en 1902, vient du grec ana (ανα) « en sens contraire », et phulaxis (φύλαξις) « protection ».
Le choc anaphylactique est la forme la plus grave d'anaphylaxie.En 1901, le prince Albert Ier de Monaco invite le professeur Charles Richet et le zoologiste Paul Portier (assistant du professeur Albert Dastre à la Sorbonne) à une expédition océanographique au Cap-Vert et aux Açores pour étudier la nature du poison contenu dans les physalies, redoutées des pêcheurs.
Au cours de campagnes précédentes, le prince avait noté les lésions sur les mains des pêcheurs de plus en plus douloureuses à mesure que se développaient les opérations de tri de pêche dans lesquelles figuraient ces cnidaires.
De retour au laboratoire de physiologie de la faculté de médecine de Paris, Richet et Portier établissent en 1902 le phénomène sur le plan expérimental en injectant des doses de toxique de physalie sur des chiens,,.
Charles Richet poursuivit ses travaux sur l'anaphylaxie de 1902 à 1911, pour lesquels il reçut le prix Nobel de physiologie ou médecine en 1913.Le choc anaphylactique se signale par les signes suivants (4 stades de gravité selon la classification de Ring et Messmer de 1977) :Lors d'un premier contact avec une substance étrangère à l'organisme (appelé allergène), le système immunitaire produit des anticorps IgE dirigés contre l'allergène.
Ces anticorps IgE sont sécrétés par des plasmocytes.
Libérés dans la circulation sanguine, ils vont se fixer sur les mastocytes ou les polynucléaires basophiles (globules blancs de la catégorie des granulocytes) via des récepteurs qui augmentent la durée de vie des IgE.Ce premier contact et cette production d'IgE n'entraîne pas à eux seuls de signes cliniques.
On parle alors de « sensibilisation ».Lors d'un deuxième contact avec l'allergène, son contact avec les anticorps IgE fixés sur la membrane des mastocytes et des polynucléaires basophiles va induire la dégranulation de ces derniers, entraînant la libération de médiateurs vasoactifs (tels que l'histamine, la sérotonine, des prostaglandines, des leucotriènes, des bradykinines…).
Si un nombre suffisant de médiateurs sont libérés, une réaction allergique a lieu.Cette deuxième rencontre de l'agent allergène n'entraîne pas nécessairement la réaction anaphylactique.
Le choc anaphylactique n'étant que le dernier stade (et le plus grave) de la réaction allergique.Dans le cas des chocs anaphylactiques, la réintroduction d'un allergène chez un sujet déjà sensibilisé, c'est-à-dire la libération de ces substances vasodilatatrices va induire une chute des résistances vasculaires périphériques (responsable d'une hypovolémie relative), une augmentation de la perméabilité des capillaires (responsable d'une hypovolémie absolue et d'œdèmes).
Ces mécanismes pathologiques vont être dans un premier temps compensés par l'augmentation du rythme cardiaque, empêchant dans un premier temps la chute de la pression artérielle.
Puis, les pressions de remplissage et le débit cardiaque vont chuter, entraînant le collapsus.Il existe un deuxième type de choc dit « anaphylactoïde ».
Dans ce cas, la libération des substances vasodilatatrices se fait sous l'action directe d'un toxique et non pas après contact allergène-anticorps.
C'est une réaction non IgE-dépendantes.Les symptômes les plus fréquemment retrouvés (isolés ou associés) sont :On retrouve aussi des vertiges, palpitations, frissons et une perte de conscience pouvant mener au coma.Parmi les allergènes les plus fréquents, on peut mentionner :Dans 20 à 30% des cas, le facteur déclenchant n'est pas identifié.Le choc anaphylactique est une urgence vitale.Le seul traitement du choc anaphylactique reste l'utilisation de l'adrénaline (épinéphrine) par voie intramusculaire, ou intraveineuse (pour les médecins spécialistes uniquement), à petites doses (0,30  à   0,50 mg par voie intramusculaire étant les doses les plus souvent recommandées).
L'administration sous-cutanée est proscrite car trop lente.
Une injection intraveineuse ne peut être effectuée qu'en présence d'un collapsus cardiovasculaire, de préférence par une équipe spécialisée; la solution d'adrénaline doit d'abord être diluée (1/10 000) et l'injection doit se faire lentement, de préférence sous surveillance cardiaque.
Pour les patients ne répondant pas à l'adrénaline ou pour les patients traités par des Béta-bloquant, l'injection de Glucagon est possible.Il existe aussi un auto-injecteur à base d'adrénaline pour administration intramusculaire, ce qui peut être utile par exemple pour les personnes qui savent qu'elles sont allergiques aux piqûres d'abeilles ou de guêpes.
Des instructions doivent toutefois leur être données en ce qui concerne la dose à utiliser, la manière de procéder, ainsi que sur les possibilités de désensibilisation.L'hypovolémie est compensée par un remplissage vasculaire, sont également utilisés des bronchodilatateurs (bêta 2-mimétiques de courte durée d'action en aérosols) pour lutter contre la bronchoconstriction.En cas de réactions œdémateuses associées, on utilise les corticoïdes.Plusieurs pays ont publié des recommandations, quant à la prise en charge, dont les États-Unis et la Grande-Bretagne.On retiendra surtout qu'en prévention d'une rechute, mieux vaut éviter tout contact avec l'agent allergène responsable (s'il a pu être identifié).On peut également utiliser les antihistaminiques ou la désensibilisation.Le sujet devra toujours porter sur lui une seringue d'adrénaline auto-injectable, dont l'apprentissage d'utilisation peut se faire auprès d'un allergologue ou d'un pharmacien.
L’odeur de verrat, ou odeur sexuelle, est une odeur forte, généralement jugée désagréable, dégagée pendant la cuisson de la viande de certains porcs mâles pubères.
Jusqu'à récemment, les éleveurs ne livraient aux abattoirs que peu de viande de verrat : pour des raisons de maniabilité des animaux dans les élevages, les porcs étaient castrés encore jeunes, avant que l'odeur sexuelle n'imprègne leur viande.
Depuis quelques années toutefois, des raisons économiques mais aussi éthiques incitent à l'élevage de porcs entiers, non castrés : l'odeur de verrat est devenue un problème commercial, économique et technique auquel différentes solutions sont proposées.
Cette odeur concerne entre 3 et 5 % des porcs mâles.L’odeur de verrat découle principalement d'une accumulation dans les tissus adipeux  d’androstérone et de scatol et dans une moindre mesure de molécules d'indole.
D'autres molécules, encore non identifiées, jouent probablement un rôle amplificateur dans la perception de ces odeurs indésirables.
Coproduite avec la testostérone par les testicules des porcs mâles à partir de la puberté, l'androstérone — de type  5a-androsténone — agit non pas comme une hormone mais comme une phéromone : elle attire la truie en rut et lui donne ainsi envie de s’accoupler.
Pour l'odorat humain, ce composé sent l'urine, la transpiration, l'ammoniac.
Le scatol est un produit de la dégradation par des bactéries des protéines (du tryptophane) dans l'intestin aussi bien des porcs mâles entiers, que des castrats et des femelles.
Son taux est néanmoins beaucoup plus élevé dans la viande des porcs entiers car les stéroïdes testiculaires inhibent en partie sa dégradation dans le foie.
Le scatol s’accumule donc peu à peu dans le gras des porcs mâles.
L'odeur de ce composé est identifiée par le nez humain comme celle de fèces, ou de naphtalène.Tous les porcs n’expriment pas cette odeur.
Ceux qui l'expriment le font à des âges et à des poids variables.Parmi les consommateurs dont l'odorat perçoit cette odeur, certains en sont moins incommodés que d'autres, voire pas du tout.
Pour une partie des consommateurs, sensibles à l'odeur de verrat, ce défaut de flaveur dans une viande cuite est toutefois rédhibitoire : pour eux, la viande est tout simplement immangeable.
Cependant, la perception de l'androsténone est génétiquement déterminée (les femmes y sont plus sensibles que les hommes et selon les pays, 20 à 40 % de la population serait anosmique), et d'autre part cette odeur de verrat n'apparaît que dans une proportion de 5 à 10 % des mâles non-castrés.
De plus, la transformation en produits charcutiers permet d'améliorer l'acceptabilité des viandes porteuses d'odeurs sexuelles.
En effet, le processus de transformation fait disparaître une partie de l'androsténone stockée dans les tissus gras (effet d'atténuation), tandis que le mélange avec des viandes indemnes dans une mêlée abaisse la concentration du produit obtenu (effet de dilution).
Enfin, le seuil d'acceptabilité de l'androsténone est supérieur dans les produits charcutiers à celui de la viande fraîche.En 1993 une directive  européenne sur la viande fraîche autorise la consommation de viande issue de mâles entiers si leur carcasse a pu être contrôlée par une méthode reconnue.
Le règlement (CE) n° 854/2004 du Parlement européen édicte que les viandes doivent être déclarées impropres à la consommation humaine lorsqu'elles présentent une odeur sexuelle prononcée.Les scientifiques de nombreux pays se sont donc penchés sur le problème, en explorant les pistes génétique, zootechnique (alimentation et âge à l'abattage), immunitaire et agroalimentaire.
En 2008 la Commission européenne lance un appel d'offres concernant une étude visant à accroître le bien-être animal et notamment à développer des alternatives à la castration ; cela aboutit au rapport final de l'Alcasde de 2009.
En France, un projet financé par l’Agence Nationale de la Recherche (programme Blanc ANDROPIG) s'intéresse également à ce domaine.Traditionnellement, la méthode employée pour éviter l'odeur de verrat est la castration chirurgicale des mâles dans leurs premières semaines de vie.
Chaque année dans l'Union européenne près de 80 % des porcelets mâles sont castrés, ce qui - en date de 2010 - représente environ 100 millions de bêtes.
La castration fragilise momentanément les animaux et les expose à un risque accru d'infection.
Mais surtout les mâles castrés présentent un moins bon taux de conversion alimentaire et une croissance moins rapide que les mâles entiers (les hormones sexuelles mâles sont anabolisantes)  leur viande par ailleurs est plus grasse.
Dans les Iles Britanniques, la castration a ainsi été abandonnée depuis 20-30 ans pour réduire le coût de l’alimentation des animaux ; en Espagne et en Grèce plus de 20 % des porcs ne sont pas castrés pour les mêmes raisons.Par ailleurs cette pratique est de plus en plus contestée, non seulement par les organisations de défense des animaux mais aussi par un large public du fait que cette opération est souvent pratiquée sans anesthésie ni analgésie.
La castration à vif des porcelets est reconnue comme étant une opération douloureuse, au moment de l’opération et au moins 4 jours après l’opération : «dans les heures qui suivent, détaille l'Inra (Institut national de la recherche agronomique), on constate une prostration, des tremblements et des spasmes chez les porcelets.
Leur souffrance dure plusieurs jours.»En 2008 une directive européenne vient imposer l'anesthésie par un vétérinaire à la suite des castrations qui seraient opérées après le septième jour de vie de l'animal.
Il est aujourd’hui reconnu que cette dérogation à l’obligation d’anesthésie n'a aucun fondement scientifique, le porcelet nouveau-né percevant  parfaitement la douleur, peut-être même davantage qu’un animal plus âgé.L'anesthésie peut être générale ou locale.Applicable dans la pratique, la castration chirurgicale avec anesthésie par inhalation a néanmoins un coût qui rend son adoption problématique par les plus petites exploitations.
L'anesthésie peut aussi poser un problème sanitaire du fait de la persistance de ses composants dans la viande.À l'automne 2010, un groupe de réflexion, mis en place par la Commission européenne, sous l'autorité de la Direction générale de la Santé et des consommateurs, fait des recommandations de principe sur la castration des porcs: à compter du 1er janvier 2012, la castration chirurgicale devra se faire, le cas échéant, avec analgésie et/ou anesthésie prolongée au moyen de méthodes mutuellement reconnues; dans un deuxième temps, la castration chirurgicale devra être abandonnée le 1er janvier 2018 au plus tard ("à la condition que soit mis en place un partenariat européen sur la castration des porcs pour la conduite des actions nécessaires à la concrétisation de cet objectif").
Certains acteurs de la filière porcine européenne ont signé ce texte, comme la Fédération vétérinaire européenne, l’INRA, Breiz Europe...
Dans le sillage de cette déclaration, la Commission Européenne arrête un programme de travail le 19 août 2011.La castration des porcelets mâles, largement pratiquée dans la plupart des pays Européens, est déjà interdite sans anesthésie en Norvège depuis 2002 et en Suisse depuis 2010.
Cette interdiction est également envisagée très sérieusement en Belgique et aux Pays-Bas,Les verrats produisent moins d'azote que les porcs castrés.Le département santé animale de la société Pfizer a développé un vaccin contre l'odeur de verrat, largement utilisé en Australie et en Nouvelle-Zélande depuis 1998.
Le principe de ce vaccin est d'induire une réponse immunitaire à la gonadolibérine, une neurohormone responsable du développement testiculaire.
Les individus vaccinés présentent donc une atrophie testiculaire partielle et de faibles concentrations en scatol et androsténone.
Malgré un lobbying très actif, ce vaccin ne fait pas l'unanimité.
Ainsi au Royaume-Uni, l'Assured Food Standards (AFS) agency a jusqu'ici refusé l'utilisation de ce vaccin et certains éleveurs demandent plus d'assurances quant à la totale innocuité du vaccin pour les consommateurs.
En France, l’inter-profession se pose la question de l'acceptabilité d'un tel procédé pour les consommateurs, étant donné le risque de confusion dans l'opinion publique entre cette vaccination et un traitement hormonal (avec en arrière-plan la mémoire collective des scandales du « poulet aux hormones »).
Elle évoque aussi le risque d'auto-injection pour l'opérateur.
La Commission européenne a délivré une autorisation de mise sur le marché valable dans toute l’Union européenne pour Improvac à Pfizer Limited, le 11 mai 2009.
L'Improvac contient un conservateur mercuriel, le thiomersal.C'est la solution adoptée par les Britanniques et les Irlandais.
En France les porcs sont abattus à l’âge de 6 mois environ, à 115-120 kg : à ce poids, un tiers des mâles non castrés développent l'« odeur de verrat ».Aux États-Unis, l’exploitation agricole Sugar Moutain Farm prône l'élevage des mâles entiers, et mise à la fois sur la sélection génétique d'animaux à faibles niveaux d'androsténone et sur l'alimentation pour limiter l'odeur de verrat.
L’un des avantages des verrats est que leur viande est plus maigre et leur croissance plus rapide d’environ 10 % que celle des porcs castrés et des cochettes ; il y a donc une meilleure efficacité de la conversion alimentaire.La limite de cette solution pourrait être une fertilité moindre des espèces ainsi sélectionnées.Des mesures visant le logement, l’alimentation et la sélection peuvent réduire de manière importante l'odeur de verrat.L'alimentation et les conditions de stabulation permettent d'agir sur la concentration de scatol.
Ainsi selon l'Office Vétérinaire Fédéral Helvétique (OVF) : « le problème lié à cette substance peut être négligé ».L’odeur de verrat peut être réduite lorsque les animaux ne se vautrent pas dans leurs déjections (comportement qui a une fonction de  thermorégulation) : la loi danoise stipule que les porcs de plus de 20 kg doivent avoir accès à une douche, ou à un autre mode de thermorégulation.Bien que les scientifiques ne soient pas d'accord sur les causes de la présence de tryptophane dans le tractus digestif que certains attribuent à la seule dégradation de débris cellulaires tandis que d'autres mettent en avant des causes alimentaires, des modifications du régime alimentaire (adjonction d’amidon ou de chicorée) ont montré qu'il était possible de réduire la présence de tryptophane et ainsi d'améliorer la qualité de la viande.En raison du lien entre le stress et les fonctions digestives, d'autres modifications comme la composition sociale des groupes d'animaux (suivant leur âge, leur sexe), la surface allouée à chaque individu, peuvent améliorer la qualité de la viande.
En élevage intensif il peut être intéressant de séparer les mâles des cochettes afin de retarder la puberté qui accroît l'odeur de verrat.Dans l'hypothèse où la castration des porcs mâles serait abandonnée, il faudrait être en mesure de trier les carcasses présentant des odeurs sexuelles sur la chaîne d'abattage pour les orienter vers un circuit de transformation adapté.
Or pour l'instant, les méthodes existantes (dosage automatisé du scatol, test olfactif par chauffage du tissu gras, nez électronique) sont soit inadaptées aux cadences, soit insuffisamment fiables pour garantir l’absence de viande porteuse d'odeur de verrat en aval de la chaîne de transformation.
Les recherches concernant le nez électronique sont particulièrement poussées en Norvège ainsi qu'en Suisse.Les Norvégiens ont un projet de recherche avec des abeilles (Apis mellifera) ou des guêpes (Microplitis croceipes) : elles sont  capables de détecter l’odeur.En 2009, il n'y avait pas encore de méthode reconnue au niveau européen pour détecter l'odeur de verrat.Limiter l’élevage à celui des individus femelles, en l'espèce des truies, grâce au tri des spermatozoïdes pourrait être une solution : réalisée au niveau expérimental, cette technique n'a pas encore - en date de 2007 - trouvé à s'appliquer au niveau des élevages porcins (mais elle est déjà mise en œuvre en élevage bovin pour d'autres raisons).
La contamination (du latin contaminatio « souillure »), appelée aussi bio-contamination, est le terme utilisé dans le domaine de la toxicologie ou de l'écotoxicologie pour désigner l'envahissement d'un organisme vivant, d'un écosystème ou d'un compartiment de l'écosystème (ex.
: sol, sédiment) par des micro-organismes pathogènes.
Par extension, cette contamination comprend la pénétration de substances toxiques ou indésirables.Dans le domaine alimentaire, il s'agit de l'introduction ou présence d'un contaminant dans un aliment ou dans un environnement alimentaire.
Contaminer,  c'est donc, selon le cas :Dans son projet de Directive cadre Stratégie pour le milieu marin, l'UE distingue :la contamination toxique ; avec par exemple : la contamination non toxique, avec par exemple :Se dit en biologie moléculaire, quand un échantillon en contamine d'autres.Dans tous les cas un facteur de risque important est la biodisponibilité du contaminant qui peut fortemnet changer selon la température, le PH ou la teneur en eau du milieu et donc évoluer dans le temps et l'espace
Une situation d’oligopole se rencontre lorsqu'il y a, sur un marché, un nombre faible d'offreurs (vendeurs) disposant d'un certain pouvoir de marché et un nombre important de demandeurs (clients).
On parle aussi de situation de marché oligopolistique.Il s'agit d'une situation de marché imparfait : dans le cadre de la concurrence pure et parfaite, le profit de chaque producteur ne dépend pas de l'attitude des autres offreurs, les agents économiques concernés sont des « Price Takers » (Preneurs de prix) dû au principe de l'atomicité.
En revanche, lorsque c'est un contexte d'un marché imparfait, ceci n'est pas applicable car les gains ou le profit réalisé par les offreurs dépendent fortement de l'attitude des autres.Il existe dans ce cas une interaction stratégique entre les firmes : les actions entreprises par une firme donnée (choix deprix, de quantité, de budget publicitaire, etc.) ont un impact sur le profit de ses concurrents.
Ainsi, si une entreprise produit une unité supplémentaire, le prix de marché doit baisser, ce qui crée une externalité (négative) sur toutes les autres entreprises.
Dans ce contexte, la meilleure stratégie d’une entreprise dépend des stratégies choisies par ses concurrents.L’une des raisons de l’existence d’un marché oligopolistique est due au fait que la sélection de la firme peut conduire spontanément à une configuration de monopole ; on parle de « monopole naturel ».Lorsque les rendements sont constants ou croissants, les producteurs sont rationnellement incités à grossir afin de réaliser des économies d'échelle, ce qui tend à la concentration, et l'équilibre d'un tel système est une situation de monopole où il ne reste plus qu'un producteur.
Néanmoins, dans le but de protéger le consommateur des abus, les institutions politiques s'opposent à la constitution de monopoles.
Ces marchés tendent vers un équilibre oligopolistique.Une fois cet équilibre atteint, les producteurs peuvent se livrer une concurrence féroce (cas d'Intel et AMD sur le marché des microprocesseurs), mais peuvent aussi s'entendre de manière plus ou moins formelle et constituer un cartel.
De même qu'elles interdisent l'abus de position dominante, les institutions politiques s'opposent aux ententes abusives.
Par exemple en France, il existe quatre sociétés (offreurs) qui proposent des services de téléphonie mobile à des millions de demandeurs (clients).
La concurrence devenant quasi inexistante entre les opérateurs, l'État français est intervenu afin d'obliger les offreurs à réviser le coût des SMS (Short Message Service) qui étaient facturés six à huit fois leur prix de revient (NB : aujourd'hui, le marché des opérateurs télécoms a été ouvert à la concurrence).Le cas d'oligopole le plus simple est un duopole, où il y a deux producteurs.Certains secteurs d'activité sont des secteurs « oligopolistiques » : les rendements d'échelle sont tellement grands qu'il est plus rentable pour l'économie que le nombre d'acteurs soit limité (voir aussi monopole naturel).Aucun duopole ou oligopole n'est parfait, mais quelques cas de figure s'y apparentent en 2008, dont :Les stratégies envisagées par les entreprises oligopolistiques sont nombreuses.
En fixant le prix et en général la politique de vente, il faut tenir compte de la réaction de tous les concurrents.
Plusieurs modèles ont été proposés pour analyser ces cas.
On peut généraliser les modèles de Cournot ou de Stackelberg à un nombre arbitraire d’entreprises.D’autres modèles sont les barrières à l’entrée, la demande coudée, le modèle de Chamberlin, le prix limite, la différenciation des produits ou la collusion implicite.
Les cartels et autres ententes illicites existent aussi même si elles sont bannies par les autorités de la concurrence.
Human immunodeficiency virus 1Le virus de l'immunodéficience humaine ou VIH-1, (en anglais, human immunodeficiency viruses-1 ou HIV-1) est une espèce de rétrovirus infectant l'humain et responsable du syndrome d'immunodéficience acquise (sida), qui est un état affaibli du système immunitaire le rendant vulnérable à de multiples infections opportunistes.La transmission du vih par plusieurs fluides corporels (sang, sécrétions vaginales, sperme ou lait maternel) fait que le sida est aujourd'hui considéré comme une pandémie ayant causé la mort d'environ 32 millions de personnes entre 1981 (date de la première identification de cas de sida) et  2018.Bien qu'il existe des traitements antirétroviraux luttant contre le VIH et retardant par conséquent l'apparition du sida, réduisant ainsi la mortalité et la morbidité, il n'existe à l'heure actuelle aucun vaccin ou traitement définitif.
Le moyen de lutte le plus efficace reste donc la prévention, qui passe notamment par les rapports sexuels protégés et la connaissance de son statut sérologique de manière à éviter d'infecter autrui.Les débuts de l'épidémie de sida datent du 5 juin 1981, quand le CDC américain annonce une recrudescence, dans les villes de Los Angeles, San Francisco et New York, de cas de pneumonies à Pneumocystis carinii et de sarcomes de Kaposi (travaux de Linda Laubenstein notamment),.
Ces deux maladies ont pour particularité d'affecter les personnes immunodéprimées.
Il est justement remarqué que, chez ces patients, le taux de lymphocytes T4 est en chute libre.
Ces cellules jouent un rôle essentiel dans le système immunitaire.
Les premiers malades sont tous homosexuels, ce qui fait que ce syndrome, qui ne portait pas encore le nom de sida, est provisoirement appelé le syndrome gay ou cancer gay.
Une des premières causes suggérées de cette immunodépression est le poppers, un vasodilatateur très utilisé chez les homosexuels.
Mais, dans les mois qui suivent, d'autres personnes sont infectées, des toxicomanes par injections, des hémophiles et des Haïtiens.
Cette découverte révèle que le poppers n'est pas la cause, et une origine infectieuse est de plus en plus admise.
Il reste alors à trouver l'agent infectieux.L'origine virale est privilégiée, eu égard aux modes de transmission alors identifiés (sanguin et sexuel).
Plusieurs virus sont mis en cause, mais on s'aperçoit qu'ils ne sont qu'une conséquence.
Robert Gallo et son équipe, qui ont découvert le premier rétrovirus humain, le HTLV-1, pensent qu'un mutant de ce dernier est la cause du sida.
Il explique cela par le fait que le HTLV-1 fait proliférer les lymphocytes T4, cet agent infectieux faisant l'inverse, une mutation peut donc en être la cause.
Cette hypothèse est renforcée par le fait que certains des cas haïtiens sont positifs à un test de dépistage du HTLV-1.
Cette positivité se révèlera être causée par un biais, le HTLV-1 étant très présent à Haïti.À partir de 1982, avec les premiers cas identifiés en France, la recherche française débute.
Willy Rozenbaum, médecin à l'hôpital Bichat de Paris, veut inciter les chercheurs à étudier plus en avant le sida et à en trouver la cause.
Par l'entremise de Françoise Brun-Vézinet, une collègue médecin, Willy Rozenbaum contacte Jean-Claude Chermann, Françoise Barré-Sinoussi et Luc Montagnier, de l'unité d'oncologie virale de l'Institut Pasteur, qui avaient les outils pour étudier les rétrovirus.
Ces derniers acceptent de commencer les recherches.En 1983, Robert Gallo n'est pas parvenu à isoler le virus dans les échantillons sanguins de patients atteints du sida.
Willy Rozenbaum pense alors que chez les malades du sida, la plupart des cellules infectées sont détruites et que c'est la raison du manque de résultats dans ces tentatives d'isolement du virus.
Il a alors l'idée de chercher le virus dans un organe riche en lymphocytes, les ganglions lymphatiques de personnes malades mais qui ne sont pas encore en phase de sida.
En janvier 1983, Willy Rozenbaum prélève un échantillon d'un patient atteint d'une lymphadénopathie, pathologie identifiée comme une maladie opportuniste du stade pré-sida.
L'échantillon est mis en culture et Françoise Barré-Sinoussi découvre une activité de transcriptase inverse, confirmant la présence d'un rétrovirus.
Une apoptose apparaît et l'adjonction de globules blancs à la mise en culture relance alors l'activité de transcriptase inverse.
Un examen au microscope électronique a permis de visualiser, pour la première fois, le virus, le 4 février 1983.Après une prise de contact avec Robert Gallo, pour un échange d'informations, l'équipe de l'Institut Pasteur confirme que le virus identifié chez le patient lymphadénopathique n'est pas le HTLV-1.
Ce nouveau rétrovirus est alors appelé Lymphadenopathy Associated Virus (LAV) et les résultats sont publiés dans Science le 20 mai 1983.
À ce stade, le lien entre le LAV et le sida n'est pas clairement établi par l'équipe de Luc Montagnier.
Luc Montagnier et David Klatzmann découvrent que ce virus détruit les lymphocytes T4 (LT4) avec lesquels il est mis en culture.
On savait que le nombre de LT4 diminuait beaucoup chez les malades atteints de sida.
Le LAV était donc sûrement l'agent provoquant le sida.L'équipe de Robert Gallo publie le 4 mai 1984, dans Science, les résultats de l'isolement d'un virus qu'elle considère comme responsable du sida et le nomme HTLV-3, qui s'avérera, bien plus tard, provenir d'un échantillon envoyé par l'Institut Pasteur.
L'équipe de Jay A. Levy à San Francisco fait de même le 24 août 1984 et trouve plusieurs rétrovirus, qu'elle nomme AIDS-associated retroviruses (ARV).Pendant un temps, les trois dénominations HTLV-3, LAV et ARV cohabiteront.
En 1986, le sigle VIH (ou HIV) est choisi.L’équipe de l’Institut Pasteur et celle de Robert Gallo ont d’abord volontiers échangé réflexions, informations et matériels biologiques : l’urgence des enjeux sanitaires, des considérations stratégiques de part et d’autre, et des relations personnelles y avaient d’abord concouru.
Divers comportements de l’équipe américaine commencent par étonner les Français, puis finissent par éroder leur confiance qui pâtit beaucoup de la conférence de presse organisée par le HHS le 23 avril 1984 quand la secrétaire américaine à la Santé Margaret Heckler affirma que Robert Gallo avait découvert le virus du sida.
C’est à l’occasion de cette même conférence que les Américains annoncèrent la prochaine distribution d’un test de diagnostic pour lesquels Gallo et le HHS avaient déposé une demande d’enregistrement juste quelques heures auparavant.
Or l’Institut Pasteur avait déposé une demande de brevet de test de dépistage devant le Bureau américain des brevets le 5 décembre 1983.
Cette demande s’était heurtée à un premier refus pour des raisons administratives.
Tandis qu’une deuxième demande se voit refusée, la demande de Gallo et du HHS est acceptée en mai 1985.
C’est ce traitement inégal concernant les brevets qui conduira l’Institut Pasteur à engager quatre actions en justice.
La polémique scientifique concernant la priorité des découvertes, qui faute d’éléments définitivement concluants à l’époque, ne faisait que commencer, allait trouver dans ces actions judiciaires un écho tout autant qu’un point d’appui : l’enjeu financier considérable représenté par les royalties dues sur la vente des tests sera une des clefs de cette controverse.
La presse généraliste, surtout américaine, interviendra plutôt dans un deuxième temps pour relancer la controverse, en n’hésitant pas à soulever des soupçons de fraudes scientifiques à l’encontre de Robert Gallo et d’un de ses collègues,.L’Institut Pasteur porte d’abord plainte contre le NIH le 13 décembre 1985 car il pense que la souche utilisée pour mettre au point le test VIH américain a été conçue à partir de la souche envoyée par Montagnier à Gallo.
L’Institut Pasteur demande au tribunal de reconnaître que le National Cancer Institute, où travaille Gallo, a violé un contrat en faisant une utilisation commerciale du virus Lav qui leur avait été pourtant transmis à seule fin d’étude.
Pasteur demandait également au tribunal d’affirmer la priorité de leur découverte du virus du sida et de les déclarer seuls bénéficiaires des royalties sur les tests de dépistage développés à partir de celui-ci.
L’Institut Pasteur perd en première instance pour des raisons formelles qui seront invalidées en appel en mars 1987 quelques jours seulement avant un compromis dont le premier effet est de mettre un terme aux différentes actions judiciaires entreprises — le procès auprès de l’United States Court of Claims principalement, mais aussi les actions auprès de l’office américain des brevets (USPTO) ou au titre de la FOIA.
Le différend ne se règle donc pas par une décision de justice mais par un compromis entre les parties (« out of court agreement »), paraphé solennellement le 31 mars 1987, lors d’une rencontre entre le président des États-Unis, Ronald Reagan, et le Premier ministre français de l’époque, Jacques Chirac.
L’accord n’est toutefois définitivement signé que le 4 décembre 1987 : la question de la priorité est résolue en qualifiant Gallo et Montagnier de « co-découvreurs » du virus du sida ; les Français renoncent aux redevances déjà encaissées par leurs adversaires américains ; les redevances associées sont partagées entre les instituts américains alors que, en Europe, elles reviennent intégralement à l’Institut Pasteur.
Les deux parties se sont en outre mises d’accord sur une chronologie des découvertes, Gallo et Montagnier s’engageant à ne publier aucune déclaration qui contredirait ce canon.Le 19 novembre 1989 dans le Chicago Tribune, John M. Crewdson signe un très long article intitulé The Great AIDS Quest-science under the microscope : Robert Gallo y est, au mieux, accusé d’avoir fait une erreur en contaminant sa souche avec celle de l’Institut Pasteur et, au pire, d’être coupable de fraude scientifique.
Par la suite, différents articles de Crewdson ou d’autres personnes suivent, relançant la controverse, ce qui conduit les autorités américaines à diligenter plusieurs enquêtes administratives, tandis qu’une commission parlementaire menée par le démocrate John Dingell lancera aussi des investigations poussées.
Dans une lettre publiée le 30 mai 1991 dans la revue Nature, Gallo reconnaît — de façon alambiquée — que la souche utilisée par les NIH a été contaminée par celle de l’Institut Pasteur ; il dément toute fraude scientifique,.
Au cours de l’été 1991, un rapport préliminaire de l’OSI disculpe Gallo de toute accusation de mauvaise conduite tout en le critiquant pour avoir censuré certains articles ; l’OSI se montre plus sévère à l’égard de Mikulas Popovic, qui, refusant le rôle de bouc émissaire, révèlera en septembre 1991 que le professeur Gallo lui aurait demandé de ne pas faire référence au virus envoyé quelques mois plus tôt par l’Institut Pasteur.
En janvier 1992, l’OSI, dans son rapport final, reconnaît Popovic coupable de mauvaise conduite scientifique (sans pour autant l’exclure des NIH) mais acquitte Gallo au bénéfice du doute.
Le rapport est contesté par une commission d’évaluation.
Le 10 février 1992, le Chicago Tribune confirme les « falsifications » américaines sur la découverte du virus du sida.
Le 17 juillet 1992, les États-Unis rejettent la demande française de renégociation de l’accord de mars 1987.
L’arrivée à la présidence des États-Unis de Bill Clinton va infléchir le cours de la controverse : la directrice du NIH est remplacée (par le docteur Harold Varmus), l'enquête de l’ORI débloquée et les négociations pour une réévaluation des royalties sur les tests reprises.
En décembre 1992, le professeur Gallo, disculpé de toute accusation de vol, est reconnu coupable — par le Bureau de l'intégrité de la recherche (ORI) du ministère de la Santé — de « mauvaise conduite scientifique » pour avoir omis de créditer les apports de l’équipe de Montagnier dans ses propres travaux.
Gallo fit ensuite appel de cette décision.
En novembre 1993, l’ORI choisit d’abandonner l’enquête avant même que Gallo ait été entendu par le bureau d’appel : Popovic ayant été disculpé de toute faute quelque temps auparavant par le bureau d’appel, l’ORI — comme tous les observateurs — anticipa qu’il en serait de même pour Gallo,.En janvier 1994 l’Inspecteur Général du HHS préconise que Gallo soit poursuivi — au pénal — par le procureur des États-Unis de l’État du Maryland qui refuse de se saisir de l’affaire.Finalement, et à la suite notamment d'un Investigative Memorandum de l’inspecteur général June Gibbs Brown daté du 6/10 juin, des institutions fédérales américaines reconnaissent, le 11 juillet 1994, que la découverte du VIH est purement française et que Robert Gallo est coupable de fraude scientifique.
Ce même 11 juillet, le conseil d’administration de la Fondation franco-américaine (créée par l’accord de mars 1987) reconnaît la priorité des chercheurs français et institue une répartition des redevances plus favorable à l’Institut Pasteur.
En octobre 2010 cette affaire connaît un nouvel épisode mineur opposant l’Institut Pasteur aux laboratoires Abbott.
La reconnaissance de cette paternité est confirmée en 2008 par le Comité Nobel, lorsqu’il attribue le Prix Nobel de Médecine à Luc Montagnier et Françoise Barré-Sinoussi, sans mentionner les travaux de Robert Gallo sur le sujet.
Lors d’un entretien, peu de temps après l’attribution des Nobel, Robert Gallo se déclare « déçu » de ne pas être également honoré, mais considère que tous les récipiendaires méritent ce prix.À côté de la controverse, la recherche continue et le LAV est étudié sous tous les aspects : plusieurs points sont alors démontrés, comme le fait qu'il est totalement différent du HTLV-1 ― oncovirus poussant les lymphocytes T à se multiplier, alors que le LAV les tue.
Avec la coopération du CDC, l'équipe de l'Institut Pasteur renforce de plus en plus l'hypothèse que le VIH est la cause du sida, ce qui est depuis considéré comme un fait avéré par la communauté scientifique.
En janvier 1985, le séquençage du LAV est réalisé par une équipe de l'Institut Pasteur, qui publie ses résultats dans Cell.
C'est cette même année qu'a été confirmée l'identité commune entre les trois virus LAV, HTLV-3 et ARV.Le 18 juillet 1986, les résultats de l'étude d'un patient venant d'Afrique de l'Ouest sont publiés, dans Science, par l'équipe de Luc Montagnier, en collaboration avec des médecins portugais.
Les examens ont permis d'identifier un nouveau type de LAV, le LAV-2.
Le séquençage du nouveau virus est réalisé l'année suivante, ainsi que la mise au point d'un test de dépistage.En 1986, le LAV (ainsi que les autres dénominations) est officiellement renommé en virus de l'immunodéficience humaine (VIH), le LAV-1 devient le VIH-1, et le LAV-2, le VIH-2.La communauté internationale prend conscience de la gravité de l'épidémie qui se transforme rapidement en pandémie et c'est ainsi que, le 26 octobre 1987, l'Assemblée générale des Nations unies vote une résolution invitant tous les États et toutes les agences onusiennes à coopérer pour lutter contre cette pandémie.
Depuis, la lutte contre le VIH/sida est devenue une priorité pour l'ONU à travers son programme Onusida, ainsi que pour nombre de gouvernements.
La communauté scientifique est également très active en vue de mettre au point un vaccin, faisant du VIH le virus le plus étudié à ce jour.Bien que l'AZT ait été utilisée dès 1986 pour lutter contre le VIH, il faudra attendre le milieu des années 1990 pour qu'arrivent sur le marché des traitements vraiment efficaces contre la réplication du VIH.
Ces traitements, appelés trithérapies, combinent plusieurs médicaments pour combattre le VIH sur plusieurs fronts à la fois.
Le développement de tests biologiques permettant d'estimer la charge virale a grandement participé à l'efficacité de ces traitements, aboutissant à modifier en conséquence la trithérapie, pour la rendre la plus efficace possible.Le VIH est un rétrovirus du genre des lentivirus (du latin lentus « lent »), qui se caractérisent par une longue période d'incubation avec, par conséquent, une évolution lente de la maladie.Le VIH-1 est un virus sphérique d'un diamètre moyen de 145 nanomètres.
Comme de nombreux virus infectant les animaux, il dispose d'une enveloppe composée d'un fragment de la membrane de la cellule infectée.
Dans cette enveloppe lipidique sont insérés des trimères de glycoprotéine d’enveloppe (Env).
Chaque protéine Env est formée de 2 sous-unités : une sous-unité de surface gp120 et une sous-unité transmembranaire gp41.
La surface d’un virus VIH contiendrait en moyenne seulement 14 trimères Env.
Lors de l'attachement du virus à la cellule, la protéine Env gp120 se lie à un récepteur CD4 présent à la surface des cellules CD4+ du système immunitaire.
C'est pour cette raison que le VIH n'infecte que des cellules ayant ce récepteur à leur surface, qui sont en très grande majorité les lymphocytes CD4+.À l'intérieur de l'enveloppe, se trouve une matrice protéique (MA) composée de protéines p17 et, encore à l'intérieur, la capside (CA) composée de protéines p24.
C'est ce dernier type de protéines qui, avec gp41 et gp120, sont utilisés dans les tests VIH western blot.
Les protéines nucléocapside p7 (NC) protègent l'ARN viral en le recouvrant.
La protéine p6 est exclue de la capside et se trouve entre la matrice et la capside, elle permet la sortie par bourgeonnement des virus nouvellement formés dans la cellule.Le génome du VIH, contenu dans la capside, est constitué d'un simple brin d'ARN en double exemplaire (9181 nucléotides), accompagné d'enzymes :Ces trois enzymes sont les principales cibles des traitements antirétroviraux, car elles sont spécifiques aux rétrovirus.Le génome du VIH est composé de neuf gènes.
Les trois principaux sont gag, pol et env, qui définissent la structure du virus et sont communs à tous les rétrovirus.
Les six autres gènes sont tat, rev, nef, vif, vpr et vpu (ou vpx pour le VIH-2), qui codent des protéines régulatrices.Le VIH est présent dans de nombreux fluides organiques.
On en a retrouvé dans la salive, les larmes et l'urine, mais en des concentrations insuffisantes pour que des cas de transmission soient enregistrés.
La transmission par ces fluides est considérée de ce fait comme négligeable.
En revanche des quantités de VIH suffisamment importantes pour déclencher une infection ont été détectées dans le sang, le lait maternel, la cyprine, le sperme, ainsi que le liquide précédant l'éjaculation et la concentration du virus dans les sécrétions génitales (sperme et sécrétions au niveau du col de l’utérus chez la femme) sont de bons prédicteurs du risque de transmission du VIH à une autre personne.Par voie de conséquence, les trois modes de contaminations sont :Les cellules cibles du VIH sont celles présentant des récepteurs CD4 à leur surface.
Ainsi, les lymphocytes T CD4+, les macrophages, les cellules dendritiques et les cellules microgliales cérébrales peuvent être infectées par le VIH.
Ainsi, la réplication virale a lieu dans plusieurs tissus.La réplication du virus se déroule en plusieurs étapes :Cette étape repose sur une reconnaissance entre les protéines de la surface virale gp120 et les récepteurs CD4 de la cellule cible.
Après l'union avec un récepteur CD4, gp120 change de conformation et est attiré vers un corécepteur devant également être présent à côté de la molécule CD4.
Plus d'une dizaine de corécepteurs ont été identifiés, mais les principaux sont CXCR4 pour les lymphocytes T CD4+ et CCR5 pour les macrophages.C'est la seconde étape de l'infection, intervenant juste après l'union de gp120 avec le corécepteur.
Cette union libère la protéine gp41, qui se fixe sur la membrane cytoplasmique.
Par repli sur elle-même, gp41 attire l'enveloppe virale vers la membrane cytoplasmique, puis la fusion des membranes cellulaire et virale a lieu grâce à un peptide de fusion présent dans gp41.
La capside du VIH pénètre alors dans le cytoplasme de la cellule ; une fois à l'intérieur de la cellule, elle se désagrège, libérant les deux brins d'ARN et les enzymes qu'elle contenait.Ainsi, la protéine gp120 est responsable de l'attachement et gp41 de la fusion, puis de la pénétration au sein de la cellule.Cette étape est spécifique aux rétrovirus.
En effet, ces derniers ayant pour génome de l'ARN et non de l'ADN, une opération de transcription inverse (ou rétrotranscription) intervient afin de convertir l'ARN viral en une molécule d'ADN en double hélice, seule structure compatible avec celle de l'ADN cellulaire dans lequel le génome viral doit être intégré pour assurer la réplication du virus.
Cette transcription inverse est réalisée par une enzyme virale : la transcriptase inverse, une ADN polymérase ARN-dépendante associée à l'ARN viral dans la nucléocapside.
Après pénétration de la capside dans le cytoplasme, la transcriptase inverse parcourt l'ARN viral et le transcrit en une première molécule d'ADN simple-chaîne, ou ADN brin(-).
Pendant cette synthèse, l'ARN matrice est dégradé par une activité ribonucléase H portée par la transcriptase inverse.
La dégradation de l'ARN est totale, sauf pour deux courtes séquences riches en purines appelées séquences PPT (polypurine tracts).
Ces deux courtes séquences vont servir d'amorces à la transcriptase inverse pour la synthèse du second brin d'ADN, le brin(+), en utilisant l'ADN brin(-) comme matrice.
L'ADN final produit est ainsi une molécule en double hélice (ADN bicaténaire aussi appelé ADN double-brin).
Ce processus de transcription inverse est complexe, et requiert la présence des protéines de nucleocapside fixées sur l'ARN viral puis sur l'ADN brin(-).
Une particularité de la transcriptase inverse est de ne pas être fidèle dans sa transcription et de souvent faire des erreurs.
C'est la raison pour laquelle le VIH a une très grande variabilité génétique.L'ADN bicaténaire pénètre dans le noyau cellulaire, selon un processus actif encore mal compris.
Cet import nucléaire constitue une particularité propre aux lentivirus qui sont, de fait, capables d'infecter des cellules en phase stationnaire, c'est-à-dire dont le noyau est intact.
Pour ce faire, l'ADN bicaténaire est, à ce moment du cycle, étroitement associé à l'intégrase et d'autres composants protéiques viraux et cellulaires, dans un complexe appelé complexe de préintégration.
Ce complexe possède la capacité d'interagir avec des éléments de la membrane nucléaire, pour traverser cette membrane et accéder à la chromatine cellulaire.
L'ADN s'intègre ensuite au hasard dans le génome de la cellule cible, sous l'effet de l'enzyme intégrase.Les deux brins d'ADN de la cellule « s'écartent » localement sous l'effet de l'ARN polymérase.
Des bases azotées libres du noyau viennent prendre la complémentarité de la séquence et se polymérisent en une chaîne monobrin, l'ARNm (messager).L'ARNm ainsi obtenu est hétérogène.
En effet, il est constitué d'une succession d'introns (parties non codantes) et d'exons (parties codantes).
Cet ARNm doit subir une maturation pour pouvoir être lu par les ribosomes.
Se passe alors une excision des introns, pour ne laisser que les exons.Une fois sorti du noyau par l'un des pores nucléaires, l'ARNm est lu par les ribosomes du RER (réticulum endoplasmique rugueux).
L'ARNm vient en fait se glisser entre les deux sous-unités du ribosome.
À chaque codon (groupe de trois nucléotides) de l'ARNm, le ribosome attribue un acide aminé.
Les différents acides aminés se polymérisent au fur et à mesure de la lecture.
Un codon initiateur AUG (Adénine-Uracile-Guanine) fera débuter la synthèse, tandis qu'un codon stop (UAA ; UGA ; UAG) en marquera la fin.Les polypeptides ainsi formés ne sont pas encore opérationnels, ils doivent subir une maturation dans l'appareil de Golgi.Les protéines de structure du virus (matrice, capside et nucléocapside) sont produites sous forme de polyprotéines dénommées polyprécurseurs Gag.
Les enzymes virales sont produites elles aussi sous forme de polyprotéines appelées Gag-Pol (Matrice-Capside-Nucléocapside-Protéase-Reverse Transcriptase - Intégrase).
Lorsqu'elles sortent du Golgi, les polyprotéines Gag et Gag-Pol sont transportées vers la membrane cellulaire où elles rejoignent les glycoprotéines virales membranaires.
Les domaines MA (matrice) de Gag et Gag-Pol interagissent avec la membrane, tandis que les ARN viraux sont capturés par les domaines NC (nucléocapside) de Gag et Gag-Pol.
Des interactions entre les différents domaines de Gag, en particulier les capsides, permettent l'assemblage d'une structure globulaire conduisant à la formation d'une particule virale par bourgeonnement de la membrane plasmique.La capside sort de la cellule infectée en arrachant une partie de la membrane cellulaire (à laquelle ont été préalablement fixées les protéines virales de surface (gp120 et gp41)).Les particules issues du bourgeonnement sont dites immatures.
Les interactions des précurseurs Gag et Gag-Pol entraînent un rapprochement de domaines (PR) dentiques de la protéase, qui vont dimériser et former une protéase active.
Cette autoactivation de la protéase va entraîner la coupure des domaines PR aux alentours, et cette réaction en chaîne va permettre l'activation de toutes les protéases virales.
Ces dernières vont ensuite couper les polyprécurseurs Gag et Gag-Pol entre chacun de leurs domaines.
Ceci va libérer la Matrice de la Capside et de la Nucléocapside, cette dernière restant fixée sur l'ARN viral.
Les protéines de capside, par leurs propriétés intrinsèques d'auto-assemblage, formeront la capside à la forme conique caractéristique.
Dans cette capside : la nucléocapside, formée de l'ARN viral, des protéines de nucléocapside, de la transcriptase inverse et de l'intégrase.
Cette étape de maturation virale est essentielle pour rendre les virions infectieux et prêts à infecter de nouvelles cellules.L'arbre phylogénétique du VIH est le suivant :Le VIH est un virus qui a une très importante variabilité génétique et présente ainsi une extrême diversité.
Deux types ont été identifiés :Au sein de chaque type existent plusieurs groupes qui, à leur tour, comportent des sous-types.Depuis 1998, le VIH-1 est classé en trois groupes auquel s'ajoute un quatrième découvert en 2009 :Les types M et N du VIH-1 sont proches du VIScpz infectant le chimpanzé et correspondraient chacun à une transmission indépendante du chimpanzé à l'humain.
Les types O et P du VIH-1 sont proches du VIS infectant le gorille (VISgor).Le groupe M prédomine largement avec plus de 40 millions de personnes contaminées, contre un peu plus de 500 pour le groupe O et seulement 7 pour le groupe N.
Non seulement le groupe M est de loin le groupe le plus important en nombre de personnes contaminées, mais il est également celui qui est le plus répandu de par le monde, en étant présent sur tous les continents, alors que les autres groupes sont uniquement présents en Afrique centrale.Le groupe M comprend neuf sous-types ou clades (de A à D, de F à H, J et enfin K).
S'ajoutent plusieurs formes recombinantes (en anglais circulating recombinant form ou CRF), qui ont pour origine la multiple infection d'une cellule par des sous-types différents, ce qui entraîne des mélanges dans le génome viral.Les sous-types et formes recombinantes du groupe M ne sont pas réparties uniformément sur toute la planète.
Ainsi, en Europe, dans les Amériques et en Australie, c'est le sous-type B qui est le plus présent, alors qu'en Afrique c'est, selon les régions, le A et le C et, en Asie, toujours selon les régions, les groupes C et E.Bien que la variabilité génétique au sein d'un même groupe ne semble pas modifier, de manière significative, la pathogénicité ni la progression de l'infection, elle pose tout de même de sérieux problèmes pour la mise au point d'un vaccin efficace sur tous les groupes et souches du VIH, pour les mesures de la charge virale et dans certains cas particuliers de test VIH.
Dans ce dernier cas, c'est ainsi que les tests de dépistage basés sur des antigènes du VIH-1 de sous-type B et du VIH-2 de sous-type A, peuvent présenter une sensibilité moindre pour la reconnaissance des autres sous-types, particulièrement lors de la primo-infection ou d'une infection par des variants comme les VIH-1 du groupe O.L'apparition de nouvelles variantes génétiques est due à un processus d'évolution, dont les mécanismes sont semblables à ceux qui expliquent l'évolution de toute espèce vivante.
La seule différence est que l'évolution du VIH est extrêmement rapide, ce qui a conduit au grand nombre de variantes actuelles.
On explique cette grande variabilité génétique du VIH par plusieurs causes :Chez les VIH, le taux de mutations est très important : plus de mille fois plus important que dans le génome d'un humain.
En voici les raisons :Ainsi, dans un seul organisme infecté, il y a déjà plusieurs variantes génétiques, représentant ainsi une quasi-espèce virale.La variabilité du génome viral n'est pas la même pour tous les gènes, certains sont plus enclins à varier que d'autres.
C'est ainsi que le gène env est le plus variable (c'est justement lui qui code les protéines de surface gp41 et gp120), alors que le gène pol est le plus conservé.Lorsqu'une cellule est infectée par deux virions génétiquement différents, les séquences peuvent se recombiner, ce qui donne naissance à des formes recombinantes.
Ce processus, aléatoire, est favorisé par les comportements à risque, parce qu'ils augmentent la probabilité de contaminations multiples chez une même personne.Il y a ensuite un processus de sélection naturelle.
Les erreurs de transcription et les recombinaisons produisent de nombreux virions différents les uns des autres.
La plupart de ces mutations entraînent la production de virions incapables de se répliquer correctement, ce qui les destine à disparaître.
Cette importante disparition de virions est compensée par le grand nombre de virions produits.
Parmi les virions survivants, certains ont pour particularité d'être plus résistants aux attaques des défenses immunitaires.
Cela a pour conséquence de les rendre mieux adaptés à leur milieu et, finalement, seuls les virions résistants sont présents dans l'organisme.
Cela mène, à plus ou moins court terme, à une inefficacité des défenses immunitaires, provoquant l'état immunodéprimé de l'organisme si le taux de lymphocytes CD4+ est trop bas.La prise d'un traitement médicamenteux par les patients infectés par le VIH entraîne également une sélection au sein de la population virale.
Ceci favorise la transmission des virions mutants les plus résistants aux médicaments.
Pour contrer cette adaptation des VIH, les multithérapies visent à « attaquer » le VIH sur plusieurs facettes à la fois, et ainsi à limiter les possibilités du virus de s'adapter à son milieu.La multiplicité temporelle des passages du VIScpz à l'humain est la raison de l'existence des différents groupes du VIH-1.
Il en est de même pour le VIH-2, dont l'ancêtre est le VISsmm.Des études mettent en évidence la présence depuis plusieurs années d'un variant du VIH-1B plus virulent aux Pays-Bas.
Il présente un grand nombre de mutations affectant près de 300 acides aminés,.Le diagnostic précoce de l'infection par le VIH est important pour une bonne prise en charge du VIH/sida.
En France, par exemple, un cas sur deux est détecté au moment du stade sida, ce qui, pour les cas non détectés, multiplie par seize le risque de décès du patient dans les six premiers mois de son traitement.Dans les pays développés, des tests sont pratiqués systématiquement pour les dons de sang, d'organes et de sperme.
Le manque de tests a entraîné plusieurs contaminations de masse.Le diagnostic sérologique est un acte médical réalisé, en France, par un médecin.Le diagnostic visant à déterminer le statut sérologique au VIH est réalisé en deux étapes :La première étape se base sur la détection d'anticorps produits en réponse à une infection par le VIH, les anticorps anti-VIH.
Cette production d'anticorps peut être détectée, avec les moyens actuels, en moyenne 22 jours après la contamination.
Durant cette période, appelée fenêtre sérologique, le patient est parfaitement infectieux, ce qui pose des problèmes évidents de santé publique.
Une fois la fenêtre sérologique passée, son statut sérologique peut être établi.La première étape de détection emploie la méthode ELISA, qui utilise la réaction anticorps-antigène pour détecter la présence des anticorps anti-VIH.
Pour éviter les faux négatifs - qui feraient passer à côté d'un cas de séropositivité - le test doit avoir une sensibilité optimale.
Un mélange d'antigènes viraux est alors utilisé, permettant la détection des anticorps anti-VIH-1 et anti-VIH-2 (on parle alors d'ELISA mixte).
L'utilisation de deux tests commerciaux d'origine différentes est généralement effectuée pour éliminer le maximum de faux positifs dès la première étape.Si la détection se révèle positive, douteuse, ou discordante, une confirmation est réalisée.
Cette dernière vise à savoir si les anticorps détectés sont bien liés à une infection par le VIH-1.
Pour cela, on utilise une méthode spécifique, dont le but est d'éliminer les résultats faussement positifs.
C'est la méthode western blot (WB) qui est généralement utilisée.
Là encore, si le test est douteux ou dénote un début de séroconversion, un second test de confirmation est réalisé trois semaines plus tard, le temps que la séroconversion soit complète.Ce n'est qu'à la suite de l'ensemble de ces tests qu'un médecin pourra déclarer un patient séropositif.Il existe d'autres techniques de détection d'une infection par le VIH, comme :Une fois la séropositivité établie, un suivi régulier de l'infection doit être effectué, pour assurer une bonne prise en charge de la maladie et ainsi évaluer au mieux l'état du malade.
Deux facteurs permettent d'évaluer l'évolution de la maladie :On considère depuis 2013 en France que tous les malades atteints par le VIH doivent être traités par antirétroviraux, quel que soit leur niveau de lymphocytes CD4+.En dessous de 200/mm3 le patient est fortement immunodéprimé et est particulièrement vulnérable aux maladies opportunistes liées au sida.
Une antibioprophylaxie par co-trimoxazole est alors indispensable pour prévenir certaines de ces infections : la pneumocystose et la toxoplasmose cérébrale.L'infection par le VIH évolue en plusieurs phases pouvant se succéder dans le temps :Dès la primo-infection, le virus se réplique activement dans l'organisme, avec une production quotidienne de dix milliards de virions, entraînant la destruction d'environ cinq milliards de lymphocytes T CD4+.
Cette réplication se stabilise, après quelques semaines, à un niveau plus ou moins important selon les sujets.
Le système immunitaire, hyperactivé, compense partiellement la destruction massive des lymphocytes T CD4+ en augmentant leur production, mais l'infection à VIH persiste malgré tout, avec pour conséquence l'émergence et la sélection de virus mutants qui échappent à la réponse immunitaire de l'hôte.Des chercheurs du CNRS, de l'Institut Curie et de l'Institut Pasteur ont découvert que le virus modifiait le pH des compartiments cellulaires où il s'accumule dans les macrophages, empêchant ainsi l'activation des enzymes chargées de le dégrader.Pendant plusieurs années, les lymphocytes T CD4+ semblent se renouveler rapidement malgré leur destruction par le virus, jusqu’à ce que l'épuisement des organes lymphoïdes centraux (thymus) ne permette plus leur régénération.
La destruction des lymphocytes T CD4+ est bien souvent due à l'hyperactivation de ces cellules, par interaction avec certaines structures du virus, et non à une destruction directe par le VIH.
Après dix à quinze ans d'évolution spontanée sans traitement, le sujet est immunodéprimé (stade sida), des pathologies infectieuses ou tumorales rares (dites opportunistes) surviennent et conduisent au décès.
Actuellement les traitements antirétroviraux évitent ou retardent l'évolution vers le stade sida, en maintenant les niveaux de réplication du virus au plus bas possible.La destruction du système immunitaire et la progression clinique avec apparition de maladies opportunistes sont directement liées au taux sanguin des lymphocytes T CD4+ du patient.
L'efficacité des traitements antirétroviraux est évaluée par le niveau de réplication virale mesurée par la charge virale VIH (taux d'ARN plasmatique), la mesure de taux de lymphocytes T CD4+ (immunodepression) et par l'état clinique du patient.Plusieurs cas de personnes séropositives ont réussi à garder pendant une longue durée (au minimum 8 ans), naturellement (c'est-à-dire sans traitement), un taux de CD4 normal (supérieur à 500/mm³) et une charge virale basse, voire indétectable pour certains,.
Elles sont dites non-progresseurs à long terme ou encore asymptomatiques à long terme (ALT).
Quelques patients français sans traitement sont restés asymptomatiques, et même à charge virale indétectable ou presque, pendant au moins vingt ans.Il n'existe pas de modèle unique, certains patients restent dans un état asymptomatique sans évolution significative de leur état, d'autres (la majorité) connaissent une lente détérioration de leur système immunitaire.Il faut noter le rôle important de la mitochondrie dans l’évolution plus ou moins rapide d'aggravation de la réplication virale et dans la baisse de la réponse immunitaire.
La protection des mitochondries freine la baisse des lymphocytes T et CD4 et la réplication du virus, favorisant l'état « ALT ».
La prise régulière de coenzymes Q10 (> 100 mg/j), associée à divers anti-oxydants vitaminés A, B, C, D, E, K, ainsi que la prise de différents minéraux anti-oxydants, ont un effet protecteur sur ces mitochondries au cours des maladies à déficiences mitochondriales, ce qui favorise une bonne réponse immunitaire.
Ce rôle protecteur est d’ailleurs important en cas de prise d’un traitement antirétroviral, en bloquant une partie de la toxicité inhérente à la prise du remède et en activant l’anti-oxydation.Il est important de souligner qu'une ou plusieurs réinfections à d'autres types ou sous-types de souches virales VIH ne favorise pas le maintien dans l'état « ALT », car, du fait de la mutation très rapide du VIH, le risque de recombinaison génétique (en termes de probabilité mathématique) avec des souches plus virulentes diminue forcement la résistance immunitaire d'un patient lambda et sa réponse immune face à un traitement antirétroviral futur.Certains patients, très rares (moins de 1 %), qui ne développent pas de maladie malgré parfois plus de vingt années de séropositivité et en l’absence de traitement, sont appelés « contrôleurs du VIH » (HIC).
Il s'agit des patients infectés par le VIH, ne développant pas le sida, dont l'organisme parvient spontanément et durablement à contrôler la réplication virale, maintenant le virus indétectable ou presque dans le plasma (jusqu’à moins de 50 copies d’ARN viral /ml),.Ils font l'objet de recherches qui pourraient conduire à des médicaments ou à un vaccin contre le VIH.Dans le monde, chaque année, il y a environ 1,7 million de cas de nouvelles infections.
En 2018, il y avait 37,9 millions de personnes vivant avec le virus de l'immunodéficience humaine, la majorité étant en Afrique sub-saharienne.
La même année, 770 000 décès dus au sida ont été recensés.En France, pour l'année 2018, l’Institut de Veille Sanitaire estime à environ 6 200 les nouveaux cas de séropositivité (chiffre stable depuis 2003).
Les rapports hétérosexuels représentent la moitié de ces nouveaux cas et concernent pour moitié des personnes d’Afrique subsaharienne.
Entre 2013 et 2018, le nombre de découvertes de séropositivité a diminué chez les hommes hétérosexuels, mais augmenté chez les homosexuels nés à l'étranger et les femmes hétérosexuelles nées à l'étranger.
La proportion d’infections à VIH-2 était de 1 % en France, en 2016.
Parmi les infections à VIH-1, la proportion de sous-types non-B est de 39% en 2016.
En 2018, 5,8 millions de sérologies VIH ont été réalisées en France, soit une augmentation de 11 % par rapport à 2013, tandis que le nombre de sérologies confirmées positives a baissé.
Cette baisse signifie surtout que l'augmentation du dépistage a bénéficié moins aux personnes les plus exposées au VIH qu'à celles les moins exposées.Les antirétroviraux constituent l'arsenal thérapeutique contre le VIH, qui s'étoffe progressivement.
Une vingtaine de médicaments antirétroviraux sont disponibles en 2006 et ont pour but d'interférer différents mécanismes : d'une part, les enzymes du VIH nécessaires à sa réplication et, d'autre part, ses mécanismes d'entrée dans la cellule.Grâce à la trithérapie utilisée depuis 1996, la mortalité due au sida a chuté, de façon significative, partout où ces nouveaux traitements étaient disponibles,,,.
C'est ainsi qu'aux États-Unis, l'utilisation à grande échelle de trithérapies a fait passer le nombre de décès chaque année de 49 000 en 1995 à 15 807 en 2016,.Ces médicaments sont susceptibles d'avoir des effets secondaires passagers ou permanents, ce qui peut conduire à l'arrêt ou surtout à la modification du traitement, sachant que, correctement suivis, ils ont une efficacité relativement importante.L'intestin joue un rôle essentiel dans l'immunopathogenèse du virus de l'immunodéficience humaine (VIH),,.
La diminution des niveaux de zonuline est corrélée à une mortalité accrue chez les patients VIH.
Les traitements par maraviroc (antagoniste de récepteur de CCR5) et raltegravir (inhibiteur de l'intégrase) augmentent la zonuline.
Ces données combinées suggèrent que la voie de la zonuline dans sa fonction d'immunité innée peut protéger contre l'infection par le VIH.La recherche sur le VIH/sida étant très importante, de nombreuses recherches, études et publications voient régulièrement le jour.
Mais la durée entre la conception d'une molécule et son autorisation de mise sur le marché oscillant entre sept et douze ans en France, il faut relativiser les effets d'annonces qui, pour certaines, ne déboucheront pas sur une application directement pratique dans la lutte contre le VIH/sida.Ainsi les seuls médicaments reconnus comme réellement efficaces sont les antirétroviraux ayant reçu leur autorisation de mise sur le marché.Depuis décembre 2021 en France il est possible sous certaines conditions de remplacer le traitement journalier par une piqûre tous les deux mois combinant deux rétroviraux (cabotégravir et la rilpivirine).Les antirétroviraux sont classés suivant leur domaine d'action :Les inhibiteurs de la transcriptase inverse empêchent la synthèse d'ADN proviral (c'est-à-dire qui va permettre la duplication du virus) à partir de l'ARN viral.
On trouve dans cette classe :Les INTI ont constitué la première classe d'antirétroviraux mise sur le marché en 1985.
Ils comprennent la zidovudine (AZT) (synthétisée en 1964), la didanosine (ddI), la zalcitabine (ddC), la stavudine (d4T), la lamivudine (3TC) (1989 et utilisée à partir de 1995), l'abacavir (ABC) et l'emtricitabine (FTC).Les mutations du génome à cause de la transcriptase inverse confèrent au VIH une résistance aux INTI, qui peut être croisée entre plusieurs INTI.
Ces composés sont tous neutres ou réducteurs, à l'exception de l'AZT qui est un oxydant.Les INNTI sont des inhibiteurs puissants et très sélectifs de la transcriptase inverse du VIH.
On trouve dans cette classe la nevirapine et l'efavirenz.
Ils ne sont actifs que sur les VIH-1.
Ils sont métabolisés en phénols par oxydation.Les analogues nucléotidiques comme le ténofovir qui a été mis sur le marché en 2002, sont des composés organophosphorés.La classe des inhibiteurs de la protéase (IP) est une classe d'antirétroviraux mise sur le marché en 1996.
Elle a constitué un tournant majeur dans les stratégies thérapeutiques contre le virus de l'immunodéficience humaine.
Ils agissent en inhibant l'action de la protéase virale qui permet le découpage et l'assemblage des protéines virales, processus indispensable à l'obtention de virus infectieux.
On obtient alors des virions incapables d'infecter de nouvelles cellules.
Les IP sont actifs sur le VIH-1 et le VIH-2, et ne créent pas de résistance croisée avec les INTI ou les INNTI.Ces inhibiteurs bloquent l'action de l'intégrase et empêchent ainsi le génome viral de se lier à celui de la cellule cible.Les molécules disponibles actuellement sont : le raltégravir, commercialisé sous la marque Isentress, l'elvitégravir et le dolutégravir, commercialisé sous la marque Tivicay.Les inhibiteurs de fusion-lyse interviennent au début du cycle de réplication du VIH, en bloquant les protéines de surface du VIH ou en perturbant les corécepteurs des cellules ciblées par le VIH.Plusieurs produits sont à l'étude et, en 2009, seuls l'enfuvirtide et le maraviroc ont reçu une autorisation de mise sur le marché.Depuis le début des années 1990 différentes trithérapies ont vu le jour, pouvant être prescrites en fonction du stade clinique, du taux de lymphocytes T CD4+ et de la charge virale.
Ce traitement antirétroviral comprend actuellement trois médicaments, en général deux inhibiteurs nucléosidiques de la transcriptase inverse, associés à un inhibiteur des protéases ou à un inhibiteur non nucléosidique de la transcriptase inverse, ou parfois à un troisième inhibiteur nucléosidique de la transcriptase inverse (trithérapies).
Un inhibiteur de fusion y est éventuellement associé.Lors d'un premier traitement, la quasi-totalité des patients voient leur charge virale plasmatique rendue indétectable dans les six premiers mois.
Ce premier traitement doit être le plus simple et le mieux toléré possible.
C'est la non observance du traitement qui est la principale cause de l'échec thérapeutique.Bien que les traitements antirétroviraux soient très efficaces lorsqu'ils sont bien suivis, le VIH est toujours présent dans l'organisme.
Si on a un temps pensé que le sang et le sperme des personnes infectées restaient contagieux, l'étude Partner2, présentée à la 22e conférence internationale sur le sida a montré qu'un porteur d'une charge virale indétectable ne transmet pas le virus,.Même si la recherche est très active et que certains candidats vaccins existent avec pour l'un des résultats encourageants concernant la faisabilité de la mise au point d'un vaccin, il n'en existe pas de vraiment efficace contre ce virus.
Le préservatif offre une protection simple et efficace lors des rapports sexuels ; depuis le début des années 2010, l'utilisation prophylactique des agents antirétroviraux Emtricitabine/ténofovir (Truvada) a également prouvé son efficacité contre la transmission lors de rapports sexuels, en particulier chez les populations particulièrement exposées (hommes homosexuels, travailleuses et travailleurs du sexe).
Les dons de sang font l'objet d'une sélection des donneurs, de dépistages systématiques et de traitements spécifiques.
Aussi, la prévention se fait par l'utilisation de seringues à usage unique en toute occasion, en particulier en cas de toxicomanie par intraveineuse ou de traitement substitutif.Malgré la large diffusion d'informations sur la maladie et la prévention, certaines personnes ont néanmoins des comportements à risque (voir article prise de risque sida), ce qui nécessite des actions de prévention.Le traitement post-exposition (TPE) est actuellement le seul moyen de stopper le VIH ou, plutôt, de ne pas être contaminé par le virus, à la suite d'une exposition.
En effet, à la suite d'une exposition à un risque de contamination (rapport sexuel non protégé par exemple), au plus tard dans les 48 heures suivant cette exposition, si le traitement est pris, le risque d'être contaminé est réduit de 80 %, ce qui en fait un traitement relativement efficace.
La communauté scientifique s'accorde à dire que ce n'est pas suffisant pour être sûr de ne pas contracter le virus.
De plus, des problèmes d'intolérance à ces médicaments font que ces traitements ne sont pas toujours pris pendant la durée nécessaire (1 mois).
Aussi, l'usage du préservatif est toujours conseillé, car c'est le seul moyen de protection efficace s'il est correctement utilisé.Certaines personnes ou groupes remettent en question le lien de causalité entre le VIH et le sida, voire nient l'existence du virus,.
Le virologue Peter Duesberg soutient que le sida est causé par la consommation à long terme de drogues ou d'antirétroviraux.
Ce point de vue a été repris pendant un temps par le gouvernement d'Afrique du Sud et, plus particulièrement, son président de l'époque, Thabo Mbeki.
En réaction à ces controverses, la Déclaration de Durban rappelle que les preuves que le sida est causé par le VIH sont claires, sans ambiguïtés et conformes aux plus hauts standards de la science.
Ces contestations constituent, selon le point de vue général, une menace pour la santé publique, en dissuadant la population de se faire tester ou les malades d'être sous des traitements antirétroviraux qui ont fait leurs preuves,.Ces dissidents affirment que l'approche officielle du sida, qui considère comme acquise sa causalité rétrovirale, a eu pour conséquence des diagnostics erronés, l'apparition d'une terreur psychologique et d'une certaine forme de racisme, l'utilisation de traitements toxiques et le gaspillage de fonds publics,.
Ces opinions sont largement rejetées, et sont considérées comme de la pseudo-science par la plupart des membres de la communauté scientifique.
La pharmacovigilance (composée des mots pharmakon : « médicament » et vigilare : « être vigilant ») est l'activité consistant à enregistrer et évaluer les effets secondaires (en particulier les effets indésirables) résultant de l'utilisation des médicaments.
On distingue la pharmacovigilance des médicaments à usage humain de celle des médicaments à usage vétérinaire.Le faible nombre de patients inclus dans les essais cliniques avant la commercialisation du médicament ne permet pas de détecter les effets indésirables qui surviennent rarement.
C'est pourquoi il est nécessaire de disposer d'un système de pharmacovigilance afin d'assurer la surveillance des médicaments sur un plus grand nombre de patients une fois le médicament commercialisé.
Ce système, dont l'évolution est assez récente et se poursuit à ce jour, est indispensable et s'inscrit dans la sécurité du médicament comme une activité de minimisation des risques.En France, « la pharmacovigilance a pour objet la surveillance du risque d'effet indésirable résultant de l'utilisation des médicaments et produits à usage humain » (article  R. 5121-150 du Code de la santé publique).Elle vise à garantir la sécurité d’emploi des médicaments.
Elle repose sur le signalement des effets indésirables par les professionnels de santé (obligation leur est faite - Article R. 5121-161 du CSP - de signaler tout effet indésirable médicamenteux grave ou inattendu) et les industriels.La politique de pharmacovigilance en France a ses limites car elle n'a pas empêché l'emploi pendant de longues années de médicaments dangereux (Mediator, Depakine, etc.) et qu'elle permet la vente libre ou la prescription sur ordonnance de médicaments considérés comme "médicaments à écarter" par la revue indépendante Prescrire.Les professionnels de santé déclarent les effets indésirables aux 31 centres régionaux de pharmacovigilance (CRPV), situés dans des structures hospitalières, et qui ont chacun leur propre compétence géographique.
Les évènements sont évalués et enregistrés, puis transmis à l'Agence Nationale de Sécurité du Médicament (ANSM), qui coordonne l'ensemble du système.Si un effet indésirable est transmis au laboratoire pharmaceutique propriétaire du médicament, il doit le déclarer directement à l'ANSM sous 15 jours si l'effet indésirable est grave (décès, mise en jeu du pronostic vital, hospitalisation ou prolongation d'hospitalisation, invalidité, anomalie ou malformation congénitale, autre critère médicalement important).
Les cas de Pharmacovigilance ne répondant pas à ces critères sont dits « non graves » et seront transmis aux Autorités Compétentes par le biais des rapports périodiques.Les différentes agences nationales responsables du médicament ont organisé un réseau d'échange d'informations sur la pharmacovigilance appelé Eudravigilance et géré par l'EMA.
Un effet indésirable grave constaté pour un même médicament en Allemagne et en Grande-Bretagne est donc transmis en France et des recoupements sont faits.
Cela peut amener à modifier les conditions d'utilisation du produit, à les restreindre voir à retirer le produit du marché.
Les professionnels de santé peuvent être avertis de manière rapide par une Lettre aux prescripteurs, ou Dear Doctor Letter (DDL), envoyée par le laboratoire.Les études cliniques de Phase IV, qui ont lieu après la mise sur le marché d'un médicament, sont une sorte de pharmacovigilance.Les données de pharmacovigilance pour un médicament sont rassemblées et analysées par le laboratoire dans un document appelé « periodic safety update report (PSUR) », qui est fourni régulièrement aux autorités de santé (l'ANSM pour la France) : tous les six mois pour un médicament nouveau, puis à terme tous les trois ans (la sécurité d'utilisation du produit étant vérifiée sur de larges populations).Au Canada, la pharmacovigilance est réglementée par la Direction des produits de santé commercialisés de la Direction générale des produits de santé et des aliments de Santé Canada.Depuis Avril 2013, par décision exécutive de la Commission européenne l'Australie figure sur la liste des pays tiers garantissant un niveau de protection de la santé publique équivalent à celui de l'Union européenne.En France, inspirée du système de pharmacovigilance humaine, elle a été mise en place par le décret no 99-553 du 2 juillet 1999, puis a été renforcée par le décret no 2003-760 du 1er août 2003.
Elle veille non seulement à l'innocuité des médicaments vétérinaires chez l'animal, mais aussi à l'innocuité des denrées alimentaires d'origine animale (issues d'animaux traités).
Elle surveille aussi les éventuels effets indésirables des médicaments sur les personnes en contact avec les médicaments vétérinaires.
Enfin, la surveillance des effets des médicaments sur l'environnement est également de son ressort.C'est l'Agence nationale du médicament vétérinaire (Anmv), intégrée à l'Anses depuis juillet 2010, qui a pour mission d'assurer la pharmacovigilance vétérinaire.
Un conservateur est défini comme toute substance capable de s’opposer aux altérations d’origines physique (photodégradation, dissociation, biodégradation, etc.) chimiques (transformation par réaction d'oxydoréduction avec l'air ou un composant, ou un contenant) ou microbiologiques d’un produit (altération par les bactéries en général).Ils allongent la durée d'utilisation ou de mise en vente d'un produit, son efficacité et parfois améliorent la sécurité alimentaire.Ces produits sont proches des stabilisateurs et en ont souvent aussi la fonction.Beaucoup de conservateurs ont des vertus biocides.
Ils sont donc écotoxiques et parfois toxiques pour l'homme.
Ils doivent donc être utilisés à faible ou très faible doses.Ils peuvent en outre être allergènes et/ou sensibilisants, ce qui pose des problèmes dans les médicaments, produits alimentaires ou cosmétiques ou  d'hygiène corporelle (à usage humain ou vétérinaire), fixateur de parfum.
C'est le cas par exemple du conservateur méthyldibromoglutaronitrile (MDBGN) (ou Euxyl K400, 1,2-dibromo-2,4-dicyanobutane, pentanedinitrile, 2-bromo-2-(bromométhyl)-, glutaronitrile, 2-bromo-2-(bromométhyl)-) qui s'est révélé être un puissant sensibilisant (en une à cinq semaines de contacts répétés,, et allergène source d'eczémas de contact allergiques,, et où l'on trouve aussi 20 % de méthylglutaronitrile, qui y est le principal allergène).
L'Agence nationale de sécurité du médicament et des produits de santé (abrégé ANSM) est un établissement public français.
Elle a pour mission principale d’évaluer les risques sanitaires présentés par les médicaments et produits de santé destinés à l'être humain.
Elle est aussi l'autorité unique en matière de régulation des recherches biomédicales.L'agence compte environ 1 000 salariés auxquels s'ajoutent 2 000 experts réguliers ou occasionnels.
Son budget de plus de 150 millions d'euros provient pour l'essentiel des taxes et redevances prélevées sur l'activité de l'industrie pharmaceutique.
Son fonctionnement et plus particulièrement son indépendance vis-à-vis des laboratoires pharmaceutiques font souvent l'objet de critiques.L’Agence du médicament est créée par la loi no 93-5 du 4 janvier 1993 et le décret no 93-265 du 8 mars 1993, à la suite notamment de l'affaire du sang contaminé.
Elle est devenue opérationnelle en avril 1993, puis la structure et l’organisation de l’agence ont été approuvées par le gouvernement français le 2 septembre 1993.Elle est une des agences françaises de sécurité sanitaire ; elle est avec l’Agence nationale de sécurité sanitaire de l'alimentation, de l'environnement et du travail (Anses) et l’Agence nationale de santé publique (SpF), l’un des trois établissements publics de l’État dont la création résulte de la loi du 1er juillet 1998 relative à la veille sanitaire et la surveillance des produits destinés à l'être humain.Elle garantit, au travers de ses missions de sécurité sanitaire, l'efficacité, la qualité et le bon usage de tous les produits de santé humaine.Les missions de l’agence sont définies par la loi du 1er juillet 1998 (codifiée, en ce qui concerne l'Afssaps, aux articles L-5311-1 et suivants du code de la santé publique).
Quatre missions principales peuvent être dégagées :À l'origine, en tant qu'Agence du médicament, le champ de compétence de l'ANSM était celui des médicaments et des produits de transfusion, à l'exclusion du médicament vétérinaire et de la santé animale.
Établissement public à caractère administratif, l'Agence du Médicament donnait par exemple les agréments aux établissements de transfusion sanguine et contrôlait ceux-ci via des inspecteurs assermentés.
La mission de l'ANSM a été élargie aux matières premières, dispositifs médicaux, dispositifs médicaux de diagnostic in vitro, produits biologiques d'origine humaine (produits sanguins labiles, organes, tissus, cellules, produits de thérapie génique et de thérapie cellulaire), produits thérapeutiques annexes, produits cosmétiques.
De plus, depuis 2008, elle est aussi chargée d'évaluer les médicaments sans ordonnance (dits « de prescription médicale facultative ») qui sont vendus en pharmacie mais non remboursés, souvent en vue d'un usage en automédication.L'ANSM autorise et contrôle aussi l'usage, notamment à des fins de recherche scientifique, de substances dangereuses soumises au risque de détournement à des fins de bioterrorisme.
Il s'agit de certains « micro-organismes et bactéries », dont la liste est fixée par arrêté, et qui comprennent actuellement, par exemple, le virus Ebola, le coronavirus responsable du SRAS, ou les bactéries Rickettsia prowazekii (typhus) ou Rickettsia rickettsii (provoquant la « fièvre pourprée des montagnes Rocheuses »).
La gestion de ces autorisations, délivrées seulement après examen du casier judiciaire, est suivie par un fichier informatique, Sambiosec, maintenu par le département de toxicologie de l'Afssaps.L'ANSM a aussi pour mission de contrôler la communication publicitaire ou non faite autour des produits de santé ainsi que de participer elle-même à des campagnes d'information dans le domaine de la santé.
Sa mission de « contrôle de la publicité » l'amène à examiner le contenu des messages promotionnels des firmes pharmaceutiques destinés aux professionnels ou au grand public.L’ANSM assure la gestion et l’évaluation des essais cliniques portant sur les produits de santé mais aussi, depuis 2008, des recherches biomédicales hors produits de santé.
Elle s'assure en particulier que ces recherches ne mettent pas en danger les personnes qui s'y prêtent.L'Agence a changé plusieurs fois de nom depuis sa création.
Elle se nomme Agence du médicament de 1993 à 1999.
Elle devient l'Agence française de sécurité sanitaire des produits de santé (ou Afssaps) entre 1999 et 2012.
Depuis 2012, elle a pris le nom d'Agence nationale de sécurité du médicament et des produits de santé (ANSM).Directeur général : Dominique Martin,, (depuis 2014) ; celui-ci est membre de droit du Conseil national de la consommation.
L'intérim est assuré par Dr Christelle Ratignier-Carbonneil, directrice adjointe à la Caisse nationale d'assurance maladie des travailleurs salariés (CNAMTS).
Elle est nommée directrice générale le 14 décembre 2020.Présidente du conseil d'administration : Catherine de Salins (depuis mai 2016),Présidente du conseil scientifique : Annick AlperovitchDans leur ouvrage Santé, Mensonges et Propagande paru en 2004, les journalistes Thierry Souccar et Isabelle Robard dénoncent les conflits d'intérêts déclarés des membres de l'Afssaps.
Sur 675 personnes siégeant dans cette organisation, près de 415 personnes (donc 62,4 %) déclarent avoir des intérêts dans l'industrie pharmaceutique, cosmétique ou autre.
Pour les auteurs, cet organisme se retrouve guidé par des intérêts commerciaux au lieu d'être guidé par l'intérêt général.En 2010, le rôle de l'Afssaps a aussi été critiqué dans l'affaire du Mediator, un antidiabétique utilisé comme coupe-faim dont les effets indésirables sérieux n'ont été reconnus que tardivement : le médicament s'est vu retirer son autorisation de mise sur le marché fin 2009, douze ans après l'interdiction des médicaments de cette classe thérapeutique aux États-Unis.
En 2009 en Europe, seuls le Portugal, Chypre et la France autorisaient encore ce médicament.Le 16 mars 2011, le député Bernard Debré et le directeur de l'Institut Necker, Philippe Even, remettent au président de la République française un rapport dans lequel ils dénoncent entre autres les conflits d'intérêts des experts de l'Afssaps et critiquent leurs compétences, ainsi que la lourdeur de l'organisme.
Ils préconisent de remplacer les 3 500 experts de l'Afssaps par 40 professeurs des universités praticiens hospitaliers, indépendants de l'industrie pharmaceutique, de scinder l'agence en deux entités, l'une chargée de l'évaluation des médicaments, et l'autre de leur surveillance, et de comparer les nouvelles molécules à des médicaments existants plutôt qu'à des placebos.Le 17 mars 2011, le récent directeur de l'Afssaps, Dominique Maraninchi, promet de rompre avec l'opacité passée, notamment en rendant accessibles en ligne les débats des experts de l'agence et d'en diffuser les vidéos, ainsi que de réévaluer plus souvent l'efficacité des traitements.Depuis 2012, l'ANSM a mis en place un programme de contrôle interne visant à vérifier l'application des règles déontologiques dans les processus décisionnels de l'agence, en accord avec la loi n° 2011-2012 du 29 décembre 2011 relative au renforcement de la sécurité sanitaire du médicament et des produits de santés.Novembre 2009 - Affaire du Mediator.
Le benfluorex (Médiator) est un antidiabétique qui a été largement prescrit et utilisé comme coupe-faim.
Il a été retiré du marché le 30 novembre 2009 à la suite de l'observation de cas d'atteintes valvulaires cardiaques.
Le nombre de décès pourrait dépasser les 1500.
Le fabricant, les Laboratoires Servier, sont poursuivis par le Parquet de Paris pour «  tromperie aggravée, escroquerie, blessures et homicides involontaires et trafic d'influence  ».
L'ANSM est renvoyée devant le tribunal correctionnel pour «  blessures et homicides involontaires  ».
Un dispositif d'indemnisation a été mis en place.
Le 29 mars 2021, l’ANSM, jugée pour avoir tardé à suspendre la commercialisation du Médiator, est condamnée à 303 000 euros d’amende.
Didier Tabuteau, directeur de l’Agence du médicament durant ces années, n’a jamais été inquiété.Janvier 2016 - Essai clinique de Rennes.
Lors d'un essai clinique validé par l'ANSM six hommes âgés de 28 à 49 ans sont victimes de troubles neurologiques graves entraînées par des lésions profondes dans le cerveau.
Ils participaient à un essai clinique de phase 1 réalisé par le centre de recherche privé Biotrial, agréé par le ministère de la Santé et inspecté à deux reprises au cours de visites de routine menées par l’Agence Nationale de Sécurité du Médicament.
Dans le cadre de l'enquête, le Parquet de Paris perquisitionne le siège de l'ANSM en avril 2016.Septembre 2016 - Depakine.
Le principe actif de cet antiépileptique causerait des malformations fœtales chez les femmes enceintes et cet avertissement ne serait apparu sur les notices qu'en 2006.
Or, les effets tératogènes (qui provoquent des malformations chez le fœtus) de la dépakine sont mentionnés dans la littérature scientifique depuis 1982.
Catherine Hill, épidémiologiste à l’Institut Gustave Roussy, a analysé les données de l'APESAC, association des victimes de la Dépakine présidée par Marine Martin, lanceuse d'alerte sur l'affaire de la Dépakine, estimant à 2 826 le nombre d’enfants présentant des malformations, soit le même chiffre que celui de l’ANSM-Cnam.
Le Parquet de Paris ouvre une enquête préliminaire en septembre 2015.
En septembre 2016, une information judiciaire pour « tromperie aggravée » et « blessures involontaires » est lancée avec la nomination de deux juges d’instruction du pôle Santé.
Depuis, le dossier est au point mort.Octobre 2017 - Levothyrox.
Cette hormone de synthèse est prescrite à 3 millions de patients, dont 80 % de femmes.
Le traitement est quotidien et doit être pris à vie par les personnes ayant subi une ablation de la thyroïde.
À la suite du changement d'un excipient de la formule, demandé par l'ANSM et réalisé par le fabricant Merck en février 2017, des milliers de personnes se sont plaintes d'effets secondaires.
Une pétition pour revenir à l’ancienne formule du Levothyrox a recueilli plus de 200 000 signatures.
En dépit de la polémique et des pétitions, le fabricant du Levothyrox a assuré au début du mois de septembre 2017 qu’il n’était « pas du tout question de revenir à l’ancienne formule », soutenu en cela par le Directeur Général de l’ANSM qui concédait seulement « un défaut d’information aux patients ».
À la demande du Ministre de la Santé, Madame Agnès Buzyn, l'ancienne formule est finalement de nouveau distribuée à partir du 2 octobre 2017 sous le nom d'Euthyrox.
L'ANSM précise que ce médicament correspondant à l'ancienne formule devra « être prescrit exclusivement en dernier recours aux patients, en nombre limité, qui rencontrent des effets indésirables durables avec les autres spécialités ».
Dans le cadre de l'enquête, le Parquet de Marseille perquisitionne le siège de l'ANSM en octobre 2017.
En septembre 2018, l'ANSM utilise la loi du secret des affaires, promulguée le 30 juillet 2018, pour censurer partiellement le document d'autorisation de mise sur le marché du Levothyrox,.
Depuis les données de l'étude de la bioéquivalence des deux formules de Lévothyrox ont été mises en ligne sur le site de l'ANSM et réanalysées par des statisticiens.La réanalyse, qui tient compte du fait que chaque volontaire a reçu successivement les deux formules, montre une grande variabilité entre les sujets quant à la biodisponibilité de chacune des formules.Une action collective est ensuite lancé en septembre 2021 contre l'Agence.
Elle est menée par l'avocat Christophe Lèguevaques, déjà à l'origine d'une autre action collective contre Merck, et lancée devant le tribunal de Montreuil (Seine-Saint-Denis).Une liste de 77 médicaments surveillés a été publiée en 2011.Mi-décembre 2014, l'Assurance maladie a déposé sur www.data.gouv.fr 112 jeux de données de santé open data, et certifiées, portant sur l’offre et la consommation de soins en France, afin d'améliorer la transparence de la prescription médicamenteuse, de la traçabilité des principes actifs et leur date de commercialisation.En septembre 2018, l'ANSM empêche la transmission d'informations sur le Levothyrox à une association de victimes, au motif du secret des affaires.
Une maladie infectieuse (ou infection) est une maladie provoquée par l'invasion d'un ou plusieurs micro-organismes ou agent infectieux (bactéries, champignons, parasites, protozoaires, virus) dans un tissu où ils se multiplient, et par une réaction générale des cellules et des tissus infectés pour éliminer ces agents pathogènes ou leurs toxines (processus impliquant notamment le système immunitaire des plantes et des animaux).L'étude des agents infectieux relève de la biologie, de la microbiologie médicale, de l'épidémiologie et de l'écoépidémiologie.
Dans la nature, des maladies infectieuses se développent chez tous les organismes vivants (animaux, végétaux, fongiques, micro-organismes… il existe également des virus de virus).
En tant qu'interactions durables, les maladies infectieuses font partie des boucles de rétroaction qui entretiennent la stabilité relative (équilibre dynamique) des écosystèmes, la plupart des pathogènes coévoluant avec leur hôte depuis des millions d'années.
Leur mode de transmission est variable et dépend de leur réservoir (humain, animal, environnemental) et parfois de vecteurs (maladies vectorielles).Elles sont plus ou moins contagieuses.
Par exemple, le tétanos est une toxi-infection causée par Clostridium tetani, une bactérie qui se trouve dans la terre.
Il n’y a pas de transmission interhumaine, l’infection se produit lorsque la bactérie entre dans l’organisme par une plaie souillée.
Un vaccin existe contre cette affection et est obligatoire en France pour tous les enfants d’âge scolaire.
Autre exemple, le paludisme est dû à un parasite, le Plasmodium falciparum (il existe d’autres Plasmodii), transmis d’homme à homme par l’intermédiaire d’un moustique, l’anophèle.
Le réservoir du parasite est humain mais il n’y a pas de transmission interhumaine.
Il n’existe à l'heure actuelle pas de vaccin.
La tuberculose se transmet d’homme à homme par mécanisme aéroporté : le réservoir est humain et c’est une maladie contagieuse.
Les infections sexuellement transmissibles (ou encore MST pour maladies sexuellement transmissibles) se transmettent à l’occasion de rapports sexuels ou par le sang.De nombreux microbes vivent normalement et nécessairement dans notre tube digestif et sur notre peau, et ne deviennent infectieux qu'à certaines occasions.
Le contact avec les microbes est nécessaire à l'entretien et au bon fonctionnement de la digestion et du système immunitaire.L'infection est le terme désignant soit une maladie infectieuse en général, soit la contamination par un germe.
C'est la conséquence pathologique au niveau d'un tissu ou d'un organisme de la présence anormale et/ou de la réplication d’un germe bactérien, viral ou mycosique.
La contamination est la pénétration du germe dans un organisme.L'infectiologie est la branche de la médecine concernant les maladies infectieuses.
Le médecin spécialiste est un infectiologue.
Suivant le type de germe, il est également question de bactériologie, de virologie, de parasitologie ou de mycologie.Un sepsis est une infection grave.
L'adjectif septique se rapporte à un organisme ou un objet contaminé par un germe (fosse septique par exemple).
Une septicémie est la contamination grave et durable (sans traitement) du sang par un germe.
Une bactériémie est une contamination transitoire du sang par un germe.
Lorsque les cas se multiplient dans un lieu et une période limitée, il est question d’épidémie.
Si la diffusion est beaucoup plus généralisée, il est alors question de pandémie.
Lorsque l'épidémie concerne le milieu animal, il est question d'épizootie.
Lorsque le germe se transmet de l’animal à l’homme, il est question d'anthropozoonose ou plus simplement de zoonose.Le contage désigne la contamination par le germe.La période d’incubation est le délai entre le contage et la première manifestation de la maladie.
Le malade peut être contagieux durant ce temps.La période de contagion est le temps pendant lequel le patient excrète le germe et peut le transmettre.
Elle dépend de chaque maladie infectieuse.Les infections nosocomiales (ou iatrogènes) sont des infections attrapées à l’hôpital.
Elles sont particulièrement complexes et dangereuses car elles surviennent chez des sujets affaiblis et concernent souvent des germes résistants aux antibiotiques.
Il s’agit d’un problème de santé publique majeur.Comme le résumait en 1935 le bactériologiste français Charles Nicolle : « Malheureusement, les signes des maladies infectieuses sont presque tous les mêmes : fièvre, maux de tête, agitation ou stupeur, éruption.
Seuls leur groupement, leur succession, une observation minutieuse ont pu, après de longs tâtonnements, permettre d'établir des tableaux symptomatiques particuliers et les distinguer entre eux.
»Les maladies infectieuses sont responsables dans le monde de 17 millions de décès par an, soit un tiers de la mortalité et 43 % des décès dans les pays en voie de développement (contre 1 % dans les pays industrialisés).
Les six maladies suivantes représentent 90 % des décès par maladies infectieuses dans le monde.Depuis les années 2000, de nombreuses urgences sanitaires reliées à l’émergence de nouveaux agents étiologiques responsables de maladies respiratoires sévères sont survenues : le syndrome respiratoire aigu sévère (SRAS), les infections d’influenza aviaire A (H5N1) chez les humains dans plusieurs pays de l’Asie, la pandémie de grippe A (H1N1) et, plus récemment, le virus influenza aviaire A (H7N9) en Chine, le coronavirus du syndrome respiratoire du Moyen-Orient (MERS-CoV) et la pandémie de Covid19.
La pathogénicité et la létalité élevées de la plupart de ces virus génèrent des répercussions sociales et une pression importante sur les services de santé.La population mondiale infectée par le VIH continue de croître : rien qu’en 2000, 5,3 millions de nouveaux cas se sont déclarés dans le monde, dont la moitié parmi les jeunes de plus de 25 ans.Après une phase de forte régression (époque pastorienne et hygiéniste), les maladies infectieuses sont revenues ou sont devenues plus résistantes (antibiorésistance).
Des maladies infectieuses émergentes ou réémergentes inquiètent périodiquement les épidémiologistes et les autorités sanitaires en raison de leurs impacts sanitaires, économiques et socio-politiques actuels ou potentiels.
Le Haut Conseil de la santé publique (HCSP) a récemment fait 25 recommandations (sur la recherche et l'enseignement, la surveillance sanitaire et la gestion raisonnée des crises sanitaires notamment).Les progrès de l'hygiène et de la vaccination ont fourni un espoir de pouvoir les éradiquer, mais elles sont encore en France, la troisième cause de mortalité :Il est également noté que certaines infections sont aussi à l’origine de maladies inflammatoires chroniques (telles que l’asthme) et de cancers.Les maladies infectieuses entravent la santé de base des individus et ont une influence négative sur chaque indice du développement humain et plus particulièrement sur l'espérance de vie à la naissance, l'éducation et le PIB réel.
Elles sont responsables d'une forte mortalité dans les régions où l'hygiène connaît un déficit et où l’accès aux soins est difficile.
La malnutrition ainsi qu'un accès limité à l'eau potable sont autant de facteurs aggravants qui diminuent les chances de survie des malades mais aussi des enfants en bas âge de même que leurs conditions de développement.
Ces deux facteurs désarment le système immunitaire et peuvent être vecteurs de maladies infectieuses.Ces maladies ont des conséquences négatives importantes sur le développement cognitif et les performances scolaires chez l’enfant.
La malaria, entre autres, peut causer de graves séquelles, dont des troubles comportementaux, des problèmes moteurs et un manque d’autonomie.
Une telle infection est donc un frein à l’éducation.
Dans le cas des épidémies, il peut arriver que les enseignants soient eux aussi touchés par la maladie.
Un manque de corps enseignant réduirait de façon directe la qualité de l’éducation en affaiblissant le système scolaire.
Par ailleurs, si dans une famille, les responsables de l'éducation des enfants (souvent la mère) sont touchés par la maladie, c’est l’éducation dans son ensemble qui va être affectée.
Le coût du traitement réduit le budget qui aurait pu être accordé à la scolarisation mais également les conditions de vie de l’enfant.
Ce qui crée un cercle vicieux : les couches les plus éduquées de la population sont de moins en moins atteintes par des maladies infectieuses telles que le sida.
En effet ces personnes qui sont les plus éduquées sont les mieux informées sur les modes de transmission et de prévention.
Or, plus de 80 % des personnes atteintes par ces maladies vivent dans les pays en développement.D'un point de vue macroéconomique, les maladies infectieuses ont un impact sur la croissance économique et le PIB.
Dans les pays en développement, la main d’œuvre est le facteur-clé de la production et donc du PIB.
Néanmoins, le bon fonctionnement des entreprises et la possibilité d'être concurrent sur le marché international nécessitent avant tout une bonne santé et une éducation de base.
Lorsque la santé de la personne génératrice de revenu pour la famille est affectée, toute la famille en souffre.
Les maladies infectieuses aggravent donc la pauvreté, réduisent la croissance économique, le capital humain et contribuent à l’augmentation des inégalités entre les pays en voie de développement et les pays riches.La prévention des maladies infectieuses vise à limiter le risque infectieux (y compris professionnel, notamment pour les métiers de la santé, de contact avec les animaux, des déchets, des cadavres, des eaux usées, des échantillons à analyser en laboratoires de biologie, etc.).Elle s’articule en trois volets : éviter l’infection, renforcer les défenses immunitaires et prendre des traitements préventifs (prophylaxie) en cas de risque d’exposition.La maladie infectieuse est provoquée par la pénétration dans l’organisme d’une bactérie ou d’un virus.
La première précaution consiste donc à « fermer les portes d’entrée », à savoir :Le port d'équipements de protection individuelle dépend de l’évaluation des risques.
Au travail outre des gants de protection, un appareil de protection respiratoire et des lunettes masques ou une visière sont parfois nécessaires, voire un vêtement de protection intégral.Les gants fins sont recommandés en cas de risque d’exposition à des liquides biologiques ou chimiques, mais déconseillé pour les activités courantes : en effet, la peau est alors dans une atmosphère chaude et humide propice au développement de germes, et par ailleurs, il vaut mieux des mains propres que des gants sales.
À noter qu’au bout d’une vingtaine de minutes, certains gants fins deviennent poreux ou sont incompatibles avec certaines substances.Il faut aussi limiter le développement de germes pathogènes sur et dans le corps et dans l’habitation, par une hygiène suffisante :Les collectivités territoriales jouent un rôle important en ce qui concerne l’hygiène collective, avec la gestion des eaux pour fournir de l’eau potable, l’organisation de la collecte et du traitement des ordures, l’équarrissage des cadavres d’animaux et la police des funérailles et des lieux de sépulture (condition de transport et de conservation des corps avant crémation ou inhumation, gestion des cimetières et crématoriums).La première mesure consiste à avoir une bonne hygiène de vie : alimentation saine, exercice physique régulier, sommeil suffisant, éviter les comportements à risque (tabagisme, excès d’alcool), ce qui permet d’avoir un meilleur état de santé général donc de mieux résister aux infections.Par ailleurs, il convient de respecter les vaccinations préventives obligatoires, ou recommandées comme la vaccination des personnes âgées contre la grippe.Il faut aussi prendre précautionneusement les médicaments prescrits par un médecin, en lisant systématiquement les notices accompagnatrices, riches en informations (effets secondaires, interactions avec d’autres médicaments, recommandations…) et ne pas hésiter à questionner le médecin ou le pharmacien en cas de doute.
Les effets peuvent ne pas être immédiats, et il faut continuer le traitement jusqu’à la fin même en cas d’amélioration et disparition des symptômes, notamment dans le cas des antibiotiques : la disparition des symptômes signifie la diminution du nombre de germes, mais pas leur disparition, si le traitement est interrompu trop tôt, ceux-ci peuvent se redévelopper, et devenir résistants à l’antibiotique.Il ne faut pas que le médecin prescrive systématiquement d’antibiotique : ils ne sont pas efficaces contre les maladies virales.Les mesures d’hygiènes simples sont les meilleurs traitement préventifs : lavage des mains, pour éviter la transmission des infections alimentaires, éternuer dans ses coudes lors d'un Éternuement et non pas dans ses mains afin de ne pas les « contaminer » par d'éventuels microbes… Il est parfois nécessaire de prendre des médicaments à titre préventif, comme les médicaments contre le paludisme lors d’un voyage dans un pays impaludé.La détection précoce d’une maladie permet de démarrer son traitement plus tôt et donc de réduire la mortalité ; il est recommandé de faire au moins une visite médicale par an.
En cas de doute sur une infection (par exemple plaie souillée, accident d’exposition au sang, rapport sexuel non protégé), le médecin pourra mettre en place un traitement préventif pour diminuer les risques de développement d’une maladie.
Pour les maladies sexuellement transmissibles, il existe en France des centres anonymes et gratuits de dépistage.Certains patients doivent être isolés (voire mis en quarantaine) pour éviter la dissémination du germe : ainsi, lors d’une varicelle, l’enfant ne doit pas aller à l’école pendant 15 jours à partir de la première éruption.
La prévention hospitalière des infections nosocomiales est un sujet complexe.
Elle repose essentiellement sur l’hygiène des soignants et des soignés (lavage des mains), sur l’isolement des patients porteurs de germes résistants aux antibiotiques, mais aussi sur une antibiothérapie ciblée et adaptée.Une nouvelle approche en phase d'étude est d'utiliser la phagothérapie à des fins préventives pour la santé humaine comme cela se fait déjà dans l'agriculture et l'industrie alimentaire.Leur étude relève de l'épidémiologie et pour les zoonoses ainsi que de l'écoépidémiologie.Certaines situations (crises sanitaires ou alimentaires…) ou lieux (ports, aéroports) sont des facteurs de risques.Le traitement par antibiotiques est le traitement qui a permis de vaincre les maladies infectieuses jusqu'à l'apparition des bactéries multi-résistantes.Il présente de nombreux avantages dont la possibilité d'une fabrication en masse, rapide et bon marché des médicaments antibiotiques.Il trouve ses limites avec l'apparition de bactéries de plus en plus résistantes.La phagothérapie est apparue au début du XXe siècle avec le développement par le Français Félix d'Hérelle de médicaments bactériophagiques réalisés à partir de virus bactériophages (simplement appelés bactériophages ou même phages) lytiques afin de traiter certaines maladies infectieuses d’origine bactérienne.
D'Hérelle a ainsi traité des épidémies de peste et de choléra avec succès.La phagothérapie a été largement utilisée dans le monde avant la découverte des antibiotiques.
Si elle a été progressivement abandonnée par les pays occidentaux séduits par les avantages de l’antibiothérapie, la phagothérapie traditionnelle est toujours employée et développée dans les pays de l'ancienne Union Soviétique.
Dans les pays occidentaux, des patients victimes d'infection par bactéries multi-résistantes se regroupent pour faciliter l'accès aux traitements bactériophagiques étrangers,,.Elle connaît un regain d'intérêt en Occident avec l'émergence de l'antibiorésistance.
Elle fait l'objet de recherches à l'Institut Pasteur mais son utilisation demeure soumise à ATUn par l'ANSM.
Vache est le nom de la femelle adulte de l'espèce Bos taurus, un ruminant appartenant à la famille des bovidés.Par extension, surtout en élevage laitier, ce nom est utilisé pour désigner l'espèce dans son entier, peut-être parce qu'il s'agit du sexe considéré comme productif, et est dans ce cas synonyme de Bos taurus.Les individus mâles sont appelés taureaux, ou bœufs s'ils sont castrés ; et les jeunes, veaux.
Une génisse ou vachette, appelée aussi taure au Québec ou dans le Poitou, est une vache qui n'a pas vêlé.
Descendant de plusieurs sous-espèces d'aurochs, les bovins actuels (zébus compris) sont élevés pour produire du lait et de la viande, ou comme animaux de trait.
En Inde, la vache est sacrée.
Le mot vache vient du latin vacca, de même sens,.En dehors de Bos taurus qui comprend aussi le zébu (Bos taurus indicus) et leur ancêtre l'aurochs (Bos taurus primigenius), le mot vache peut désigner la femelle du bison (Bison spp.)
de même que bisonne, celle du yack (Bos grunniens) ou « vache de Tartarie » qui peut aussi désigner l'espèce dans son entier, et celle de l'orignal (Alces americanus).
Par contre la femelle du buffle, qui ressemble beaucoup à une vache, est toujours appelée bufflonne ou bufflesse.Le poids moyen d'une vache adulte varie en fonction de la race de 500 à 900 kg.
Elle est plus petite que le taureau.Les bovins n'ont pas d'incisives supérieures, ils ne peuvent pas très bien mordre l'herbe et leurs dents servent principalement à broyer la nourriture.
Pour se nourrir, les bovins utilisent leur langue pour ramasser l'herbe, puis la pincer entre leurs incisives inférieures et leur bourrelet gingival.« En moyenne, la vache marche et broute un tiers du temps, rumine dans un état de somnolence un autre tiers du temps et se repose le dernier tiers, ventre au sol, pattes antérieures repliées.
»Alors que les taureaux sont destinés principalement à la boucherie et rarement à la reproduction, les vaches sont le plus souvent destinées à assurer le renouvellement du troupeau ou la production de lait.
La vache est élevée soit pour son lait (races de vaches laitières), soit pour la production de viande (races à viande ou « allaitantes »), soit pour les deux (races mixtes).Comme tous les mammifères, une vache ne peut donner du lait qu'à partir du moment où elle a mis bas.
Avant d'avoir eu son premier veau, la jeune femelle est appelée génisse.Les vaches laitières sont normalement mises à l'engraissement et envoyées à l'abattoir (vaches de réforme) vers l'âge de 8 ans.
Elles fournissent en France l'essentiel de ce qui est commercialisé sous la dénomination « viande de bœuf » (80 % en 2013).
La France comptait 18,9 millions de vaches en 2006 et 18,7 millions de têtes de vaches en France en 2011.
35 % du cheptel (toutes vaches confondues) vit dans le centre de la France.
39 % du même cheptel est en Bretagne, Pays de la Loire et Basse-Normandie.La Prim’Holstein est la race laitière la plus répandue en France.De 1985 à 2011, le nombre de vaches allaitantes a augmenté, passant de 3 339 000 à 4 108 000 têtes (soit +23 % en 26 ans).
Dans le même temps le nombre de vaches laitières est passé de 6 538 000 à 3 678 000 têtes (soit -44 %).C'est après fin 2003 que le nombre de vaches allaitantes a dépassé le nombre de vaches laitières.Répartition des laitières et allaitantes par région : fort nombre de têtes de vaches allaitantes en Pays de Loire, ainsi que dans la diagonale Bourgogne, Massif-Central, Midi-Pyrénées.
Et fort nombre de têtes de vaches laitières à l'Ouest (Bretagne, Pays de la Loire, Basse-Normandie).Près de deux millions de veaux de boucherie (ou veaux de lait) sont abattus chaque année en France, dont la plus grande partie provient du cheptel de vaches laitières.En Inde, une grande partie de la population considère traditionnellement les vaches comme des animaux sacrés.
Elles sont libres de se promener dans les rues et jusque sur les autoroutes.
Elles ne sont pas destinées à être mangées mais fournissent le lait nécessaire aux rituels religieux.
Le barattage de la mer de lait est un des mythes de la cosmogonie indienne.
La vache Audhumla est un mythe cosmogonique de la mythologie scandinave.La sourate Al-Baqara (en arabe : سورة البقرة, Sūratu al-Baqarah, « La vache ») est la deuxième et la plus longue sourate du Coran.
Le nom de « sourate de la vache » fait référence à un différend entre Moïse et les Israélites à propos d'une vache qu'ils doivent sacrifier afin de connaître le meurtrier d'un homme tué.
Ne pas confondre avec l'incident biblique où Moïse interdit d'adorer le veau d'or.La Torah fait référence au rite de la Vache rousse.Proverbe : « À chacun son métier, et les vaches seront bien gardées.
»Expressions :Voir aussi : Idiotisme animalier.
La fièvre est l'état d'un animal, à sang chaud (endotherme) ou à sang froid (ectotherme), dont la température interne est nettement supérieure (hyperthermie) à sa température ordinaire, de façon contrôlée.Chez les endothermes (essentiellement les mammifères et les oiseaux), ce phénomène physiologique semble être principalement une réponse hypothalamique stimulée par des substances pyrogènes principalement libérées par les macrophages et/ou lors des phénomènes inflammatoires.Chez l'humain, la fièvre accroît les défenses par plusieurs voies complémentaires : elle stimule l'immunité spécifique et non spécifique et la microbiostase (inhibition de la croissance) en diminuant le fer disponible pour les micro-organismes pathogènes afin de diminuer leur virulence.
Le phénomène se déroule suivant trois phases :La température corporelle normale moyenne des humains est de 37 °C (entre 36,5 et 37,5 °C selon les individus et le rythme nycthéméral).
La fièvre est définie par une température rectale au repos supérieure ou égale à 38,0 °C.
S'il n'existe pas de consensus concernant un seuil à partir duquel la fièvre elle-même serait dangereuse, certains auteurs estiment en se basant sur des données animales que le système nerveux central pourraît présenter des signes de souffrance à partir de 41,5 °C.
Lorsque la fièvre est modérée, entre 37,7 et 37,9 °C, on l'appelle fébricule.Chez certains ectothermes, la fièvre s'obtient en se déplaçant dans des zones plus chaudes ; cette fièvre est qualifiée de comportementale.Il n'existe pas de définition précise universellement admise de la fièvre notamment du fait de difficultés concrètes de mesure en situation clinique (la température mesurée dépend du moment de la journée, de la proximité d'un repas, de caractéristiques environnementales).
Cependant, le Brighton Collaboration Fever Working Group s'accorde à la définir en 2004 comme relevant d'une température corporelle supérieure ou égale à 38 °C, et ce quelles que soient les modalités de mesure, l'âge ou les conditions environnementales.
L'OMS de son côté, considère comme fiévreuse une température axillaire supérieure ou égale à 37,5 °C,,.La température corporelle se mesure à l'aide d'un thermomètre médical.
Suivant le placement de celui-ci, on parle de :La température buccale et la température axillaire étant moins élevées que la température rectale, prise comme référence, des corrections doivent être appliquées (+0,5 °C pour la buccale, +0,7 °C pour l'axillaire).L'état d'homéothermie est maintenu par une commande centrale exercée par la partie antérieure de l'hypothalamus (« thermostat hypothalamique »).
L'hypothalamus reçoit des informations provenant des neurones associés aux thermorécepteurs périphériques, et aussi du sang circulant.
En retour l'hypothalamus envoie des informations vers les neurones périphériques qui contrôlent les pertes de chaleur (vasodilatation périphérique et sudation) ou la production de chaleur (frissons musculaires).La fièvre est une hyperthermie qui dépend du contrôle hypothalamique, et qui se traduit par un trouble de régulation des mécanismes de perte ou de production de chaleur.
L'augmentation de température par le thermostat résulte de l'effet de substances sanguines dites pyrogènes, exogènes ou endogènes.Les pyrogènes exogènes proviennent de micro-organismes infectants, comme l'endotoxine des bactéries gram-négatives, ou les toxines des bactéries gram-positives, soit par action directe sur le thermostat, soit par action indirecte en activant la production de pyrogènes endogènes par les cellules de l'hôte (leucocytes).Les leucocytes peuvent produire des pyrogènes endogènes capables d'induire un état fébrile.
Il s'agit de protéines solubles de la famille des cytokines, parmi les plus importantes : l'interleukine 1, le TNF, les interférons...
La plupart des cellules de l'organisme, soumises à des stress cellulaires, peuvent produire des pyrogènes.
Ceci explique que tout état fébrile n'indique pas forcément une maladie infectieuse.Les cytokines agissent sur des récepteurs spécifiques présents sur toutes les cellules de l'organisme, comme les récepteurs Toll qui activent les mécanismes inflammatoires.
Ces derniers se traduisent notamment par une extravasation des leucocytes et leur migration vers les tissus pour neutraliser l'agent agresseur.
Lorsque l'agression est maitrisée par les réponses inflammatoires et immunitaires, le thermostat hypothalamique induit un retour de la température corporelle à la normale.La fièvre est donc considérée comme une réaction de défense de l'organisme contre une agression microbienne, physique ou chimique, qui s'est conservée tout au long de l'évolution des vertébrés.
Son avantage se voit le plus clairement chez les poissons et les poikilothermes (animaux « à sang froid ») qui résistent mieux aux infections en augmentant la température de leur corps.
Chez les mammifères, les avantages sont plus faibles (l'augmentation étant relativement plus limitée).
De plus une fièvre très élevée (supérieure à 41 °C) peut léser le système nerveux central, d'où un probable système de régulation empêchant que la fièvre ne dépasse un certain plafond.La fièvre est un signe médical fréquent.
Il appartient au médecin d'essayer de la rattacher à une étiologie (diagnostic) et d'évaluer sa gravité.Pour établir un diagnostic devant ce signe le médecin recherchera ses caractéristiques sémiologiques : homme / femme - âge - antécédents - ethnie - facteurs de risques - caractère aiguë / prolongée - lieu de séjour - fièvre isolée ou regroupement syndromique - incidence et prévalence locales et saisonnières, etc.En médecine générale, le plus souvent (voir carré de White) la fièvre conduira vers un diagnostic de pathologie bénigne.La cause de la fièvre peut être infectieuse (bactérie, virus ou parasite) ou non infectieuse (par exemple Vascularite, thrombose veineuse profonde ou effet secondaire).
La fièvre due à une infection bactérienne est généralement plus élevée que celle due à un virus.Malgré leurs faibles prévalences dans les pays occidentaux, il est indispensable que le médecin sache écarter des atteintes particulièrement graves :Voici ce que constate l'ANSM sur la fièvre de l'enfant, par la plume d'Aude Chaboissier : Au cas par cas (par exemple : antécédents convulsifs, allergie, comorbidité, fiabilité de l'entourage, traitements associés, etc.) le médecin doit peser le rapport entre les bénéfices attendus et les risques encourus (hépatotoxicité, cardiotoxicité, syndrome de lyell, choc anaphylactique, cellulite faciale, etc.) avant de prescrire ou non des antipyrétiques.Attitudes pratiques pour la prise en charge d'une fièvre persistante supérieure à 38,5 °C :Ces recommandations concernent le confort de l'enfant et ne font ni baisser, ni n’élèvent la température car le thermostat hypothalamique mettra en marche les mécanismes de thermogenèse (si l'enfant est trop refroidi) et de thermolyse (si l'enfant est dans un environnement trop chauffé) afin de laisser le corps à la température prévue tant que les mécanismes immunitaires seront activés.Devant une fièvre de l'enfant, dans les pays occidentaux, il est fréquent de demander un avis diagnostic auprès d'un médecin généraliste pour affirmer le caractère bénin de l'épisode afin que l'enfant puisse être pris en charge par des adultes rassurés.Toutefois, un diagnostic médical est primordial si la fièvre de l'enfant présente des caractéristiques inhabituelles : nourrissons, fièvre plus élevée qu’habituellement, durée et évolution inhabituelle, comportements inhabituels (pleurs continus, fatigue, agitation, etc.), teint inhabituel, éruptions cutanées, signes d'accompagnements (vomissements, etc.), épidémie locale de pathologies potentiellement graves (méningite, etc.).
La poussée dentaire n'est pas une cause de fièvre.Au-dessus de 40 °C, la température peut être un signe de maladie grave et peut être mal tolérée par l'organisme : Exemple : chez les personnes ayant une prédisposition, le risque de convulsion augmente.Chez le jeune enfant, cette fièvre peut entraîner des convulsions qui, si elles sont impressionnantes, sont en général bénignes ; il faut toutefois impérativement éviter que cette situation ne se prolonge, il faut donc abaisser lentement la température de l'ensemble du corps.On préconisait auparavant de donner systématiquement des bains d'eau dont la température est de 2 °C en dessous de la température du bébé, et la prescription médicale consistait souvent en une bithérapie aspirine-paracétamol ; la chute de la température était une priorité avec trois objectifs : empêcher le développement de l'hyperthermie maligne, éviter les convulsions fébriles et améliorer le confort de l'enfant.Cependant, aucune étude récente n'a mis en évidence l'effet des antipyrétiques pour la prévention des convulsions, et par ailleurs, seuls certains enfants (2 à 5 %) sont sujets aux convulsions.Une fièvre réelle (supérieure à 38 °C) chez un enfant doit toujours donner lieu à une consultation médicale, mais rarement aux urgences de l'hôpital sauf pour les nourrissons de moins de 3 mois.Il convient de prendre contact rapidement avec un médecin (le Samu en France) afin d'avoir des conseils et éventuellement une intervention médicalisée en présence de signes de gravité tels que : Avant d'aller consulter un médecin, il est nécessaire d'attendre 24 h pour un enfant entre 4 mois et moins de 2 ans puis 48 h pour un enfant de 2 ans et plus, sauf si les symptômes s'aggravent.La fièvre ayant un rôle dans la lutte contre l'infection, pour un enfant n'étant pas sujet aux convulsions et hors urgence (voir ci-dessus), l'administration d'antipyrétique n'est plus systématique, et n'est envisagée qu'à partir de 38,5 °C.
On conseille alors plutôt le paracétamol en monothérapie,,.L'utilisation de l'ibuprofène chez l'enfant est controversée,.
Il peut y avoir des effets secondaires rares mais graves chez l'enfant varicelleux.Par le passé, la fièvre a pu être délibérément provoquée dans un but de guérison.
C'est ce que l'on a appelé « la pyrothérapie ».
C'est le Dr Konteschweller Titus qui forgea le mot « pyrétothérapie » en 1918 rappelant notamment à cette fin l'usage du vaccin contre la typhoïde.
Cette approche obtint une certaine reconnaissance avec la mise au point par Julius Wagner-Jauregg de la malariathérapie pour la guérison de la syphilis (cela lui valut le Nobel en 1927).
D'autres procédés ont été utilisés,,,, que l'avènement des antibiotiques notamment ont relégué dans un oubli presque total.
Dans les dernières années cependant – notamment dans le domaine de la lutte anticancéreuse – la réévaluation de la littérature à l'aune des connaissances contemporaines suscite un regain d'intérêt pour la - fever therapy, pyrétothérapie ainsi que pour la thermothérapie (élévation de la température par voie externe),.Tout comme chez les organismes endothermes, chez les ectothermes, la température de la fièvre augmente la capacité défensive de l'hôte en diminuant le taux de réplication des pathogènes et en augmentant l'efficacité du système immunitaire.
En effet, la fièvre est une défense immunitaire ancienne avec des mécanismes physiologiques apparemment bien conservés au sein d'une large diversité de taxons d'invertébrés et de vertébrés.
Pour ce faire, certains ectothermes modifient leurs comportements habituels assurant leur thermorégulation : ils se placent dans des endroits chauds afin d'élever leur température.
Ce mécanisme, nommé fièvre comportementale a été identifié dans les années 1970 chez les iguanes du désert, les crapets arlequins et les têtards.
Il concerne aussi les poissons et les insectes.
Il permet aux insectes fébriles d'acquérir une survie et une fécondité supérieures aux non fébriles, mais l'atteinte et le maintien de la température élevée exigent des efforts coûteux pour l'organisme, parfois mortels.Dans le cas d'une infection fongique par Beauveria bassiana de la Mouche domestique, les hautes températures ont un effet négatif sur la croissance du champignon.
Au petit matin, lorsque le champignon s'est développé à sa température optimale tout au long du cycle de la nuit, les immunosuppresseurs sont à des niveaux élevés et la réponse fébrile est la plus intense, pendant au maximum deux heures.
À mesure que les facteurs immunitaires exogènes sont réduits ou éliminés de l'hémolymphe, la mouche se déplace progressivement vers des zones plus fraîches.
Pendant la nuit, le champignon se rétablit, car la mouche ne peut pas exprimer de fièvre pour supprimer la croissance fongique.
Et le cycle recommence le lendemain.
La Mouche domestique provoque également des intensités de fièvre différentes, sélectionnant des températures plus élevées lorsqu'elle est infectée par une dose fongique plus élevée, montrant ainsi une capacité à gérer le bénéfice-risque de la fièvre.
Les algues /alg/ sont des organismes vivants capables de produire de la photosynthèse oxygénique et dont le cycle de vie se déroule généralement en milieu aquatique.
Elles constituent une part très importante de la biodiversité et la base principale des chaînes alimentaires des eaux douces, saumâtres et marines.
Diverses espèces sont utilisées pour l'alimentation humaine, l'agriculture et l'industrie.Les algues ne constituent pas un groupe évolutif unique, mais rassemblent toute une série d'organismes pouvant appartenir à des groupes phylogénétiques très différents.
De fait, les algues ont souvent été définies par défaut, par simple opposition aux végétaux terrestres ou aquatiques pluricellulaires.L'étude des algues s'appelle la phycologie.
Le terme d'algologie est parfois utilisé, mais il désigne également la branche de la médecine qui traite de la douleur.De nombreuses estimations ont fait varier le nombre d’espèces d’algues de 30 000 à plus d'un million.
Malgré les incertitudes quant aux organismes qui devraient être considérés comme des algues, un inventaire établi en 2012, d'après la base de données AlgaeBase (qui inclut 15 phyla et 64 classes mais ne prend pas en compte les quelque 200 000 espèces de diatomées, microalgues siliceuses), recense 72 500 espèces d’algues différentes.Le mot « algue » est issu du mot latin alga de même signification.
Bien que certaines spéculations le rapprochent du latin algēre, « avoir froid », aucune raison connue ne permet d'associer les algues à la température.
Une source plus vraisemblable serait *allĭga « liant, entrelaçant » (dérivé de adlĭgātĭo action de lier).Le mot grec ancien pour « algue » est φῦκος / phŷkos, ce qui pouvait signifier soit l'algue elle-même (probablement une algue rouge), soit un colorant rouge qui en dérive.
En effet, la latinisation fūcus désignait avant tout le rouge cosmétique.
Son étymologie est également incertaine, mais un candidat potentiel est le terme hébreux biblique פוך / pūk, « peinture », un fard à paupières utilisé par les anciens égyptiens et d'autres habitants de Méditerranée orientale.
Il pourrait alors s'agir de n'importe quelle couleur : noir, rouge, vert ou bleu.L'étude moderne des algues, marines ou d'eau douce, est appelée soit phycologie, soit algologie, selon que la racine grecque ou latine est utilisée.
Le mot fucus est repris dans un certain nombre de taxons.Jusque dans les années 1960, la classification du monde vivant comportait un « règne végétal » subdivisé en thallophytes (taxon dans lequel était inclus les algues) et les cormophytes.
Ces taxons étaient des regroupements artificiels d'organismes très divers sur la base de ressemblances morphologiques, et sont devenus obsolètes.
La définition des algues est liée à l'histoire des sciences et des classifications et répond plus à des nécessités pratiques qu'elle n’est cohérente.
Le terme collectif d'algues est en effet une dénomination commode permettant de regrouper des organismes photosynthétiques inféodés aux zones humides mais plusieurs groupes algaux n'ont pas d'ancêtre commun direct (groupes polyphylétiques, disséminés en plusieurs lignées évolutives bien distinctes au sein du domaine des eucaryotes),.Dans l'acception la plus large du terme, les algues rassemblent :La morphologie est donc très diversifiée : de nombreuses espèces sont unicellulaires, éventuellement mobiles, d'autres forment des filaments cellulaires ou des lames simples, d'autres développent des architectures complexes et différenciées, par apposition cellulaire ou par enchevêtrement de filaments tubulaires.
Les algues ne possèdent cependant pas de tissus nettement individualisés, comme on peut en trouver parmi les végétaux terrestres vasculaires.
Les couleurs des algues, qui peuvent être très variées (verte, jaune, rouge, brune...) ont servi, dans le sillage de Lamouroux à désigner les différents « groupes » taxinomiques d'algues.Bien que pouvant appartenir à des groupes non apparentés, les algues peuvent constituer des groupes écologiques pertinents : les macroalgues marines ou d'eau douce, le phytoplancton, le périphyton, le phytobenthos, etc.Certaines algues contribuent à des formes symbiotiques stabilisées très répandues dans la nature, telles que les lichens et les coraux zooxanthellés, mais certaines espèces peuvent aussi être impliquées dans des formes de symbioses plus rares ou plus insolites, par exemple avec certaines éponges d'eau douce comme Spongilla lacustris, avec des mollusques nudibranches comme Phyllodesmium longicirrum et même, cas unique connu chez les Vertébrés, avec la salamandre maculée Ambystoma maculatum.Il existe quelques cas d'algues parasites.Tous les végétaux aquatiques ne sont cependant pas des algues.
Plusieurs groupes de plantes terrestres se sont adaptés à une existence immergée en eau douce (des mousses, les fougères Hydropteridales, diverses Spermaphytes dont les Potamogetonacées, les Hydrocharitacées, les Utriculaires, etc.).Quelques familles de plantes à fleurs vivent même exclusivement ou partiellement dans la mer (Zostéracées, Posidoniacées, Cymodoceaceae, certaines Hydrocharitaceae, Ruppiaceae et Zannichelliaceae) constituant des herbiers marins.À l'inverse, de nombreuses algues unicellulaires ont conquis des habitats terrestres très diversifiés, pourvu qu'ils soient au moins un peu humides.Ainsi, Chlamydomonas nivalis vit dans les glaciers.
Des algues verdissent de nombreuses écorces d'arbres.
L'algue Klebsormidium est fréquemment trouvée sur les façades d'Europe ainsi que d'autres espèces selon Ortega-Calvo et al.
(1991) ; Rindi et Guiry (2004) ; Barberousse (2006) et Rindi (2004),, dont Trentepohlia, Trebouxia, Prasiola et Chlorella ou encore une espèce du genre Trentepohlia est responsable des traînées rougeâtres sur le ciment de poteaux électriques, de murs ou sur le crépi de mortier appliqué sur certaines façades de bâtiments, par exemple assez fréquemment dans l'ouest de la France.
Des murs peuvent être teintés de jaune-orangé, brun ou bordeaux en raison de la présence de caroténoïdes et de produits de dégradation de la chlorophylle (les phycobiliprotéines) issus d’algues, de cyanobactéries et de microchampignons.
La colonisation de crépis par des bactéries chemo-organotrophiques et/ou les produits de dégradation des cyanobactéries et des algues enrichies en fer provoque une coloration rouge et rose des façades selon Warscheid et Braams (2000), cités par Estelle Dalod dans sa thèse sur l'influence de la composition chimique de mortiers sur leur biodétérioration par les algues.Traditionnellement, on classait les cyanobactéries parmi les algues, référencées comme cyanophytes ou algues bleu-vert, bien que certains traités les en aient exclues.
Elles apparaissent déjà dans des fossiles du Précambrien, datant d'environ 3,8 milliards d'années.
Elles auraient joué un grand rôle dans la production de l'oxygène de l'atmosphère.
Leurs cellules ont une structure procaryote typique des bactéries.
La photosynthèse se produit directement dans le cytoplasme.
Lorsqu'elles sont en symbiose avec un champignon, elles forment un lichen.Elles sont à l'origine des chloroplastes des cellules eucaryotes, et ont ainsi permis aux végétaux de réaliser la photosynthèse, à la suite d'une endosymbiose.Toutes les autres algues sont eucaryotes.
Chez-elles, la photosynthèse se produit dans des structures particulières, entourées d'une membrane, qu'on appelle chloroplastes.
Ces structures contiennent de l'ADN et sont similaires aux cyanobactéries validant l'hypothèse de l'endosymbiose.Trois groupes de végétaux ont des chloroplastes « primaires » :Dans ces groupes, le chloroplaste est entouré par 2 membranes.
Ceux des algues rouges ont plus ou moins la pigmentation typique des cyanobactéries, alors que la couleur verte, et celle des plantes supérieures, est due à la chlorophylle a et b. L'analyse biochimique des membranes permet raisonnablement de soutenir l'hypothèse que ces groupes ont un ancêtre commun, c'est-à-dire que l'existence des chloroplastes serait la conséquence d'un seul événement endosymbiotique.Deux autres groupes, les Euglénophytes et les Chlorarachniophytes, ont des chloroplastes verts contenant de la chlorophylle a et b. Ces chloroplastes sont entourés, respectivement, de trois ou quatre membranes et furent probablement acquis de l'incorporation d'une algue verte.
Ceux des Chlorarachniophytes contiennent un petit nucléomorphe, reste du noyau de la cellule.
On suppose que les chloroplastes des Euglénophytes ont seulement 3 membranes parce qu'ils furent acquis par myzocytose plutôt que par phagocytose.Les autres algues ont toutes des chloroplastes contenant des chlorophylles a et c.
Ce dernier type de chlorophylle n'est pas connu du moindre procaryote ou chloroplaste primaire, mais des similarités génétiques suggèrent une relation avec l'algue rouge.
Ces groupes comprennent :Dans les trois premiers de ces groupes (Chromista), le chloroplaste a 4 membranes retenant un nucléomorphe chez les Cryptophytes, et on suppose maintenant qu'ils ont en commun un ancêtre coloré.
Le chloroplaste des Dinoflagellés typiques a 3 membranes, mais il y a une diversité considérable dans les chloroplastes de ce groupe, quelques membres ayant acquis leurs plastes par d'autres sources.
Les Apicomplexa, un groupe de parasites étroitement apparentés, ont aussi des plastes dégénérés appelés apicoplastes, différents toutefois des véritables chloroplastes, qui semblent avoir une origine commune avec ceux des dinoflagellés.Quelques genres, classés selon Catalogue Of Life :ProkaryotaRègne BacteriaEukaryotaRègne ChromistaRègne PlantaeRègne ProtozoaUn des projets collaboratifs de Tela botanica porte sur la création d'une base de données Algues pour les algues (macroalgues et microalgues marines, saumâtres, dulçaquicoles et terrestres) de France métropolitaine, et éventuellement ensuite des territoires d'outre-mer.La plupart des algues les plus simples sont unicellulaires flagellés ou amoeboïdes, mais des formes coloniales et non-mobiles se sont développées indépendamment dans plusieurs de ces groupes.
Les niveaux d'organisation les plus courants, dont plusieurs peuvent intervenir dans le cycle de vie d'une espèce, sont les suivants :Des niveaux plus élevés d'organisation ont même été atteints, menant à des organismes avec des différenciations complètes des tissus.
Ce sont les algues brunes qui peuvent atteindre 70 m de long (varech) ; les algues rouges et les algues vertes.
Les formes les plus complexes se trouvent chez les algues vertes (voir Charales), dans une lignée qui a conduit aux plantes supérieures.
Le point où ces dernières commencent et où les algues s'arrêtent est marqué habituellement par la présence d'organes reproductifs munis de couches de cellules protectrices, une caractéristique qu'on ne trouve pas dans les autres groupes d'algues.Les algues constituent, avec les bactéries et le zooplancton, une part essentielle importante de l'écologie aquatique et de l'environnement marin notamment.
Elles ont adopté des modes de vie très divers, certaines vivant même hors de l'eau.
Grâce à des spores résistantes, nombre d'entre elles ont une capacité exceptionnelle de résistance.
Le vent, les embruns et les oiseaux migrateurs contribuent à leur dispersion.Les algues jouent un rôle fondamental dans le cycle du carbone.
En effet, elles fixent le carbone atmosphérique via la photosynthèse et contribuent ainsi à limiter l'effet de serre.Bien qu'elles soient toutes pourvues de chlorophylle, elles peuvent être autonomes (autotrophes ou saprophytes), parasites, ou vivre en symbiose.Les macroalgues croissent surtout dans les eaux peu profondes et procurent des habitats différents.
Les microalgues, qui composent le phytoplancton, sont à la base de la chaîne alimentaire marine.
Le phytoplancton peut être présent en forte densité là où les nutriments sont abondants, par exemple dans les zones de remontée d'eau ou eutrophisées.
Elles peuvent alors former des efflorescences, et changer la couleur de l'eau.Les marées vertes qui peuvent couvrir certaines plages d'un matelas nauséabond de quelques décimètres d'épaisseur et de quelques mètres voire dizaines de mètres de large, sont dues à la prolifération d'algues vertes, essentiellement Ulva lactuca, dans un milieu enrichi en nitrates par le ruissellement dans les zones d'agriculture intensive ou par un traitement insuffisant des eaux usées de zones urbaines.La consommation animale de populations algales est le fait de filtreurs (microalgues, spores d'algues), de brouteurs d'algues (animaux marins qui raclent ou sucent, à l'aide de leur radula, les algues microscopiques, les jeunes germinations des macroalgues) ou de patureurs (animaux broutant des morceaux de macroalgues, principalement les poissons phytophages).
La pression animale sur ces populations provient essentiellement des animaux de la zone de balancement des marées qui ont également une répartition étagée : Mollusques Gastéropodes (Littorines, aplysies, Gibbules, Troques, Pourpres, Patelles) et des Crustacés Cirripèdes représentés par plusieurs espèces de Balanes.Les algues offrent des supports à l'épifaune fixée (ascidies, vers polychètes), abritent une macrofaune vagile (crabes, oursins) et une microfaune importantes servant de nourriture à différents prédateurs (poissons, crustacés).Le plus ancien document attestant de l'usage médicinal des algues remonte en Chine avec le Shennong bencao jing, ouvrage traitant des drogues végétales, animales et minérales et dont la paternité a été attribuée à un empereur mythique Shennong vivant aux environs de 2800 av.
Un chapitre entier de ce livre traite des algues et recommande notamment l'usage d'algues brunes riches en iode (Laminaria digitata, Laminaria saccharina, Fucus vesiculosus, Sargassum) dans le traitement du goitre, réalisant une iodothérapie avant la lettre.
L'auteur chinois Sze Teu écrit en 600 av.
« certaines algues sont les seuls mets dignes de la table d'un roi » mais la civilisation gréco-romaine se montre moins enthousiaste pour les végétaux marins (la seule exception étant les matrones romaines qui destinent le Fucus à des usages cosmétiques.
Ainsi Virgile écrit dans l’Énéide « nihil vilior alga » (rien de plus vil que les algues).L'exploitation des goémons comme engrais remonte au moins au haut Moyen Âge en France.
L'exploitation du varech devient industrielle à partir du XVIe siècle.Légume méprisé car situé en bas de la chaîne des êtres d'Aristote, l'algue est parfois consommée par les populations littorales pour faire face aux difficultés et aux menaces de disettes, cette consommation étant supplantée par celle de la pomme de terre dont la culture s'étend en Europe pendant toute la première moitié du XVIIIe siècle et contribue à mettre fin aux famines endémiques.Les décennies 1990 et 2000 voient les algues être stigmatisées : les plages doivent en être débarrassées pour les touristes qui veulent des plages « propres » et les marées vertes produisent un effet désastreux sur l'opinion publique ; mais leur retour en grâce est amorcé avec la valorisation de nombreux produits à base d'algues pour l'industrie cosmétique, l'alimentation, la médecine, la thalassothérapie, etc.Une cinquantaine d'espèces d'algues comestibles sauvages ou cultivées sont utilisées pour l'alimentation humaine, soit directement, soit sous forme de compléments alimentaires, soit sous forme d'additifs :Les algues sont aussi une source d'oligo-éléments, notamment de magnésium et d'iode, qui font souvent défaut à l'alimentation dans les pays industrialisés (ceux qui consomment peu de poisson notamment, et qui consomment du sel raffiné dépouillé de son iode naturel).
Elles renferment également des polyphénols antioxydants appelés phlorotanins.Il faut éviter la consommation d'algues qui vivent dans l'eau polluée, car certains polluants sont absorbés par ces végétaux.
C'est le cas par exemple avec les rejets d'eau radioactive près des centrales nucléaires côtières, des centres de retraitement de déchets radioactifs (Windscale en Grande-Bretagne, usine de la Hague en France par exemple) ou des lieux d'expérimentation de bombes atomiques (l'atoll de Moruroa en Polynésie française par exemple) : les teneurs en radionucléides peuvent alors rendre ces algues dangereuses pour la santé.On note l'utilisation ancienne du goémon dans la fabrication de farines et tourteaux incorporés aux aliments composés, pour volailles notamment.En Bretagne, le goémon était utilisé pour l'alimentation des vaches.Le goémon, ou varech, est récolté sur les côtes, notamment en Bretagne depuis très longtemps pour en faire de l'engrais.
Autrefois, il servait aussi à produire de la soude et de la potasse.
Il existe plusieurs façons d'utiliser les algues comme engrais naturels pour l'usage agricole ou de jardinage.Deux usages sont préconisés : l'alternance des types de fumure 1 an sur 2 (algue-fumier animal) ; et une utilisation modérée 2 à 3 kg/m2 ou 20 tonnes par hectare.
Lors du ramassage, il faut prendre en compte le sable associé aux dépôts d'algue d'estran, il peut représenter 25 à 30 % du poids total, et selon la nature du sol à amender, il est susceptible de fragiliser la structure de rétention aqueuse des sols initiaux ou au contraire alléger des sols un peu lourd.Le maërl, ou Phymatolithon calcareum (Lithothamnium calcareum), une algue rouge calcifiée, était utilisé pour l'amendement des sols acides.
Les fonds à maërl sont maintenant protégés.En 2022, près de cinquante sociétés dans le monde développent des composés bioactifs marins extraits d'algues pour élaborer une gamme caractéristique de biostimulants qui limitent l'utilisation d'engrais.
Par exemple, la société Goëmar fait depuis les années 1980 des recherches sur des stimulateurs de la défense des plantes et a mis au point un vaccin à base de laminarine qui a obtenu l'homologation sur plusieurs cultures.C'est probablement à partir d'algues que les biocarburants pourront être produits avec le meilleur rendement, rendant ainsi envisageable une production en quantité significative sans déforestation massive.
Des cultures d'algues unicellulaires à forte teneur en lipides (50 % à 80 % en masse) et à temps de doublement rapide (de l'ordre de 24 h) permettent en effet une production de biodiesel moins polluante et incomparablement plus efficace que l'agriculture intensive de végétaux terrestres : les superficies nécessaires sont 30 fois moindres.Plusieurs techniques de production sont étudiées :Les lipides extraits de cette biomasse peuvent être utilisés :Une limite de cette filière est la nécessité d'alimenter les cultures d'algues en fortes concentrations de CO2.
Tant que ce CO2 sera issu de l'exploitation d'une énergie fossile, on ne pourra pas considérer cette source de biocarburant comme une énergie renouvelable.La microalgue euglena est un exemple tangible de biocarburant à base d'algue.
En effet, en 2015, la société japonaise Euglena (entreprise) fournit quotidiennement un bus en biocarburant, composé à hauteur de 1 % d'euglena.
La société a aussi pour ambition de développer du biocarburant pour avion, et a annoncé vouloir l’utiliser à l’occasion des Jeux olympiques d'été de 2020, mais aucun avion n’a pour le moment volé avec du biocarburant produit par la société,.Les macroalgues marines constituent une source de recherche non négligeable pour les molécules antifouling.
En effet ces organismes sont sujets au biofouling avec l’adhésion de multiples organismes tels que des bactéries, des microalgues, d’autres macroalgues ou encore divers mollusques.
Il y a par exemple entre 102 et 107 cellules.cm−2 de bactéries épiphytes selon les espèces de macroalgues.
Le développement de biofouling peut avoir des effets délétères pour l’algue.
En effet, le recouvrement de leur surface d’échange par les organismes invasifs peut limiter l’accès aux nutriments mais aussi à la lumière, empêchant la photosynthèse.
Les microorganismes adhérés peuvent également être pathogènes pour l’algue et nuire à son développement.
Pour contrer le biofouling, la macroalgue développe donc des moyens de défense chimiques et physiques.
Par exemple, l’algue peut endiguer l’invasion d’organismes en générant des dérivés réactifs de l’oxygène (ROS), mais aussi en sécrétant des métabolites secondaires biocides ou répulsifs (molécules anti-quorum sensing).
Certaines macroalgues présentent également une topographie particulière de surface, recouverte d’une couche mucilagineuse inhospitalière limitant la fixation d’organismes.Les revêtements antifouling écoresponsables peuvent donc s’inspirer des algues pour inhiber l’adhésion des organismes sur une surface, à la fois en imitant leur topographie de surface, mais aussi en y greffant des molécules d’algues à visée antifouling.
Quelques exemples de molécules et leur spectre d’action sont présentés dans le tableau ci-dessous.Certaines substances tirées des algues, notamment l'algine, déjà citée, sont utilisées comme gélifiants, épaississants, émulsifiants, dans de nombreuses industries : pharmacie, cosmétiques, matières plastiques, peintures…L'agar-agar sert de base pour la fabrication des milieux de culture bactériologique.Phymatolithon calcareum (Lithothamnium) fournit un calcaire poreux utilisé pour la filtration de l'eau.La capacité des algues à filtrer l'eau en concentrant ses constituants est également utilisable dans des stations d'épuration des eaux usées (villes) ou des eaux sortant d'installations industrielles (industrie chimique notamment).
Il reste à choisir ce qu'il est fait de ces algues devenues des déchets, en général toxiques.Les alginates sont utilisés dans les pansements gastriques (formation d'un gel surnageant à la surface du contenu gastrique), les pansements destinés aux grands brûlés (activation de la cicatrisation) maintien d'un environnement humide avec un grand pouvoir d'absorption) et les prises d'empreintes dentaires.Les extraits d'algues sont recherchés pour leurs principes actifs (vitamine C, polyphénols…) incorporés dans les crèmes anti-âge hydratantes, régénérantes et anti-UV qui représentent les plus fortes valeurs ajoutées de la filière cosmétique utilisant les algues.
Il est également possible de fabriquer des biomatériaux et matériaux biosourcés à partir d'algues, sans faire appel au pétrole (tensioactifs issus de laminaires dont sont extraits des mannuronates, bioplastiques biodégradables produits à l'aide de microalgues élevées dans les eaux usées, briques composées à 60 % de sargasses.Les principales familles de molécules anti-inflammatoires présentes chez les macroalgues sont les polysaccharides sulfatés, les acides gras polyinsaturés (PUFAs), le vidadol A et B, les caroténoïdes (fucoxanthine, astaxanthine), les alcaloïdes (caulerpine), les terpénoïdes, et la phéophytine a.
La fucoxantine est un dérivé des caroténoïdes et a été isolé chez l’algue brune Myagropsis myagroides.
Des études in vitro sur des lignées cellulaires de macrophages de souris RAW 264 induites par LPS ont permis de montrer qu’il y a principalement inhibition de la production de NO de manière dose-dépendante par la fucoxantine et que ceci est dû à l’inhibition de la transcription de iNOS (en).
Il y a donc inhibition de la sécrétion de cytokine et en particulier de TNFα.
La fucoxanthine réduit aussi la translocation vers le noyau des protéines P50 et P65 et donc la dégradation, dans le cytoplasme, de l’inhibiteur de B (ikB) ce qui induit la diminution de la transactivation du facteur NFkB et inhibe la phosphorylation des protéines kinases mitogènes (MAPKs, JNK, ERK…).
De plus, des tests LDH ont permis d’établir la non cytotoxicité de la fucoxantine.La caulerpine est un alcaloïde bi-indolé.
Plusieurs isomères de la caulerpine ont été isolés chez les rhodophycées et les chlorophycées.
Pour étudier in vivo l’effet anti-inflammatoire de la caulerpine, deux modèles ont été utilisés chez la souris : l’œdème de l’oreille induit par des capsaicines et la l’inflammation du péritoine induite par des carrageenans.
Une inhibition de la formation de l’œdème des oreilles de souris de 56 % est observée lorsqu’il y a eu préalablement traitement à la caulerpine.
De même, il y a réduction de l’inflammation du péritoine chez les souris traitées à la caulerpine.
Des mécanismes d’action similaires à l’indométhacine tels que l’inhibition de COX et des phosphilases A sont possibles.
La caulerpine est aussi antinociceptive, anti-tumorale, régulatrice de croissance et a des propriétés stimulantes pour la croissance de la racine des plantes.Une étude in vitro révèle que la phéophytine a isolée d’Ulva (Enteromorpha) prolifera supprime l’induction de la production d’anion superoxyde par un composé pro-inflammatoire.
La phéophytine inhibe la chimiotaxie des leucocytes ainsi que la formation de l’œdème de l’oreille de souris et ce, in vivo.L’effet cytotoxique d’un ensemble de polysaccharides sulfatés extraits de l’algue Sargassum hemiphyllum a été testé in vitro en mesurant la prolifération cellulaire ainsi que la production de LDH ; il n’y a pas d’effet cytotoxique détectable in vitro.
Des analyses in vitro semblent montrer que les polysaccharides inhibent la formation des médiateurs de l’inflammation tels que les cytokines.
Ces études mènent les chercheurs à penser que les polysaccharides sulfatés interagissent avec la voie de formation du facteur de transcription trimérique NF-kB en séquestrant l'un des monomères à l’extérieur du noyau.Des études ont montré que certaines espèces de microalgues et les métabolites qu'elles produisent auraient une activité neuroprotectrice qui pourraient présenter un intérêt pour le traitement de la maladie d'Alzheimer.Des extraits de l'espèce Chlorella vulgaris, Synechococcus  et Nannochloropsis oculata sont riches en caroténoïdes et protègent le cerveau contre les dommages neuronaux associés au stress oxydant, qui est considérée comme l'un des facteurs qui contribuent au développement de la maladie d'Alzheimer .
Nannochloropsis (en) oculata, Tetraselmis chui (en) et Cocculinella minutissima (en) possèdent de forts effets inhibiteurs sur l'activité de  l'acétylcholinestérase qui dégrade l'acétylcholine responsable de l'amélioration de la mémoire et la cognition.
Un extrait de l'espèce Nannochloropsis oceanica limiterait le stress oxydant induit par l'agrégation des peptides bêta-amyloïdes dans le cerveau et qui nuit à la croissance et à la survie des neurones.En zone intertidale, les algues, qui sont des organismes fixés, sont soumises à de nombreux stress, dont le rayonnement ultraviolet (UV).
Les UV provoquent un stress oxydant en entraînant la formation de dérivés réactifs de l’oxygène (DRO) comme le peroxyde d'hydrogène (H2O2).
Ces DRO peuvent endommager l'ADN, et provoquer la peroxydation des lipides et la carboxylation des protéines au sein des cellules.
À long terme, cela peut engendrer le vieillissement cellulaire, des cancers, ou encore des inflammations.
Afin de tolérer ces stress, les algues possèdent des stratégies d’adaptation comme la synthèse de métabolites secondaires photoprotecteurs.Il existe chez les algues une diversité importante de molécules photoprotectrices, qui agissent de différentes manières : filtres UVA-filtre UVB, molécules induisant la mélanogénèse, molécules réflectrices, anti-oxydantes et cicatrisantes.
Leurs propriétés intéressent de plus en plus les industriels, notamment en cosmétique : l’objectif est de trouver des filtres naturels afin de réduire les filtres chimiques présents dans les crèmes solaires afin de limiter les réactions d’allergies et réduire la pollution des milieux par ces substances.
Les molécules photoprotectrices qui sont le plus fréquemment retrouvées chez les algues sont les acides aminés analogues de la mycosporine ou MAA (pour l'anglais mycosporine-like amino acid).
Pour les algues n’ayant pas de MAA pour se protéger des UV, il existe d’autres types de molécules comme les phlorotanins ou les caroténoïdes.Les MAA sont présents chez de nombreux organismes (mollusques, macroalgues, bactéries, cyanobactéries…).
Les MAA sont de petits métabolites secondaires, d’une grande diversité structurale et possédant la propriété de chromophore : ils ont la possibilité de former un nuage électronique délocalisé pouvant entrer en résonance avec des rayons incidents d’une longueur d’onde donnée.
Par exemple, le porphyra-334, extrait de Porphyra umbilicalis, capte et reflète les UV d’une longueur d’onde de 334 nm (UVA) sans produire de dérivés réactifs de l'oxygène.
Leur synthèse est induite par l’exposition aux rayonnements solaires.Leur propriété photoprotectrice est transmise le long de la chaine trophique jusqu’au consommateur secondaire.
Par exemple, les oursins doivent se nourrir d’algues possédant des MAA afin de conférer à leurs œufs une résistance solaire permettant leur bon développement.
Récemment, une équipe de chercheurs a mis en évidence l’efficacité photoprotectrice des MAA et notamment la porphyra-334 chez des fibroblastes humains.
La porphyra-334 ne semble pas toxique pour ces cellules et semble réduire leur sénescence.
Cette MAA limite le stress en reflétant les radiations UVA, réduisant le stress oxydatif lié à l'exposition aux UV et réduit la synthèse de métalloprotéases matricielles (MMP) impliquées dans la destruction des tissus conjonctifs.
La porphyra-334 est également impliquée dans la capture des DRO impliqués dans les dommages ADN, peroxydation des lipides et carboxylation des protéines.Ainsi les MAA présentent un haut potentiel cosmétique dans la protection solaire et la lutte contre la sénescence cellulaire.Les phlorotanins sont des polyphénols trouvés chez les algues brunes.
Ce sont des oligomères de phloroglucinol avec une variété de combinaison entrainant une diversité importante de ces molécules.Ils ont différents rôles comme la protection contre les herbivores.
Ils sont suspectés de protéger les algues contre les UVB puisque leur spectre d’absorption présente un pic à environ 270 nm (UVB).
En 2011, une équipe de chercheurs a démontré que les phlorotanins avaient un effet photoprotecteur chez des embryons de poisson-zèbre.
En effet, les phlorotanins réduisent la génération de dérivés réactifs de l'oxygène, l’hyperpigmentation et la mort cellulaire liées à une exposition aux UVB chez ces embryons.Des algues unicellulaires microscopiques (Dinoflagellées) peuvent rendre toxiques pour l'homme les mollusques (moules, huîtres, praires, coques, palourdes…) et interdire leur consommation sous peine de troubles gastro-entériques graves ou, plus rarement, d'atteintes neuromusculaires ; c'est un phénomène assez récurrent dans la mytiliculture de l'étang de Thau en Languedoc et sur les côtes de l'océan Atlantique, notamment en Bretagne et en Vendée.Sargassum muticum, algue brune introduite accidentellement en Europe en 1973 avec des huitres japonaises, a colonisé rapidement le littoral atlantique de l'Espagne à la Norvège ainsi que la Méditerranée occidentale jusqu'à Venise.
Elle a remplacé certaines espèces (laminairia saccharina en particulier) et a pu constituer une nuisance importante pour la conchyliculture.
Ce phénomène a été clairement caractérisé pour la première fois dans les années 1970, les pollutions augmentant de manière importante dans les années 1980, avant de se stabiliser dans les années 1990.Caulerpa taxifolia, algue verte tropicale échappée accidentellement du musée océanographique de Monaco est devenue depuis quelques années envahissante en mer Méditerranée au détriment de la végétation autochtone, entre autres les herbiers de posidonie.
Elle présente une faible toxicité et n'est pas consommée par la faune locale.Les goémoniers considèrent comme une « mauvaise herbe » Saccorhiza polyschides, une laminaire très robuste, sans intérêt économique, qui colonise rapidement les rochers dépouillés par l'exploitation des Laminaria digitata.
Le vaccin contre les infections invasives à méningocoque est un vaccin destiné à prévenir les infections dues à Neisseria meningitidis, une bactérie.
Il en existe plusieurs, ciblant différents sérotypes et pouvant être conjugués à des protéines.
L'efficacité du vaccin est importante et ses effets secondaires sont le plus souvent sans gravité.
Il fait partie des vaccins recommandés chez le nourrisson.Neisseria meningitidis est une bactérie responsable d'infections du rhinopharynx, et surtout de formes invasives telles que des méningites, dont la mortalité est de 10 %, et des bactériémies, notamment le purpura fulminans, dont la mortalité est de 20 à 30 % et les séquelles possibles sont une perte de substance cutanée ou une amputation.Les vaccins contre les infections invasives à méningocoque contiennent des polyosides de la capsule bactérienne.
On distingue les vaccins non conjugués et les vaccins conjugués à des protéines (protéine CRM 197, dérivée de la toxine de Corynebacterium diphtheriae, ou anatoxine tétanique).
En France, les vaccins non conjugués disponibles sont les vaccins bivalent, dirigé contre les sérotypes A et C, et tétravalent, dirigé contre les sérotypes A, C, Y et W135.
Une variante de ce vaccin tétravalent - commercialisée sous le nom Nimenrix - est désormais utilisable chez le très jeune enfant, à partir de 6 semaines.
Les vaccins conjugués disponibles sont les vaccins monovalent C et tétravalent A, C, Y et W135.
Ils sont injectables par voie intramusculaire.Les vaccins contre les méningocoques de type B ont été développés plus tardivement.
Ils contiennent une série de protéines immunogènes propre à ce méningocoque.
Deux vaccins sont en cours de test, se différant suivant les protéines, le 4CMenB et le MenB-FHbp.En France, la vaccination recommandée du nourrisson consiste en une injection de vaccin conjugué monovalent C à l'âge de 5 mois puis une deuxième injection à 12 mois.Les vaccins non conjugués sont peu efficaces chez le nourrisson.
Le vaccin bivalent A et C a une efficacité importante après l'âge de 24 mois.Les vaccins conjugués sont efficaces dès le plus jeune âge.
Le vaccin monovalent C a une efficacité évaluée à 93 % avant l'âge de 5 mois, 87 % entre les âges de 5 mois et 2 ans, et 97 % entre les âges de 3 et 16 ans.
L'efficacité reste élevée un an après la vaccination uniquement chez les enfants vaccinés à partir de l'âge de 5 mois.
Le vaccin conjugué tétravalent A, C, Y et W135 a une efficacité évaluée entre 69 et 96 % entre les âges de 11 et 65 ans, variable selon la valence et l'âge du sujet ; la durée de protection est inconnue.Le vaccin 4CMenB dirigé contre le méningocoque de type B, permet de diminuer par trois l'incidence de la maladie sur une durée supérieure à trois ans .
Par contre ce vaccin est inefficace sur le portage du germe.
Les effets indésirables observés après l'injection du vaccin contre les infections invasives à méningocoque peuvent être une douleur, une rougeur ou un œdème au site d'injection, une irritabilité, une fièvre, une céphalée, un malaise.
Les événements graves sont rares : réactions allergiques généralisées, anaphylaxie, atteintes neurologiques (paresthésie, réaction méningée, vertige, convulsion), nausée et vomissement, éruption cutanée, arthralgie et purpura.Le vaccin est contre-indiqué en cas d'hypersensibilité à l'un des composants.
L'injection doit être différée en cas de maladie fébrile aiguë sévère.
Le système immunitaire d'un organisme est un système biologique complexe constitué d'un ensemble coordonné d'éléments de reconnaissance et de défense qui discrimine le soi du non-soi.
Ce qui est reconnu comme non-soi est détruit.Il protège l'organisme des agents pathogènes : virus, bactéries, parasites, certaines particules ou molécules « étrangères » (dont certains poisons), mais est responsable du phénomène de rejet de greffe.Il est hérité à la naissance, mais autonome, adaptatif et doué d'une grande plasticité, il évolue ensuite au gré des contacts qu'il a avec des microbes ou substances environnementales étrangères au corps.On dénombre plusieurs types de systèmes immunitaires parmi les espèces animales, et généralement plusieurs mécanismes immunitaires collaborent au sein d'un même organisme.Pour de nombreuses espèces, dont les mammifères, le système est constitué de 3 couches.
Ses principaux effecteurs sont les cellules immunitaires appelées leucocytes (ou globules blancs) produites par des cellules souches, au sein de la moelle osseuse rouge.
Cette séparation en trois couches n’empêche pas une interaction très importante des couches entre elles:On appelle réponse immunitaire l'activation des mécanismes du système immunitaire face à la reconnaissance de non-soi, agressive ou pas, face à une agression ou à une dysfonction de l'organisme.L'ensemble de ces systèmes (y compris lors de la vaccination) permet la résilience immunitaire, notion qui recouvre la somme des mécanismes efficaces de défense d’un organisme vis-à-vis d’un agent pathogène (du grec pathos : souffrance) ; il se dégrade avec l'âge (Immunosénescence).Le système peut entraîner un dysfonctionnement autoimmune.Toutes les cellules du système immunitaire dérivent d'une cellule souche présente dans la moelle osseuse.
Cette cellule souche donne deux lignées de cellule : la lignée lymphocytaire et la lignée myélocytaire.Les cellules de l'immunité innée sont produites par la lignée myélocytaire.
Les cellules de l'immunité adaptative sont produites par la lignée lymphocytaire.Un seul type de cellule est produite par les deux lignées : la cellule dendritique.La cellule souche multipotente donne le progéniteur lymphoïde (lymphoid progenitor) qui se divise en trois types de cellules :Responsable de la production des hématies et plaquettes, cette lignée donne naissance à des cellules impliquées dans le système immunitaire inné et dans le système immunitaire adaptatif en produisant des cellules portant les antigènes des agents pathogènes pour les présenter aux cellules du système immunitaire adaptatif :L'organisme se défend contre les dysfonctions de ses cellules et les agressions, c'est-à-dire des processus qui ont pour conséquence de détruire des êtres vivants.
Ces agressions peuvent revêtir différentes formes :Le système inné est un mécanisme très rapide de défense aux infections: il permet souvent d'arrêter un agent pathogène ou, du moins, de permettre la mise en route du système adaptatif qui a des armes plus puissantes et plus spécifiques pour arrêter l'agent pathogène.
Il a longtemps été considéré comme un système non spécifique, mais la découverte de récepteurs cellulaires spécifiques de plusieurs familles de pathogènes (comme les bactéries gram-négatives) dans les années 2000 a changé notre regard sur le système inné.Le système immunitaire inné est déclenché par des récepteurs cellulaires reconnaissant des structures moléculaires uniques aux agents pathogènes ou par des molécules signifiant les dégâts.Elles dérivent toutes de la lignée myélocytaire de l'hématopoïèse.
Elles sont parfois regroupées sous le terme de leucocytes phagocytaires ou phagocytes.
Ce terme est très réducteur car il laisse à penser que la seule fonction de ces cellules est la phagocytose, alors qu'elles ont d'autres fonctions essentielles.Ce sont des cellules immunitaires qui reconnaissent les microorganismes grâce à de nombreux récepteurs cellulaires présents à leur surface.
Ces récepteurs permettent aux phagocytes de reconnaître certaines structures présentes à la surface des microorganismes infectieux et d'internaliser ces derniers à l'aide d'une vacuole digestive.
Par la suite, ils fusionnent la vacuole contenant les microbes avec un lysosome.
Les lysosomes peuvent contenir des formes toxique d'oxygène comme du monoxyde d'azote (NO) ou du peroxyde d'hydrogène (H2O2), et ils peuvent aussi contenir du lysozyme et d'autres enzymes digestives qui dégradent des structures microbiennes.Les cellules résidentes sont les premières activées en cas de franchissement de la barrière épithéliale (cutanée, respiratoire ou intestinales) par un microbe.Les macrophages ont une plus grande capacité de phagocytose que les granulocytes neutrophiles, et, lorsqu'ils phagocytent un microorganisme, des voies cellulaires internes les stimulent, ce qui les rend plus efficaces dans leurs tâches.Ces cellules contiennent des granules contenant des substances vasodilatatrices comme l'histamine.
Cette substance en vasodilatant le vaisseau entraîne une diminution de la vitesse de circulation du sang permettant au leucocyte neutrophile de traverser la paroi vasculaire.Les cellules dendritiques qui dérivent aussi des monocytes sont des cellules présentatrices d'antigènes.
Leur rôle est de capturer un microbe au site d'infection, de migrer vers les tissus lymphoïdes et de présenter les antigènes du microbe aux lymphocytes T à l'aide d'une molécule de CMH.
Ce type de molécule joue un rôle très important dans la réaction immunitaire primaire.Les granulocytes neutrophiles représentent 60 à 70 % des leucocytes.
Ils pénètrent dans les tissus infectés pour phagocyter les microbes présents et les détruire.
Généralement, les granulocytes neutrophiles s'autodétruisent en même temps qu'ils détruisent les microbes.
Ils ont normalement une espérance de vie de seulement quelques jours.
Ce sont des cellules présentes dans le sang et capables de migrer vers un site où se produit une infection.Les granulocytes éosinophiles sont présents en très petite quantité dans l'organisme.
Ils ont une faible capacité de phagocytose, mais ils sont essentiels dans le combat contre les parasites présents dans l'organisme.
Ils se lient à la paroi du parasite et libèrent des enzymes qui vont causer des dommages importants à celui-ci.Les leucocytes basophiles sont les plus rares des leucocytes.
Leur taux est si faible que l'absence de leucocyte basophile au cours d'une numération formule sanguine ne doit pas être considérée comme anormale.Les monocytes représentent 5 % des leucocytes.
Ils circulent dans le sang et migrent vers un tissu où ils se transformeront par la suite en macrophages.
Les macrophages et les cellules dendritiques sont des cellules résidentes dans les tissus sous-épithéliaux.Il existe quatre grands groupes de molécules intervenant dans l'immunité innée : les peptides anti-microbiens, le système du complément, l'interféron I alpha et I beta et les protéines de la phase aiguë dont la plus utilisée en pratique médicale est la protéine C reactive.L'introduction d'un agent infectieux, comme une bactérie gram négatif, au cours d'une piqûre à travers la peau déclenche dans les minutes qui suivent la libération de peptides anti-microbiens et de cytokines par les cellules de l'épithélium cutané.Les cellules résidentes de l'immunité innée (macrophage, mastocyte, cellule dendritique) reconnaissent le pathogène par des récepteurs appelés pattern recognition receptor (PRR) ou en français récepteurs de reconnaissance de motifs moléculaires, dont il existe 4 types principaux.
Pour les bactéries gram-négatives, il s'agit d'un récepteur de type Toll (TLR ou Toll Like Receptor).
La bactérie contient sur la surface de sa paroi des lipopolysaccharides spécifiques aux bactéries gram-négatives qui sont reconnus par les TLRs.
Les structures biochimiques reconnues par le TLR sont appelées motifs moléculaires associés aux pathogènes.La liaison TLR-PPR va déclencher des événements qui diffèrent selon le type cellulaire.
Au niveau des mastocytes, elle entraînera la libération d'histamine, celle-ci déclenchant la dilatation des vaisseaux aboutissant à un ralentissement de la circulation sanguine.
Au niveau des macrophages et des cellules dendritiques, elle entraînera la libération des cytokines et des chimiokines; les chimiokines vont attirer les leucocytes une fois que ceux-ci ont traversé l’endothélium de la paroi vasculaire.
La liaison TLR-PPR active une voie de signalisation qui va déclencher une synthèse de protéine anti-microbienne.Le ralentissement du débit sanguin secondaire à la vasodilatation permet aux leukocytes de traverser la paroi.
Outre les leucocytes, les facteurs du complément traversent la paroi participant aussi à la réaction du système inné.
Au niveau cutané, la manifestation clinique de l'infection se traduit par quatre signes : rougeur, chaleur, douleur et œdème.
Ces quatre signes caractérisent la réaction inflammatoire.Si le système inné n'arrive pas à contenir l'infection, la cellule dendritique va se diriger vers un ganglion lymphatique par les canaux lymphatique.
Elle va se maturer au cours du voyage.
Dans le ganglion, elle présentera à la cellule T CD4 + auxiliaire des petits morceaux de 30 à 40 acides aminés de la bactérie phagocytée.
Cette présentation de l’antigène se fait par son complexe majeur histocompatibilité de classe II.L'immunité adaptative repose sur 3 acteurs : les organes lymphoïdes, les lymphocytes B et les lymphocytes T.
Ces 3 acteurs vont permettre de reconnaître un agent pathogène, de le signaler et de déclencher soit l'immunité humorale soit l'immunité cellulaire.
Que ce soit l'immunité humorale ou l’immunité cellulaire, l'immunité adaptative ne se déclenchera que si cet antigène porte aussi un récepteur cellulaire de pathogénicité montrant bien la complexité et l'interaction des deux immunités.Les organes lymphoïdes comprennent le thymus, la moelle osseuse, la rate, les amygdales, l'appendice et les ganglions lymphatiques.Le système immunitaire humoral agit contre les bactéries et les virus avant leur pénétration dans les cellules.
Les cellules responsables de la destruction des pathogènes extra-cellulaires sont les lymphocyte B agissant en sécrétant des anticorps.La production et la maturation des lymphocytes B se fait dans la moelle osseuse.
Les lymphocytes B sont le support de l'immunité humorale.
Ils possèdent à leur surface des récepteurs, nommés BCR, B Cell Receptor ou récepteurs des cellules B. Chaque lymphocyte B possédée plusieurs BCRs mais pour un seul agent pathogène.
Ce BCR est une immoglobuline membranaire formée de 2 chaînes légères et de 2 chaînes longues.
Il existe autant de lymphocytes B que de pathogènes.
L'ensemble des lymphocytes B est appelé le répertoire des lymphocytes B. Chaque BCR possède 2 sites de fixations à l'antigène.Le lymphocyte B avant d'être activé est appelé naïf.
L'activation du lymphocyte B par l'intermédiaire des BCR déclenche une expansion clonale du lymphocyte activé, avec production de cellule mémoire, et déclenche à distance des cellules produisant des anticorps.
Ces cellules produisant des anticorps sont appelés plasmocytes.
L'activation du lymphocyte B par un antigène nécessite l'implication des cellules lymphocytaires T CD4.Les lymphocytes B sont nommés B car ces lymphocytes ont été découverts chez l'oiseau dans la bourse de Fabricius ; par la suite le « B » fut conservé car c'est l'initiale de bone marrow (l'anglais de moelle osseuse) qui correspond au lieu de maturation de ces cellules à la suite d'une exposition à une interleukine (molécule chimique permettant le clonage des lymphocytes B et leur différenciation) produite par les lymphocytes T4.Ses principaux moyens d'action sont les immunoglobulines, aussi appelées anticorps.
Les anticorps sont des molécules ayant une forme de « Y » formées de quatre chaînes polypeptidiques : deux chaînes légères (environ 200 acides aminés chacune) et deux chaînes lourdes (environ 450 acides aminés chacune).Les chaines légères ont des régions constantes et des régions variables.
Les régions variables dépendent de la régulation somatique.
Les anticorps ont une forme en Y.
La barre verticale du Y est constituée de deux chaînes lourdes constantes qui vont déterminer la fonctionnalité de l’immunoglobuline.
Les deux barres inclinées du Y sont formées chacune d'une chaîne lourde et d'une chaîne légère, chacune ayant une partie constante et une partie variable qui est responsable de la spécificité de l'anticorps.Il existe 5 classes d'anticorps : les IgM, les IgG, les IgA, les IgE et les IgD.
Les IgM sont les premiers anticorps à être produits lorsque le corps reconnaît un nouvel antigène.
Ceux-ci se retrouvent dans le corps sous forme de pentamère et ils sont très efficaces pour activer le complément.
Les IgG sont la classe d'anticorps la plus retrouvée dans le sang, c'est aussi la seule classe d'anticorps qui peut traverser le placenta et donner au fœtus une immunité passive.
Les IgA se retrouvent dans les sécrétions (salive, larme, mucus, etc.) sous la forme de dimères.
De plus, la présence de ce type d'anticorps dans le lait de la femme permet aux nouveau-nés de recevoir une immunité passive durant la période d'allaitement.
Les IgE sont les anticorps impliqués dans les réactions allergiques puisqu'ils provoquent la libération d'histamine et d'autres substances impliquées dans ce genre de réaction par les granulocytes basophiles.
Finalement, les IgD sont retrouvés à la surface des lymphocytes B dits « naïfs » (qui n'ont pas encore été exposés à un antigène) et servent de récepteurs cellulaires à ceux-ci.
Contrairement aux quatre autres classes d'anticorps, les IgD ont une région transmembranaire qui leur permet de se fixer à la membrane cellulaire des lymphocytes B.Les quatre fonctions principales des anticorps sont :La fonction principale de l'immunité cellulaire est de détruire les agents infectieux intracellulaires.
Les cellules responsables de la destruction des pathogènes intra-cellulaires sont les lymphocytes T qui agissent directement en injectant des substances toxiques dans les cellules infectées.La formation et la maturation des lymphocytes T se fait dans le thymus où le lymphocyte prend le nom de thymocyte.
Le lymphocyte T est aussi porteur d'un récepteur pour reconnaître les antigènes pathogènes : les récepteurs des cellules T ou TCR.
À la différence des récepteurs des cellules B, le récepteurs des cellules T ne reconnaissent qu'un seul type de molécules : les peptides.La reconnaissance de la présence d'un agent infectieux intracellulaire par les lymphocyte T se fait par l'intermédiaire du complexe majeur d'histocompatibilité, nommés aussi CMH ou MHC, présent sur les cellules.Ce complexe majeur d'histocompatibilité a été découvert lors des transplantations d'organes.
Ces MHC recueillent en permanence les peptides formés continuellement par la cellule par la dégradation protéique intracellulaire ; elles sont spécifiques à un individu.Les peptides formés en permanence par la cellule par la dégradation protéique intracellulaire et portés par les MHC à l'extérieur de la cellule permettent aux lymphocytes T de vérifier la « santé » de la cellule.
En cas d'infection virale, les MHC vont présenter à l'extérieur des peptides viraux qui vont être reconnus par les lymphocytes T.
Il en est de même lors d'une greffe d'organe après laquelle les MHC produits seront reconnus comme n’appartenant pas à l'organisme (au soi) risquant de déclencher un rejet de greffe.Le système immunitaire cellulaire s'occupe des cellules infectées par des virus, bactéries, et les cellules cancéreuses.
L'action s'effectue via les lymphocytes T.
Les lymphocytes T sont capables d'interagir avec les cellules de l'organisme grâce à leurs récepteurs cellulaires T ou TCR (T Cell Receptor) formés de deux chaînes polypeptidiques: la chaîne α (alpha) et la chaîne β (bêta).
Ces récepteurs sont tout aussi spécifiques aux antigènes que les anticorps ou que les récepteurs de lymphocytes B, mais, contrairement aux anticorps et aux récepteurs de lymphocytes B, les récepteurs de lymphocytes T ne reconnaissent que de petits antigènes qui doivent être présentés par une molécule de CMH à la surface d'une cellule infectée.Aux lymphocytes T s'ajoutent aussi les lymphocytes NK (natural killer).
Ces cellules sont impliquées dans une réponse à mi-chemin entre spécifique et non spécifique, selon les situations.
Ils jouent notamment un rôle en début de grossesse, le fœtus devant se protéger contre eux pour pouvoir survivre dans le ventre de sa mère.Lorsqu'un agent pathogène pénètre dans une cellule, il reste dans le cytoplasme ou infecte les vacuoles.
Les mécanismes pour détruire l'agent différent selon sa localisation et expliquent en partie l'existence de deux familles de MCH, les MCH I et MCH II.Les MHC I sont produites par les infections cytoplasmiques.
Ils activent les lymphocytes T CD 8 qui possèdent le récepteur CD 8.
Ces cellules jouent un rôle prédominant dans l'infection virale.
Les lymphocytes T CD 8 sont nommés lymphocytes cytotoxiques ou CTL.
En effet, la liaison de CD8 sur la molécule de CMH permet de garder le lymphocyte T et la cellule infectée liés plus longtemps, ce qui favorise l'activation du lymphocyte.
Une fois activé, le lymphocyte T cytotoxique libère des protéines, comme la perforine ou des granzymes qui provoquent la formation de pores dans la paroi cellulaire de la cellule infectée, entraînant sa mort.
Cela a pour effet de priver le pathogène d'un lieu de reproduction et de l'exposer aux anticorps et aux leucocytes phagocytaires qui circulent dans la région infectée.
Les MHC I sont présents sur toutes les cellules nuclées de l'organisme.
Les hématies ne possèdent donc pas de MHC I.Les MHC II sont présents sur un nombre très restreint de cellules : cellules dendritiques, macrophages et lymphocytes B.Les MHC II sont produits par les infections vacuolaires ou la phagocytose.
Ils activent les lymphocytes T CD 4 qui possèdent le récepteur CD 4.
Les lymphocytes T CD 4 sont nommés lymphocytes helpers ou auxiliaires.
En activant les TCD4, ceux-ci libèrent des cytokines transformant les lymphocytes B en plasmocytes sécrétant des immunoglobulines.Vidéo de la réponse adaptativePour que la cellule lymphocytaire B produise des anticorps spécifiques et que le lymphocyte T CD8+ naïf se transforme en lymphocyte T CD8 tueur, il faut deux signaux :La cellule dendritique est une cellule immunitaire résidant dans le derme ou dans le tissu conjonctif sous-épithélial des bronches ou de l'intestin.
Dès l’introduction d'un pathogène, elle va être activée par les molécules émises par les cellules de l'épithélium (les peptides anti-microbiens et les cytokines pro-inflammatoires : l' interleukine-1, l' interleukine-6 et l'interféron-1 alpha et beta).La cellule dendritique immature possède des récepteurs de reconnaissance de motifs moléculaires qui reconnaissent la famille du microbe porteur d'un motif moléculaire associé aux pathogènes.
Elle va internaliser le microbe, le transporter vers un ganglion lymphatique par la lymphe.
Au cours du transport, elle va devenir une cellule dendritique mature avec apparition de molécules qui vont lui permettre de se fixer à un lymphocyte T CD4+ auxiliaire naïf.Durant son transport et dans le ganglion, la cellule dendritique coupe le microbe en morceaux compris entre 30 et 50 acides aminés.
Ces morceaux vont être présentés aux lymphocytes T CD4+ auxiliaires grâce au complexe majeur d'histocompatibilité de type II (MCH II).
C'est la présentation de l'antigène.L'activation de la cellule T CD4+ se fait grâce à la synapse immunologique.
Des molécules d'adhésion immobilisent la cellule dendritique au lymphocyte TCD4+.
La cellule dendritique présente un peptide à la cellule T CD4+.
La protéine CD4 se fixe sur un domaine du MCH II.
Enfin, des co-récepteurs sont produits par la cellule dendritique après stimulation des récepteurs de reconnaissance de motifs moléculaires.
L'ensemble représente la synapse immunologique : la cellule T CD4+ est avertie d'une espèce particulière de microbe par le MCH II de la cellule dendritique à travers les récepteurs de reconnaissance de motifs moléculaires de cette cellule dendritique.En fonction du signal de famille de pathogène donné par la cellule dendritique lors de la présentation de l'antigène, des cytokines de types différentes vont être émises par la cellule dendritique et activent de façon spécifique les lymphocytes T CD4+ notamment en Th1, Th2.
Chaque groupe est spécialisé d'une famille de pathogènes (virus, ver, bactérie, etc.).Le même microbe qui a été reconnu par la cellule dendritique se fixe sur les récepteurs des cellules B. Cette fixation va entraîner une activation et un processus aboutissant à la présentation de peptides microbiens par les complexes majeurs d'histocompatibilité de type II (MCH II) au récepteur du T CD4+ : c'est le premier signal.Le lymphocyte T CD4+ va reconnaître que ce peptide est le même que celui présenté par la cellule dendritique : c'est le deuxième signal.En fonction du type de CD4+ (Th1, Th2), le TCD 4+ va synthétiser des cytokines, principalement des interleukines, qui à leur tour vont déterminer le type d’anticorps sécrétés.
Le lymphocyte B naïf se transforme en lymphocyte B activé.
Il va commencer à produire des anticorps A, G ou E. Ces anticorps vont rejoindre le site de l'infection par les canaux lymphatiques aboutissant au canal thoracique se jetant dans l'aorte et vont atteindre le site de l'infection.
Un groupe de lymphocytes à mémoire est aussi créé.L'introduction d'un agent infectieux, comme un virus, déclenche dans les minutes qui suivent la libération de peptides anti-microbiens et de cytokines par les cellules de l'épithélium cutané.Les molécules citées ci-dessus vont aller se fixer sur les récepteurs PRR des macrophages, des mastocytes et de la cellule dendritique.
Les mastocytes vont relâcher des granules d'histamine qui ont des capacités vasodilatatrices, ce qui va dilater les parois des vaisseaux sanguins et donc ralentir la vitesse de la circulation sanguine pour permettre au granulocytes de traverser la paroi vasculaire.
Les macrophages eux, vont relâcher des chimiokines qui vont se fixer sur les récepteurs PRR des granulocytes et vont les attirer dans le vaisseau sanguin.
Les cellules dendritiques vont capturer un microbe et migrer jusqu'aux vaisseaux lymphatiques et aux ganglions, où ils vont présenter une molécule MHC II au lymphocyte T4.Grâce à la dilatation des vaisseaux produite par les mastocytes et grâce aux chimiokines, les granulocytes présents dans les tissus vont traverser la paroi vasculaire.
Les granulocytes neutrophiles vont phagocyter, les ganulocytes basophiles vont relâcher de l'histamine, qui va déclencher la réaction inflammatoire, et les granulocytes éosinophiles vont se lier à la paroi du parasite et libérer des enzymes qui vont causer des dommages importants à celui-ci.Les cellules dendritiques capturent un microbe et migrent jusqu'aux vaisseaux lymphatiques et aux ganglions, où ils vont présenter une molécule MHC II au lymphocyte T4.Si l'inflammation n'est pas contrôlée par le système inné, les lymphocyte T4 vont activer les lymphocytes B spécifiques au microbe à l'aide d'une cytokine, l'interleukine 2.
Les lymphocytes B vont alors produire des anticorps.Les peptides anti-microbiens qui sont libérés en premier par les cellules de l'épithélium cutané vont se fixer aux récepteurs du lymphocyte qui va alors s'activer.
Il va libérer tout d'abord de la perforine, une protéine qui va créer des pores dans la paroi des cellules infectées.
Il va ensuite libérer du granzime, une protéase à sérine qui va pénétrer par ces pores et induire l'apoptose (mort de la cellule).Les anticorps vont se fixer sur les antigènes de la bactéries ou de virus.
Ensuite les anticorps présentent le microbe aux macrophages.
Les macrophages activent la phagocytose grâce aux récepteurs FCR.Chaque individu acquiert en vieillissant une « mémoire immunologique ».
Elle conserve un certain temps les traces de « lutte » passée contre des pathogènes ou parasites, et des cellules spécifiques, permettant une réaction immunitaire plus rapide et efficace.
Cette mémoire se constitue de manière naturelle, ou à l'aide de vaccins mais semble se dégrader avec l'âge (phénomène d'immunosénescence).En effet, l'exposition antérieure à un antigène modifie la vitesse, la durée et l'intensité de la réaction immunitaire.
La réaction immunitaire première consiste en la production de cellules effectrices des lymphocytes lors d'une première exposition à l'antigène.
Lors d'une seconde exposition au même antigène, la réaction immunitaire secondaire sera plus rapide et efficace car l'organisme aura conservé en mémoire certains lymphocytes de la première attaque.C'est le principe de la vaccination : on injecte un antigène à la personne pour qu'elle se crée une « mémoire humorale », qui sera directement efficace lors d'une éventuelle attaque ultérieure.Une étude en 2015, basée sur la comparaison de la santé de « vrais » et « faux » jumeaux (210 jumeaux au total, de 8 à 82 ans, suivis pour plus de 200 paramètres de leur système immunitaire, ce qui est une première en nombre de paramètres d'intérêt immunologique), confirme qu'après la naissance, l'environnement a plus d'effets que nos gènes sur le fonctionnement et l'efficacité de notre immunité, notamment via l'exposition antérieure de l'organisme à des agents pathogènes (et/ou à des vaccins).
Les réponses différentes des vrais jumeaux à la vaccination anti-grippale montrent aussi que les réactions (production d'anticorps) ne dépendent pratiquement pas des traits génétiques mais presque entièrement de l'éducation immunitaire de chacun, et donc de nos relations antérieures à l'environnement microbien et parasitaire (dans ce cas liées à des contacts précédents avec diverses souches du virus de la grippe).
Face au cytomégalovirus, qui sommeille dans une fraction importante de la population humaine (ne causant que rarement des symptômes), les conclusions sont les mêmes.La meilleure compréhension des mécanismes globaux de l'immunité pourrait peut-être à l'avenir permettre de réduire les problèmes de rejet de greffe car la compatibilité entre un receveur et un donneur ne provient pas que de l'ADN, mais aussi d'enzymes et de facteurs d'immunité qu'on commence à rechercher dans le domaine de la biologie adaptative (via l'immunoséquençage notamment,,).
À l'échelle d'une vie, l'évolution du système immunitaire peut être comparée aux mécanismes complexes en jeu à d'autres échelles dans l'évolution adaptative.
De même, des vaccins plus personnalisés pourraient être imaginés.Le système immunitaire peut se dégrader en réagissant excessivement ou insuffisamment.L'absence de régulation du système inné peut aboutir au choc cytokinitique.S'il s'attaque aux cellules de l'organisme qui ne sont pas pathologiques (par mauvaise reconnaissance), il va alors se créer une maladie auto-immune qui va se caractériser par une inflammation continue de certains tissus ou par la nécrose complète de certains tissus (par exemple le diabète de type I).S'il y a un défaut du système immunitaire, dans ce cas les pathogènes ou les cancers pourront se développer plus aisément.Notons l'existence d'une maladie impliquant le système immunitaire adaptatif.
Il s'agit du Bare Lymphocytes Syndrome (BLS).
Les patients souffrant de cette maladie ne peuvent présenter d'antigène à la surface des cellules présentatrices d'antigène et il ne peut donc pas y avoir production d'anticorps.
Cette maladie a notamment permis des avancées en biologie moléculaire en permettant l'identification par complémentation d'un facteur de transcription essentiel, le transactivateur de classe II (CIITA).
Le mot antibactérien (du latin anti : « contre » et bacteria : « bactérie ») diffère de sens selon qu'on l'emploie comme adjectif ou comme nom.L'adjectif « antibactérien » a conservé son sens premier et propre.
Il qualifie tout ce qui sert à lutter contre les bactéries, agents de très nombreuses maladies infectieuses telles que le choléra,la légionellose,la lèpre, la syphilis, le tétanos, la tuberculose ou le typhus.Un antibactérien est un dispositif clinique qui permet soit de détruire les bactéries affectant le patient soit d'empecher la multiplication des bactéries.Dans le premier cas, on parle d'antibactérien bactéricide et dans le second cas d'antibactérien bactériostatique.Les trois premiers types d'antibactériens ci-après sont nommés antibiotiques.La pénicilline provient du champignons Penicillium notatum,Dans le vivant, les bactéries sont en concurrence et certaines bactéries développent des molécules pour détruire d'autres bactéries.La thyrothricine est obtenue à partir de la bactérie bacillus subtilis ; la streptomycine est isolée à partir de Streptomyces griseus; l'érythromycine est produite par une souche de Saccharopolyspora_erythraea; la vancomycine est isolée à partir de Amycolatopsis orientalis.La quinolone est dérivée de la quinoléine qui a été extraite pour la première fois par F. Runge en 1834 du goudron de houille.Avec l'importance grandissante de la résistance des bactéries aux antibiotiques - les antibactériens décrits ci-avant - les chercheurs et praticiens redécouvrent des antibactériens plus anciennement connus.C'est le cas du miel.
C'est un antibactérien efficace contre, en particulier, Bacillus subtilis, Escherichia coli, les staphylocoques dorés, Pseudomonas aeruginosa et Enterococcus faecium.
L'effet antibactérien du miel est dû à une multiplicité de facteurs.Dans la nature on le nomme bactériophage, lorsqu'il est préparé comme dispositif clinique il est nommé bactériophagique.L'utilisation des bactériophages pour combattre les bactéries est millénaire.
L'exemple cité est celui des eaux de la rivière Yamuna étudié par le médecin militaire britannique Ernest Hankin.Pour la même raison que les deux précédents - BMR - les recherches sur les plantes et extraits de plantes à vertu antibactérienne se multiplient.En 1884, l'origan du Comtat, composé de 64 plantes dont la marjolaine/origan, protège ses utilisateurs d'une épidémie de choléra.Dans la Classification anatomique, thérapeutique et chimique (ATC) utilisée par l'Organisation mondiale de la santé, les agents antibactériens sont répertoriés sous le code J01, parmi les anti-infectieux systémiques (lettre J).
Un agent biologique est un micro-organisme (bactérie, spore de microchampignon, virus), un parasite, une culture cellulaire ou une toxine.
On parle d'agent infectieux si cet agent est susceptible de provoquer une infection, une allergie ou une intoxication chez son hôte.
Cet agent peut être vivant ou non (ex : les virus ne sont pas vivants, ni le prion pathogène, mais ils sont classés parmi les agents biologiques).
Hormis pour le prion de la vache folle (identique à celui qui est l'agent de la maladie de Creutzfeldt-Jakob chez l'homme) ou celui qui est responsable de la maladie débilitante chronique, ils sont identifiés notamment par leur nom latin de genre et d’espèce.
Les agents biologiques vivant ont besoin de nourriture et de certaines conditions environnementales pour survivre et leur durée de vie est également limitée.
Certains peuvent sporuler ou survivre à la congélation.Ces agents ont la capacité de nuire à la santé humaine (et/ou animale ou de végétaux) de diverses façons, allant de réactions allergiques (le plus souvent bénignes) à des maladies ou intoxications graves, conduisant éventuellement à la mort.
L'évaluation des risques biologiques induits par ces agents doit tenir compte de leur pouvoir infectieux (effets directs), mais aussi d'éventuelles synergies et de  molécules secondaires telles que les toxines produites par les bactéries, les cyanotoxines produits par les cyanobactéries ou les mycotoxines de moisisssures  ou encore les endotoxines issues de la paroi de certaines bactéries, etc.…Ces agents sont pour certains omniprésents dans l'environnement naturel, dans l'eau, le sol, les plantes et les animaux, les excréments, les cadavres....Parce que de nombreux agents biologiques se reproduisent rapidement, mutent facilement et rapidement, peuvent acquérir, dupliquer et échanger des gènes de résistance (aux métaux, aux antibiotiques et à d'autres biocides), et parce qu'ils requièrent très peu ressources pour se nourrir ou se conserver, ils constituent un danger particulier dans une grande variété de milieux professionnels.En France le code du travail définit les agents biologiques et les classe en quatre groupes selon la gravité du risque d’infection pour l’homme.
Des agents biologiques, sélectionnés et parfois génétiquement modifiés sont utilisés pour des expériences, la production de molécules d'intérêt, comme arme bactériologique (aujourd'hui interdite) ou par exemple pour la biohydrométallurgie.
L'inflammation est la réaction stéréotypée du système immunitaire, face à une agression externe (infection, trauma, brûlure, allergie, etc.) ou interne (cellules cancéreuses) des tissus.
C'est un processus dit ubiquitaire ou universel qui concerne tous les tissus, faisant intervenir l'immunité innée et l'immunité adaptative.
Elle est cependant inhibée dans le système immunitaire des muqueuses, dont le mécanisme d'action est spécifique.L'inflammation est identifiée en médecine par le suffixe -ite.
Traditionnellement, les symptômes associés à l'inflammation sont décrits en latin par « dolor, calor, rubor, tumor, et functio laesa » (douleur, chaleur, rougeur, œdème et perte de fonctionnalité).
Le plus gros problème qui découle de l'inflammation est que la défense de l'organisme attaque à la fois les agents nocifs et non nocifs, d'une manière qui endommage les tissus ou les organes sains.L'inflammation chronique est une réponse à de nombreuses transformations de l'environnement et du comportement modernes (elle est favorisée par la sédentarité, la mauvaise hygiène alimentaire (malbouffe), la pollution, les altérations du microbiote humain) et un facteur important dans le développement de maladies de civilisation telles que la résistance à l'insuline, l'obésité, les maladies cardiovasculaires, les maladies immunitaires, et même les troubles de l'humeur et du comportement.Dès les premières civilisations, on trouve des témoignages de sa connaissance et de sa guérison.
Les premiers écrits sont apparus dans des papyrus égyptiens datant de 3000 av.
En Grèce et à Rome, un livre a été conservé, l'un des nombreux écrits de Aulus Cornelius Celso, encyclopédiste, "De Medicinae", dans lequel quatre signes cardinaux d'inflammation sont identifiés.Traditionnellement, à sa suite, les symptômes associés à l'inflammation sont décrits en latin par « dolor, calor, rubor, tumor, et functio laesa » (douleur, chaleur, rougeur, œdème et perte de fonctionnalité — la formulation des quatre premiers étant attribués à Aulus Cornelius Celsus et celle du cinquième souvent attribuée à Claude Galien).
Si l’inflammation est connue depuis l’Antiquité, l’impotence fonctionnelle a été rajoutée à sa définition par Rudolf Virchow en 1858.En 1793, le chirurgien écossais John Hunter a souligné ce qui est aujourd'hui considéré comme une évidence : « L'inflammation n'est pas une maladie, mais une réponse non spécifique qui produit un effet curatif sur le corps dans lequel elle se produit ».Le pathologiste Julius Cohnheim a été le premier chercheur à utiliser le microscope pour examiner les vaisseaux sanguins enflammés dans des membranes minces et translucides, telles que le mésentère et la langue de la grenouille.
Il observa la réorganisation initiale du flux sanguin, la formation de l'œdème après augmentation de la perméabilité vasculaire,la migration des leucocytes.
En 1867, il démontra que l'émigration des globules blancs était à l'origine du pus.
La contribution de Cohnheim fut fondamentale pour comprendre l'ensemble du processus inflammatoire.Le biologiste russe Ilya Ilitch Metchnikov découvrit le processus de phagocytose, en observant l'ingestion d'épines de rose par les amibocytes de larves d'étoiles de mer, et de bactéries par les leucocytes de mammifères (1882) ; la conclusion de ce chercheur était que l'objet de l'inflammation était de faire en sorte que des cellules ayant une capacité phagocytaire atteignent la zone lésée afin qu'elles puissent phagocyter des agents infectieux.
Cependant, il est vite devenu clair que les facteurs cellulaires (phagocytes) et les facteurs sériques (anticorps) étaient essentiels à la défense contre les micro-organismes.
En reconnaissance de cela, Metchnikoff et Paul Ehrlich (qui a développé la théorie humorale) ont partagé le prix Nobel de médecine en 1908.
.A ces noms il faut ajouter celui de Sir Thomas Lewis qui, par de simples expériences sur la réponse inflammatoire de la peau, a établi le concept que divers produits chimiques induits localement par la stimulation d'une lésion, comme l'histamine, sont des facteurs médiateurs des altérations vasculaires.
Ce concept fondamental est à la base des importantes découvertes de médiateurs chimiques de l'inflammation et de la possibilité d'utiliser des médicaments anti-inflammatoires.L'inflammation aiguë peut être considérée comme la première ligne de défense contre les blessures infligées à un tissu.
Elle fait partie du système immunitaire inné.Le processus d'inflammation aiguë est initié par les cellules immunitaires résidentes déjà présentes dans le tissu impliqué, principalement les macrophages résidents, les cellules dendritiques, les histiocytes, les cellules de Kupffer et les mastocytes.
Ces cellules possèdent des récepteurs de surface appelés récepteur de reconnaissance de motifs moléculaires (PRR), qui peuvent reconnaître (c'est-à-dire se lier à) deux sous-classes de molécules, qui agissent comme signal déclencheur :Au début d'une infection, d'une brûlure ou d'autres blessures, ces cellules reconnaissent un signal de danger pour l'organisme (l'un des PRR reconnaît un PAMP ou un DAMP) et s'activent, libérant des médiateurs inflammatoires responsables des signes cliniques de l'inflammation du tissu concerné.Les cellules immunitaires réagissent aux stress physiques détectés dans les tissus (chaleur, froid, pression) et produisent les médiateurs sérotonine et histamine, qui sont de puissants agents vasoactifs qui agissent sur la contraction et la perméabilité des vaisseaux artériels et veineux.Telle que définie, l'inflammation aiguë est une réponse immunovasculaire à des stimuli inflammatoires.
Cela signifie que l'inflammation aiguë peut être largement divisée en une phase vasculaire, qui se produit en premier, suivie d'une phase cellulaire impliquant des cellules immunitaires (plus spécifiquement des granulocytes myéloïdes dans le cadre aigu).La réponse inflammatoire aiguë nécessite une stimulation constante pour être soutenue.
Les médiateurs inflammatoires sont de courte durée et se dégradent rapidement dans les tissus.
Par conséquent, l'inflammation aiguë commence à se résorber dès que le stimulus est supprimé.L'inflammation est déclenchée par l'action de médiateurs chimiques, qui déclenchent la phase vasculaire, ou vasculo-exsudative.
On constate :En plus des médiateurs dérivés des cellules, plusieurs systèmes de cascade biochimiques acellulaires - constitués de protéines plasmatiques préformées - agissent en parallèle pour initier et propager la réponse inflammatoire.
Ceux-ci incluent le système du complément, activé par les bactéries, et les systèmes de coagulation et de fibrinolyse, activés par la nécrose (par exemple, brûlure, traumatisme).Les facteurs chimiques produits durant l'inflammation (histamine, bradykinine, sérotonine, leucotrienes et prostaglandines) augmentent la sensation de douleur, induisent localement la vasodilatation des vaisseaux sanguins et le recrutement de phagocytes, en particulier les neutrophiles.
Les neutrophiles peuvent également produire des facteurs solubles contribuant à la mobilisation d'autres populations de leucocytes.
Les cytokines produites par les macrophages et les autres cellules du système immunitaire inné constituent un relais de la réponse immunitaire.
On compte, parmi ces cytokines, le TNFα, HMGB1, et l'interleukine-1.Les trois cytokines majeures de l'inflammation sont l'interleukine-1, l'interleukine-6 et le facteur de nécrose tumorale,.
On les nomme le trio pro-inflammatoire.Sous l'influence de médiateurs chimiques, les cellules endothéliales (formant les vaisseaux sanguins) s'activent.
Cela entraîne une vasodilatation locale artériolaire puis capillaire qui provoque :Ce gonflement local des vaisseaux sanguins provoque la rougeur (rubor) et la sensation de chaleur (calor).L’augmentation de l'apport sanguin permettra d’évacuer les cellules mortes et les toxines (détersion), et d’apporter les éléments nécessaires à la guérison, notamment des globules blancs pour combattre les corps étrangers.Les molécules médiatrices modifient également les vaisseaux sanguins pour permettre la migration des leucocytes, principalement des neutrophiles et des macrophages, hors des vaisseaux sanguins (extravasation) et dans les tissus.
Dans des conditions normales, l'endothélium ne permet pas la sortie des protéines et l'échange se fait par pinocytose.
Au cours de l'inflammation, les bases morphologiques de l'endothélium sont altérées par l'action de médiateurs chimiques, produisant une altération des jonctions cellulaires et des charges négatives de la membrane basale.
Généralement, cet effet se produit dans les veinules, mais s'il est très intense, il atteint les capillaires et une extravasation se produit en raison de la rupture.Parallèlement, les cellules endothéliales activées expriment des molécules d'adhésion (nécessaires à la diapédèse).
De son côté, la diminution de la vitesse (stase) permet aux leucocytes de se marginaliser le long de l'endothélium, un processus essentiel à leur recrutement dans les tissus.Le vaisseau devenant plus perméable, l’eau du plasma sanguin s'épanche par osmose vers les tissus.La perméabilité accrue des vaisseaux sanguins entraîne une exsudation (fuite) de liquide dans les tissus.
La fuite de liquide provoque une augmentation de la viscosité du sang, ce qui augmente la concentration des globules rouges (congestion veineuse).L’œdème inflammatoire (tumor) est donc la conséquence du passage du plasma (plus précisément d'un exsudat) dans la zone lésée.
Il se traduit par un gonflement du tissu touché, et comprime les nerfs alentour, provoquant la sensation douloureuse et les démangeaisons (dolor).
Certains des médiateurs libérés comme la bradykinine augmentent la sensibilité à la douleur (hyperalgésie).
La perte de fonction (functio laesa) est probablement le résultat d'un réflexe neurologique en réponse à la douleur.L'œdème a plusieurs fonctions : il permet l'apport jusqu'à la lésion de moyens de défense (immunoglobulines, protéines du complément…), la dilution de l'agent pathogène, et la limitation du foyer inflammatoire.Le mouvement du liquide plasmatique entraîne avec lui des protéines importantes, telles que la fibrine et les immunoglobulines (anticorps), dans le tissu enflammé.Une partie du liquide tissulaire exsudé sera également acheminée par les vaisseaux lymphatiques vers les ganglions lymphatiques régionaux.
Dans des conditions normales, le système lymphatique filtre et contrôle les petites quantités de liquide extravasculaire qui ont été perdues par les capillaires.
Au cours de l'inflammation, la quantité de liquide extracellulaire augmente, et le système lymphatique participe à l'élimination de l'œdème.
De plus, dans ce cas, une plus grande quantité de leucocytes, de débris cellulaires et de microbes passe dans la lymphe, pour lancer la phase de reconnaissance et d'attaque du système immunitaire adaptatif.
Comme pour les vaisseaux sanguins, les lymphatiques prolifèrent également dans les processus inflammatoires, pour répondre à la demande accrue.
Les vaisseaux lymphatiques peuvent devenir secondairement enflammés (lymphangite) ou les ganglions lymphatiques peuvent devenir enflés (lymphadénite), en raison d'une hyperplasie des follicules lymphoïdes et d'un nombre accru de lymphocytes et de macrophages.Les molécules d’adhésion (CAM, intégrines, sélectines) libérées par les cellules endothéliales sont un signal pour les leucocytes présents dans les vaisseaux sanguins, qui dans la région inflammatoire ont tendance à quitter le milieu du courant pour s’accoler à la paroi de l’endothélium du vaisseau, par « margination », favorisée par le ralentissement du flux sanguin.La diapédèse leucocytaire est le phénomène permettant le passage des leucocytes de la circulation sanguine jusqu'au foyer de l'inflammation.
La traversée de l'endothélium par les leucocytes ou diapédèse intervient dans un segment particulier du système circulatoire : les veinules post-capillaires.
On peut distinguer différentes étapes :Après la migration des leucocytes hors des vaisseaux sanguins (extravasation), les cellules inflammatoires, dont les leucocytes, se dirigent ensuite de façon unidirectionnelle par chimiotaxie, le long d'un gradient créé par les cellules locales, pour atteindre le site de la lésion.À l'issue de la phase vasculaire ou vasculo-exsudative, la phase cellulaire fait suite à la diapédèse, lorsque les leucocytes sont amassés dans le tissu interstitiel.Elle correspond à la formation du granulome inflammatoire.
Il participe à la détersion (rôle des granulocytes et des macrophages) et permet le développement de la réaction immunitaire adaptative.
Les cellules composant le granulome ont également un rôle de sécrétion de médiateurs chimiques.Les leucocytes engloutissent les microbes et les détruisent, générant la production de pus.
Le pus sera éliminé vers l'extérieur si la lésion est en contact avec l'extérieur, ou il générera un abcès si la zone où s'est formé le pus est à l'intérieur d'un organe.La réparation des lésions tissulaires s'effectue grâce aux macrophages, qui stimulent les fibroblastes pour synthétiser le collagène et les cellules endothéliales pour générer de nouveaux vaisseaux, grâce à la sécrétion de facteurs de croissance.L 'Inflammation systémique implique trois organes (le foie, le système nerveux central et les glandes surrénales) et le trio pro-inflammatoire (l'interleukine-1, l'interleukine-6 et le facteur de nécrose tumorale).Les molécules inflammatoires sensibilisent les terminaisons nerveuses.
Les neurones relarguent la substance P et la CGRP des peptides qui ont des actions vaso-dilatatrices puissantes.L'inflammation peut :L’inflammation bien contrôlée est une réponse normale du corps qui nait s’amplifie et s’éteint.
Elle est consécutive à une agression interne (comme un cancer) ou externe (comme une infection).
Lorsque le corps n’arrive plus à maîtriser l’inflammation, celle-ci peut engendrer des maladies diverses comme le diabète, le cancer ou devenir chronique comme l’arthrite, la maladie de Crohn par exemple.Des efforts importants ont été déployés pour comprendre les mécanismes moléculaires inflammatoires et comment les combattre.
En effet, une inflammation de trop longue durée ou trop intense peut avoir des effets délétères sur l’organe où elle siège et potentiellement entraver sa fonction.
Les mécanismes de la phase d’initiation de l’inflammation sont maintenant bien compris.
En revanche, les mécanismes de la phase d’arrêt de l’inflammation n’étaient jusque récemment pas connus.
Ces dernières années, les travaux de l’équipe du professeur Charles Serhan, de l’École de Médecine de Harvard CETRI (Center for Experimental Therapeutics and Reperfusion : injury), ont permis de comprendre cette phase appelée résolution caractérisée par l’arrêt de la réponse inflammatoire, la réparation du tissu enflammé pour permettre finalement le retour à l’état initial du tissu appelé homéostasie.De nombreuses études scientifiques démontrent ainsi que le corps humain dispose de mécanismes naturels pour contrôler et programmer l’arrêt de l’inflammation.
Ces mécanismes portent le nom de Résolution, processus associé à la synthèse d’une famille de molécules spécifiques appelée SPM (en) pour médiateurs spécialisés de la résolution ou Specialized Pro-resolving Mediators en anglais.On peut définir la résolution de l’inflammation comme le processus biologique naturel et indispensable pour stopper naturellement l’inflammation.
Ce mécanisme est piloté par des médiateurs appelés SPM issus des acides gras polyinsaturés (AGPI) comme les oméga 3.Les AGPI qui donnent naissances aux SPM sont l’acide arachidonique (AA), l’acide docosahexahenoique (DHA), l’acide eicosapentaénoique (EPA) et l’acide docosapentaénoique (DPA).
Ainsi l’AA va donner naissance aux lipoxines, l’EPA au résolvines de type E, le DHA aux résolvines de type D, aux marésines, aux protectines et le DPA aux résolvines de la famille n-3.Dans certains cas, le corps ne produit pas ces molécules en quantité suffisante ou au bon moment.
L’arrêt de l’inflammation est alors altéré et peut s’accompagner de complications telles que fibrose, cicatrices ou perdurer de façon chronique.De nombreux travaux ont ainsi permis de mieux comprendre la finesse des mécanismes mis en place naturellement par notre organisme et de démontrer que les réponses inflammatoires chroniques semblent être dues à un défaut de résolution.A la faveur de ces découvertes, l’enjeu pour arrêter l’inflammation n’est donc plus de la bloquer, mais de la réguler en favorisant sa phase de résolution.
Ce nouveau champ de recherches porte le nom de pharmacologie de la résolution.Les SPM agissent de façon différente aux anti-inflammatoires et représentent donc une alternative thérapeutique très prometteuse pour arrêter de façon programmée l’inflammation sans la bloquer.Ils agissent en :Les SPM présentent des activités biologiques très bénéfiques car ils sont synthétisés au niveau du site inflammatoire et passent dans la circulation sanguine pour exercer leur activité à distance (activité autacoïde).
Ils vont permettre ainsi d’arrêter l’inflammation (en inhibant les voies dépendantes de NF-kB par exemple).
En permettant un arrêt programmé de l’inflammation, ils évitent le versant fibrotique d’une mauvaise cicatrisation et favorisent les capacités de défense de l’organisme (ils sont non immunosuppresseurs).Il existe actuellement deux méthodes principales pour mesurer les SPM :Des études cliniques montrent que l’augmentation des SPM dans le corps est corrélée à une amélioration clinique de l’état inflammatoire.C’est le cas par exemple de l’étude Barden publiée en 2016qui a montré une corrélation négative entre la douleur perçue par le patient et la présence de RVE2 dans le liquide synovial suggérant que la production de SPM peut être associée à la gestion naturelle de l’inflammation et de la douleur par le corps humain.En effet dans les modèles animaux d’autres SPM ont également montré des effets atténuateurs sur la douleur,.
Ces effets analgésiques sont médiés par des récepteurs spécifiques couplés aux protéines G.Pour aller plus loin dans les recherches sur le rôle des SPMs dans les maladies inflammatoires, l’Union européenne via son programme H2020, a sélectionné et financé le projet immunAID (H2020-EU.3.1.1.
Ce projet est coordonné par l’INSERM et il est composé de 24 partenaires dans 12 pays.L’inflammation peut se manifester par :On fait parfois référence aux noms latins, notamment dans les langues étrangères, pour décrire les manifestations de l’inflammation.
Ces manifestations ont été décrites il y a 2 000 ans par Celsus : rubor (rougeur), calor (chaleur), tumor (gonflement), dolor (douleur), functio laesa (impotence fonctionnelle).
Si l’inflammation est connue depuis l’Antiquité, l’impotence fonctionnelle a été rajoutée à sa définition par Rudolf Virchow en 1858.Le phénomène inflammatoire s'accompagne de modifications biologiques telles que l'augmentation de la concentration sanguine de plusieurs protéines dont l'haptoglobine, la céruloplasmine, des globulines, ou la protéine C réactive (CRP).
Une électrophorèse des protéines plasmatiques permet d'objectiver ces changements dans leur globalité.L'élévation des « protéines inflammatoires » accroît la vitesse de sédimentation.La ferritine augmente, reflétant la séquestration tissulaire du fer sérique.
Cette séquestration est secondaire à l'augmentation de la sécrétion d'hepcidine, médiée notamment par l'interleukine 6.
Cette séquestration est un des facteurs concourant à l'installation d'une anémie sur le long terme (anémie inflammatoire).Dans certains cas, une polynucléose neutrophile est présente.Des études récentes ont lié l'inflammation chronique à plusieurs types de pathologies, dites « maladies de civilisation » : maladies cardio-vasculaires, diabète et obésité...L'état inflammatoire chronique est reconnu favoriser le développement des tumeurs et a fortiori des tumeurs cancéreuses,.L’inflammation, est une réaction de défense généralement bénéfique, mais pose parfois problème, par la douleur qu'elle engendre ou lorsqu'elle perdure et devient chronique, risquant alors de nuire à la structure ainsi qu'à la fonction de l'organe touché.Le froid (glace à travers un tissu par exemple) suffit parfois à combattre l’inflammation (il induite une vasoconstriction, diminuant l’œdème et calme la douleur).Des médicaments anti-inflammatoires peuvent calmer les symptômes ou limiter les effets délétères de l'inflammation sur l'organisme.
On distingue les anti-inflammatoires non stéroïdiens et les glucocorticoïdes.
Ces médicaments existent sous de nombreuses formes (orale, suppositoire, inhalation, perfusion ou bien locale par pommade, collyre...) selon les indications.Des thérapies récentes (biothérapies) bloquent spécifiquement certains médiateurs de l'inflammation (anti-TNFα, anti-IL4…).
Elles ont révolutionné la prise en charge de maladies inflammatoires telles que la polyarthrite rhumathoïde ou les spondylarthrites ankylosantes mais avec des effets secondaires.Certains aliments contribuent à réduire l'inflammation - ou ses marqueurs sanguins -, en particulier les omega-3,,, (contenus dans les poissons gras et l'huile de lin ou de colza par exemple), les anthocyanes (contenus dans les fruits rouges et la betterave par exemple), le bêta-glucane (contenu par l'avoine et les grains entiers par exemple), le riz complet, le thym, le curcuma, le gingembre, le chou, l'ananas, l'huile d'olive, les noix, l'ail, les oignons.
À l'inverse, les aliments à fort indice glycémique ou à forte charge glycémique (sucre, amidon par exemple) contribuent à augmenter ces marqueurs sanguins.La restriction calorique semble réduire l'inflammation.
Dans une étude de restriction calorique portant sur 218 personnes pendant 2 ans, dénommée CALERIE, le taux de Protéine C réactive a baissé de 47 %.Basée sur l’approche développé par le Professeur Charles Serhan, Professeur à l’école de médecine de Harvard, qui a établi le concept de résolution de l’inflammation à la suite de la découverte des SPM, une approche micronutritionnelle peut également être développée pour lutter contre l’inflammation.Elle consiste en premier lieu à apporter à notre corps le substrat qui lui permet d'augmenter la synthèse de SPM lors d’une réponse inflammatoire, qu’elle soit aiguë, chronique ou de bas grade.
Cet apport peut se faire via l’ingestion d’acides gras polyinsaturés spécifiques enrichis en SPM ou favorisant la production de SPM.Selon l’endroit où est située l’inflammation, elle peut prendre différents noms, en général en -ite :
Un solvant est une substance, liquide ou supercritique à sa température d'utilisation, qui a la propriété de dissoudre, de diluer ou d'extraire d’autres substances sans les modifier chimiquement et sans lui-même se modifier.
Les solvants sont utilisés dans des secteurs très diversifiés tels que le dégraissage, les peintures, les encres, la détergence, la synthèse organique, et représentent des quantités considérables en termes de tonnage et de chiffre d'affaires.En Suisse romande et en Belgique, on utilise le terme anglais thinner pour les solvants organiques destinés à la dilution des peintures.L'eau est le solvant le plus courant, la solution étant alors qualifiée de solution aqueuse.Le terme « solvant organique » se réfère aux solvants qui sont des composés organiques qui contiennent des atomes de carbone.
Habituellement, les solvants ont un point de fusion faible et s'évaporent facilement.
Les solvants permettent de dissoudre les réactifs et d'amener les réactifs en contact.
Ils ne réagissent pas chimiquement avec le composé dissous : ils sont inertes.
Les solvants peuvent aussi être utilisés pour extraire les composés solubles d'un mélange, l'exemple le plus commun étant l'infusion de thé dans de l'eau chaude.Les solvants sont souvent des liquides transparents avec une odeur caractéristique.
La concentration d'une solution est la quantité de soluté dans un certain volume de solvant.Pour les solutions liquides (phase uniforme liquide contenant plusieurs espèces chimiques), si l'une des espèces est très largement majoritaire (au moins un facteur 100), on l'appelle le « solvant ».
C'est le cas de l'eau pour les solutions aqueuses (par exemple une solution aqueuse de sulfate de cuivre : l'eau est le solvant et les ions sulfate et cuivre(II) les solutés).En règle générale, les atomes ou molécules de même nature s'assemblent pour former un liquide ou un solide (un cristal ou un solide amorphe).
Dans le cas d'une solution, le solvant empêche les atomes ou molécules de s'assembler, il les disperse.
Dans le cas de l'eau, cela se produit selon deux phénomènes :Il existe de nombreuses classifications des solvants : en fonction de la nature chimique du composé, de sa polarité, de ses propriétés physico-chimiques, de son secteur d'utilisation, de sa toxicité, de son origine (pétrolière ou agrosourcée), etc.Le tableau suivant compare ces différentes familles :Les solvants inorganiques ne contiennent pas d'atomes de carbone.
L'eau, les solutions aqueuses contenant des additifs (tensioactifs, solution tampon...), l'acide sulfurique concentré, l'ammoniaque sont des solvants inorganiques classiques.Les solvants organiques contiennent des atomes de carbone.
Ils sont classés en trois familles :Espèces non ioniques : la majorité des solvants actuels sont des espèces non ioniques.Espèces ioniques : tandis que la plupart des solvants sont de nature moléculaire (formés d'une seule espèce neutre), il existe une nouvelle classe de solvants, appelés liquides ioniques, constitués d'anions et de cations.
Les liquides ioniques sont des sels fondus possédant un point de fusion inférieur à 100 °C et une tension de vapeur quasiment nulle (ils sont non-volatils).
Ils constituent une alternative de plus en plus sérieuse aux solvants moléculaires classiques et sont désormais très utilisés en électrochimie.
De nombreuses recherches actuelles s'intéressent à leur utilisation pour la séparation des métaux radioactifs et pourraient aboutir à des solutions particulièrement écologiques pour le retraitement des déchets radioactifs.Il est important de préciser que l'origine du solvant n'a pas de conséquence sur sa toxicité ; un solvant agrosourcé peut être néfaste pour l'homme ou l'environnement (cas du furfural).Les solvants pétrochimiques proviennent du pétrole et donc de la pétrochimie.
La plupart des solvants actuellement utilisés sont d'origine pétrochimique (hexane, benzène, acétate d'éthyle, dichlorométhane).Les solvants agrosourcés (appelés aussi biosolvants) proviennent de la valorisation de la biomasse végétale (bois, sucre, huiles végétales, huiles essentielles).
Les exemples les plus connus sont les alcools (méthanol, éthanol, etc.), le furfural, le glycérol ou encore des esters comme le lactate d'éthyle.Les solvants les plus couramment utilisés peuvent être caractérisés par les propriétés physiques suivantes : point de fusion, point d'ébullition, pression de vapeur saturante, solubilité dans l'eau, miscibilité avec d'autres solvants, constante diélectrique, densité, viscosité, pouvoir solvant (indice kauri-butanol et point d'aniline), paramètres de solubilité d'Hansen (en).Les solvants ci-dessous sont groupés en solvants apolaires, polaires aprotiques et polaires protiques, classés par polarité croissante.La dissolution peut se faire par réaction chimique entre des espèces du solvant (en général des ions) et le solide.
Le cas le plus fréquent est celui de la dissolution par un acide : les protons H+ (ou dans l'eau, les ions oxonium H3O+) provoquent une oxydation du solide2M + 2H+ → 2M+ + H2(l'atome de solide M cède un électron à l'ion H+ qui peut alors former une molécule de dihydrogène), l'ion M+ étant alors soluble dans le solvant.À haute température (au-delà de 2 000 °C), le verre (dioxyde de silicium SiO2) est liquide.
On peut donc y dissoudre un certain nombre de produits qui sont, eux, solides à cette température.On peut aussi dissoudre les solides dans d'autres types de verre, par exemple le métaborate de lithium ou le tétraborate de lithium, utilisés pour diluer les matériaux à analyser en spectrométrie de fluorescence X (technique de préparation dite de la « perle fondue »).Bien qu'ayant lieu à haute température et avec un solvant différent, le principe est similaire à la dissolution dans l'eau (dispersion solvatation, dissolution acide).Plusieurs raisons (telles que la raréfaction des ressources pétrolières, la réglementation de plus en plus stricte sur l'utilisation de composés volatils, toxiques ou reprotoxiques) incitent les industriels et académiques à se tourner vers de nouveaux solvants alternatifs, souvent appelés « solvants verts ».
Il n'existe pas de définition officielle d'un solvant vert mais plusieurs définitions peuvent être mentionnées : l'adjectif « vert » peut faire référence aux 12 principes de la chimie verte dans le cas où le solvant rempli un ou plusieurs de ces principes (synthèse avec économie d'atomes, issu de matières premières renouvelables...).
Cependant, le terme « solvant vert » peut être employé dans différents cas, comme dans le cas où le solvant n'est pas toxique, ou bien qu'il est biodégradable ou encore qu'il provient de ressources renouvelables.
Ainsi, le terme « vert » peut correspondre à différentes définitions.
C'est pourquoi différentes familles de solvants sont qualifiées de « solvants verts » : les solvants agrosourcés, les liquides ioniques, les fluides supercritiques, les polymères liquides.Les solvants agrosourcés sont, comme leur nom l'indique, issus d'agro-synthons (petites molécules d'origine renouvelable pouvant être obtenues à partir de cellulose, d'hémicellulose, de lignine, d'huile végétale, etc.) Le glycérol et le lactate d'éthyle sont deux exemples représentatifs de cette famille de solvants.
Leur origine non pétrolière les classe parmi les solvants verts.Les liquides ioniques sont classés parmi les solvants verts du fait de leur non volatilité.
Cependant, de nombreux doutes subsistent sur la toxicité de ces composés.
Les liquides ioniques les plus étudiés sont les dérivés imidazolium, mais leur toxicité prouvée tend les académiques à se tourner vers des structures moins toxiques pouvant même parfois être issues de ressources renouvelables.
C'est par exemple le cas de l'acétate de choline.Les fluides supercritiques sont classés parmi les solvants verts car ils sont inertes.
L'exemple le plus utilisé est le CO2 supercritique.
L'inconvénient de cet exemple est lié aux risques que présentent les installations industrielles mettant en œuvre des fluides supercritiques (sous pression).Les polymères liquides sont aussi cités parmi les solvants verts du fait de leur non volatilité et, pour certains, de leur biocompatibilité.
Les polyéthylène glycols, notés PEG, font partie de cette famille.Les solvants servent comme :De nombreux solvants présentent des risques pour la santé, ce qui est d'autant plus inquiétant qu'en 2003, 14,7 % de la population salariée était exposée à des solvants (contre 12,3 % en 1994 ; études INRS) ; il n'est pas nécessaire de travailler dans une usine chimique pour être en contact avec des solvants toxiques, les professionnels de la peinture, de la plasturgie, de l'imprimerie, du nettoyage, du funéraire, de la blanchisserie, etc. subissent aussi leurs effets néfastes.Plusieurs types d'éthers de glycol ont été ainsi mis en cause dans des cas de cancers graves ; neuf ont été classés reprotoxiques (dangereux pour les fœtus des femmes enceintes).Enfin, de nombreux composés chimiques ont fait l'objet d'études faibles avant leur mise sur le marché et les risques réels qu'ils nous font courir sont mal connus.
D'où l'importance du projet européen REACH qui pourrait obliger les industriels à mieux tester leurs produits, et l'importance du travail des comités d'hygiène (CHSCT en France) sur ces questions dans le cadre de l'entreprise.
L'air des habitations peut aussi receler de nombreux solvants (issus des colles, peintures et vernis, mais aussi des produits d'entretien), d'où la recommandation d'aérer chaque pièce au moins 10 minutes chaque jour.
Le latin (en latin : Lingua Latīna ou Latīna Lingua) est une langue italique de la famille des langues indo-européennes, parlée à l'origine par les Latins dans le Latium de la Rome antique.
Bien qu'il soit souvent considéré comme une langue morte, sa connaissance, voire son usage, se sont maintenus à l'université et dans le clergé.
De nombreuses écoles et universités continuent à l'enseigner,.
Le latin est toujours utilisé pour la production de néologismes dans de nombreuses familles de langues.
Le latin, ainsi que les langues romanes (dites parfois néo-latines), sont la seule branche des langues italiques à avoir survécu.
Les autres branches sont attestées dans des documents datant de l'Italie préromaine, mais ont été assimilées durant la période républicaine ou au début de l'époque impériale.Langue flexionnelle, elle comporte sept cas, deux nombres et trois genres.
L'alphabet latin est dérivé des alphabets étrusque et grec.
Enrichi de lettres supplémentaires et de signes diacritiques, il est utilisé aujourd'hui par de nombreuses langues vivantes et comportait à l'époque classique 23 lettres, dont 4 voyelles, 2 semi-voyelles et 17 consonnes.Les langues italiques formaient, à côté des langues celtiques, germaniques et helléniques, une sous-famille « centum » des langues indo-européennes qui incluait le latin, parlé par la population du Latium en Italie centrale (les Latins), et d'autres parlers comme l'ombrien et l'osque, au voisinage immédiat d'une langue étrusque non indo-européenne mais dont le latin a subi l'influence culturelle.
De nos jours, les langues italiques sont représentées par les langues romanes, issues du latin populaire (l'italien, le roumain/moldave, l'aroumain, le français, l'occitan, le francoprovençal, le catalan, l'espagnol, le portugais, le sarde, le ladin, le corse, etc., ainsi que des langues aujourd'hui éteintes, comme le dalmate ou le mozarabe).On appelle latin archaïque (prisca latinitas) l'état du latin en usage de l'origine jusqu'au tout début du Ier siècle av.
J.-C.L'expansion territoriale de la Rome antique assure au latin une diffusion de plus en plus large à partir du IIIe siècle av.
Langue officielle de l'Empire romain, elle se répand dans la majeure partie de l'Europe occidentale, de l'Afrique du nord, de l'Asie Mineure et des régions danubiennes.
Sous l'Empire, le latin est la langue du droit, de l'administration romaine et de l'armée ainsi que des nombreuses colonies romaines, coexistant avec le grec et les parlers locaux.Après la chute de l'Empire romain d'Occident au Ve siècle, les envahisseurs germaniques adoptent progressivement le mode de pensée romain et la langue latine afin d'asseoir leur légitimité.
Tout au long du haut Moyen Âge, bien qu'il ne soit pas une langue vernaculaire, le latin reste la langue des actes officiels, de la diplomatie, de la liturgie et de la littérature savante (théologie, philosophie, sciences).Durant la suite du Moyen Âge, les langues locales s'affirment sur le plan littéraire et intérieur, et tandis qu'il donne naissance à de nombreuses langues vernaculaires dérivées (les langues romanes) et que des langues non romanes (comme l'anglais ou l'allemand) lui empruntent du vocabulaire, le latin reste influent aux plans diplomatique, juridique, scientifique et philosophique.Le latin est réformé vers 800, puis au XIe siècle, sur le modèle du latin classique, afin d'éviter une dérive vers les langues vernaculaires qui en étaient issues.Pendant tout le Moyen Âge, le latin fait office de langue liturgique de l'Église catholique romaine.
Presque toutes les bibles utilisées à cette époque en Occident sont écrites en latin, sur le modèle de la Vulgate de saint Jérôme, de même que les autres livres liturgiques.
L'Historia scholastica de Pierre le Mangeur, texte de base pour l'étude de la Bible à partir des années 1170, est écrit en latin.
La traduction de la Bible en langues vernaculaires est même interdite à la fin du XIIe siècle par des lettres du pape Innocent III, puis par plusieurs conciles au début du XIIIe siècle.
Les lettrés s'expriment toujours en latin.
La langue des universités est le latin, dès la création de celles-ci vers la fin du XIIe siècle.
Les intellectuels du Moyen Âge écrivent tous leurs traités en latin.
Par exemple, l'encyclopédie (pour employer un terme contemporain) de Vincent de Beauvais, le Speculum maius, est écrite en latin.
Toutefois, à partir du concile de Tours (813), dans les territoires correspondant à la France et l'Allemagne actuelles, les homélies ne sont plus prononcées en latin mais en « langue romane rustique » (gallo-roman), ou dans la « langue tudesque » (germanique).Pendant le Moyen Âge, on désigne par le mot litteratus une personne qui maîtrise le latin.
L'illiteratus est celui qui l'ignore, ce qui ne signifie pas qu'il n'est pas « lettré ».À la Renaissance, la fonction scientifique et philosophique de la langue latine commence à décliner, tout comme sa fonction diplomatique (Ordonnance de Villers-Cotterêts, 1539).
Cela n'empêchera pas Érasme de publier une quantité de textes en un latin redevenu classique et très riche ; de même, René Descartes (1596 – 1650) écrit volontiers en latin… surtout lorsqu'il est pressé (même s'il publie son Discours de la méthode d'abord en français pour des raisons particulières ; les ouvrages de son époque sont souvent imprimés en latin pour être diffusés dans toute l'Europe).
Dans la partie germanique de l'Europe (où le droit romain reste en vigueur jusqu'à la fin de l'Empire), le latin restera plus longtemps la langue des publications importantes ou scientifiques, tandis que du côté français, d'énormes efforts sont accomplis (surtout avec Louis XIV) pour le remplacer par un français châtié et remanié.
Le latin reste toutefois la langue liturgique et officielle du catholicisme (textes doctrinaux ou disciplinaires, droit, etc.).Le terme néolatin s'est répandu vers la fin des années 1890 parmi les linguistes et les scientifiques.
Il sert aux spécialistes des lettres classiques à désigner l'utilisation de la langue latine après la Renaissance, dans un but aussi bien scientifique que littéraire.
Le début de la période est imprécis mais le développement de l'éducation chez les laïcs, l'acceptation des normes littéraires humanistes, ainsi que la grande disponibilité de textes latins qui a suivi l'invention de l'imprimerie, marquent une transition vers une ère nouvelle à la fin du XVe siècle.
Au XIVe siècle, le latin est une langue privilégiée dans l'enseignement tant ouest-européen (heures de cours, rédaction des thèses) qu'est-européen, bien qu'il ne soit guère plus utilisé que par les commentateurs et éditeurs de textes antiques.
En Belgique, l'usage de la langue vulgaire dans les universités n'a été toléré qu'à partir de 1835 environ.
La fin de la période néo-latine est également indéterminée, mais l'usage normal du latin pour communiquer les idées est devenu rare après quelques décennies au XIXe siècle et, vers 1900, c'est dans le vocabulaire scientifique international de la cladistique et de la systématique qu'il survivait essentiellement.Au XXe siècle, c’est avant tout une langue de culture, qui reste utilisée par l’Église catholique romaine depuis l’époque de l’Empire romain.
C’est avec le français, langue diplomatique, la langue officielle du Saint-Siège, tandis que de l'État du Vatican utilise de facto l'italien ; le latin est aussi partiellement langue d'enseignement dans les universités pontificales romaines.
Le latin est maîtrisé sans être pratiqué par des évêques, prêtres et diacres catholiques.
Des publications latines profanes sont également réalisées tout au long du XXe siècle, comme celles des communistes russes, qui publient tous leurs ouvrages de botanique en latin pendant la période de la guerre froide, des traductions en latin de certains albums de la bande dessinée Astérix ou, plus récemment, des deux premiers tomes du best-seller Harry Potter.Il reste de plus dans l’Église catholique romaine divers mouvements traditionalistes, comme les fraternités sacerdotales Saint-Pierre ou Saint-Pie-X, qui célèbrent la messe suivant le rite tridentin, en latin, forme ordinaire dans l'Église romaine avant la réforme liturgique de 1969 adossée au concile Vatican II.
Celui-ci, dans la constitution sur la liturgie Sacrosanctum Concilium, demande une participation active des fidèles dans la liturgie et, pour ce faire, introduit une série de modifications, dont un usage plus important des langues vernaculaires (SC 36), même si celles-ci ne sont pas originellement censées se substituer totalement au latin.
Le pape Benoît XVI rétablit l'usage complémentaire du rite tridentin sans limitations en 2007, par le motu proprio Summorum Pontificum.
Sous la forme ordinaire, la messe devrait aussi être dite en latin, quoique ce soit rarement le cas dans les faits.Au début du XXIe siècle, de nombreux mouvements, tels le Vivarium Novum de Rome, la Schola Nova de Belgique, la Domus Latina de Bruxelles ou l'ALF prônent son maintien comme langue de communication européenne, et l'utilisent notamment lors de congrès : il s'agit de promouvoir le latin classique comme une véritable langue moderne grâce aux ajouts de vocabulaire.
Dans Le Monde, Pierre Georges mentionne soixante mille mots ou expressions ajoutés au latin au cours du siècle écoulé, dont res inexplicata volans pour « OVNI » ou vis atomica pour « puissance nucléaire ».
Des revues et des sites Web sont édités en latin (par exemple le magazine de mots croisés Hebdomada Aenigmatum), tandis que la radio finlandaise a émis en latin trois fois par semaine pendant plus de vingt ans jusqu'en juin 2019.
d'Erfurt (Allemagne) a une émission en latin chaque semaine.
La prononciation contemporaine qui semble s'imposer est la prononciation ancienne restituée.
Radio Vatican émet une fois par semaine un journal d'actualité radiophonique Hebdomada Papæ, d'une durée de cinq minutes dont la prononciation utilisée est italienne.
Radio Vatican retransmet également quotidiennement des offices divins catholiques en latin (Completorium, Laudes, Vesperæ) et la Sainte-Messe.
Enfin, Radio Vatican consacre une émission dénommée Anima Latina sur l'approfondissement de la connaissance du latin, la langue officielle de l'Église catholique et de la liturgie (avec les langues vernaculaires depuis le Concile Vatican II) dans l'Église latine.Le latin est toujours aujourd'hui la langue officielle de l'Église catholique.
Par exemple, le Code de droit canonique de 1983 et même le Code des canons des Églises orientales (qui pourtant n'ont jamais utilisé le latin comme langue liturgique) de 1990 sont écrits en latin, et les spécialistes font constamment référence au texte latin.Les Romains sont les créateurs de l'alphabet latin qui comportait, à l'époque classique, les lettres suivantes :Les lettres k, y et z sont rares : k n'existait pas dans l'alphabet latin (on ne peut guère signaler que les noms communs « Kalenda » et « Kalumniator » et les noms propres « Kaeso » et « Karthago » (Carthage)), mais était initialement utilisé un c devant a, o et les consonnes ; y et z ont été ajoutées pour transcrire les mots grecs à partir de l'époque classique.Quintilien se plaint que cet enrichissement de l'alphabet permette de mieux transcrire les mots grecs que les mots latins.On ne connaît pas avec une précision totale la prononciation du latin classique, malgré les nombreux témoignages laissés par les auteurs latins et les moyens mis en œuvre par la méthode comparatiste (cf.
remarque de Quintilien ci-dessus).L'une des modifications les plus importantes depuis l'indo-européen commun est le rhotacisme (passage de  à  dans certaines conditions ; principalement entre voyelles).
La prononciation d'une langue n'étant pas figée, tant que le latin a été parlé, ses phonèmes ont évolué.
Les évolutions les plus flagrantes ont été :Chaque voyelle (a, e, i, o, u, y) peut être brève ou longue (distinguées aujourd'hui par le diacritique ˘ ou ¯).
Le latin antique était une langue à accent de hauteur aussi dotée d'un accent d'intensité secondaire.Certaines consonnes peuvent être géminées, ex : « siccus », « stella », « annus », « terra », « grossus », « littera », etc.Le latin enseigné actuellement en France (et dans beaucoup de pays à travers le monde) correspond la plupart du temps à cette prononciation restituée du Ier siècle av.
: c'est cette prononciation qu'il faut pratiquer pour lire à peu près convenablement un texte latin et qui est presque généralisée actuellement dans les congrès internationaux qui choisissent cette langue.Une autre prononciation du latin est celle du « latin ecclésiastique », ou « latin d'église », qui est assez proche du bas-latin, voire de l'italien, avec quelques exceptions.
Cette prononciation, qui n'est fondée sur aucune base philologique sérieuse, est celle définie par Érasme dans son ouvrage Dialogus de recta latini graecique sermonis pronuntiatione écrit en 1528.Voici quelques généralités sur la grammaire du latin classique.La morphologie du latin est celle d'une langue hautement flexionnelle.On compte dans le système nominal autant les noms que les adjectifs, qui suivent des flexions proches, sinon similaires.
La flexion nominale comporte : La conjugaison du verbe latin repose tout entière sur l'opposition de deux thèmes, celui du présent (infectum) et celui du parfait (perfectum).Le système verbal latin s'organise en fait à partir de trois radicaux :La classification scolaire en 4 ou 5 conjugaisons, basée sur la voyelle finale du thème, n'est valable que pour la série de l'infectum, construite sur le radical du présent.
À la série du perfectum, construite sur les radicaux du parfait et du supin, cette distinction est inappropriée,.Le radical du présent s'obtient en enlevant à l'infinitif présent sa désinence -re.Les phrases principales latines se composent comme en français de :Exemples : Remarque :Les phrases secondaires latines sont :Les propositions subordonnées complétives / CODLe comparatif de supériorité se forme à partir du radical d'un adjectif (ex clarus ⇒ clar) + ior, ior, ius.
Le comparatif de clarus est donc clarior, ior, ius.Il a le même usage qu'en français.Pour le former, on prend le radical d'un adjectif (ex clarus ⇒ clar) + issimus, issima, issimum.Donc, le superlatif de clarus, a, um est clarissimus, issima, issimum.Attention: certains comparatifs et superlatifs sont irréguliers.Comme toute langue indo-européenne, le latin hérite d'un certain nombre de termes du lexique indo-européen commun.
Ainsi, à agnus, « agneau », correspondent le vieux-slave агнѧ (agnę), le russe ягнёнок (iagnionok), le grec ancien ἀμνός/amnós, le breton oan, etc., qui descendent tous de l'étymon *h₂egʷʰno.Le latin emprunte ensuite aux langues non italiques voisines :Enfin, le latin emprunte aux langues italiques voisines : osque, ombrien.Un mot latin peut avoir directement engendré un mot français ; c'est le cas pour ala /aile, amare /aimer, barba /barbe, carpa /carpe, etc.Dans d'autres cas, la situation n'est pas si simple et le mot a évolué d'une manière moins linéaire : aqua, « eau », donne eau mais après une autre évolution phonétique, le même étymon aqua a donné le doublet ève, encore présent dans le doublet populaire évier de aquarium.
Fagus, « hêtre », se voit évincé par un mot germanique et crus, « jambe », ne se retrouve qu'indirectement dans crural.
L’expérimentation animale consiste à utiliser des animaux comme substitut ou « modèle », pour mieux comprendre la physiologie d'un organisme et ses réponses à divers facteurs (alimentation, environnement, agents pathogènes) ou substances (pour en tester, vérifier ou évaluer l'efficacité, l'innocuité ou la toxicité), et tout particulièrement pour tenter de prévoir ce qui se passe chez l'Homme.Pour des raisons de taille, d'accumulation de connaissances, de standardisation, de prix et de temps, la très grande majorité des expérimentations animales se font sur des rongeurs.
La souris commune étant de mieux en mieux connue au point de vue génétique, son usage augmente plus que celui des autres espèces, mais il existe d'autres animaux vertébrés ou invertébrés utilisés comme organismes modèles.L'expérimentation animale est une pratique controversée, certaines personnes pensant qu'on fait ainsi souffrir des animaux, sans apporter aucun bénéfice ni pour eux, ni pour les humains.
Selon un sondage Ipsos de 2003, 64 % des Français sont plutôt ou tout à fait défavorables à l'expérimentation animale, le chiffre montant à 85 % pour une interdiction de celle-ci si des méthodes substitutives existent.
Ce dernier point est d'ailleurs déjà mis en vigueur par la réglementation européenne et française qui interdit l'utilisation d'animaux en recherche si d'autres méthodologies existent.
Le chiffre descend à 60 % d'opinions favorables à une interdiction de l'expérimentation animale relative aux cosmétiques.
D'autres sondages donnent des indications sur l'opinion du public sur le sujet de l'expérimentation animale en ce qui concerne le domaine médical.
Un sondage IPSOS réalisé en 2007 pour le Gircor, indique que 69 à 77 % des Français sont favorables à l'usage de l'expérimentation animale pour lutter contre les maladies graves.
51 % désapprouvent toute expérimentation sur les chiens et les singes, même si cela peut aider à résoudre des problèmes de santé pour les humains, selon l'Eurobaromètre 2010, alors que seulement 18 % désapprouvent l'expérimentation sur souris si cela doit régler des problèmes de santé.Cependant, les institutions scientifiques et autorités affirment la nécessité d'avoir recours à cette méthodologie pour garantir le progrès scientifique et médical.
Selon un rapport de la Commission européenne, 11,5 millions d'animaux ont été utilisés en 2011 par les 27 États membres, dont 80 % de lapins et de rongeurs.La directive européenne, sur la protection des animaux utilisés à des fins scientifiques a été révisée et mise à jour en 2010 sous le code Directive 2010/63/UE.
Elle affirme le principe des 3R qui demande que l'utilisation d'animaux soit remplacée, réduite et améliorée autant que possible.
Elle impose un examen critique des projets d'étude sous l'angle bénéfice pour la recherche et contrainte pour les animaux et la publication de résumés non-techniques.
Elle impose des conditions d'hébergement minimales.
Le développement des méthodes alternatives est encouragé de différentes façons.
Tous les États membres ont transposé cette directive dans leur réglementation.Il y a environ 2 500 ans que, d'après Hippocrate : « les maladies sont une cause naturelle et non surnaturelle, que l'on peut étudier et comprendre ».
Galien (131-201), en Grèce, s'est beaucoup inspiré d'Hippocrate mais aussi d'Aristote.
Il commence à avoir recours aux animaux pour ses premières démonstrations en physiologie et en anatomie, par exemple pour démontrer que les artères contiennent du sang et non de l'air, contrairement aux croyances du moment.
Quelques siècles plus tard, des animaux tels que les crapauds, les grenouilles, poules et vers plats seront utilisés comme modèles.
Au XVIIe siècle, la philosophie cartésienne se refusait à croire une quelconque souffrance possible chez les animaux.À la fin du XVIIIe siècle et au début du XIXe siècle, deux écoles s'opposent : celle qui privilégie les études en laboratoire comme Georges Cuvier (1769-1832) et celle défendant l'observation de ces animaux dans leur milieu naturel comme Geoffroy Saint-Hilaire (1772-1844).
Jean Henri Fabre se désespère, en 1879 dans ses « Souvenirs entomologiques » en écrivant : « Vous éventrez la bête et moi je l'étudie vivante, vous travaillez dans un laboratoire de torture et de dissection, j'observe sous le ciel bleu, vous scrutez la mort, j'observe la vie ».
Charles Darwin, dans son ouvrage On the Origin of Species publié en 1859, insiste sur la continuité entre l'homme et l'animal et sur la nécessité d'études comparatives.Edward L. Thorndike (1874-1949), est considéré comme l'un des précurseurs de l'expérimentation animale contrôlée.
Claude Bernard quant à lui, a développé les principes fondamentaux de la physiologie qui reposent sur des « vivisections zoologiques », mais en utilisant des anesthésiants.Au début du XXe siècle les premiers modèles d'études privilégiés émergent : les rats, les souris, les mouches commencent à coloniser majoritairement les laboratoires.
Des vers tels que les nématodes seront aussi utilisés.À l'issue de la seconde guerre mondiale, en 1949, le code de Nuremberg stipule dans son article 3 que les fondements d'une expérimentation chez l'homme doivent s'appuyer sur les résultats d'expériences antérieures effectuées sur l'animal.Mais l’expérimentation animale reste un sujet de controverse.
L’opposition à l’usage des animaux dans les domaines scientifiques, pharmaceutique et cosmétique, s’accompagne d’une évolution des rapports homme/animal.
L’animal n’est plus vu comme un simple « objet utilitaire ».
Son rôle se redéfinit au sein des sociétés occidentales, au point que certaines personnes parlent d’une « humanisation » de l’animal.
On a parlé à ce sujet des retrouvailles de l'humanité et de l'animalité.En France, la question du bien-être animal est au cœur des débats sur l’expérimentation des animaux.
En 2000, est promulguée une loi relative à la protection animale et l'article L.214 du Code rural reconnait l’animal comme un « être sensible » que l’on doit respecter.
L’article l.515-14, voté en 2015, change le statut de l’animal dans le code civil et considère les animaux comme des « êtres vivants doués de sensibilité ».Les conditions qui règlementent l’usage d’animaux à des fins expérimentales sont de plus en plus strictes et traduisent un changement de comportement des individus à l’égard des animaux.
Catherine Bousquet, journaliste et écrivain scientifique, dans un ouvrage titré Bêtes de science, conclut à ce propos par une question lourde et forte ; « Sans elles, que saurions nous de nous-même ?
».La réglementation qui encadre l'utilisation d'animaux à des fins scientifiques a été mise à jour le 7 février 2013, transposant ainsi la directive européenne 2010/63/UE.
La charte nationale de l’expérimentation animale définit les principes éthiques de l’utilisation des animaux à des fins scientifiques.En complément de cette directive, de manière autonome, des scientifiques (suisses et allemands principalement) ont rédigé et lancé en novembre 2011 la Déclaration de Bâle (Basel Declaration), rapidement signée par près de 900 chercheurs ou laboratoires dont 500 hors de Suisse et d'Allemagne.
Ils souhaitent qu'elle soit le pendant pour l'animal de la déclaration d'Helsinki de 1964 (et plusieurs fois révisée depuis) rappelant des principes éthiques et donnant des recommandations aux médecins et autres participants à la recherche médicale sur l'Être humain ou des études contenant des données à caractère personnel ou des échantillons biologiques non-anonymes.En France, les animaux sont principalement utilisés dans les domaines suivants : recherche fondamentale (27 %), recherche médicale humaine ou vétérinaire (19 %), mise au point et contrôle des médicaments et des produits de santé humains ou vétérinaires (52 %).
Un très petit nombre d'animaux sont aussi utilisés pour l'enseignement professionnel, la protection de l'environnement ou la conservation des espèces.
Les animaux sont aussi utilisés pour l’étude de maladies animales.Tous les animaux utilisés en recherche française proviennent d'élevages, et à plus de 97 % d'élevages situés en Europe.1,77 million d'animaux ont été utilisés en 2014.
Plus de 58 % étaient des rongeurs, 30 % étaient des poissons, 5 % des lapins, 5 % des oiseaux, moins de 1 % des animaux de ferme, moins de 0,3 % des carnivores ou des singes.
Aucun chimpanzé n'est utilisé en recherche en France ou en Europe.Les domaines d'utilisation des animaux en recherche pour l'Union européenne en 2011 sont donnés ci-après :En médecine, l'expérimentation animale permet de comprendre le fonctionnement de l'organisme, des organes et des cellules, de vérifier des hypothèses thérapeutiques, et, dans la mise au point de médicaments, de déterminer des doses efficaces ou au contraire toxiques avant de procéder à des tests cliniques sur des êtres humains.Beaucoup d'études ne pourraient être menées ni chez l'Homme (car trop dangereuses) ni sur des cellules isolées (car faisant intervenir plusieurs organes en interaction, par exemple par des hormones).
Ainsi, l'expérimentation animale fut à l'origine de la découverte des hormones par Claude Bernard et de la mise en évidence de l'insuline par Frederick Banting et John Macleod qui leur valut le Prix Nobel de médecine en 1923.
Une partie des découvertes ayant valu à leur auteur un prix Nobel de médecine et de physiologie ont été obtenues à partir d'expérimentations animales.En 1865, Jean-Antoine Villemin démontra le caractère contagieux de la tuberculose en inoculant à des lapins des matières tuberculeuses,.En chirurgie, l'expérimentation animale permet de tester des actes chirurgicaux d'abord sur l'animal, avant de les tenter sur l'homme.
Ainsi, les greffes de trachées avec une aorte ont-elles été d'abord tentées chez le mouton avant de les appliquer à l'homme.
L'implantation de cœur artificiel, et plus généralement toute innovation dans la chirurgie cardiaque, a déjà été effectuée chez l'animal avant d'être tentée sur l'homme.
Un traitement de l'infarctus du myocarde par thérapie cellulaire a été testé avec succès en 2007 sur des rats avant qu'un essai clinique utilisant les mêmes principes ne soit lancé sur l'homme en 2014.Des médicaments ont été découverts à l'issue d'études préalables chez les animaux.
Par exemple, en 1992, on découvre que, chez des souris atteintes d'une maladie similaire à la sclérose en plaques (une maladie auto-immune), les cellules immunitaires fabriquent une protéine qui leur permet de pénétrer dans le cerveau.
Ces études ont permis de découvrir qu'un anticorps, le natalizumab, agissait sur la protéine analogue chez l'homme, et ont donné lieu à un traitement de la sclérose en plaques chez l'homme.Pour de nombreuses maladies, des tests sont d'abord effectués sur des animaux modèles.
En effet, ces tests ont pour but de valider les hypothèses posées lors de la mise au point d'un éventuel traitement.
S'ils se révèlent négatifs chez l'animal, on ne les mènera pas sur l'homme, en raison du coût élevé des essais cliniques humains et des risques sanitaires qu'on pourrait faire peser sur les patients, en particulier lorsqu'il s'agit d'enfants.
À l'inverse, s'ils sont positifs sur l'animal, c'est un argument en faveur de la mise en place d'essais cliniques chez l'homme.
En cas de succès des essais, on passe à la phase finale de fabrication du médicament et de mise sur le marché.
Ainsi, en thérapie génique, la recherche d'un virus vecteur susceptible d'être rendu inoffensif, sa possibilité de transporter le matériel génétique adéquat, l'efficacité de cet apport, la sécurité du traitement à long terme nécessitent des recherches sur l'animal avant d'envisager d'appliquer le procédé ainsi validé à l'homme.
C'est ainsi que le Généthon a proposé une thérapie du syndrome de Wiskott-Aldrich pour lequel des essais sur l'homme sont conduits depuis 2011.
De même, le principe général des thérapies antisens a déjà été validé chez l'animal à l'issue d'études menées entre 2004 et 2011, avant que des essais cliniques basés sur les mêmes principes ne soient lancés chez l'homme, conduisant dans certains cas à la mise au point de traitements, comme pour l'amyotrophie spinale en 2019.
D'autres thérapies géniques ont été mises au point en suivant cette longue démarche, pour des maladies rares du sang, de la vision, des muscles et certains cancers, par exemple pour la maladie de Pompe, le déficit en adénosine désaminase, la bêta-thalassémie, la leucémie aiguë lymphoblastique, le lymphome diffus à grandes cellules B, l'amaurose de Leber.Toujours en thérapie génique, il s'avère qu'un traitement nécessitant plusieurs injections perd de son efficacité à partir de la deuxième injection.
La raison en est que le système immunitaire réagit immédiatement lorsqu'il reconnaît pour la deuxième fois un virus, vecteur du médicament, qui a déjà été injecté une première fois.
Une méthode pour remédier à cet inconvénient serait d'accompagner le vecteur par des nanoparticules contenant des immunosuppresseurs qui réduiraient la réponse immunitaire spécifiquement sur le médicament transgénique, mais pas sur les autres infections dont le malade risquerait de souffrir en cas de traitement immunosuppresseur global.
Afin de vérifier la validité de cette hypothèse, des tests ont été menés sur des animaux.
S'étant révélés positifs, il est dorénavant envisagé de mener la même expérimentation chez l'être humain,.
Une méthode comparable est appliquée avec succès depuis 2014 dans le traitement de la goutte.Dans le cas de la maladie d'Alzheimer, on a observé aussi bien chez l'homme que chez des souris modèles une diminution du débit sanguin dans le cerveau, les capillaires bouchés ayant un taux important de neutrophiles.
En 2019, des expériences ont montré que l'injection d'anticorps contre les neutrophiles pouvaient avoir pour conséquence de déboucher les capillaires bouchés et d'améliorer l'état des souris traitées.
Une piste thérapeutique consiste alors à tester sur les souris modèles plusieurs molécules susceptibles d'empêcher l'adhérence des neutrophiles avant d'en sélectionner un certain nombre pour les tester ensuite sur l'être humain.En radiothérapie du cancer, des études sont menées concernant une technique de radiothérapie flash, consistant à irradier la tumeur plus intensément mais pendant un temps très bref.
Des essais sur la souris ont en effet montré que cette méthode donnait moins d'effets secondaires, et des essais cliniques sur l'homme sont envisagés en 2022.Lors d'études menées chez le singe pendant la période 2000-2015, il a été montré qu'une puce électronique implantée dans le cerveau du singe permettait à celui-ci de commander à distance un bras articulé, commandé directement par le cerveau du singe.
Une fois validée chez l'animal, la même technique a été tentée sur des personnes tétraplégiques.
En 2014, un patient tétraplégique pareillement équipé a réussi à animer un bras robotisé qui a saisi une bouteille pour l'approcher de ses lèvres.
Une autre patiente a pu animer individuellement les cinq doigts d'une main virtuelle sur un écran pour jouer une mélodie simple sur un clavier virtuel.
Les recherches se poursuivent pour arriver à détecter les signaux du cerveau par des moyens moins invasifs.Les essais effectués sur les animaux servent également à la mise au point de traitements applicables aux animaux.
C'est le cas par exemple dans la mise au point d'antibiotiques.
À l'inverse, on cherche également des traitements substitutifs aux antibiotiques, certaines bactéries étant devenues résistantes à ceux-ci.
Des études sont menées sur des bactéries telles que Bdellovibrio qui ont la propriété de s'attaquer à d'autres bactéries.
Des expériences menées chez la larve du poisson-zèbre suggèrent que Bdellovibrio pourrait aider à la lutte contre la bactérie Shigelle, dont une espèce est responsable de la dysenterie.Lorsqu'un essai clinique est envisagé pour l'homme, le produit utilisé est d'abord testé en phase pré-clinique sur des animaux afin d'évaluer à quelle dose ce produit est efficace, à quelle dose il devient nocif, quel est le devenir du médicament dans l'organisme, quels sont les effets secondaires.
Cette première étape a pour but de limiter les risques sur les premiers volontaires humains en phase I de l'essai.Cependant, les adversaires des essais pharmaceutiques dénoncent "la valeur informative limitée" de ces essais du fait que l'animal n'est pas identique à l'Homme.
C'est la raison pour laquelle les essais cliniques sont menés de manière graduée : phase pré-clinique chez l'animal d'abord, suivi d'une phase I sur quelques patients en bonne santé, puis d'une phase II sur quelques malades, puis d'une phase III sur un échantillon plus large de malades, et d'une phase IV sur l'ensemble des malades après autorisation de mise sur le marché.
Un produit qui ne passerait pas la phase pré-clinique ne sera jamais testé sur l'homme.
Les précautions prises n'empêchent pas l'existence d'un risque à toute phase de l'étude, comme le montre l'exemple dit de "l'essai thérapeutique de Rennes", en 2016, qui a causé un décès en phase I et l'hospitalisation de cinq personnes à la suite d'effets secondaires graves, alors que, lors de l'essai pré-clinique, « les résultats à disposition des études de toxicité chez l’animal ne montrent pas d’éléments laissant présager une toxicité telle que survenue dans l’essai ».Pour pouvoir réaliser une expérimentation, il est nécessaire d'utiliser un modèle qui soit prédictif pour l'objectif de l'étude (biologie, santé ou maladie humaine ou animale, atteinte de l'environnement).
Les modèles animaux n'échappent pas à cette contrainte.Beaucoup de traitements démontrés comme efficaces chez l'animal ne fonctionnent pas chez l'homme, et le rat, la souris ou le lapin peuvent répondre très différemment à un même équivalent-toxique.
Chaque espèce possède en effet des caractéristiques physiologiques propres.
Par exemple, le chimpanzé ne développe pas le sida et les tumeurs ne se développent pas toutes de la même manière chez l'homme et chez l'animal.
Il en est d'ailleurs de même au sein d'une même espèce : tous les humains ne réagissent pas de la même façon au virus de la grippe ou au cancer.Pour ces raisons, il est essentiel que le choix d'un modèle biologique qu'il soit animal ou cellulaire soit réfléchi, et que les limites des conclusions qu'on pourra en tirer soient connues dès avant même d'initier le projet.Les modèles animaux sont intéressants parce qu’ils partagent une majeure partie de leurs gènes avec les êtres humains.
Les chercheurs recourent par exemple le plus souvent au modèle de la souris, en raison des traits génétiques, physiologiques, pathologiques et immunologiques qu’elle partage avec l’être humain.
Entre les deux espèces, 99 % des gènes sont en effet homologues (identiques ou proches).Le choix d'un animal de laboratoire et de la souche au sein d'une espèce n'est pas neutre.
Il existe aujourd'hui de nombreuses lignées particulières (transgéniques ou non), dont certaines par exemple n'ont pas d'immunité, pas de poils, ou développent plus facilement ou moins facilement des cancers, etc.
Le choix d'une de ces souches parmi toutes celles sélectionnées et produites pour les laboratoires peut introduire certains biais ; Les études toxicologiques sont en grande partie financées par les fabricants et/ou basées sur des données fournies par les fabricants qui ont fait travailler leur laboratoire ou des laboratoires externes avec des lignées animales pouvant par exemple être très peu sensibles au cancer ou aux perturbateurs endocriniens.
Divers acteurs et les détracteurs d'une étude « longue durée » (deux ans) ayant conclu à un risque pour l'exposition à un OGM et/ou au désherbant total Roundup ont ainsi en 2012 reproché à son auteur (Gilles-Éric Séralini) d'avoir utilisé la souche Sprague-Dawley de rats de laboratoire, connue pour développer plus spontanément que d'autre des tumeurs cancéreuses, ce à quoi G.E.
Sérallini a répondu que « cette souche de rats est utilisée dans presque tous les tests, et c’est en particulier la souche qui a servi pour homologuer tous les OGM ».Ainsi, les auteurs d'une étude de l'université du Missouri-Columbia ont découvert en 2005 que les lignées de rats de laboratoire utilisés par les industriels pour les évaluations toxicologique du Bisphénol A (BPA) étaient au moins 25 000 fois moins sensibles aux perturbations hormonales que la moyenne et plus récemment, des différences encore plus importantes (avec des animaux jusqu'à 100 000 fois moins sensibles que d'autres) ont été observées dans d'autres cas, ce qui prend une importance majeure dans le cas des perturbateurs endocriniens susceptibles d'agir à de très faibles doses.Le recours au chien en tant que modèle prédictif pour tester l’efficacité et la toxicité des thérapies innovantes pour les maladies neuromusculaires a connu de récents succès.
En effet, les chiens peuvent souffrir des mêmes maladies génétiques que la population humaine, provenant de mutations sur des gènes similaires.
En 2017, un traitement par thérapie génique chez des chiens atteints de myopathie myotubulaire a fait preuve d’une vraie efficacité lors des travaux d’une équipe française,.
Ce traitement avait fait l'objet d'études chez la souris depuis 2007, et des essais cliniques sur l'homme ont débuté en 2017.Toujours en 2017, une autre équipe a constaté l’efficacité d’une thérapie innovante dans le traitement de chiens atteints de la myopathie de Duchenne.
La maladie est due à un défaut du gène codant la dystrophine, trop long pour être contenu dans un vecteur viral utilisé en thérapie génique.
L'expérimentation sur des chiens a permis de valider la possibilité d'utiliser un gène plus court codant une microdystrophine.
Ces essais ont en effet abouti à la restauration de la force musculaire et la stabilisation des symptômes cliniques de chiens naturellement touchés par une myopathie.
Ces études ont permis la mise au point d'un essai clinique sur des enfants atteints de cette maladie, qui débute en mars 2021,.Les animaux utilisés pour l'expérimentation sont des êtres sensibles, capables de ressentir la douleur.
Pour la reproductibilité des expériences ils vivent dans des conditions très contrôlées et en Europe soumises aux normes européennes.
Ils proviennent d'établissements d'expérimentation ou de fournisseurs déclarés (l'utilisation d'animaux « domestiques capturés » est strictement prohibée).
De plus, l'expérimentation doit avoir lieu dans un établissement agréé et ne peut être conduite que par une personne titulaire d'une autorisation nominative d'expérimenter sur les animaux.
Enfin, la loi oblige les expérimentateurs à réduire toutes formes de souffrance ou d'angoisse (le recours aux analgésiques, par exemple, est très courant).
Les animaux de laboratoires doivent être et sont traités avec soin et respect (dans le cas contraire, le personnel de recherche s'expose à des sanctions pénales).Par souci de réduire au mieux la souffrance des animaux de laboratoire, en 1959 a été édicté la règle des 3 R.Certaines associations de protection des animaux affirment que ces lois ne sont pas appliquées, s'appuyant sur divers exemples dénoncés par leurs enquêteurs infiltrés dans des laboratoires/centres d'élevages qui ne sont cependant jamais cités, pour éviter toute poursuite.
Les associations de protection des animaux jouent un rôle important dans les discussions sur l'expérimentation animale et ont permis d'établir une législation plus respectueuse envers les animaux.Quelques exemples de souffrances causées par des tests en laboratoire :Au-delà des expériences en elles-mêmes, les conditions de détention des animaux sont parfois mises en cause : absence de lumière du jour, éclairage artificiel parfois permanent, cages ou aquariums exiguës (les rats ne peuvent généralement pas s'y mettre debout), voire stériles avec peu ou pas de contacts ou de compagnons, ne permettant pas d'exprimer certains comportements naturels.
Placer des individus d'espèces sociales en cage individuelle les conduit à développer une forme de stress physiques et mentaux.
« Seul un médicament sur neuf qui agit chez l'animal réussit jamais dans des essais cliniques humains, et les laboratoires ont souvent du mal à reproduire les résultats des autres.
L'environnement dans lequel vivent ces créatures pourrait-il faire partie du problème ?
» s'interrogent des chercheurs qui veulent améliorer la valeur et le bien-être des animaux de laboratoire à l'Université Stanford de Palo Alto (Californie).
Joseph Garner constate que « les animaux de laboratoire tendent à être obèses, ont un système immunitaire affaibli et développent des cancers - avant même que les scientifiques ne fassent des expériences sur eux ».
Il pousse donc les scientifiques à enrichir la qualité de vie de ces animaux (avec des jouets, des compagnons et des occasions de faire de l'exercice et d'explorer) pour que les résultats d'expérience soient plus conformes au réel.
Il encourage aussi à transporter les souris dans un tube plutôt qu'en les prenant par la queue, ce qui est stressant pour elles.
Mais il existe des détracteurs de cette approche qui craignent des coûts supplémentaires (des dizaines de millions de rongeurs et de poissons sont utilisés rien que dans les laboratoires américains), une complexification de leur travail et une reproductibilité encore diminuée de certaines expériences.Certains chercheurs pensent que le bien-être de l'animal de laboratoire peut être nécessaire à la pertinence des résultats de nombreuses expérimentations.En 1947, Donald Hebb, psychologue qui utilisait des rats de laboratoire constatait que ses rats apprenaient moins bien au laboratoire que ceux qu'ils élevait chez lui en semi-liberté avec ses filles.Dans les années 1960, plusieurs études ont conclu que des rats de laboratoire simplement élevés en présence de blocs de bois et d'un assortiment de labyrinthes rotatifs développaient de plus grandes régions sensorielles de leur cerveau, mais seuls les primates voient leurs conditions de détention s'améliorer (dans les années 1980 notamment).En 1996, un Guide du Conseil national américain de la recherche pour le soin et l'utilisation des animaux de laboratoire encourage le personnel chargé des soins aux animaux à ajouter des éléments dans les cages dont des couvertures pour fabriquer des nids voire de diffuser de la musique et des films aux animaux tels que chiens, et singes.
Un guide spécifique aux poissons est publié en 1995.En 2000, un neuroscientifique australien (Anthony Hannan, de l'Université de Melbourne), inspiré par des travaux ayant prouvé qu'enrichir la vie d'un animal enclenche chez lui la croissance de nouveaux neurones, observe ce qui se passe quand il "pimente" la vie de ses souris de laboratoire,.
Après avoir introduit dans les cages du carton pour faire des nids, des boules de couleurs vives pour le jeu ainsi que des échelles et des cordes pour grimper, et il constate que les souris R6/2, ainsi stimulés étaient bien moins enclines à perdre du volume cérébral et à développer des symptômes de type Huntington  que élevés de manière standard, (c'est la première expérience qui a montré que la maladie de Huntington n'est pas à 100 % génétique et des conclusions similaires ont été produites avec les souris ou rats utilisés comme modèles pour l'étude de l'autisme, de la dépression ou de la maladie d'Alzheimer.
D'autres montreront que l'absence d'activité physique et de stimulation de l'activité cérébrale accroissent la vulnérabilité de la souris et du rat à certaines désordres cérébraux,,.
On sait aussi maintenant qu'un stress important ou chronique chez une femelle ou un mâle peut induire des modifications épigénétiques pour plusieurs générations de sa descendance.La théorie de la recherche de nourriture sociale suggère que les animaux vivants en groupe tirent profit des liens sociaux persistants, ce qui conduit à une tolérance accrue dans la recherche de nourriture et le partage d'informations.
Les chauves-souris sont parmi les mammifères les plus sociaux, vivant souvent dans des colonies de dizaines à des milliers d'individus pendant des dizaines d'années, mais on sait peu de choses sur leur dynamique de recherche de nourriture sociale.
Nous avons observé trois colonies de chauves-souris en captivité pendant plus d'un an, quantifiant plus de 13 000 interactions d'alimentation sociale.
Nous avons constaté que les individus utilisaient systématiquement l'une des deux stratégies de recherche de nourriture, soit produire (collecter) des aliments eux-mêmes, soit les extraire directement de la bouche d'autres individus.
Les types de recherche de nourriture individuels étaient cohérents pendant au moins 16 mois, sauf pendant la période de lactation où les femelles se sont déplacées vers la production.
Les «scrouners» ont délibérément choisi avec qui interagir lors de la recherche sociale, générant ainsi des relations sociales persistantes et non aléatoires avec deux ou trois producteurs spécifiques.
Ces relations persistantes entre producteurs et scrouners semblent réduire l'agressivité au fil du temps.
Enfin, le dépouillement était fortement corrélé avec la vigilance, et nous émettons l'hypothèse que les individus sujets à la vigilance se tournent vers la fouille dans la nature pour atténuer le risque d'atterrir sur un arbre fruitier potentiellement dangereux.
Nous trouvons que la colonie de chauves-souris est un système social riche et dynamique, qui peut servir de modèle pour étudier le rôle que la recherche de nourriture sociale joue dans l'évolution de la socialité des mammifères.
Nos résultats soulignent l'importance de considérer les tendances individuelles lors de l'exploration des modèles de comportement social des animaux vivant en groupe.
Ces tendances soulignent davantage la nécessité d'étudier les réseaux sociaux au fil du temps.La qualité de cette alimentation est une condition non suffisante mais nécessaire du bien être animal.De plus, elle a aussi une importance majeure pour les protocoles d'études (qui souvent vont introduire un contaminant, polluant ou médicament dans cette nourriture) afin de comparer leurs effets à ceux d'une nourriture supposée dénuée de ces contaminants, polluants ou médicaments et délivrée à une « population témoin » de la même espèce.Or si les pensionnaires de nombreux grands zoos sont depuis longtemps alimentés avec des produits bio, ce n'est pas le cas ou rarement pour des animaux de laboratoire : ainsi en 2015 deux chercheurs ont constaté que ces animaux de laboratoires sont maintenant tous nourris avec des aliments très standardisés (ce qui est important pour la reproductibilité des expériences).
Ces aliments proviennent de l'agriculture industrielle et s'ils présentent des teneurs précises de lipide, glucides, fibres, vitamines, sucres, etc adaptés aux espèces et âges des animaux de laboratoire leur étiquetage ne précise pas les éventuels contaminants qu'ils pourraient contenir.
C'est pourquoi Treize échantillons de croquettes pour animaux de laboratoire ont été analysés.
262 pesticides, 22 OGM, quatre métaux lourds et métalloïdes, 17 organochlorés dioxines et furanes], et 18 polychlorobiphényles y ont été recherchés.
Nombre de ces contaminants potentiels ont été retrouvés dans les croquettes, dont le Roundup (résidu de désherbant le plus présent, retrouvé dans 9 des 13 échantillons analysés ; et 11 marques de croquettes présentaient des traces d’OGM.
Les régimes alimentaires utilisés en France pour alimenter les rats de laboratoires étaient ceux présentant le plus fort taux de métaux lourds ou métalloïdes, avec notamment du mercure et de l’arsenic.
Ceci constitue un biais pour de nombreuses expériences qui utilisent une population témoin supposée ne pas être exposée à ces toxines ou produits testés.Le devenir des animaux utilisés pour les tests est variable.
L'adoption ne concerne qu'une infime minorité d'entre-eux.
Dans la plupart des cas, s'ils n'ont pas été tués et disséqués pour les besoins de l'expérimentation, ils sont "sacrifiés" (terme en usage), c'est-à-dire euthanasiés.
Le rapport aux animaux de laboratoire pose question : simples outils de travail pour les chercheurs ?
C'est pourquoi des méthodes alternatives émergent.Le nombre d’animaux utilisés en France pour l’expérimentation a augmenté de 8,4 % entre 2014 et 2016 (de 1 769 618 à 1 918 481 animaux),.Les laboratoires de recherche s'engagent à appliquer la règle des trois « R » : remplacer, réduire, raffiner, selon cette hiérarchie.
La Directive européenne de 2010 (article 4) en précise les principes :Il existe différentes méthodes dites « alternatives », permettant de remplacer le nombre d’animaux utilisés à des fins scientifiques.
De nombreuses hypothèses de recherches peuvent ainsi être testées in vitro (cellules en culture) ou ex vivo (organes ou tissus isolés).
Ces méthodes permettent, d’étudier les mécanismes associés à certaines pathologies ou encore de tester l’effet de potentiels traitements.
L’utilisation de modèles informatiques de prédiction (méthodes in silico) peut aussi apporter de précieuses informations.
Dans certains cas, l’expérimentation in vitro a même complètement remplacé l'expérimentation animale (par exemple, produits cosmétiques dans l'Union européenne),.L'industrie pharmaceutique suisse publie un rapport (son 5e en 2015) pour le bien être animal.
Son bilan met en avant les différentes méthodes alternatives pour réduire le nombre d'animaux au strict nécessaire et en limitant les contraintes auxquelles ils sont soumis.Des méthodes alternatives sont proposées telles que le projet d’Interpharma sur la mise en évidence et l’étude de toxicités rénales dans des modèles cellulaires, concentrés sur la réplication de l’architecture du tubule rénal.
Des effets toxiques pourraient ainsi être identifiés à un stade précoce du développement des médicaments.Le partenariat public-privé dans le domaine des sciences de la vie vise à développer "l'Innovative Medicines Initiative (IMI), qui soutient des projets de recherches.
Le projet eTox a pour but de développer des stratégies méthodologiques innovantes et de nouveaux logiciels afin d'améliorer les prédictions de toxicité des candidats-médicaments.
Les études sur l’animal ne seront conduites que pour des substances optimisées, réduisant le nombre d’animaux nécessaires pour les essais pré-cliniques.
Le projet StemBANCC vise à générer et à caractériser 1 500 lignées de cellules souches pluripotentes humaines induites.
Ces cellules iPS serviront à élaborer in vitro des modèles de maladies humaines (maladies d’Alzheimer et de Parkinson, neuropathie, diabète, migraine, troubles bipolaires, etc.) afin d’accélérer le développement de médicaments.
Ainsi, il est possible de générer des cellules hépatiques, cardiaques, nerveuses et rénales pour effectuer des tests toxicologiques.Des modèles de peau humaine sont utilisés pour la recherche sur les vaccins : les équivalents cutanés humains et les explants peuvent remplacer les modèles animaux.Pour réduire le nombre d’animaux d’expérience et les essais multiples, le tout avec des résultats plus précis, des processus d’imagerie in vivo et ex vivo sont utilisés.
Ces méthodes permettent de mesurer la croissance tumorale à l’aide de substances luminescentes et de l’imagerie en 3D : grâce à l’histologie en fluorescence en trois dimensions, il devient possible de décrire en détail l’effet de nouvelles substances actives sur l’approvisionnement des vaisseaux sanguins tumoraux.La méthode in vitro utilisant des embryons de poisson zèbre pour tester l’effet des substances sur le développement est une solution alternative qui reste à valider.
Elle remplit pour la première fois tous les critères essentiels pour le test de toxicité développementale.
Plus perfectionné que ceux sur les tissus hépatiques de rat, ce test permet de couvrir l’ensemble du développement embryonnaire, de l’œuf fécondé à l’embryon développé.
Ainsi, il tient compte de la toxicité potentielle de produits de la dégradation sans avoir besoin de recourir à des tissus de mammifères.Précisément 1 865 403 animaux ont été utilisés en France en 2019.Le débat sur la condition et le bien-être des animaux étant grandissant, il existe de nombreuses controverses quant aux expérimentations animales.Depuis le XIXe siècle, les controverses portant sur l’expérimentation animale se font de plus en plus nombreuses dans le monde, notamment en Europe.
Ainsi, c’est la Royal Society For The Prevention Of Cruelty To Animals qui, en 1824, est la première association caritative de défense animale voyant le jour en Grande-Bretagne.
Approuvée par la Reine Victoria en 1840, d’où la mention « Royal », l’association se veut agir contre la maltraitance animale, notamment dans le cadre de l’expérimentation, en agissant avec ses membres pour sauver un animal, identifier les personnes maltraitantes, et jusqu’à changer la loi lorsque c’est possible.En France, plus récemment, le collectif Stop aux animaux dans les labos d'expérimentation (SALE), créé en 2008, organise dans plusieurs grandes villes des actions visant à informer sur les pratiques en laboratoire, et à dénoncer une certaine « propagande officielle », en prenant appui notamment sur la Directive 2010/63/UE du parlement européen et du conseil du 22 septembre 2010 relative à la protection des animaux utilisés à des fins scientifiques, qui « affirme la nécessité du recours à l'expérimentation animale pour le progrès médical et définit les conditions dans lesquelles elle peut être pratiquée dans l’Union européenne ».
Pour SALE, cette directive est jugée comme inutile, renforçant le mal-être des animaux en laboratoire.On note également depuis 1997 la création de l'Association GRAAL (Groupement de Réflexion et d'Action pour l'Animal) qui œuvre depuis plus de 20 ans à la réhabilitation des animaux de laboratoires en trouvant des alternatives (maison de retraite, adoption par des particuliers) afin de garantir une seconde vie aux animaux de laboratoires.
Ayant de nombreux partenaires (Lush, Lilo…) le GRAAL est la première association en France à avoir recherché une alternative à l'euthanasie des animaux de laboratoires.
Une autre association française, White Rabbit, recueille plus spécifiquement des lapins de laboratoire.La réhabilitation des animaux de laboratoires est basée sur le volontariat des chercheurs et n'est en aucun cas obligatoire, elle reste donc peu utilisée (500 animaux sauvés par an par le GRAAL) .En août 2022, une initiative citoyenne européenne visant une Europe sans expérimentation animale a recueilli plus de 1 400 000 signatures.En France, les propositions de loi sur la progression des méthodes de l’expérimentation animale sont, dans la majeure partie des cas, dues aux eurodéputés, et souvent rejetées.
L'association L214, qui œuvre pour le bien-être animal, est à l'origine du site Politique-animaux.fr qui recense chaque prise de position pour, en faveur, et contre les animaux en politique.
Sur l'expérimentation animale, il est apparent que les controverses et les propositions effectuées pour la diminuer proviennent des partis politiques écologistes.
Par exemple, Laurence Abeille, membre d'Europe-Écologie-Les-Verts, se prononce régulièrement contre l'expérimentation animale, pour un contrôle accentué des expérimentations animales en milieu scolaire ou pour leur interdiction concernant les cosmétiques.
Younous Omarjee, eurodéputé de l'Union d'Outre-Mer, a fait adopter en commission un projet de développement des alternatives à l’expérimentation animale pour la recherche médicale : "Trois projets (…) ont été adoptés hier par la Commission environnement du Parlement européen (…) Le deuxième projet pilote adopté ce matin vise à financer le développement de méthodes alternatives à l’expérimentation animale pour la recherche bio médicale.
Ces méthodes alternatives, encore aujourd’hui à l’état embryonnaire ou peu connues, pourraient permettre d’éradiquer un jour les tests sur animaux et mettre fin aux souffrances souvent inutiles infligées aux animaux.
Si ce projet était adopté, près d’un million d’euros seraient dédiés au développement de ces méthodes alternatives".La résistance à l'expérimentation animale a surgi au moment où l'homme a commencé à utiliser les animaux pour des expériences.
En 1871, au Royaume-Uni, une législation destinée à règlementer l'utilisation des animaux à des fins scientifiques trouve son origine dans la loi intitulée Cruelty to Animals Act.
En 1980, le conseil de l'Europe et l'Union européenne introduisent des dispositions relatives à l'expérimentation animale.L'évolution de la relation entre les humains et les animaux a remis en question l'expérimentation animale.
Or, à la différence des produits chimiques ou des composés médicaux, les produits biologiques exigent des tests à plusieurs reprises avant d'être mis sur le marché, d'où les tests systémiques sur les animaux.
De ce fait, la recherche a recours à des animaux lorsqu'il est nécessaire de découvrir les réactions du corps.Cependant, l'Union européenne prévoit un grand budget au développement et à la validation des méthodes alternatives pour les industries cosmétiques.
Les organisations de protection des animaux ont également constaté que même dans les pays dépourvus de dispositions et conditions favorables à la protection des animaux, on remarque une résistance sur les tests des animaux à des produits cosmétiques.
Il est également scientifiquement prouvé que "les tests sur les animaux à des fins de sécurité sont extrêmement problématiques dans la mesure où les résultats sont d'une qualité et une validité contestable pour les humains"Depuis plusieurs années, les autorités européennes ont intensifié leur action contre l'utilisation de l'expérimentation animale dans l'industrie cosmétique.
La Commission européenne en a une définition :Prise en 2013, la décision d’interdire, sur l’ensemble du territoire européen, tous les cosmétiques ayant fait l’objet de tests sur les animaux marque l’aboutissement d’un très long processus amorcé en 1993 avec la mise en œuvre d’une directive concernant la protection des animaux au moment de leur abattage ou de leur mise à mort.
La première directive « cosmétique » introduite en 1976 a, au fur et à mesure de ses modifications successives, établi un cadre réglementaire dans le but d’éliminer progressivement l’expérimentation animale.
C’est le Royaume-Uni qui a été le précurseur de la législation sur l’expérimentation animale dans le monde par la loi de 1997 qui interdit l’expérimentation animale dans le secteur de la cosmétique,.Cette législation met en exergue la volonté de l’Union Européenne de sensibiliser ses citoyens et de leur offrir la possibilité de mieux consommer, de manière éthique, transparente et dans le respect des droits des animaux.C’est ainsi qu’en septembre 2014 est entrée en vigueur la loi sur l’interdiction de l’expérimentation des produits cosmétiques sur les animaux vendus en Europe.
Cette loi de 2014 n’est pas une nouveauté.
En 2003, un amendement a mis en œuvre cette interdiction graduelle en prohibant à partir de 2004 l’expérimentation s’appliquant aux produits cosmétiques finis où les fabricants de cosmétiques ont l’interdiction de faire des tests sur les animaux en Europe.
Puis, en 2009, ils décident de remplacer progressivement les tests sur les animaux par d’autres procédés.
L’interdiction du 11 mars 2013 reflète la conviction du public que les cosmétiques « ne peuvent pas passer avant la vie et le bien-être ».Cependant, certains fabricants de cosmétiques utilisent toujours des animaux pour tester leurs produits avant leur commercialisation.
Selon une étude réalisée en 2016 par l’association de défense des animaux Peta, plus de 250 marques de cosmétiques, notamment Avon, Neutrogena, Guerlain, L’Occitane, MAC Cosmetics, Vidal Sassoon et Mary Kay, ont encore recours à ces pratiques.
Un pays comme la Suisse a interdit depuis 2008 l’expérimentation de produits et d’ingrédients cosmétiques sur les animaux mais cette loi est facilement contournable lorsque l’expérimentation est à visée médicale.
De ce fait, il existe des activités illégales d’expérimentation animale sur produits cosmétiques délocalisées en Suisse.Selon, la Société pour la prévention de la cruauté envers les animaux, 27 000 animaux sont utilisés pour ces tests chaque année.
Avant l’interdiction des tests, près de 9 000 animaux étaient utilisés par l’industrie cosmétique en Europe.
Ils étaient plus de 1 510 en 2004 et 344 en 2009.En 2011, 11 481 521 animaux ont été utilisés dans les laboratoires, soit 4,3 % de moins qu’en 2009.
Enfin, malgré l’interdiction des tests expérimentaux sur les animaux de 2009, encore 90 ont été utilisés pour tester des cosmétiques, en 2011.
Les lapins, les rats et les animaux à sang froid, autrement dit, les reptiles, et les poissons, sont les espèces les plus utilisées par les États membres de l’Union européenne.
En 2011, les rongeurs représentent près de 80 %, et des changements sont intervenus dans l’utilisation des espèces différentes, au fil des années.
Malgré les restrictions et les interdictions quant à l’expérimentation animale, la part des animaux utilisés, reste élevée, même si parfois la part a connu une diminution par rapport aux années précédentes.Comparaison des pourcentages des catégories d'espèces utilisés entre 1996 et 2011 :Le taux reste inchangé entre 1996 et 2011, car de nouveaux pays se sont rajoutés à l’Union européenne, et donc la proportion d’animaux utilisés devient plus grande.
En 1996, on comptait 14 membres de l’Union européenne, et 27 membres en 2011.
Bien que des pays aient rejoint l’UE, les taux sont en diminution, puisque pour 14 membres de l’Union européenne en 1996 on comptait 81,3 % de rongeurs et lapins utilisés, contre 80 % en 2011 avec 27 membres de l’UE.
Pour les rongeurs et lapins, leur proportion change légèrement, tout en restant assez stable, aux alentours de 80 %.
Concernant les animaux à sang froid, cela va de 9 % à 15,5 %, c’est seulement en 1999 que l’utilisation de ces animaux a réellement diminué, en passant à 6,6 %.
L’expérimentation sur les oiseaux en 1996 était dès lors inexistante, mais pour se contenir à un taux entre 4,7 % et 6,5 % entre 1999 et 2011.Bien plus loin que l’Europe, « l’ interdiction des tests (pour les produits cosmétiques) sur les animaux progresse partout dans le monde ».
Les pays concernés sont principalement l’Inde, la Chine, L’Australie, le Brésil, la Nouvelle-Zélande, les États-Unis et Israël.Rares sont les pays qui ont voté des lois interdisant l’expérimentation animale.
Mais cela ne reste que dans le cadre des produits cosmétiques.
Il y a eu une évolution des votes des lois dans le monde mais les années 2013-2014 sont considérées comme les années charnières avec des percées impressionnantes dans le monde entier.
PlantaeLes plantes (Plantae) sont des organismes photosynthétiques et autotrophes, caractérisés par des cellules végétales.
Elles forment l'un des règnes des Eukaryota.
Ce règne est un groupe monophylétique comprenant les plantes terrestres.La science des plantes est la botanique, qui dans son acception classique étudie aussi les algues et les cyanobactéries (qui n'appartiennent pas au règne des Plantae).
L'ancien « règne végétal » n'existe plus dans les classifications modernes (cladistes ou évolutionnistes).Le nombre d'espèces de plantes est difficile à déterminer, mais il existerait (en 2015) plus de 400 000 espèces décrites, dont la grande majorité sont des plantes à fleurs (369 000 espèces répertoriées), sachant que près de deux mille nouvelles espèces sont découvertes chaque année.
Depuis le début du XXe siècle, trois espèces de plantes disparaissent chaque année, principalement victimes de la déforestation.
Une plante sur cinq serait menacée d'extinction.Les plantes ont été jusqu'au milieu du XXe siècle l'un des trois grands groupes dans lesquels les êtres vivants étaient traditionnellement répartis, les deux autres groupes étant celui des animaux et celui des Fungi plus connus sous le nom de champignons.
La division remonte aux environs du temps d'Aristote (384 av.
qui différenciait les plantes, celles-ci ne se déplaçant pas, et les animaux souvent en mouvement pour attraper leurs proies.
Dans son Historia Plantarum, Théophraste (371-288 av.
décrit près de 480 plantes et est le premier à proposer une classification basée sur des caractères propres aux végétaux et non sur des caractères anthropocentriques.
Il en envisage d'ailleurs plusieurs : selon lui, les végétaux peuvent être répartis en quatre groupes selon leur hauteur : les arbres (dendron, d'où la dendrologie), arbrisseaux (thamnos), sous-arbrisseaux (phruganon) et plantes herbacées (poa) parmi lesquelles il classe les plantes potagères et les céréales.
Le savant grec considère également possible de distinguer à l'intérieur de ces grandes catégories les espèces domestiques et les espèces sauvages ou encore les espèces terrestres et les espèces aquatiques.
Il désigne le végétal et la plante de la même manière, avec le terme grec phytos (d'où la phytologie) alors que les Romains emploient les termes latins d’arbores et herbae.Au cours du Moyen Âge apparaissent des usages botaniques pour les termes planta et vegetabilis : le premier désigne les végétaux selon leur usage, c'est-à-dire à des fragments que l’on « plante », le second faisant référence au verbe vegetare utilisé dans le vocabulaire religieux au sens de fortifier, vivifier, faire croître (d’un point de vue spirituel).
À partir du XVIe siècle, les deux termes sont utilisés indistinctement ou alternativement pour désigner ce qui est vivant et immobile, par opposition à animalia (vivant et mobile) et à mineralia (non vivant et immobile).
À cette époque, des botanistes, notamment les frères Jean et Gaspard Bauhin, entament une réflexion sur le classement des plantes.
Ils cherchent à établir des groupes naturels de plantes à partir de leur ressemblance mais c’est le botaniste Andrea Cesalpino qui fait progresser la classification des plantes.
Dans son livre intitulé De plantis libri, paru en 1583, il propose quinze classes qui se basent sur des critères stables, tels que le caractère ligneux ou herbacé de la tige (« Arbores, Fructices, Suffructices et Herbae », les arbres, arbustes, arbrisseaux et herbes), la présence ou l'absence de graines, la forme du fruit, la présence ou l'absence d'une enveloppe autour d'elle, la forme de la racine.
Cette classification commode est employée durant deux siècles.John Ray (1628-1705), naturaliste anglais, propose d'établir un nouveau système de classification ayant pour fondement le plus grand nombre possible de caractères de la fleur, du fruit ou de la feuille.
Puis, Pierre Magnol (1638-1715), inventeur du terme famille, répertorie 76 familles de plantes.
Joseph Pitton de Tournefort (1656-1708) établit un classement des végétaux suivant la structure des fleurs et introduit les notions d'espèce et de genre.
Enfin, Carl von Linné (1707-1778), botaniste du roi de Suède, crée la base du système moderne de classification scientifique et codifie la nomenclature binominale des végétaux et des animaux.
Ces deux groupes deviennent des règnes, végétal et animal.
Sa classification des plantes basée sur le « système sexuel » (nombre d'étamines) divise les groupes naturels, et est encore un obstacle au progrès en systématique.
En 1763, Michel Adanson publie Familles des Plantes, dans laquelle il présente une classification naturelle basée sur « l'ensemble de toutes les parties de la plante » (65 caractères végétaux).
Cette classification naturelle est poursuivie par les de Jussieu et par la classification de Candolle qui améliore le système de Jussieu, en introduisant notamment les caractères anatomiques, qui permettent de distinguer les végétaux vasculaires qui présentent un système de circulation de la sève, des végétaux cellulaires.Un certain nombre d'espèces anciennement considérées comme des plantes, tels les champignons, les algues unicellulaires voire les algues pluricellulaires, commencent à être exclus de ce groupe pour former des catégories propres dès la fin du XIXe siècle.Les premières classifications semi-phylogénétiques (basées sur une appréciation subjective d'ancienneté des caractères selon un postulat aujourd'hui abandonné) sont l'œuvre de l'école allemande (classification d'Eichler (en) en 1883, classification d'Engler en 1924) et de l'école anglo-saxonne (classification de Bessey (en) en 1915, classification d'Hutchinson (en) en 1926).Les classifications modernes prémoléculaires des Angiospermes (classification de Takhtajan en 1943, classification de Cronquist en 1957, classification de Thorne en 1968, classification de Dahlgren en 1975) sont régulièrement révisées en fonction de progrès de la connaissance permettant de proposer de nouvelles hypothèses évolutives.
Ces classifications complètent les classifications phylogénétiques moléculaires actuelles, notamment les classifications phylogéniques moléculaires en clades de l'Angiosperm Phylogeny Group.
Au début du XXIe siècle, la systématique est ainsi basée sur une organisation phylogénétique rendue plus concrète par la mise en évidence de synapomorphies morphologiques ou biochimiques.Aujourd'hui la communauté scientifique francophone privilégie le terme végétaux plutôt que celui de plante, mais dans le même temps ces deux termes ne désignent plus vraiment un groupe homogène dans les classifications phylogénétiques.Le biologiste Marc-André Selosse estime la définition du terme végétal discutable et arbitraire.
Si on réunit tous les eucaryotes capables de photosynthèse, alors ce terme « flou » correspond à un groupe polyphylétique dans lequel sont rassemblées des espèces de nombreuses lignées évolutives diverses qui ont acquis (parfois par convergence) un plaste photosynthétique.
Chez plusieurs de ces lignées, la distinction animal/végétal est d'ailleurs ténue.
Le système des cinq règnes de Whittaker comprend les « Plantae » comme des eucaryotes photosynthétiques pluricellulaires (notion de métaphytes, conception non valide mais présente encore dans les manuels scolaires).
Selon une autre conception fonctionnelle macrocentrée, on peut restreindre cette définition aux Archaeplastida, comprenant les végétaux terrestres, les algues vertes et les algues rouges, ou plus restrictivement encore n'y inclure que les plantes vertes, la limiter aux plantes terrestres voire aux plantes à fleurs.En classification classique, traditionnellement, seules les algues vertes ou Chlorophytes étaient considérées comme plantes, et ne formaient donc pas un sous-règne.
La classification des autres algues dans le règne des plantes est une introduction de la classification scientifique amorcée depuis le XIXe siècle.
Auparavant, elles ont été classées de façon variable avec les protistes.
Les progrès de la phylogénie ont fait récemment disparaître certaines classes et des rapprochements morphologiquement étonnants s'opèrent dans la classification.En classification classique ou traditionnelle, le sous-règne des Bryophytes (Bryobiotina, Bryophyta lato sensu) comprend trois divisions (ou embranchements) de végétaux terrestres non vasculaires : la division des Hépaticophytes (Hepaticophyta) : 6 000 espèces de plantes hépatiques ; la division des Anthocérotophytes (Anthocerotophyta) : 100 espèces d’anthocérotes ; et la division des Bryophytes (Bryophyta stricto sensu) : 9 500 espèces de mousses.Le sous-règne des Trachéobiontes (Tracheobionta ou Tracheophyta) est composé, selon une classification traditionnelle :Les chiffres montrent la domination qu’exercent aujourd’hui les Angiospermes (Magnoliophyta) parmi les plantes.L'image ci-contre représente un arbre phylogénétique des plantes vivantes, montrant les éléments suivants :Voir aussi les articles Archaeplastida (classification phylogénétique) et Chlorophyta (classification phylogénétique), ainsi que l’article Histoire évolutive des végétaux.En agriculture, une grande division est souvent faite entre les plantes herbacées et les plantes ligneuses (celles qui forment du bois).Dans le cadre des théories sur l’optimisation de l’exploitation de ressources minérales disponibles ponctuellement dans le temps et l’espace, la compétition qu'on observe entre les modules d'une même plante à la recherche de nourriture, présente des similitudes avec les comportements de fourrageage chez les animaux.
Mais au niveau général, elle présente de fortes divergences.
L'autotrophie de la plante la rend immobile et sessile (ce qui lui permet de souder les cellules végétales entre elles par leur paroi pectocellulosique qui confère rigidité mécanique et résistance à l'ensemble), ce qui l'oppose à l'animal, hétérotrophe, au corps plus mou et mobile.
À nutrition égale, l'investissement énergétique alloué à la mobilité (au coût énergétique élevé) est important chez les animaux, alors que les plantes recourent à diverses stratégies écologiques en investissant surtout dans leur croissance, leur repousse (modules) et dans leurs défenses chimiques contre les herbivores et contre les pathogènes.Les associations symbiotiques avec des mycorhizes concernent environ 90 % des plantes vasculaires.
Ces champignons mycorhiziens assurent l'essentiel de la nutrition hydrominérale des plantes.
Par provocation, il est tentant de dire que « les plantes, dans leur état naturel, ont des mycorhizes plutôt que des racines ».Une hypothèse est que les plantes ont évolué morphologiquement et physiologiquement pour purger l'excès de carbone atmosphérique par le processus de photosynthèse.Il existe des plantes presque partout sur la Terre - dans le désert, sous l'eau, dans les forêts tropicales et même en Arctique.
Toutefois, leur répartition à la surface de la Terre est fonction des conditions climatiques.
Ainsi, pour rendre compte des principaux groupes de végétaux, le climatologue et botaniste allemand Wladimir Köppen a établi une classification des climats.
Cette classification, publiée pour la première fois en 1901 et remaniée à plusieurs reprises depuis, est la plus ancienne et la plus connue.La classification de Köppen comprend cinq groupes de climats eux-mêmes divisés en cinq types climatiques.
Le contour de chaque groupe correspond à la satisfaction d'un critère lié à la température de l'air ou combinant à la fois la température de l'air et le niveau des précipitations.La zone tropicale s'étend de part et d'autre de l'équateur entre le tropique du Cancer (23° 27' de latitude nord) et le tropique du Capricorne (23° 27' de latitude sud).
Elle représente l'une des grandes zones climatiques nées de la circulation générale de l'atmosphère et de son déplacement saisonnier.
Cette zone couvre environ 45 % de la surface globale des forêts.
La température moyenne du mois le plus froid est supérieure à + 18 degrés Celsius.
La végétation correspondante est la forêt tropicale ou la savane.Ces régions sont essentiellement caractérisées par la présence d'arbustes et d'herbes qui se sont adaptés à l'environnement désertique et qui, par un système de racines souterraines peu profond mais étendu à proximité de la surface (fasciculé), arrivent à récolter une quantité d'eau suffisante à leur croissance.
La végétation est très peu développée et recouvre peu d'espace.
Les espèces sont appelées xérophytes (du grec xero = sec, et phytos = plante), il existe des cactus, des plantes à cuticule épaisse pour limiter l'évapotranspiration, des plantes en coussinets, des succulentes (exemple famille des Crassulassées, dont le Sedum ou la joubarbe).
La plupart des plantes chlorophylliennes de ces régions fonctionnent grâce à la photosynthèse en C4.En Europe, cette forêt s'étend de la forêt boréale à la forêt méditerranéenne (entre 40° et 55° nord).
Le régime thermique est modéré avec en hiver un peu de gel sur la partie supérieure des sols, et un été modérément chaud.
Il existe trois espèces dominantes.Il existe deux grands types de végétation en milieu polaire et subpolaire incluant la toundra, située entre 55° et 70° nord, une végétation dominée par les herbes et les mousses, souvent associées à divers arbustes.
C'est une formation végétale continue et basse avec l'absence d'arbres à cause d'un sol gelé en profondeur en permanence, le pergélisol (température inférieure à 0 °C).
L'absence d'arbres est aussi due à un raccourcissement de la période de végétation (l'été ne dure parfois qu'un à deux mois) ; et la taïga, une forêt boréale de grands conifères, typique de la Sibérie et du Canada.
Les hivers sont plus longs et plus rigoureux et les mois d'été sont plus chauds (température supérieure à 10 °C).
Cela devrait représenter la limite entre la taïga et la toundra.
Le sous-bois est constitué de plusieurs conifères à aiguilles et de fougères.
Dans l'hémisphère sud, cette formation végétale est plus réduite (dans les îles de l'Antarctique, la toundra en touffes domine la région).La classification des types biologique, selon Christen Christiansen Raunkiær, est une classification écologique, qui classe les plantes selon la manière dont elles protègent leurs bourgeons à la mauvaise saison (froide ou sèche) ; elle distingue cinq groupes ou types biologiques de végétaux :Yinon et ses collègues ont en 2018 publié une évaluation quantitative du carbone stocké dans le vivant, montrant que si les plantes comptent bien moins d'espèce que le règne animal (moins que le seul groupe des arthropodes par exemple), en revanche elles constituent au sein du Vivant le « règne » qui domine largement en termes de poids de carbone, puisqu'elles sont constituées de 80 % de tout le carbone stocké par des organismes.
Le carbone de tout le Vivant terrestre et marin pèserait aujourd'hui environ 550 gigatonnes (Gt) dont 450 Gt sont des plantes, loin devant les bactéries (70 Gt) et les champignons (12 Gt), et très loin devant la faune.
En effet, la faune dont l'Homme fait partie ne compte que pour 2 Gt de Carbone (dont 50 % sont sous forme d'arthropodes), loin devant les humains qui avec 0,06 gigatonnes sont comparables aux termites ou au krill et des termites ; cependant, ajoutent les auteurs, la pression de l'Homme sur le reste de la biomasse terrestre et marine est depuis 10 000 ans énorme : L'humanité a beaucoup déforesté et elle utilise une grande quantité de végétaux pour nourrir ses troupeaux de bovins, porcs et autres animaux domestiques ou de compagnie dont le poids en carbone est aujourd'hui environ 20 fois plus élevé que celui que tous les mammifères sauvages (tout comme nos volailles domestiquées dépassent en poids l'ensemble des autres oiseaux).
L'humanité aurait déjà divisé par deux la biomasse végétale, (qui joue aussi un rôle majeur pour le climat local et global, comme puits de carbone et source d'évapotranspiration).Les plantes vivant dans les milieux où l’eau est une source limitante ont dû développer plusieurs mécanismes afin de limiter leur perte d’eau.
Certaines sont en dormance lors de la saison sèche et en germination lors de la saison de pluie, tandis que d’autres perdent une partie de leurs feuilles pendant la saison sèche, conservant ainsi quelques feuilles pour la photosynthèse.
Les racines des plantes utilisant des stratégies d’évitement de la sécheresse sont plus profondes et plus épaisses et certaines possèdent des tiges souterraines leur permettant de stocker de la nourriture (principalement les hydrates de carbone) et de l’eau pendant de longues périodes.
Leurs feuilles sont souvent épaisses et coriaces et possèdent peu de stomates.
Ceux-ci sont habituellement situés sur la face abaxiale (dorsale) de la feuille, ce qui ralentit la vitesse de transpiration.
Certaines feuilles possèdent des trichomes laineux réfléchissant ainsi la lumière et empêchant les feuilles de s’échauffer et de perdre leur eau trop vite.
Les stomates des plantes adaptées dans les milieux arides ou semi-arides sont souvent dans des cryptes de la surface foliaire, ce qui réduit la vitesse de transpiration.On appelle xérophytes les plantes capables de vivre et grandir dans des conditions de sécheresse marquée ; c’est le cas, entre autres, des plantes succulentes, qui survivent en constituant des réserves d’eau lors de pluies et en les utilisant lors de périodes de sécheresse.Les plantes de montagne ont développé plusieurs stratégies face à un milieu où la neige persiste longtemps au sol, où il y a une courte saison végétative, une extrême sécheresse, du vent, de fortes amplitudes thermiques, etc.
Le refroidissement ralentit notamment la photosynthèse et la croissance.
Ces plantes, ainsi que ceux vivant dans la toundra, ont alors développé des adaptations afin d’éviter le froid et d’en limiter ses effets.
Tout d’abord, certaines sont de petites tailles, leur permettent de profiter de la chaleur à la surface du sol et d’une protection contre le vent par le recouvrement de la neige.
D’autres végétaux, dans la toundra notamment, comme le bouleau et le saule, forment une couverture au sol, c’est-à-dire qu’ils poussent à l’horizontale et non à la verticale.
La forme des plantes peut aussi être différente.
Un motif en coussinet réduit l’évaporation et emprisonne la chaleur des rayons du soleil.
Les feuilles de certaines plantes peuvent être réduites et épaisses et leur surface épaisse et cireuse empêchant la perte d’eau par des vents desséchants.
D’autres plantes poussent comme une rosette, un tapis épais ou tout simplement blotties ensemble pour conserver leur chaleur et les aider à croître.
Un duvet peut aussi les protéger du froid.
Cette pilosité forme un écran qui limite la déshydratation provoquée par les vents et réfléchit une partie des rayonnements solaires en excès.
Les plantes adaptées au froid ont habituellement un cycle de reproduction rapide pour contrer le fait que l’été soit court et que l’hiver soit long et un système racinaire peu profond.Toute plante qui est en contact avec des concentrations anormalement fortes en sel se nomme halophyte.
Afin de pouvoir survivre dans ces conditions, les racines de ces plantes ont un potentiel osmotique très faible pour pouvoir maintenir un gradient entre la plante et les racines.
De plus, le sel peut se concentrer dans les feuilles les plus basses, celles qui tombent avant les autres, ce qui permet d’éviter les effets toxiques du sel.
Il peut aussi s’accumuler dans des organes, tels que des glandes à sels ou des vésicules, qui s’occupent de l’excréter.Un autre type de plante peut se développer dans les milieux salés, il s’agit des glycophytes.
Ceux-ci excluent les ions de leurs feuilles et les accumulent dans les racines et les tiges.Les hydrophytes représentent le groupe de végétaux vivant entièrement ou partiellement dans l’eau.
L’ensemble de leur appareil végétatif est donc en contact avec l’eau.
Comme la concentration du dioxygène dans ce milieu ne se retrouve pas à la même concentration que dans l’air, ces plantes ont développé des stratégies d’acquisitions.
Entre autres, elles possèdent des aérenchymes, un tissu parenchymateux (constitué de cellules vivantes) comportant de larges espaces intercellulaires remplis d’air, servant à transporter le dioxygène des parties hors de l’eau vers celles sous l’eau.
De plus, ces plantes absorbent l’eau directement du milieu extérieur grâce à la surface de leur feuille qui n’est pas ou peu cutinisée (substance prévenant les pertes d’eau).
Il n’y a alors aucune transpiration effectuée.La plupart des végétaux possèdent des adaptations qui leur permettent de survivre ou de se défendre contre les agressions.
Elles disposent pour cela d'un système de communication chimique, qui est utilisé en réponse à une agression ou à un agresseur afin d'en minimiser les dégâts, voire de les éliminer.
Les parties lésées libèrent des molécules de glutamate qui génèrent un signal chimique sous la forme d'un flux d'ions calcium, qui se propage à des vitesses de l'ordre du mm/s (donc beaucoup moins vite que chez les animaux, jusqu'à 120 m/s) et déclenche ailleurs la sécrétion d'hormones défensives qui activent différents systèmes de défense.Toutefois, ériger des structures de défense a un coût.
Par exemple, à la suite de l’apparition d’un polluant atmosphérique, une plante présentera des signes de faiblesse allant d’une baisse de rendement aux nécroses, parce qu’elle a dû consacrer beaucoup d’énergie à la construction de structures de défense.Les plantes présentent diverses défenses contre les herbivores.
Ces dernières peuvent être physiques, chimiques, mais également symbiotiques.
Elles peuvent ériger des structures qui préviendront l’herbivorie telles que des épines, des trichomes, ou posséder des parois cellulaires composées de lignine, une substance n’étant pas digestible par les mammifères.
Elles peuvent aussi produire des composés qui auront mauvais goût, qui seront toxiques ou qui attireront les prédateurs des herbivores (surtout pour les insectes).
La production de canavanine par les plantes, par exemple, peut être toxique pour les insectes qui l’ingèrent car cet acide aminé prend la place de l’arginine dans les protéines de la victime, altérant ainsi leurs fonctions.
Avec le temps, cette stratégie limite l’herbivorie de ces insectes qui trouvent de nouvelles sources de nourriture, ce qui protège les plantes.Certaines plantes sont aussi capables de s’adapter à l’apparition d’un polluant dans leur environnement.
Parmi ces polluants, on retrouve entre autres l’acide fluorhydrique, qui perturbe le métabolisme du calcium des végétaux, ainsi que l’ozone, qui oxyde les composés des plantes et donc, qui leur est très néfaste.
En réponse à cette dernière substance, une plante peut produire des composés phénoliques ou augmenter la production de cire cuticulaires pour se défendre.Les plantes ne sont pas toutes exposées aux mêmes conditions.
Certaines ont développé des adaptations leur permettant de résister au froid.
L’une d’entre elles consiste à avoir une très petite taille et donc à se situer le plus près du sol possible où la température est habituellement de quelques degrés plus élevée.
De plus, lorsqu’il y a de la neige, ces plantes se retrouvent protégées du froid et du vent par cette dernière.
Une autre façon de réduire les dommages causés par le froid est d’adapter une forme circulaire.
Non seulement cette forme procure une meilleure protection contre le froid, elle permet aussi de limiter les pertes d’eau puisque c’est celle qui a le plus petit rapport surface/volume.Il existe, selon leur degré de différenciation, quatre grands types d'organisation incluant les thallophytes, plantes vivant en milieux humides, caractérisées par un thalle, appareil végétatif peu différencié en forme de lame - algues ; les bryophytes : ce sont les mousses et les hépatiques, dont l’appareil végétatif commence à se différencier en tige et feuille.
Ils constituent une nouvelle étape vers le passage de la vie aquatique à la vie terrestre ; les tracheophyta (anciennement appelées cormophytes ou « végétaux supérieurs ») : ce sont les plantes vasculaires ou plantes à racines (rhizophytes), qui comprennent les ptéridophytes (fougères) et les spermaphytes (plantes à graines).
L’appareil végétatif est maintenant bien différencié en racine, tige, feuille et surtout vaisseaux conducteurs de sève (phloème et xylème).
C’est grâce à ces vaisseaux conducteurs et à leur port dressé et rigide (par synthèse de la cellulose dans l’espace intercellulaire de ces vaisseaux, pour la construction d’un squelette de bois) que ces plantes sont adaptées au milieu terrestre.La pathologie végétale étudie les maladies dont souffrent les végétaux.
Le terme phytopathologie sous-entend des maladies causées par des agents infectieux externes à la plante.
Il peut s’agir de micro-organismes (bactéries et champignons), de virus, ou encore d’insectes.
Ainsi, il existe différents types de maladies (bactériennes, virales, cryptogamiques, à phytoplasmes, à nématodes…) qui dépendent de l’agent infectieux de départ.
Les maladies parasitaires des végétaux sont aussi générées par des problèmes environnementaux, la pollution ou encore par la destruction de certaines biodiversités qui génèrent des modifications de notre écosystème.Toutes les espèces végétales peuvent être sujet à des phytopathologies.
Par conséquent, les cultures exposées peuvent développer des symptômes très différents tels que :Les phytovirus ont la particularité de pénétrer la cellule végétale de leur hôte afin de tirer profit des mécanismes de la cellule et donc pouvoir, par la suite, se reproduire.C’est notamment le cas du virus de la mosaïque du tabac qui s’attaque aux plants de tabac.
Constitué d’un brin d’ARN spiralé autour duquel se développe des sous-unités protéiques, il a été le premier virus identifié.
Cet ensemble de protéines constitue la capside du virus.
Une fois la plante infectée, les feuilles de cette-dernière vont prendre l’apparence d’une mosaïque, d'où le nom du virus.
Il est généralement transmis par voie mécanique notamment grâce aux vêtements ou aux structures de serres, voie qui s'avère être très efficace.
Pour limiter la propagation de ce virus, il est recommandé de pratiquer la prophylaxie poussée.Les bactéries peuvent être à l’origine de nombreuses phytopathologies et engendrer différents symptômes tels que des pourritures, des chancres, des nécroses, des jaunissements… Pour s’introduire dans la plante, les bactéries se faufilent par des ouvertures naturelles (stomates) ou bien par des blessures.Il résulte de la colonisation de la plante par différentes bactéries telles que Clavibacter michiganensis sepedonicus ou Ralstonia solanacearum.
Ce type d’infection fait des ravages sur les cultures de pommes de terre, de tomates ou encore de riz.Par exemple, chez la tomate, l’agent pathogène est Ralstonia solanacearum.
Cette bactérie vit enfouie dans le sol à une profondeur d’environ 30 cm.
Elle peut donc être disséminée par les pratiques d’irrigation ou encore par les pratiques culturales pouvant blesser la plante et faciliter son infiltration.
Son mode d’action est d’empêcher la circulation de la sève brute, constituée d’eau et de sels minéraux.
Les feuilles de la plante sont alors privées de nutriments et se flétrissent.
Lorsque la charge bactérienne est élevée, le flétrissement affecte toute la plante qui se rabougrit et meurt.Il résulte de la colonisation des arbres fruitiers par des bactéries du genre Pseudomonas.
Notamment Pseudomonas syringae, une bactérie Gram négative, qui produit une protéine permettant à l’eau de geler malgré des températures supérieures à 0 °C.
Les plantes infectées sont alors plus sensibles au gel et reconnaissable par l’apparition d'une tâche brune de forme concave qui se répand sur les branches et le tronc de l’arbre.
Puis survient une déformation de l’écorce, due au développement de boursouflures et de crevasses.
Enfin, l’altération de l’écorce provoque un écoulement de gomme.
Durant l’été, la bactériose végétale peut toucher les organes verts et les feuilles âgées de la plante.La chlorose est une maladie qui est générée par un manque de fer ou de magnésium et qui se manifeste par un manque de coloration sur les feuilles dû à un déficit en chlorophylle, mais une coloration très prononcée sur les nervures.
Edward Jenner, membre de la Royal Society (17 mai 1749 - 26 janvier 1823), est un scientifique et médecin anglais qui étudia les sciences naturelles dans son environnement à Berkeley, dans le Gloucestershire, en Angleterre.Il est le premier médecin à avoir introduit et étudié de façon scientifique le vaccin contre la variole, et est considéré comme le « père de l'immunologie ».Il naît le 17 mai 1749 à Berkeley en Angleterre.
Jenner fut formé à Chipping Sodbury, dans le Gloucestershire comme apprenti de M. Ludlow, un chirurgien, pendant huit ans à partir de l'âge de 14 ans.
Jenner partit pour Londres en 1770 en vue d'étudier la chirurgie et l'anatomie sous la direction du chirurgien John Hunter et également à l’université St George de Londres.
Hunter était un expérimentateur renommé qui fut plus tard membre de la Royal Society.William Osler rapporte que Jenner était un étudiant à qui Hunter répétait une maxime de William Harvey, très célèbre dans le milieu médical (et caractéristique de l’époque des Lumières) : « Ne croyez pas, essayez ».
Jenner fut très tôt remarqué par des hommes célèbres pour avoir fait progresser la pratique médicale et les institutions de la médecine.
Hunter a continué à correspondre avec lui sur des sujets d'histoire naturelle et l’a recommandé à la Royal Society.
De retour dans sa région natale en 1773, il devint médecin généraliste et chirurgien, exerçant son activité d’abord à Berkeley.Jenner et d'autres collègues fondèrent une société de médecine à Rodborough dans le Gloucestershire et ils se réunissaient pour dîner ensemble et lire des documents traitants de sujets médicaux.
Jenner a apporté sa contribution à des articles sur l’angine de poitrine, l’ophthalmie, les maladies des valves cardiaques et fit des observations sur la vaccine.
Il a également appartenu à une société analogue qui se réunissait à Alveston, près de Bristol.Dans le domaine de la cardiologie, il était partisan de la théorie expliquant l'angine de poitrine par les calcifications observables sur les coronaires.
Mais si cette théorie semble plus proche de la vérité que les théories concurrentes de l'époque (« névralgie » pour l'école française, par exemple), il faut se garder d'y voir simplement une correspondance avec l'explication moderne par l'athérosclérose.
En effet, la calcification n'était pas censée agir par le rétrécissement du calibre des artères, mais par l'obstacle que leur durcissement mettait à la dilatation du cœur.Il fut élu membre de la Royal Society en 1788 à la suite d'une étude détaillée sur la vie méconnue du coucou dans son nid en combinant pour son étude l’observation, l’expérimentation et la dissection.La description par Jenner du coucou tout juste éclos poussant les œufs et les oisillons de son hôte hors du nid a été confirmée au XXe siècle lorsqu’il est devenu possible de le photographier.
Ayant observé son comportement, il a mis en évidence une adaptation anatomique du bébé coucou qui présente une dépression dans le dos qui n'était plus présente après 12 jours de vie et dans laquelle il rassemble les œufs et les autres poussins pour les pousser hors du nid.
On avait supposé que les oiseaux adultes étaient responsables de cette pratique mais l'adulte n’est pas présent dans le nid suffisamment longtemps.
Ses conclusions ont été publiées dans les Philosophical Transactions de la Royal Society en 1787.Il a épousé en mars 1788 Catherine Kingscote (décédée en 1815 d’une tuberculose) qu’il avait rencontrée lorsque les aérostats sont apparus dans l’actualité des sciences et qu’il les avait expérimentés avec d'autres curieux.
Au cours de la tentative, son ballon a atterri à Kingscote Parc, propriété d’Anthony Kingscote dont Catherine était l'une des trois filles.En 1792, il obtient son doctorat en médecine de l’université de St Andrews.Il quitte peu après le comté du Gloucestershire où il est né, et lorsque James Cook l'invite à participer à son second voyage autour du monde, il refuse.Il était franc-maçon.Au XVIIIe siècle, la variole ou « petite vérole » était redoutée, car un tiers de ceux qui contractaient la maladie en mouraient et ceux qui survivaient étaient généralement défigurés.
Voltaire rapporte que 60 % des personnes contractaient la variole et que 20 % de la population en mourait.Six personnes au moins en Angleterre et en Allemagne (Sevel, Jensen, Jesty 1774, Rendall, Plett 1791) avaient expérimenté avec succès la possibilité d'utiliser une maladie bénigne commune aux vaches et aux humains, la vaccine, comme moyen d'immunisation contre la variole chez l'homme.
Ainsi en 1769, le docteur Jobst Bose, un fonctionnaire du Holstein vivant à Gottingen, montre qu'une protection contre la variole peut être acquise via le lait de vaches malades de la vaccine, et en 1774 un agriculteur du Dorset, Benjamin Jesty, réussit à induire une immunité artificielle chez sa femme et ses deux enfants avec la vaccine au cours d'une épidémie de variole.
Mais ce n’est qu’à la suite des travaux de Jenner, soit une vingtaine d'années après ces premières expériences, que le procédé sera largement compris.
Il est d'ailleurs généralement admis que Jenner n'était pas au courant du succès de Jesty et est arrivé indépendamment aux mêmes conclusions.En partant de l'observation courante que les trayeuses ne contractaient généralement pas la variole, Jenner a théorisé que le pus présent dans les vésicules des trayeuses qui avaient contracté la vaccine (une maladie semblable à la variole, mais beaucoup moins virulente), protégeait les trayeuses de la variole.
Il est possible qu’il ait été aidé par le fait d’avoir entendu l’histoire de Benjamin Jesty et peut-être d'autres pionniers qui avaient délibérément infecté leurs familles par la vaccine et constaté une réduction des risques dans ces familles.Le 14 mai 1796, Jenner a testé sa théorie en inoculant James Phipps, un jeune garçon de huit ans, avec le contenu ( du pus) des vésicules de vaccine de la main de Sarah Nelmes, une trayeuse qui avait contracté la vaccine transmise par une vache nommée Blossom.
Phipps a été le dix-septième cas décrit dans le premier article de Jenner sur la vaccination.Jenner inocula Phipps avec le pus de la vaccine dans les deux bras le même jour, en grattant le pus des vésicules de Nelmes avec un morceau de bois puis en le transférant sur les bras de Phipps.
Cette inoculation a provoqué de la fièvre et un malaise général, mais pas de maladie grave.
Plus tard, il a inoculé Phipps selon la technique de la variolisation qui était auparavant la méthode de routine pour obtenir l'immunité contre la maladie.
Jenner a indiqué que plus tard, le garçon a été de nouveau soumis à la variolisation et n’a pas non plus présenté de signe d'infection.Il poursuit ses recherches et les transmet à la Royal Society, qui n'avait pas publié le rapport initial.
Après l'amélioration de la méthode et d’autres travaux, il publie une étude sur vingt-trois cas.
Certaines de ses conclusions étaient correctes et d’autres erronées – les méthodes modernes de microbiologie et de microscopie peuvent permettre de répéter cette étude plus facilement.
La communauté médicale, aussi prudente à l’époque qu’aujourd'hui, étudia ses conclusions un certain temps avant de les accepter.
Finalement, la vaccination fut acceptée et, en 1840, le gouvernement britannique interdit la variolisation et encouragea la vaccination gratuite.Le vaccin contre la variole a ensuite été accepté dans toute l'Europe.
Napoléon Ier tiendra même à ce que son fils, le roi de Rome, reçoive le traitement préventif.
Louis Odier (1748-1817), médecin suisse qui a vécu à Londres, contribue à son adoption en Suisse et en France.La poursuite de ses travaux sur la vaccination empêchait Jenner de continuer sa pratique médicale habituelle.
Appuyé par ses collègues et après une requête du Parlement, le roi lui accorda 10 000 £ pour ses travaux sur la vaccination.
En 1806, il reçut à nouveau 20 000 £ pour ses travaux.En 1803 à Londres, il s'est impliqué dans le développement de la Jennerian Institution, une société s'occupant de la promotion de la vaccination pour éradiquer la variole.
En 1808, avec l'aide du gouvernement, cette société devient le National Vaccine Establishment.
Jenner est membre de la Medical and Chirurgical Society à sa fondation en 1805, et il y présente un certain nombre de ses articles.
C'est maintenant la Société Royale de Médecine.De retour à Londres en 1811, il observe un nombre significatif de cas de variole survenus après une vaccination.
Il constate que, dans ces cas, la gravité de la maladie a été considérablement atténuée par la vaccination antérieure.
En 1821, il est nommé médecin éminent par le roi George IV, un honneur national, et a été élu maire de Berkeley et juge de paix.
Il poursuit ses recherches dans le domaine de l'histoire naturelle.
En 1823, dernière année de sa vie, il présente ses observations sur la migration des oiseaux à la Royal Society.Il a été victime le 25 janvier 1823 d’une crise d’apoplexie qui s’est manifestée par une hémiplégie droite.
Il n'a jamais récupéré de sa paralysie, et est décédé des suites de ce qui était apparemment un accident vasculaire cérébral (il avait déjà subi une première attaque cérébrale) le 26 janvier 1823, à 73 ans.
Il a eu un fils et une fille.
Son fils aîné est mort de tuberculose à l'âge de 21 ans.En 1980, l’Organisation mondiale de la santé a déclaré que la variole était une maladie éradiquée.
Ce résultat était le fruit d'une coordination des efforts de santé publique accomplis par de nombreuses personnes.
Selon l'OMS, la vaccination a été une composante de ce succès dans quelques pays, mais ce sont les mesures de surveillance active et d'endiguement qui furent "en mesure de réaliser l'éradication dans un délai relativement bref", pour l'Inde par exemple.
La maladie a été éradiquée, cependant des échantillons du virus sont conservés dans des laboratoires du Centers for Disease Control and Prevention (CDC) d’Atlanta (Georgie) aux États-Unis, et du State Research Center of Virology and Biotechnology (VECTOR) à l'oblast de Koltsovo à Novossibirsk, en Russie.Benjamin Jesty, un agriculteur, avait, vingt ans avant les découvertes de Jenner, été vacciné par la vaccine pour induire une immunité contre la variole.
Il est admis que Jenner a fait la même découverte mais indépendamment, et surtout, qu'il a systématisé le processus de façon scientifique.
Les protéines sont des macromolécules biologiques présentes dans toutes les cellules vivantes.
Ce sont des polymères, formées d'une ou de plusieurs chaînes polypeptidiques.
Chacune de ces chaînes est constituée de l'enchaînement de résidus d'acides aminés liés entre eux par des liaisons peptidiques.Les protéines assurent une multitude de fonctions au sein de la cellule vivante et dans les tissus.
Ce sont des protéines enzymatiques (enzymes) qui catalysent les réactions chimiques de synthèse et de dégradation nécessaires au métabolisme de la cellule.
D'autres protéines assurent un rôle structurel au sein du cytosquelette ou des tissus (actine, collagène), certaines sont des moteurs moléculaires qui permettent la mobilité (myosine), d'autres sont impliquées dans  le  conditionnement  de  l'ADN (histones), la  régulation  de  l'expression génétique (facteurs de transcription), le métabolisme énergétique (ATP synthase) ou encore la transmission de signaux cellulaires (récepteurs membranaires).Les chaînes protéiques sont synthétisées dans la cellule au niveau du ribosome, à partir de l'information codée dans les gènes, qui déterminent l'ordre dans lequel s'enchaînent les 22 acides aminés, dits protéinogènes, qui sont incorporés directement lors de la biosynthèse des protéines.
La succession des acides aminés est appelée séquence du polypeptide.
Des modifications post-traductionnelles peuvent intervenir ensuite, une fois la protéine synthétisée, ce qui peut avoir pour effet d'en modifier les propriétés physiques ou chimiques.
Il est également fréquent que des molécules non protéiques, appelées groupes prosthétiques, se fixent de manière stable sur des protéines et contribuent de manière déterminante à leurs fonctions biologiques : c'est par exemple le cas de l'hème dans l'hémoglobine, sans lequel cette protéine ne pourrait pas transporter l'oxygène dans le sang.Les protéines adoptent une structure tridimensionnelle qui leur permet d'assurer leur fonction biologique.
Cette structure particulière est déterminée avant tout par leur séquence en acides aminés dont les propriétés physico-chimiques diverses conduit la chaîne protéique à adopter un repliement stable.Au laboratoire, elles peuvent être séparées des autres constituants cellulaires à l'aide de diverses techniques telles que l'ultracentrifugation, la précipitation, l'électrophorèse et la chromatographie.
Le génie génétique a introduit un grand nombre de méthodes permettant de faciliter la purification des protéines.
Leur structure peut être étudiée par immunohistochimie, par mutagenèse dirigée, par cristallographie aux rayons X, par résonance magnétique nucléaire et par spectrométrie de masse.Les protéines sont un composant important de l'alimentation animale, elles sont dégradées dans le tube digestif et les acides aminés libérés sont  absorbés au niveau de l'intestin grêle pour ensuite être réutilisés par l'organisme.Le terme protéine vient du grec ancien prôtos qui signifie premier, essentiel, plus précisément de πρωτει ̃ος / proteios (« qui occupe le premier rang, premier »), auquel vient s'adjoindre le suffixe -ine qui permet de former des substantifs féminin dans le vocabulaire scientifique, et particulièrement en chimie,.Cette étymologie fait probablement référence au fait que les protéines sont indispensables à la vie et qu'elles constituent souvent la part majoritaire (≈ 60 %) du poids sec des cellules (animales).
Une autre théorie voudrait que protéine fasse référence, comme l'adjectif protéiforme, au dieu grec Protée, qui pouvait changer de forme à volonté.
Les protéines adoptent en effet de multiples formes et assurent de multiples fonctions.
Toutefois, cette caractéristique ne fut mise en évidence bien plus tard, au cours du XXe siècle.Les protéines furent découvertes à partir de 1835 aux Pays-Bas par le chimiste organicien Gerardus Johannes Mulder (1802-1880), sous le nom de wortelstof.
C'est son confrère suédois, Jöns Jacob Berzelius, qui lui suggéra en 1838 le nom de protéine.Les protéines sont formées d'une ou plusieurs chaînes polypeptidiques, qui sont des biopolymères linéaires pouvant être très longs, composés d'acides L-α-aminés dont il existe une vingtaine de variétés.
On parle généralement de protéine au-delà d'une cinquantaine de résidus dans la molécule et de peptide jusqu'à quelques dizaines de résidus.Tous les acides aminés protéinogènes — à l'exception de la proline — partagent une structure commune, constituée d'une fonction acide carboxylique, d'une amine primaire sur le carbone α, et d'une chaîne latérale.
Cette dernière présente une très grande variété de structures chimiques, et c'est l'effet combiné de toutes ces chaînes latérales d'une chaîne polypeptidique qui détermine la structure tridimensionnelle ainsi que les propriétés chimiques de cette dernière.
La planche ci-dessous présente la structure chimique des 22 acides aminés protéinogènes : Les acides aminés d'une chaîne polypeptidique sont liés entre eux par des liaisons peptidiques qui s'établissent entre le carboxyle –COOH d'un premier acide aminé et l'amine primaire –NH2 d'un second :Le squelette de la protéine est ainsi constitué d'un enchaînement linéaire d'acides aminés sur lequel sont branchées les chaînes latérales et reliées par des liaisons peptidiques.
La liaison peptidique présente deux formes de résonance qui lui confèrent en partie les propriétés d'une double liaison, ce qui limite les rotations autour de son axe, de sorte que les quatre atomes du groupement amide -(C=O)NH- sont toujours à peu près coplanaires.
Les deux autres liaisons constituant le squelette de l'acide aminé peuvent en revanche tourner librement.
Les deux angles dièdres correspondant à ces deux liaisons internes déterminent la géométrie locale adoptée par la chaîne protéique.L'extrémité de la chaîne polypeptidique côté carboxyle est appelée extrémité C-terminale, tandis que celle côté amine est appelée extrémité N-terminale.
Les mots protéine, polypeptide et peptide sont assez ambigus et leur sens peut se recouvrir.
On parle généralement de protéine en référence à la molécule biologique complète dotée d'une conformation stable, tandis qu'un peptide désigne généralement une molécule plus courte dépourvue de structure tridimensionnelle stable.
La limite entre les deux est très imprécise et se situe autour de quelques dizaines de résidus d'acides aminés.Les protéines étaient censées toujours être de grande taille (aux échelles biomoléculaires) ; on sait dès le début des années 1990 que ce n'est pas le cas, à la suite de la découverte d'une, puis de quelques autres MicroProtéines (parfois dénommées MiPs).
Depuis, les scientifiques ont mis en évidence l'existence de centaines puis de milliers de microprotéines et de nanoprotéines (n'associant parfois que quelques acides aminés, peut-être auto-assemblés), si petites que les systèmes classiques d'analyse génomique ne les repéraient pas.
Elles semblent avoir des rôles-clés au sein des cellules au sein du complexe protéique, en interagissant dans les relations protéines-protéines.
Certaines contrôlent ainsi l’activité de protéines plus grosses, jouant un rôle de régulateurs post-traductionnels, sans interagir directement avec l'ADN ou l'ARN.
D'autres promeuvent le développement musculaire et régulent la contraction musculaire.
D'autres encore contribuent à la gestion des déchets intracellulaires (ARN ancien, dégradé ou défectueux).
Chez les plantes,, elles pourraient participer à la détection de la lumière et dans d'autres cas jouer un rôle dans la signalisation phytohormonale.
Chez l'animal, elles participeraient au fonctionnement de l'horloge biologique.On en trouve notamment dans les venins (d'araignées, de scorpions et d'autres animaux venimeux).
Des nanoprotéines complexes peuvent être créées in vitro par autoassemblage d'acides aminés ; elles pourraient peut-être être utilisées pour la reconnaissance et à la catalyse biomoléculaires.
On leur a déjà trouvé un intérêt commercial : certains insecticides en utilisent.
Elles présentent un intérêt médical : on s'en sert pour marquer des tumeurs cérébrales afin de permettre une chirurgie plus précise.La nature des protéines est déterminée avant tout par leur séquence en acides aminés, qui constitue leur structure primaire.
Les acides aminés ayant des propriétés chimiques très diverses, leur disposition le long de la chaîne polypeptidique détermine leur arrangement spatial.
Celui-ci est décrit localement par leur structure secondaire, stabilisée par des liaisons hydrogène entre résidus d'acides aminés voisins, et globalement par leur structure tertiaire, stabilisée par l'ensemble des interactions entre les résidus — parfois très éloignés sur la séquence peptidique mais mis en contact spatialement par le repliement de la protéine — ainsi qu'entre la protéine elle-même et son environnement.
Enfin, l'assemblage de plusieurs sous-unités protéiques pour former un complexe fonctionnel est décrit par la structure quaternaire de cet ensemble.Il peut aussi se former des liaisons covalentes supplémentaires, soit au sein d'une même chaîne protéique, soit entre différentes chaînes peptidiques au sein d'une protéine, notamment au travers de la formation de ponts disulfure entre résidus de cystéine.La plupart des protéines adoptent une conformation tridimensionnelle unique.
La forme naturelle d'une protéine in vivo est son état natif, qui correspond à la forme qu'elle prend pour être biologiquement active et fonctionnelle.
De nombreuses protéines prennent par elles-mêmes leur forme biologiquement active sous l'effet de la distribution spatiale des résidus d'acides aminés qui les constituent, d'autres ont besoin d'être assistées pour ce faire par des protéines chaperonnes pour être repliées selon leur état natif.En biochimie, on peut donc distinguer quatre niveaux d'organisation pour décrire la structure des protéines :Les protéines ne sont pas des molécules entièrement rigides.
Elles sont susceptibles d'adopter plusieurs conformations apparentées en réalisant leurs fonctions biologiques.
La transition d'une de ces conformations à une autre est appelée changement conformationnel.
Dans le cas d'une enzyme par exemple, de tels changements conformationnels peuvent être induits par l'interaction avec le substrat au niveau du site actif.
En solution, les protéines subissent également de nombreux changements conformationnels en raison de la vibration thermique de la collision avec d'autres molécules.On peut distinguer trois grands groupes de protéines en fonction de leur structure tertiaire ou quaternaire : les protéines globulaires, les protéines fibreuses et les protéines membranaires.
Presque toutes les protéines globulaires sont solubles et ce sont souvent des enzymes.
Les protéines fibreuses jouent souvent un rôle structurel, à l'instar du collagène, constituant principal des tissus conjonctifs, ou de la kératine, constituant protéique des poils et des ongles.
Les protéines membranaires sont souvent des récepteurs ou des canaux permettant aux molécules polaires ou électriquement chargées de traverser la membrane.La connaissance de la structure tertiaire, voire quaternaire, d'une protéine peut fournir des éléments importants pour comprendre comment cette protéine remplit sa fonction biologique.
La cristallographie aux rayons X et la spectroscopie RMN sont des méthodes expérimentales courantes pour étudier la structure des protéines, qui peuvent l'une et l'autre fournir des informations avec une résolution à l'échelle atomique.
Les données RMN permettent d'obtenir des informations à partir desquelles il est possible d'estimer un sous-ensemble de distances entre certaines paires d'atomes, ce qui permet d'en déduire les conformations possible de cette molécule.
L'interférométrie par double polarisation est une méthode analytique quantitative permettant de mesurer la conformation globale de la protéine ainsi que ses changements conformationnels en fonction de son interaction avec d'autres stimulus.
Le dichroïsme circulaire fournit une autre technique de laboratoire permettant de résoudre certains éléments de la structure secondaire des protéines (hélices α et feuillets β notamment).
La cryo-microscopie électronique permet d'obtenir des informations structurelles à plus faible résolution sur les très grosses protéines, notamment les virus.
La cristallographie électronique (en), technique issue de la précédente, permet dans certains cas de produire également des données à haute résolution, notamment pour les cristaux bidimensionnels de protéines membranaires.
Les structures protéiques résolues sont généralement déposées dans la Protein Data Bank (PDB), une base de données en accès libre donnant la structure d'un millier de protéines pour laquelle les coordonnées cartésiennes de chaque atome sont disponibles.Le nombre de protéines dont la structure a été résolue est bien plus faible que le nombre de gènes dont la séquence est connue.
De plus, le sous-ensemble de protéines dont la structure a été résolue est biaisé en faveur des protéines qui peuvent être aisément préparées en vue d'une analyse par cristallographie aux rayons X, l'une des principales méthodes de détermination des structures protéiques.
En particulier, les protéines globulaires sont comparativement les plus faciles à cristalliser en vue d'une cristallographie, tandis que les protéines membranaires sont plus difficiles à cristalliser et sont sous-représentées parmi les protéines disponibles dans la PDB.
Pour remédier à cette situation, des démarches de génomique structurale ont été entreprises afin de résoudre les structures représentatives des principales classes de repliement des protéines.
Les méthodes de prédiction de la structure des protéines visent à fournir le moyen de générer la structure plausible d'une protéine à partir des structures qui ont pu être déterminées expérimentalement.Les acides α-aminés protéinogènes sont assemblés en polypeptides au sein des cellules par les ribosomes à partir de l'information génétique transmise par les ARN messagers depuis l'ADN constituant les gènes.
C'est la séquence nucléotidique de l'ADN, transcrite à l'identique dans l'ARN messager, qui porte l'information lue par les ribosomes pour produire les protéines selon la séquence peptidique spécifiée par les gènes.
La correspondance entre la séquence nucléotidique de l'ADN et de l'ARN messager d'une part et la séquence peptidique des protéines synthétisées d'autre part est déterminée par le code génétique, qui est essentiellement le même pour tous les êtres vivants connus hormis un certain nombre de variantes assez limitées.Le code génétique établit la correspondance entre un triplet de bases nucléiques, appelé codon, sur l'ARN messager et un acide α-aminé protéinogène.
Cette correspondance est réalisée in vivo par les ARN de transfert, qui sont des ARN comptant une centaine de nucléotides tout au plus et portant un acide aminé esterifiant leur extrémité 3’-OH.
Chacun des acides aminés est lié à des ARN de transfert spécifiques, portant des codons eux aussi spécifiques, de sorte que chacun des 64 codons possibles ne peut coder qu'un seul acide aminé.
En revanche, chacun des 22 acides aminés protéinogènes peut être codé par plusieurs codons différents.
Ce sont les enzymes réalisant l'estérification des ARN messagers avec les acides aminés — les aminoacyl-ARNt synthétases — qui maintiennent le code génétique : en effet, ces enzymes se lient spécifiquement à la fois à un ARN de transfert donné et à un acide aminé donné, de sorte que chaque type d'ARN de transfert n'est estérifié que par un acide aminé spécifique.Le cas de la sélénocystéine et de la pyrrolysine est quelque peu différent en ce que ces acides aminés particuliers ne sont pas codés directement par des codons spécifiques mais par recodage traductionnel de codons stop en présence de séquences d'insertions particulières appelées respectivement élément SECIS et élément PYLIS, qui recodent les codons stop UGA (Opale) et UAG (Ambre) respectivement en sélénocystéine et en pyrrolysine.
De surcroît, la sélénocystéine n'est pas liée telle quelle à son ARN de transfert, car elle est trop réactive pour exister librement dans la cellule ; c'est la sérine qui est liée à un ARN de transfert de sélénocystéine ARNtSec par la sérine-ARNt ligase.
Le séryl-ARNtSec ne peut être utilisé par les ribosomes car il n'est pas reconnu par les facteurs d'élongation intervenant au cours de la biosynthèse des protéines, de sorte que la sérine ne peut être incorporée dans les sélénoprotéines à la place de la sélénocystéine.
En revanche, le séryl-ARNtSec est un substrat pour certaines enzymes qui assurent sa conversion en sélénocystéinyl-ARNtSec : conversion directe par la sélénocystéine synthase chez les bactéries, conversion indirecte via l'O-phosphoséryl-ARNtSec successivement par la O-phosphoséryl-ARNtSec kinase et la O-phosphoséryl-ARNt:sélénocystéinyl-ARNt synthase chez les archées et les eucaryotes.Les gènes codés dans l'ADN sont tout d'abord transcrits en ARN pré-messager par des enzymes telles que les ARN polymérases.
La plupart des êtres vivants modifient cet ARN pré-messager à travers un ensemble de processus appelés modifications post-transcriptionnelles conduisant à l'ARN messager mature.
Ce dernier est alors utilisable par les ribosomes pour servir de modèle lors de la biosynthèse des protéines.
Chez les procaryotes, l'ARN messager peut être utilisé dès qu'il est synthétisé ou être traduit en protéines après avoir quitté le nucléoïde.
En revanche, chez les eucaryotes, l'ARN messager est produit dans le noyau de la cellule tandis que les protéines sont synthétisées dans le cytoplasme, de sorte que l'ARN messager doit traverser la membrane nucléaire.La biosynthèse d'une protéine à partir d'un ARN messager est la traduction de cet ARNm.
L'ARN messager se lie au ribosome, qui le lit séquentiellement à raison de trois nucléotides à chaque étape de la synthèse.
Chaque triplet de nucléotides constitue un codon sur l'ARN messager, auquel peut se lier l'anticodon d'un ARN de transfert apportant l'acide aminé correspondant.
L'appariement entre le codon et l'anticodon repose sur la complémentarité de leurs séquences respectives.
C'est cette complémentarité qui assure la reconnaissance entre l'ARN de transfert et le codon de l'ARN messager.
L'acide aminé apporté par l'ARN de transfert sur le ribosome établit une liaison peptidique avec l'extrémité C-terminale de la chaîne naissante, ce qui permet de l'allonger d'un résidu d'acide aminé.
Le ribosome se déplace alors de trois nucléotides sur l'ARN messager pour faire face à un nouveau codon, qui suit exactement le codon précédent.
Ce processus se répète jusqu'à ce que le ribosome soit en face d'un codon stop, auquel cas la traduction s'arrête.La biosynthèse d'une protéine s'effectue ainsi résidu après résidu, de l'extrémité N-terminale vers l'extrémité C-terminale.
Une fois synthétisée, la protéine peut subir diverses modifications post-traductionnelles telles que clivage, phosphorylation, acétylation, amidation, méthylation, glycosylation, lipidation, voire la formation de ponts disulfure.
La taille des protéines ainsi synthétisées est très variable.
Cette taille peut être exprimée en nombre de résidus d'acides aminés constituant ces protéines, ainsi qu'en daltons (symbole Da), qui correspondent en biologie moléculaire à l'unité de masse atomique.
Les protéines étant souvent des molécules assez grosses, leur masse est souvent exprimée en kilodaltons (symbole kDa).
À titre d'exemple, les protéines de levure ont une longueur moyenne de 466 résidus d'acides aminés, pour une masse de 53 kDa.
Les plus grosses protéines connues sont les titines des sarcomères formant les myofibrilles des muscles striés squelettiques : la titine de souris contient quelque 35 213 résidus d'acides aminés formés de 551 739 atomes pour une masse de plus de 3 900 kDa et une longueur de l'ordre de 1 µm.Les petites protéines peuvent également être synthétisées in vitro par un ensemble de méthodes appelées synthèse peptidique, qui reposent sur des techniques de synthèse organique telles que la ligature chimique (en) pour produire efficacement des peptides.
La synthèse chimique permet d'introduire des acides aminés non naturels dans la chaîne polypeptidique, en posant par exemple des sondes fluorescentes sur la chaîne latérale de certains d'entre eux.
Ces méthodes sont utiles au laboratoire en biochimie et en biologie cellulaire mais ne sont généralement pas employées pour des applications commerciales.
La synthèse chimique n'est pas efficace pour synthétiser des peptides de plus de 300 résidus d'acides aminés environ, et les protéines ainsi produites peuvent ne pas adopter facilement leur structure tertiaire native.
La plupart des méthodes de synthèse chimique des protéines procèdent de l'extrémité C-terminale vers l'extrémité N-terminale, c'est-à-dire dans le sens inverse de la biosynthèse des protéines par les ribosomes.Parmi tous les constituants de la cellule, les protéines sont les éléments les plus actifs.
Hormis certains ARN, la plupart des autres molécules biologiques sont chimiquement assez peu réactives et ce sont les protéines qui agissent sur elles.
Les protéines constituent environ la moitié de la matière sèche d'une cellule d'E.
coli tandis que l'ARN et l'ADN en constituent respectivement un cinquième et 3 %.
L'ensemble des protéines exprimées dans une cellule constitue son protéome.La caractéristique principale des protéines qui leur permet de réaliser leurs fonctions biologiques est leur faculté de se lier à d'autres molécules de façon à la fois très spécifique et très étroite.
La région d'une protéine permettant de se lier à une autre molécule est son site de liaison, qui forme souvent une dépression, une cavité, ou « poche », dans la surface de la molécule.
C'est la structure tertiaire de la protéine et la nature chimique des chaînes latérales des résidus d'acides aminés du site de liaison qui déterminent la spécificité de cette interaction.
Les sites de liaison peuvent conduire à des liaisons particulièrement spécifiques et étroites : ainsi, l'inhibiteur de ribonucléase se lie à l'angiogénine humaine avec une constante de dissociation sub-femtomolaire (< 10−15 mol L−1) mais ne se lie pas du tout à la ranpirnase, homologue d'amphibien de cette protéine (constante supérieure à 1 mol L−1).
Une légère modification chimique peut radicalement modifier la faculté d'une molécule à interagir avec une protéine donnée.
Ainsi l'aminoacyl-ARNt synthétase spécifique de la valine se lie à cette dernière sans interagir avec l'isoleucine, qui lui est pourtant structurellement très proche.Les protéines peuvent se lier selon les cas à d'autres protéines ou à de petites molécules comme substrats.
Lorsqu'elles se lient spécifiquement à d'autres protéines identiques à elles-mêmes, elles peuvent polymériser pour former des fibrilles.
Ceci est fréquent pour les protéines structurelles, formées de monomères globulaires qui s'auto-assemblent pour former des fibres rigides.
Des interactions protéine-protéine régulent également leur activité enzymatique, l'avancement du cycle cellulaire et l'assemblage de grands complexes protéiques réalisant des réactions étroitement apparentées partageant une fonction biologique commune.
Les protéines peuvent également se lier à la surface des membranes cellulaires et même fréquemment en faire partie intégrante.
La capacité de certaines protéines à changer de conformation lorsqu'elles se lient à des molécules spécifiques permet de construire des réseaux de signalisation cellulaire extrêmement complexes.
D'une manière générale, l'étude des interactions entre protéines spécifiques est un élément clé de notre compréhension du fonctionnement des cellules et de leur faculté à échanger de l'information,.Le rôle le plus visible des protéines dans la cellule est celui d'enzyme, c'est-à-dire de biomolécule catalysant des réactions chimiques.
Les enzymes sont généralement très spécifiques et n'accélèrent qu'une ou quelques réactions chimiques.
La très grande majorité des réactions chimiques du métabolisme sont réalisées par des enzymes.
Outre le métabolisme, ces dernières interviennent également dans l'expression génétique, la réplication de l'ADN, la réparation de l'ADN, la transcription de l'ADN en ARN, et la traduction de l'ARN messager en protéines.
Certaines enzymes agissent sur d'autres protéines pour y lier ou en cliver certains groupes fonctionnels et des résidus d'autres biomolécules, selon un processus appelé modification post-traductionnelle.
Les enzymes catalysent plus de 5 000 réactions chimiques différentes.
Comme tous les catalyseurs, elles ne modifient pas les équilibres chimiques mais accélèrent les réactions, parfois dans des proportions considérables ; ainsi, l'orotidine-5'-phosphate décarboxylase catalyse en quelques millisecondes une réaction qui prendrait sinon plusieurs millions d'années,.Les molécules qui se lient aux enzymes et sont modifiées chimiquement par elles sont appelées substrats.
Bien que les enzymes soient parfois constituées de plusieurs centaines de résidus d'acides aminés, seuls quelques-uns d'entre eux entrent en contact avec le ou les substrats de l'enzyme, et un très petit nombre — généralement trois ou quatre — sont impliqués directement dans la catalyse.
On appelle site actif la région d'une enzyme impliquée dans la réaction chimique catalysée par cette protéine : il regroupe les résidus qui se lient au substrat ou contribuent à son positionnement, ainsi que les résidus qui catalysent directement la réaction.De nombreuses protéines sont impliquées dans les mécanismes de signalisation cellulaire et de transduction de signal.
Certaines protéines telles que l'insuline appartiennent au milieu extracellulaire et transmettent un signal de la cellule où elles sont synthétisées vers d'autre cellules parfois situées dans des tissus éloignés.
D'autres sont des protéines membranaires qui agissent comme récepteurs dont la fonction principale est de se lier aux molécules porteuses de signaux et d'induire une réponse biochimique dans la cellule cible.
De nombreux récepteurs membranaires ont un site de liaison exposé à l'extérieur de la cellule et un domaine effecteur (en) en contact avec le milieu intracellulaire.
Ce domaine effecteur peut être porteur d'une activité enzymatique ou peut subir des changements conformationnels agissant sur d'autres protéines intracellulaires.Les anticorps sont les constituants protéiques du système immunitaire dont la fonction principale est de se lier aux antigènes ou aux xénobiotiques afin de les marquer pour élimination par l'organisme.
Les anticorps peuvent être sécrétés dans le milieu extracellulaire ou bien ancrés dans la membrane plasmique de lymphocytes B spécialisés appelés plasmocytes.
Là où les enzymes sont très spécifiques de leurs substrats afin d'accélérer des réactions chimiques très précises, les anticorps n'ont pas cette contrainte ; en revanche, leur affinité pour leur cible est extrêmement élevée.De nombreuses protéines transporteuses de ligands se lient spécifiquement à de petites molécules et les transportent à destination à travers les cellules et les tissus des organismes multicellulaires.
Ces protéines doivent posséder une forte affinité pour leur ligand lorsque la concentration de celui-ci est élevée, mais doivent également pouvoir le libérer lorsque sa concentration est faible dans les tissus cibles.
L'exemple canonique de la protéine porteuse de ligand est l'hémoglobine, qui transporte l'oxygène des poumons vers les autres organes et tissus chez tous les vertébrés et a des homologues apparentés dans tous les règnes du vivant.
Les lectines sont des protéines qui se lient réversiblement à certains glucides avec une très grande spécificité.
Elles jouent un rôle dans les phénomènes de reconnaissance biologique impliquant cellules et protéines.Les protéines transmembranaires peuvent également jouer le rôle de protéines transporteuses de ligands susceptibles de modifier la perméabilité de la membrane plasmique aux petites molécules polaires et aux ions.
La membrane elle-même possède un cœur hydrophobe à travers lequel les molécules polaires ou électriquement chargées ne peuvent pas diffuser.
Les protéines membranaires peuvent ainsi contenir un ou plusieurs canaux à travers la membrane cellulaire et permettant à ces molécules et à ces ions de la traverser.
De nombreux canaux ioniques sont très spécifiques de l'ion dont ils permettent la circulation.
Ainsi, les canaux potassiques et les canaux sodiques sont souvent spécifiques de l'un des deux ions potassium et sodium à l'exclusion de l'autre.Les protéines structurelles confèrent raideur et rigidité à des constituants biologiques qui, sans elles, seraient fluides.
La plupart des protéines structurelles sont fibreuses.
C'est par exemple le cas du collagène et de l'élastine qui sont des constituants essentiels de tissus conjonctifs tels que le cartilage, et de la kératine présente dans les structures dures ou filamenteuses telles que les poils, les ongles, les plumes, les sabots et l'exosquelette de certains animaux.
Certaines protéines globulaires peuvent également jouer un rôle structurel, par exemple l'actine et la tubuline dont les monomères sont globulaires et solubles mais polymérisent pour former de longs filaments rigides constituant le cytosquelette, ce qui permet à la cellule de maintenir sa forme et sa taille.Les protéines motrices sont des protéines structurelles particulières qui sont capables de générer des forces mécaniques.
Ce sont par exemple la myosine, la kinésine et la dynéine.
Ces protéines sont essentielles à la motilité des organismes unicellulaires ainsi qu'aux spermatozoïdes des organismes multicellulaires.
Elles permettent également de générer les forces à l'œuvre dans la contraction musculaire et jouent un rôle essentiel dans le transport intracellulaire.Les mannoprotéines semblent pourtant avoir des rôles-clé au sein des cellules, notamment en y contrôlant la porosité de la paroi cellulaire,,.Les protéines remplissent ainsi des fonctions très diverses au sein de la cellule et de l'organisme :La structure et les fonctions des protéines peuvent être étudiées in vivo, in vitro et in silico.
Les études in vivo permettent d'explorer le rôle physiologique d'une protéine au sein d'une cellule vivante ou même au sein d'un organisme dans son ensemble.
Les études in vitro de protéines purifiées dans des environnements contrôlés sont utiles pour comprendre la façon dont une protéine fonctionne in vivo : par exemple, l'étude de la cinétique d'une enzyme permet d'analyser le mécanisme chimique de son activité catalytique et de son affinité relative vis-à-vis de différents substrats.
Les études in silico utilisent des algorithmes informatiques pour modéliser des protéines.Pour pouvoir être analysée in vitro, une protéine doit préalablement avoir été purifiée des autres constituants chimiques de la cellule.
Ceci commence généralement par la lyse de la cellule, au cours de laquelle la membrane plasmique est rompue afin d'en libérer le contenu dans une solution pour donner un lysat.
Ce mélange peut être purifié par ultracentrifugation, ce qui permet d'en séparer les constituants en fractions contenant respectivement les protéines solubles, les lipides et protéines membranaires, les organites cellulaires, et les acides nucléiques.
La précipitation des protéines par relargage permet de les concentrer à partir de ce lysat.
Il est alors possible d'utiliser plusieurs types de chromatographie pour isoler les protéines que l'on souhaite étudier en fonction de leurs propriétés physico-chimiques telles que leur masse molaire, leur charge électrique, ou encore leur affinité de liaison.
Le degré de purification peut être suivi à l'aide de plusieurs types d'électrophorèse sur gel si la masse moléculaire et le point isoélectrique des protéines étudiées sont connus, par spectroscopie si la protéine présente des caractéristiques spectroscopiques identifiables, ou par dosage enzymatique (en) si la protéine est porteuse d'une activité enzymatique.
Par ailleurs, les protéines peuvent être isolées en fonction de leur charge électrique par focalisation isoélectrique.Les protéines naturelles requièrent éventuellement une série d'étapes de purification avant de pouvoir être étudiées en laboratoire.
Afin de simplifier ce procédé, le génie génétique est souvent utilisé pour modifier les protéines en les dotant de caractéristiques qui les rendent plus faciles à purifier sans pour autant altérer leur structure ni leur activité.
On ajoute ainsi des « étiquettes » reconnaissables sur les protéines sous forme de séquences d'acides aminés identifiées, souvent une série de résidus d'histidine — étiquette poly-histidine , ou His-tag — à l'extrémité C-terminale ou à l'extrémité N-terminale de la chaîne polypeptidique.
De ce fait, lorsque le lysat est placé dans une colonne chromatographique contenant du nickel, les résidus d'histidine se complexent au nickel et restent liées à la colonne tandis que les constituants dépourvus d'étiquette la traversent sans être arrêtés.
Plusieurs types d'étiquettes ont été développés afin de permettre aux chercheurs de purifier des protéines particulières à partir de mélanges complexes.L'étude in vivo des protéines implique souvent de savoir précisément où elles sont synthétisées et où elles se trouvent dans les cellules.
Bien que la plupart des protéines intracellulaires soient produites dans le cytoplasme et que la plupart des protéines membranaires ou sécrétées dans le milieu extracellulaire sont produites dans le réticulum endoplasmique, il est rare qu'on comprenne précisément comment les protéines ciblent spécifiquement certaines structures cellulaires ou certains organites.
Le génie génétique offre des outils utiles pour se faire une idée de la localisation de certaines protéines, par exemple en liant la protéine étudiée à une protéine permettant de la repérer, c'est-à-dire en réalisant une protéine de fusion entre la protéine étudiée et une protéine utilisée comme marqueur, telle que la protéine fluorescente verte.
La localisation intracellulaire de la protéine de fusion résultante peut être facilement et efficacement visualisée par microscopie.D'autres méthodes de localisation intracellulaire des protéines impliquent l'utilisation de marqueurs connus pour certains compartiments cellulaires tels que le réticulum endoplasmique, l'appareil de Golgi, les lysosomes, les mitochondries, les chloroplastes, la membrane plasmique, etc.
Il est par exemple possible de localiser des protéines marquées avec une étiquette fluorescente ou ciblées avec des anticorps contre ces marqueurs.
Les techniques d'immunofluorescence permettent ainsi de localiser des protéines spécifiques.
Des pigments fluorescents sont également utilisés pour marquer des compartiments cellulaires dans un but similaire.L'immunohistochimie utilise généralement un anticorps ciblant une ou plusieurs protéines étudiées qui sont conjugués à des enzymes émettant des signaux luminescents ou chromogènes pouvant être comparés à divers échantillons, ce qui permet d'en déduire des informations sur la localisation des protéines étudiées.
Il est également possible d'utiliser des techniques de cofractionnement dans un gradient de saccharose (ou d'une autre substance) à l'aide d'une centrifugation isopycnique.La microscopie immunoélectronique combine l'utilisation d'une microscopie électronique classique à l'utilisation d'un anticorps dirigé contre la protéine étudiée, cet anticorps étant préalablement conjugué à un matériau à forte densité électronique telle que l'or.
Ceci permet de localiser des détails ultrastructurels ainsi que la protéine étudiée.L'ensemble des protéines d'une cellule ou d'un type de cellule constitue son protéome, et la discipline scientifique qui l'étudie est la protéomique.
Ces deux termes ont été forgés par analogie avec le génome et la génomique.
Si le protéome dérive du génome, il n'est cependant pas possible de prédire exactement quel sera le protéome d'une cellule à partir de la simple connaissance de son génome.
En effet, l'expression d'un gène varie d'une cellule à l'autre au sein d'un même organisme en fonction de la différenciation cellulaire, voire dans la même cellule en fonction du cycle cellulaire.
Par ailleurs, un même gène peut donner plusieurs protéines (par exemple les polyprotéines virales), et des modifications post-traductionnelles sont souvent nécessaires pour rendre une protéine active.Parmi les techniques expérimentales utilisées en protéomique, on relève l'électrophorèse bidimensionnelle, qui permet la séparation d'un grand nombre de protéines, la spectrométrie de masse, qui permet l'identification de protéines rapide et à haut débit ainsi que le séquençage de peptides (le plus souvent après digestion en gel (en)), les puces à protéines (en), qui permettent la détection de concentrations relatives d'un grand nombre de protéines présentes dans une cellule, et l'approche double hybride qui permet également l'exploration des interactions protéine-protéine.
L'ensemble des interactions protéine-protéine d'une cellule est appelé interactome.
L'approche visant à déterminer la structure des protéines parmi toutes leurs conformations possibles est la génomique structurale.Il existe à présent tout un ensemble de méthodes informatiques permettant d'analyser la structure, la fonction et l'évolution des protéines.
Le développement de tels outils a été rendu nécessaire par la grande quantité de données génomiques et protéomiques disponibles pour un très grand nombre d'êtres vivants, à commencer par le génome humain.
Il est impossible d'étudier toutes les protéines expérimentalement, de sorte que seules un petit nombre d'entre elles font l'objet d'études au laboratoire tandis que les outils de calcul permettent d'extrapoler les résultats ainsi obtenus à d'autres protéines qui leur sont semblables.
De telles protéines homologues sont efficacement identifiées par les techniques d'alignement de séquences.
Des outils de profilage des séquences peptidiques permettent de localiser les sites clivés par les enzymes de restriction, les cadres de lecture dans les séquences nucléotidiques, et de prédire les structures secondaires.
Il est également possible de construire des arbres phylogénétiques et d'élaborer des hypothèses relatives à l'évolution à l'aide de logiciels tels que ClustalW (en) permettant de remonter aux ancêtres des organismes modernes et à leurs gènes.
Les outils bio-informatiques sont devenus indispensables à l'étude des gènes et des protéines exprimées par ces gènes.En plus de la génomique structurelle, la prédiction de la structure des protéines vise à développer des moyens permettant d'élaborer efficacement des modèles plausibles décrivant la structure de protéines qui n'ont pu être résolues expérimentalement.
Le mode de prédiction de structure de plus efficace, appelé modélisation par homologie, se fonde sur l'existence de structures modèles connues dont la séquence présente des similitudes avec celle de la protéine étudiée.
Le but de la génomique structurelle est de fournir suffisamment de données sur les structures résolues afin de permettre l'élucidation de celles qui restent à résoudre.
Bien qu'il demeure malaisé de modéliser précisément des structures lorsqu'il n'existe que des modèles structurels éloignés auxquels se référer, on pense que le nœud du problème se trouve au niveau de l'alignement des séquences car des modèles très exacts peuvent être établis dès lors qu'un alignement de séquences très exact est connu.
De nombreuses prédictions de structures ont été utiles au domaine émergent du génie protéique (en), qui a notamment élaboré de nouveaux modes de repliement.
Un problème plus complexe à résoudre par le calcul est la prédiction des interactions intermoléculaires, comme la prédiction de l'ancrage des molécules et des interactions protéine-protéine.Le repliement et la liaison des protéines peuvent être simulés à l'aide de techniques telles que la mécanique moléculaire, la dynamique moléculaire et la méthode de Monte Carlo, qui bénéficient de plus en plus des architectures informatiques parallèles et du calcul distribué, comme le projet Folding@home ou la modélisation moléculaire sur processeur graphique.
Le repliement de petits domaines protéiques en hélice α, comme la coiffe de la villine et la protéine accessoire du VIH ont été simulées in silico avec succès, et les méthodes hybrides qui combinent la dynamique moléculaire standard avec des éléments de mécanique quantique ont permis l'exploration des états électroniques des rhodopsines.Le plan de fabrication des protéines dépend donc en premier lieu du gène.
Or les séquences des gènes ne sont pas strictement identiques d'un individu à l'autre.
De plus, dans le cas des êtres vivants diploïdes, il existe deux exemplaires de chaque gène.
Et ces deux exemplaires ne sont pas nécessairement identiques.
Un gène existe donc en plusieurs versions d'un individu à l'autre et parfois chez un même individu.
Ces différentes versions sont appelées allèles.
L'ensemble des allèles d'un individu forme le génotype.Puisque les gènes existent en plusieurs versions, les protéines vont également exister en différentes versions.
Ces différentes versions de protéines vont provoquer des différences d'un individu à l'autre : tel individu aura les yeux bleus mais tel autre aura les yeux noirs, etc.
Ces caractéristiques, visibles ou non, propres à chaque individu sont appelées le phénotype.
Chez un même individu, un groupe de protéines à séquence similaire et fonction identique est dit isoforme.
Les isoformes peuvent être le résultat de l'épissage alternatif d'un même gène, l'expression de plusieurs allèles d'un gène, ou encore la présence de plusieurs gènes homologues dans le génome.Au cours de l'évolution, les accumulations de mutations ont fait diverger les gènes au sein des espèces et entre espèces.
De là provient la diversité des protéines qui leur sont associées.
On peut toutefois définir des familles de protéines, elles-mêmes correspondant à des familles de gènes.
Ainsi, dans une espèce peuvent coexister des gènes, et par conséquent des protéines, très similaires formant une famille.
Deux espèces proches ont de fortes chances d'avoir des représentants de même famille de protéines.On parle d'homologie entre protéines lorsque différentes protéines ont une origine commune, un gène ancestral commun.La comparaison des séquences de protéines permet de mettre en évidence le degré de « parenté » entre différentes protéines, on parle ici de similarité de séquence.
La fonction des protéines peut diverger au fur et à mesure que la similarité diminue, donnant ainsi naissance à des familles de protéines ayant une origine commune mais ayant des fonctions différentes.L'analyse des séquences et des structures de protéine a permis de constater que beaucoup s'organisaient en domaines, c'est-à-dire en parties acquérant une structure et remplissant une fonction spécifique.
L'existence de protéines à plusieurs domaines peut être le résultat de la recombinaison en un gène unique de plusieurs gènes originellement individuels, et réciproquement des protéines composés d'un unique domaine peuvent être le fruit de la séparation en plusieurs gènes d'un gène originellement codant une protéine à plusieurs domaines.Lors de la digestion, à partir de l'estomac les protéines d'origines végétales, bactériennes, fongiques ou animales sont désagrégées (hydrolysées) par des protéases ; découpées en polypeptides et ensuite en acides aminés utiles pour l'organisme, y compris en acides aminés essentiels (que l'organisme ne peut pas synthétiser).
Le pepsinogène est converti en pepsine au contact de l'acide chlorhydrique stomacal.
La pepsine est la seule enzyme protéolytique qui digère le collagène, la principale protéine du tissu conjonctif.
La digestion des protéines a surtout lieu dans le duodénum.
Elles sont principalement absorbées quand elles arrivent dans le jéjunum et seules 1 % des protéines ingérées se retrouvent dans les fèces.
Certains acides aminés restent dans les cellules épithéliales de l'intestin, utilisés pour la biosynthèse de nouvelles protéines, y compris des protéines intestinales constamment digérées, recyclées et absorbées par l'intestin grêle.La digestibilité des protéines varie considérablement selon leur nature et la préparation de l'aliment.L'ANSES recommande un apport nutritionnel conseillé (ANC) de 0,83 g·kg-1·j-1, pour un maximum de 2,2 g·kg-1·j-1 chez l’adulte en bonne santé, soit 62 g par jour pour un homme de 75 kg.
Il faut noter que les ANC sont supérieurs aux besoins moyens qui sont de 0,66 g·kg-1·j-1 selon ce même rapport, ce qui donnerait 49,5 g par jour pour le cas précédent.Les besoins moyens en protéines ont été définis par la FAO qui recommande 49 g de protéines pour les hommes adultes et 41 g pour les femmes (47 si enceintes, 58,5 si allaitantes).Selon l'American Heart Association, il n'est pas nécessaire de consommer des protéines animales pour avoir suffisamment de protéines dans son alimentation : les protéines végétales peuvent fournir suffisamment d'acides aminés essentiels et non essentiels, pourvu que les sources de protéines alimentaires soient variées et que l'apport calorique suffise à répondre aux besoins énergétiques.
Il n'est pas nécessaire de les combiner dans un même repas.
L'Association américaine de diététique rappelle elle aussi que les protéines végétales peuvent répondre aux exigences en matière de protéines si l'alimentation végétale est variée et répond aux besoins en énergie.
De plus, « un assortiment d'aliments végétaux consommés au cours d'une journée peut fournir tous les acides aminés essentiels et assurer une rétention et une utilisation suffisantes de l'azote chez les adultes en bonne santé, de sorte que la combinaison de protéines au cours d'un même repas n'est pas nécessaire.
»La totalité des acides aminés nécessaires doit être apportée par la nourriture, sous peine d'être carencé, ce qui implique des sources diversifiés de protéines.
La recommandation de combiner les protéines animale et végétales dans chaque repas est invalidée depuis 1994 à la suite d'un article de Vernon Young et Peter Pellett devenu une référence sur le métabolisme des protéines chez l'homme, confirmant que la combinaison de protéines dans les repas est totalement inutile.
Les personnes ne souhaitant pas manger de protéines animales ne risquent pas de déséquilibre d'amino-acides des protéines végétales de leur régime alimentaire.
De nombreuses protéines végétales contiennent un peu moins d'un ou de plusieurs des acides aminés essentiels (lysine surtout et moindrement méthionine et thréonine), sans pour autant que la consommation exclusive de sources de protéines végétales empêche d'avoir une alimentation équilibrée en acides aminés essentiels.Les conclusions de l'article de Young et Pellet sont seulement à considérer dans le cas très général où les céréales ne sont pas la source exclusive de l'alimentation, ce qu'ils prennent soin de préciser d'ailleurs, où qu'ils explicitent dans d'autres articles.
Ainsi dans certaines régions défavorisées les rations alimentaires peuvent ne comporter que des céréales, ce qui entraîne de graves problèmes de santé pour les jeunes enfants, par exemple dans les foyers pauvres de l'état du Madhya Pradesh en Inde (blé et riz).Par ailleurs des firmes semencières cherchent à obtenir ou ont déjà obtenu des variétés de céréales à contenu en acides aminés modifié (OGM), par exemple des maïs enrichis en lysine,.Les autorités françaises de santé (AFSSA/ANSES) refusent encore de trancher cette question.Les compléments alimentaires protéinés existent, pour les sportifs souhaitant développer leur volume musculaire, et  pour les personnes en carences de protéines.
Les protéines utilisées sont souvent des protéines issues de la luzerne (Luzerne sous forme d'extrait foliaire (EFL)) de la féverolle, du pois ou du lactosérum (sous le nom de « whey »), et des acides aminés ramifiés désignés sous le nom de « BCAA ».Les acides aminés essentiels comptent souvent pour une part importante de ces protéines (ex.
: 61,8 et 63,3 % des teneurs totales en acides aminés respectivement chez Tricholoma portentosum et Tricholoma terreum (chez lesquels la leucine, l'isoleucine et le tryptophane sont les acides aminés limitants).
Les scores d'acides aminés corrigés (PDCAAS) des protéines de ces deux champignons sont faibles par rapport à ceux de la caséine, du blanc d'œuf et du soja, mais supérieurs à ceux de nombreuses protéines végétales.
La teneur en matières grasses était faible (5,7 % pour Tricholoma portentosum et 6,6 % pour Tricholoma terreum) chez les deux espèces, les acides oléique et linoléique représentant plus de 75 % du total des acides gras.Certains comme le champignon de Paris (3,09 g de protéine pour 100 g) sont depuis longtemps cultivés et séchés, mais individuellement (comme d'autres aliments) ils peuvent être déficients en certains acides aminés (ex.
: acides aminés soufrés, méthionine et cystine dans le cas des pleurotes par exemple) mais ils sont riches en lysine et leucine qui manquent par exemple dans les céréales.
On leur découvre encore des vertus (ex.
: l'une de ces protéines semble chez la souris inhiber les allergies alimentaires) et des défauts (ex.
: une autre protéine fongique s'est montrée cardiotoxique).
Streptococcus pneumoniae (le pneumocoque) est une espèce de bactérie du genre Streptococcus.
C'est un important agent pathogène chez l'humain.
Il est notamment responsable de nombreuses co-infections : il a, par exemple, aggravé la mortalité lors de la pandémie de grippe espagnole.
Son nom initial était Diplococcus pneumonia en 1926.
Il a été rebaptisé Streptococcus pneumoniae en 1974 vu sa croissance en chaînes dans les milieux liquides.
À cause de son implication comme agent pathogène dans les pneumonies, il a longtemps été dénommé simplement pneumocoque.Les infections à pneumocoque sont particulièrement dangereuses et nécessitent très souvent une hospitalisation, avec des taux de mortalité compris entre 8 % et 15 %.Observé au microscope, le  pneumocoque se présente sous forme de diplocoques à Gram positifs lancéolés accolés par leur côté pointu, formant un chiffre 8.
Dans les produits pathologiques, les pneumocoques pathogènes sont entourés d'une capsule bien visible.Pour les différencier des streptocoques auxquels ils sont très apparentés, on parle de Streptococcus pneumoniae dans certaines nomenclatures, on se fonde sur les caractères suivants :Streptococcus pneumoniae semble pouvoir utiliser les acides du groupe de l'acide sialique comme source de carbone, ce qui expliquerait au moins en partie sa capacité à rapidement infecter les poumons ou certains d'autres organes (s'il peut y pénétrer).
Le pneumocoque ne trouve pas de sucres libres dans la trachée ou le reste de l'arbre pulmonaire, mais il peut dégrader les acides sialiques pour les transformer en sucre et s'en nourrir.La pneumolysine est la seule exotoxine protéique décrite chez le pneumocoque mais la pathogénie de cette bactérie repose principalement sur son pouvoir invasif.Communs aux autres streptocoques, de nature protéique et polysaccharidique « C » (au cours des états inflammatoires plus ou moins aigus et évolutifs, il apparaît dans le sérum des malades une protéine qui réagit par précipitation avec cet antigène C : il s'agit de la protéine C réactive ou CRP.
)Également polysaccharidiques, dont la diversité antigénique permet de distinguer plus de 90 types de pneumocoques.
75 % des infections respiratoires sont dues au type I, II, III (le plus virulent), V et VIII.C'est l'étude de ces antigènes capsulaires qui fut le départ de la génétique bactérienne.
Griffith avait constaté en 1928 que si on injecte à une souris un pneumocoque R (non capsulé) ainsi qu'une petite quantité de pneumocoques S tués, la souris meurt et on récupère des pneumocoques S (capsulés) dans son sang.
De plus, si la souche R dérive d'un pneumocoque de type I par exemple, et qu'on y ajoute du pneumocoque de type S tué de type II, les pneumocoques capsulés que l'on récupère seront du type II.Oswald Avery, en 1943, démontra que c'est l'ADN du pneumocoque lisse tué qui induit cette « transformation ».C'est donc bien la possession d'une capsule avec son antigène spécifique de type qui confère sa virulence au pneumocoque.
Seuls les anticorps anticapsulaires confèrent une immunité valable.
In vitro, les leucocytes  ne  phagocytent les pneumocoques encapsulés qu'en présence d'anticorps spécifiques de type capsulaire.La détermination de type d'un pneumocoque était essentielle à l'époque où la sérothérapie constituait le seul traitement efficace à condition bien sûr d'utiliser le sérum correspondant au type en cause.
La méthode la plus simple se fondait sur le phénomène de Neufeld : si l'on émulsionne un pneumocoque encapsulé (produit pathologique ou culture) dans une goutte d'antisérum, on observe un très net épaississement de la capsule si le type de celle-ci correspond au sérum employé.La compétence chez Streptococcus pneumoniae est contrôlée par la détection du quorum ou quorum sensing.L’induction de la compétence chez S. pneumoniae est divisée en deux phases dans le temps.
La phase « précoce » et la phase « tardive », régulées respectivement par ComE ~ P et ComX.À mesure que la population de bactéries se développe, la concentration en auto-inducteurs CSP (peptide stimulant la compétence) augmente proportionnellement.
Une fois le seuil de concentration critique atteint, le CSP extracellulaire se lie et active le récepteur ComD de l’histidine kinase correspondante.
L'activation de ComD entraîne son auto-phosphorylation et la phosphorylation de ComE, un régulateur de réponse cytosolique.ComE phosphorylé se lie à une séquence de promoteur conservée Ceb et active la transcription de ComX, ComAB et ComCDE, ComE.
ComE  est responsable de l’activation d'au moins 17 autres gènes nécessaires au développement de l'état compétent.
L'activation de la transcription génique de son propre gène et du gène codant le CSP, ComC induit la surproduction du signal auto-inducteur (CSP), conduisant ainsi à une boucle de rétroaction positive permettant de synchroniser sa perception au sein de la population bactérienne et, garantissant à toutes les cellules de la population de devenir compétentes.Les niveaux d'expression des gènes précoces induits par ComE atteignent un pic entre  7,5 et 10 min après l'induction de la CSP extracellulaire.Quant à ComX, il active la RNAP (ARN polymérase) qui transcrit les gènes tardifs nécessaires à l'absorption et à l'intégration de l'ADN.
Les niveaux d'expression des gènes tardifs induits par ComX atteignent un pic environ 12,5 à 15 min après l'induction de la CSP.
Les gènes tardifs comprennent plus de 80 gènes, dont 14 identifiés comme essentiels pour la transformation.La fonction du ComAB est d'exporter et clivé ComC en un CSP actif.Le pneumocoque est la cause la plus commune de méningites bactériennes communautaires chez l'adulte, et il est l'un des deux principaux agents mis en cause dans les otites.Chez les enfants, les infections invasives à pneumocoque concernent surtout la tranche d'âge avant 2 ans et peuvent conduire à des pneumonies et des méningites.
Cette dernière entraîne une mortalité dans 8 % à 15 % des cas, et des séquelles fréquentes : épilepsie, surdité, parésie.
Le germe est responsable d'un peu plus de 10 % de la mortalité de l'enfant de moins de 5 ans, essentiellement dans les pays du tiers-monde, ce qui constitue un problème de santé publique majeur.
Chez les enfants, les maladies favorisant les infections invasives à streptococcus pneumoniae sont l'asplénie, la drépanocytose, le HIV, mais aussi les déficits immunitaires congénitaux, les cardiopathies congénitales cyanogènes, l'insuffisance cardiaque, l'insuffisance rénale et le syndrome néphrotique, les pneumopathies chroniques, le diabète, les traitements immunosuppresseur et radiothérapique, les brèches cérébro-méningées.
Au début du XXIe siècle, les infections à pneumocoque tuaient près de 800 000 enfants par an dans le monde.Le pneumocoque est présent comme commensal des voies respiratoires chez 5 à 10 % des individus normaux, généralement en petit nombre (antagonisé par le streptococcus viridans).
Il est plus fréquent (25 à 60 %) et plus abondant chez les patients atteints de bronchite chronique sans que son rôle pathogène dans cette maladie soit nettement établi : il est généralement associé à des bacilles hémophiles.Ces formes commensales n'ont généralement pas de capsule, contrairement aux formes virulentes qui peuvent causer notamment :Ces diverses infections s'accompagnent de réactions fibrineuses qui entraînent des cloisonnements difficiles à traiter.Assez fragile dans les milieux extérieurs, ce germe se transmet surtout par les particules de salive des malades et porteurs sains par contact direct ou indirect avec les sécrétions du nez ou de la gorge d’un porteur (baiser, toux, éternuements).Au point de vue épidémiologique, la fréquence des pneumonies lobaires a nettement baissé (hygiène générale, chimiothérapie); les autres localisations restent relativement fréquentes.
Il faut noter une susceptibilité plus élevée des personnes à la peau noire vis-à-vis de ce germe.La présence de diplocoques capsulés (dans le crachat rouille de la pneumonie lobaire, le liquide cérébrospinal, dans des hémocultures, du pus de sinusite...) permet un diagnostic d'autant plus sûr et précis que les germes sont abondants et constituent l'unique flore observée.Par la sensibilité à l'optochine et aux sels biliairesIl permet l'isolement à partir d'une flore mixte.La recherche d'anticorps dans le sang du malade ne présente guère d'intérêt (trop tardive) mais on peut éventuellement révéler dans le sang ou le LCR la présence de l'antigène capsulaire en employant un sérum antipneumococcique spécifique ou polyvalent (contre-immuno-électrophorèse).Les pneumocoques sont, jusqu'à maintenant, généralement bien sensibles à la majorité des antibiotiques, sauf aux aminoglycosides.
Les pénicillines, les sulfamidés, les macrolides sont actifs sur tous les pneumocoques, quel que soit leur type.
On observe une résistance relative aux tétracyclines comme pour les streptocoques.Malheureusement, comme la plupart des germes, la résistance aux antibiotiques se diffuse progressivement et on comptait jusqu'à un quart des souches résistantes à la pénicilline aux États-Unis en 1998.Il existe plusieurs types de vaccins antipneumococciques :
La voie orale ou voie gastro-intestinale ou per os (expression latine qui signifie « par la bouche ») est une voie d'administration de médicaments, à destination entérale, qui consiste à les avaler par la bouche.L’action des médicaments pris par voie orale est parfois locale, mais le plus souvent générale (systémique) du fait d'une reprise du ou des principes actifs dans la circulation sanguine.Les formes galéniques utilisées sont solides, liquides ou orodispersibles.
Plus précisément, en fonction de la forme galénique utilisée, on distinguera la voie d'administration buccale, sublinguale, perlinguale ou encore transmuqueuse buccale (entre la lèvre et la gencive) ou palatale (entre la langue et le palais).L’administration des médicaments par voie orale a les avantages et les inconvénients suivants :Les formes orales solides sont les comprimés et les capsules.
Les capsules peuvent avoir une enveloppe dure (gélules) ou molle.
Les comprimés et les capsules à enveloppe molle sont composés d’un seul morceau, tandis que les gélules sont composées de deux semi-cupules contenant une poudre ou des granulés.Ces formes solides sont surtout utilisées pour les principes actifs solides peu solubles.
Hormis les capsules à enveloppe molle, les principes actifs liquides ne peuvent être utilisés qu’en petite quantité.Ces formes solides peuvent avoir une libération conventionnelle ou une libération modifiée, on parle alors de :La modification des conditions de libération de ces formes solides peut avoir lieu en modifiant :Les formes solides sont vendues en unidose (blister) ou en multidose (pilulier).L’administration des formes galéniques solides par voie orale a les avantages suivant : Les formes orales solides pour préparation sont des formes solides qu'il faut dissoudre ou disperser dans de l'eau avant administration.
Ces formes sont par exemple : les granulés pour solutions ou suspensions buvables, les poudres pour solutions ou suspensions buvables, les comprimés dispersibles, les comprimés effervescents, etc.Ces formes sont vendues dans des conteneurs :Les formes orales liquides sont  les solutions buvables, les sirops, les élixirs, les émulsions buvables, les suspensions buvables, les gouttes buvables, etc.Les formes orales liquides sont vendues dans des conteneurs :Les formes multidose sont fréquemment accompagnées avec des cuillères, des compte-gouttes ou des seringues graduées.Les formes multidoses permettent d’adapter facilement la posologie à chaque patient mais peuvent induire des risques d’imprécision de posologie et une possibilité d’erreur.
En plus, une fois le flacon ouvert, sa durée de conservation devient courte.
Les lymphocytes T, ou cellules T, sont une catégorie de leucocytes qui jouent un grand rôle dans la réponse immunitaire adaptative.
« T » est l'abréviation de thymus, l'organe dans lequel leur développement s'achève.Ils sont responsables de l'immunité cellulaire : les cellules infectées par un virus par exemple, ou les cellules cancéreuses reconnues comme étrangères à l'organisme (c'est-à-dire distinctes des cellules que les lymphocytes T ont appris à tolérer lors de leur maturation) sont détruites par un mécanisme complexe.Les lymphocytes T expriment tous le marqueur membranaire CD3.Il existe plusieurs types de cellules T :L'immunité cellulaire (la réponse immunitaire vis-à-vis d'organismes pathogènes à l'intérieur des cellules) implique l'activation des cellules T.CD4 et CD8 font référence aux antigènes caractéristiques à la surface des différents sous-types de lymphocytes T.
Ces molécules CD sont des marqueurs diagnostiques utiles pour identifier et quantifier ces cellules par cytométrie au moyen d'anticorps dirigés contre eux.Anciennement, au lieu de CD4 et CD8, etc., on parlait de OKT4 et OKT8, etc. et même de T4 et T8.En réalité, OKT (3 4 ou 8) est le nom générique d'une classe d'anticorps monoclonaux thérapeutiques grâce auxquels on a pu caractériser les antigènes CD3, CD4 et CD8 à la surface des lymphocytes T.La plupart des récepteurs des cellules T sont des hétérodimères formés à partir d’une chaîne alpha et d’une chaîne bêta.
Les gènes codant les protéines du récepteur des cellules T sont structurellement semblables à ceux des immunoglobulines.
Ils contiennent de nombreux domaines V, D et J pour les chaînes bêta, et seulement V et J pour les chaînes alpha.
Ces locus sont réarrangés pendant le développement des lymphocytes T, ce qui leur donne leur spécificité antigénique.Pendant le développement des lymphocytes T, les gènes codant les sous-unités constituant le récepteur des cellules T (TCR) recombinent selon le même modèle que celui décrit pour les immunoglobulines.
La recombinaison DJ concerne d’abord la chaîne bêta.
Ce processus peut concerner ou bien la jonction du segment Dβ1 et l’un des six segments Jβ1 ou bien la jonction du segment Dβ2 avec l’un des six segments Jβ2.
Comme décrit ci-dessus, la recombinaison DJ est complétée par un réarrangement Vβ-to-DβJβ.
Tous les gènes situés dans les intervalles du complexe Vβ-Dβ-Jβ sont éliminés et le transcrit primaire synthétisé comporte le segment constant(Vβ-Dβ-Jβ-Cβ).
Les modifications post-transcriptionnelles éliminent les introns et la traduction de l’ARNm produit la protéine TCR β.La recombinaison de la chaîne alpha se fait après la chaîne beta.
Elle est semblable au réarrangement des chaînes légères des immunoglobulines (VJ).
L’assemblage d’une chaîne β et α forme le TCR αβ qui est présent sur la surface d’une majorité de lymphocytes T.Il existe deux grands types de récepteur des cellules T : αβ et γδ.
Bien que les fonctions des lymphocytes portant ces deux types de récepteur des cellules T différent, les locus de gènes codant les protéines γ et δ sont recombinées de la même manière.Une absence de la protéine Artemis impliquée dans ce processus de recombinaison non homologue va bloquer la recombinaison V(D)J.
La diversification des lymphocytes T et B est entravée, voire totalement interrompue.
Leur absence dans le système immunitaire peut être la cause de différentes maladies immunodéficientes.La formation des lymphocytes T débute chez l'adulte dans la moelle osseuse et chez l'embryon dans le foie fœtal.
Un progéniteur T dont on ne connait toujours pas la nature, quitte la moelle osseuse ou le foie fœtal et colonise le thymus.Ce progéniteur pourrait être la cellule souche hématopoïétique, le MPP (multipotent progenitor), le LMPP (lympho-myeloid prime progenitor), le ELP (early lymphoid progenitor) ou le CLP (common lymphoid progenitor).
Il semblerait que le progéniteur doive exprimer le CCR9 (récepteur de la chimiokine CCL25) pour entrer dans le thymus.Au sein du thymus on distingue avec les marqueurs CD8 et CD4 trois stades successifs : un stade double négatif DN (CD4- CD8-), un stade double positif DP (CD4+ CD8+) et un stade simple positif (CD4+ CD8- ou CD4- CD8+).
Au sein des doubles négatifs avec les marqueurs CD44 et CD25 on observe quatre populations : DN1 CD44+ CD25-, DN2 CD44+ CD25+, DN3 CD44- CD25+ et DN4 CD44- CD25-.En résumé, au sein du thymus on a successivement les stades : DN1 DN2 DN3 DN4 double positifs et simple positif.
Les cellules simples positives se différencient en lymphocyte T naïfs.La spermine (une des polyamines très courantes) semble jouer un rôle important pour les thymocytes,,,,.La colonisation du thymus par les progéniteurs lymphoïdes commence au jour 11.5 de l’embryogenèse chez la souris (E11.5) et dans la huitième semaine de gestation dans l'espèce humaine, et est dirigé par au moins deux différentes voies :L'entrée des progéniteurs lymphoïdes dans le thymus n'est pas un événement continu mais périodique qui se produit par vagues pendant l'embryogenèse et à l'âge adulte,,.
Pendant l'embryogenèse, les vagues distinctes de cellules ayant colonisé le thymus donnent naissance à des lignées de lymphocytes T γδ avec différentes utilisations des chaînes Vγ et Vδ du TCR, indiquant que les progéniteurs qui colonisent le thymus fœtal diffèrent dans leur potentiel développemental des progéniteurs lymphoïdes T qui entrent dans le thymus post-natal,,,,.À la suite de leur entrée dans le thymus, les progéniteurs lymphoïdes commencent leur développement en lymphocytes T par une voie développementale communément identifiée par l'expression de CD25 et de CD44, jusqu'au stade double-négatif 3 (DN3),, caractérisé par le profil d'expression CD4- CD8- CD25+ CD44−.
Seules les cellules qui réussissent le réarrangement du gène codant la chaîne β du TCR sont sélectionnés pour une différenciation future après ce stade DN3.
Le développement initial des thymocytes jusqu'au stade DN3 est promu par la voie Notch et ses ligands Delta, et est supporté par des signaux délivrés par l'interleukine-7 (IL-7),, qui proviennent des cellules épithéliales du cortex thymique (cTECs).
Le long de cette voie développementale, les thymocytes DN immatures promeuvent la différenciation des cellules stromales thymiques et déclenchent la formation de l'environnement cortico-épithélial du thymus,,,.
Chez les souris dont le développement thymique au-delà du stade DN1 est déficient, les cellules épithéliales thymiques (TECs) arrêtent leur développement dans un stade immature, dans lequel elles expriment à la fois la kératine 5 et la kératine 8.
Elles sont alors incapables de se différencier en cTECs qui expriment la kératine 8 mais pas la kératine 5.
En conséquence, le thymus de ces souris ne forme pas de cortex histologiquement normal et contient de larges cystes,.
Cependant, chez les souris dont le développement thymique est défaillant après le stade DN3, telles que les souris déficientes pour le gène activant la recombinaison 1 (RAG-1), le cortex et les cTECs kératine 5− kératine 8+ associées sont normalement générés dans le thymus.
Ainsi, la différenciation des thymocytes du stade DN1 au stade DN3 régule la différenciation des précurseurs TEC en cTECs qui forment l'environnement cortical du thymus.D'une manière concomitante, les thymocytes DN se relocalisent vers l'extérieur, depuis la jonction cortico-médullaire vers la région subcapsulaire du cortex thymique.
De nombreux récepteurs de chimiokines, incluant CXCR4, CCR7 et CCR9, sont vraisemblablement impliqués dans le mouvement de ces thymocytes immatures : en effet, les thymocytes DN CXCR4-déficients ne parviennent pas à se diriger efficacement depuis la jonction cortico-médullaire vers le cortex et ne peuvent pas se différencier au-delà des stades DN.
De plus, les thymocytes DN2 déficients pour CCR7 (le récepteur de CCL19 et CCL21) s'arrêtent en partie dans la jonction cortico-médullaire.
En revanche, si les thymocytes DN2 et DN3 des souris CCR9-déficientes sont distribuées normalement à travers le cortex, il ne parviennent pas à s'accumuler efficacement dans la région subcapsulaire.Les lymphocytes doubles positifs migrent dans le cortex thymique, où ils sont mis en contact avec des antigènes peptidiques présentés dans les molécules du CMH des cellules épithéliales du cortex thymique.
Seuls les lymphocytes qui sont capables de se lier à un complexe CMH-peptide avec suffisamment d’affinité reçoivent un signal de survie.
Les autres vont mourir par apoptose et leur débris seront éliminés par des macrophages.
Ce phénomène est appelé « sélection positive » car les cellules survivantes sont celles qui ont lié une interaction.Selon la nature du CMH que leur TCR a pu lier, les lymphocytes doubles positifs perdent l'un des deux marqueurs.
Les cellules dont le TCR peut lier des molécules du CMH de classe I gardent le CD8 et perdent le CD4; ceux qui lient une molécule de classe II perdent le CD8 et gardent le CD4.En résumé, on garde les lymphocytes T qui reconnaissent le CMH du soi présentant un peptide.Les cellules ayant survécu à la sélection positive vont migrer dans la moelle thymique (médulla).
Une fois dans la médulla, les thymocytes sont mis à nouveau en présence de peptides issus du soi, c'est-à-dire des auto-antigènes présentés par les cellules dendritiques ou les cellules épithéliales médullaires complexés avec les molécules du CMH portées par des cellules épitheliales.
Cette fois, ce sont les cellules dont le TCR interagit fortement avec les auto-antigènes qui vont mourir par apoptose secondaire à une hyperactivation.
Comme cette fois ce sont les cellules qui ne lient pas d’interaction qui survivent, on parle de sélection négative.
C’est ce phénomène qui permet l’élimination précoce de lymphocytes auto-réactifs qui sont la cause de maladies auto-immunes.En résumé on élimine les lymphocytes reconnaissant fortement les peptides du soi présentés par le CMH.Au moment où les lymphocytes naïfs quittent le thymus, ils sont incapables de réagir à la présence de « leur » peptide.Le récepteur des cellules T (TCR) est un récepteur membranaire reconnaissant des peptides antigéniques présentés par la niche peptidique du CMH (de classe I et de classe II).
Chaque lymphocyte T possède un TCR unique spécifique d'un peptide antigénique présenté par le CMH.
Le TCR est formé de deux chaînes alpha et bêta pour les lymphocytes T alpha-bêta ou gamma-delta pour les lymphocytes T gamma-delta ; ces chaînes appartiennent à la super famille des immunoglobulines.Chaque chaîne est issue d'une recombinaison génique des fragments VDJ réalisée par les enzymes RAG1 et RAG2 au sein du thymus.
La recombinaison des chaînes bêta, gamma, delta débute au stade DN2 (double négatif, DN) et se poursuit jusqu'au stade DN3.
Si les thymocytes réussissent le réarrangement de la chaine bêta (le TCR gamma-delta est réarrangé au stade DN3) les cellules se différencient alors en DN4 puis en double positif (cellules CD4+ et CD8+).
Au stade double positif les cellules réarrangent la chaîne alpha du TCR puis subissent la sélection thymique.Les lymphocytes T naïfs vont vers les ganglions lymphatiques et les lymphocytes T mémoires (formés après la première infection) sont circulant (sang, lymphes, ganglions, etc.).Dans les ganglions lymphatiques les lymphocytes T naïfs rencontrent des cellules présentatrices d'antigènes professionnelles (CPA pro), parmi lesquelles les cellules dendritiques (en grande majorité), les macrophages et les lymphocyte B. Les "CPA pro" qui ont migré au sein des ganglions se mettent à interagir avec les lymphocytes T naïfs.
Les lymphocytes T naïfs qui possèdent un récepteur des cellules T spécifique du complexe peptide-antigène s'activeront.
La différenciation du lymphocyte T naïf en lymphocyte T activé nécessite :La première rencontre moléculaire est celle des molécules d'adhésion.
Une fois ce contact établi, les TCR vont rencontrer les complexes CMH-peptides.
En cas de rencontre épitope et paratope, la liaison de haute affinité entre le TCR et le CMH provoque la transduction de signaux dans le lymphocyte.
C'est ce qu'on appelle le « premier signal ».
Cette première activation va entrainer la synthèse de molécules CD28 et CD40L à la membrane du lymphocyte.
Ces molécules vont interagir avec des protéines membranaires de la CPA: CD80 et CD86 pour CD28, CD40 pour le CD40L et enfin LFA-1 pour ICAM-1.
En l'absence de ces molécules sur la CPA, l'activation du lymphocyte sera avortée.
En revanche, si la liaison CD80/86- CD28 se fait, le lymphocyte sera activé.
La liaison CD40/CD40L permet quant à elle l'activation finale des CPA qui vont sécréter des cytokines qui orienteront la réponse immunitaire induite tandis que la liaison LFA-1/ICAM-1 permet de stabiliser la liaison entre le TCR et le CMH.Lors de l'activation d'un lymphocyte T naïf (première infection) il y a formation d'un certain nombre de lymphocytes T mémoires (issus de l'activation et de la différenciation d'un lymphocyte T naïf).
Ces lymphocytes T mémoires sont circulants et « patrouillent » dans la lymphe, ganglions lymphatiques, sang, rate, etc. Leur seuil d'activation est plus faible comparé aux lymphocytes T naïfs, ce qui rend la réponse mémoire bien plus rapide et efficace.
Il y a également dans le cas de la réponse mémoire plus de lymphocytes T mémoires (spécifiques du même antigène) que lors de la première infection.Il existe aussi des lymphocytes B mémoires qui sont également formés après une première infection.Le facteur de nécrose tumorale contribue à l'élimination des lymphocytes T cytotoxiques activés.
Une partie des cellules se différencie en cellules mémoires qui rendront les réponses ultérieures plus efficaces.
En l'absence de signaux de survie, les autres cellules entrent de façon préprogrammée en apoptose.
Les signaux de survie sont liés à des cytokines produites par des cellules non lymphocytaires : l'interleukine 7 pour la survie des cellules naïves et l'interleukine 15 pour les cellules mémoires.
Les parvovirus canins (CPV pour Canine ParvoViruses) sont des virus très résistants dans le milieu extérieur (plusieurs mois à température ambiante) ; aussi il n'est pas aisé de s'en débarrasser, d'autant que les animaux vaccinés et guéris peuvent en être porteurs sans développer les signes cliniques.Virologiquement, ces virus sont apparentés à un autre parvovirus, le parvovirus félin (FPV pour Feline ParvoVirus), agent du typhus félin (panleucopénie féline).Les parvovirus canins sont des virus à ADN simple-brin sans enveloppe.
Ils possèdent une symétrie icosaédrale et un génome d'environ 5 000 nucléotides.Il en existe 2 types.Également appelé virus minute des chiens (VMC, ou CMV pour Canine minute virus), il est responsable d'avortements, de mortinatalité et de mortalité chez le très jeune chiot (avant 2 mois d'âge généralement).C'est l'agent de la parvovirose canine, une gastro-entérite généralement mortelle, en particulier chez les chiens les plus jeunes ou âgés.
Historiquement isolé à la fin des années 1970 à partir des premières épizooties de parvovirose canine dans des élevages américains, il a rapidement évolué sous la forme de 2 variants antigéniques (CPV-2a et CPV-2b) entre 1979 et 1985.
Les 3 formes CPV-2, CPV-2a et CPV-2b sont régulièrement isolées sur des chiens non-vaccinés présentant une gastro-entérite.
Un troisième type, CPV-2c, a été découvert en Espagne, en Italie et au Viêt Nam.
Le vaccin contre la coqueluche est un vaccin destiné à prévenir la coqueluche, une maladie causée par une bactérie du genre Bordetella.
Il existe des vaccins acellulaires et des vaccins à germes entiers.
L'efficacité du vaccin est importante et ses effets secondaires sont le plus souvent sans gravité.
Il fait partie des vaccins recommandés chez l'enfant et le jeune adulte.La coqueluche est une infection de l’arbre respiratoire inférieur contagieuse et d’évolution prolongée.
La gravité repose sur les complications pulmonaires et neurologiques, surtout chez les nourrissons.
Deux bactéries du genre Bordetella sont responsables des syndromes coquelucheux chez l’homme : Bordetella pertussis et Bordetella parapertussis.Selon leur composition, on distingue les vaccins acellulaires et les vaccins à germes entiers.
Les vaccins acellulaires contiennent des antigènes purifiés de Bordetella pertussis, pouvant être une anatoxine ou des adhésines (hémagglutinine filamenteuse, pertactine et fimbriae).
Ils sont adsorbés sur sels d'aluminium.
En France, les vaccins disponibles sont acellulaires et existent uniquement sous forme combinée :Les vaccins doivent être administrés par voie intramusculaire.En France, la primovaccination recommandée du nourrisson consiste en 2 injections à 2 mois d'intervalle, aux âges de 2 et 4 mois, suivies d'un rappel à l'âge de 11 mois.
Par la suite, des rappels sont recommandés aux âges de 6 ans, puis entre 11 et 13 ans, puis de 25 ans, selon le calendrier vaccinal 2019.L'efficacité des vaccins acellulaires est de 85 % chez l'enfant, avec une durée de 10 ans.
Elle est de 92 % chez l'adulte pour une durée de 2,5 ans.
Il n'y a pas de corrélation entre la protection et le taux d'anticorps.En raison d'une recrudescence du nombre de cas de coqueluche dans le monde, il est recommandé dans un certain nombre de pays aux femmes enceintes de se faire vacciner.
Cette vaccination apporte une protection au bébé importante et diminue le risque d'attraper la coqueluche de plus de 90 % jusqu' au 2ème mois et de 69 % la première année,,,.
L'enfant est normalement vacciné à 2 et 4 mois et est immunisé à partir de 6 mois contre la maladie.
L'immunité est plus faible après la 8ème semaine et ce, malgré la première vaccination.La tolérance des vaccins acellulaires est meilleure en comparaison avec les vaccins à germes entiers.
Les effets indésirables locaux les plus fréquents sont l'apparition de sensibilité, d'érythème ou d'œdème.
Les effets indésirables généraux les plus fréquents sont la fièvre, l'irritabilité et la somnolence.
Les effets secondaires plus rares sont les pleurs persistants, les épisodes d'hypotonie-hyporéactivité, les convulsions fébriles et les gonflements du membre du site d'injection.Les vaccins acellulaires sont contre-indiqués en cas d'antécédent de réaction d'hypersensibilité à la suite d'une vaccination contre la coqueluche ou à l'administration d'un produit constituant les vaccins (y compris les substances présentes à l'état de traces telles que certains antibiotiques ou le formaldéhyde).
Ils sont contre-indiqués en cas d'antécédent de convulsion fébrile ou d'hypotonie-hyporéactivité à la suite de l'administration du même antigène vaccinal, ou d'encéphalopathie d'origine inconnue dans les suites d'une vaccination antérieure contre la coqueluche.
La vaccination doit être faite à distance d'une affection fébrile aiguë grave.Les effets indésirables peuvent inclure : fièvres, survenue d'érythème (rougeur cutanée), réactions du système nerveux par des convulsions, de spasmes des muscles, survenue de réactions inflammatoires, état de choc et autres réactions raresLes contre-indications peuvent inclure : des antécédents d'allergie, des réactions intenses à d'autres vaccins, les encéphalopathies évolutives, fièvre (égale ou supérieur à 40 °C), une affection chronique, des affections graves de l'appareil pulmonaire, lorsque la survenue de manifestations neurologiques est constatée, il est déconseillé de procéder aux injections suivantes.Les études sur les effets indésirables des vaccinations maternelles n'ont pas montré d'effets indésirables graves chez la mère et l'enfant.
Une étude en Angleterre portant sur 20 074 femmes ayant reçu le vaccin durant leur grossesse montre qu'il n'y a pas de preuve de risques accrus pour la mère et l'enfant à naître.
En biologie et en médecine, l'immunité, est la capacité (naturelle ou acquise) d'un organisme à se défendre contre des substances étrangères et des agents infectieux (bactéries, virus, parasites).
C'est l'une des principales lignes de défenses biologiques.
Elle est mobilisée pour combattre l'infection et les maladies infectieuses, ou toute intrusion biologique indésirable, tout en présentant une certaine tolérance immunologique (nécessaire pour éviter l'allergie et la maladie auto-immune et empêcher le rejet de l'embryon/foetus par l'organisme de la mère).Ce sont les deux principales composantes du système immunitaire.
De manière complémentaire, elles contribuent à la capacité de l'organisme à repousser ou contrôler certains corps étrangers, les micro-organismes et virus.Durant la grossesse, l'immunité maternelle est naturellement modifiée, afin que le fœtus ne soit pas rejeté comme un corps étranger.
Le vaccin contre le tétanos est un vaccin destiné à prévenir le tétanos, une maladie causée par une bactérie de l'espèce Clostridium tetani.
L'efficacité du vaccin est importante et ses effets secondaires sont le plus souvent sans gravité.
Il fait partie des vaccins recommandés tout au long de la vie.Le tétanos est une toxi-infection aiguë non contagieuse due à une neurotoxine produite par la bactérie Clostridium tetani et responsable d'une atteinte neuromusculaire souvent mortelle.Le vaccin contre le tétanos disponible en France se compose d'une anatoxine adsorbée sur hydroxyde d'aluminium.Il existe également sous forme combinée :En France, la primo-vaccination recommandée des nourrissons se compose de 2 injections à 2 mois d'intervalle, aux âges de 2 et 4 mois, suivies d'un rappel à l'âge de 11 mois.
Les rappels ultérieurs recommandés sont aux âges de 6 ans puis entre 11 et 13 ans chez l'enfant.
Par la suite, chez l'adulte, les vaccinations sont recommandées aux âges de 25 ans, 45 ans et 65 ans, puis tous les 10 ans.La primo-vaccination du nourrisson est obligatoire en France.La durée de l'immunité conférée par la vaccination est évaluée à 20 ans en moyenne, avec un taux d'anticorps significatif (10 UI/L) chez 95 % des sujets à 5 ans et 91 % des sujets à 10 ans.Le vaccin contre le tétanos est prescrit par le médecin traitant ou bien une sage-femme (pour les femmes, l'entourage des femmes enceintes et l'entourage du nouveau-né jusqu'à ses 8 semaines).
Il est ensuite réalisé par voie intramusculaire, c’est-à-dire, l'administration d'un produit médicamenteux dans les muscles.
Généralement, le vaccin du tétanos est injecté dans le muscle deltoïde.
Il peut aussi être administré par voie sous-cutanée (sous la peau),.Le principal effet indésirable du vaccin contre le tétanos est la douleur au site d'injection.
Plus rarement, un épisode fébrile peut survenir, et des cas d'urticaire, d'anaphylaxie et de trismus ont été décrits.Le vaccin est contre-indiqué en cas d'hypersensibilité à un des constituants ou de troubles neurologiques survenus à la suite d'une précédente administration.
La vaccination est à différer en cas de maladie aiguë.
L’hépatite désigne toute inflammation aiguë ou chronique du foie.
Les causes les plus connues étant les infections virales du foie et l'alcoolisme.
Mais l'hépatite peut aussi être due à certains médicaments ou à un trouble du système immunitaire de l'organisme.
L'hépatite est dite aiguë lors du contact de l'organisme avec le virus ou chronique lorsqu'elle persiste au-delà de six mois après le début de l'infection.
L'hépatite peut évoluer ou non vers une forme grave (fulminante), une cirrhose ou un cancer.L'hépatite grave peut mener à la destruction du foie et, sauf transplantation hépatique, à la mort.La journée mondiale contre l'hépatite, journée internationale consacrée à la prévention, la détection ainsi que le traitement des hépatites, est organisée par l'Organisation mondiale de la santé (OMS) tous les 28 juillet.La grande majorité des hépatites est asymptomatique c’est-à-dire ne présente aucun symptôme.
Cependant, il existe des symptômes qui ne sont pas spécifiques tels qu'une fatigue chronique, des nausées, la fièvre, la perte d'appétit, les maux de tête, les urines foncées à rougeâtres (et excréments jaune clair, traduisant un problème de bilirubine), les douleurs ostéoarticulaires.
La jaunisse (ictère) est caractéristique de cette maladie mais elle n'est pas spécifique.Selon l'OMS, l’hépatite virale touche 400 millions de personnes dans le monde, mais 95 % des personnes ayant une hépatite ignorent leur infection.
Découvert en 1989, le virus de l’hépatite C est la première cause d’hépatites chroniques et de cirrhose en Europe et en Amérique du Nord.
Les hépatites virales sont les hépatites A, B, C, D, E et G.Une hépatite F pourrait exister, mais les recherches n'ont pas abouti à l'heure actuelle.Les cinq virus principaux sont l'hépatite A et E (causées par l’ingestion d’eau ou d’aliments contaminés) et l'hépatite B, C et D (habituellement survenant après un contact parentéral avec des liquides biologiques contaminés).
L’hépatite B peut se transmettre par voie sexuelle.Un adénovirus est responsable d'une forme d'hépatite aiguë chez l'enfant.Une fois dans le sang, les médicaments passent par le foie qui les métabolise et permet leur évacuation par les voies naturelles.
Parfois, c'est ce passage hépatique qui active le médicament.
Néanmoins, l'abus de certains médicaments peut conduire à une dégradation de l'état du foie et à une hépatite.
Le paracétamol, par exemple, a une toxicité hépatique connue.La borréliose de Lyme a plusieurs fois été liée à une hépatite (hépatite granulomateuse souvent), généralement subclinique (aux premiers stades de l’infection), révélée par un taux d’enzymes hépatiques anormalement élevé.
Cependant la manière dont la borréliose peut interférer avec le foie étaient en 2014 encore « largement inexplorée ».
Jusqu’alors ces hépatites n’avaient été signalées qu’en début de maladie, et en l’absence de traitement antibiotique,.
Puis un article médical de 2014, a présenté le cas d’une femme de 53 ans, diagnostiquée positive à la maladie de Lyme, après un érythème migrant survenu en 1988 à la suite d'une piqure de tique, et ayant développé une hépatite aiguë (avec des enzymes hépatiques élevées) lors d’un traitement antibiotique.
L'examen histologique des tissus de biopsie du foie a révélé des spirochètes dispersés dans tout le parenchyme hépatique.
Ces spirochètes ont été identifiés comme Borrelia burgdorferi par des tests moléculaires avec des sondes d'ADN spécifiques.
Des spirochètes mobiles ont également été isolés de l'hémoculture du patient et l'isolat a été identifié comme Borrelia burgdorferi sensu stricto par deux laboratoires indépendants utilisant des techniques moléculaires, démontrant que le patient avait une infection systémique active à Borrelia burgdorferi et une « hépatite de Lyme » consécutive, en dépit du traitement antibiotique (clarithromycine et tinidazole).
Les tests faits chez cette patiente pour le virus de l'hépatite A, le virus de l'hépatite B, le virus de l'hépatite C, le virus de l'immunodéficience humaine, le virus de l'herpès simplex, le virus d'Epstein-Barr, la syphilis, la toxoplasmose, le cytomégalovirus, les anticorps antinucléaires, les anticorps antimitochondriaux et l'enzyme de conversion de l'angiotensine étaient négatifs ou normaux.
L'échographie abdominale et l'IRM ont révélé une architecture hépatique normale sans lésions focales ni dilatation biliaire.La patiente n'avait initialement pas pris d'antibiotiques, mais ses symptômes de maladie de Lyme (principalement des myalgies et une arthrite de Lyme sévère se sont aggravés (avec des tests de la fonction hépatique montrant un excès d'enzymes hépatiques).
Le Western blot était positif pour la Borréliose de Lyme et le test pour Anaplasma phagocytophilum était négatif.
Après un traitement par corticostéroides et anti-inflammatoires n'ayant montré aucun bénéfice, elle a commencé une antibiothérapie à la clarithromycine et au cefdinir en septembre 2013.
En janvier 2014, ses symptômes de maladie de Lyme s'étaient atténués, et ses tests de fonction hépatique étaient revenus à la normale.
Le taux de CD57 NK était remonté, de 18 cellule/μl à 110 cellules/μl (la normale étant comprise entre 60 et 360 cells/μl).L’hépatite auto-immune est une maladie inflammatoire chronique du foie caractérisée par la présence d’autoanticorps.
La présence anormale de HLA II (Human Leucocyte Antigen) à la surface des hépatocytes (cellules du foie) entraîne une attaque des anticorps contre le foie : c’est l’hépatite auto-immune.
Cette maladie peut évoluer vers la cirrhose.
On peut distinguer 2 types d’hépatite auto-immune :Pour la traiter, on prescrit des corticoïdes qui sont efficaces dans 85 % des cas environ.
On peut prescrire également des immuno-suppresseurs tels que l'azathioprine ou la ciclosporine.
Si tout cela ne fonctionne pas, une transplantation peut être envisagée.Le déficit en alpha 1-antitrypsine est une maladie génétique.La stéatose hépatique non alcoolique est une surcharge en graisse du foie sans rapport avec la prise d'alcool.
C’est une maladie le plus souvent asymptomatique mais dont la prévalence est actuellement en augmentation en raison du surpoids de plus en plus fréquent.
Le problème est une évolution possible, dans un faible nombre de cas, vers une cirrhose, confirmant l’intérêt de son diagnostic.Une hépatite chronique est une pathologie nécrotico-inflammatoire du foie, de sévérité variée, excluant les maladies biliaires (cholangiopathies), la maladie alcoolique (hépatopathie alcoolique) et les stéatohépatites.Cette classification utilise les lésions élémentaires :Les termes anciens d'« hépatite chronique persistante » et « hépatite chronique agressive » ont été abandonnés.
Ils ont été remplacés à partir de 1981, de façon progressive par le score de Knodell, puis, en 1994, par le score Metavir (ou index Metavir), établi par des anatomopathologistes français.
Il semblait en effet que les nombreux paramètres nécessaires au score de Knodell ne pouvaient pas toujours être obtenus, en particulier sur des biopsies de petites tailles comportant peu d’espaces portes.Diverses formes, sporadiques ou infectieuses sont connues chez les animaux.
Parmi les hépatites non infectieuses, on citera l’hépatite aiguë diffuse ou parenchymateuse (qui peut cependant être due à une infection) et l’hépatite suppurée ou abcès du foie, souvent sous la dépendance d’un corps étranger.
Les hépatites chroniques ou cirrhoses se divisent chez les animaux en cirrhose hématogène, cirrhose biliaire et cirrhose cardiaque, selon l’origine pathogénique.
MAPI est l'acronyme de manifestatation postvaccinale indésirable, employé surtout dans le domaine de la pharmacovigilance.
L'immunologie est la branche de la biologie qui s'occupe de l'étude du système immunitaire.
Apparu très tôt au cours de l'évolution, ce système a évolué pour distinguer le non-soi du soi.
Les réactions de défense de l'organisme face à un organisme pathogène — quelle que soit la nature de celui-ci, virus, bactéries, champignons ou protozoaires.
Les maladies auto-immunes, les allergies et le rejet des greffes forment l'aspect médical de cette science.
Les mécanismes de synthèse et de maturation des anticorps, d'activation du système du complément, la mobilisation et la coordination des cellules de défense, en forment l'aspect fondamental et mécanistique.Les plus anciens témoignages connus d’observations d’ordre immunologique datent de 430 av.
lorsque l’historien Thucydide relata un épisode de « peste ».
À cette date, pendant l’épidémie de fièvre typhoïde qui sévit à Athènes durant la guerre du Péloponnèse, Thucydide nota que seules les personnes ayant déjà supporté et survécu à l’infection étaient aptes à s’occuper des malades.Aux alentours de 6000 av.
J.-C., il existe en Chine des pratiques de transmission volontaire de la variole en vue de prévention.
Cette technique, appelée « variolisation », consiste à prélever du pus sur un malade peu atteint par la maladie pour l’inoculer avec une aiguille chez un sujet sain.
Ce procédé se répandit à partir du XVe siècle, surtout en Chine, en Inde et en Turquie.
Par l’entremise de l’épouse de l’ambassadeur britannique à Constantinople, qui fit vacciner son fils de cette manière, la variolisation s’est fait connaître en Angleterre vers 1722, puis s’est propagée dans les années suivantes dans toute l’Europe.À la même époque, le médecin de campagne Edward Jenner constatait que les fermières en contact régulier, lors de la traite, avec la variole de la vache (vaccine ou Cowpox), qui est inoffensive pour les humains, étaient épargnées par les épidémies de variole, alors fréquentes, ou ne montraient que de faibles symptômes.
Après avoir intensivement étudié le phénomène, il préleva le 14 mai 1796 du pus sur une pustule d’une jeune fille contaminée par la vaccine, et l’injecta à un jeune garçon de huit ans.
Après que le garçon eut guéri de la maladie bénigne induite par la vaccine, Jenner lui injecta de la variole véritable.
Le garçon surmonta également cette infection sans symptômes sérieux.
Par rapport à la variolisation, le procédé de Jenner offrait certains avantages majeurs : les personnes vaccinées par la vaccine ne présentaient pas les boutons et les cicatrices typiques induites par la variolisation ; il n’y avait aucun risque de mortalité contrairement à la variolisation ; et les personnes vaccinées ne représentaient aucun risque de contagion.
Le virus de la vaccine est la l’origine des noms de « vaccin » et « vaccination », et Edward Jenner est considéré aujourd’hui comme le fondateur de l’immunologie.Une autre étape majeure dans le développement de l’immunologie est la conception d’un vaccin contre la rage par Louis Pasteur en 1885.
Le 6 juillet 1885, il vaccine Joseph Meister, un garçon de neuf ans qui avait été mordu deux jours plus tôt par un chien enragé.
Joseph Meister devint alors le premier être humain à survivre à la rage dans l’histoire de la médecine.
En une année, le vaccin fut administré à 350 personnes contaminées, et aucune ne mourut de son infection rabique.Deux ans auparavant, Robert Koch avait découvert le responsable de la tuberculose, le bacille qui porte son nom, et peu de temps après, le test à la tuberculine, qui permet de prouver l’infection par la tuberculose, et qui se fonde sur la réponse immunitaire.
Ces travaux servirent de base aux travaux de Calmette et Guérin, qui décrivirent le bacille qui porte leur nom (BCG pour bacille de Calmette et Guérin) et menant à la vaccination contre la tuberculose.
Le vaccin permettant de lutter contre les maladies infectieuses se développa à partir de cette époque.
Max Theiler reçu le prix Nobel de médecine en 1951 pour la mise au point d’un vaccin contre la fièvre jaune.En 1888, Émile Roux et Alexandre Yersin ont découvert la toxine diphtérique.
Deux ans plus tard, Emil Adolf von Behring et Shibasaburo Kitasato mettent en évidence une antitoxine dans le sérum des patients qui avaient survécu à la diphtérie.
Emil von Behring fut le premier à utiliser ces anti-sérums pour la prise en charge des malades diphtériques dans le cadre de la séroprophylaxie.
Pour ces travaux, il reçut en 1901 le prix Nobel de physiologie ou médecine.Le bactériologue belge Jules Bordet découvre en 1898 que chauffer le sérum au-dessus de 55 °C bloque sa capacité de coller à certaines substances chimiques.
La capacité du sérum à tuer les bactéries était également perdue.
Il posa le postulat suivant : il existe dans le sérum une substance, sensible à la chaleur, nécessaire à l’action du sérum sur les bactéries, et il nomma ce composé « Alexin ».
Ehrlich étudia ce composé dans les années suivantes, et introduisit le concept de complément encore utilisé de nos jours.En 1901, Karl Landsteiner mit en évidence l’existence des groupes sanguins et par cette découverte permit de franchir une nouvelle étape importante dans la compréhension du système immunitaire.
Il reçut en 1930 le prix Nobel de médecine.
En 1906, Clemens Peter Freiherr von Pirquet observa que les patients à qui il administrait du sérum de cheval avaient une forte réaction à la deuxième injection.
Il nomma cette réaction d’hypersensibilité « allergie ».
Le phénomène d’anaphylaxie fut découvert par Charles Richet, qui reçut pour cela le prix Nobel de médecine en 1913.
Emil von Dungern et Ludwik Hirszfeld publient en 1910 leurs recherches sur la transmission des groupes sanguins, et ainsi les premiers résultats sur la génétique d’une partie du système immunitaire.
Dans ce travail, ils proposent la nomenclature « ABO », qui deviendra un standard international en 1928.
En 1917, Karl Landsteiner décrit le concept d’haptènes, qui après s’être conjuguées à une protéine sont capables d’induire une réponse immunitaire avec production d’anticorps spécifiques.
Lloyd Felton réussit en 1928 la purification des anticorps à partir du sérum.
De 1934 à 1938, John Marrack développa la théorie de la reconnaissance spécifique d’un antigène par un anticorps.En étudiant le rejet de greffes, Peter Gorer découvrit l’antigène H-2 de la souris, et ainsi, sans le savoir, le premier antigène de ce qu’on appellera ensuite le complexe majeur d'histocompatibilité (MHC pour l’anglais major histocompatibility complex).
Toujours par l’étude du rejet de greffe, Peter Medawar et Thomas Gibson découvrirent d’importantes fonctions des cellules immunitaires.
C’est par ces travaux que l’acceptation générale de l’immunité cellulaire se fit.
En 1948, Astrid Fagraeus découvrit que les anticorps sont produits dans le plasma sanguin par les lymphocytes B. L’année suivante, Frank Macfarlane Burnet et Frank Fenner publiaient leur hypothèse de la tolérance immunologique, qui fut validée quelques années plus tard par Jacques Miller, qui découvrit l’élimination des lymphocytes T auto-réactifs dans le thymus.
Burnet et Fenner reçurent le prix Nobel de médecine en 1960 pour leurs travaux sur la tolérance.
En 1957, Frank Macfarlane Burnet décrivit le principe fondamental de l’immunité adaptative comme étant la sélection clonale.L’Anglais Alick Isaacs et le Suisse Jean Lindenmann, en étudiant l’infection de cultures cellulaires par des virus, découvrirent en 1957 que les cellules, au cours de l’infection par un virus, étaient en grande partie résistantes à une autre infection par un deuxième virus.
Ils isolèrent à partir des cellules infectées une protéine qu’ils nommèrent interféron.
À la fin des années 1960 et au début des années 1970, John David et Barry Bloom découvrirent le facteur d’inhibition de la migration des macrophages (MIF) ainsi que de nombreuses autres substances sécrétées par les lymphocytes.
Dudley Dumonde proposa pour ces substances le nom de « lymphokine ».
Stanley Cohen, qui reçut en 1986 le prix Nobel de médecine pour sa découverte des facteurs de croissances NGF et EGF, commença, au début des années 1970, à travailler avec Takeshi Yoshida sur les fonctions des lymphokines.
Ils mirent en évidence que ces substances, produites de nombreux types différents de cellules, étaient capables d’action à distance, comme des hormones.
À la suite des nombreuses découvertes dans ce domaine, Stanley Cohen proposa en 1974 le terme « cytokine » qui s’imposa rapidement.
Entretemps, plus de cent cytokines différentes étaient identifiées, et leurs structures et activités étudiées en détail.Les années soixante sont en général considérées comme le début de l’époque moderne de l’immunologie.
Jacques Oudin découvre en 1956 l’allotypie des protéines, puis en 1963 l’idiotypie des anticorps.
Rodney Porter et Gerald Edelman réussirent à élucider la structure des anticorps entre 1959 et 1961, et furent lauréats du prix Nobel de médecine en 1972.
En même temps, Jean Dausset, Baruj Benacerraf et George Snell découvraient le complexe majeur d'histocompatibilité, également appelé système HLA (de l’anglais Human Leukocyt Antigen) chez l’être humain, découverte qui leur permit de recevoir le prix Nobel de médecine en 1980.
En 1959, Joseph Murray réalise la première allogreffe en transplantant un rein.
Avec Donnall Thomas, ils étudient l’immunosuppression artificielle qui permet la tolérance des patients vis-à-vis de leur greffe ; ils reçurent le prix Nobel de médecine en 1990 pour ces études.
Vers 1960 également, la communauté scientifique découvrait, grâce aux travaux de Jacques Miller, d’autres caractéristiques fondamentales des cellules immunitaires, en particulier la description des fonctions et de la différenciation des lymphocytes B et T.
Après cette percée, la théorie selon laquelle l’immunité est divisée en une partie cellulaire et une autre humorale s’imposa, et les deux théories ne furent plus mises en concurrence.
Dans les décennies suivantes, les différents sous-types (appelés isotypes) d’anticorps furent identifiés et leurs fonctions respectives étudiées.
En 1975, Georges Köhler, Niels Kaj Jerne et César Milstein décrivent la méthode de production des anticorps monoclonaux.
Cette découverte eut un impact majeur sur la recherche fondamentale, ainsi que pour le diagnostic et le traitement de maladies, et ils reçurent en 1984 le prix Nobel de médecine.
D’autres découvertes majeures furent faites dans les années suivantes : en 1973, Ralph Steinman et Zanzil Cohn découvrent les cellules dendritiques.
Ralph Steinman obtiendra le prix Nobel en 2011 pour cette découverte.
En 1974, Rolf Zinkernagel et Peter Doherty découvrent la restriction de la présentation de l’antigène par les molécules du MHC, découverte qui lui valut le prix Nobel de médecine en 1996 ; En 1985, Susumu Tonegawa identifie les gènes des immunoglobulines, et reçoit pour cela en 1987 le prix Nobel ; la même année, Leroy Hood fait de même pour les gènes du récepteur des cellules T.Un autre concept émerge en 1986 : celui de l'orientation de la réponse immunitaire.
Basé sur le rôle des lymphocytes T CD4+ (CD pour cluster de différenciation), ce concept, développé par Robert Coffman et Tim Mosmann, présente la dichotomie entre une « Th1 », réponse orientée contre des cellules d'une part, qui produira des lymphocytes cytotoxiques spécifiques, comme dans le cas du cancer ou d'une infection intracellulaire; et une réponse « Th2 » contre un agent soluble, qui produira des anticorps spécifiques, comme dans le cas d'une bactérie extracellulaire ou d'une toxine.
La balance Th1/Th2 est toujours un intense champ de recherche.La notion de tolérance induite par des lymphocytes fut pour la première fois évoquée en 1969 par Nishizuka et Sokakura.
Ils présentaient leurs résultats concernant une sous-population de lymphocytes T suppresseurs capables d'empêcher une réaction de lymphocytes naïfs.
Très controversés, ces résultats seront oubliés jusqu'à la redécouverte du phénomène par Sakaguchi en 1982 sous le nom de T régulateur, sujet activement étudié actuellement.Depuis les années 1950, la théorie qui domine en immunologie est celle de la reconnaissance du « soi » et du « non-soi » par le système immunitaire adaptatif.
Cependant, ce modèle ne permet pas d'expliquer de manière satisfaisante les phénomènes de tolérance, de rejet de greffe, ni la nécessité de la présentation de l'antigène, et en 1989, Charles Janeway propose un modèle selon lequel ce serait l'immunité innée qui serait la véritable gardienne des clefs du déclenchement d'une réponse immunitaire.
La décision de réagir ou non face à un agent étranger reposerait sur la reconnaissance de motifs par des récepteurs putatifs qu'il nomme les récepteurs de reconnaissance de motifs moléculaires.
Ce modèle est approfondi à partir de 1994 par Polly Matzinger, qui développe la théorie du danger.
D'après Matzinger, le déclenchement de la réponse immunitaire se ferait sur la base de motifs moléculaires associés aux pathogènes par les récepteurs de reconnaissance de motifs moléculaires.
Ce modèle fut validé expérimentalement depuis par l'identification de récepteurs de signaux de danger et de certains de leurs ligands.De nos jours, la multiplication des cytokines, chimiokines, sous-types et marqueurs cellulaires rend difficile d'avoir une vue d'ensemble du domaine.Du fait de la complexité des phénomènes étudiés et de leur intime imbrication, les immunologistes sont souvent réduits à utiliser des concepts plus ou moins abstraits pour interpréter les informations disponibles.
Au fil du temps, de plus en plus de nouveaux concepts, se recoupant plus ou moins, se font jour dans la communauté scientifique, la plupart du temps en opposant deux notions.
La liste ci-dessous ne peut pas être exhaustive, mais donne un aperçu de quelques-unes de ces grandes notions.
Elle reprend naturellement certains points déjà vu dans l'historique, mais les développe sous un aspect simplifié et plus pragmatique.Le concept de base de l'immunologie de la réponse adaptative est celui d'antigène.
Globalement, on qualifie d'antigène toute substance qui est reconnue par le système immunitaire adaptatif.
Tous les antigènes ne déclenchent pas de réactions immunitaires; ils sont dits non immunogènes.
Autrement dit tous les antigènes ne sont pas immunogènes.Il est important de dire qu'il n'y a pas de réponse immunitaire sans antigène.Il existe différentes dénominations des antigènes :Un antigène peut comporter un à plusieurs épitopes (chaque épitope peut être reconnu par un paratope spécifique d'un anticorps ou d'un récepteur des cellules T (en anglais T cell receptor ou TCR).Le complexe épitope + paratope forme un complexe type : clef-serrure.
Néanmoins, un épitope n'est pas spécifique (dans l'absolu) à un antigène.
C'est pourquoi il peut exister des réactions croisées (AG 1 reconnu par anticorps mais si un AG 2 porte également l'épitope de AG 1 alors AG 2 peut être reconnu par cet anticorps).Concept important, celui du système inné et du système adaptatif (ou acquis, bien que ce terme soit de moins en moins utilisé).
Il s'agit ici d'opposer des phénomènes « non spécifiques » à des événements « spécifiques », sous-entendu « de l'antigène ».Dans le premier cas, il s'agit d'une réaction suivant l'introduction d'un nouvel élément, quel qu'il soit, et qui repose sur une réaction globale d'un type cellulaire.
Toutes les cellules blessées, quelle qu'en soit la cause, ont des réactions similaires, et les cellules du système immunitaire réagissent de manières stéréotypées également.
Cette réponse innée est rapide, sans mémoire et indépendante de l'antigène.
Une multitude de situation (blessure, infection virale ou bactérienne, etc.) mènent à des réactions innées similaires.La réponse adaptative concerne des phénomènes liés aux antigènes, et consiste en la sélection de clones de lymphocytes, capables de cibler ce qui est perçu comme une menace.
Cette réponse adaptative est lente, strictement dépendante des antigènes, et possède une mémoire immunitaire.
Chaque situation différente mènera à la sélection de quelques clones lymphocytaires qui prendront en charge le danger.Un des plus anciens concepts oppose une composante cellulaire à une composante soluble (« humorale ») de l'immunité.
Elle tient du fait que le sérum, donc débarrassé des cellules sanguines et du fibrinogène, peut produire des phénomènes rapides et très efficaces de destruction (lyse) d'organismes cibles, d'une part et que les effets de certaines cellules immunitaires sont plus difficiles à observer, car sont plus lents et imposent des conditions d'expérimentation très strictes.
Les deux types de phénomènes furent pendant longtemps impossibles à observer concomitamment.
Cette opposition n'aura plus lieu d'être dès que les techniques permettront de prouver que ce sont bien des cellules immunitaires qui produisent ces facteurs solubles.La découverte du rôle des cellules T CD4+ helper (Th), à savoir d'aider la réponse immunitaire, fit se dégager assez vite un fait expérimental : dans certaines conditions, les Th peuvent favoriser une réponse à médiation cellulaire, avec génération de cellules cytotoxiques, ou une réponse humorale, avec production d'anticorps.
En d'autres termes, un même antigène dans des situations différentes induira parfois une réponse à médiation cellulaire, parfois une réponse à médiation humorale.
Reprenant l'ancienne dichotomie cellulaire/humorale, le concept Th1/Th2 permet d'opposer les conditions dans lesquelles les T CD4+ réagissent en produisant des signaux dirigeant la réponse vers une cytotoxicité cellulaire, avec formation de cellules T CD8+ cytotoxiques (CTL pour cytotoxic T lymphocytes) en grand nombre; ou au contraire la formation d'une réponse soluble, avec différenciation de lymphocytes B en plasmocytes, produisant des anticorps en grande quantité.La réponse cellulaire fut pendant longtemps considérée comme résultant d'une reconnaissance directe par les cellules immunitaires des cellules étrangères.
Autrement comment expliquer que des substances produisent une réaction forte chez un organisme et aucune chez un autre ?
L'introduction d'un élément étranger (infection ou greffe) doit être suivie d'une acceptation ou d'un rejet par le système immunitaire.
Lors d'une greffe de peau par exemple, la peau prélevée sur le donneur était bien acceptée par le système immunitaire du donneur.
Or, après la greffe, le système immunitaire du receveur peut bien décider de considérer la nouvelle peau comme étrangère, et la rejeter, alors qu'elle ne constitue en rien un danger (mais sera considéré comme un danger par le système immunitaire).
Ce concept reste très actuel, bien que ses mécanismes aient été en grande partie élucidés par l'étude des interactions entre les récepteurs des cellules T (TCR) et les molécules du complexe majeur d'histocompatibilité (CMH).Une autre question peut se poser : comment se fait-il que certains corps étrangers ne soient « pas reconnus ?
» Autrement dit : lors de la reconnaissance d'un antigène donné, qu'est-ce qui active ou non les défenses immunitaires ?La première notion-clé est celle de tolérance centrale : aucun organisme n'est censé produire de lymphocytes auto-réactifs, c'est-à-dire des lymphocytes réagissant contre les antigènes du soi non modifié.
La seconde notion-clé est celle de tolérance périphérique : elle repose sur une inhibition conditionnelle de la réponse des cellules immunitaires face à un antigène du « non-soi ».La difficulté est de comprendre dans quelles conditions un antigène induit :La théorie du danger repose sur un constat simple: dans certaines situations, un même antigène peut être perçu comme sans danger (tolérogène) ou dangereux (immunogène), et, dans le second cas, entraîner une réponse très différente : réponse cellulaire ou réponse anticorps de divers types, allant jusqu'à l'allergie.
La théorie du danger stipule que ce sont les conditions dans lesquelles l'antigène est perçu qui déterminent le type de réponse immunitaire qui sera développé.
Ces conditions particulières impliquent des signaux de danger en plus ou moins grande quantité et plus ou moins variés, et qui accompagnent l'antigène.
La combinaison des signaux de danger (ou leur absence) oriente la réponse immunitaire.L'ensemble des organes du système immunitaire s'appelle le système lymphoïde.C'est là que les cellules du système immunitaire sont produites, par un processus appelé hématopoïèse.
C'est également le lieu de l'acquisition de l'immunocompétence des lymphocytes B.Lors de la production des lymphocytes B, ces derniers avant de quitter la moelle doivent avoir acquis certaines caractéristiques comme : les chaînes légères (κ ou λ) et lourdes (μ) des BCR.
Il y a au sein de la moelle osseuse une sélection négative : 90 % des lymphocytes B sont détruits.
Les 10 % restant rejoindront la circulation systémique pour poursuivre leur maturation dans les organes lymphoïdes secondaires.C'est là qu'a lieu la maturation et la sélection des lymphocytes T.Les cellules (futurs lymphocytes) entrent dans le thymus et rejoignent le cortex.
Il y aura apparition de caractéristiques de lymphocyte « delta-gamma » et « alpha beta » :Pour cela, il va y avoir des cellules épithéliales du thymus qui vont présenter les complexes CMH I et CMH II.
Si la molécule de surface CD4+ reconnaît le CMH II, le lymphocyte T se différencie en lymphocyte T CD4+ ; si la molécule de surface CD8+ reconnait le CMH I, le lymphocyte T se différencie en lymphocyte T CD8+.
Cette étape s'appelle la sélection positive.
Nous avons donc à la sortie du cortex du thymus des lymphocytes CD4+ et CD8+.
À la jonction cortico-médullaire du thymus, il va y avoir l'étape de la sélection négative.
En effet, il est dangereux de laisser quitter du thymus des lymphocytes ayant une trop grande affinité pour les cellules du soi (qui les détruirait ?).
Pour cela, les thymocytes (lymphocytes T CD4+ et lymphocytes T CD8+) vont rencontrer des cellules du soi.
Après la sélection positive dans le compartiment médullaire, il va y avoir la sélection négative.
Les thymocytes vont rencontrer des cellules du soi.Grâce à cela, on élimine les lymphocytes T auto-réactifs dangereux pour l’organisme.Tous les lymphocytes T « en vie » vont former les lymphocytes T naïfs : car n’ont pas encore rencontré les antigènes du non-soi.
Ils vont sortir du thymus et vont aller dans les organes secondaires.
C’est là qu’ils rencontreront les antigènes externes du non-soi.Au niveau du système sanguin, il y a des échappées de protéines.
Ces protéines se retrouvent dans le liquide interstitiel et doivent retourner dans le sang afin de contrôler son osmolarité.
Les capillaires lymphatiques récupèrent ces protéines et captent aussi les agents pathogènes, cellules du système immunitaire et débris de cellules mortes.
Le système lymphatique entraîne la lymphe au niveau d'un centre intégrateur qui correspond aux ganglions lymphatiques.
Après le passage de la lymphe dans le ganglion, la lymphe est épurée.
La lymphe circule vers le cœur à sens unique.
Elle rejoint la circulation sanguine au niveau du cœur par le canal thoracique et se jette dans la veine sous-clavière gauche.Les ganglions lymphatiques ont une structure plus ou moins globuleuse.
Ils se décomposent en plusieurs zones.Les appendices secondaires (formations lymphoïdes agrégées) ont des zones particulières d'épuration.
Ce sont l’anneau de Waldeyer au carrefour aérodigestif (amygdales et végétations adénoïdes), l'appendice et les plaques de Peyer.La rate fait également partie du système immunitaire car elle épure le sang vis-à-vis des pathogènes qui pourraient s'y trouver.Les organes lymphoïdes tertiaires comprennent tous les tissus et organes où la réponse immunitaire a lieu.
Ils contiennent peu de cellules lymphoïdes dans les conditions physiologiques normales mais peuvent en importer une grande quantité lors de la présence d'un pathogène.
Ils comprennent :Il faut noter l'existence de sanctuaires immunitaires.
Ce sont des tissus où les cellules immunitaires ne pénètrent pas ; il s'agit des testicules et de la chambre antérieure de l'œil.
Les lymphocytes naïfs ne peuvent pas franchir la barrière hémato-encéphalique.Il s'agit des mécanismes de défense impliquant des facteurs solubles.
Elle est de deux types : défense innée et défense adaptative.Les défenses innées correspondent à des molécules présentes spontanément dans l'organisme et qui préexistent à la menace.
Il s'agit des anticorps naturels, des défensines et du système du complément.
Les tissus agressés produisent également des molécules de l'inflammation, tels que le facteur tissulaire et les dérivés de l'acide arachidonique: leucotriènes et prostaglandinesElle est supportée par la présence d'anticorps circulants.
Les anticorps sont produits par les plasmocytes, issus de la différenciation terminale d'un clone de lymphocyte B. Ce sont des molécules de type immunoglobuline de différents types :De manière générale, les anticorps agissent de deux manières différentes: soit par l'activation du complément, soit par fixation du complexe immun sur une cellule immunitaire possédant un récepteur pour le fragment constant des anticorps (tels que les macrophages, les lymphocytes NK par exemple).Les phénomènes immunitaires à médiation cellulaire impliquent différents types de cellule, regroupés dans deux concepts: les cellules de l'immunité innée et celles de l'immunité adaptative.Ce sont des cellules qui sont capables de réagir à un phénomène sans éducation préalable.
Elles réagissent à des stimuli présents sur une variété de pathogènes, et indépendamment des antigènes.
Il s'agit :Il s'agit de réactions qui mettent en jeu des cellules de type lymphocyte T.
Leur maturation dépend d'un stimulus antigénique et d'une éducation par une cellule présentatrice d'antigène.
Leur activation face à une cible dépend de la présentation de l'antigène par la cellule cible.
Les lymphocytes T ne sont donc capables de reconnaître que des cellules transformées (c'est-à-dire infectées par un pathogène intracellulaire, ou une cellule tumorale).
Il y a deux types principaux de lymphocytes T :On retrouve également les lymphocytes B via la diversité de leurs BCR, qui sont des AC.La connaissance des mécanismes immunologiques a permis le développement de nombreuses techniques d'analyses aussi bien quantitatives que qualitatives, utilisant notamment les anticorps, vecteurs de l'immunité humorale, mais aussi parfois des tests cellulaires.
La maitrise de production des anticorps a ouvert le champ à de nombreuses techniques de purification par « affinité », mais aussi des applications thérapeutiques.La plupart de ces techniques utilisent les propriétés des anticorps monoclonaux ou polyclonaux purifiés par affinité.
Leur affinité et leur spécificité de liaison à leur cible fait d'eux des outils incontournables de détection ou capture spécifique.
Ils permettent de déterminer la présence dans un échantillon complexe d'un antigène ou même d'une de ses parties particulière(épitope).
De nombreuses modalités de mise en œuvre existent.Les premières techniques d'analyse proposées utilisaient des anticorps non marqués, par exemple dans les réactions de précipitation, les réactions d'agglutination (p. ex.
test de Coombs), turbidimétrie ou néphélométrie et les réactions de neutralisation.
On utilise la capacité de former des complexes immuns multiples de l'antigène cible et des 2 sites des IgG ou 5 sites des IgM, et éventuellement le fait que l'anticorps est fixé ou se fixe à des cellules ou des particules (agarose).
Les complexes antigène-anticorps deviennent visibles macroscopiquement de manière diffuse (opacité par turbidimétrie) ou locale (précipitation), éventuellement après coloration, exemple : au Bleu de Coomassie.Par exemple dans plusieurs méthodes dites d'immunoprécipitation (ex.
: Ouchterlony), l'anticorps présent dans un gel immobilise un antigène diffusant depuis un puits, et on visualise une ligne blanche représentant la précipitation du complexe immun formé.
Il existe une variante faisant appel à l'électrophorèse (Fused Rocket Electrophoresis).
D'autres techniques similaires sont utilisées en recherche pour déceler des interactions entre deux protéines ou pour purifier un composé dans une solution.Des méthodes devenues plus fréquentes consistent à utiliser des anticorps marqués, « détectables » facilement, c'est-à-dire couplés à des composés colorés ou le plus souvent fluorescents, des particules d'or, des enzymes qui produiront un signal coloré fluorescent ou luminescent, ou de petits composés détectables indirectement (biotin, tags), voire des éléments radioactifs.
La réaction ag/ac est mise en œuvre en phase homogène ou hétérogène.
Par exemple cette dernière modalité se décline dans les techniques comme l'ELISA, le blotting ou le micro-réseau, selon que le support est une microplaque, membrane, lame de verre...
Ces techniques d'analyse in-vitro permettent de détecter des protéines ou autres molécules, de façon qualitative (spécificité) et/ou semi-quantitative (par titration, comparé à un titration de standards).
L'ELISA sur microplaque est une technique très flexible, de la R&D au contrôle qualité ou au screening.
Selon la spécificité des anticorps, on peut détecter de faibles différences ou modifications entre molécules (isoformes de protéines, phosphorylation, acétylation, etc.).
Le microréseau permet de tester qualitativement des centaines de milliers de molécules (ou anticorps) sur 1 cm2 (screening), avec deux ou trois paramètres (anticorps.
Le western blot après électrophorèse 2D permet de distinguer qualitativement et quantitativement dans un même échantillon des protéines et leurs variants (profiling).D'autres techniques utilisent le principe de l'ELISA, mais le support consiste en la cible à détecter, par exemple une cellule ou un virus.
Par exemple une coupe de tissus est « marqué immunologiquement » (fixation de l'anticorps), et on analyse avec un microscope les cellules « colorées » par l'anticorps (Immuno-Histochimie (IHC)), ou rendues fluorescentes (Immuno-Fluorescence (IH) - on observe l'intensité de la fluorescence, ou son changement de longueur spectrale (ratiométrie), ou le changement de polarisation de la fluorescence (Fluorescence Polarization), ou le temps entre l'excitation et l'émission (Life Time Resolved Fluorescence)).
Ces immuno-analyses renseignent sur la localisation d'antigènes, dans une cellule ou un tissu, et leur relative abondance.
Une limitation repose sur la résolution optique, et sur la superposition des antigènes (dans l'épaisseur de la coupe), ce qui est partiellement adressé par scanning focal (Microscopie confocale).
En cytométrie de flux (FCM), on marque les cellules en suspension, qui sont analysées individuellement, ce qui rend l'information très puissante (populations cellulaires, notamment en multiples détections, d'autant que les cellules peuvent être triées.Les techniques d'analyse immunologique (immuno-métrique si elles sont rendues quantitatives) utilisant des anticorps marqués recourent souvent à des systèmes d'amplication, qui repose souvent sur plusieurs anticorps, dont des anticorps « secondaires », marqués et reconnaissant les anticorps « primaires » spécifiques de la cible à détecter.
Elles peuvent être multiplexées dans divers techniques (ELISA Fluo, MicroArray, W-Blot, IHF, CMF) : 2 et jusqu'à 4 anticorps spécifiques marqués différemment sont utilisés simultanément, et l'on peut alors avoir des résultats multiples sur le même échantillon (simultanément, ou après superposition).
Des variantes combinent des billes pour atteindre jusqu'à 48 détections.D'autres modalités permettent d'apprécier la distance entre deux molécules (FRET, BRET).Une autre propriété des anticorps utilisée en clinique animale et depuis quelques années en clinique humaine est la faculté de certains isotypes d'anticorps à lier le complément, et donc de lyser les cellules à la surface desquelles ils sont fixés.
En pratique, cela permet de détruire les cellules possédant un marqueur antigénique particulier (techniques de « lyse »).Les techniques de purification par affinité utilisent les anticorps couplés chimiquement à des résines pour capturer des antigène cibles (éventuellement complexés à d'autres partenaires - technique voisine de l'immunoprécipitation).
Les applications vont de la R&D à l'industrie (fabrication).Les applications des analyses immunologiques sont majeures en R&D, en diagnostic médical et vétérinaire, et même en contrôle qualité (alimentaire).Le diagnostic des infections bactérienne (ex la toxoplasmose) ou virales (ex le VIH, l'hépatite B) se fonde le plus souvent sur la détection d'anticorps circulants dans le sérum des patients (parfois dans d'autres fluides).
La technique la plus utilisée est l'ELISA « direct ».La technique la plus utilisée est l'ELISA avec les modalités dites « sandwich » et « inhibition » (ou « compétition »), en colorimétrie (EIA : enzyme ImmunoAssays) ou radiométrique, plus rarement fluorescence.
Mais comptent aussi la cytométrie de flux pour des cas plus difficiles et recherche hospitalière, le micro-réseau qui se développe pour préciser le diagnostic avec plus de paramètres.
Enfin la microscopie avec immunochimie (IHC) est très utilisée pour préciser le (ou à défaut de) diagnostic sérologique, dans les hôpitaux, et même l'immunofluorescence (IF).
Ceci vaut aussi pour le cancer (cf.
infra).Les immuno-analyses sont capables de doser certains analyses circulants, et de détecter des marqueurs cellulaires normaux (qui signent le type ce cellule, ou une activité — récepteur, enzyme —) ou cancéreux.La détermination de la formule lymphocytaire fait appel à la cytométrie en flux, utilisant des anticorps monoclonaux couplés à des molécules fluorescentes spécifiques de marqueurs (cluster de différenciation CD4/8, etc.).Le dosage d'hormones dans le sérum est fait souvent par ELISA, mais certaines (hormones thyroïdiennes notamment) se font par turbidimétrie ou néphélométrie.La recherche du cancer du colon et du pancréas se fait par ELISA avec quelques marqueurs fréquents (par exemple le CA19-9), marqueurs tumoraux.En clinique animale et depuis quelques années en clinique humaine on recourt à la faculté de certains isotypes d'anticorps à lier le complément, et donc de lyser les cellules à la surface desquelles ils sont fixés.La connaissance de l'immunologie et les techniques immunologiques sont présentes à de nombreux niveaux en médecine, du diagnostic au développement de vaccins, du traitement de maladies auto-immunes au thérapies par greffe ou utilisant des anticorps.L'utilisation de toutes sortes de vaccins a permis le triomphe de la médecine contre de nombreuses maladies infectieuses.
Ainsi, la variole est éradiquée, et d'autres maladies sont des candidats à l'éradication par la vaccination : la rougeole, l'hépatite B par exemple.
Ce sont des maladies causées par des virus dont l'être humain est le seul réservoir.
La vaccination d'une grande partie de la population permettrait de les éradiquer.
Ce sont des objectifs fixés par l'Organisation mondiale de la santé.Par ailleurs, il existe depuis 2006 un vaccin destiné à diminuer le risque de cancers du col de l'utérus.
Ce vaccin est dirigé contre un virus responsable de la transformation des cellules épithéliales du col en cellules tumorales.
Vacciner les jeunes filles avant leurs premiers contacts sexuels permettrait de diminuer de 80 % les cas de cancer du col.L'immunologie et l'étude du système immunitaire est un outil indispensable pour deux domaines particuliers : le rejet de greffe et les maladies auto-immunes, comme le diabète.
Parallèlement, l'immunologie des tumeurs étudie comment le système immunitaire interagit avec les cellules tumorales, dans le but d'influencer médicalement la puissance potentielle d'une réaction immunitaire dirigée contre une tumeur.Côté thérapeutique, on utilise des anticorps modifiés « humanisés » pour véhiculer des agents toxiques (toxines, radioéléments) jusqu'à des cellules cibles cancéreuses pour détruire des tumeurs (Immuno-Thérapie).
Similairement mais pour du diagnostic, des anticorps spécifiques de marqueurs tumoraux sont marquées (fluorescence ou radioactivité faible (Immunoscintigraphie|Immuno-Scintigraphie)) et injectés au patient avant imagerie médicale afin de diagnostiquer ou localiser des tumeurs avant chirurgie.
À ces applications pointues, appelons enfin simplement l'importance des techniques immunologiques classiques pour le diagnostic médical, sérologique ou infectieux notamment -voir ci-dessus section techniques et applications-.
La vaccine, communément appelée « variole de la vache », est une maladie infectieuse des bovidés (cowpox en anglais) et des équidés (horsepox en anglais).
Le virus, proche de celui de la variole, fournit un vaccin qui permet d'immuniser l'homme contre cette dernière.
Le vaccin de la vaccine n'est cependant plus utilisé de nos jours car la variole est éradiquée depuis 1980.La vaccine est transmissible à l'homme, pour qui elle est le plus souvent bénigne (elle peut s'avérer plus grave voire mortelle pour les personnes immunodéprimées).
La constatation par Edward Jenner que la vaccine bénigne protégeait ses porteurs de la variole, maladie grave, par immunité croisée, a conduit à l'utiliser dans la prévention de la variole (vaccination) à la place de l'ancien procédé de variolisation, qui consistait à contaminer le sujet avec une variole peu virulente.En 1906, Adelchi Negri montre que la vaccine est un virus filtrant.
Le virus Cowpox doit être distingué du virus dit « de la vaccine », auquel il a longtemps été assimilé (en anglais Vaccinia Virus).
Le virus « de la vaccine » — le Vaccinia Virus des Anglo-saxons — connu pour avoir servi de base au vaccin anti-variolique aurait une origine plutôt équine.La question des rapports du virus de la vaccine (Cowpox) avec celui de la variole (Smallpox) furent incertains, du temps de Jenner et plus tard encore, puisqu'en 1880 Pasteur préfère s'abstenir d'une opinion précise sur le sujet, tout en se prévalant de la découverte de Jenner pour rendre acceptable la possibilité de l'atténuation d'un germe.Le passage de la vaccine de bras à bras entraîna des contaminations nosocomiales notamment de syphilis.
Par ailleurs on constata que ce passage de bras à bras entraînait une diminution de l'efficacité de la vaccination.
Deux italiens, Troja — dès 1804 — et Gennaro Galbiati — à partir de 1810 —, revenant par là à la source du vaccin, mirent au point la vaccine dite animale car prélevée directement sur un bovidé malade du cow-pox, une maladie de fait pas très fréquente.
En 1843 Negri développa à son tour cette méthode, transmettant le cowpox de vaches à vaches.
Une génisse, inoculée à Naples de la vaccine, parvenant à la gare de Lyon Perrache en 1864, sera à l'origine de la fondation de l'Institut de la Vaccine de Saint Mandé.
La vaccine animale doit être distinguée stricto sensu de la rétro-vaccination qui procède de la réinoculation à la vache du vaccin de l'homme (bovo vaccin).
L'idée, erronée, que la variole puisse se transformer en vaccine/cowpox une fois inoculée à la vache a pu se perpétuer jusqu'au début du XXe siècle ; des tentatives furent ainsi faites afin de se procurer de la lymphe vaccinale (variolo-vaccin).
La vaccine (Cowpox) touche essentiellement l'Europe et notamment la Grande-Bretagne où elle est en augmentation.
Les cas humains, très rares aujourd'hui, sont surtout contractés au contact de chats domestiques, eux-mêmes infectés par les campagnols, principaux réservoirs du virus.
Chez les vaches, le virus Cowpox est rarement observé de nos jours.Il faut enfin noter l'existence de la paravaccine, une zoonose bovine causée par le virus du Pseudocowpox : il représente 80 % des infections du trayon de la vache laitière.Le Vaccinia virus, membre de la famille des Poxviridae, fait partie des virus les plus grands et complexes connus à ce jour.
La façon dont le virus entre dans la cellule a été une énigme durant de nombreuses années car il est trop grand pour emprunter des voies d’endocytose comme les cavéoles, ce que font certains virus comme le virus coxsackie.
Pour entrer, le Vaccinia virus utilise la voie de la macropinocytose qui permet d’accommoder de plus grandes particules.
Dans la majorité des cellules la macropinocytose n’est pas constitutivement active et doit être activée par un signal reconnu par la cellule.
Le Vaccinia virus a évolué de façon à déclencher la macropinocytose chez les cellules avoisinantes en présentant des molécules de phosphatidylsérine pour mimer la composition lipidique d'un corps apoptotique se faisant ainsi passer pour une cellule morte en attente d'être phagocytée et recyclée.Les Poxviridae sont des virus à ADN qui se répliquent dans le cytoplasme, à l’extérieur du noyau.
La réplication de l’ADN et la transcription se passant normalement à l’intérieur du noyau, ces virus ont besoin d’un génome de grande taille, permettant de coder les enzymes et les protéines nécessaires aux étapes de réplication du virus.
D’autres virus comme Adénovirus pénètrent à l’intérieur du noyau et piratent la machinerie de la cellule hôte pour pouvoir se répliquer.
Un organisme (du grec organon, « instrument »), ou organisme vivant, est, en biologie et en écologie, un système vivant complexe, organisé et est le produit de variations successives au cours de l'évolution.
Il est constitué d'une ou plusieurs cellules vivantes (on parle alors, respectivement, d'organisme unicellulaire ou pluricellulaire).
Les organismes vivants sont classifiés en espèces partageant des caractéristiques génétiques, biologiques et morphologiques communes.Les organismes complexes, multicellulaires, sont constitués d'un ensemble de cellules vivantes différenciées, assurant des fonctions spécialisées et opérant de manière concertée.
Ces cellules dérivent en général d'une progénitrice unique et partagent le même patrimoine génétique.
Elles interagissent de façon à fonctionner comme un ensemble stable dynamiquement.Un organisme vivant se trouve en effet dans un état thermodynamique de non-équilibre, mais conservant un environnement interne approximativement constant, grâce à l’apport continu d'énergie et, le cas échéant, de nutriments.
Ce phénomène d'équilibre dynamique maintenu par l'organisme est appelée homéostasie.Quelques centaines d'espèces, dites « organismes modèles », sont utilisées comme modèles d'étude par les scientifiques et les laboratoires de recherche pour comprendre les mécanismes fondamentaux du vivant.Un organisme est un être organisé, qui peut être un organisme unicellulaire ou un organisme multicellulaire.
Le terme d'organisme complexe s'applique à tout organisme vivant ayant plus d'une cellule.Il est difficile de définir avec précision ce qu'est un être vivant.
On peut donner quelques caractéristiques du vivant :La matière vivante est fondée sur la chimie organique avec comme base le carbone.Tout organisme vivant est mortel, par définition.Selon la source d'énergie utilisée, on distingue les organismes chimiotrophes, tirant leur énergie de molécules et les phototrophes, tirant leur énergie de la lumière.Tous les organismes vivants sont composés d'un nombre plus ou moins grand de cellules.
Un organisme se développe en général à partir d'une cellule unique, par divisions cellulaires successives.
Au cours de ce développement, les cellules subissent des étapes de différenciation, ce qui leur permet d'acquérir des spécialisations associées à des fonctions particulières.
Un ensemble de cellules spécialisées de même type qui s'associent forment un tissu et l'organisation structurée de différents tissus constitue un organe.
À l'intérieur d'un organisme vivant complexe, on trouve ainsi différents types cellulaires et différents tissus, variables suivant le type d'organisme considéré (animaux, plantes...).Ce type d'organisation hiérarchique : cellule, tissu, organe peut s'étendre aux grandes fonctions de l'organisme, on parle alors de système ou d'appareil, qui sont une collection d'organes participant à la même grande fonction : système nerveux, système respiratoire, appareil reproducteur, système racinaire (chez les plantes)...L'ensemble de l'organisme suit en général un plan d'organisation commun à tous les individus d'une même espèce.
Ce plan d'organisation détermine la disposition relative des organes et des tissus, l'existence et le positionnement de membres ou d'appendices.
Il est déterminé génétiquement et partagé en général par des espèces voisines sur le plan évolutif.
Certains organismes vivants ont au cours de leur cycle de vie des stades d'existence très différenciés (stade larvaire, stade adulte...) avec des morphologies et des plans d'organisation qui peuvent varier, au travers d'étapes de métamorphose.Georges Chapouthier a proposé d'interpréter la complexité des organismes par l'application répétée de deux principes généraux, compatibles avec la sélection darwinienne : le principe de « juxtaposition » d'unités identiques, puis le principe d'« intégration » de ces unités dans des ensembles plus complexes, dont elles constituent alors des parties.
La tuberculose est une maladie infectieuse causée par la bactérie Mycobacterium tuberculosis, qui se transmet par voie aérienne, avec des signes cliniques variables.
Elle touche le plus souvent les poumons et peut parfois atteindre d’autres organes.Elle arrive en tête des causes de mortalité d'origine infectieuse à l’échelle mondiale, devant le sida.
L'Organisation mondiale de la santé (OMS) rapporte à travers son rapport annuel consacré à la tuberculose et sorti en 2015 que 1,5 million de personnes sont mortes de la tuberculose l’année précédente.
Parmi les nouveaux cas de tuberculose enregistrés en 2019, 87 % sont survenus dans les trente pays présentant la plus forte charge de la maladie.
Deux tiers des cas sont concentrés dans huit pays, avec l’Inde en tête, suivie de l’Indonésie, de la Chine, des Philippines, du Pakistan, du Nigéria, du Bangladesh et de l’Afrique du Sud.Le rapport 2015 de l’OMS rapporte également que la mortalité a baissé de 47 % depuis 1990 grâce en grande partie au développement des traitements ainsi que les modalités de dépistage et de prévention.
Cela représente un bon indicateur du progrès réalisé par les systèmes de soins, diagnostiques et thérapeutiques.Bien que la maladie soit curable, la forte prévalence dans les pays les plus pauvres s’explique par la conjonction d’un ensemble de facteurs : précarité, promiscuité, dénutrition, analphabétisme, infrastructure médicale insuffisante, et surtout épidémie d’infection par le VIH.
La prévalence s’accroît en cas de guerre ou de famine.
On constate également que l’accès au diagnostic et au traitement pose un problème dans les pays concernés.La tuberculose est connue au XVIIe siècle sous le nom de « peste blanche », en écho à la peste noire qui ravage l'Europe à cette époque.Le terme « tuberculose » est utilisé pour la première fois par Johann Lukas Schönlein en 1839.
Il est issu du nom de la lésion unitaire de la maladie, le « tubercule », utilisé depuis le XVIIe siècle et formé depuis le latin tuber signifiant « excroissance ».
La tuberculose « miliaire » (caractérisée par la dissémination de très nombreux nodules de petite taille dans les deux poumons) tire son nom de la ressemblance de ces nodules avec des grains de millet.Dans les textes consacrés à la tuberculose, ce terme est souvent abrégé en TB, ou TBC.Maladie au long cours aux manifestations très diverses et affectant aussi bien humains et animaux, la tuberculose est une maladie très ancienne, mais dont l'unité nosologique et l'étiologie ne furent établies qu'au XXe siècle.Une ancienne théorie du XXe siècle postulait que la tuberculose humaine à M. tuberculosis dérivait de la tuberculose bovine à M. bovis, en étant une conséquence de la domestication animale.Les études génomiques indiquent que M. tuberculosis et bovis ont évolué à partir d'un ancêtre commun présent chez les mammifères et qui aurait infecté les hominidés d'Afrique de l'Est, il y a trois millions d'années.
Cet ancêtre commun aurait coévolué avec ses hôtes pour aboutir aux mycobactéries humaines et animales actuelles.
Les souches modernes pathogènes M. tuberculosis seraient issues d'un clone apparu il y a 15 000 à 20 000 ans, ou 11 000 ans, à partir d'une souche ancestrale de M. tuberculosis,.Dès l’Antiquité gréco-romaine, plusieurs auteurs ont décrit une maladie amaigrissante au long cours, dénommée suivant les uns « phtisie » (pour dépérissement), suivant les autres « tabès ».
Hippocrate (Ve – IVe siècle av.
et Caelius Aurelianus (Ve siècle) en ont dressé les symptômes, notamment pulmonaires.
Arétée de Cappadoce (fin du IIe siècle) en a cependant dressé la description la plus détaillée.
Ces descriptions initiales n’ont guère subi de modifications notables jusqu’au début du XIXe siècle.L'origine de la maladie a été débattue durant l'Antiquité, entre héréditaire ou contagieuse.
Plus tard, Avicenne (début du XIe siècle) décrit la tuberculose comme uniquement contagieuse.En 1733, Pierre Desault (1675-1737) publie un Essai sur la phtisie, de même que François-Emmanuel Fodéré en 1795, mais la présentation la plus claire est celle de Gaspard Laurent Bayle avec ses Recherches sur la phtisie pulmonaire publiées en 1810.
Bayle la définit moins par son expression clinique que par ses lésions anatomiques dont le tubercule,.L'invention du stéthoscope par René Laennec en 1817 facilite le diagnostic de la maladie.En 1839, le médecin allemand Johann Lukas Schönlein rassemble en une description unifiée les manifestations cliniques disparates de la maladie.
Jusqu'alors, « phtisie » et « tuberculose » étaient souvent considérées comme deux entités, voisines mais distinctes.
Si Schönlein forge en 1834 le terme de tuberculose (en allemand: Tuberkulose), composé d'un nom latin et d'une terminaison grecque, la littérature médicale, tout comme le langage commun, continuera d'utiliser indistinctement, jusqu'au début du XXe siècle, les termes de « phtisie », « consomption » et « tuberculose ».De 1865 à 1868, le médecin Jean-Antoine Villemin reproduit chez les animaux (lapins, cobayes) les lésions de la tuberculose humaine, par inoculation de tissu altéré humain.
Il peut ainsi affirmer que cette maladie, de nature jusqu'alors inconnue, est due à un microbe invisible par les moyens techniques de l'époque.
Il démontre en 1869 que la transmission se fait par voie aérienne.
Ses conclusions se heurtent à une forte opposition, en France notamment.
Elles inspirent cependant des travaux comme ceux d'Edwin Klebs, Julius Cohnheim, Carl Salomonsen et Tappeiner qui aboutissent à établir de façon indubitable la contagiosité de la maladie.En 1882 enfin, à la suite des travaux de Louis Pasteur, Robert Koch met en évidence le bacille tuberculeux à partir de lésions humaines : le 24 mars 1882, il communique d'abord à la Société de physiologie de Berlin une note sur la recherche et la culture du bacille de la tuberculose ; le 10 avril, il publie dans le Berliner klinische Wochenschrift un mémoire sur l'étiologie de la tuberculose qu'il rapporte à un bacille décelé dans les crachats et les lésions tuberculeuses humaines.En 1894, Carlo Forlanini met au point la première méthode thérapeutique invasive avec le pneumothorax artificiel intrapleural : par une injection d'air dans la cavité thoracique, entraînant la rétraction du poumon infecté, il obtient une amélioration de la maladie.En 1940, Selman Waksman découvre l'action antituberculeuse de l'actinomycine puis, en 1942, de la streptothricine.
Ces antibiotiques ne peuvent toutefois être utilisés en thérapeutique humaine ou vétérinaire du fait de leur trop grande toxicité.En 1943, Waksman découvre enfin la streptomycine qui permet, un an plus tard, la première guérison par antibiotique d'un malade gravement atteint de tuberculose.En 1948, a lieu le premier essai clinique randomisé de l'histoire de la médecine : l'épidémiologiste Austin Bradford Hill montre que la streptomycine est plus efficace que la collapsothérapie.Le nombre annuel de nouveaux cas dans le monde, incluant les cas de rechute, était en 2006 d'environ 5,4 millions.
Il était en 2018 estimé à dix millions par l'OMS.
Environ 58 % des nouveaux cas se trouvent dans la région sud-est de l’Asie et les régions du Pacifique ouest.
L'OMS estime par ailleurs qu'environ un quart de la population mondiale est porteuse d’une tuberculose latente, c’est-à-dire est porteuse de la bactérie sans toutefois développer de symptômes et sans être contagieuse.
L'organisme estime entre 5 et 15 % le risque pour les porteurs sains de développer la maladie à un moment de leur existence.La prévalence de la tuberculose en 2015 a chuté de 42 % depuis 1990.
Elle varie d'un pays à un autre en fonction de plusieurs facteurs dont le niveau socio-économique ; le rapport annuel de l'OMS nous apprend que les pays en développement sont les plus touchés (95 % des cas) et en particulier la région de l’Asie du Sud-Est, avec 44 % des nouveaux nouveaux et l'Afrique (28 % des nouveaux cas mondiaux en 2018).
La tuberculose est une cause majeure de mortalité chez les personnes infectées par le VIH.
Elle serait responsable de 13 % environ des décès par sida dans le monde.Environ 1,5 million de personnes sont mortes de la tuberculose en 2018, dont une personne sur six était porteuse du VIH.La tuberculose, sans bénéficier de programmes de prévention et de cure aussi importants, tue ainsi à peu près deux fois plus que le sida, soit environ 4 000 personnes par jour.Paradoxalement cette augmentation du nombre de morts, rapportée à l'explosion démographique mondiale, représente un progrès dans la prévention.
Par rapport à 1990, c'est-à-dire sur une période plus longue, la baisse est en effet de 47 %.
Autrement dit, une politique de santé efficace montre au terme de quinze années ses limites face à un certain nombre de freins à la prévention.
Face aux formes résistantes et multirésistantes de la maladie, la bataille s'achemine en 2015 vers une défaite.
Il manque au programme mondial de recherche coopérative les deux tiers de son budget annuel, lequel reste limité à 700 millions de dollars, alors que la dépense mondiale totale consacrée à la prévention, assumée principalement par les États, atteint presque 6 milliards d'euros.En 2014, on estime à 190 000 le nombre de morts par tuberculose résistante.
Ils ont été recensés dans 105 des 205 pays transmettant leurs informations à l'OMS.La maladie comprend deux étapes : la tuberculose-infection qui peut rester latente et silencieuse, puis la tuberculose-maladie où les troubles se manifestent.
Le risque de contracter une tuberculose dépend d'abord du risque d'exposition au bacille (infection), puis du risque de développer la maladie après infection.Cette infection touche l'adulte jeune, et les hommes sont près de deux fois plus atteints que les femmes.
La malnutrition et les intoxications médicamenteuses sont des causes reconnues de l'augmentation du nombre de cas.Après l’âge de 60 ans, des personnes ayant été contaminées dans leur enfance ou leur adolescence (par M. tuberculosis, ou M. bovis), peuvent dans certains cas déclarer une tuberculose évolutive.La tuberculose peut revêtir différentes formes selon la localisation du foyer infectieux.
La tuberculose pulmonaire est la forme la plus fréquente et la source essentielle de la contagion.
À partir du poumon, le bacille peut diffuser dans l'organisme et causer d'autres atteintes, ganglionnaires, ostéoarticulaires et urogénitales notamment.
Les formes les plus létales sont les formes diffuses (miliaires) et méningées.La primo-infection regroupe les manifestations cliniques, radiologiques et bactériologiques, survenant après un premier contact infectant avec le bacille de Koch (BK).
Elle est souvent asymptomatique chez l’adulte mais la littérature rapporte qu’elle peut être symptomatique chez les enfants à 90 % associant les signes généraux ; les symptômes sont dominés par la toux chez plus de la moitié des cas, les douleurs thoraciques chez 20 % des cas, et la dyspnée.
L’examen clinique met en évidence des adénopathies périphériques chez 37,5 % et la confirmation du diagnostic se fait à travers l’intradermoréaction à tuberculine (IDR).La tuberculose pulmonaire est la forme la plus fréquente et présente plus de 85 % des cas,.
Le tableau le plus classique et le plus fréquent chez les tuberculeux pulmonaires laisse définir le syndrome d’imprégnation tuberculeuse : fièvre, sueur nocturne, amaigrissement, anorexie.Le dépistage de la tuberculose pulmonaire se fait généralement au cours de consultation habituelle par un interrogatoire auprès des malades qui présentent principalement des signes d’imprégnation ainsi que des symptômes respiratoires persistant pendant plus de deux semaines.
Cependant, le tableau symptomatique peut être polymorphe, représentatif dans son ensemble de toute la séméiologie bronchopulmonaire.Clinique de la tuberculose :+++ = courant (> 50 %), ++ occasionnel, + rareLe diagnostic repose sur les différents éléments allant de l’interrogatoire à l’examen physique et clinique.
L’interrogatoire doit enquêter sur la notion de contagion en tenant compte de la physiopathologie de la maladie et les modalités du développement de la lésion.
L’installation de la maladie peut se faire progressivement en s’étalant sur plusieurs semaines et l’examen clinique se révèle utile à la recherche des éléments d’orientation vers l’affirmation du diagnostic.
Quant à l’examen clinique, les éléments qui peuvent faire suspecter la TBC sont nombreux :En revanche quand il s’agit d’une installation brutale, l’hémoptysie et crachats sanguins sont plus observés chez les personnes atteintes ainsi que l’épanchement pleural est observé que ce soit aérien ou liquidien.Le clinicien devant un contexte de symptomatologie pulmonaire qui persiste au-delà de 15 jours, et en tenant également compte de la prévalence dans la région en cause, est en mesure de suspecter la tuberculose et procède à la procédure de l’affirmation de diagnostic.
Cela doit conduire vers des examens complémentaires : radiographie du thorax et l’examen cytobactériologique des crachats.
Le diagnostic définitif est fondé sur l’isolement ou la culture du bacille, habituellement à partir des crachats.Les cavernes sont une complication fréquente de la tuberculose pulmonaire.
On appelle caverne une cavité creusée au sein du parenchyme pulmonaire.
Les bacilles tuberculeux se développent initialement dans le poumon sous forme de nodules, appelés granulomes, qui sont peu à peu entourés de lymphocytes et de macrophages destinés à contenir l'infection.
Un granulome peut évoluer soit vers la disparition sans cicatrice, soit vers la caverne, sans que les mécanismes sous-jacents soient compris en totalité.
Les vestiges de macrophages détruits occupent le centre du granulome et forment la majeure partie de la nécrose caséeuse.
Chez certains patients, cette nécrose caséeuse se liquéfie et devient un milieu de culture adapté aux bacilles, qui prolifèrent.
Des enzymes protéolytiques érodent alors la capsule fibreuse située en périphérie du granulome, et son centre liquide peut alors se vider peu à peu.
Lorsqu'une caverne tuberculeuse arrive en communication avec l'arbre bronchique, la dissémination des bacilles dans l'air expiré augmente la contagiosité,.
Par ailleurs, la quantité importante de bacilles contenus dans les cavernes favorise le développement de résistances aux anti-tuberculeux.Elle est très fréquente au même titre que la tuberculose pulmonaire.
Les adénopathies sont souvent médiastinales et hilaires.
Elles sont en général de taille modérée, mais peuvent parfois obstruer une bronche.
En périphérie les adénopathies sont surtout cervicales, puis axillaires et inguinales.
Initialement fermes et mobiles, les ganglions sont ensuite fixés par une péri-adénite avec peu de signes inflammatoires.
Les fistules externes à bord irrégulier laissent ensuite sourdre (suinter) un pus caséeux qui se recouvre de croûtes.
C'est cette maladie, nommée scrofule ou écrouelles que les rois de France et d'Angleterre étaient censés guérir par simple toucher.
La croyance et les cérémonies qui y étaient attachées ont perduré jusqu'au XIXe siècle.Le diagnostic repose sur l’examen bactériologique du liquide de ponction et l’examen anatomopathologique à la suite de la biopsie ganglionnaire.
L’apparition des signes généraux doivent encourager un traitement sans attendre le diagnostic microbiologique dans ces pays.Selon la même étude faite en Tunisie (une région endémique de la tuberculose) qui a porté sur cinquante patients atteints de la tuberculose ganglionnaire, il a été remarqué que les adénopathies étaient principalement cervicales (75 %), puis médiastinales (21 %), sus-claviculaires (9,4 %) et axillaires (6,3 %).
Les tailles ont été retrouvées surtout entre 3 et 5 cm.
Les adénopathies étaient inflammatoires ou fermes.
Dans 21,9 % des cas, la tuberculose ganglionnaire était associée à d’autres types de tuberculose.
La bactériologie a permis le diagnostic chez 65,6 % des cas.La tuberculose urogénitale est responsable de 14 à 41 % des atteintes extrapulmonaires.
Le rein est très souvent infecté lors d’une tuberculose miliaire le plus souvent au niveau du cortex rénal.
Cliniquement, les lésions sont très souvent unilatérales.
Au niveau du rein, elles sont préférentiellement situées dans la médullaire où elles vont produire des granulomes épithélioïdes avec une nécrose caséeuse (lésion spécifique à la tuberculose) aboutissant à une destruction tissulaire.L’atteinte se manifeste par des symptômes liés à la distension rénale en cas d’atteinte urétérale.
Elle peut se manifester cliniquement par une cystite banale.
Or, le diagnostic est évoqué devant une pyurie sans germe.
En cas de lésion génitale, les lésions touchent fréquemment l’épididyme se traduisant par une épididymite.Le clinicien oriente vers l’examen d'urine (recherche de bacille de Koch) des urines afin de confirmer le diagnostic.
L'examen cytobactériologique des urines permet d'évaluer une partie des conséquences.
Environ 50 à 75 % des hommes avec une atteinte génitale ont des anomalies radiologiques au niveau de l’appareil urinaire.
Un bilan radiologique de tout l’appareil urinaire (uroscanner, à défaut une urographie intraveineuse) est toujours indiqué ainsi qu’une radiographie du thorax à la recherche d’une localisation pulmonaire.La forme la plus fréquente et la plus redoutable est la tuberculose rachidienne dite mal de Pott.
La localisation au niveau de l’espace intervertébral (mal de Pott) est la plus fréquente des localisations ostéoarticulaires et la plus grave car elle siège au voisinage des structures nerveuses importantes.
Elle représente 10 % des cas de tuberculose.Selon une étude tunisienne qui a porté sur 180 cas de tuberculose rachidienne, il a été remarqué que l'état général a été altéré chez 80 patients (44 %).
Une fièvre modérée allant de 37,8 °C à 38,5 °C a été notée chez 55 patients (30 %) et une adénopathie satellite dans 40 cas (27 %).
Selon la même étude, l'intradermoréaction à la tuberculine pratiquée 120 fois a été positive dans 85 % des cas.La phase initiale de l’infection est marquée par l’atteinte des espaces intervertébraux rachidiens, et l’atteinte de la synoviale, où se développe la lésion tuberculeuse laissant apparaître une symptomatologie plus ou moins spécifique marquée par : des douleurs au niveau du rachis de type mécanique ainsi qu’un syndrome infectieux modéré et des signes de déficit neurologique s’installant progressivement.
Si elle est dépistée et traitée à ce stade d’invasion, l’évolution se fait vers la guérison et sans destruction.En revanche et en absence de traitement, l’évolution se fait lentement à partir d’un état stable vers la phase d’état où la destruction est irréversible.
Sur le plan tissulaire, on remarque une lésion spécifique à la tuberculose : la nécrose caséeuse développée dans l’espace intravertébral et laissant des séquelles majeures et irréversibles.
La symptomatologie est variée et marquée par des douleurs intenses avec une tuméfaction de la région affectée et adénopathie du site drainant la région ainsi que les troubles neurologiques.Le clinicien oriente vers les examens complémentaires afin d’affirmer son diagnostic et cela à travers la radiologie qui fournit des images plus ou moins spécifiques et la mise en évidence du BK via l’examen bactériologique et anatomopathologique à la suite d'une ponction/biopsie réalisée sur le site de l’infection.Une forme extrêmement rare, mais très redoutable.
Le tableau clinique et radiologique sont atypiques.
Elle touche les enfants et les adultes jeunes.
Dans sa forme typique la méningite tuberculeuse associe un syndrome méningé et un syndrome infectieux progressif et peu intense : fièvre au long cours, otalgie, vomissement.
Le syndrome méningé est caractérisé par les trois symptômes : la raideur de la nuque, les nausées et les vomissements.À la suite de la pratique de la PL, le LCR est classiquement clair, avec une lymphocytose, une hyperalbuminorachie et une hypoglucorachie.
Sa gravité nécessite la mise en route rapide du traitement.Des séquelles fonctionnelles s’observent dans plus d’un tiers des cas : hémiplégie, paralysie des paires crâniennes, troubles sensoriels, calcifications intracrâniennes, etc.Rare en Occident où elle ne représente que 1,5 à 2,1 % de l'ensemble des formes que peut prendre la tuberculose, la forme cutanée de la tuberculose est cependant endémique en région tropicale et au Maghreb.
Elle adopte alors des formes cliniques variées : chancre tuberculeux, tuberculose cutanée miliaire, lupus tuberculeux, scrofulodermes ou gommes tuberculeuses, ou encore tuberculose péri-orificielle.La classification de Beyt de 1980, basée sur des critères physiopathologiques, est aujourd'hui la référence pour distinguer les diverses formes :La réaction cutanée tuberculinique met en évidence la présence d’une hypersensibilité retardée induite par les antigènes mycobactériens (Mycobacterium tuberculosis, BCG, certaines mycobactéries atypiques).
La réaction cutanée à la tuberculine est explorée par IDR.
Cette IDR est réalisée par une injection dans le derme à la face antérieure de l'avant-bras d'un volume exact de 0,1 ml de la solution liquide de tuberculine.
La validité d'interprétation du test tuberculinique nécessite une technique parfaite.La tuberculine provoque des indurations au niveau du site de l’injection.
Une réaction est jugée positive lorsque le diamètre d'induration est >= à 5 mm.
En absence de vaccination, une induration supérieure à 8 mm doit témoigner et attester une primo-infection tuberculeuse.
Si l'induration est supérieure à 25 mm, la tuberculose maladie doit être évoquée.
Cette pratique se révèle outil dans le diagnostic des TBC ganglionnaires (positive chez 100 %), et la phase de la primo-infection de la tuberculose.Après avoir extrait des expectorations ou du liquide de ponction auprès du malade, l’échantillon du prélèvement fait l’objet d’un examen cytobactériologique à travers les différentes techniques :La spécificité des modalités de diagnostic a fait l’objet de plusieurs études d’évaluation d’efficacité.
Une étude rapporte que la méthode de coloration Zde N et la MF bénéficient d’une spécificité élevée allant jusqu’à 98 % dans le cas de la MF.
Une étude montre également que la concordance diagnostique entre la MF et la culture (souvent prise comme référence) est largement supérieure à celle qui existe entre la méthode de ZN et la culture (95,1 % contre 69,6 %).Les méthodes de ZN et l’examen de culture apportent une grande valeur diagnostique vu leur caractère économique en termes de cout.
Ils sont des examens peu couteux et accessibles et fortement recommandés dans le diagnostic de la TBC.
Ils se révèlent très pratiques et efficaces dans le diagnostic des tuberculoses ganglionnaire, pulmonaire, méningée et ostéoarticulaire.L’examen anatomopathologique se pratique sur l’échantillon résultant de la biopsie.
Il met en évidence une lésion spécifique à la tuberculose dite : granulome épitheloide gigantocellulaire à centre caséeux nécrosé.
Le terme de granulome désigne l’ensemble des éléments cellulaires présents dans un foyer inflammatoire.
Le foyer tuberculeux est entouré d’une grande cellule polynucléaire résultant de la fusion des macrophages tel que mentionné dans la physiopathologie de la maladie.Met en évidence la présence de l’ADN du germe dans l’échantillon issu de la ponction ou des crachats en cas de TBC pulmonaire.
La technique de l’art et telle que recommandée par l’OMS est réalisée à l’aide d’un dispositif nommé GeneXpert et l’utilisation du test rapide Xpert MTB/RIF.
La technique s’appuie sur l’amplification de l’ADN germique via la cartouche Xpert MTB/RIF riche en ADN polymérase (enzyme intervenant dans la réplication de l’ADN au cours du cycle cellulaire) et les ressources énergétiques et protéiques nécessaires à cette procédure.
Son utilisation a largement augmenté depuis 2010, date à laquelle l’OMS a recommandé pour la première fois son utilisation.
Cela comporte un avantage majeur portant sur son efficacité et son faible coût.De nombreuses études ont évalué l’efficacité de la cartouche dans la mise en évidence des BK et BK résistants à la Rifampicine ; il est rapporté par une méta-analyse compilant plusieurs études que le test MTB/RIF est spécifique à plus de 90 % et présente un outil important facilitant l’accès à un diagnostic précis à faible cout.
La mise en évidence des BK est établie dans 2 heures après le test.La modalité de diagnostic radiologique se révèle très utile et indiquée comme étant un examen de première intention en cas de tuberculose pulmonaire et ostéoarticulaire.
Cela est justifié par les images radiologiques plus ou moins spécifiques à la tuberculose.
La littérature rapporte que la spécificité varie de 27 à 81 % selon l’étude.
Les imageries idéales et révélatrices de la tuberculose répondent à certains attributs dont le premier est lié au siège.
En raison de l’affinité que les BK ont envers les régions aérées, la lésion radiologique est souvent observée dans les parties hautes des poumons.
Néanmoins, l’image radiographique peut contenir différentes formes :Un premier vaccin fut expérimenté en 1886 par Vittorio Cavagnis tandis qu'à cette même époque Robert Koch tenta vainement de développer un sérum curatif basé sur la tuberculine.
En 1902, à partir d'un bacille d'origine humaine atténué, Behring essaya un vaccin contre la tuberculose bovine : le bovovaccin.
Behring proposa également, sans succès, la tuberculase.
Toujours dans le domaine vétérinaire, Koch essaya le tauruman.
Pour mémoire, il faut aussi citer le sérum de Marmorek (1904), le sérum de Maragliano, les sérums de Richet et Héricourt, ainsi que les tentatives peu honnêtes de Friedmann (en) et de Spahlinger.
C'est en 1921, qu'Albert Calmette et Camille Guérin de l'Institut Pasteur de Lille essayent avec succès le premier vaccin contre la tuberculose sur lequel ils travaillaient depuis 1908 — qui était conçu pour être un vaccin vétérinaire.
Baptisé BCG (pour « Bacille de Calmette et Guérin » ou « Bilié de Calmette et Guérin ») ce vaccin issu d'une souche vivante atténuée de Mycobacterium bovis deviendra obligatoire en France en 1950.L’efficacité de la vaccination par BCG se limite à la protection contre l’évolution mortelle de la tuberculose, particulièrement la méningite tuberculeuse et la maladie disséminée (miliaire).
Le vaccin est plus efficace chez le nouveau-né et l'enfant que chez l'adulte (protection estimée entre 75 et 85 % des formes graves du nourrisson et du jeune enfant et entre 50 et 75 % des formes de l'adulte).Il ne permet donc pas d'empêcher la transmission de la maladie et d'enrayer l'épidémie mondiale.
L'avenir est dans la recherche des gènes de virulence du bacille.Sur base d'études faites à grande échelle et organisées par l'Organisation mondiale de la santé (OMS), certains pensent que l'efficacité du BCG est faible : dans une étude faite sur 260 000 personnes dans un pays d'endémie tuberculeuse (en Inde), les auteurs n'ont pas trouvé de différence significative entre le groupe qui avait reçu le BCG et celui qui ne l'avait pas reçu.
Une autre étude faite également en Inde sur 366 625 personnes a montré que le BCG n'avait aucune action préventive sur les formes de tuberculose pulmonaire parmi les adultes.En juillet 2007, la ministre française de la santé, Roselyne Bachelot, a annoncé la suspension de l'obligation de vacciner tous les enfants et les adolescents contre la tuberculose par le BCG, à l'occasion de la présentation du nouveau programme de lutte contre cette maladie.En France (depuis 1964), en Belgique et en Suisse, cette maladie est sur la liste des maladies infectieuses à déclaration obligatoire.En France, en particulier, c'est la mise sous traitement antituberculeux qui fait partie de la déclaration.
Cela permet d'inclure les cas confirmés bactériologiquement et les cas probables reposant sur un faisceau d'arguments épidémiologiques, cliniques et d'imagerie en l'absence de preuve bactériologique formelle.
En effet ces cas probables nécessitent les mêmes investigations d'enquête épidémiologique pour rechercher d'éventuels cas contact ou contaminant autour d'eux.Toutes les espèces de vertébrés peuvent être atteintes spontanément par différents types de bacilles tuberculeux.
Ces tuberculoses animales peuvent être cause de zoonoses.Les symptômes de la tuberculose animale n’ont été décrits et rapprochés de la forme humaine que très tardivement.
Si Aristote décrivit déjà les scrofules chez les animaux, les lésions de la tuberculose bovine restèrent longtemps confondues avec celles de la péripneumonie contagieuse et de l’hydatidose bovine ou de la morve des chevaux.
Le premier à rapprocher les tubercules humains de ceux du bœuf fut Ernst Friedrich Gurlt, en 1831.
Auparavant la tuberculose bovine, surtout dans les cas de localisation pleurale, a pu être assimilée plutôt à la syphilis humaine.Afin de prévenir la transmission du bacille chez l'humain, soit par voie aérienne directement par contact, soit par voie digestive après ingestion de viande ou de lait insuffisamment cuit ou pasteurisé, la plupart des pays développés ont entrepris d'assainir leur cheptel bovin.La détection des animaux porteurs se fait par voie clinique, allergique et par recherche des lésions évocatrices sur les carcasses à l'abattoir.
En France, cette prophylaxie est obligatoire depuis 1963 sur tout le territoire national pour tous les bovins âgés de plus de six semaines.
Pour que les animaux puissent se déplacer sans contrainte, le cheptel doit obtenir le statut « officiellement indemne de tuberculose ».
Pour cela, tous les animaux sont testés régulièrement par intradermotuberculination.
La fréquence est annuelle mais peut être allégée quand la prévalence de la maladie dans le département est faible.
Les animaux réagissant peuvent être soit testés comparativement par une tuberculine aviaire (pour détecter les faux positifs), soit envoyés à l'abattoir (l'abattage est alors subventionné) où les lésions évocatrices seront recherchées par un vétérinaire inspecteur, et éventuellement confirmées par diagnostic de laboratoire.
Les troupeaux où l'infection est confirmée peuvent faire l'objet d'un abattage total, également subventionné.Parallèlement, en France, un réseau de cinq mille vétérinaires sanitaires surveille l'apparition de signes cliniques évocateurs.
Des visites sanitaires biennales de tous les troupeaux de bovins sont obligatoires.
La vaccination au BCG positivant le test intradermique, elle est interdite sur le territoire français.Cette politique a permis de faire considérablement baisser la prévalence de la tuberculose bovine.
En 2000, la commission européenne a reconnu à la France le statut de pays officiellement indemne.
En 2006, le taux d'incidence était de 0,032 % de cheptels infectés alors qu'il était de près de 25 % en 1955.
Il convient de distinguer la tuberculose bovine de la paratuberculose bovine, due également à une mycobactérie, mais qui n'est pas une zoonose.Avant l’obligation de pasteurisation du lait, la proportion des cas de tuberculose humaine d’origine bovine était estimée à 1,3 % des cas de tuberculose humaine.
En France aujourd'hui, les rares cas de tuberculose humaine d'origine animale (0,5 % des cas) sont constatés dans leur majorité chez des sujets de plus de soixante ans, ce qui est le signe d’une infection ancienne.La fréquence de la tuberculose chez les carnivores domestiques, essentiellement due à M. bovis ou M. tuberculosis, a baissé, en même temps que celles des tuberculoses humaine et bovine.
Le vétérinaire doit cependant toujours veiller à ce que les carnivores ne servent pas de relais épidémiologique secondaire dans un foyer de tuberculose, qu’il soit animal ou humain.
Le diagnostic de la tuberculose des carnivores est extrêmement difficile à poser.Afin de dépister la tuberculose auprès des populations géorgiennes, le Centre National pour le Contrôle des Maladies et de la Santé Publique de Géorgie utilise un camion autonome qui permet à l’équipe médicale de se stationner à n'importe quel endroit, pour procéder aux examens.Le traitement est d'une durée de six mois pour une tuberculose pulmonaire à bacille de Koch sensible chez un patient immunocompétent, comprenant 2 mois de quadrithérapie antibiotique (isoniazide, rifampicine, pyrazinamide et éthambutol), puis 4 mois de bithérapie (isoniazide et rifampicine).
Le traitement prolongé est indispensable afin de guérir de la maladie et éviter l'émergence de souches résistantes dont l'évolution est souvent beaucoup plus grave.
Malheureusement, ce traitement étant long et complexe, il est difficile à faire respecter aux patients en particulier dans les pays dont le système de santé est lacunaire, où la thérapie sous observation directe est difficile à mettre en œuvre, ce qui favorise l'apparition d'antibiorésistance.En plus et afin	de prévenir	ce risque de résistances, une association d’antibiotiques est utilisée.
En effet, les mécanismes de résistance étant spécifiques, chaque antituberculeux de l’association va tuer les bacilles mutants résistants à l’autre antituberculeux.
En suivant ce raisonnement, il parait logique de proposer une association de	deux antibiotiques.
L’isoniazide et	la rifampicine sont cette association de base.
Il faut toutefois prendre en compte l’historique de mise sur le marché des antituberculeux.
L’isoniazide était, dans les années 50, un des rares antituberculeux disponible.
Par conséquent des échecs de traitement ont déjà eu lieu avec sélection de mutants résistants (on parle de « résistance secondaire »).
Ces patients ont pu transmettre ces souches résistantes à d’autres patients qui ont développé une tuberculose avec une résistance d’emblée (on parle alors de « résistance primaire »).
Du fait de la	circulation de ces souches résistantes il faut ajouter un troisième antituberculeux à la bithérapie associant rifampicine et isoniazide, l’éthambutol.
Celui-ci permet d’être assuré d’avoir toujours une bithérapie en cas de résistance primaire à l’isoniazide (5% des cas en France).
Cependant, cette trithérapie nécessite une durée de traitement d’au moins 9 mois pour éradiquer les bacilles persistants qui présentent un métabolisme ralenti et qui sont à l’origine des rechutes.
Le pyrazinamide ajouté pendant les 2 premiers mois permet de réduire la durée du traitement de 9 à 6 mois.La rifadine est un traitement qui peut être utilisé pour traiter la tuberculose osseuse.L'isoniazide est utilisé généralement à la dose de 5 mg, en association avec trois autres antibiotiques.
L’isoniazide inhibe la multiplication des bactéries responsables de la tuberculose.
Ce médicament doit être administré à jeun.
Antibiorésistance : une large épidémie de cas de tuberculose résistante à ce médicament s'est déclarée à Londres de 1995 à 2006.La rifampicine est utilisée habituellement à la dose de 10 mg/kg et par jour, pendant une durée de six mois, pour le traitement de la tuberculose.
Cet antibiotique est un fort inducteur enzymatique : il accélère la dégradation des autres médicaments, notamment les contraceptifs oraux.
Les femmes sous contraceptifs sont donc invitées à revoir leur traitement à la hausse (après consultation du gynécologue), voire à passer à une contraception mécanique (préservatif…) pendant la durée du traitement.
La rifampicine provoque une coloration orangée des urines.
C'est un bon moyen d'objectiver l'observance du traitement.La streptomycine (découverte par Selman Waksman vers 1946) fut le premier antibiotique actif contre le bacille de Koch.
Il est contre-indiqué chez la femme enceinte et doit impérativement être associé à d'autres antituberculeux (INH et PAS).
Par voie intramusculaire chez l'adulte : 15 à 25 mg/kg et par jour.
Par voie intrarachidienne : pour l'adulte, 25 à 100 mg/j, pour un enfant, 20 à 40 mg/kg et par jour en deux ou quatre injections.
Surveillance du traitement : les fonctions auditives et rénales devront être surveillées régulièrement.L'éthambutol est utilisable chez la femme enceinte.
Elle doit être utilisée le matin à jeun en une seule prise, quinze à vingt milligrammes par kilogramme.
Ne pas dépasser vingt-cinq milligrammes par kilogramme par 24 heures sans dépasser soixante jours, puis réduire à quinze milligrammes par kilogramme et par jour.
Surveillance par un fond d'œil et un examen de la vision des couleurs mensuels.Le bédaquiline (R207910), une molécule de la famille des diarylquinolines, pourrait se révéler prometteuse contre Mycobacterium tuberculosis.
Elle fait naître trois espoirs : raccourcissement de la durée du traitement ; envisager des prises une seule fois par semaine en association avec un autre antituberculeux ; être active sur des souches multi résistantes, avec une efficacité bactéricide bien supérieure à celle de l'isoniazide et de la rifampicine.
Ce médicament est actuellement en phase très précoce de son développement.
Seules des études approfondies chez l'humain permettront de vérifier que ces espoirs sont fondés.Des corticoïdes sont ajoutés au traitement antituberculeux en cas de méningite tuberculeuse, de résistances ou de rechute de traitement.
La corticothérapie doit être commencée après instauration de l'antibiothérapie, à la dose de 0,5 à 1 mg/kg et par jour pour une durée de un à deux mois.Le traitement des infections latentes repose soit sur l’isoniazide en monothérapie pour une durée de 6 ou 9 mois, soit sur l’association isoniazide-rifampicine pendant 3 mois.La résistance aux traitements est due à des traitements insuffisants en doses ou en durée.
Elle pose des problèmes importants car la tuberculose est beaucoup plus délicate à soigner, surtout en cas de résistances à plusieurs anti-tuberculeux (multi résistance).
Dans le pire des cas, elle est dite étendue lorsqu'elle concerne des antibiotiques de première intention (isoniazide, rifampicine) et un ou plusieurs antibiotiques de seconde intention.Le dépistage de ces formes est difficile, la mise en culture du germe en présence des différents antibiotiques (antibiogramme) requérant plusieurs semaines pour avoir un résultat du fait de la lenteur de multiplication du mycobactérium.
La recherche directe de mutations responsable de la résistance est faisable et donne de bons résultats.
Du fait de son coût, ces techniques sont difficilement applicables dans les pays pauvres.
Une autre méthode consiste à observer la croissance de la souche de mycobacterium au microscope, en présence de différents antibiotiques.
Elle donne des résultats fiables et assez rapide (une semaine).Le traitement des formes résistantes consiste en l'utilisation d'antituberculeux testés comme efficace sur la souche en question, complété par une fluoroquinolone et par des antibiotiques, dits de seconde ligne, comme la moxifloxacine, la bédaquiline, le delamanid.
La prise en charge a fait l'objet d'un document de recommandations publié par l'OMS en 2006.
D'autres traitements comme le télacébec sont également développés.Le 14 août 2019, après 12 mois de test sur 109 patients en Afrique du Sud, la Food and Drug Administration annonce qu'un cocktail de médicaments fait de bédaquiline, de linézolide et de prétomanide, réparti en 5 comprimés par jour, permet de réduire la durée de traitement de la tuberculose résistante à 6 mois (plus 6 mois de suivi thérapeutique) avec un taux de guérison de 90 % — contre des traitements de 18 à 24 mois avec la prise de 30 à 40 gélules quotidiennes et de nombreuses piqures jusque-là.Avant la découverte d'antibiotiques efficaces, on pratiquait la collapsothérapie.
La collapsothérapie est un affaissement de la partie atteinte du poumon et d'une partie du thorax par insufflation d'air, le pneumothorax, ou par chirurgie mutilante.L'écrivain François Abgrall (1906-1930), décédé très jeune à 23 ans de cette maladie à une époque où elle était très mal soignée a décrit dans son livre Et moi aussi, j'ai eu vingt ans !
qui est un témoignage précieux sur le statut du malade tuberculeux vers 1925, les symptômes de cette maladie et la manière dont elle était soignée en France dans les années 1920.
À l'époque, la seule thérapeutique proposée est la collapsothérapie.
La technique consiste à mettre le poumon « au repos » en laissant entrer l'air ou en injectant un produit huileux entre les feuillets de la plèvre, détachant ainsi le poumon des côtes.
Cette manœuvre soulage provisoirement le patient mais s'accompagne de complications multiples parmi lesquelles la perte du poumon n'est pas exclue.Ces méthodes ont disparu des pays occidentaux dans les années 1950.Selon une étude d'Olivier Neyrolles de l'Institut Pasteur, le bacille de Koch serait stocké dans les cellules adipeuses.
C'est ainsi qu'il résisterait aux antibiotiques les plus puissants et qu'il serait capable de réapparaître après de nombreuses années chez des personnes guéries.Le traitement bactériophagique pourrait représenter à terme une solution de traitement dans les cas de résistance aux antibiotiques.
En effet le bacille de Koch appartient au genre Mycobacterium dont les membres présentent des caractéristiques similaires.
En mai 2019, une équipe internationale de l'Université de Pittsburgh a réussi à traiter avec succès par phagothérapie un patient hospitalisé à Londres victime d'une infection généralisée par Mycobacterium abscessus, en utilisant un cocktail de phages modifiés génétiquement administré par voie intraveineuse.
La myofasciite à macrophages (MFM) est une entité tissulaire caractérisée par des lésions musculaires infiltrées par des macrophages.
Ces lésions sont visualisées à l'analyse de tissu musculaire au microscope lors d'une biopsie musculaire.
La MFM est responsable d'un syndrome pseudo-grippal : douleurs musculaires et articulaires, une fatigue et une légère fièvre.
Bien qu'il ne soit pas établi que cette entité histologique soit associée à un quelconque syndrome clinique, certains lui associent des symptômes variables.Pour le Comité consultatif mondial sur la sécurité des vaccins de l'OMS (GACVS, de l'anglais : Global Advisory Committee on Vaccine Safety), la MFM se caractérise par une « infiltration centripète de l’épimysium, du périmysium et de l’endomysium périfasciculaire par des cellules négatives à la réaction acide periodique de Schiff (PAS) appartenant à la lignée macrophagique et porteuses d’inclusions cristallines osmiophiles »,, avec « absence de nécrose (des cellules épithélioïdes et géantes) et de figures de mitose, et des lésions à peine visibles au niveau des fibres ».
En 2004, l'OMS ajoute la présence d'une « nécrose musculaire microscopique » autour des inclusions d'aluminium.Le diagnostic est établi par une biopsie du muscle (généralement le deltoïde en France) qui la met en évidence.Les inclusions (en) dans les macrophages sont constituées de sels d'aluminium ; ceci a été montré par des études via microsonde nucléaire, microanalyse aux rayons X et spectrométrie d'absorption atomique.La myofasciite à macrophage est décrite seulement en France, à quelques exceptions près.La myofasciite à macrophages est essentiellement retrouvée chez l'adulte, mais des lésions ont été décelées chez de jeunes enfants (biopsie du quadriceps).Il n'est pas établi que cette entité histologique soit associée à un quelconque syndrome clinique d'après les conclusions de l'OMS et de l'Afssaps en 2004, ainsi que du HCSP en 2013.
Cependant, certains ont pu lui associer des symptômes variables.La découverte de la myofasciite à macrophages (MFM) s’est faite en plusieurs étapes à partir de 1993, par Michelle Coquet, neuropathologiste à Bordeaux, et autour en France du travail du Groupe Nerf-Muscle du Département de Pathologie de Hôpital Henri Mondor de Créteil, et le Groupe d’études et de recherche sur les maladies musculaires acquises et dysimmunitaires (GERMMAD) de l’Association française contre les myopathies.
La myofasciite à macrophages (MFM) est décrite pour la première fois en août 1998 dans le journal The Lancet,.À la fin des années 1990, l'existence d'une lésion histologique de myofasciite était bien établie, mais la notion éventuelle de « maladie » associée à cette lésion demeurait controversée, notamment parce que ce syndrome n'a d'abord été décrit épidémiologiquement qu'en France (« à quelques exceptions près » remarquait le Comité consultatif mondial sur la sécurité des vaccins de l'OMS en 1999), alors que le mode très « internationalisé » de préparation des vaccins rend peu probable une anomalie pharmaceutique qui se limiterait à un seul pays.Parmi les hypothèses discutées en 1999 par ce comité :L'OMS crée un Comité consultatif de l'OMS pour la sécurité des vaccins, qui rencontre en 1999 des représentants du GERMMAD, des experts en matière de maladies neuromusculaires ou des adjuvants aluminiques, du Secrétariat d’État français à la santé et à l’action sociale, de l’Agence française de sécurité sanitaire des produits de santé ainsi que des représentants de l’industrie.Sur la base des « faits » qui lui ont été soumis, ce comité a reconnu « l’existence d’une entité histopathologique distincte appelée myofasciite à macrophages, caractérisée d’une part par la présence, dans le deltoïde, d’amas denses, persistants et localisés, de macrophages positifs au PAS accompagnés d’inclusions cristallines osmiophiles d’aluminium, et d’autre part par une réaction inflammatoire chronique focale », en précisant qu'il « existe, à l’appui de ces observations, des données faisant état de lésions passagères comparables chez des animaux de laboratoire après injection intramusculaire de vaccins contenant de l’aluminium », mais en posant trois questions à résoudre :La piste des vaccins aluminiques a ensuite été écartée par certaines autorités sanitaires nationales alors que le Comité consultatif mondial sur la sécurité des vaccins de l'OMS invitait néanmoins à poursuivre la recherche et à élargir le nombre d'échantillons et la population épidémiologiquement étudiée pour « établir s’il existe une association entre des lésions MMF locales et tout symptôme ou affection générale », concluant en 1999 qu'au vu des « limites des connaissances actuelles, la MMF ne se rattache pas à des pathologies telles que la myopathie inflammatoire, la dermatomyosite, la polymyosite, la myosite à inclusions et la fasciite à éosinophiles.
Les données actuelles n’établissent ni n’excluent la possibilité d’une maladie générale affectant d’autres organes » ; « Il existe de nombreux mécanismes immunitaires qui pourraient être à l’origine du passage d’une immunoréaction locale à une affection généralisée et la question doit être étudiée plus à fond ».
Le Comité estimait en 1999 ne pas disposer de données suffisantes pour remettre en cause l'aluminium dans les vaccins, tout en recommandant « vivement d’entreprendre des recherches afin d’évaluer les aspects cliniques, épidémiologiques, immunologiques et biologiques de cette pathologie ».En 2002, une étude épidémiologique sur l'homme était en cours.
Et des résultats préliminaires obtenus sur le modèle animal (singe et chez plusieurs souches de rat de laboratoire montraient une persistance à long terme de l’aluminium et les modifications histopathologiques au point d’injection du vaccin avec une « très faible réaction inflammatoire locale, sans autres symptômes ou conséquences » selon le comité, de même pour les études comparant le taux de macrophages chez les sujets bien portants et chez des sujets touchés par des MMF.
Le comité en 2002 estimait que les MMF pourraient être un simple marqueur de la vaccination avec persistance prolongée d’aluminium au point d’injection, sans conséquences remettant en cause l'adjuvant aluminium dans les vaccins.Cette étude cas-témoins entamée en 2002 a comparé des témoins (ayant une biopsie musculaire ne révélant pas de MFM) et des patients (les cas) ayant une MFM, selon le site de la biopsie, le sexe, l’âge et le délai entre la vaccination et la biopsie, pour chercher une éventuelle association entre MFM et syndrome clinique spécifique.
Une probabilité d’avoir reçu des vaccins contenant de l’hydroxyde d’aluminium comme adjuvant était effectivement plus élevée chez les patients touchés par la MFM, qui présentaient aussi plus de signes de fatigue et de signes fonctionnels apparentés que les témoins (avec fatigue plus fréquente en début d'évolution ; c'est elle qui souvent a conduit à la biopsie musculaire), mais les myalgies et arthralgies n'étaient pas toujours associées aux MFM.
On n'a pas observé d'autre différence des symptômes et des facteurs de risque spécifique aux patients atteints de MFM.
Selon le Comité consultatif de l'OMS pour la sécurité des vaccins (GACVS), cette étude ne permet pas de penser que la MFM puisse être liée à des symptômes cliniques ou une maladie spécifique quelconque.Selon le GACVS, le fait que la MFM soit principalement observé en France, pourrait être dû au fait qu'on pratique dans ce pays des biopsies du deltoïde alors que dans beaucoup d’autres pays d'autres muscles sont plus volontiers choisis et être aussi expliqué par « la très large promotion de la vaccination anti-hépatite B chez l’adulte.
»En mai 2004, le comité estime que l' « agrégat macrophagique inflammatoire comportant des inclusions cristallines et accompagné d’une nécrose musculaire microscopique » observé dans les biopsies de certains patients vaccinés pourrait n'être qu'« une sorte de « tatouage » laissée par la vaccination) », sans preuve de véritable affection ou maladie clinique.
L'OMS n'estime pas pouvoir reconnaitre l'existence d'un syndrome spécifique associé car à ce jour (2004) :Après une étude épidémiologique, le conseil de l'AFSSAPS a ainsi conclu en 2004 qu'en l'état actuel des connaissances, aucun syndrome clinique spécifique n'est retrouvé associé à la vaccination avec des vaccins contenant des adjuvants aluminiques.En 2013, dans son rapport « Aluminium et vaccins », le Haut Conseil de la santé publique (HCSP) estime que les données scientifiques disponibles ne permettent pas de remettre en cause la sécurité des vaccins contenant de l’aluminium.
Le HCSP met en garde contre « les conséquences, en matière de réapparition de maladies infectieuses,  résultant d’une remise en cause des vaccins contenant de l’aluminium en l’absence de justification scientifique ».En 2016, l'académie de pharmacie a produit un rapport sur les adjuvants aluminiques.
Elle constate aussi que le lien de cause à effet entre la présence persistante de l'aluminium au niveau du site d'injection du vaccin et son incorporation du métal dans les macrophages, et la MFM n'est pas démontré.En mai 2001, une association de malades se constitue : Association d'« Entraide aux Malades de la Myofasciite à Macrophages » (E3M)En juillet 2012, l'association E3M (Entraide aux Malades de Myofasciite à Macrophages) dénonce le retrait progressif du marché des seuls vaccins encore sans aluminium décidé à partir de 2008 par les laboratoires.
En 2014, l'association E3M porte plainte contre X pour faux et usage de faux, escroquerie, atteinte à l'intégrité de la personne, mise en danger de la personne/risque causés à autrui,.
L'association conteste les raisons pour lesquelles Sanofi a justifié le retrait des vaccins sans aluminium.Depuis juillet 2011, « 250 parlementaires ont interpellé le ministère de la santé sur la question des sels d’aluminium et des vaccins.
»En mars 2012, les députés du « groupe d'étude sur la vaccination » formulent onze « recommandations » dont l'une est un moratoire sur l’aluminium vaccinal, en attendant que des études précisent les risques qu'elles pourraient ou non faire encourir aux personnes vaccinées (principe de précaution).
L'association E3M souligne que le phosphate de calcium, autrefois utilisé comme adjuvant, est une alternative « immédiatement disponible » à l'aluminium.En octobre 2012, l'Association santé environnement France, publie une synthèse sur l'aluminium.
Selon l'ASEF, « 1 000 cas de MFM ont été identifiés par biopsie musculaire en France (dans cinq centres d’anatomo-pathologie en France), mais cette pathologie décrite récemment semble très sous-diagnostiquée car elle est encore mal connue des professionnels de santé ».
En novembre 2012, les chercheurs qui ont découvert la maladie estiment qu'il existe une part de la population (jusqu'à 5 % de la population, selon le Pr Romain Gherardi) qui est génétiquement prédisposée à ce syndrome dont les symptômes, maintenant étudiés chez 585 adultes, apparaissent en moyenne 11 mois après le vaccin.
Chez eux, des cellules du système immunitaire pourraient capturer les molécules d'aluminium ou des composés d'aluminium et les transporter jusqu'au cerveau « alors même que le nombre de vaccins recommandés ne cesse d'augmenter, avec près de 200 vaccins en développement actuellement ».Début novembre 2012, l'ANSM décide de ne pas poursuivre le financement des recherches de l'INSERM sur ce sujet dans le cadre de son appel à projet, tout en affirmant être intéressé par le sujet, mais alors que Romain Gherardi et l'équipe référente mondiale depuis 15 ans sur cette question n'ont selon lui « jamais reçu un centime d'argent public pour ses recherches ».
Selon France info, l'ANSM assure s'intéresser à la question, mais mettrait en doute la rigueur des travaux du scientifique — l'aluminium utilisé sur les rats ne serait pas le même que l'aluminium vaccinal.
Mi novembre 2012, des spécialistes de la question tels que Romain Gherardi (France), Christopher Exley (Grande-Bretagne), Christopher Shaw (Canada) ou Yehuda Shoenfeld (Israël) s'associent, soutenus par le Réseau Environnement Santé (RES) et l'association Entraide aux Malades de Myofasciite à Macrophages pour protester dans une lettre ouverte à la ministre de la Santé (Marisol Touraine) et lors d'une conférence de presse contre le non-financement de leurs recherches alors que selon leurs derniers travaux épidémiologiques, concernant la « nocivité des sels d’aluminium », on est passé « du soupçon aux certitudes », au moins pour certains profils génétiques.En 2012, l'association E3M lance une grève de la faim pour protester contre le retrait des crédits de recherche.
La grève s'achève le 19 décembre après que l'association a obtenu gain de cause.
: document utilisé comme source pour la rédaction de cet article.
La séroprévalence ou séroépidémiologie évalue le nombre de personnes, dans une population donnée, ayant été exposées à un microorganisme, ou à un vaccin, et qui développent des anticorps spécifiques à des taux significatifs (pour le diagnostic – personnes séropositives –, ou pour la prévention – personnes protégées ou immunisées –-).Les techniques de détection d'anticorps sont les tests sérologiques, pratiqués alors sur l'ensemble d'une population ou sur un échantillon représentatif de celle-ci.
La séroprévalence est souvent présentée sous forme de pourcentage ou encore de cas ramenés à une population de 100 000 individus.
Un déficit immunitaire, une immunodéficience (IMD) ou une immunodépression, sont une situation pathologique liée à l'insuffisance d'une ou de plusieurs fonctions immunologiques.
On parle aussi de « dysfonctionnement immunitaire ».
La pandémie de SIDA est à l'origine d'une augmentation du nombre de cas d'immunodépression (en Afrique du Sud notamment).
Dans les pays riches, dont en France, le nombre de patients immunodéprimés ou « immunosupprimés » est également en hausse régulière, d’une part en raison de l’amélioration du pronostic global du cancer, et d’autre part de l’utilisation croissante d’immunosuppresseurs pour d’autres maladies (auto-immunes), ainsi qu’en raison d’un nombre croissant de transplantations d’organes.
Ces patients ont comme première cause d’admission en réanimation des infections sévères (atteintes respiratoires le plus souvent).
Le déficit immunitaire est dit « primitif » quand le patient le présente dès sa naissance ou l’a acquis dans l’enfance, il est dit « secondaire » quand il survient à la prise de médicaments immunodépresseurs ou immunosuppresseurs ou pour d’autres raisons.
Dans un organisme immunodéprimé, le risque est accru de voir plusieurs souches d'un pathogène se recombiner génétiquement pour faire émerger un pathogène nouveau.On distingue l'immunodéficience d'origine génétique, ou immunodéficience innée, dont un des cas extrêmes est représenté par les enfants-bulles, et l’immunodéficience acquise dont l'exemple le plus connu est celui du SIDA.
Au-delà de sa nature innée ou acquise, l'immunodéficience peut se manifester à des degrés divers.Les déficits immunitaires peuvent être de type congénital, ou même héréditaire, souvent alors décelés chez l'enfant ou le jeune adulte, ou de type acquis (décelable à tout âge).
Une dépression immunitaire peut aussi être induite par certaines formes ou niveaux de stress (sujet traité par la psycho-immunologie, ou encore par la production d'endotoxine lors de certaines infections  ; de nombreux parasites, microbes ou virus disposent de moyens de diminuer ou contourner l'immunité, ce qui leur permet de mieux coloniser l'organisme qu'ils infectent).Lorsque l'immunodéficience est innée, elle a alors souvent une origine génétique.
Certains acteurs de la défense immunitaire ne sont pas fabriqués correctement en raison d'une anomalie du gène qui code cette information.
Ce manque s'exprime par un mauvais fonctionnement de la moelle osseuse, chargée de la fabrication des cellules de l'immunité.
Ainsi, par exemple, la moelle osseuse d'un enfant atteint d'une telle immunodéficience ne pourra pas fabriquer de phagocytes ou de lymphocytes B (donc pas d'anticorps) ou lymphocyte T.
Il ne possède donc pas les éléments nécessaires pour se défendre contre les infections.L'immunodéficience innée signifie que le système immunitaire est incapable de lutter efficacement contre les microbes.
La moindre infection peut donc être fatale et c'est pourquoi certains patients, comme les enfants-bulles, atteints d'immunodéficience innée, vivent dans une « bulle » stérile qui les maintient à l'abri des microbes.Il est parfois possible de corriger une immunodéficience innée grâce à une greffe de moelle osseuse.Les déficits immunitaires sont classés en fonction de leur place dans l'organisation physiologique de l'immunologie.Certains déficits échappent à la classification.Il en est ainsi de la candidose cutanéo-muqueuse chronique, de l'acrodermatitis enteropathica, du syndrome à Hyper IgE, et de certains déficits fonctionnels du système immunitaire combinés à d'autres malformations, notamment dans le cadre du développement osseux (Nanisme).Le système du complément est très complexe, avec des réactions en cascade de nombreuses protéines à action enzymatique et qui concourt à la lyse cellulaire, en collaboration avec le système immunitaire spécifique.Chaque protéine du complément peut exprimer un déficit, génétique, autosomal récessif.Ces déficits ont comme manifestations cliniques des infections à répétitions et des maladies auto-immunes, type LED (Lupus érythémateux disséminé)Il s'agit des déficits de la phagocytose et de la bactéricidie, notamment :Un grand nombre de situations pathologiques ou de blessures (chez le grand brûlé par exemple) s'accompagnent d'un dysfonctionnement du système immunitaire, générateur d'infections à répétition.
Il est difficile de les citer toutes, et nous devons nous contenter de faire état des situations les plus spécifiques.La sarcoïdose est une maladie non maligne du système lymphoïde qui s'accompagne d'un déficit de l'immunité cellulaire.Un grand nombre de thérapeutiques ont comme effet secondaire l'apparition d'un déficit immunitaire plus ou moins sévère, on peut citer entre autres la banale et fréquente corticothérapie, mais aussi les traitements du cancer (radiothérapie, chimiothérapie).
Sur le même principe, l'irradiation accidentelle peut être responsable d'une immunodéficience en cas de doses importantes.Le traitement immunosuppresseur, notamment pour lutter contre le rejet de greffe, mais aussi les maladies auto-immunes, dont la sclérose en plaques.Une immunodéficience favorise d'une part le développement de micro-organismes ordinairement non pathogènes, responsables alors de maladies dites opportunistes, ainsi que le développement plus fréquent et plus grave d'infections à germes pathogènes (agent infectieux responsable d'une maladie infectieuse), et d'autre part permet dans certains cas l'apparition de cancers, dont le développement résulte de la multiplication anarchique de cellules cancéreuses normalement éliminées entre autres par les cellules NK chez les personnes immunocompétentes.Dans un organisme immunitairement déprimé des germes habituellement non pathogènes pour l'homme et provenant par exemple de l'air, de l'eau, du sol ou des aliments peuvent aussi provoquer des infections sévères, dites « infections opportunistes ».
Il existe alors aussi un risque accru de recombinaison génétique entre souches (de microorganismes infectieux, bactériennes ou virales notamment) plus ou moins proches, avec émergence possible de nouveaux pathogènes (y compris à partir d'un virus atténué utilisé dans certains vaccins),.Un déficit immunitaire peut être à l'origine de difficultés de cicatrisation et/ou d'autres pathologies, notamment de tumeurs, tumeurs malignes, cancer ou leucémie.Certaines interleukines, interférons et facteurs de croissance (les facteurs de croissance sont des molécules qui ordonnent aux cellules de l'organisme de se reproduire) sont utilisés, dans ce cas des facteurs de croissance stimulant le développement des leucocytes).Des agents hématopoïétiques comme le filgrastim (Neupogen) peuvent être administrés afin de corriger une neutropénie, notamment chez les patients sous une chimiothérapie qui diminue la production de globules blancs, dans des cas de neutropénie chronique grave ou chez des personnes recevant certains médicaments contre le VIH,.Une transfusion de leucocytes (globules blancs) peut être réalisée dans des cas très particuliers.
Le tétanos (en grec ancien : τέτανος, « rigidité spasmodique du corps » ), est une toxi-infection touchant l'être humain et autres animaux.
Il est dû à une infection locale par la bactérie Clostridium tetani produisant une neurotoxine, la tétanospasmine, ciblant le système nerveux central.
Cette toxine est l'un des plus puissants poisons biologiques connus.
Elle entraîne la mort dans 20 à 30 % des cas.
La guérison s'obtient après plusieurs jours ou semaines d'hospitalisation en réanimation et soins intensifs.Dans les pays développés, si cette maladie est en voie de disparition, elle persiste encore par insuffisance de vaccination.
Ailleurs, elle touche surtout les femmes qui viennent d'accoucher et les nouveau-nés des régions les plus pauvres, du fait d'une absence d'hygiène et de vaccination.
En 2019, ce tétanos maternel et néonatal demeure un problème de santé publique dans 12 pays en développement.Cette maladie n'est ni immunisante (il est possible d'être infecté plusieurs fois), ni contagieuse (pas de transmission de personne à personne).
Elle n'est pas éradicable car les bactéries sont en permanence dans le sol et l'environnement, mais elle est totalement évitable par la vaccination et l'hygiène des plaies.Les manifestations d'un tétanos déclaré sont suffisamment spectaculaires et caractéristiques pour avoir été reconnues dès la Haute Antiquité.
En Égypte, le papyrus Kahun (2000 av.
concernant les maladies des femmes, mentionne une contraction des mâchoires s'étendant à la partie postérieure du corps.
), le tétanos est nommé par Platon et décrit par Hippocrate (Des Maladies, III) sous deux formes : le tétanos (contraction des mâchoires avec rigidité du tronc et des membres) et l'opisthotonos (avec rigidité dorsale postérieure concave).
Selon sa doctrine des jours critiques, il énumère les différents jours où le malade meurt ou survit (3e, 5e, 7e, 14e).
Dans le texte hippocratique Aphorismes (5e section), on peut lire : « le spasme qui survient après une blessure est mortel ».Une première description complète et précise apparaît au IIe siècle apr.
dans le Traité des maladies aiguës (livre I, chapitre 6) d'Arétée de Cappadoce (médecin romain, originaire d'Anatolie centrale).
Cette description se termine ainsi :Aucun changement notable n'apparaît jusqu'à la fin du XVIIIe siècle.
Durant les guerres napoléoniennes, les premières statistiques de médecine militaire sur le tétanos font état de 12 à 13 cas de tétanos pour 1 000 blessés.Au début du XIXe siècle, le tétanos est discuté sous deux formes : le tétanos chirurgical ou traumatique (lié à une plaie), le tétanos médical ou spontané (sans plaie reconnue).
Les origines et les conditions du tétanos restent inconnues ou confuses : origine digestive, musculaire, nerveuse ?
En 1854, Simpson émet l'idée d'un poison pénétrant dans la plaie.
En effet, les manifestations du tétanos ressemblent à celles d'un empoisonnement massif à la strychnine (isolée en 1818 à partir de la noix vomique).
Les recherches s'orientent alors vers la reproduction du tétanos chez l'animal.En 1884, Antonio Carle (it) et Giorgio Rattone (it) réussissent cette transmission au lapin, en inoculant, dans le nerf sciatique, le pus d'un abcès à l'origine d'un tétanos humain.La même année, Arthur Nicolaier fait de même chez le lapin et le cobaye en inoculant, sous leur peau, des terres de rues ou de jardins.
Dans le pus des abcès provoqués, il décèle des bacilles allongés, de nature anaérobie, qu'il décrit comme l'agent spécifique du tétanos.
Il ne les retrouve pas dans le tissu nerveux, renforçant l'idée que le tétanos est dû à un poison lié à une infection bactérienne locale (toxi-infection).En 1889, Kitasato parvient à cultiver la bactérie en laboratoire, à montrer ses deux formes, végétative et sporulée.En 1890, Knud-Faber obtient la toxine par filtration du bouillon de culture.
Cette toxine tétanique, isolée et purifiée, peut alors être étudiée à la lumière des travaux menés en parallèle sur la toxine diphtérique.Toujours en 1890, Kitasato et von Behring immunisent des lapins par la toxine atténuée.
Ils montrent que ces lapins produisent des antitoxines protectrices, injectées à d'autres lapins non immunisés, elles les protègent du tétanos.
Par la suite, l'antitoxine tétanique sera obtenue en grandes quantités par l'immunisation de chevaux.
C'est le début de la sérothérapie antitétanique applicable à l'Homme, celle-ci offre une protection rapide mais de courte durée (à l'époque, 8 jours environ).Le conflit de 14-18 réalise une expérience à grande échelle, jugeant la valeur des progrès obtenus.
Au début de la guerre, les réserves de sérum étaient insuffisantes, et les chirurgiens militaires étaient divisés en querelles d'écoles sur la meilleure façon de traiter les plaies.
Au 1er trimestre du conflit, l'armée britannique enregistre 8 cas de tétanos pour 1 000 blessés.
À partir d'août 1915, l'Institut Pasteur fournit 4 000 doses de sérum par jour et 6 millions sur toute la durée du conflit.
Avec l'amélioration continue du traitement des plaies et de la disponibilité du sérum, le taux de tétanos chute à moins de 1,5 cas pour 1 000 blessés.
Quand l'armée américaine intervient en 1917, elle a l'avantage de profiter de l'expérience de ses alliés, avec un taux de 0,16 cas de tétanos pour 1 000 blessés à la fin du conflit.Toutefois, il est apparu aussi que la sérothérapie antitétanique avait des effets indésirables, parfois graves, dont la maladie sérique (réaction allergique au sérum de cheval), ce qui limitait les possibilités de répéter les injections.
Elle n'était efficace qu'effectuée rapidement, dans les 24 h après les blessures.
Un vaccin humain préventif, plus sûr et de longue durée d'action, était nécessaire.La recherche vaccinale se heurte à une difficulté : l'immunisation animale alors utilisée pour la production de sérum, n'est pas applicable à l'Homme.
Elle est trop risquée, car la toxine atténuée, chauffée et iodée, n'est pas stable, elle peut retrouver sa toxicité.
Le problème est d'obtenir une anatoxine, c'est-à-dire une toxine atténuée stable (sécurité) conservant ses propriétés immunogènes (efficacité).Pierre Descombey, Gaston Ramon, Christian Zoeller trouvent la solution durant la période 1922-1927.
La toxine atténuée doit être chauffée et formolée (formaldéhyde) pour la sécurité.
D'autre part, l'efficacité peut être améliorée par l'ajout de substances stimulant l'immunité, comme les sels d'aluminium, c'est l'adjuvant.
Enfin Ramon met au point les premières méthodes de titrage permettant de doser et mesurer la quantité et l'efficacité biologique des anatoxines.
Les premières méthodes vaccinales sont précisées : nombre de doses, intervalles de temps, périodicité, rappels, etc.À partir de 1929, en France, plusieurs types de vaccins antitétaniques sont disponibles : le vaccin simple sous forme diluée, sans adjuvant, le vaccin adsorbé, avec adjuvant, et le vaccin divalent tétanos-diphtérie.La guerre de 39-45 sera, pour les vaccins, ce qu'a été 14-18 pour les sérums, l'occasion de juger à grande échelle.
D'autant plus que les doctrines de médecine militaire, au début du conflit, sont différentes selon les belligérants.
La France, le Royaume-Uni, le Canada utilisent le vaccin adsorbé ; les États-Unis, le vaccin fluide pour l'armée de terre et le vaccin adsorbé pour la marine.
Les Britanniques font 2 doses sans rappel, les Américains 3 doses et un rappel, etc.
Les Allemands préfèrent en rester aux sérums, en réservant la vaccination aux parachutistes, seuls susceptibles d'opérer loin de leur propre service de santé.En 1942, l'armée britannique, qui compte 22 cas de tétanos depuis le début du conflit, adopte le schéma américain.
Les États-Unis compteront 12 cas de tétanos sur un peu plus de 2,7 millions de blessés durant tout le conflit (ensemble des opérations), soit un taux de 0,44 pour 100 000.
Du début de la Première Guerre mondiale à la fin de la seconde, les statistiques militaires des cas de tétanos sont passées de l'échelle sur 1 000 à l'échelle sur 100 000.
En revanche, les hôpitaux américains et britanniques qui reçoivent les blessés allemands prisonniers font état de 53 cas de tétanos sur un seul mois de l'hiver 44-45.
Durant la bataille de Normandie, les Allemands auraient eu 80 cas de tétanos, aucun chez leurs parachutistes engagés comme troupe au sol,.Après la guerre, la toxine tétanique et son mode d'action font l'objet d'une recherche fondamentale.
En 1946-1948, ce sont les premières estimations du poids moléculaire de la toxine, les travaux sur sa constitution en sous-unités et leurs structures se poursuivent au moins jusqu'en 1989.
En 1957, c'est la première étude suggérant une action de la toxine sur la neurotransmission.
En 1959, cette action s'opère par affinité avec des récepteurs spécifiques du tissu nerveux.
En 1986, le séquençage du gène de la toxine est effectué et en 2003, celui du génome complet de la bactérie Clostridium tetani.Parallèlement, les études sur l'action de la toxine à l'échelle moléculaire se poursuivent jusqu'à nos jours.
Il s'agit d'identifier et de comprendre tous les évènements biochimiques qui se succèdent en cascade à partir de sa fixation au neurone jusqu'à son mode d'action terminal.Sur le plan médical, les progrès de l'immunologie permettent de remplacer les sérums antitétaniques d'avant-guerre par leurs principes actifs purifiés, les immunoglobulines antitétaniques d'origine équine.
Elles ont une plus longue durée d'action que les premiers sérums, mais avec un risque allergique persistant.
Dans les années 1960, les premières immunoglobulines d'origine humaine sont disponibles, le risque allergique est réduit au minimum, mais elles coûtent beaucoup plus cher.
Elles s'imposeront finalement pour être la norme dans les pays développés.
Dans les années 2000, la plupart des pays en développement y accèdent progressivement, en fonction de leurs moyens et de la baisse des coûts.Enfin, à partir de 1960, les progrès de la réanimation et des soins intensifs (sédation, assistance respiratoire, soutien nutritionnel, etc.) ont permis d'abaisser la mortalité du tétanos déclaré à 20-30 % contre 80-90 % à la fin du XIXe siècle.
Mais il ne s'agit pas là d'un traitement curatif.
Il s'agit de soulager et maintenir en vie le malade, jusqu'à ce que la toxine s'épuise d'elle-même par consommation (au bout de quelques jours ou de plusieurs semaines).
Un peu comme Hippocrate, qui surveillait le passage des jours critiques.Si le tétanos de l'enfant est connu depuis l'Antiquité, le tétanos du nouveau-né est pratiquement ignoré des médecins jusqu'au XVIIIe siècle.
À l'exception d'un obscur médecin de l'Antiquité tardive, Moschion (en), qui pensait que le trismus (contraction des mâchoires) du nouveau-né était dû à une stagnation du sang dans l'ombilic.
La maladie sera connue dans les milieux populaires sous les noms de « maladie des 3-6 jours » en Chine, « maladie des 7 jours » ou « maladie des 8 jours » ailleurs.
Aujourd'hui, selon l'OMS, la maladie survient, dans 90 % des cas, entre 3 et 14 jours.Au XVIIIe siècle, l'accouchement et les soins aux nouveau-nés sortent progressivement de la sphère populaire et privée (femmes, matrones) pour entrer dans le domaine des médecins et de l'État (santé publique).
En France, les médecins des Lumières commencent à décrire une maladie des nouveau-nés apparaissant à la première semaine, et qu'ils appelaient « induration » ou « enfant gelé ».
Au début du XIXe siècle, l'idée d'une maladie de l'ombilic n'était qu'une théorie parmi des dizaines d'autres : irritation digestive, air froid, air marin, atmosphère impure, feux de cheminées, faute de la matrone, etc.
En 1818, Abraham Colles est le premier à remarquer les similitudes entre cette maladie et le tétanos.
Durant le XIXe siècle, sa mortalité de 99 % était telle que, selon Sally McMillen, « peu de parents éprouvaient le besoin d'appeler un médecin ».En 1923, Broeck et Bauer, montrent que le sérum antitétanique peut traverser le placenta.
En 1927, Ramon suggère de protéger le nouveau-né en immunisant la mère.
En 1961, Schofield et Wesbrook, étudiant la maladie en Nouvelle-Guinée, montrent qu'ils peuvent réduire la fréquence de la maladie en vaccinant les femmes enceintes.En 1989, l'OMS lance sa campagne pour l'élimination mondiale du tétanos néo-natal (voir ci-dessous).Le tétanos est en déclin dès le début du XXe siècle, sous l'influence de plusieurs facteurs :Autant de facteurs qui diminuent considérablement les risques d'exposition au tétanos, mais sans les supprimer.
De fait, dans les années 1930, le tétanos représente encore en moyenne 1 à 3 cas pour 100 000 habitants et par an, le tétanos néo-natal, lui, étant déjà en voie de quasi-disparition.L'arrivée de la vaccination généralisée, réellement appliquée à partir de 1950, accélère le processus.
En France, l’incidence du tétanos est passée de 25 cas par million d’habitants en 1946, à moins de 0,15 cas par million d’habitants au cours des années 2012 à 2017.Pour cette même période (2012-2017), 35 cas de tétanos ont été déclarés en France, dont 8 décès (létalité de 23 %).
Les cas concernent principalement des personnes âgées (71 % avaient 70 ans ou plus) et des femmes (63 %).
3 cas avaient moins de 10 ans, tous nés et vivant en métropole (2 non vaccinés et 1 vacciné de façon incomplète).
Des séquelles (difficultés motrices, complications musculaires et ostéo-articulaires) ont été signalées pour 12 patients (34 %), dont 2 des 3 enfants.
Tous les cas dont le statut vaccinal a pu être documenté étaient non ou mal vaccinés.En Europe de l’Ouest, seule l’Italie garde une incidence plus élevée que la France avec, en moyenne, une soixantaine de cas déclarés chaque année entre 2006 et 2015 (1 cas pour un million d’habitants).Le rôle de la vaccination se constate par la modification des catégories à risques.
Au début du XXe siècle, le tétanos se voyait le plus souvent chez le jeune adulte.
Depuis la vaccination, les cas de tétanos appartiennent surtout aux catégories suivantes : les personnes âgées, avec une prédominance féminine qui serait liée à l'absence des rappels du service militaire obligatoire des hommes de leur âge ; les immigrants en provenance de pays à faible politique vaccinale ; les usagers de drogue injectable, comme l'héroïne par exemple ; enfin, les personnes opposées à la vaccination et leurs enfants, pour des raisons religieuses ou socio-culturelles.En quelque sorte, le tétanos résiduel des pays développés épouse en creux les insuffisances de la couverture vaccinale,, notamment le manque de rappels.
Si le tétanos devient de plus en plus rare, sa gravité entraîne systématiquement une hospitalisation prolongée en service de réanimation, avec une létalité élevée et des séquelles fréquentes.Dans les années 1980, les décès par tétanos dans les pays en développement étaient estimés à un million par an, dont 80 % par tétanos néo-natal (défini par l'OMS comme tétanos survenant dans les 28 premiers jours de vie).
Ceci représentait six décès pour 1 000 naissances vivantes.Les pays les plus touchés se situent sur la zone équatoriale de l'Afrique-Asie.
Les cas surviennent de façon groupée dans des zones rurales, pauvres et isolées, dépourvues d'hygiène et sans accès à la vaccination, la mortalité pouvant dépasser 50 pour 1 000 naissances.En 1989, l'OMS lance son appel en faveur de l'élimination mondiale du tétanos néonatal, puis en 1993 du tétanos maternel (défini par l'OMS comme tétanos de la femme enceinte et jusqu'à six semaines de l'accouchement), les deux réunis en tétanos maternel et néo-natal (TMN).
Les moyens d'action s'articulent sur deux axes : vaccination des femmes en âge de procréer et stratégie des « trois propretés » — des mains, du cordon ombilical et de la table d'accouchement.Cela concernait 90 pays, qui se donnent comme objectif d'éliminer le TMN en tant que problème de santé publique.
L'élimination est certifiée pour un pays lorsqu'il atteint moins de un cas de TMN pour 1 000 naissances au niveau de tous les districts (définition de OMS : 3e niveau d'administration, apparemment l'équivalent du département en France).En 2002, le nombre mondial de décès est réduit à 180 000, mais ces bons résultats sont stagnants.
Il reste encore 57 pays où moins de 60 % des femmes sont vaccinées et où moins de 50 % ont accès à l'hygiène de l'accouchement.
Les difficultés sont nombreuses, malgré l'implication renforcée de l'UNICEF et d'autres organisations humanitaires.
Les entraves sont les restrictions budgétaires, les difficultés d'accès (manque d'infrastructure, conflits armés…), l'opposition à la vaccination du fait qu'elle vise les jeunes femmes (rumeurs d'un vaccin contraceptif ou stérilisant).Depuis 2013, le nombre mondial de décès est passé sous la barre des 50 000, ce qui représente une réduction de 94 % en 20 ans.
En 2017, 30 848 cas de TN sont notés dans le monde, contre un million deux décennies auparavant.En 2019, le TMN reste encore un problème de santé publique dans 12 pays que sont : Afghanistan, Angola, République centrafricaine, Guinée, Mali, Nigeria, Pakistan, Papouasie-Nouvelle-Guinée, Somalie, Soudan, Soudan du Sud et Yémen,.En 2021, ces 12 pays n'ont toujours pas atteint le niveau minimum de couverture vaccinale (deux doses), de suivi de la grossesse, et de soins aux accouchées et nouveau-nés, qui devrait être d'au moins 80 % des femmes en âge de procréer (soit 107 millions de femmes).
Les obstacles sur le chemin de l'élimination mondiale du TMN sont la fragilité et l'insuffisance des systèmes de santé, et des facteurs socio-économiques comme :La pandémie de COVID-19 perturbe la lutte contre le TMN en détournant ressources et moyens de santé (préventifs et de surveillance).
Par exemple, sur les 12 pays, seuls le Nigéria et le Pakistan ont pu fournir des données sur les pratiques de soins du cordon ombilical, tandis que l'incidence réelle du tétanos néonatal devient plus difficile à déterminer.Clostridium tetani (Bacillus tetani, ou bacille de Nicolaïer) est un bacille gram positif sporulant anaérobie strict.
C'est une bactérie tellurique ubiquitaire, plus fréquente sous les tropiques que dans les pays tempérés ou froids.
Elle peut se présenter sous deux formes : la forme végétative active et la forme sporulée inactive (Plectridium tetani).
Les deux formes se transforment l'une en l'autre, essentiellement selon la teneur en oxygène, mais aussi selon le pH, la température, et les conditions chimiques du milieu.
La forme active apparaît en anaérobie, c'est-à-dire en absence ou pauvreté d'oxygène (moins de 5 %).La forme sporulée (inactive) est très résistante, à la chaleur, à la dessiccation et aux désinfectants.
Ces spores se trouvent dans le sol (réservoir naturel de la bactérie).
Plus particulièrement dans les sols fertiles, en climat chaud et humide, riches en matières organiques comme les régions cultivées et de pâturage.
À l'abri de la lumière solaire, elles peuvent survivre pendant des années.
On peut les retrouver dans la poussière, sur les plantes (grains, fourrages, etc.), dans les selles animales et, à l'occasion, humaines.La quantité de terre nécessaire et suffisante pour détecter la bactérie a été estimée à 1 mg.
Une faible quantité de terre contaminée dans une blessure est susceptible de provoquer un tétanos.Lorsque ces spores sont avalées par un animal brouteur, elles résistent au processus de digestion, pour être rejetées à l'extérieur avec les selles.
Leur germination et leur développement éventuel dans le tube digestif (conditions d'anaérobie en fin de côlon) reste une question discutée.L'Homme entre accidentellement dans le cycle des deux formes, à l'occasion de plaies souillées.
Si les circonstances sont favorables (tissus nécrotiques, corps étrangers, etc.), il se crée dans la plaie des micro-environnements pauvres en oxygène (anaérobie, faible potentiel d’oxydo-réduction).
Les spores germent et reprennent leurs formes végétatives (bactéries pouvant libérer la toxine responsable de la maladie).
Ces bactéries ne sont pas invasives (elles ne pénètrent pas dans l'organisme, ni ne s'y développent), elles restent localisées dans la plaie.Toute effraction cutanée, même minime, contaminée par la terre, la poussière, les déjections animales peut être la porte d'entrée des spores tétaniques.
Le plus souvent, dans la moitié des cas, il s'agit de plaies accidentelles : abrasions, lacérations, brûlures, piqûres, griffures, fracture ouverte, etc.
Dans un tiers des cas, de plaies ou suppurations chroniques : ulcères de jambes, escarre dans les pays développés ou otite, infection dentaire dans les pays en développement.Tout acte, médical ou pas, qui perce la peau ou les muqueuses avec des instruments mal stérilisés est susceptible de transmettre le tétanos.
C'est particulièrement le cas des régions les plus pauvres des pays en développement (manque de moyens, ou pratiques traditionnelles) : injection, tatouages, scarifications, piercings, circoncision, excision, section du cordon ombilical, etc.
L'accouchement et l'interruption de grossesse en mauvaise conditions hygiéniques sont aussi des portes d'entrées.
Les circonstances sont innombrables, on a même décrit le tétanos par cure-dent.Dans 10-15 % des cas, on ne retrouve pas de porte d'entrée, une plaie minime est passée inaperçue.
Dans tous les cas, la présence de corps étrangers, de pus, de tissus nécrosés, favorise l'établissement des spores dans la plaie.Pour qu'un tétanos se déclare, trois conditions sont nécessaires :Depuis la plaie infectée, quand les conditions s'y prêtent, les spores prennent leur forme germinative.
La bactérie se multiplie, élaborant deux toxines : la tétanolysine, qui n'entre pas en jeu lors des manifestations de la maladie (tout au plus, rôle d'initiation locale, favorisant l'installation des bactéries) et la tétanospasmine, une puissante neurotoxine, cause directe de la maladie.La tétanospasmine est l'une des plus puissantes neurotoxines biologiques connues, avec une dose mortelle minimum de moins de 2,5 ng par kilogramme de poids, soit 175 milliardièmes de gramme pour un homme de 70 kg.
C'est l'explication de la nature non immunisante de la maladie : une quantité infime de toxine, suffisante pour provoquer la maladie, ne l'est pas pour déclencher une production d'anticorps,.
Il existe différentes tétanospamines (selon le type de clostridium tetani), mais elles sont identiques sur le plan antigénique, aussi une même antitoxine les neutralise toutes.À l'intérieur des bactéries, durant leur phase de croissance, cette toxine est synthétisée comme une chaîne polypeptidique inactive.
Elle est libérée lors de la mort de la bactérie (autolyse et éclatement des parois).
Elle est activée en se transformant en une chaîne lourde liée à une chaîne légère.
La chaîne lourde sert de moyen d'entrée et de transport dans les neurones (liaison aux récepteurs neuronaux et pénétration intracellulaire).
La chaîne légère porte les propriétés toxiques.
Pour les détails au niveau moléculaire, voir l'article détailléCette toxine est d'abord circulante, une partie diffuse dans le muscle, pour se fixer sur les jonctions neuro-musculaires au niveau des terminaisons nerveuses les plus proches.
L'autre partie emprunte la voie lymphatique et sanguine, se disséminant largement et y persister plusieurs jours, avant de pénétrer les neurones en divers sites.La toxine qui pénètre les neurones moteurs est dite toxine fixée.
En fait, elle chemine à l'intérieur du neurone, de façon rétrograde, à l'allure de 3 à 13 mm à l'heure, jusqu'au système nerveux central, en franchissant les espaces intersynaptiques.
Arrivée à destination, la chaîne légère se détache pour bloquer la neurotransmission.
Les muscles d'action opposée se désynchronisent, ce qui provoque spasmes et contractures.
En plus du système moteur, la toxine agit sur le système autonome en bloquant les réflexes sympathiques des organes internes, ce qui représente une menace vitale.L'action de la toxine dans les neurones peut persister pendant des semaines.
Son action s'épuise d'elle-même et ses effets sont réversibles.
Les mécanismes de récupération restent encore mal compris,.Toutes les espèces animales sont susceptibles de présenter un tétanos, mais de façon très variable selon les espèces.
Le tétanos est pratiquement inconnu chez les animaux à sang froid (poïkilothermes) qui sont les plus résistants.
La grenouille, dans un environnement froid (de moins de 18 °C), est insensible à la toxine tétanique, mais devient susceptible à plus de 27 °C.En pratique, le tétanos existe surtout chez les mammifères, mais toujours avec une sensibilité variable selon les espèces.
Les carnivores sont les plus résistants.
Chez le chien le tétanos est lié le plus souvent à une plaie des pattes antérieures, avec contracture des muscles faciaux, difficultés respiratoires et hyperthermie.
Les jeunes chiots présentent une forme plus sévère que les chiens les plus âgés.
Près de la moitié des chiens survivants gardent des troubles du sommeil (spasmes musculaires, aboiement).Chez le chat, le tétanos se présente sous une forme locale et modérée (raideur en extension d'une patte), l'animal récupérant en quelques semaines,.Le cheval et les primates sont les plus sensibles.
Le taux de mortalité peut aller jusqu'à plus de 80 %.
Les animaux survivants ont une convalescence de deux à six semaines.
Aucune immunité ne se développe.Le tétanos est commun chez le cheval non vacciné : les oreilles se dressent, les naseaux se dilatent, on observe une chute de la 3e paupière.
L’animal transpire, il a des difficultés à avancer, à tourner et à reculer.
Les spasmes généralisés s'accompagnent de problèmes cardiovasculaires et respiratoires.
Dans les formes suraigües, la mort survient en un ou deux jours, sinon en une à trois semaines.
Dans les formes modérées, le tétanos se limite à des contractures musculaires locales qui régressent en quelques semaines.
Dans une série de 176 cas de tétanos, survenus chez le cheval en Europe de 2000 à 2014, le taux de mortalité était de 68,2 %.Les pratiques d'élevage peuvent être source de tétanos (injections vétérinaires, ferrage ou écornage des sabots, pose d'anneaux, castrations, etc.) si elles ne sont pas faites dans des conditions d'asepsie.
Chez les moutons, les chèvres et les porcs : le tétanos se manifeste par des troubles de la marche, une chute et un opisthotonos.
Le tétanos est plus fréquent chez les agneaux et les porcelets (contamination lors de la section du cordon ombilical).Le tétanos expérimental de laboratoire touche rat, souris, cobaye et lapin.
Les différences de sensibilité seraient dues à des variations de structure moléculaire des récepteurs nerveux, la toxine tétanique s'adaptant au mieux à ceux de l'Homme et du cheval.Le diagnostic du tétanos est uniquement clinique.
Les examens biologiques et complémentaires sont inutiles (aucune aide au diagnostic positif), sauf dans quelques cas douteux nécessitant un diagnostic différentiel.La durée d'incubation de la maladie varie de 3 jours à 3 semaines (médiane 7 à 8 jours).
Des durées plus courtes ou plus longues sont possibles.
La durée d'incubation dépend de la situation du foyer infectieux initial par rapport au système nerveux central (l'incubation est plus longue pour une plaie au pied que pour une plaie à la tête).Cette durée d'incubation est une indication de pronostic.
Plus l'incubation est courte (moins de 7 jours), plus le tétanos sera sévère.
Au-delà de 10 jours la forme sera d'autant plus modérée.
Il existe trois formes de tétanos : le tétanos généralisé (touchant tout le corps, forme la plus grave, se produisant dans 80 % des cas), le tétanos localisé à un membre ou à un groupe musculaire, et le tétanos localisé à la tête (tétanos céphalique, atteinte des nerfs crâniens).Le premier signe est le spasme des muscles masticateurs, le trismus, ou l'impossibilité d'ouvrir la bouche par contraction invincible des mâchoires.
Le test de l'abaisse-langue peut être utile dans les formes frustes ou débutantes : la paroi postérieure du pharynx est touchée avec un abaisse-langue.
Chez l'individu non atteint, ceci déclenche un réflexe nauséeux.
L'individu atteint, lui, va mordre l'abaisse-langue sans chercher à le recracher.
Le trismus s'accompagne du « rictus sardonique », grimace caractéristique par contraction des muscles de la face.
Chez les personnes âgées, le premier signe peut être une difficulté à avaler (dysphagie).Puis la maladie se généralise selon un modèle descendant pour s'étendre à d'autres muscles : cou, thorax, dos, abdomen et extrémités.
Des spasmes continus peuvent aboutir à l'opisthotonos, réalisant une hyper-extension de la nuque et du dos par contracture des muscles paravertébraux.
Viennent ensuite les spasmes généralisés (membres supérieurs en flexion, membres inférieurs en extension), déclenchés par n'importe quel stimulus (bruit, lumière, toucher) ou survenant spontanément dans les formes graves.
Avant l'ère de l'anesthésie-réanimation, les spasmes étaient extrêmement douloureux, le malade restant conscient,.La violence des spasmes peut se compliquer par des fractures, luxations, rhabdomyolyse.
La contracture des sphincters peut entraîner une rétention aiguë d'urine et/ou fécale.
Surinfection bactérienne, pneumonie d'inhalation, apparition d'escarres, embolie pulmonaire, déshydratation ou dénutrition surviennent surtout chez les sujets âgés ou fragilisés.
La mort peut survenir par arrêt respiratoire (spasme de la glotte ou des muscles respiratoires) ou par atteinte des fonctions végétatives (hyper/hypothermie, hypertension artérielle/hypotension, arythmies cardiaques).La guérison s'obtient après quelques jours ou plusieurs semaines.Le tétanos localisé est très rare chez les humains.
Les spasmes restent localisés à un groupe musculaire proche de la blessure initiale et peuvent durer plusieurs semaines avant de disparaître progressivement.
L'extension à un tétanos généralisé est possible, mais de bon pronostic (moins de 1 % de mortalité).Le tétanos céphalique fait suite à une infection ou plaie de la tête (notamment près de l'orbite ou sur le territoire du nerf facial).
L'incubation est courte, l'extension à une forme généralisée est possible.Il est dû à l'infection de la section du cordon ombilical.
Il survient, dans 90 % des cas, du 3e au 14e jour de vie, principalement au 6e-8e jour.
C'est un trait distinctif, car les autres causes de mortalité du nouveau-né apparaissent dès les deux premiers jours.
Après une phase de deux jours au moins, où le nouveau-né tète et se comporte normalement, surviennent rapidement des pleurs incessants et une incapacité de téter, puis les spasmes se généralisent.
Souvent, ce qui se déroule en jours chez l'adulte, se déroule en heures chez le nouveau-né,.Les survivants d'un tétanos néo-natal peuvent présenter des séquelles neurologiques : paralysie cérébrale, troubles psychomoteurs, troubles du comportement.Un trismus peut avoir de nombreuses causes : angine, abcès, troubles de l'articulation temporo-mandibulaire, infection des parotides, trouble neurologique autre que le tétanos, etc.Le tétanos céphalique peut être confondu au début avec une paralysie faciale ou une névralgie du trijumeau.La rage se distingue du tétanos par ses hallucinations, l'hydrophobie, agitation ou stupeur, et la notion de morsure animale.Des situations métaboliques et toxiques peuvent ressembler au tétanos : la tétanie hypocalcémique (mais il n'y a pas de trismus), l'empoisonnement par la strychnine, l'intoxication aux phénothiazines (présence du toxique dans l'estomac, le sang ou les urines, selon le cas).Chez les patients hystériques, l'observation un peu prolongée note des contractions cloniques (en secousses) ou des relâchements musculaires, plutôt que des spasmes toniques persistants (contractures permanentes).L'expérience acquise par la médecine militaire au cours de la Seconde Guerre mondiale (voir l'historique) a permis de corriger et préciser les meilleures politiques vaccinales de chaque pays.
À partir de 1965, l'OMS émet les premières recommandations internationales du vaccin antitétanique.
D'abord les standards internationaux du produit vaccin (composition, formulation, etc.), puis ceux de la vaccination elle-même (doses, rappels, etc.).
Les standards du produit ont été établis en 1965, et révisés en 1981 et 2000.
Ces recommandations s'appliquent aux producteurs (privés ou publics), et en tant qu'utilisateurs, aux gouvernements et aux agences de l'ONU, comme l'UNICEF.Les vaccins qui satisfont aux critères OMS sont dits « pré-qualifiés ».
Chaque pays reconnaît un ou plusieurs « préqualifiés » pour les qualifier à son propre usage.
Ces recommandations ne sont pas contraignantes, un pays comme les États-Unis peut imposer des critères plus stricts que ceux de l'OMS.
Des pays en développement ont des difficultés à atteindre le minimum requis.
Ainsi, dans les années 1990, il y avait 63 producteurs de vaccins répartis dans 42 pays, 22 producteurs locaux ne répondaient pas aux critères.
En 2007, les producteurs fournissant les vaccin antitétaniques « pré-qualifiés » sont une douzaine, les deux premiers étant Sanofi Pasteur et GlaxoSmithKline.L'OMS recommande un calendrier de vaccination antitétanique durant l'enfance de 5 doses.
Les trois premières avant l'âge de 12 mois, plus deux rappels (entre 4 et 7 ans, entre 12 et 15 ans).
Une 6e dose est recommandé chez le jeune adulte.
Ce calendrier est appliqué de diverses façons selon les pays, selon leur situation épidémiologique, leur histoire administrative et économique.Ainsi la France a eu longtemps un calendrier de 6 doses durant l'enfance, plus un rappel tous les dix ans chez l'adulte.
Depuis 2013, elle s'est alignée sur les recommandations de l'OMS avec 5 doses chez l'enfant.
Les rappels chez l'adulte se faisant à l'âge de 25, 45 et 65 ans, puis tous les 10 ans.Le vaccin antitétanique est considéré comme l'un des plus efficaces.
L'efficacité sérologique (capacité à induire des anticorps protecteurs) est proche de 100 %, l'efficacité clinique et/ou de terrain (capacité à réduire l'incidence de la maladie) se situe entre 80 et 100 %.Toutefois ces évaluations sont atténuées par deux sujets notables.
Le premier concerne des échecs vaccinaux signalés lors des campagnes contre le tétanos néonatal dans les années 1990 au Bangladesh, où l'efficacité a chuté à moins de 50 %.
Après discussion sur des causes administratives (défaut d'organisation) ou médicales (mauvais transfert des anticorps à travers le placenta, lié au paludisme ou au SIDA),, c'est la faible activité du vaccin, d'origine locale, qui a été mis en cause.Le second concerne la question du « seuil protecteur », c'est-à-dire le taux d'anticorps nécessaire et suffisant pour garantir une protection.
Celui-ci est obtenu à partir de données animales (souris, cobaye) extrapolées à l'Homme.
À ces tests in vivo, s'ajoutent des tests in vitro (neutralisation, ELISA standards ou modifiés).
Le « seuil protecteur » est une convention, établie par consensus, censé répondre à toutes les situations.
Toutefois, des cas exceptionnels de tétanos chez des personnes correctement immunisées (au-dessus du seuil protecteur) ont été documentés.
Un tel risque est estimé à 4 pour 100 millions.La durée de l'immunité (après le 2e rappel) était évaluée en moyenne à 10 ans (95 % des sujets protégés à 5 ans, 91 % à 10 ans, 60 % après 15 ans).
Des études plus récentes suggèrent des durées beaucoup plus longues, avec une demi-vie des anticorps tétaniques de 11 ans, soit de 20 à 30 ans.Le vaccin antitétanique est aussi considéré comme très sûr.
Le plus souvent, il s'agit de manifestations locales mineures (douleur, rougeur transitoires).
La fréquence et la gravité des réactions locales et générales augmentent avec l'âge et le nombre de rappels reçus.
Les réactions générales bénignes (fièvre, douleur) apparaissent dans moins de 1 % des cas.Les manifestations graves sont très rares, ce sont des réactions allergiques : anaphylaxie (1 à 6 cas par million de doses administrées), phénomène d'Arthus (réactions locales survenant chez des sujets hyperimmunisés), névrite brachiale (5 à 10 cas par million de doses).Aucun lien n'a été trouvé avec le syndrome de Guillain-Barré, après une dizaine d'années de surveillance.L'adjuvant aluminium, qui se retrouve dans de nombreux autres vaccins inactivés, peut entraîner une lésion histologique locale dite myofasciite à macrophages, mais le fait qu'elle puisse être la cause d'un ensemble de troubles non spécifiques reste controversé.
Des associations de patients militent pour cette reconnaissance.L'objectif est de supprimer toute source potentielle de toxines.
Selon l'importance de la plaie, on procède à sa mise à plat, ablation des corps étrangers, nettoyage et lavage, débridement (enlèvement des tissus morts), désinfection et parage.
L'antibiothérapie n'est pas systématique, elle se fait en cas de plaie souillée, vue tardivement, avec délabrement important.
L'évaluation de l'état immunitaire (à jour ou pas de ses vaccinations) se fait sur document médical ou par un test rapide (dosage des anticorps antitétaniques).En situation de plaie mineure, propre, la vaccination est proposée aux personnes non à jour.En situation de plaie majeure ou à risques (plaie étendue, pénétrante, avec corps étranger, vue tardivement), les personnes non à jour sont vaccinées dans un bras, et dans l'autre bras, immunoglobulines anti-tétaniques (250 UI IM en dose unique) dites aussi gammaglobulines.
Elles assurent une protection immédiate (en 2 ou 3 jours, ce qui est suffisant par rapport à la durée d'incubation) et persistant plus de 4 semaines, le vaccin prenant le relais pour une protection différée mais de longue durée.
Il s'agit là des recommandations françaises.
Les conduites à tenir peuvent varier selon les pays, mais les principes de bases restent les mêmes.Depuis les années 1960, les gammaglobulines anti-tétaniques d'origine équine sont remplacées par des immunoglobulines d'origine humaine.
Il s'agit d'un médicament dérivé du sang, obtenu à partir de fractionnement du plasma de sujets hyperimmunisés,.Pour prévenir le tétanos chez le nouveau-né, la vaccination maternelle doit être à jour pour permettre une immunisation passive par voie placentaire.
Les instruments et autres produits pour la section du cordon ombilical doivent être stérilisés et l'antisepsie doit être respectée pour les soins du cordon.En France, certains services d'urgence utilisent un test rapide de détection du seuil des anticorps pour une aide à la décision, dans le but d'éviter une prescription inutile (et coûteuse) de gammaglobulines.
Cette procédure est en cours d'évaluation et, en 2016, elle n'a pas été intégrée dans les recommandations, ni généralisée à tous les services.
Cette décision reste de la seule responsabilité des médecins seniors des urgences.Le traitement du tétanos déclaré a plusieurs objectifs : 1) supprimer la production de toxine si cela n'a pas été déjà fait (traitement des plaies), 2) neutraliser la toxine encore circulante, 3) contrôler les spasmes et soutenir le patient durant toute la durée de la maladie.L’antibiothérapie vise à réduire la prolifération bactérienne au niveau de la plaie.
La pénicilline G, le métronidazole ou la doxycycline sont les plus utilisés.
Le métronidazole serait la meilleure option, mais son avantage ne serait que théorique (études contradictoires).L’administration d’immunoglobuline anti-toxine tétanique (sérothérapie) permet de neutraliser la toxine circulante qui n’a pas encore pénétré les neurones ; la posologie optimale et la meilleure voie d'administration (intramusculaire ou intrathécale) restent en discussion,,.La clé du traitement est le contrôle des spasmes.
Le patient doit d'abord être placé dans un environnement calme et sans lumière pour limiter au maximum les stimuli susceptibles de déclencher des séries de spasmes, il faut aussi éviter autant que possible de le manipuler.
Pour le versant pharmacologique, les produits standards actuels sont les benzodiazépines : diazépam (Valium), midazolam.
Ils ont l'avantage d'avoir des effets combinés : myorelaxant, anticonvulsif, anxiolytique et sédatif.
D'autres produits peuvent être aussi utiles contre les spasmes, comme le sulfate de magnésium intraveineux, ou le baclofène en intrathécal.Dans les formes graves ou prolongées, une ventilation mécanique peut être nécessaire, avec curarisation, intubation, voire trachéotomie.
De même, il faut assurer l'hydratation et la nutrition (sonde naso-gastrique ou tube de gastrotomie).
La maladie tétanos provoque une forte demande énergétique (contractions musculaires, transpiration) avec catabolisme accéléré.La toxine a aussi des effets, difficiles à traiter, sur le système végétatif.
Les bêta-bloquants, la clonidine, la morphine sont utilisés.
Dans tous les cas, il faut prévenir toutes les complications inhérentes à une réanimation prolongée : infections nosocomiales, complications cardiovasculaires (thromboses, embolies…), ulcères de décubitus, etc.La vitamine C en intraveineux pourrait réduire la mortalité chez l'animal, voire chez l'homme, mais cela n'a pas été confirmé, ce qui en fait une mesure qui ne peut être recommandée ou qui est difficile à commenter.Du point de vue de la médecine fondée sur les faits (EBM evidence-based medicine), il est difficile de juger les différentes modalités de traitement, pour des raisons logistiques et éthiques (on ne peut pas donner de placebo à un tétanique).
Toutefois, c'est bien aux progrès des soins intensifs que l'on doit la réduction notable de la mortalité des tétanos déclarés.
Les lymphocytes B à mémoires dérivent des lymphocytes B. Après reconnaissance des antigènes par les lymphocytes B (lors de la réponse immunitaire primaire), certains se différencient en lymphocytes B mémoires et d'autre en plasmocytes.Les lymphocytes B à mémoires ont pour rôle de mémoriser les propriétés de l'antigène les ayant activés, afin de créer une réponse immunitaire plus rapide, plus longue, plus intense et plus spécifique dans le cas d'une seconde infection par ce même antigène (réponse immunitaire secondaire).
De plus, les lymphocytes B à mémoires ont une durée de vie beaucoup plus longue que les plasmocytes.C'est sur le principe de cette mémoire immunitaire que les vaccins sont réalisés.
Mais le rôle de ces cellules n'est toutefois pas clair, car leur nombre ne semble pas varier au cours du temps, contrairement au taux d'anticorps spécifiques.Cette caractéristique de la réponse immunitaire spécifique a été reconnue il y a 2 400 ans par l'historien grec Thucydide d'Athènes qui remarqua que « nul ne souffrait de la peste à deux reprises ».Dans la moelle osseuse, les précurseurs des lymphocytes se différencient en lymphocytes B immuno-compétents qui expriment des IgD et IgM.
Ils peuvent alors reconnaître leur antigène spécifique par leur immunoglobuline (Ig) de membrane, également appelé récepteur des cellules B, et participer à la réponse immunitaire dite à médiation humorale.
Si l'antigène est T-dépendant, alors les lymphocytes B activés coopèrent avec les lymphocytes T auxiliaires dans les organes lymphoïdes secondaires.
Il se forme alors un centre germinatif au sein duquel ils subissent la maturation d'affinité et la commutation de classe leur permettant de produire des immunoglobulines A, E ou G. Ils se différencient ensuite en plasmocytes à courte durée de vie, plasmocytes à longue durée de vie ou lymphocytes B mémoire.Les lymphocytes B mémoires ont déjà subi le processus de maturation d'affinité et la commutation de classe, ce qui se traduit par la présence de mutations somatiques sur les gènes codant les immunoglobulines.Parmi ces lymphocytes B mémoires, on trouve de nombreuses sous-populations caractérisées par le type d'Ig synthétisée (IgA, IgE, IgG ou IgM) et le niveau d'expression de molécules de surface (CD27 notamment, mais aussi FCRL4).
Cependant, le rôle spécifique de chaque sous-population dans la mémoire immunitaire est encore débattu.On estime que les lymphocytes B mémoires peuvent persister plus de 50 ans chez l’homme et ceci sans nouvelle exposition à leur antigène spécifique.
Cependant les mécanismes demeurent encore mal connus : ils reposeraient notamment sur une modification de l'expression génique provoquant une augmentation de l’expression de molécules anti-apoptotiques.Les lymphocytes B mémoires sont capables de proliférer et se différencier très rapidement en plasmocytes producteurs d’anticorps à la suite d'une deuxième exposition à leur antigène spécifique.
Cette capacité à réagir plus rapidement avec un très court temps de latence est liée à différents mécanismes :La mémoire du système immunitaire est utilisée à des fins médicales : la vaccination qui permet à l'organisme d'acquérir préventivement et durablement une mémoire immunitaire relative à un micro-organisme déterminé.
Ceci se fait grâce à l'injection d'un antigène sous une forme non pathogène mais provoquant une réaction immunitaire avec mise en place d'une réponse mémoire protectrice.
La plupart des vaccins induisent une réponse anticorps : il y alors une production de lymphocytes B mémoires qui en cas d'une deuxième infection par l'antigène se réactiveront rapidement et protègeront l'organisme de l'infection.
En médecine, une injection est une méthode instrumentale utilisée pour introduire dans l'organisme une substance à visée thérapeutique ou diagnostique.
Cet acte médical se fait au moyen d'une voie d'administration constituée d'une aiguille creuse ou d'un cathéter mis en place par effraction plus ou moins profonde du revêtement externe du corps, c'est-à-dire la peau le plus souvent.Ce dispositif constitue une voie parentérale, ce qui signifie que le produit injecté dans le corps ne passe pas par les intestins, permettant une biodisponibilité de 100 %.
En outre, l'injection constitue la principale méthode d'administration de médicament pour un patient incapable de prendre un traitement par voie simple (trouble de conscience, trouble de déglutition, trouble du jugement avec risque élevé pour le patient ou son environnement).L'inconvénient principal de ce type de voie d'abord est le risque d'infection ou moins souvent d'hémorragie.
Il peut être également source de douleur, ecchymose ou hématome.
Par ailleurs, il existe une phobie liée aux injections, appelée trypanophobie.Par voie générale, l'injection peut être réalisée par plusieurs voies qui permettent la diffusion de la substance par sa circulation dans le sang :L'injection peut également se faire par voie locale dans un quelconque compartiment du corps, sans qu'il y ait de diffusion à l'ensemble de l'organisme.
Par exemple, en intradermique, l'injection est faite dans la peau, entre l'épiderme et le derme : l'intradermoréaction tuberculinique.
Rotavirus est un genre de virus de la famille des Reoviridae.
Le virus a été identifié en 1973 par Ruth Bishop à Melbourne.Les rotavirus sont la première cause de gastro-entérites graves chez les nourrissons et les jeunes enfants dans le monde ; Ils semblent (chez la souris au moins) pouvoir infecter les glandes salivaires, la salive devenant alors un agent infectieux ; avec les norovirus, ils causent des gastro-entérites chez environ 300 millions de nouveau-nés et jeunes enfants par an.Les rotavirus sont la première cause de diarrhée aiguë sévère du jeune enfant dans le monde,.
L'OMS coordonne un suivi épidémiologique mondial.Presque tous les enfants sont infectés par un rotavirus au cours des cinq premières années de leur vie.
Cette infection peut rester asymptomatique ou entraîner une gastro-entérite (GEI, gastro-entérite infantile), dont les rotavirus sont la principale cause.
L'infection est souvent asymptomatique chez l'adulte.Environ 500 000 enfants de moins de 5 ans meurent de diarrhée à rotavirus chaque année, à plus de 85 % dans les pays à faible revenu d'Afrique et d'Asie.Depuis 2001, l’OMS a mis en place un réseau de surveillance des rotavirus (réseaux régionaux de sentinelles en milieu hospitalier dans 35 pays des six régions de l'OMS), qui a montré que près de 40 % des hospitalisations pour diarrhée de l’enfant de moins de 5 ans dans le monde sont dues à des rotavirus (souches G1, G2, G3, G4 et G9 le plus souvent, avec une répartition des souches variant selon les régions), ceci pour 62 584 échantillons de selles analysés.
Pour ces mêmes échantillons (non nécessairement représentatifs de la réalité mondiale), pour 4 936 enfants testés positifs au rotavirus de 2001 dans les pays suivis, 325 étaient en Afrique, 388 en Amérique, 323 en Europe, 1 290 en Méditerranée orientale, et 2 610 en Asie du Sud-Est et Pacifique occidental.Les souches varient selon les pays ou les régions biogéographiques.Dans les pays industrialisés, les infections à rotavirus représentent 15 à 50 % des cas de gastro-entérites ; bien que ces infections soient parfois sévères, la mortalité associée à celles-ci reste faible.En France, près de 300 000 épisodes annuels seraient décomptés chez les enfants de moins de cinq ans avec une dizaine de décès.
Chaque année, 155 000 consultations en médecine générale, 30 000 recours aux urgences hospitalières et 14 000 hospitalisations sont dues aux Rotavirus.
Son coût annuel est estimé à environ 28 millions d'euros.
Lors du pic de l'épidémie hivernale 2005–2006, on estime que 1 850 000 personnes ont consulté leur médecin généraliste en 8 semaines pour une gastro-entérite ; l'incidence a été de 367 cas pour 100 000 habitants (le seuil épidémique étant fixé à 260 cas pour 100 000 habitants).Il s'agit donc d'un important problème de santé publique.
D'autant plus que chaque année, l'épidémie de gastro-entérite à Rotavirus concorde souvent avec les épidémies de bronchiolite et de grippe, pouvant mettre en difficulté les systèmes de soins pédiatriques.On rencontre des gastro-entérites à Rotavirus lors d'épidémies hivernales, mais il existe également des cas  sporadiques tout au long de l'année.Ce sont des virus non enveloppés de structure icosaédrique et à ARN double brin (bicaténaire).
En microscopie électronique, les virions de 60 à 80 nm de diamètre ont l'aspect d'une roue, d'où leur nom.
Leur capside est formée de trois couches de protéines.Leur génome est constitué de onze segments codant douze protéines.
Sept groupes antigéniques ont été identifiés.
La protéine VP6 de la couche intermédiaire de la capside détermine les sérogroupes, A à G. Trois d'entre eux (A, B et C) infectent les humains, majoritairement le groupe A.
Les protéines de la couche externe, VP4 et VP7, induisent quant à elles, la production d'anticorps neutralisants.
La couche interne est formée par VP2, et les protéines VP1 et VP3 sont associées au génome.La voie de transmission est féco-orale directe ou indirecte, essentiellement interhumaine.
Le virus est résistant dans le milieu extérieur pendant des mois entre 4 °C à 20 °C.La dose pathogène est estimée à environ 10 à 100 particules virales.
Une personne avec une diarrhée à Rotavirus excrète un grand nombre de virus (108 - 1010 particules/ml de selles) pendant environ une dizaine de jours, les doses infectieuses peuvent rapidement être acquises par les mains contaminées, les objets, les aliments, l'eau).
L'excrétion asymptomatique (sans signe clinique) est possible et peut jouer un rôle dans la persistance de cette maladie.Très résistants au pH acide de l'estomac et aux enzymes digestives (lipases et protéases), ils infectent les cellules épithéliales matures de la muqueuse des villosités de l'intestin grêle (entérocytes).
Ils les détruisent partiellement, entraînant un raccourcissement des villosités, laissant la place à des entérocytes immatures avec une diminution de l'activité enzymatique.Une protéine non structurelle (NSP4) semblerait jouer un rôle dans la pathogénie du virus et pourrait agir comme une véritable entérotoxine virale.Les virus sont ainsi « absorbés » par les cellules épithéliales digestives par endocytose dans une vésicule appelée endosome.
Il semble que les protéines de la couche extérieure (VP7 et VP4) puissent rompre la membrane de l'endosome, créant ainsi un gradient de concentration en calcium.
Cela facilite la fragmentation de la protéine VP7, ne laissant autour de l'ARN viral que la couche composée des protéines VP2 et VP6.L'ARN polymérase va permettre la transcription de l'ARNm viral.
Cette action est réalisée de façon plus aisée dans l'enveloppe protéinique du virus car l'environnement aqueux des cellules hôtes ralentit de façon significative le détachement des deux brins d'ARN, phase initiale de la synthèse de l'ARNm).Le fait que l'ARN viral reste entouré, à ce stade, d'une capside est également utile pour déjouer les réponses immunitaires de l'hôte, réponses déclenchées par la présence d'un double-brin d'ARN.Au cours de l'infection, le rotavirus va donc produire un ARN messager à la fois pour leur traduction en protéines, mais également pour la réplication de son génome.
La plupart des protéines du rotavirus vont s'accumuler dans des structures appelées viroplasmes (structures cytoplasmiques formées au cours de l’infection) où l'ARN est répliqué.L'infection est immunogène, protégeant d'une nouvelle infestation.Des encéphalites peuvent compliquer ces gastro-entérites.
Leur mécanisme est encore discuté.Les rotavirus entraînent une gastro-entérite.Après une période d'incubation allant de quelques heures à quelques jours (en général 24 à 72 heures), des selles fréquentes et liquides apparaissent soudainement.Le virus pouvant atteindre le foie, ces selles peuvent être claires et accompagnées d'urines foncées.La fièvre, généralement peu élevée, s'accompagne parfois de vomissements, surtout chez les nourrissons.
La guérison complète survient après 4 à 7 jours.Cependant, une diarrhée sévère sans réhydratation adaptée (en eau et électrolytes par un soluté de réhydratation orale) peut entraîner le décès.
L'association à d'autres pathogènes du système digestif peut jouer un rôle dans la sévérité de la maladie.Les jeunes enfants, les prématurés, les personnes âgées et les sujets immunodéprimés sont particulièrement enclins à développer des symptômes plus sévères.La mise en culture du virus (surtout d'origine humaine) est difficile car la multiplication du virus nécessite la présence de trypsine qui est incompatible avec l'utilisation de serum pour la croissance des cellules.La recherche d'antigènes viraux se fait le plus souvent par la technique ELISA (de l'anglais « Enzyme-Linked Immuno Sorbent Assay »).
La technique de référence consiste à rechercher les particules virales en microscopie électronique mais n'est pas utilisée en pratique routinière de laboratoire.Le diagnostic sérologique par recherche d'anticorps n'est pas utilisé.Non utilisée en routine, elle consiste en une amplification des acides nucléiques par RT-PCR.Ils sont représentés par :Il n'existe pas d'agent antiviral spécifique.Le traitement symptomatique vise à éviter la déshydratation par une réhydratation précoce, le plus souvent orale à l'aide de solutions glycoélectrolytiques.Depuis le 28 novembre 2013, le Haut Conseil de la santé publique recommande la vaccination contre les rotavirus des nourrissons âgés de moins de 6 mois selon un schéma vaccinal à 2 doses (2 et 3 mois de vie) pour le vaccin monovalent et à 3 doses (2, 3 et 4 mois de vie) pour le vaccin pentavalent.
Cette nouvelle recommandation va à l’encontre des avis publiés par l’organisme indépendant en 2006 et en 2010.L'évaluation de l'effet de la vaccination dans des pays développés est très encourageante.Un premier vaccin a été développé en 1983 mais s'est révélé assez peu efficace en pratique courante dans les pays du tiers monde.Un second vaccin oral anti-rotavirus, le Rotashield, a été breveté en 1991 et homologué en 1998 et a permis l’administration d’environ 1,5 million de doses avant l’interruption de sa commercialisation à la suite d'une recommandation du CDC à Atlanta : quelques cas d’occlusions intestinales fatales par invagination intestinale avaient été associés à la vaccination anti-rotavirus.
Ce vaccin a été élaboré à partir d’une souche de rotavirus du singe Rhésus recombinée par co-infection avec trois souches de rotavirus humain.
Les rotavirus sélectionnés pour l’élaboration du vaccin possèdent dix gènes du rotavirus de singe rhésus et un gène d’une des trois souches de rotavirus humain codant la protéine VP7.
Ce vaccin est efficace contre les trois sérotypes de rotavirus humain.Depuis 2004, deux nouveaux vaccins (à virus actifs)  sont commercialisés : le Rotateq du laboratoire Merck et le Rotarix du laboratoire GlaxoSmithKline.
Administrés par voie orale, ils sont indiqués dans l’immunisation active des nourrissons à partir de six semaines.
Le schéma de vaccination comporte :Ces deux vaccins autorisés et maintenant utilisés en routine dans onze pays (dont l'Australie) ont montré une efficacité de 8 à 98 %, selon les essais faits en Amérique et Europe.
Le vaccin semble agir davantage sur la gravité de l'infection que sur son incidence.
Dans plusieurs pays pauvres, ils diminuent substantiellement la proportion des diarrhées graves et la mortalité de ces dernières,.
La diffusion de ces vaccins dans ce type de pays est cependant potentiellement limitée par son coût important, par la nécessité de préserver la chaîne du froid dans le transport du vaccin et par la fenêtre vaccinale relativement étroite (nourrissons de moins de deux semaines).
Les deux vaccins comportent cependant un risque très faible d'occlusion intestinale par invagination intestinale, (un à cinq cas pour 100,000 vaccinations).Le Rotavac a été développé en Inde et utilisé dans ce pays.
Administré en trois injections, il ne semble pas se compliquer d'invagination intestinale.En France, en 2012, les formules de vaccins contre la gastro-entérite à rotavirus (Rotarix, Rotateq) ne sont pas remboursés par la Sécurité sociale.
Depuis le 28 novembre 2013, le Haut Conseil de la santé publique (HCSP) recommande la vaccination contre les rotavirus des nourrissons âgés de moins de six mois selon un schéma vaccinal à deux doses (deux et trois mois de vie) pour le vaccin monovalent et à trois doses (2, 3 et 4 mois de vie) pour le vaccin pentavalent.
Cette nouvelle recommandation va à l’encontre des avis publiés par l’organisme indépendant en 2006 et en 2010.« La notification d’effets indésirables graves y compris ayant pu entraîner la mort » conduit le HCSP à suspendre sa recommandation le 21 avril 2015.Le CSH, Conseil Supérieur d'Hygiène belge recommandait, en février 2007, la vaccination contre le rotavirus chez tous les nourrissons à partir de l'âge de deux mois ; aucune dose de vaccin ne sera administrée au-delà de l'âge de six mois vu le risque accru d'invagination intestinale observé avec un précédent vaccin contre le rotavirus chez les enfants de plus de six mois.
Le vaccin y est remboursé depuis le 1er novembre 2006.La vaccination contre les gastro-entérites à rotavirus prévue pour les nourrissons de moins de 16 semaines, ne protège pas les autres populations vulnérables : immunodéprimés, personnes âgées, etc.
Des vaccins contre le virus Ebola sont développés depuis les années 1980, mais leur emploi se heurte encore, quarante ans plus tard, à différents obstacles scientifiques et techniques.Le virus Ebola est un virus enveloppé à ARN simple brin de polarité négative appartenant à la famille des Filoviridae.
Il cause des fièvres hémorragiques souvent mortelles, principalement dans certaines régions d’Afrique.
Il infecte principalement les primates non humains et humains et pourrait éventuellement être utilisé dans des actes de bioterrorisme.
Un vaccin rapidement actif contre ce virus est donc activement recherché,, qui doit encore franchir plusieurs obstacles scientifiques et techniques.
La campagne vaccinale de 2017 se tenant au Libéria est entrée en phase II, après les résultats encourageants de la phase I.Les épidémies successives de fièvre Ebola peinent à être maîtrisées et sont sources de coûts humains, sanitaires et socioéconomiques élevés.
Ceux-ci sont plus importants que pour d’autres types de fièvres hémorragiques souvent mortelles, causées par des virus semblables au virus Ebola comme le virus de Marburg et le virus de Lassa.
Il n’existe aucun traitement antiviral ni de prophylaxie contre la maladie à virus Ebola,.
Les traitements visent plutôt à diminuer les symptômes engendrés par ce virus et à améliorer la qualité de vie du patient.
Des traitements symptomatiques sont administrés pour les cas graves qui doivent être réhydratés afin de maintenir les fonctions rénales et l’équilibre électrolytique.
Ce traitement permet de mieux combattre l’infection et l’état de choc.
Ce virus comme beaucoup d'autres pourrait faire l'objet d'usages bioterroristes,.
Ceci a été un argument de plus en faveur de la recherche d'un vaccin.En 1980, un vaccin à base de virus inactivé a été efficace chez le cobaye, mais non chez les primates non humains, ce qui a retardé les essais sur les humains (les primates non humains ont un système immunitaire très semblable à celui de l’humain).
Des vaccins utilisant des protéines recombinantes ont été essayés par la suite, mais sans résultats.En 1997, des chercheurs testent un vaccin qui semblait immuniser des cochons d’Inde.
Ce groupe de Howard Hughes Medical Institute avait injecté un vaccin ADN dans les muscles des cobayes.
Les animaux ont été protégés de l’infection après avoir été infectés par le virus à deux reprises, soit deux et quatre mois après l’immunisation.
En 2000, une équipe de Vaccine Research Center, National Institute of Health et une équipe de Special Pathogens Branch, Centers for Disease Control and Prevention, ont concocté un vaccin générant une immunité tant cellulaire qu’humorale chez les macaques cynomolgus.
Infectés par une forte dose du virus Ebola Zaïre de 1976, les animaux vaccinés furent tous asymptomatiques pendant plus de six mois et ce, sans qu’il n’y ait de virus détectable dans leur organisme après l’exposition initiale.
Cette étude démontra qu’il est possible de développer un vaccin préventif contre le virus Ebola chez les primates non humains en quatre doses seulement.En 2003, les mêmes auteurs qu’en 2000, associés cette fois au laboratoire P4 de l’USAMRIID (Fort Detrick, Maryland, États-Unis), ont amélioré leur processus de vaccination chez le macaque pour qu’il puisse être administré en une seule dose.
Le nouveau mélange d’adénovirus effectué permettait une induction d’anticorps beaucoup plus rapide que précédemment.
Quatre semaines après la nouvelle immunisation, les macaques infectés ont tous survécu et ce, toujours sans trace de virémie.En 2005, de premiers résultats sont obtenus (de même que contre le virus de Marburg) chez des primates non humains avec un vaccin basé sur une souche atténuée recombinante.C’est en 2007 qu’une question fut réglée.
L’opportunité de vérifier si le vaccin fonctionne après l’infection par d’autres souches que l’Ebola Zaïre (ZEBOV) et l’Ebola Soudan (SEBOV) est survenue par la découverte d’une nouvelle souche dans la région de Bundibugyo en Ouganda (BEBOV),.
Le Dr Nancy J. Sullivan et ses collègues du National Institute of Allergy and Infectious Diseases décidèrent d’essayer une stratégie de vaccination appelée prime-boost, ou amorce-rappel en français,.
Cette stratégie utilise des vecteurs ADN ainsi que des vecteurs d’Adénovirus recombinants (rAd5) afin d’assurer une réponse immunitaire en cellules T autant qu’en cellules B et ainsi induire une protection croisée contre BEBOV,.
La question fut donc réglée lorsque l’équipe prouva que sur les quatre macaques cynomolgus immunisés avec un vaccin efficace contre ZEBOV et SEBOV ont survécu à l’infection par BEBOV.Tout récemment, la stratégie prime boost a été expérimentée sur un petit groupe d’humains, montrant qu'elle est sécuritaire pour ce qui a trait à la stimulation d’une réponse immunitaire.
Mais l’expérimentation humaine débute et il n’y a pas encore de confirmation de protection totale contre l’infection par Ebola.En 2015, une équipe américaine a testé un vecteur viral (stomatite vésiculeuse) exprimant la glycoprotéine du virus Ebola chez le porcs comme modèle animal.
L'inoculation n'a pas déclenché les symptômes de la maladie et selon les auteurs,  le virus du vaccin ne pose pas dans ce cas  de risque de dissémination chez les porcs.En décembre 2016, on annonce un premier vaccin efficace, qui sera testé durant une campagne vaccinale en Afrique de l'ouest courant 2017.
Le 19 octobre 2017, l'Administration chinoise des médicaments et des aliments approuve un vaccin élaborée par l'Institut de bioingénierie de l'Académie chinoise des sciences médicales militaires et CanSino Biotechnology Inc. se présentant sous forme posologique lyophilisée faisant de la Chine le troisième pays à élaborer un vaccin contre l’Ebola, avec les États-Unis et la Russie.Le 5 mars 2019, dans un article publié dans Nature Structural & Molecular Biology, Kartik Chandran de l'Albert Einstein College of Medicine à New York et Erica Ollmann Saphire du La Jolla Institute for Immunology en Californie entre-autres, annoncent avoir identifié chez un survivant de l'épidémie de maladie à virus Ebola en Afrique de l'Ouest un anticorps efficace face aux 3 souches du virus Ebola.
Cet anticorps pourrait donc servir de base pour créer un vaccin efficace,.Le vaccin utilisé en 1997 consistait en une injection intramusculaire d’un plasmide ADN contenant un gène codant une protéine structurale du virus Ebola.
Déjà à cette époque, les recherches suggéraient que les protéines de surface de l’enveloppe du virus en question pouvaient générer une réponse immunitaire.
C’est alors que les chercheurs ont décidé d’utiliser cette technique de ''vaccin à ADN'' et ont inséré les gènes codant les protéines de surface du virus dans des plasmides bactériens.
C’est une fois injecté dans les muscles que le plasmide a pu induire l'expression des protéines recombinantes du virus dans les cellules de l'animal, des cobayes dans ce cas.
Les cobayes vaccinés étaient protégés contre une infection aux virus Ebola lors d'un défi.
La conclusion en a été que les réponses immunitaires humorales et cellulaires ont été suffisantes pour arrêter l'infection par le virus.Cette méthode de développement de la vaccination est aussi utilisée pour l’influenza, la malaria ainsi que la tuberculose.En 2000, le vaccin produit contenait une combinaison d’ADN avec un vecteur adénoviral codant des protéines virales.
Comme les équipes travaillant sur le virus Ebola l’ont précédemment découvert, cette équipe a respecté l’idée de stimuler la réponse immunitaire plutôt que la réponse d’anticorps.
Le vaccin concocté favorisait donc la prévention et consistait à limiter la propagation de l’infection par les macaques cynomolgus.
En seulement quatre injections du vaccin, on a pu arriver à une excellente immunisation.Le vaccin de 2003, ne consistant qu’à réduire le nombre de doses administrées, on favorisa la réponse d’anticorps, puisque, pour être efficace, un vaccin se doit de stimuler non seulement la réponse à immunité humorale, mais aussi la réponse lymphocytaire cytotoxique.
Le vaccin ne fut donc qu’une amélioration de celui concocté en 2000, afin de ne procéder qu’à une injection simple pour obtenir une réponse immunitaire aussi efficace sinon meilleure.C’est en 2007 qu’on changea de stratégie.
On opta pour la stratégie prime boost qui consiste en une administration première d’un vaccin prime à ADN codant la majorité des protéines de surface se trouvant sur l’enveloppe des souches Ebola Zaïre et Ebola Soudan.
Quelques mois plus tard, on procède à l’administration de la partie boost basée sur un adénovirus atténué qui produit aussi des fragments de protéines de surface de l’Ebola qui sont aussi reconnus par le système immunitaire.Avec ce vaccin, on prévoit de vacciner les gens qui vivent dans les endroits où l’infection à différentes souches d’Ebola est fréquente.
Le but de ce vaccin est aussi de vacciner la majorité du personnel médical afin de protéger leur vie et de contrôler la propagation de l’infection.
Tous les autres travailleurs dans le domaine de la santé et surtout les chercheurs se trouvant dans les laboratoires seront également vaccinés.
On parlerait aussi de faire vacciner le personnel militaire.Avec ce vaccin, on espère d’abord limiter la propagation de la maladie au sein des populations et du personnel soignant.
Si cette immunisation fonctionne, elle marquera une avancée importante dans le développement de la vaccination et la stratégie utilisée contre ce virus  ; en vaccinant les personnes les plus à risques, on espère pouvoir constituer une sorte de barrière immunitaire autour d’elles pour protéger le reste de la population.Plusieurs obstacles ont retardé le développement d'un vaccin efficace contre le virus Ebola.Le réservoir naturel du virus Ebola étant inconnu, il est plus difficile pour le système de santé publique d’en faire la prévention.
Il devient donc important de développer rapidement un système de protection.
Cette problématique limite aussi les chercheurs à bien comprendre les spécificités pathogéniques associées à ce virus.Une autre problématique est qu’il faut recruter du personnel compétent et autorisé à diriger ce genre de recherches.
Comme le virus Ebola est un virus très infectieux, le risque pour les scientifiques d’en être infecté est assez élevé.Le niveau de risque associé au virus en question est très élevé.
Il est donc important d’avoir un laboratoire très sécurisé.
Un laboratoire de niveau P4 est donc nécessaire pour ce type de virus, d’autant plus qu’il n’existe qu’un nombre limité de ces installations à haut confinement présentant un personnel fiable, capable et autorisé à effectuer de telles recherches.
Le support industriel est aussi très important dans ce type de recherches et les coûts engendrés sont élevés.
La limitation est que ce vaccin est développé sans perspective commerciale.
Les investissements à mener sont donc lourds, mais sans entrée d’argent attendue.L’usage d’un adénovirus pour concevoir le vaccin est très intéressant et fonctionne bien sur les modèles rongeurs ou primates non humains.
En revanche, une partie de la population humaine possède une immunité innée contre ce type de virus.
Cela limite les possibilités en ce qui concerne les souches d’adénovirus.
Un vaccin efficace peut donc être produit à partir d’un adénovirus canin ou autre, mais l’emploi d’un adénovirus humain ne constitue pas la meilleure stratégie d’immunisation.Les virus simplement tués, ou inactivés, sont inefficaces dans ce type de vaccin, parce qu’ils engendrent uniquement une réponse d’anticorps.
Les chercheurs ont démontré la nécessité d'une réaction médiée par la production de cellules T, qui génèrent une réponse immunitaire humorale, assez forte pour empêcher et même éliminer l’infection.
C'est un virus atténué qu'il faut utiliser pour générer ce type de protection.
La posologie est l'étude des modalités d'administration des médicaments, mais recouvre également l'ensemble des modalités d'administration de la prise d'un médicament.
Ces indications proviennent du laboratoire pharmaceutique et sont données au patient par le médecin ou le pharmacien.Le terme de posologie s'identifie à la définition des doses et du rythme des prises de médicaments.Plus précisément, c'est l'étude des doses auxquelles doivent être administrés les médicaments pour donner un effet thérapeutique donné.
On parle ainsi de posologie par prise ou par 24 heures.Pour chaque médicament, il existe une dose usuelle et une dose maximale.Le prescripteur peut être amené à modifier les doses selon différents facteurs tels que :
Louis Pasteur, né le 27 décembre 1822 à Dole (Jura) et décédé le 28 septembre 1895 à Marnes-la-Coquette (Hauts-de-Seine, à cette époque en Seine-et-Oise), est un scientifique français, chimiste et physicien de formation.
Pionnier de la microbiologie, il connut, de son vivant même, une grande notoriété pour avoir mis au point un vaccin contre la rage.Louis Pasteur est né à deux heures du matin le 27 décembre 1822 dans la maison familiale de Dole, troisième enfant de Jean-Joseph Pasteur et de Jeanne-Étiennette Roqui,,.
Il est baptisé dans la Collégiale Notre-Dame de Dole le 15 janvier 1823.
Son père, après avoir été sergent dans l’armée napoléonienne, reprit la profession familiale de tanneur.
En 1827, la famille quitte Dole pour Marnoz, lieu de la maison familiale des Roqui, pour finalement s'installer dans une nouvelle maison en 1830 à Arbois, localité plus propice à l'activité de tannage.
Le jeune Pasteur suit à Arbois les cours d'enseignement mutuel puis entre au collège de la ville.
C'est à cette époque qu'il se fait connaître pour ses talents de peintre ; il a d'ailleurs fait de nombreux portraits de membres de sa famille et des habitants de la petite ville.Il part au collège royal de Besançon.
Puis, en octobre 1838, il le quitte pour l'Institution Barbet, à Paris, afin de se préparer au baccalauréat puis aux concours.
Cependant, déprimé par cette nouvelle vie, il renonce à son projet, quitte Paris et termine son année scolaire 1838-1839 au collège d'Arbois.
À la rentrée 1839, il réintègre le collège royal de Franche-Comté, à Besançon.
En 1840, il obtient le baccalauréat en lettres puis, en 1842, après un échec, le baccalauréat en sciences mathématiques.
Pasteur retourne à Paris en novembre.
Logé à la pension Barbet, où il fait aussi office de répétiteur, il suit les cours du lycée Saint-Louis et assiste avec enthousiasme à ceux donnés à la Sorbonne par le chimiste Jean-Baptiste Dumas ; il a pu également prendre quelques leçons avec Claude Pouillet.
En 1843, il est finalement admis — quatrième — à l'École normale.
Plus tard il sera élève de Jean-Baptiste Boussingault au Conservatoire national des arts et métiers.Alors qu'il est professeur suppléant à la Faculté des Sciences de Strasbourg, Pasteur se marie le 29 mai 1849 avec Marie-Anne, la fille du recteur Aristide Laurent (1791-1869), lequel réside dans les bâtiments de l'Académie avec sa famille.
Ensemble ils ont cinq enfants, dont les trois premiers sont nés à Strasbourg : Jeanne (1850-1859), Jean Baptiste (1851-1908), Cécile Marie Louise Marguerite – dite Cécile – (1853-1866).
La quatrième, Marie-Louise (1858-1934) se marie en 1879 avec René Vallery-Radot, Camille (1863-1865) est la dernière.
De l'union de Marie-Louise et de René Vallery-Radot sont issus Camille Vallery-Radot (1880-1927), sans descendance, et Louis Pasteur Vallery-Radot (1886-1970), membre de l'Académie française et de l'Académie de Médecine, également sans enfant et dernier descendant de Pasteur.Son épouse Marie, dont Émile Roux dit qu'« elle a été le meilleur collaborateur de Louis Pasteur », écrit sous sa dictée, réalise les revues de presse et veille à son image puis à sa mémoire jusqu'à sa mort, en 1910.À l'École normale, Pasteur étudie la chimie et la physique, ainsi que la cristallographie.
Il devient agrégé-préparateur de chimie, dans le laboratoire d'Antoine-Jérôme Balard, et soutient en 1847 à la faculté des sciences de Paris ses thèses pour le doctorat en sciences,.
Ses travaux sur la chiralité moléculaire lui vaudront la médaille Rumford en 1856.Il est professeur à Dijon puis à Strasbourg de 1848 à 1853.
Le 19 janvier 1849, il est nommé professeur suppléant à la faculté des sciences de Strasbourg ; il occupe également la suppléance de la chaire de chimie à l’école de pharmacie de cette même ville, du 4 juin 1849 au 17 janvier 1851.En 1853 il est fait chevalier de la Légion d'honneur.En février 1854, pour avoir le temps de mener à bien des travaux qui puissent lui valoir le titre de correspondant de l'Institut, il se fait octroyer un congé rémunéré de trois mois à l'aide d'un certificat médical de complaisance.
Il fait prolonger le congé jusqu'au 1er août, date du début des examens.
« Je dis au Ministre que j'irai faire les examens, afin de ne pas augmenter les embarras du service.
C'est aussi pour ne pas laisser à un autre une somme de 6 ou 700 francs ».Il est ensuite en 1854 nommé professeur de chimie et doyen de la faculté des sciences de Lille nouvellement créée.
C'est à cette occasion qu'il prononce la phrase souvent citée : « Dans les champs de l'observation, le hasard ne favorise que les esprits préparés.
» Pasteur, qui s'intéressait à la fermentation depuis 1849 (voir plus loin), est stimulé dans ces travaux par les demandes des brasseurs lillois concernant la conservation de la bière.Après Frédéric Kuhlmann et Charles Delezenne, Pasteur est ainsi un des premiers en France à établir des relations fructueuses entre l'enseignement supérieur et l'industrie chimique.Les travaux qu'il réalise à Lille entre 1854 et 1857, notamment ceux effectués à la demande de l'industriel Louis Bigo dans sa distillerie de betteraves à sucre d'Esquermes, conduisent à la présentation de son Mémoire sur la fermentation appelée lactique dans le cadre de la Société des sciences, de l'agriculture et des arts de Lille le 8 août 1857.En 1857, il est nommé administrateur chargé de la direction des études à l'École normale supérieure.De 1861 à 1862, Pasteur publie ses travaux réfutant la théorie de la génération spontanée.
L'Académie des sciences lui décerne le prix Jecker pour ses recherches sur les fermentations.
En 1862, il est élu à l'Académie des sciences, dans la section de minéralogie, en remplacement de Henri Hureau de Senarmont.En 1863, il commence l'étude des altérations du vin, et entre autres, le processus de formation du vinaigre, il publie un ouvrage sur le sujet en 1866.En octobre 1865, le baron Haussmann, instituant une commission chargée d'étudier l'étiologie du choléra et les moyens d'y remédier, y nomme Pasteur, avec Dumas (président), Claude Bernard (malade, il n'y prendra part que de loin), Sainte-Claire Deville et Pelouze.
Les savants, qui cherchent le principe de la contagion dans l'air (alors que Snow, dans un travail publié en 1855, avait montré qu'il était dans l'eau), ne trouvent pas le microbe, que Pacini avait pourtant fait connaître en 1854.À l'École normale supérieure, où règne l'esprit républicain, Pasteur, proche de Napoléon III, est contesté tant par ses collègues que par les élèves, ce qui le pousse à démissionner, en 1867, de ses fonctions d'administrateur.
Il reçoit une chaire en Sorbonne et on crée, à l'École normale même, un laboratoire de chimie physiologique dont la direction lui est confiée.Ses études sur les maladies des vers à soie, menées de 1865 à 1869 à la demande de Napoléon III, triomphent de la pébrine mais non de la flacherie et ne permettent pas vraiment d'endiguer le déclin de la sériciculture.
Pendant ces études, il demeure à Pont-Gisquet près d'Alès.
Durant cette période, une attaque cérébrale le rend hémiplégique.
Il se remet, mais gardera toujours des séquelles : perte de l'usage de la main gauche et difficulté à se déplacer.
En 1868 il devient commandeur de la Légion d'honneur.
Cette même année, l'université de Bonn le fait docteur honoris causa en médecine.La défaite de 1870 et la chute de Napoléon III sont un coup terrible pour Pasteur, grand patriote et très attaché à la famille impériale.
Au lendemain de la proclamation de la IIIe République, il n'hésite pas à prophétiser que « l'Empereur peut attendre avec confiance le jugement de la postérité.
» Par ailleurs, il est malade.
L'Assemblée nationale lui vote une récompense pour le remercier de ses travaux dont les conséquences économiques sont considérables.
Le 25 mars 1873, il est élu « membre associé libre » de l'Académie de médecine,.
En 1874, ses recherches sur la fermentation lui valent la médaille Copley, décernée par la Royal Society, de Londres.En 1876, Pasteur se présente aux élections sénatoriales, mais c'est un échec.
Ses amis croient qu'il va enfin s'arrêter et jouir de sa retraite, mais il reprend ses recherches.
Il gagne Clermont-Ferrand où il étudie les maladies de la bière avec son ancien préparateur Émile Duclaux, et conclut ses études sur la fermentation par la publication d'un livre : Les Études sur la bière (1876).En 1878, il devient grand-officier de la légion d'honneur.
Le 11 décembre 1879, Louis Pasteur est élu à l'unanimité à l'Académie vétérinaire de France.
En 1881, l'équipe de Pasteur met au point un vaccin contre le charbon des moutons, à la suite des études commencées en 1877.En 1882, il est reçu à l'Académie française.
Dans son discours de réception, il accepte pour la science expérimentale l'épithète « positiviste », en ce sens qu'elle a pour domaine les causes secondes et s'abstient donc de spéculer sur les causes premières et sur l'essence des choses, mais il reproche à Auguste Comte et à Émile Littré d'avoir voulu imposer à toute la pensée humaine cette abstention.
Il plaide pour le spiritualisme et célèbre « les deux saintetés de l'Homme-Dieu », qu'il voit réunies dans le couple que l'agnostique Littré formait avec sa femme chrétienne.
C'est dans ce discours que Pasteur prononce la phrase souvent citée : « Les Grecs  nous ont légué un des plus beaux mots de notre langue, le mot enthousiasme  — un dieu intérieur ».Il reçoit, le 29 décembre 1883, le mérite agricole pour ses travaux sur les vins et la fermentation.
Il se rend régulièrement aux réunions du Cercle Saint-Simon.En 1885, Pasteur refusa de poser sa candidature aux élections législatives, alors que les paysans de la Beauce, dont il avait sauvé les troupeaux grâce au vaccin contre le charbon, l'auraient sans doute porté à la Chambre des Députés.La découverte du vaccin antirabique (1885) vaudra à Pasteur sa consécration dans le monde : il recevra de nombreuses distinctions.
L'Académie des sciences propose la création d'un établissement destiné à traiter la rage : l'Institut Pasteur naît en 1888.
En 1892, la Troisième République lui organise un jubilé triomphal pour son 70e anniversaire.
À cette occasion, une médaille gravée par Oscar Roty lui est offerte par souscription nationale.Il meurt le 28 septembre 1895 à Villeneuve-l'Étang, dans l'annexe (dite « de Garches ») de l'Institut Pasteur.
Après des obsèques nationales, le 5 octobre, son corps, préalablement embaumé, est déposé dans l'un des caveaux de Notre-Dame, puis transféré le 27 décembre 1896, à la demande de sa famille, dans une crypte du musée Pasteur.
La famille avait décliné la proposition de l'inhumation au Panthéon.Dans les travaux que Pasteur a réalisés au début de sa carrière scientifique en tant que chimiste, il résolut en 1848 un problème qui allait par la suite se révéler d'importance capitale dans le développement de la chimie contemporaine : la séparation des deux formes de l'acide tartrique.
Le seul acide tartrique que l'on connaissait à l'époque était un sous-produit classique de la vinification, utilisé dans la teinturerie.
Parfois, au lieu de l'acide tartrique attendu, on obtenait un autre acide, qu'on appela acide racémique puis acide paratartrique.
Une solution de l'acide tartrique, comme de chacun de ses sels (tartrates), tournait le plan de la lumière polarisée la traversant, alors qu'une solution de l'acide paratartrique, comme de chacun de ses sels (paratartrates), ne causait pas cet effet, bien que les deux composés aient la même formule brute.
En 1844, Mitscherlich avait affirmé que, parmi les couples tartrate / paratartrate, il y en avait un, à savoir le couple « tartrate double de soude et d'ammoniaque » / « paratartrate double de soude et d'ammoniaque », où le tartrate et le paratartrate n'étaient discernables que par la propriété rotatoire, présente dans le tartrate et absente dans le paratartrate (« tartrate double de soude et d'ammoniaque » était la façon dont on désignait à l'époque le tartrate — base conjuguée de l'acide tartrique — de sodium et d'ammonium).
En particulier, ce tartrate et ce paratartrate avaient, selon Mitscherlich, la même forme cristalline.
Pasteur eut peine à croire « que deux substances fussent aussi semblables sans être tout à fait identiques ».
Il refit les observations de Mitscherlich et s'avisa d'un détail que Mitscherlich n'avait pas remarqué : dans le tartrate en question, les cristaux présentent une dissymétrie (« hémiédrie »), toujours orientée de la même façon ; en revanche, dans le paratartrate correspondant, il coexiste deux formes de cristaux, images spéculaires non superposables l'une de l'autre, et dont l'une est identique à celle du tartrate.
Il sépara manuellement les deux sortes de cristaux du paratartrate, en fit deux solutions et observa un effet de rotation du plan de polarisation de la lumière, dans un sens opposé pour les deux échantillons.
La déviation du plan de polarisation par les solutions étant considérée, depuis les travaux de Biot, comme liée à la structure de la molécule, Pasteur conjectura que la dissymétrie de la forme cristalline correspondait à une dissymétrie interne de la molécule, et que la molécule en question pouvait exister en deux formes dissymétriques inverses l'une de l'autre.
C'était la première apparition de la notion de chiralité des molécules.
Depuis les travaux de Pasteur, l'acide racémique ou paratartrique est considéré comme composé d'un acide tartrique droit (l'acide tartrique connu antérieurement) et d'un acide tartrique gauche.Les travaux de Pasteur dans ce domaine ont abouti, quelques années plus tard à la naissance du domaine de la stéréochimie avec la publication de l'ouvrage la Chimie dans l'Espace par van 't Hoff qui, en introduisant la notion d'asymétrie de l'atome de carbone a grandement contribué à l'essor de la chimie organique moderne.Pasteur avait correctement démontré (par l'examen des cristaux puis par l'épreuve polarimétrique) que l'acide paratartrique est composé de deux formes distinctes d'acide tartrique.
En revanche, la relation générale qu'il crut pouvoir en déduire entre la forme cristalline et la constitution de la molécule était inexacte, le cas spectaculaire de l'acide paratartrique étant loin d'être l'illustration d'une loi générale, comme Pasteur s'en apercevra lui-même.
François Dagognet dit à ce sujet : « la stéréochimie n'a rien conservé des vues de Pasteur, même s'il demeure vrai que les molécules biologiques sont conformées hélicoïdalement ».Gerald L. Geison, dans un livre de 1995, et d'autres auteurs après lui ont noté chez Pasteur une tendance à atténuer sa dette envers Auguste Laurent pour ce qui est de la connaissance des tartrates.
Geison a formulé d'autres critiques contre les travaux de Pasteur sur la chiralité des molécules, mais dans un travail publié en 2019, Joseph Gal, de l'université du Colorado à Denver, conclut que, pour l'essentiel, ces critiques sont entièrement dépourvues de valeur scientifique.En 1849, Biot signale à Pasteur que l'alcool amylique dévie le plan de polarisation de la lumière et possède donc la propriété de dissymétrie moléculaire.
Pasteur estime peu vraisemblable que l'alcool amylique hérite cette propriété du sucre dont il est issu (par fermentation), car, d'une part, la constitution moléculaire des sucres lui paraît très différente de celle de l'alcool amylique et, de plus, il a toujours vu les dérivés perdre la propriété rotatoire des corps de départ.
Il conjecture donc que la dissymétrie moléculaire de l'alcool amylique est due à l'action du ferment.
S'étant persuadé (sous l'influence de Biot) que la dissymétrie moléculaire est étroitement liée à la vie, il voit là la confirmation de certaines « idées préconçues » qu'il s'est faites sur la cause de la fermentation et qui le rangent parmi les tenants du ferment vivant.En 1787, en effet, Adamo Fabbroni, dans son Ragionamento sull'arte di far vino (Florence), avait le premier soutenu que la fermentation du vin est produite par une substance vivante présente dans le moût.
Cagniard de Latour et Theodor Schwann avaient apporté des faits supplémentaires à l'appui de la nature vivante de la levure.
Dans le même ordre d'idées, Jean-Baptiste Dumas, en 1843 (époque où le jeune Pasteur allait écouter ses leçons à la Sorbonne), décrivait le ferment comme un être organisé et comparait son activité à l'activité de nutrition des animaux.Berzelius, lui, avait eu une conception purement catalytique de la fermentation, qui excluait le rôle d'organismes vivants.
Liebig, de façon plus nuancée, avait des idées analogues : il voulait bien envisager que la levure fût un être vivant, mais il affirmait que si elle provoquait la fermentation, ce n'était pas par ses activités vitales mais parce qu'en se décomposant, elle était à l'origine de la propagation d'un état de mouvement (vibratoire).
Berzelius et Liebig avaient tous deux combattu les travaux de Cagniard de Latour et de Schwann.Pasteur « dispose d'une première orientation donnée par Cagniard de Latour ; il la développe et montre que c'est en tant qu'être vivant que la levure agit, et non en tant que matière organique en décomposition ».
Ces travaux bénéficient de la mise au point des premiers objectifs achromatiques dépourvus d'irisation parasite.
De 1857 à 1867, il publie des études sur les fermentations.
Inaugurant la méthode des cultures pures, il établit que certaines fermentations (lactique, butyrique) où on n'avait pas aperçu de substance jouant un rôle analogue à celui de la levure (ce qui avait servi d'argument à Liebig) sont bel et bien l'œuvre d'organismes vivants.Il établit la capacité qu'ont certains organismes de vivre en l'absence d'oxygène libre (c'est-à-dire en l'absence d'air).
Il appelle ces organismes anaérobies.Ainsi, dans le cas de la fermentation alcoolique, la levure tenue à l'abri de l'air vit en provoquant aux dépens du sucre une réaction chimique qui libère les substances dont elle a besoin et provoque en même temps l'apparition d'alcool.
En revanche, si la levure se trouve en présence d'oxygène libre, elle se développe davantage et la fermentation productrice d'alcool est faible.
Les rendements en levure et en alcool sont donc antagonistes.
L'inhibition de la fermentation par la présence d'oxygène libre est ce qu'on appellera « l'effet Pasteur ».Même si Liebig resta sur ses positions, les travaux de Pasteur furent généralement accueillis comme prouvant définitivement le rôle des organismes vivants dans la fermentation.
Toutefois, certains faits (comme le rôle joué dans l'hydrolyse de l'amidon par la diastase, ou alpha-amylase, découverte en 1833 par Payen et Persoz) allaient dans le sens de la conception catalytique de Berzelius.
C'est pourquoi Moritz Traube en 1858 et Marcellin Berthelot en 1860 proposèrent une synthèse des deux théories, physiologique et catalytique : la fermentation n'est pas produite directement par les êtres vivants qui en sont responsables couramment (levures etc.) mais par des substances non vivantes, des « ferments solubles » (on disait parfois « diastases » et on dira plus tard « enzymes »), substances elles-mêmes sécrétées ou excrétées par les êtres vivants en question.
En 1878, Berthelot publia un travail posthume de Claude Bernard qui, contredisant Pasteur, mettait l'accent sur le rôle des « ferments solubles » dans la fermentation alcoolique.
Il en résulta entre Pasteur et Berthelot une des controverses célèbres de l'histoire des sciences.Pasteur ne rejetait pas absolument le rôle des « ferments solubles ».
Dans le cas particulier de la fermentation ammoniacale de l'urine, il considérait comme établi, à la suite d'une publication de Musculus, que la cause proche de la fermentation était un « ferment soluble » (dans ce cas, l'enzyme qu'on appellera « uréase ») produit par le ferment microbien qu'il avait découvert lui-même.
Il admettait aussi le phénomène, signalé par Georges Lechartier et Bellamy, de l'alcoolisation des fruits sans intervention du ferment microbien alcoolique.
Plus d'une fois, il déclara qu'il ne repoussait pas (mais n'adoptait pas non plus) l'hypothèse d'un ferment soluble dans la fermentation alcoolique.
Toutefois, il écrivit en 1879 (à propos du ferment soluble alcoolique) : « La question du ferment soluble est tranchée : il n'existe pas; Bernard s'est fait illusion ».
On s'accorde donc à penser que Pasteur fut incapable de comprendre l'importance des « ferments solubles » (consacrée depuis par les travaux d’Eduard Buchner) et souligna le rôle des micro-organismes dans les « fermentations proprement dites » avec une insistance excessive, qui n'allait pas dans le sens du progrès de l'enzymologie.
On met cette répugnance de Pasteur à relativiser le rôle des organismes vivants sur le compte de son vitalisme, qui l'empêcha aussi de comprendre le rôle des toxines et d'admettre en 1881, lors de sa rivalité avec le vétérinaire Henry Toussaint dans la course au vaccin contre le charbon, qu'un vaccin « tué » pût être efficace.Les travaux de Pasteur sur la fermentation ont fait l'objet d'un débat dans les années 1970 et 1980, la question étant de savoir si, en parlant de « fermentations proprement dites », Pasteur avait commis une tautologie qui lui permettait de prouver à peu de frais la cause biologique des fermentations.À partir de 1859, Pasteur mène une lutte contre les partisans de la « génération spontanée », en particulier contre Félix Archimède Pouchet et un jeune journaliste, Georges Clemenceau ; ce dernier, médecin, met en cause les compétences de Pasteur, qui ne l'est pas, et attribue son refus de la génération spontanée à un parti pris idéologique (Pasteur est chrétien).
Il fallut à Pasteur six années de recherche pour démontrer la fausseté sur le court terme de la théorie selon laquelle la vie pourrait apparaître à partir de rien, et les microbes être générés spontanément.Depuis le XVIIIe siècle, partisans et adversaires de la génération spontanée (aussi appelée hétérogénie) cherchent à réaliser des expériences décisives à l'appui de leur opinion.Les partisans de cette théorie (appelés spontéparistes ou hétérogénistes) soutiennent que, quand le contact avec l'air fait apparaître sur certaines substances des êtres vivants microscopiques, cette vie tient son origine non pas d'une vie préexistante mais d'un pouvoir génésique de l'air.Pour les adversaires de la génération spontanée, l'air amène la vie sur ces substances non par une propriété génésique mais parce qu'il véhicule des germes d'êtres vivants.En 1791 déjà, Pierre Bulliard avance, à la suite d'expériences rigoureuses, que la putréfaction ne donne pas naissance à des êtres organisés et que toute moisissure ne peut survenir que de la « graine d'un individu de la même espèce ».En 1837, encore, Schwann a fait une expérience que les adversaires de la génération spontanée considèrent comme probante en faveur de leur thèse : il a montré que si l'air est chauffé (puis refroidi) avant de pouvoir exercer son influence, la vie n'apparaît pas.En 1847, M. Blondeau de Carolles faisant état d'une expérience reprenant celles conduites par Turpin conclut : « tout être organisé provient d'un germe qui, pour se développer, n'a besoin que de circonstances favorables, et que ce germe ne peut dévier de la mission qui lui est assignée, laquelle est de reproduire un être semblable à celui qui l'a formé ».Le 20 décembre 1858, l'Académie des Sciences prend connaissance de deux notes où Félix Pouchet, naturaliste et médecin rouennais, prétend apporter une preuve définitive de la génération spontanée.Le 3 janvier 1859, l'Académie des Sciences discute la note de Pouchet.
Tous les académiciens qui participent à cette discussion : Milne Edwards, Payen, Quatrefages, Claude Bernard et Dumas, alléguant des expériences qu'ils ont faites eux-mêmes, s'expriment contre la génération spontanée, qui, d'ailleurs, est alors devenue une doctrine minoritaire.Même après les discussions de l'Académie, il reste cependant deux points faibles dans la position des adversaires de la génération spontanée :« Personne, raconte Pasteur, ne sut indiquer la véritable cause d'erreur de ses expériences , et bientôt l'Académie, comprenant tout ce qui restait encore à faire, propose pour sujet de prix la question suivante : Essayer, par des expériences bien faites, de jeter un jour nouveau sur la question des générations spontanées ».C'est Pasteur qui va obtenir le prix en 1862, pour ses travaux expérimentaux exposés dans son Mémoire sur les corpuscules organisés qui existent dans l'atmosphère.
Examen de la doctrine des générations spontanées.Ses expériences sont, pour l'essentiel, des versions améliorées de celles de ses prédécesseurs.
Il comble de plus les deux desiderata signalés plus haut.
Tout d'abord, il comprend que certains résultats antérieurs, apparemment favorables à la génération spontanée étaient dus à ce qu'on utilisait la cuve à mercure pour empêcher la pénétration de l'air ambiant : le mercure, tout simplement, est lui-même très sale.Ensuite, il présente une expérience qu'on ne peut pas accuser de « tourmenter » l'air : il munit des flacons d'un col en S (col de cygne) et constate que, dans un nombre appréciable de cas, l'air qui a traversé les sinuosités, sans avoir été ni chauffé, ni filtré ni lavé, ne provoque pas l'apparition d'êtres vivants sur les substances qui se trouvent au fond du flacon, alors qu'il la provoque sur une goutte placée à l'entrée du circuit.
La seule explication de l'inaltération du fond est que des germes ont été arrêtés par les sinuosités et se sont déposés sur le verre.
Cette expérience avait été suggérée à Pasteur par le chimiste Balard ; Chevreul en avait fait d'analogues dans ses cours.Enfin, Pasteur réfute un argument propre à Pouchet : celui-ci, arguant de la constance avec laquelle (dans ses expériences, du moins) la vie apparaissait sur les infusions, concluait que, si la théorie de ses adversaires était exacte, les germes seraient à ce point ubiquitaires que « l'air dans lequel nous vivons aurait presque la densité du fer ».
Pasteur fait des expériences en divers lieux, temps et altitudes et montre que (si on laisse pénétrer l'air ambiant sans le débarrasser de ses germes) la proportion des bocaux contaminés est d'autant plus faible que l'air est plus pur.
Ainsi, sur la Mer de Glace, une seule des vingt préparations s'altère.Dans l'expérience des ballons à col de cygne, l'air était de l'air normal, ni chauffé, ni filtré ni lavé chimiquement, mais la matière fermentescible était chauffée, ce dont un spontépariste aurait pu tirer argument pour prétendre que le résultat de l'expérience (non-apparition de la vie) ne provenait pas de l'absence des germes, mais d'une modification des propriétés de la matière fermentescible.
En 1863, Pasteur montre que si on met un liquide organique tout frais (sang ou urine) en présence d'air stérilisé, la vie n'apparaît pas, ce qui, conclut-il, « porte un dernier coup à la doctrine des générations spontanées ».Il y avait toutefois une lacune dans la démonstration de Pasteur : alors qu'il se posait en réfutateur de Pouchet, il n'utilisa jamais une infusion de foin comme le faisait Pouchet.
S'il l'avait fait, il se serait peut-être trouvé devant une difficulté inattendue.
En effet, de 1872 à 1876, quelques années après la controverse Pasteur-Pouchet, Ferdinand Cohn établira qu'un bacille du foin, Bacillus subtilis, peut former des endospores qui le rendent résistant à l'ébullition.À la lumière des travaux de Cohn, le pasteurien Émile Duclaux reconnaît que la réfutation de Pouchet par Pasteur devant la Commission académique des générations spontanées était erronée : « L'air est souvent un autre facteur important de la réviviscence des germes (...).
foin contient d'ordinaire, comme Cohn l'a montré depuis, un bacille très ténu (...).
C'est ce fameux bacillus subtilis (...).
Ses spores, en particulier, peuvent supporter plusieurs heures d'ébullition sans périr, mais elles sont d'autant plus difficiles à rajeunir qu'elles ont été plus maltraitées.
Si on ferme à la lampe le col du ballon qui les contient, au moment où le liquide qui les baigne est en pleine ébullition elles ne sont pas mortes, mais elles ne se développent pas dans le liquide refroidi et remis à l'étuve, parce que l'air fait défaut.
Si on laisse rentrer cet air, l'infusion se peuple, et se peuplerait encore si on ne laissait rentrer que de l'air chauffé, car l'air n'agit pas, comme le croyait Pasteur au moment des débats devant la Commission académique des générations spontanées, en apportant des germes : c'est son oxygène qui entre seul en jeu.
» (Émile Duclaux ajoute que Pasteur revint de son erreur).L'air comme facteur de réviviscence de germes non pas morts, mais en état de non-développement, telle est donc l'explication que la science a fini par préférer à l'air convoyeur de germes pour rendre compte d'un phénomène que Pouchet, pour sa part, interprétait comme suit : « les Proto-organismes, qui naissent spontanément (...) ne sont pas extraits de la matière brute proprement dite, ainsi que l'ont prétendu quelques fauteurs  de l'hétérogénie, mais bien des particules organiques, débris des anciennes générations d'animaux et de plantes, qui se trouvent combinées aux parties constituantes des minéraux.
Selon cette doctrine, ce ne sont donc pas des molécules minérales qui s'organisent, mais bien des particules organiques qui sont appelées à une nouvelle vie ».On considère que c'est John Tyndall qui, en suivant les idées de Cohn, mettra la dernière main à la réfutation de la génération spontanée.Pasteur estimait d'ailleurs que la génération spontanée n'était pas réfutée de façon absolue, mais seulement dans les expériences par lesquelles on avait prétendu la démontrer.
Dans un texte non publié de 1878, il déclarait ne pas juger la génération spontanée impossible.Si l'on peut reprocher à Pasteur comme un manque de rigueur le fait de ne pas avoir cherché à répéter vraiment les expériences de Pouchet, il y a une autre circonstance où, dans ses travaux sur la génération spontanée, Pasteur peut sembler tendancieux, puisqu'il admet avoir passé sous silence des constatations qui n'allaient pas dans le sens de sa thèse.
En effet, travaillant à l'aide de la cuve à mercure alors qu'il n'avait pas encore compris que le mercure apporte lui-même des germes, il avait obtenu des résultats apparemment favorables à la génération spontanée : « Je ne publiai pas ces expériences ; les conséquences qu'il fallait en déduire étaient trop graves pour que je n'eusse pas la crainte de quelque cause d'erreur cachée, malgré le soin que j'avais mis à les rendre irréprochables.
J'ai réussi, en effet, plus tard, à reconnaître cette cause d'erreur ».Se fondant sur ces deux entorses de Pasteur à la pure méthode scientifique, et aussi sur ce qu'ils considéraient comme l'évidente partialité de l'Académie des sciences en faveur de Pasteur, Farley et Geison, dans un article de 1974, ont soutenu qu'un facteur externe à la science intervenait dans la démarche de Pasteur et de l'Académie des sciences : le désir de faire échec aux idées matérialistes et subversives dont la génération spontanée passait pour être l'alliée.
(Pasteur, qui était spiritualiste, voyait un lien entre matérialisme et adhésion à la génération spontanée, mais se défendait de s'être lui-même laissé influencer par cette sorte de considérations dans ses travaux scientifiques.)
Dans son livre de 1995, Geison reprend une bonne part de l'article de 1974, mais reconnaît que cet article était trop « externaliste » au détriment de Pasteur et faisait la part trop belle à Pouchet.H.
Collins et T. Pinch, en 1993, prennent eux aussi pour point de départ de leur réflexion les deux entorses de Pasteur à la pure méthode scientifique et la partialité de l'Académie des sciences, ils mentionnent eux aussi (brièvement) les enjeux religieux et politiques que certains croyaient voir dans la question, mais n'évoquent pas la possibilité que Pasteur lui-même ait cédé à de tels mobiles idéologiques.
En fait, ils exonèrent Pasteur et blâment plutôt une conception aseptisée de la méthode scientifique : « Pasteur savait ce qui devait être considéré comme un résultat et ce qui devait l'être comme une 'erreur'.
Pasteur était un grand savant, mais la manière dont il a agi ne s'approche guère de l'idéal de la méthode scientifique proposé de nos jours.
On voit mal comment il aurait pu transformer à ce point notre conception de la nature des germes s'il avait dû adopter le modèle de comportement stérile qui passe aux yeux de beaucoup pour le parangon de l'attitude scientifique ».Signalons cependant, à propos de cette apologie un peu cynique, que des voix se sont élevées contre la tendance de certains théoriciens « externalistes » ou « relativistes » des sciences à réduire l'activité scientifique, et notamment celle de Pasteur, à des manœuvres et à des coups de force où la rationalité aurait assez peu de part.Dans un article de 1999 et un livre de 2003, D. Raynaud a réexaminé la controverse sur la génération spontanée en partant de la correspondance non publiée entre les membres de l'Académie des Sciences et Pouchet.
À partir de quatre arguments principaux, il a conclu à l'inanité de l'apologie de Pouchet présentée par certains historiens et sociologues « relativistes » des sciences.En 1862, Pasteur confirme l'opinion formulée dès 1822 par Christiaan Hendrik Persoon, en établissant le rôle d'un microorganisme, le mycoderma aceti (renommé Acetobacter aceti) dans la formation du vinaigre.En 1863, il y a déjà quelques années que les maladies des vins français grèvent lourdement le commerce.
Napoléon III demande à Pasteur, spécialiste de la fermentation et de la putréfaction, de chercher un remède : Pasteur, qui transporta deux années de suite en automne son laboratoire à Arbois, publiera les résultats de ses travaux dans Études sur le vin en 1866 (il avait publié un premier papier sur le sujet dès 1863).
Il propose de chauffer le vin à 57 °C afin de tuer les germes et résout ainsi le problème de sa conservation et du transport, c'est la pasteurisation.
Il a au sujet de ce procédé une querelle de priorité avec l'œnologue Alfred de Vergnette de Lamotte, dans laquelle les savants Balard et Thenard prennent parti respectivement pour Pasteur et pour Vergnette.
Pasteur et Vergnette avaient d'ailleurs été tous deux précédés par Nicolas Appert qui avait publié le chauffage des vins en 1831 dans son ouvrage Le livre de tous les ménages.
La découverte de la pasteurisation vaudra à Pasteur le Mérite Agricole, mais aussi le Grand Prix de l’Exposition universelle (1867).Des dégustateurs opérant à l'aveugle avaient conclu que la pasteurisation n'altérait pas le bouquet des grands vins, mais « Pasteur fut forcé de reconnaître la forte influence de l'imagination après avoir vu sa commission d'expertise renverser complètement ses conclusions sur le même vin en l'espace de quelques jours ».
Finalement, la pasteurisation du vin n'eut pas un grand succès et fut abandonnée avant la fin du XIXe siècle.
Avant la Première Guerre mondiale, l'Institut Pasteur pratiqua sur le vin une pasteurisation rapide en couche mince qui ne se répandit guère mais fit plus tard « un retour triomphal en France sous son nom américain » de flash pasteurization.En Bourgogne, la pasteurisation du vin a été abandonnée dans les années 1930.Les maladies microbiennes du vin ont été évitées par d'autres moyens que la pasteurisation : conduite rationnelle des fermentations, sulfitage des vendanges, réduction des populations contaminantes par différents procédés de clarification.
D'un emploi malaisé au niveau du chai, où elle ne met pas en outre la cuvée à l'abri d'une contamination postérieure au chauffage, la pasteurisation a toutefois son utilité pour certains types de vins, - d'ailleurs plutôt de qualité moyenne et de consommation rapide — au moment de l'embouteillage où l'on préfère parfois les techniques de sulfitage et de filtration stérile (mais la brasserie recourt plus volontiers à la pasteurisation).Pour sa mise en évidence du rôle des organismes vivants dans la fermentation alcoolique et pour les conséquences d'ordre pratique qu'il en a tirées, Pasteur est considéré comme le fondateur de l’œnologie, dont Chaptal avait posé les premiers jalons.
Toutefois, en limitant l'action positive aux seules levures, Pasteur n'a pas pu voir le rôle de certaines bactéries dans le déclenchement de la fermentation malolactique (rôle qui, une fois redécouvert -en 1946- permettra une conduite beaucoup plus subtile de la vinification).Contrairement à la pasteurisation du vin, la pasteurisation du lait, à laquelle Pasteur n'avait pas pensé (c'est le chimiste allemand Franz von Soxhlet qui, en 1886, proposa d'appliquer la pasteurisation au lait), s'implanta durablement.
(Ici encore, d'ailleurs, on marchait sur les traces d'Appert).La théorie de l'origine microbienne des maladies contagieuses, appelée théorie microbienne ou théorie des germes, existait depuis longtemps, mais seulement à l'état d'hypothèse.
La première démonstration de la nature vivante d'un agent infectieux est établie en 1687 par deux élèves de Francesco Redi, Giovanni Cossimo Bonomo et Diacinto Cestoni qui montrent, grâce à l'utilisation du microscope, que la gale est causée par un petit parasite, Sarcoptes scabiei.
Cette découverte n'eut pourtant alors aucun écho.
Vers 1835, quelques savants, dont on a surtout retenu Agostino Bassi, prouvent qu'une des maladies du ver à soie, la muscardine, est causée par un champignon microscopique.
En 1836-37 Alfred Donné décrit le protiste responsable de la trichomonose : Trichomonas vaginalis.
En 1839 Johann Lukas Schönlein identifie l'agent des teignes faviques : Trichophyton schoenleinii ; en 1841, le Suédois Frederick Theodor Berg identifie Candida albicans, l'agent du Muguet buccal et en 1844, David Gruby identifie l'agent des teignes tondantes, Trichophyton tonsurans (cette dernière découverte apparemment oubliée, fut faite de nouveau par Saboureau en 1894).
Il s'agissait là toutefois de protozoaires ou d'organismes multicellulaires.
En 1861, Anton de Bary établit le lien de causalité entre le mildiou de la pomme de terre - responsable notamment de la Grande Famine en Irlande - et le champignon Botrytis infestans (qui avait déjà été observé par Miles Joseph Berkeley en 1845).Dans un essai de 1840, Friedrich Gustav Jakob Henle, faisant écho aux travaux de Bassi sur la nature microbienne de la muscardine du ver à soie et à ceux de Cagniard de Latour et de Theodor Schwann sur la nature vivante de la levure, avait développé une théorie microbienne des maladies contagieuses et formulé les critères permettant selon lui de décider si telle maladie a pour cause tel micro-organisme.La théorie, en dépit de ces avancées, rencontrait des résistances et se développait assez lentement, notamment pour ce qui est des maladies contagieuses humaines.
Ainsi, la découverte du bacille du choléra était restée quasiment lettre morte quand Pacini l'avait publiée en 1854, alors qu'elle devait trouver immédiatement une vaste audience quand Koch la refit en 1883.
À l'époque des débuts de Pasteur, donc, la théorie microbienne existe, même si elle est encore dans l'enfance.
D'autre part, il est de tradition, surtout depuis le XVIIIe siècle, de souligner l'analogie entre les maladies fiévreuses et la fermentation.
Il n'est donc pas étonnant, dans ce contexte, que les travaux de Pasteur sur la fermentation aient stimulé le développement de la théorie microbienne des maladies contagieuses.
En 1860, après avoir réaffirmé le rôle des organismes vivants dans la putréfaction et la fermentation, Pasteur lui-même ajoutait : « Je n'ai pas fini cependant avec toutes ces études.
Ce qu'il y aurait de plus désirable serait de les conduire assez loin pour préparer la voie à une recherche sérieuse de l'origine de diverses maladies ».
Casimir Davaine, au début de ses publications de 1863 sur le charbon, qui sont maintenant considérées comme la première preuve de l'origine microbienne d'une maladie transmissible à l'homme, écrivait « M.
Pasteur, en février 1861, publia son remarquable travail sur le ferment butyrique, ferment qui consiste en petites baguettes cylindriques, possédant tous les caractères des vibrions ou des bactéries.
Les corpuscules filiformes que j'avais vus dans le sang des moutons atteints de sang de rate  ayant une grande analogie de forme avec ces vibrions, je fus amené à examiner si des corpuscules analogues ou du même genre que ceux qui déterminent la fermentation butyrique, introduits dans le sang d'un animal, n'y joueraient pas de même le rôle d'un ferment ».Pasteur lui-même, en 1880, rappelle ses travaux sur les fermentations et ajoute : « La médecine humaine, comme la médecine vétérinaire, s'emparèrent de la lumière que leur apportaient ces nouveaux résultats.
On s'empressa notamment de rechercher si les virus et les contages ne seraient pas des êtres animés.
Le docteur Davaine (1863) s'efforça de mettre en évidence les fonctions de la bactéridie du charbon, qu'il avait aperçue dès l'année 1850 ».On verra toutefois que Pasteur, quand il aura à s'occuper des maladies des vers à soie, en 1865, commencera par nier le caractère microbien de la pébrine, compris par d'autres avant lui.
Quant aux maladies contagieuses humaines, c'est seulement à partir de 1877 qu'il participera personnellement au développement de leur connaissance.
(Dès 1873 Gerhard Armauer Hansen, porté par la conclusion de Pasteur dans le débat sur la génération spontanée certes, mais aussi lecteur de Charles-Louis Drognat-Landré et de Davaine, identifie l'agent causal de la lèpre.
Cette découverte, toutefois, ne fera pas immédiatement l'unanimité.
)Le chirurgien anglais Joseph Lister, après avoir lu les travaux de Pasteur sur la fermentation (où la putréfaction est expliquée, comme la fermentation, par l'action d'organismes vivants), se convainc que l'infection postopératoire (volontiers décrite à l'époque comme une pourriture, une putréfaction) est due elle aussi à des organismes microscopiques.
Ayant lu ailleurs que l'acide phénique (phénol) détruisait les entérozoaires qui infectaient certains bestiaux, il lave les blessures de ses opérés à l'eau phéniquée et leur applique un coton imbibé d'acide phénique.
Le résultat est une réduction drastique de l'infection et de la mortalité.Lister publie sa théorie et sa méthode en 1867, en les rattachant explicitement aux travaux de Pasteur.
Dans une lettre de 1874, il remercie Pasteur « pour m'avoir, par vos brillantes recherches, démontré la vérité de la théorie des germes de putréfaction, et m'avoir ainsi donné le seul principe qui ait pu mener à bonne fin le système antiseptique ».L'antisepsie listérienne, dont l'efficacité triomphera en quelques années des résistances, est, au point de vue théorique, une branche importante de la théorie microbienne.
Sur le plan pratique, toutefois, elle n'est pas entièrement satisfaisante : Lister, qui n'a pensé qu'aux germes présents dans l'air, et non à ceux que propagent l'eau, les mains des opérateurs ainsi que les instruments et les tissus qu'ils emploient, attaque les microbes dans le champ opératoire, en vaporisant l'acide phénique dans l'air et en l'appliquant sur les plaies.
C'est assez peu efficace quand il faut opérer en profondeur et, de plus, l'acide phénique a un effet caustique sur l'opérateur et sur le patient.
On cherche donc bientôt à prévenir l'infection (asepsie) plutôt qu'à la combattre (antisepsie).Pasteur « est de ceux qui cherchent à dépasser l'antisepsie par l'asepsie ».
À la séance du 30 avril 1878 de l'Académie de médecine, il attire l'attention sur les germes propagés par l'eau, l'éponge ou la charpie avec lesquelles les chirurgiens lavent ou recouvrent les plaies et leur recommande de ne se servir que d'instruments d'une propreté parfaite, de se nettoyer les mains puis de les soumettre à un flambage rapide et de n'employer que de la charpie, des bandelettes, des éponges et de l'eau préalablement exposées à diverses températures qu'il précise.
Les germes en suspension dans l'air autour du lit du malade étant beaucoup moins nombreux que dans l'eau et à la surface des objets, ces précautions permettraient d'utiliser un acide phénique assez dilué pour ne pas être caustique.Certes, ces recommandations n'étaient pas d'une nouveauté absolue : Semmelweis et d'autres avant lui (par exemple Claude Pouteau et Jacques-Mathieu Delpech,) avaient déjà compris que les auteurs des actes médicaux pouvaient eux-mêmes transmettre l'infection, et ils avaient fait des recommandations en conséquence, mais les progrès de la théorie microbienne avaient tellement changé les données que les conseils de Pasteur reçurent beaucoup plus d'audience que ceux de ses prédécesseurs.En préconisant ainsi l'asepsie, Pasteur traçait une voie qui serait suivie (non sans résistances du corps médical) par Octave Terrillon (1883), Ernst von Bergmann et William Halsted,.
En 1865, Jean-Baptiste Dumas, sénateur et ancien ministre de l'Agriculture et du commerce, demande à Pasteur d'étudier une nouvelle maladie qui décime les élevages de vers à soie du sud de la France et de l'Europe, la pébrine, caractérisée à l'échelle macroscopique par des taches noires et à l'échelle microscopique par les « corpuscules de Cornalia ».
Pasteur accepte et fera cinq longs séjours à Alès, entre le 7 juin 1865 et 1869.Arrivé à Alès, Pasteur se familiarise avec la pébrine et aussi avec une autre maladie du ver à soie, connue plus anciennement que la pébrine : la flacherie ou maladie des morts-flats.
Contrairement, par exemple, à Quatrefages, qui avait forgé le mot nouveau pébrine, Pasteur commet l'erreur de croire que les deux maladies n'en font qu'une et même que la plupart des maladies des vers à soie connues jusque-là sont identiques entre elles et à la pébrine.
C'est dans des lettres du 30 avril et du 21 mai 1867 à Dumas qu'il fait pour la première fois la distinction entre la pébrine et la flacherie.Il commet une autre erreur : il commence par nier le caractère « parasitaire » (microbien) de la pébrine, que plusieurs savants (notamment Antoine Béchamp) considéraient comme bien établi.
Même une note publiée le 27 août 1866 par Balbiani, que Pasteur semble d'abord accueillir favorablement, reste sans effet, du moins immédiat.
Il ne changera d'opinion que dans le courant de 1867 ».Alors que Pasteur n'a pas encore compris la cause de la maladie, il propage un procédé efficace pour enrayer les infections : on choisit un échantillonnage de chrysalides, on les broie et on recherche les corpuscules dans le broyat ; si la proportion de chrysalides corpusculeuses dans l'échantillonnage est très faible, on considère que la chambrée est bonne pour la reproduction.
Cette méthode de tri des « graines » (œufs) est proche d'une méthode qu'avait proposée Osimo quelques années auparavant, mais dont les essais n'avaient pas été concluants.
Par ce procédé, Pasteur jugule la pébrine et sauve pour beaucoup l'industrie de la soie dans les Cévennes,.En 1884, Balbiani, qui faisait peu de cas de la valeur théorique des travaux de Pasteur sur les maladies des vers à soie, reconnaissait que son procédé pratique avait remédié aux ravages de la pébrine, mais ajoutait que ce résultat tendait à être contrebalancé par le développement de la flacherie, moins bien connue et plus difficile à prévenir.
En 1886, la Société des agriculteurs de France émettait le vœu « que le gouvernement examine s’il n'y avait pas lieu de procéder à de nouvelles études scientifiques et pratiques sur le caractère épidémique des maladies des vers à soie et sur les moyens de combattre cette influence ».
Decourt, qui cite ce vœu, donne des chiffres dont il conclut qu'après les travaux de Pasteur, la production des vers à soie resta toujours très inférieure à ce qu'elle avait été avant l'apparition de la pébrine et conteste dès lors à Pasteur le titre de « sauveur de la sériciculture française ».À partir de 1876, Pasteur travaille successivement sur le filtre et l'autoclave, tous deux mis au point par Charles Chamberland (1851-1908), et aussi sur le flambage des vases.Bien que ses travaux sur les fermentations, comme on l'a vu, aient stimulé le développement de la théorie microbienne des maladies contagieuses, et bien que, dans l'étude des maladies des vers à soie, il ait fini par se ranger à l'opinion de ceux qui considéraient la pébrine comme « parasitaire », Pasteur, à la fin de 1876 (année où l'Allemand Robert Koch a fait progresser la connaissance de la bactérie du charbon), est encore indécis sur l'origine des maladies contagieuses humaines : « Sans avoir de parti pris dans ce difficile sujet, j'incline par la nature de mes études antérieures du côté de ceux qui prétendent que les maladies contagieuses ne sont jamais spontanées (...) Je vois avec satisfaction les médecins anglais qui ont étudié la fièvre typhoïde avec le plus de vigueur et de rigueur repousser d'une manière absolue la spontanéité de cette terrible maladie ».
Mais il devient bientôt un des partisans les plus actifs et les plus en vue de la théorie microbienne des maladies contagieuses, domaine où son plus grand adversaire est Robert Koch, leur rivalité féroce (sur fond de guerre franco-prussienne) mais féconde s'étendant aux écoles qu’ils ont créées et se manifestant d'abord sur l'étiologie du charbon, puis sur le choléra, la sérothérapie antidiphtérique et la peste.
En 1877, Pasteur découvre le « vibrion septique », qui provoque un type de septicémie et avait obscurci l'étiologie du charbon; ce microbe sera nommé plus tard Clostridium septicum.
En 1880, il découvre le staphylocoque, qu'il identifie comme responsable des furoncles et de l'ostéomyélite.
Son combat en faveur de la théorie microbienne ne l'empêche d'ailleurs pas de reconnaître l'importance du « terrain », importance illustrée par l'immunisation vaccinale, à laquelle il va consacrer la dernière partie de sa carrière.Quand Pasteur commence ses recherches sur les vaccins, on fait des inoculations préventives contre une maladie humaine, la variole (la méthode de Jenner est célèbre), et contre deux maladies du bétail : la clavelée, maladie du mouton, et la péripneumonie bovine.Certains clavelisateurs cherchent à atténuer la virulence du claveau (la substance morbide injectée) par culture ou par inoculations successives d'animal à animal, mais, selon un dictionnaire de l'époque, leurs résultats sont illusoires.Le germe du choléra des poules, nommé ensuite Pasteurella avicida, fut isolé en 1879 par l'italien Perroncito ; la même année Henry Toussaint réussit à le cultiver.
C'est d'ailleurs auprès de Toussaint que Pasteur se procura la souche du microbe de choléra des poules.Durant l'été 1879, Pasteur et ses collaborateurs, Émile Roux et Émile Duclaux, découvrent que les poules auxquelles on a inoculé des cultures vieillies du microbe du choléra des poules non seulement ne meurent pas mais résistent à de nouvelles infections — c'est la découverte d'un vaccin d'un nouveau type : contrairement à ce qui était le cas dans la vaccination contre la variole, on ne se sert pas, comme vaccin, d'un virus bénin fourni par la nature (sous forme d'une maladie bénigne qui immunise contre la maladie grave) mais on provoque artificiellement l'atténuation d'une souche initialement très virulente et c'est le résultat de cette atténuation qui est utilisé comme vaccin.S'il faut en croire la version célèbre de René Vallery-Radot et d'Émile Duclaux, c'est en reprenant de vieilles cultures oubliées (ou laissées de côté pendant les vacances) qu'on se serait aperçu avec surprise qu'elles ne tuaient pas et même immunisaient.
Il y aurait là un cas de sérendipité.Antonio Cadeddu, toutefois, rappelle que « depuis les années 1877-1878,  possédait parfaitement le concept d'atténuation de la virulence ».
C'est un des motifs pour lesquels Cadeddu, à la suite de Mirko Grmek, met en doute le rôle allégué du hasard dans la découverte du procédé d'atténuation de la virulence et pense que cette atténuation a sûrement été recherchée activement, ce que les notes de laboratoire de Pasteur semblent bien confirmer.Dans sa double communication du 26 octobre 1880 à l'Académie des Sciences et à l'Académie de médecine, Pasteur attribue l'atténuation de la virulence au contact avec l'oxygène.
Il dit que des cultures qu'on laisse vieillir au contact de l'oxygène perdent de leur virulence au point de pouvoir servir de vaccin, alors que des cultures qu'on laisse vieillir dans des tubes à l'abri de l'oxygène gardent leur virulence.
Il reconnaît toutefois dans une note de bas de page que l'oxygène ne joue pas toujours son rôle d'atténuation, ou pas toujours dans les mêmes délais : « Puisque, à l'abri de l'air, l'atténuation n'a pas lieu, on conçoit que, si dans une culture au libre contact de l'air (pur) il se fait un dépôt du parasite en quelque épaisseur, les couches profondes soient à l'abri de l'air, tandis que les superficielles se trouvent dans de tout autres conditions.
Cette seule circonstance, jointe à l'intensité de la virulence, quelle que soit, pour ainsi dire, la quantité du virus employé, permet de comprendre que l'atténuation d'un virus ne doit pas nécessairement varier proportionnellement au temps d'exposition à l'air ».Certains voient là un demi-aveu de l'irrégularité du vaccin, irrégularité que la suite confirma : « Cette voie, que le génie de Pasteur avait ouverte et qui fut ensuite si féconde, se révéla bientôt fermée en ce qui concerne la vaccination anti-pasteurellique de la poule.
Des difficultés surgirent dans la régularité de l'atténuation et de l'entretien de la virulence à un degré déterminé et fixe ».La théorie de Pasteur, selon laquelle la virulence du vaccin était atténuée par l'action de l'oxygène, n'a pas été retenue.
D. Brock, après avoir présenté comme vraisemblable l'explication, étrangère à Pasteur, de l'atténuation dans les cultures par mutations et sélection (l'organisme vivant, qui possède des défenses immunitaires, exerce une sélection en défaveur des microbes mutants peu virulents, ce qui n'est pas le cas dans les cultures), ajoute : « Ses recherches  sur les effets de l'oxygène sont quelque chose de curieux.
Bien que l'oxygène puisse jouer un rôle en accélérant les processus d'autolyse, il n'a probablement pas une action aussi directe que Pasteur le pensait ».En 1880, Auguste Chauveau et Henry Toussaint publient les premières expériences françaises d'immunisation d'animaux contre le charbon par inoculation préventive.
Greenfield, à Londres, obtient l'immunisation en inoculant le bacille préalablement atténué par culture.
Au vu des publications de Greenfield, certains auteurs estiment qu'il a la priorité sur Pasteur, mais Greenfield reconnaissait lui-même que ses résultats étaient peu concluants.Le 5 mai 1881, lors de la célèbre expérience de Pouilly-le-Fort, un troupeau de moutons est vacciné contre la maladie du charbon à l'aide d'un vaccin mis au point par Pasteur, Émile Roux et surtout Charles Chamberland.
Cette expérience fut un succès complet.
Certains auteurs reprochent cependant à Pasteur d'avoir induit le public scientifique en erreur sur la nature exacte du vaccin utilisé lors de cette expérience.
C'est ce qu'on a appelé le « Secret de Pouilly-le-Fort ».Afin de répondre à la demande importante de vaccins charbonneux qui s'est manifestée immédiatement après l'expérience de Pouilly-le-fort, et ce tant en France qu'à l’étranger, et tandis qu'un décret de juin 1882 inscrivait le vaccin charbonneux dans la loi de police sanitaire des animaux, Pasteur doit organiser « précipitamment » la production et la distribution en nombre de vaccin.
Pour ce faire une entité est créée Le Vaccin charbonneux, rue Vauquelin.
Des accidents vaccinaux survenus à l'automne 1881 et au printemps 1882, en France et à l’étranger, imposent à Pasteur de revenir sur le postulat de la fixité des vaccins.
En 1886, la diffusion du vaccin charbonneux à l'étranger est confiée à une société commerciale, la Compagnie de Vulgarisation du Vaccin Charbonneux qui détenait un monopole commercial mais aussi technique visant tant à préserver les secrets de fabrication qu'à garantir l'homogénéité des vaccins.Le vaccin de Pasteur et ses dérivés donnaient des résultats globalement satisfaisants, mais ils s'affaiblissaient parfois au point de ne pas provoquer une réaction immunitaire suffisante et, dans d'autres cas, ils restaient assez virulents pour communiquer la maladie qu'ils étaient censés prévenir.
Nicolas Stamatin en 1931 et Max Sterne en 1937 obtinrent des vaccins plus efficaces à l'aide de bacilles dépourvus de la capacité de former une capsule (bacilles acapsulés ou acapsulogènes).Envoyé par Pasteur dans le Sud-est de la France où sévit une épidémie de rouget du porc, dit aussi le mal rouge, Louis Thuillier identifie le bacille de cette maladie le 15 mars 1882.
Cette découverte a en réalité déjà été faite par H.J.
La description originellement donnée par Pasteur et Thuillier d'un bacille en forme de 8 est fautive.
Le pasteurien Adrien Loir écrira en 1937-1938 que le bacille qu'ils ont cultivé et qui a servi à produire le vaccin (voir plus loin) était bien celui du rouget, même s'ils l'ont décrit incorrectement, mais en 1957, Gaston Ramon estimera que le bacille découvert par Thuillier était une pasteurelle du porc et non le bacille du rouget.
Dans une communication datée du 26 novembre 1883 et intitulée La vaccination du rouget des porcs à l'aide du virus mortel atténué de cette maladie , Pasteur présente à l'Académie des Sciences un vaccin obtenu par une diminution de la virulence du bacille à l'aide de passage successifs sur le lapin, espèce naturellement peu réceptive à cette maladie.
Il s'agit d'une nouvelle méthode d'atténuation de la virulence, qui s'apparente à celle sur laquelle est basée le vaccin de Jenner.
En dépit des efforts de l'administration française, le vaccin du rouget, mis sur le marché dès 1886, ne rencontre pas un grand succès en France.
Le 22 octobre 1884, Pasteur note que « la Société vétérinaire de la Charente a été de nouveau découragée pour des vaccinations de rouget par un échec qu'elle a subi en octobre ».
Cet échec a été attribué à  un investissement insuffisant de Chamberland chargé d'en assurer le développement dans le cadre du laboratoire Pasteur.
Ainsi pour la seule année 1890, seuls 20 000 porcs sont vaccinés en France, alors qu'en Hongrie ce nombre se monte alors à 250 000.Faute de données précises, l'épidémiologie de la rage humaine et animale est difficile à retracer avant le XXe siècle.
Elle semble en extension en Europe occidentale à partir du XVIe siècle, probablement en raison d'une croissance démographique perturbant les habitats de la faune sauvage, avec multiplication des contacts entre animaux sauvages et domestiques, notamment lors du marronnage.
La rage des loups, renards et chiens est présente en Europe tout au long du siècle en causant plusieurs centaines de décès humains.En 1879, Pierre-Henri Duboué dégage de divers travaux de l'époque une « théorie nerveuse » de la rage : « Dans cette hypothèse, le virus rabique s'attache aux fibrilles nerveuses mises à nu par la morsure et se propage jusqu'au bulbe.
» Le rôle de la voie nerveuse dans la propagation du virus de la rage, conjecturé par Duboué presque uniquement à partir d'inductions, fut plus tard confirmé expérimentalement par Pasteur et ses assistants.La même année 1879, Galtier montre qu'on peut utiliser le lapin, beaucoup moins dangereux que le chien, comme animal d'expérimentation.
Il envisage aussi de mettre à profit la longue durée d'incubation (c'est-à-dire la longue durée que le virus met à atteindre les centres nerveux) pour faire jouer à un moyen préventif (qu'il en est encore à chercher ou à expérimenter) un rôle curatif : « J'ai entrepris des expériences en vue de rechercher un agent capable de neutraliser le virus rabique après qu'il a été absorbé et de prévenir ainsi l'apparition de la maladie, parce que, étant persuadé, d'après mes recherches nécroscopiques, que la rage une fois déclarée est et restera longtemps, sinon toujours incurable, à cause des lésions qu'elle détermine dans les centres nerveux, j'ai pensé que la découverte d'un moyen préventif efficace équivaudrait presque à la découverte d'un traitement curatif, surtout si son action était réellement efficace un jour ou deux après la morsure, après l'inoculation du virus ».
(Galtier ne précise pas que le moyen préventif auquel il pense doive être un vaccin.
)Dans une note de 1881, il signale notamment qu'il semble avoir conféré l'immunité à un mouton en lui injectant de la bave de chien enragé par voie sanguine.
(L'efficacité de cette méthode d'immunisation des petits ruminants : chèvre et mouton, par injection intraveineuse sera confirmée en 1888 par deux pasteuriens, Nocard et Roux).Dans cette même note, toutefois, Galtier répète une erreur qu'il avait déjà commise dans son Traité des maladies contagieuses de 1880 : parce qu'il n'a pas pu transmettre la maladie par inoculation de fragments de nerfs, de moelle ou de cerveau, il croit pouvoir conclure que, chez le chien, le virus n'a son siège que dans les glandes linguales et la muqueuse bucco-pharyngienne.Les choses en sont là quand Pasteur, en 1881, commence ses publications sur la rage.Dans une note du 30 mai de cette année, Pasteur rappelle la « théorie nerveuse » de Duboué et l'incapacité où Galtier a dit être de confirmer cette théorie en inoculant de la substance cérébrale ou de la moelle de chien enragé.
« J'ai la satisfaction d'annoncer à cette Académie que nos expériences ont été plus heureuses », dit Pasteur, et dans cette note de deux pages, il établit deux faits importants :Dans cette note de 1881, Galtier n'est nommé qu'une fois, et c'est pour être contredit (avec raison).En décembre 1882, nouvelle note de Pasteur et de ses collaborateurs, établissant que le système nerveux central est le siège principal du virus, où on le trouve à l'état plus pur que dans la salive, et signalant des cas d'immunisation d'animaux par inoculation du virus, autrement dit des cas de vaccination.
Galtier est nommé deux fois en bas de page, tout d'abord à propos des difficultés insurmontables auxquelles se heurtait l'étude de la rage avant l'intervention de Pasteur, notamment parce que « la salive était la seule matière où l'on eût constaté la présence du virus rabique » (suit une référence à Galtier) et ensuite à propos de l'absence d'immunisation que les pasteuriens ont constatée chez le chien après injection intraveineuse : « Ces résultats contredisent ceux qui ont été annoncés par M. Galtier, à cette Académie, le 1er août 1881, par des expériences faites sur le mouton.
» Galtier, en 1891 puis en 1904, se montra ulcéré de cette façon de traiter sa méthode d'immunisation des petits ruminants par injection intraveineuse, dont l'efficacité fut confirmée en 1888 par deux pasteuriens, Roux et Nocard.Deux notes de février et mai 1884 sont consacrées à des méthodes de modification du degré de virulence par passages successifs à l'animal (exaltation par passages successifs aux lapins, atténuation par passages successifs aux singes).
Les auteurs estiment qu'après un certain nombre de passages chez des animaux d'une même espèce, on obtient un virus fixe, c'est-à-dire un virus dont les propriétés resteront immuables lors de passages subséquents (en 1935, P. Lépine montra que cette fixité était moins absolue qu'on ne le croyait et qu'il était nécessaire de contrôler le degré de virulence et le pouvoir immunogène des souches « fixes »).En 1885, Pasteur se dit capable d'obtenir une forme du virus atténuée à volonté en exposant de la moelle épinière de lapin rabique desséchée au contact de l'air gardé sec.
Cela permet de vacciner par une série d'inoculations de plus en plus virulentes.Pour expérimenter ses recherches sur l'homme, Pasteur écrit, le 22 septembre 1884, à l'Empereur du Brésil pour lui proposer d'offrir aux condamnés à mort de son pays, la possibilité d'échapper à leur exécution en devenant cobayes.Mais c'est en 1885, en France, qu'il fait ses premiers essais sur l'homme.Il ne publia rien sur les deux premiers cas : Girard, sexagénaire de l'hôpital Necker, inoculé le 5 mai 1885, et la fillette de 11 ans Julie-Antoinette Poughon, inoculée après le 22 juin 1885, ce qui, selon Patrice Debré, alimente régulièrement une rumeur selon laquelle Pasteur aurait « étouffé » ses premiers échecs.
En fait, dans le cas Girard, qui semble avoir évolué favorablement, le diagnostic de rage, malgré des symptômes qui avaient fait conclure à une rage déclarée, était douteux, et, dans le cas de la fillette Poughon (qui mourut le lendemain de la vaccination), il s'agissait très probablement d'une rage déclarée, ce qui était et est encore, avec une quasi-certitude, un arrêt de mort à brève échéance, avec ou sans vaccination.G.
Geison a noté qu'avant de soigner ces deux cas humains de rage déclarée, Pasteur n'avait fait aucune tentative de traitement de rage déclarée sur des animaux.Le 6 juillet 1885, on amène à Pasteur un petit Alsacien de Steige âgé de neuf ans, Joseph Meister, mordu l'avant-veille par un chien qui avait ensuite mordu son propriétaire.
Meister avait reçu quatorze blessures et le chien, toujours agressif, avait été abattu par des gendarmes.
Les morsures étant récentes, il n'y a pas de rage déclarée.
Cette incertitude du diagnostic rend le cas plus délicat que les précédents et Roux, l'assistant de Pasteur dans les recherches sur la rage, refuse formellement de participer à l'injection.
Pasteur hésite, mais deux éminents médecins, Alfred Vulpian et Jacques-Joseph Grancher, estiment que le cas est suffisamment sérieux pour justifier la vaccination et la font pratiquer sous leur responsabilité.
Le fort écho médiatique accordé alors à la campagne de vaccination massive contre le choléra menée par Jaume Ferran en Espagne a pu également infléchir la décision de Pasteur.
Joseph Meister reçoit sous un pli fait à la peau de l’hypocondre droit treize inoculations réparties sur dix jours, et ce par une demi-seringue de Pravaz d'une suspension d'un broyat de moelle de lapin mort de rage le 21 juin et conservée depuis 15 jours.
Il ne développera jamais la rage.En fait, la valeur de preuve du cas Meister laisse sceptiques certains spécialistes.
Ce qui fit considérer que le chien qui l'avait mordu était enragé est le fait que « celui-ci, à l'autopsie, avait foin, paille et fragments de bois dans l'estomac ».
Aucune inoculation de substance prélevée sur le chien ne fut faite.
Dans une communication à l'Académie de médecine (11 janvier 1887), Peter, principal adversaire de Pasteur et grand clinicien, déclara que le diagnostic de rage par la présence de corps étrangers dans l'estomac était caduc.
Victor Babès, disciple de Pasteur, confirmera dans son Traité de la rage que « l'autopsie est, en effet, insuffisante à établir le diagnostic de rage.
En particulier, la présence de corps étrangers dans l'estomac est à peu près sans valeur.
»Un détail du traitement de Meister illustre ces mots écrits en 1996 par Maxime Schwartz, alors directeur général de l'Institut Pasteur (Paris) :Pasteur, en effet, fit faire à Meister, après la série des inoculations vaccinales, une injection de contrôle.
L'injection de contrôle, pour le dire crûment, consiste à risquer de tuer le sujet en lui injectant une souche d'une virulence qui lui serait fatale dans le cas où il ne serait pas vacciné ou le serait mal ; s'il en réchappe, on conclut que le vaccin est efficace.Pasteur a lui-même dit les choses clairement : « Joseph Meister a donc échappé, non seulement à la rage que ses morsures auraient pu développer, mais à celle que je lui ai inoculée pour contrôle de l'immunité due au traitement, rage plus virulente que celle des rues.
L'inoculation finale très virulente a encore l'avantage de limiter la durée des appréhensions qu'on peut avoir sur les suites des morsures.
Si la rage pouvait éclater, elle se déclarerait plus vite par un virus plus virulent que par celui des morsures ».À propos de la seconde de ces trois phrases, André Pichot, dans son anthologie d'écrits de Pasteur, met une note : « Cette phrase est un peu déplacée, dans la mesure où il s'agissait ici de soigner un être humain (et non de faire une expérience sur un animal) ».Pasteur ayant publié ses premiers succès, son vaccin antirabique devient vite notoire et les candidats affluent (parmi les premiers vaccinés, Jean-Baptiste Jupille est resté célèbre).
Déçu par quelques cas où le vaccin a été inefficace, Pasteur croit pouvoir passer à un « traitement intensif », qu'il présente à l'Académie des Sciences le 2 novembre 1886.
L'enfant Jules Rouyer, vacciné dans le mois d'octobre précédant cette communication, meurt vingt-quatre jours après la communication et son père porte plainte contre les responsables de la vaccination.D'après un récit fait une cinquantaine d'années après les évènements par le bactériologiste André Loir, neveu et ancien assistant-préparateur de Pasteur, le bulbe rachidien de l'enfant, inoculé à des lapins, leur communique la rage, mais Roux (en l'absence de Pasteur, qui villégiature à la Riviera) fait un rapport en sens contraire ; le médecin légiste, Brouardel, après avoir dit à Roux « Si je ne prends pas position en votre faveur, c'est un recul immédiat de cinquante ans dans l'évolution de la science, il faut éviter cela !
», conclut dans son expertise que l'enfant Rouyer n'est pas mort de la rage.
Patrice Debré accepte ce récit, tout en notant qu'il repose uniquement sur André Loir.À la même époque, le jeune Réveillac, qui a subi le traitement intensif, meurt en présentant des symptômes atypiques où Peter, le grand adversaire de Pasteur, voit une rage humaine à symptômes de rage de lapin, autrement dit la rage de laboratoire, la rage Pasteur, dont on commence à beaucoup parler.Selon P. Lépine et L. Cruveilhier, « on renonça plus tard à une méthode de traitement aussi énergique, et qui pouvait présenter quelques dangers ».En fait, on finit même par renoncer au traitement ordinaire de Pasteur-Roux.
En 1908, le médecin italien Claudio Fermi (it) proposa un vaccin contre la rage avec virus traité au phénol.
Progressivement, dans le monde entier, le vaccin phéniqué de Fermi supplanta les moelles de lapin de Pasteur et Roux.
En France, où on en était resté aux moelles de lapin, P. Lépine et V. Sautter firent en 1937 des comparaisons rigoureuses : une version du vaccin phéniqué protégeait les lapins dans la proportion de 77,7 %, alors que les lapins vaccinés par la méthode des moelles desséchées n'étaient protégés que dans la proportion de 35 %.
Dans un ouvrage de 1973, André Gamet signale que la préparation de vaccin contre la rage par la méthode des moelles desséchées n'est plus utilisée.
Parmi les méthodes qui le sont encore, il cite le traitement du virus par le phénol.Même si ce sont les travaux de Pasteur sur la vaccination antirabique, et donc les derniers de sa carrière, qui ont fini par faire l'essentiel de sa gloire aux yeux du grand public, un immunologiste comme Patrice Debré estime que les œuvres les plus remarquables de Pasteur sont les premières.La création d'un Institut antirabique sera d'abord évoquée devant l'Académie des Sciences par Vulpian dès octobre 1885 après que Pasteur y eut exposé les résultats de son traitement préventif.
Le 1er mars 1886, Pasteur mentionne brièvement son projet devant l'Académie des Sciences : à l'issue de cette même séance une commission ad-hoc adopte ce projet et décide de lancer une souscription internationale afin de permettre le financement de ce qui est déjà nommé Institut Pasteur.Reconnu d'utilité publique par décret du 4 juin 1887, l'Institut Pasteur / Institut Antirabique de Paris sera officiellement inauguré le 14 novembre 1888 en présence du Président Sadi Carnot.En 1877, Pasteur veut tester l'hypothèse selon laquelle le bacille du charbon ne causerait l'état morbide que de façon indirecte, en produisant un « ferment diastasique soluble » qui serait l'agent pathogène immédiat.
Il prélève le sang d'un animal qui vient de mourir du charbon, le filtre de façon à en ôter les bacilles et inocule le filtrat à un animal sain.
L'animal récepteur ne développe pas la maladie et Pasteur estime que cette expérience « écarte complètement l'hypothèse du ferment soluble ».
Dans une publication ultérieure, toujours en 1877, Pasteur note toutefois que le sang filtré, s'il ne cause pas la maladie, rend les globules agglutinatifs, autant et même plus que dans la maladie, et envisage que ce soit l'effet d'une « diastase » formée par les bacilles.
En fait, les pasteuriens Roux et Yersin prouveront en 1888 (dans le cas de la diphtérie) que les microbes sécrètent bel et bien une substance (la toxine) qui est la cause directe et isolable de la maladie.Des épistémologues et historiens des sciences comme F. Dagognet et A. Pichot pensent que le demi-échec de Pasteur à mettre l'existence et le rôle des toxines en évidence a la même cause que son attitude défensive face à la théorie des enzymes : son « vitalisme » (Dagognet dit « végétalisme »), qui tend à séparer rigoureusement les domaines du vivant et du non-vivant.
Il faut dire, à la décharge de Pasteur, que l'existence d'une toxine du charbon ne sera démontrée qu'en 1955.
En 1880, d'ailleurs, Pasteur accepte d'envisager, à titre d'hypothèse, le rôle d'une substance toxique.En 1880, le vétérinaire Henry Toussaint estime, à tort ou à raison, avoir immunisé des moutons contre le charbon par deux méthodes : en inoculant du sang charbonneux dont les microbes ont été éloignés par filtration, et en inoculant du sang charbonneux où les microbes ont été laissés, mais tués par chauffage.
Pasteur, qui voit ainsi Toussaint, « à son insu, peut-être, car il n'y fait aucune allusion », battre en brèche les opinions publiées antérieurement par Pasteur, rejette l'idée d'un vaccin qui ne contiendrait pas d'agents infectieux vivants.
Ici encore, André Pichot voit un effet de la tendance de Pasteur à cloisonner rigoureusement les domaines du vivant et de l'inanimé.
Pasteur, toutefois, finira par admettre la possibilité des « vaccins chimiques ».Pour expliquer l'immunisation, Pasteur adopta tour à tour deux idées différentes.
La première de ces idées, qu'on trouve déjà chez Tyndall et chez Auzias-Turenne, explique l'immunisation par l'épuisement, chez le sujet, d'une substance nécessaire au microbe.
La seconde idée est que la vie du microbe ajoute une matière qui nuit à son développement ultérieur.
Aucune de ces deux idées n'a été ratifiée par la postérité, encore que la seconde puisse être considérée comme une esquisse de la théorie des anticorps.En 1950, René Dubos faisait gloire à Pasteur « d'audacieuses divinations ».
En 1967, François Dagognet cite ce jugement de Dubos, mais pour en prendre le contre-pied : il rappelle que Pasteur a seulement ajouté à la chimie des isomères que Berzelius et Mitscherlich avaient fondée, qu'il avait été précédé par Cagniard-Latour dans l'étude microscopique des fermentations, par Davaine dans la théorie microbienne des maladies contagieuses et, bien sûr, par Jenner dans la vaccination.
Il ajoute que la science de Pasteur « consiste moins à découvrir qu'à enchaîner ».Dans le même ordre d'idées que Dagognet, André Pichot définit comme suit le caractère essentiel de l'œuvre de Pasteur : « C'est là le mot-clé de ses travaux : ceux-ci ont toujours consisté à mettre de l'ordre, à quelque niveau que ce soit.
Ils comportent assez peu d'éléments originaux ; mais, le plus souvent, ils partent d'une situation très confuse, et le génie de Pasteur a toujours été de trouver, dans cette confusion initiale, un fil conducteur qu'il a suivi avec constance, patience et application ».Patrice Debré dit de même : « Pasteur donne parfois même l'impression de se contenter de vérifier des résultats décrits par d'autres, puis de se les approprier.
Cependant, c'est précisément quand il reprend des démonstrations laissées, pour ainsi dire, en jachère, qu'il se montre le plus novateur : le propre de son génie, c'est son esprit de synthèse ».Pasteur n'était en rien un chercheur isolé dans sa tour d'ivoire.
Ses travaux étaient orientés vers les applications médicales, hygiéniques, agricoles et industrielles.
Il a toujours collaboré étroitement avec les professions concernées (même si, parmi les médecins, ses partisans étaient en minorité) et il a su obtenir le soutien des pouvoirs publics à la recherche scientifique.À Lille, Pasteur dépose un brevet sur la fermentation alcoolique le 3 février 1857.
À Paris, il dépose un brevet sur la fabrication de l'acide acétique le 9 juillet 1861.
Le 11 avril 1865, Pasteur obtient en France un brevet sur la conservation des vins par chauffage modéré à l’abri de l’air (méthode qui portera le nom de pasteurisation).
Le 28 juin 1871 il obtient un brevet en France sur la fabrication de la bière.
Ce brevet est à l'origine de la création de la «Société des bières inaltérables - procédé Pasteur» que Pasteur crée le 4 mars 1873.
Cette société, au capital de 250000 francs, procède au rachat du brevet sur la bière pour un montant de 150 000 francs.
La même année, l'Office américain des brevets accorde en 1873 à Pasteur un brevet « sur une levure exempte de germes organiques de maladie, en tant que produit de fabrication ».Par la loi du 3 août 1875, l'Assemblée Nationale accorde une pension à Louis Pasteur en récompense des services rendus.Louis Pasteur, par ailleurs, a eu quelques velléités de s'engager activement en politique.Dans sa théorie solidariste, qui passe pour l’idéologie officielle de la Troisième République, Léon Bourgeois considère Louis Pasteur comme un père fondateur de la République pour avoir identifié un lien biologique entre les humains : selon le résumé du philosophe Pierre Charbonnier, « chacun étant potentiellement pour l’autre une source d’infection, la maladie est une responsabilité collective, le socle le plus tangible de la solidarité qui existe de fait entre nous », ce qui entraîne « la nécessité d’institutions protectrices qui traduisent la solidarité microbienne en mesures d’éducation et de prévoyance ».Dans les dernières années du XIXe siècle et les premières du XXe siècle, l'apologétique catholique attribuait volontiers à Pasteur la phrase « Quand on a bien étudié, on revient à la foi du paysan breton.
Si j'avais étudié plus encore j'aurais la foi de la paysanne bretonne ».En 1939 (l'entre-deux-guerres a été la grande époque de l'Union rationaliste), Louis Pasteur Vallery-Radot, petit-fils de Louis Pasteur, fait cette déclaration : « Mon père a toujours eu soin, et ma mère également d'ailleurs, de dire que Pasteur n'était pas pratiquant.
Si vous ouvrez la Vie de Pasteur, vous verrez que mon père parle du spiritualisme et non du catholicisme de Pasteur.
Je me souviens parfaitement de l'irritation de mon père et de ma mère, quand quelque prêtre, en chaire, se permettait de lui attribuer cette phrase qu'il n'a jamais dite : « J'ai la foi du charbonnier breton.
» (...) Toute la littérature qui a été écrite sur le prétendu catholicisme de Pasteur est absolument fausse ».En 1994-1995, Maurice Vallery-Radot, arrière-petit-neveu de Pasteur , ne se contente pas du spiritualisme, du théisme de Pasteur.
Il tient que Pasteur resta, au fond, catholique, même s'il n'allait pas régulièrement à la messe.Dans son livre Pasteur paru en 1896 (éd.
Gauthier-Vilars), Charles Chappuis, son ami d'enfance, témoigne que Louis Pasteur se rendait à Notre-Dame de Paris pour écouter les sermons de carême.Après le décès de sa petite fille Jeanne, en 1859, il écrit à un proche qu’elle « vient d’aller au Ciel pour prier pour nous ».En 1882 il est admis sous la coupole de l’Académie française.Pasteur parla : « Au-delà de cette voûte étoilée, qu’y a-t-il ?
Et au-delà ?...Quand cette notion  s’empare de l’entendement, il n’y a qu’à se prosterner.
On se sent prêt à être saisi par la sublime folie de Pascal ».Un témoin, Ernest Legouvé, membre de l’Institut, déclarera dans son discours pour les funérailles de Pasteur à Notre-Dame de Paris : « Ces paroles firent courir dans toute l’assemblée un frisson d’enthousiasme et de foi ».En 2004, Pasteur sert de caution morale à une cause d'une nature différente : son précédent est évoqué à l'Assemblée nationale en faveur de l'euthanasie compassionnelle.
La commission rapporte, en se référant à Léon Daudet, que quelques-uns des dix-neuf Russes soignés de la rage par Pasteur développèrent la maladie et que, pour leur épargner les souffrances atroces qui s'étaient déclarées et qui auraient de toute façon été suivies d'une mort certaine, on pratiqua sur eux l'euthanasie avec le consentement de Pasteur.Pourtant, il y eut une époque où un Pasteur praticien de l'euthanasie n'était pas une chose qu'on exhibait volontiers : Axel Munthe ayant lui aussi raconté l'euthanasie de quelques-uns des mordus russes dans la version originale en anglais de son Livre de San Michele (The Story of San Michele), la traduction française publiée en 1934 par Albin Michel, bien que donnée comme « texte intégral », fut amputée du passage correspondant.Du vivant même de Pasteur, des rues adoptèrent son nom : il existe à ce jour 2 020 artères (rues, boulevards…) « Pasteur » en France.
C'est un des noms propres les plus attribués comme nom de rue.
Lors des grands mouvements de décolonisation, qui entraînèrent des changements de nom de rues, les voies nommées en hommage à Pasteur gardèrent souvent leur nom.
C'est le cas encore aujourd'hui, par exemple, d'un boulevard du quartier résidentiel de Bellevue à Constantine, en Algérie.C'est également le cas au Viet Nam dans au moins deux villes importantes: à Ho Chi Minh Ville, dans le 3e arrondissement (vietnamien: Quận 3), où par ailleurs l'Institut Pasteur d'Hô-Chi-Minh-Ville, construit en 1891, est toujours en activité et n'a pas été renommé à la suite de l'indépendance;  à Danang, troisième ville du pays, où l'ancienne rue Pasteur, située dans l'arrondissement Hải Châu (vietnamien: Quận Hải Châu) n'a pas été rebaptisée.En 2015, Pasteur est le onzième personnage le plus célébré au fronton des 67 000 établissements publics français : pas moins de 361 écoles, collèges et lycées lui ont donné son nom, derrière Saint-Joseph (880), Jules Ferry (642), Notre-Dame (546), Jacques Prévert (472), Jean Moulin (434), Jean Jaurès (429), Jeanne d'Arc (423), Antoine de Saint-Exupéry (418), Sainte Marie (377), Victor Hugo (365), mais devant Marie Curie (360), Pierre Curie (357), Jean de la Fontaine (335).La Poste française émet en 1923 une série de timbres-poste d'usage courant à l'effigie de Louis Pasteur.
Vingt-cinq timbres  à ce type, dont des surchargés ou préoblitérés sont émis jusqu'en 1932.Pasteur sera célébré aussi par des timbres de grand format en 1936, 1938, 1973 et 1995Le paquebot Pasteur, lancé en 1938, a fait l'objet d'un timbre de 70c non émis (en 1939), surchargé 1F   + 1F en 1941.L’œuvre complète de Pasteur est téléchargeable sur le site de la Bibliothèque nationale de France, Gallica (cliquer sur le lien puis en haut et à droite à la rubrique « Télécharger »)
Les Adenoviridae, ou adénovirus, sont une famille de virus qui regroupe une centaine de variétés, dont une quarantaine environ peut infecter l'humain.
C'est en 1953 que ceux-ci ont été mis en évidence par Wallace P. Rowe (en) à partir de fragments d'amygdale (qui lui donne son nom, du grec adến : glande, et non de « ADN »).Les adénovirus sont des virus possédant de l'ADN double brin linéaire (30 000 à 38 000 paires de bases, pb), les deux brins d'ADN possèdent à leurs extrémités des séquences répétées inversées qui permettent aux molécules monocaténaires (simple brin) de se circulariser (la protéine p55 permet la circularisation).
Les adénovirus sont des particules d'un diamètre de 60  à   90 nm, sans enveloppe, à capside icosaédrique formée de 252 capsomères (240 hexons (en) et 12 pentons).
Les capsomères situés aux sommets de l'icosaèdre sont des pentons prolongés par une fibre de longueur variable et terminée par l'antigène Y, responsable de la propriété d'hémagglutination.L’hexon est constitué de trois chaînes de polypeptides II.
Les polypeptides VI, VIII et IX forment les liaisons entre les capsomères.
La base du penton est constituée de cinq polypeptides III et la fibre de trois polypeptides IV.Les polypeptides VII sont des analogues d’histones, ils se complexent avec l'ADN.
Les polypeptides V entourent le complexe ADN-VII et le relient à la capside.52 sérotypes ont été identifiés, classés en 7 sous-groupes, appelés de A à G.Le cycle viral complet dure de 30 à 36 heures et se termine par la libération d'environ 10 000 particules virales après lyse de la cellule infectée.
Ce rendement, très impressionnant, varie cependant d'un sérotype à un autre et du type cellulaire infecté.
Le cycle se divise en trois étapes, une phase précoce correspondant à l'attachement et à l'entrée du virus, suivi d'une phase de réplication de l'ADN viral et de production des protéines virales et d'une phase tardive d'assemblage et de libération des virions.Le cycle viral débute par l'attachement de la particule virale à la cellule hôte et à son internalisation dans cette dernière.La phase précoce peut être décrite par les différentes étapes suivantes :L'entrée de l'adénovirus a beaucoup été étudiée pour les sérotypes 2 et 5 (appartenant à la famille C des adénovirus humains).
Cette entrée est séquentielle et repose sur l'interaction avec des protéines cellulaires.
Pour les adénovirus de sérotype 2 et 5, la fibre de la particule virale est responsable de l'attachement à la cellule hôte via le récepteur CAR (Coxsackie and Adenovirus Receptor (en)) ).
Ce récepteur est commun aux virus Coxsackie B3 de la famille des Picornaviridae et aux adénovirus de la famille A, C, E et éventuellement D.
CAR est une glycoprotéine transmembranaire de 46 kilodaltons appartenant à la superfamille des immunoglobulines.
Cette protéine est exprimée sur un large spectre de type cellulaire expliquant le large tropisme des adénovirus.
La protéine CAR est impliquée dans l'adhésion intercellulaire au niveau basolatéral des jonctions serrées des épithéliums.Tous les sérotypes, à l'exception de ceux du sous-groupe B, ont la capacité de se lier à CAR, mais tous n'utilisent pas préférentiellement ce récepteur.
Par exemple, l'adénovirus 37, appartenant au sous-groupe D, peut se lier à CAR mais utilise le récepteur CD46 pour infecter les cellulesMême si l'expression de CAR participe au tropisme de l'Adénovirus in vitro , il n'y a cependant pas de corrélation directe entre le tropisme du virus pour des tissus exprimant fortement CAR in vivo chez la souris.
Ceci sous-entend la présence de récepteurs alternatifs qui seraient préférentiellement utilisés in vivo.
L'attachement de la tête de la fibre au récepteur CAR conduit à un changement de conformation permettant d'exposer le motif RGD (en) (Arginine - Glycine - Acide aspartique) porté sur une boucle à la surface de chaque monomère de la base de penton.
Ce motif va ensuite interagir avec les intégrines cellulaires AlphaV Béta1, AlphaV Béta3, AlphaV Béta5, Alpha5 Béta1 et Alpha3 Béta1.L'exposition des cinq motifs RGD portés par la base de penton (molécule pentamérique) permet l'association simultanée de plusieurs molécules d'intégrines.
ce recrutement va initier l'entrée par endocytose dans la cellule.Le virus entre dans la cellule par la voie des vésicules à clathrine, puis passe dans les endosomes.
Le mécanisme par lequel le virus s'extrait de l'endosome n'est pas encore clairement élucidé, mais des études suggèrent l'implication de la protéine virale VI dans cet échappement.
Néanmoins, à la suite de l'acidification des endosomes précoces, les protéines IIIa et VIII se dissocient.Les gènes précoces sont divisés en 4 groupes : E1 (A et B), E2 (A et B), E3 et E4.E1A code des protéines transactivatrices (en) de la transcription qui agissent au niveau des promoteurs viraux et promoteurs de gènes cellulaires endogènes ainsi que pour des protéines d’autorégulation.
Il active l’entrée en phase S.Une protéine de E1A active également le gène qui code la protéine p53 qui induit les mécanismes d’apoptose (p53 est un facteur de transcription qui va activer l'expression du gène de Bax).Cette région code 7 protéines (minimum) toxiques pour la cellule qui vont induire l’apoptose indépendante de p53.La protéine E4orf6 bloque l’accumulation de p53.
E4orf4 se lie à une protéine phosphatase p2a, entraînant la  déphosphorylation d’activateurs de E1A et autres facteurs de transcription, aboutissant à la diminution de l’expression de E4 (autorégulation).Son expression dépend d’activateurs synthétisés lors de l’expression de E1A et E4.
La région E3 permet à la cellule infectée d’échapper au système immunitaire, elle contrecarre les défenses innées.E3 code une protéine qui s’associe aux molécules CMH de classe I.
Cette protéine empêche que ces molécules soient exprimées à la surface de la cellules.E3 code aussi plusieurs protéines qui interfèrent avec l’inflammation (Tumor Necrosis Factor ou facteur de nécrose tumorale).
Ces protéines de E3 viennent empêcher la fixation du TNF sur son récepteur.Une protéine de la région E3 produite très tardivement jouerait un rôle dans la destruction de la cellule.E1B a une fonction anti-apoptotique.
E1B s’exprime quasi simultanément avec E3 et code la protéine p55k qui se lie a p53 et l’inactive, et pour la protéine p19k, un équivalent fonctionnel de Bcl-2 (la protéine Bcl2 empêche l’homodimérisation de Bax, et l’homodimérisation de Bax permet l’activation de la caspase qui active à son tour l’endocaspase qui digère l’ADN).E1B bloque également l’apoptose induite par les produits d’E4 (nécessité d’un délai : le virus doit avoir du temps pour synthétiser ses particules virales).E1B19k serait inhibée tardivement par la protéine d’E3 qui joue un rôle dans la destruction de la cellule, la protéine p19k étant inhibée, Bax est actif et induit l'apoptose.Son expression, comme celle de E3, dépend d’activateurs produits par E1A et E4.
Cette région E2 est impliquée dans la réplication de l’ADN viral.E2A code une DNA binding protein (DBP) p72 qui recouvre l’ADN monocaténaire néo-synthétisé et le protège de l'activité des nucléases cellulaires.E2B code une protéine terminale p55 liée de façon covalente aux extrémités 5’ de l’ADN bicaténaire et sert d’amorce à la réplication.Un des brins va être copié de façon continue de 5’vers 3’.
L’autre brin est déplacé et recouvert par une protéine : la DBP (DNA Binding Protein) p72.
Plusieurs fourches de réplication peuvent se suivre.
On obtient des brins bicaténaires et monocaténaires.
Ces derniers vont se circulariser grâce à des séquences répétées inversées a et a'.Les gènes tardifs sont regroupés sous un seul opéron et se décomposent en 3 familles : L1, L2 et L3.
La transcription s’effectue à partir de ce promoteur unique.
Le regroupement de plusieurs gènes sous la régulation d’un seul promoteur permet une expression simultanée des protéines tardives.Les ARNm tardifs vont être traduits en protéines du core, de la capside et protéines des fibres.L’assemblage se fait dans le noyau, donc les protéines de structure doivent migrer dans le noyau.
Les produits des régions d'E3 et d'E4 induisent l'apoptose, la cellule est lysée et les virions libérés.Ils sont capables d'infecter des cellules à division lente et se multiplient dans l'œil, l'appareil respiratoire et l'appareil digestif.
Le pouvoir pathogène des adénovirus s'exerce principalement sur l'appareil respiratoire.
La transmission peut être :Ils sont excrétés par les selles de façon prolongée.
Ils sont responsables de pharyngites, d'angine et de pneumonies, mais aussi de conjonctivites.
Certains sérotypes (40, 41), lorsqu'ils sont déglutis, peuvent causer des gastro-entérites (1 à 9 % des gastroentérites chez les enfants).
Exceptionnellement, ils peuvent provoquer une encéphalite primaire (et non post ou para-infectieuse), sévère chez l'enfant et l'immunodéprimé.Les adénovirus peuvent aussi provoquer des dermatoses érythémateuses (Acrodermatite papuleuse infantile de Gianotti-Crosti).Les corps apoptotiques contenant des particules virales sont transmis aux cellules adjacentes par endocytose.On estime que 50 % des infections à adénovirus sont asymptomatiques.Les anticorps apparaissent dès l'enfance, cependant, la multitude des types (plus de 42 chez l'humain) fait que l'on peut avoir des gastroentérites à répétition.
À l'âge de 4 ans, 85 % des enfants ont développé une immunité contre l'adénovirus de type entérique.Le mastadénovirus humain C, responsable d'infections respiratoires bénignes, a été identifié chez un humain daté d'environ 31 000 ans.
L'analyse génétique de ces souches anciennes suggère une présence du virus prédatant l'apparition de l'homme moderne.Selon ICTV (20 juillet 2021) :
Maurice Ralph Hilleman (né le 30 août 1919 à Miles City – 11 avril 2005 à Philadelphie), était un microbiologiste américain spécialisé dans l'étude des vaccins.Il développa plus de trois douzaines de vaccins.
Parmi ceux-ci, celui contre la rougeole, les oreillons, l'hépatite A, l'hépatite B, la varicelle, la méningite, la pneumonie et la bactérie Haemophilus influenzae.
Il a également joué un rôle dans la découverte des adénovirus, des virus hépatiques et du virus cancérigène SV40.
Adel F. Mahmoud, président de Merck Vaccines, les recherches du Dr.
Hilleman ont sauvé des millions de vies et en ont préservé des millions d'autres de la maladie.Maurice Hilleman est né dans une ferme à Miles City dans le Montana.
Sa sœur jumelle meurt à sa naissance puis sa  mère deux jours après.
Plus tard, il découvre Charles Darwin et fut surpris à l'église en train de lire L'Origine des espèces.
À cause de son manque d'argent, il ne parvient pas à rentrer à l'université.
Son frère ainé l'aide cependant à décrocher une bourse pour aller à la Montana State University.
Puis il s'inscrit à l'Université de Chicago et décroche un doctorat de microbiologie en 1944.Après avoir rejoint la société E.R.
Squibb (aujourd'hui Bristol-Myers Squibb), il développe un vaccin contre l'Encéphalite japonaise, une maladie qui menace les troupes américaines dans le Pacifique durant la Seconde Guerre mondiale.
Chef du Département des maladies respiratoires à l'Institut de recherche Walter Reed Army de 1948 à 1951, il découvre les mutations génétiques lorsqu'un virus grippal mute.
Cela l'aide à découvrir qu'une épidémie de grippe qui sévit alors à Hong Kong pourrait devenir une pandémie.
Travaillant à l'instinct, lui et son collègue découvrent une nouvelle caractéristique de la grippe qui pourrait tuer des millions de personnes.
Quarante millions de doses de vaccins sont préparées et distribuées.En 1957, le Dr.
comme chef du département de recherche des nouveaux virus et de biologie cellulaire à Whitehouse Station dans le New Jersey.
Il est alors avec Merck quand Hilleman développe la majorité de ses quarante vaccins expérimentés et autorisés.
Il prit sa retraite en 1984 comme vice-président des Laboratoires de Recherche Merck à West Point en Pennsylvanie.Le 21 mars 1963, sa fille, alors âgée de 5 ans, est frappée par les oreillons.
Il prélève alors le virus et réalise un vaccin avec.À sa mort, le 11 avril 2005, à 85 ans, le Dr.
Hilleman était professeur adjoint l'École de Médicine pédiatrique, à l'Université de Pennsylvanie.
Il a mis au point huit des quatorze vaccins utilisés dans les pays industrialisés.
L'innocuité définit la qualité d'un objet, d'un organisme, d'une substance, qui n'est pas toxique et qui, plus largement, est inoffensif pour l'être humain ou l'animal.
Ce terme s'oppose aux notions de nocivité et de toxicité.Le site du CNTRL présente ce terme comme définissant « la qualité de ce qui n'est pas nuisible », le site du dictionnaire Larousse, précise que ce mot définit « ce qui n'est pas toxique » ou « nocif ».Au-delà de l'aspect scientifique et par extension, ce terme, utilisé dans une approche littéraire, désigne également la qualité d'une personne ne causant aucun dommage à autrui et qui, par conséquent, est parfaitement inoffensive.Ce terme dérive du latin innocuus qui signifie « qui n’est pas nuisible », la racine noc correspondant à l'idée de nuisance qui se retrouve dans les mots « innocent », « nocivité » et « nuisance », mais pas dans le terme « inoculer » qui a une origine différente.L'innocuité des aliments (food safety en anglais) est une situation qui, en vertu de mesures appropriées, permet aux aliments consommées par la population humaine ou animale de ne présenter aucun risque sanitaire.Selon le site de l'Autorité européenne de sécurité des aliments (AESA), La présomption d’innocuité reconnue (QPS) se définit comme une « présomption fondée sur des preuves raisonnables » en lien avec la recherche sur les dangers biologiques (BIOHAZ).À la suite de l'identification et de l'évaluation d'un groupe de micro-organismes, lorsque des experts concluent que ceux-ci n'entraînent pas de problèmes en matière de sécurité, le groupe dans son ensemble se voit accorder le « statut QPS ».
Une fois que l'AESA a accordé officiellement le statut QPS à un micro-organisme, ce dernier est inscrit dans la liste des agents biologiques dite « liste QPS ».
Cette liste est actualisée tous les trois ans.L'approche HACCP, système de gestion également utilisée pour évaluer l'innocuité des aliments, consiste à effectuer une série de contrôles sur les points critiques de la chaîne alimentaire.
Ce système permet de faciliter l'inspection par les autorités compétentes dans le contrôle des aliments en renforçant la confiance du consommateur dans l'innocuité des aliments.En 2007, L’OMS souligne qu’il est nécessaire de veiller à l’innocuité des médicaments destinés à l'enfant et que des essais cliniques pour les populations doivent être effectués en tenant compte de l’âge et d'autres facteurs.
Dans un communiqué, l'OMS précise que l'organisation s’attache à « promouvoir l’innocuité des médicaments dans le cadre de son Programme international de pharmacovigilance établi en 1968 ».La Direction des produits de santé commercialisés (DPSC) est un organisme canadien ayant pour mission de surveiller l'innocuité et l'efficacité des produits de santé en vente dans ce pays.L'innocuité des vaccins est généralement liée aux réactions de l'organisme de la personne vaccinée, désignées par les termes « effets indésirables » ou « complications ».
Les effets indésirables du BCG, par exemple, sont habituellement localisés, bénins et ne nécessitent pas de traitement.L'innocuité de certains vaccins à fait l'objet de communications publiques de l'OMS, notamment à propos des vaccins contre l’encéphalite japonaise en juin 2013, des vaccins antivarioliques en janvier 2016, et du vaccin contre le HCV (papillomavirus) en juin 2017.En France, L'INSERM a publié à la fin de l’année 2017 un communiqué afin de convaincre le public de l'efficacité et de l’innocuité pour les enfants des onze vaccins obligatoires en France à partir de 2018.La plupart des adjuvants immunologiques classiques (notamment le phosphate de calcium) ne posent aucun problème à ce niveau.
Hors de cet usage, le mécanisme d’action des adjuvants aluminiques a soulevé de nombreuses questions et interrogations, notamment dans le grand public.
En mars 2016, l’académie nationale de pharmacie, en France, publie un rapport qui conclut à l’absence de lien de causalité entre les adjuvants aluminiques et la survenue de symptômes.De nombreuses enquêtes dans la presse, mais également des études indépendantes, semblent indiquer que certains déodorants utilisant des sels d'aluminium ne présentent pas toutes les garanties prouvant leur innocuité.Dans de nombreux pays, l'usage des ondes électromagnétiques est au cœur d’un débat et de nombreuses controverses en ce qui concerne leur possible danger pour la santé des usagers de téléphone mobile et des riverains d'antenne relais.
Des groupes de chercheurs internationaux ont publié des rapports indiquant des effets néfastes sur les citoyens, bien que la majorité des spécialistes semblent admettre que les ondes électromagnétiques n’ont pas d’impact sur la santé des usagers au niveau de l'usage à court terme, insistant cependant sur le manque d'études quant à leurs effets à long terme.De nombreux pesticides sont classés CMR (Cancérogène, mutagène et reprotoxique) et donc toxiques pour l’ADN ou reprotoxiques (nocifs pour la fertilité), et certaines de ces substances chimiques sont évoquées dans l'éventuelle apparition de nouvelles maladies en lien avec le dérèglement du système hormonal.En décembre 2011, une étude (dite méta-analyse) publiée dans la revue Food and Chemical Toxicology et coordonnée par Agnès Ricroch, scientifique à AgroParisTech, avance que les plantes OGM commercialisées ne présentent pas de risque pour la santé, mais elle a été fortement contestée par d'autres spécialistes.
Les controverses qui s'expriment à l'égard des « OGM » portent essentiellement sur ceux qui relèvent de la définition « restrictive », soit ceux obtenus par génie génétique.L'usage de la matière plastique dans les ustensiles et les objets contenant des produits alimentaires entraîne des questions au niveau scientifique quant à son éventuelle nocivité.Certaines familles d’agents chimiques (dont le bisphénol A) sont utilisées dans la fabrication de plusieurs plastiques et présentent une configuration voisine de celle des hormones.
Ces agents peuvent interagir avec le récepteur de certaines d’entre elles, entraînant une activité hormonomimétique.
Ces produits sont alors qualifiés de « perturbateurs endocriniens », ceux-ci répondant en tant qu'« altéragène biologique, physique ou chimique » à la définition normalisée du mot « polluant » retenue par l'AFNOR en France.
Le paludisme ou la malaria, appelé également « fièvre des marais », est une maladie infectieuse due à un parasite du genre Plasmodium, propagée par la piqûre de certaines espèces de moustiques anophèles.Avec 229 millions de personnes malades et 409 000 décès en 2019, le paludisme demeure la parasitose la plus importante et concerne majoritairement les enfants de moins de cinq ans et les femmes enceintes.
95 % des cas ont été enregistrés dans vingt-neuf pays, notamment en Afrique subsaharienne (27 % au Nigeria, 12 % en R.D.
Congo, 5 % en Ouganda, 4 % au Mozambique) (cf.
section détaillée : « Épidémiologie »).Le parasite du paludisme est principalement transmis, la nuit, lors de la piqûre par une femelle moustique du genre Anopheles, elle-même contaminée après avoir piqué un individu atteint du paludisme.
Le parasite infecte les cellules hépatiques de la victime puis circule dans le sang, en colonisant les érythrocytes (hématies ou globules rouges) et en les détruisant.De nombreuses espèces d'animaux homéothermes sont parasitées par des Plasmodiidae, qui leur sont inféodés.
Sur les 123 espèces connues du genre Plasmodium, seules quatre sont spécifiquement humaines : Plasmodium falciparum responsable d'une grande majorité des décès, et trois autres qui provoquent des formes de paludisme plus bénignes et généralement non mortelles, Plasmodium vivax, Plasmodium ovale et Plasmodium malariae.
L'espèce Plasmodium knowlesi, courante en Asie du Sud-Est mais que l'on croyait jusqu'à une date récente spécifique à différents singes, est désormais reconnue comme affectant aussi les humains, mais de façon généralement bénigne (cf.
« Causes »).La cause de la maladie a été découverte le 6 novembre 1880 à l'hôpital militaire de Constantine (Algérie) par un médecin de l'armée française, Alphonse Laveran, qui reçut le prix Nobel de physiologie ou médecine en 1907.
C'est en 1897 que le médecin anglais Ronald Ross (prix Nobel en 1902) prouva que les moustiques anophèles étaient les vecteurs de la malaria (jusqu'à cette date, le « mauvais air » émanant des marécages était tenu responsable de la propagation de la maladie).Le 6 octobre 2021, l'OMS « recommande l’utilisation généralisée du vaccin antipaludique RTS,S/AS01 (RTS,S) chez les enfants en Afrique subsaharienne et dans d'autres régions où la transmission du paludisme à P. falciparum est modérée ou forte ».Le terme paludisme provient du latin palus, « marais ».Le mot malaria dérive de l'italien mal'aria, « mauvais air ».
Ce terme est très utilisé dans le monde, en particulier par les anglophones et les italophones.On trouve des parasites proches de celui de la malaria chez les chimpanzés, le genre le plus proche de l'humain.
Les chimpanzés abritent un parasite du paludisme, le Plasmodium reichenowi, proche parent du Plasmodium falciparum ; les gorilles abritent quant à eux le Plasmodium falciparum qui pourrait être à l'origine du parasite humain (le séquençage de l'ADN du Plasmodium falciparum dans des fèces de gorille infecté montre par analyse phylogénétique que ce parasite primatophile serait l'ancêtre de la souche qu'on retrouve chez l'humain).Le paludisme affecte les êtres humains depuis le Pléistocène, il y a plus de 50 000 ans et il aurait été un agent pathogène depuis le début de l'histoire de notre espèce.
Cela représente plusieurs milliers de générations d'humains, et le paludisme est considéré comme l'une des maladies les plus mortelles de l'histoire de l'humanité.Une spéculation controversée estime que la moitié de la totalité des humains ayant existé sont morts du paludisme : en seraient morts 54 milliards d'humains sur un total de 108 milliards ayant existé ou existant encore.Les parasites humains et leurs vecteurs (moustiques) ont coévolué avec les groupes humains se dispersant en Afrique et en Eurasie.
La transmission du paludisme a dépendu des espèces de moustiques anthropophiles (piquant préférentiellement l'humain) dont l'extension a toujours été limitée par les conditions environnementales (latitude, altitude…).Une des conséquences de l'ancienneté de cette association co-évolutive est l'existence biologique, dans les populations modernes, d'un polymorphisme génétique sanguin.
La diversité des conditions de peuplement a conduit à une sélection naturelle des gènes de la drépanocytose, des thalassémies, du déficit en glucose-6-phosphate déshydrogénase, de l'elliptocytose héréditaire (appelée dans certains cas ovalocytose).
Ces maladies, qui touchent les globules rouges du sang, donnent un avantage sélectif contre le paludisme (cf.
section détaillée : « Les facteurs génétiques »).Il y a environ 10 000 ans, la propagation du paludisme fut favorisée par le changement climatique, le début de l'agriculture (révolution néolithique) donc la sédentarisation avec poussée démographique.Des fièvres périodiques, évoquant le paludisme, sont signalées dès l'Antiquité dans des textes chinois, indiens, assyriens et grecs.
Les descriptions plus détaillées sont celles d'Hippocrate et d'auteurs de l'Empire Romain.
La théorie médiévale d'une maladie associée aux miasmes provenant de marais reste en vigueur jusqu'au XIXe siècle.En janvier 2010, une équipe de scientifiques égyptiens et américains a prouvé, par l'analyse de l'ADN, que Toutânkhamon était atteint de paludisme au moment de sa mort (vers 1327 av.
En Inde, dès l'antiquité, les Veda (« Textes de la connaissance ») font état des fièvres paludiques ; les médecins Charaka et Sushruta (probablement Ve siècle av.
en font une description et lui associent, déjà, la piqûre de moustique.
Les symptômes de fièvre intermittente ont été décrits par Hippocrate ; il lie ces fièvres à certaines conditions climatiques et environnementales, et les divise en trois types : febris tertiana (tous les trois jours), quartana (tous les quatre jours), et quotidiana ou continua (maintenant appelée tropica).
apparaît, dans certaines régions de Chine, l'utilisation, en tisane, du qing hao su (青蒿素) appelé plus tard artémisinine en Occident et extrait d'une plante médicinale utilisée comme antipyrétique appelée qing hao (青蒿) (Artemisia annua ou « Armoise annuelle »).
D'usage encore plus ancien, les racines du chángshān (常山) (Dichroa febrifuga) ont aussi d'indubitables effets médicinaux.
On trouve ainsi des références à des périodes de fièvre paludique en Chine et à des symptômes de cette maladie dans le Huangdi Neijing (« Le Canon de Médecine ») datant des environs du Ier siècle avant notre ère,.Le paludisme était commun dans des endroits du monde d'où il a maintenant disparu, comme la grande majorité de l'Europe (la maladie d'origine africaine s'étant notamment diffusée dans l'Empire romain) et de l'Amérique du Nord.Dans certains endroits d'Angleterre, la mortalité due à la malaria était comparable à celle de l'Afrique subsaharienne d'aujourd'hui.
Même si William Shakespeare est né au début d'une période plus froide appelée le « petit âge glaciaire », il connaissait suffisamment les ravages de cette maladie pour les citer dans huit de ses pièces.
Plasmodium vivax a sévi jusqu'en 1958 dans les polders de Belgique et des Pays-Bas.Au début du XVIe siècle, ce sont les colons européens et leurs esclaves qui ont probablement amené le paludisme sur le continent américain (on sait que Christophe Colomb était atteint de cette maladie avant son arrivée dans les terres nouvelles).
Les jésuites missionnaires espagnols virent que les Indiens riverains du lac de Loxa au Pérou utilisaient de la poudre d'écorce de Cinchona pour soigner les fièvres.
Cependant, on ne trouve aucune référence au paludisme dans les ouvrages médicaux des Maya ou des Aztèques.
L'utilisation de l'écorce de « l'arbre à fièvre » a été introduite dans la médecine européenne par les missionnaires jésuites dont Barbabe de Cobo qui l'expérimente en 1632 et l'exporte également ; si bien que la précieuse poudre s'appela également « poudre des jésuites ».
En 2012, une étude des marqueurs génétiques de milliers d'échantillons de Plasmodium falciparum confirme l'origine africaine du parasite en Amérique du Sud (les Européens ayant été eux-mêmes affectés par cette maladie par l'intermédiaire de l'Afrique) : il a emprunté entre le milieu du XVIe siècle et le milieu du XIXe siècle les deux routes principales de la traite négrière, la première menant au nord du continent sud-américain (Colombie) par les Espagnols, la seconde aboutissant plus au sud (Brésil) par les Portugais.En 1717, la pigmentation post mortem au graphite de la rate et du cerveau est publiée par Giovanni Maria Lancisi, le médecin du pape Clément XI, dans un ouvrage, édité en 1717, sur le paludisme De noxiis paludum effluviis eorumque remediis.
Il y présente des preuves que la maladie est transmise par les mouches.
Lancisi introduit le mot mal'aria, « mauvais air ».En 1820, Pierre Joseph Pelletier et Joseph Bienaimé Caventou séparent les alcaloïdes cinchonine et quinine de la poudre de l'écorce de « l'arbre à fièvre », permettant la création de doses standardisées des composants actifs.Vers 1832, François Clément Maillot perfectionne le traitement curatif et prophylactique de la quinine.
Ce n'est qu'en 1881 toutefois que son apport est officiellement reconnu à l'occasion du congrès sur le paludisme tenu à Alger.En 1848, Johann Friedrich Meckel (surnommé Meckel le jeune) note un grand nombre de granules noir-bruns dans le sang et la rate d'un patient qui venait de mourir dans un hôpital psychiatrique.
Meckel était probablement en train de voir des parasites de malaria sans le comprendre, car il ne mentionne pas le paludisme dans son rapport, en pensant que le pigment était de la mélanine.En 1878, le Dr Patrick Manson émet le premier l'hypothèse que le paludisme est transmis par un moustique du genre Culex qui absorbe le parasite et pond dans l'eau que l'humain ingurgite.En 1879, l'Allemand Edwin Klebs et l'Italien Ettore Marchiafava annoncent avoir trouvé l'agent responsable de la malaria Bacillus malariae, hypothèse que les découvertes de Laveran feront oublier.En 1880, Charles Louis Alphonse Laveran établit, en Algérie, la relation entre les observations faites par Meckel le jeune et le parasite qu'il observe pour la première fois dans les globules rouges de 44 personnes souffrant du paludisme.
En voyant l'exflagellation se produire, il devient convaincu que les flagelles mobiles sont des micro-organismes parasites (minuscules êtres vivants unicellulaires qui se multiplient végétativement par mitose).
Or bien des médecins de l'époque pensaient encore que les protozoaires n'étaient en fait que des globules rouges altérés.
Laveran doit se battre pour faire admettre sa théorie, car il restait à trouver comment ces organismes s'introduisaient dans le corps humain.
N'ayant pas obtenu un poste lui permettant de poursuivre ses recherches, Laveran prend sa retraite et poursuit ses recherches sur les protozoaires à l'Institut Pasteur en tant que bénévole.
C'est en 1898 qu'il publie son Traité du paludisme.
Il voit aussi l'effet de la quinine, qui détruit ces parasites.
Il suggère que le paludisme est causé par ce protozoaire.
C'est la première fois qu'un protozoaire est identifié comme étant la cause d'une maladie.
Cette découverte lui vaut l'attribution du prix Nobel de médecine en 1907.
Les études scientifiques sur le paludisme viennent de faire leur première avancée significative.En 1880, Ettore Marchiafava et Angelo Celli, à la demande d'Alphonse Laveran, étudient au microscope le cycle de reproduction des protozoaires dans le sang humain, et observent qu'ils se divisent à peu près simultanément à intervalles réguliers et que la division coïncide avec les attaques de fièvre.
En 1885, ils appellent ce protozoaire Plasmodium.En 1881, Carlos Finlay, un médecin cubain qui traite les patients atteints de la fièvre jaune à La Havane, affirme que ce sont les moustiques qui transmettent cette maladie aux humains.En 1886 et 1892, Camillo Golgi publie ses découvertes sur la fréquence et la périodicité des fièvres dues à la malaria, et montre qu'il existe plusieurs types de paludisme causés par des organismes protozoaires différents.En 1891, Paul Ehrlich et Paul Guttman remarquent les propriétés antipaludéennes du bleu de méthylène.
Cette découverte fait suite à celle de Celli et Guarnieri, qui se basait elle-même sur les précédents travaux d'Ehrlich montrant l'affinité de cette substance pour certaines cellules.
Ehrlich veut promouvoir le développement de médicaments en exploitant les différences biochimiques.
C'était la première fois qu'une substance de synthèse était active contre le paludisme (dès 1849, August von Hofmann avait cependant déjà souligné l'intérêt de la synthèse de la quinine à partir de goudron de houille).En 1895, l'expédition française de Madagascar fut un « désastre sanitaire » : sur 21 600 personnes débarquées, 5 731 sont mortes du paludisme et 25 sont mortes au combat.
À noter que ce genre de « désastre » s'est reproduit plus tard, comme pendant la guerre du Viêt Nam pour les soldats nord-vietnamiens (voir l'article sur l'artémisinine).En 1898, Amico Bignami réussit à transmettre expérimentalement le paludisme grâce à des moustiques.
Il n’hésite pas à se faire piquer lui-même et à contracter la maladie.En 1898, c'est le Britannique Ronald Ross, travaillant en Inde et correspondant régulièrement avec Laveran et Manson, mais qui a du mal à imaginer pourquoi l'insecte ne transmet pas directement le parasite par piqûre, qui prouve finalement que le paludisme est transmis par cette piqûre.
Pour confirmer sa théorie, il dissèque, pendant deux ans, des oiseaux paludéens qu'il fait piquer par des centaines de variétés de moustiques.
Ce n'est qu'après ces deux ans, au bord du découragement, qu'il remarque une espèce de moustique qui ne se développe que dans les eaux de surface et ne se voit que la nuit : l'anophèle.
Il continue alors ses recherches ; il récolte et élève les larves et retrouve des protozoaires de Laveran vers le septième jour dans l'estomac de l'anophèle.
La preuve est établie : c'est bien cet insecte qui transmet le parasite vivant à ses dépens.
Il constate qu'une période d'incubation de 10 à 14 jours est nécessaire entre la piqûre et l'apparition des parasites dans le sang.
Il venait de prouver que certaines espèces de moustiques transmettent le paludisme aux oiseaux, en isolant les parasites des glandes salivaires des moustiques qui se nourrissent des oiseaux affectés.
Ceci lui vaut le prix Nobel de médecine en 1902.
Après avoir démissionné des services médicaux indiens, Ross travaille pour l'école de médecine tropicale de Liverpool alors récemment créée, et dirige les efforts d'éradication du paludisme en Égypte, au Panama, en Grèce et sur l'île Maurice.
Jusque vers les années 1930, les chercheurs parlent d'Anopheles maculipennis en général sans faire de distinction claire ou précisément circonstanciée entre les différentes variétés.En 1899, le zoologiste italien Giovanni Battista Grassi, se basant sur les travaux de Ross (sur les oiseaux), fit de même pour le vecteur chez les humains et prouva que le cycle vital du Plasmodium a besoin du moustique comme étape nécessaire.
Grassi, Giuseppe Bastianelli et Amico Bignami décrivent le cycle de développement de Plasmodium falciparum, Plasmodium vivax et Plasmodium malariae chez Anopheles claviger.L'année suivante, les découvertes de Finlay et Ross sont confirmées par une équipe médicale dirigée par Walter Reed ; et les recommandations sont mises en place par William C. Gorgas lors de la construction du canal de Panama.
Les mesures de santé publique ainsi adoptées ont sauvé les vies de milliers d'ouvriers (alors que plusieurs milliers d'autres y étaient morts auparavant) et ont aidé à développer les futures méthodes de lutte contre la maladie.Tandis que les connaissances sur la maladie s'accroissent notamment du fait de la pratique de la malariathérapie — un traitement aujourd'hui désuet — la mise au point de médicaments antipaludiques, et l'utilisation d'insecticides pour lutter contre le vecteur des parasites marquent cette période.
Ces découvertes déterminent l'OMS à lancer le programme mondial d'éradication de la malaria (Global Malaria Eradication Program) en 1955.
Alors que ce programme n'a pas encore atteint son objectif, et tandis qu'une forme latente de parasitose est découverte, la recherche s'oriente vers la mise au point d'un vaccin.Au début du XXe siècle, avant les antibiotiques, les patients atteints de syphilis sont volontairement « traités » en les infectant avec le paludisme, pour leur donner de la fièvre.
Le traitement thérapeutique par le paludisme ou malariathérapie est également l'occasion d'accroître considérablement les connaissances sur la malaria ; il ouvre la voie aux recherches en chimiothérapie et reste pratiqué jusque vers 1950.En 1922, John William Watson Stephens (en) , identifie le 4e parasite connu du paludisme chez l'humain, P. ovale.Dès les années 1930, les chercheurs avaient remarqué la moindre sensibilité des populations noires à la malaria.
En 1949, Émile Brumpt s'étonnait de ne constater aucun cas de malaria au Libéria et au Gabon, à Lagos ou à Stanleyville alors que s'y trouvaient des vecteurs de P. vivax.En 1949, J.B.S.
Haldane suggère que les thalassémiques hétérozygotes seraient plus résistants au paludisme.
En novembre, Linus Pauling, Harvey Itano, S.
Singer et Ibert Wells publient dans le journal Science la première preuve d'une maladie humaine causée par une protéine anormale.
En utilisant l'électrophorèse, ils démontrent que les individus atteints de drépanocytose ont une hémoglobine modifiée, et que les hétérozygotes, qui ont à la fois des formes normales et anormales d'hémoglobine, sont plus résistants aux infections de paludisme.
C'est aussi ainsi que l'on démontre que les lois de Mendel déterminent les propriétés physiques des protéines, et non pas seulement leur absence ou présence : c'est le début de la génétique moléculaire.En dépit de qualités exceptionnelles, la quinine, produit d'importation de pays éloignés, disponible en quantité limitée, présentait le désavantage d'occasionner parfois des effets secondaires ; en outre son administration se devait d'être quotidienne : autant d'incitations à adopter et à rechercher des substituts, ce qu'avait tenté de faire en vain William Henry Perkin dès 1856.
La Première Guerre mondiale, coupant l'Allemagne de l'Inde et de Java - principaux fournisseurs mondiaux de quinine - incita les Allemands à rechercher des substituts à partir de l'observation d'Ehrlich sur l'action du bleu de méthylène.Sont ainsi découverts successivement, la plasmoquine (1926), la quinacrine/Sontochin (1930), la rhodoquine (1931) et le certuna (1935).
Pour ce faire, la recherche allemande s'appuya sur un modèle animal mis au point en 1926 par Roehl.En 1926, des chercheurs allemands découvrent les propriétés antipaludiques du pamaquin/plasmoquine/paraquine.
La structure de ce premier médicament antipaludique dérivé des aminoquinoloéines n'est toutefois divulguée qu'en 1928.
Les chercheurs britanniques, français et russes ont déjà remarqué l'action antipaludique des molécules de la série des amino-8 quinoléines.
Ils se mettent à la recherche d'autres composés actifs.
En 1930, Ernest Fourneau et son équipe mettent au point à l'Institut Pasteur la rhodoquine,,, efficace à des doses très inférieures à celles de la plasmoquine.En Algérie, les frères Edmond et Étienne Sergent durant toute la première moitié du XXe siècle mettent en place à la demande d'Emile Roux une doctrine posant les bases de la lutte anti-paludique en Afrique du Nord.
Ces travaux permettent un recul progressif du paludisme en Algérie et de nombreuses vies sont sauvées.Dans l'Entre-deux-guerres, il y a deux modèles animaux soutenant la recherche d'antipaludiques de synthèse : l'un basé sur le paludisme simien peu pratique à grande échelle, l'autre plus usité, le paludisme aviaire, recourant surtout au canari impaludé par différents types de plasmodium.Dans les mêmes années 1930, aux laboratoires Elberfield de IG Farben en Allemagne, Hans Andersag et ses collègues synthétisent et testent environ 12 000 composants différents et arrivent à produire la résochine, un substitut de la quinine.
Elle est liée à la quinine car elle possède un noyau de quinoline.
Cette résochine (RÉSOrcinate d'une 4-aminoCHINoline : 7-chloro-4-amino]quinoléine) et un composant similaire, la sontonchine (3-méthylresochine) sont synthétisés en 1934 en coopération avec des entreprises américaines, grâce à plus de 2 000 accords entre IG Farben et des compagnies étrangères, comme Standard Oil of New Jersey, DuPont, Alcoa, Dow Chemical, Agfa, Winthrop Chemical Company et d'autres compagnies américaines.
Ce médicament est plus tard appelé chloroquine.
C'est un inhibiteur de la biocristallisation des pigments et l'un des meilleurs antimicrobiens jamais créés.
La quinine comme la chloroquine affecte les parasites de la malaria au début de leur cycle de vie, quand les parasites forment des pigments d'hématine, dérivant de la dégradation de l'hémoglobine.Le proguanil est découvert en 1944 par Curd, Davey et Rose, chercheurs britanniques d'Imperial Chemical Industries.
La pyriméthamine, enfin, est mise au point entre 1950 et 1952 par le laboratoire Burroughs-Wellcome.
Associée à la sulfadoxine dans les années 1970, elle compose le Fansidar.Dans les années 1950 et 1960, les antipaludiques de synthèse, dont le coût de fabrication est très faible, tendent à remplacer la quinine d'extraction, plus chère.Pendant la guerre du Viêt Nam, en réponse à une demande expresse des « Việt Cộng », une étude systématique de plus de 200 plantes médicinales chinoises est entreprise sous la direction de la pharmacologue Tu Youyou et de son groupe de recherche à Pékin en 1972.
Le qing hao su (青蒿素), appelé artémisinine en Occident, est extrait à faible température dans un milieu neutre (pH 7) de plantes de qing hao (青蒿) séchées, d'après les instructions de Ge Hong.
Celui-ci était le premier, au IVe siècle, à recommander l'utilisation de qing hao pour le traitement de « fièvres intermittentes » dans son Manuel de prescriptions pour urgences médicales.
Il recommande de faire tremper les feuilles et les branches de l'armoise pendant une nuit, d'extraire le jus amer et de le boire directement.
Actuellement, on utilise des dérivés en combinaisons: l’artéméther en combinaison avec la luméfantrine, l'artésunate-amodiaquine, la dihydroartémésinine-pipéraquine.Les premières cultures in vitro du parasite à leur phase sanguine sont réalisées en 1976 par Trager et Jensen, ce qui facilite considérablement le développement de nouveaux médicaments.Les propriétés insecticides du DDT (dichloro diphényl trichloro-éthane) sont établies, en 1939 par Paul Hermann Müller travaillant à Geigy Pharmaceutical à Bâle en Suisse grâce au pyrethrum fait de pyrèthre de Dalmatie (plante de la famille des chrysanthèmes) écrasé.
L'épandage de DDT est une méthode standard de protection contre les insectes.
Cependant, en raison de l'impact environnemental du DDT et de la résistance développée par les moustiques, le DDT est de moins en moins utilisé, surtout dans les zones où le paludisme n'est pas endémique (cf.
section détaillée : « Les moyens de combattre le moustique ou de s'en protéger »).En 1948, Paul Müller reçoit le prix Nobel de médecine.Dans les années 1920, des chercheurs américains injectent du sang de singes de différentes espèces à des humains pour déterminer l'éventualité d'une transmission du paludisme du singe à l'humain.En 1932-33, Sinton et Mulligan mettent en évidence la présence de Plasmodium gonderi chez des Cercopithecidae.
Jusque dans les années 1960 on n'avait qu'exceptionnellement constaté en Inde l'infection naturelle des singes pourtant déjà utilisés en nombre à des fins de recherche.Pourtant on savait déjà depuis 1932 que P. knowlesi pouvait être transmis à l'humain par le biais de sang simien infecté.
La question de la transmissibilité à l'humain du paludisme simien, considérée notamment dans le cadre d'un programme d'éradication, reprit de l’intérêt en 1960 quand fut mise en évidence, fortuitement, la possibilité d'une transmission (via un moustique) de la malaria d'un singe vers un humain.
En 1969, la souche Chesson de Plasmodium vivax fut adaptée pour la première fois à un primate non humain.Depuis 2004, P. knowlesi connu pour être responsable du paludisme simien, a été reconnu responsable d’infections humaines qu'il est recommandé de traiter comme P. falciparum.Bien que les différentes étapes sanguines et le vecteur du paludisme (l'anophèle) aient été identifiés dès le XIXe siècle, ce n'est qu'en 1980 que la forme latente (cycles exo-érythrocytaires secondaires qui vont entretenir dans le foie la parasitose pendant 3 à 5 ans ou plus pour P. vivax, 2 ou 3 pour P. ovale et pendant la vie entière pour P. malariae) du parasite dans le foie a été observée.
La découverte de cette forme latente du parasite explique enfin pourquoi des individus apparaissent guéris du paludisme mais rechutent plusieurs années après que le parasite a disparu de leur sang (cf.
section détaillée : « Phase hépatique »).Le prix Nobel de médecine 2015 a été attribué à l'Irlandais William Campbell, au Japonais Satoshi Ōmura et à la Chinoise Tu Youyou pour leurs travaux concernant le traitement des maladies parasitaires dont le paludisme.La conception de vaccins efficaces est rendue très difficile par le fait que la protéine permettant au parasite de s'ancrer aux parois des vaisseaux sanguins de son hôte est codée par un gène var présent à 50-60 exemplaires différents (employés successivement), et que des parties de ces gènes changent de place dans les chromosomes au fil des divisions (une tous les deux jours), créant ainsi de nouveaux variants desdits gènes.
Le premier vaccin antimalarique, le SPf66, basé sur un peptide synthétique, a été mis au point en janvier 1986 par Manuel Elkin Patarroyo.
Son efficacité était toutefois assez faible voire nulle vis-à-vis de P. falciparum.Actuellement trois types de recherches de deuxième génération sont basées sur les antigènes issus des différents stades du cycle évolutif parasitaire :Depuis 1992, GlaxoSmithKline Biologicals développe à Rixensart en Belgique un vaccin antimérozoïte dit RTS,S.
En décembre 2005, le professeur Pedro L. Alonso de l'université de Barcelone juge les premiers résultats encourageants (efficacité dès la 1re injection dans 30 % des cas, diminution de 50 % des crises graves.
Du 26 mai 2009 à 2013, il a subi la phase III des essais cliniques, qui a montré une supériorité de RTS, S/AS01 sur les autres adjuvants.
Il est préparé à partir de peptides parasitaires de synthèse et de protéines recombinantes ou d'ADN (découvert dans les mitochondries et les apicoplastes de Plasmodium).
Sachant que le parasite, pour pénétrer les hématies, prend la forme d'une protéine et est capable de muter une soixantaine de fois pour tromper le système immunitaire, cette piste utilise deux protéines recombinantes qu'elle fusionne :RTS, S/AS01 a reçu un avis favorable de l'EMA en juillet 2015.
Il est commercialisé sous le nom de Mosquirix et protège aussi contre l'Hépatite B. Un pilote de l'OMS est prévu début 2018 avec le Ghana, le Kenya et le Malawi.
La protection qu'il confère diminue avec le temps, chutant à 30 % en trois à quatre ans.
En août 2021, après trois ans d'essais cliniques au Burkina Faso et au Mali sur environ 6 000 enfants de 5 à 17 mois, une étude conclut que combiner une dose de rappel du vaccin « RTS, S » de GSK (juste avant la saison des pluies) à des antipaludiques (sulfadoxine-pyriméthamine ou amodiaquine), dope considérablement l'efficacité de ce vaccin.
Selon Brian Greenwood, cette synergie vaccin-médicament évite 90 % environ des hospitalisations et décès.D'autres solutions vaccinales font l'objet de recherche :Les généticiens visent plutôt à combattre le parasite, non chez l'humain, mais chez son vecteur, le moustique.En 2000, l'équipe du professeur Andrea Crisanti de l'Imperial College London parvient à créer le premier moustique génétiquement modifié.
En 2003, elle reconnait que si le gène marqueur persiste pendant une trentaine de générations lors de la fécondation entre moustiques modifiés, celui-ci ne subsiste que sur 4 à 16 générations lors d'une fécondation avec un moustique non modifié.Depuis avril 2001, un consortium international vise le séquençage complet du génome d’Anopheles gambiae.
Il est patronné par le Tropical Disease Research (TDR).
Ce séquençage a été confié au Genoscope d'Évry et au Celera Genomics d'Alameda.
Le but est d'identifier les gènes impliqués dans l’immunité du moustique vis-à-vis des parasites des Plasmodium ou dans ses récepteurs olfactifs et gustatifs avec, à terme, la conception de molécules attractives ou répulsives pour le moustique ainsi que cibler les protéases impliquées dans sa réponse immunitaire,.Le 15 juillet 2010, le professeur d'entomologie Michael Riehle annonce avoir réussi à créer avec son équipe à l'université d'Arizona, un Anopheles Stephensi femelle génétiquement modifié capable de détruire les parasites dans son corps et donc incapable de transmettre la maladie.
Les chercheurs étudient maintenant le moyen de remplacer, dans la nature, les populations d'anophèles « normales » par celles issues du laboratoire, en espérant que ces moustiques ne deviennent pas invasifs en transmettant d'autres maladies ou que le parasite ne contourne pas cette résistance.Dans les années 1990, le paludisme était annuellement la cause de 400 à 900 millions de cas de fièvres, et entre 700 000 et 2,7 millions de morts, soit en moyenne un mort toutes les 30 secondes.
En 2012, entre 473 000 et 789 000 personnes sont mortes du paludisme.
La grande majorité des victimes sont des enfants de moins de 5 ans,, les femmes enceintes étant aussi particulièrement vulnérables car le placenta constitue une cible où les parasites (Plasmodium falciparum) peuvent s'accumuler.
Malgré les efforts entrepris pour réduire la transmission de la maladie et améliorer son traitement, il y a eu peu d'évolution depuis le début des années 1990.
La mortalité semble décroître depuis la fin des années 2000 et est estimée à 1,2 million de personnes en 2010.La co-infection avec le VIH n'accroît pas la mortalité, et pose moins de problème que la co-infection paludisme / tuberculose, les deux maladies s'attaquant habituellement à des tranches d'âge différentes : le paludisme est plus fréquent chez les jeunes tandis que la tuberculose atteint davantage les personnes âgées.
Cependant, le paludisme et le VIH contribuent à leur propagation mutuelle : le paludisme accroît la charge virale et l'infection du VIH augmente la probabilité d'une infection de paludisme.Le paludisme est endémique dans les zones intertropicales dans les Amériques, dans de nombreux endroits d'Asie, et dans la plupart de l'Afrique.
C'est toutefois dans l'Afrique sub-saharienne que l'on trouve 85 à 90 % des morts du paludisme.
La distribution géographique de la maladie au sein de grandes régions est complexe, et l'on trouve ainsi des zones paludiques et non paludiques proches l'une de l'autre.
Dans les régions sèches, les périodes de paludisme peuvent être prédites sans trop d'erreurs en utilisant les cartes de précipitation.
À l'opposé de la dengue, le paludisme est davantage présent dans les campagnes que dans les villes.
Par exemple, les villes du Viêt Nam, du Laos et du Cambodge sont pratiquement exemptes de paludisme, mais celui-ci reste présent dans les campagnes.
En 2016, d'après l'Organisation mondiale de la santé, aucun cas de paludisme n'a été recensé au Sri Lanka durant trois années consécutives ; c'est donc le deuxième pays du Sud-Est asiatique, après les Maldives, à avoir éradiqué le paludisme.
La Chine est devenue le 30 juin 2021 le quarantième territoire ayant éradiqué cette maladie.
En Afrique en revanche, le paludisme est présent aussi bien dans les zones rurales qu'urbaines, même si le risque est diminué dans les grandes villes.
Les niveaux endémiques mondiaux de la maladie n'ont pas été cartographiés depuis les années 1960.
Cependant, le Wellcome Trust britannique finance le Malaria Atlas Project afin de rectifier ceci et d'évaluer le poids de cette maladie à l'avenir.Finalement, le paludisme est la maladie parasitaire la plus répandue dans le monde.
Elle est au 1er rang des priorités de l'OMS tant par ses ravages directs que par ses conséquences socio-économiques dont : une improductivité aboutissant à la sous-alimentation et au sous-développement.Jusqu'au XIXe siècle, des épidémies de paludisme pouvaient se produire jusque dans le Nord de l'Europe.
La régression du paludisme en Europe est principalement due à l'assèchement des marais et au drainage des zones humides.
La disparition du paludisme en France a étonné les chercheurs à tel point qu'on a pu parler à ce propos de disparition spontanée, voire de disparition mystérieuse.
Il semblerait que cette disparition ait eu de multiples causes.
Dans des régions comme la Sologne par exemple, diverses innovations agronomiques portant notamment sur les pratiques culturales ont pu à cet égard jouer un rôle appréciable en cumulant chacune leur effet.
La maladie a commencé à régresser, comme ailleurs en Europe, avant l'utilisation de la quinine, qui fut d'ailleurs employée au début de façon inappropriée, trop tardivement ou en doses trop faibles.
L'adoption de la quinine a servi toutefois à accélérer la disparition de la maladie dans les régions où elle était en régression.En 2016, le centre grec de contrôle et de prévention des maladies a interdit le don du sang dans 12 communes du pays pour cause de paludisme, après que l'infection eut été considérée comme disparue durant quarante ans.En France métropolitaine, la malaria n'a disparu que relativement récemment.
La maladie était encore commune au XIXe siècle.
Elle était encore présente en 1931 dans le marais poitevin, la Brenne, la plaine d'Alsace, les Flandres, les Landes, en Sologne, en Puisaye, dans le golfe du Morbihan, en Camargue… Durant tout le Moyen Âge et jusqu’aux XVe – XVIe siècles, le paludisme affectait surtout les campagnes ; ce même lorsque bon nombre de cités étaient établies le long des fleuves pour les commodités de transport, et malgré les crues périodiques de ces fleuves dans bien des endroits.
La Renaissance vit une recrudescence des fièvres, les guerres de Religion forçant les citadins à s’enfermer dans des murailles entourées de fossés aux eaux croupies.
De même à Paris à la fin du XIXe siècle, lors des grands travaux de Haussmann, qui ont occasionné des creusements importants et de longue durée.
Les flaques, mares et autres points d'eau croupie perduraient longtemps, engendrant une pullulation d'anophèles au milieu d'une grande concentration d'humains.
De plus, un grand nombre d'ouvriers venaient de régions infectées et étaient porteurs du plasmodium.En 1802, l'épidémie de Pithiviers a motivé par sa gravité l'envoi d’une commission de la Faculté de médecine.
Elle était due à une très grosse crue, d'ampleur inhabituelle, qui avait couvert d'eau les prairies avoisinantes pendant plusieurs semaines.Cette maladie a été éradiquée de Corse en 1973.
Inconnu du temps de la présence romaine, le paludisme y fut introduit lors des raids vandales.
La Corse connaît sa dernière épidémie de cas non importés à Plasmodium vivax de 1970 à 1973.
Fait notable, en 2006 est survenu un cas autochtone de Plasmodium vivax sur l'île.
Depuis, la quasi-totalité des cas observés en France sont des paludismes d'importation.
Des troupes venant des colonies furent à l'origine des dernières épidémies mentionnées.Les facteurs critiques affectant la propagation ou l'éradication de la maladie ont été les changements de comportements humains (méthodes d'agriculture avant tout, déplacements de population, etc.), le niveau de vie (la pauvreté était et reste la principale cause de mortalité) et la densité de la population (plus la densité humaine est grande et plus la densité de moustiques sera grande).L’usage du quinquina et de la quinine devient courant en seconde moitié du XIXe siècle.
P. malariae, qui y est plus sensible, a disparu avant P. vivax.
Mais les doses employées sont insuffisantes pour empêcher le développement des hématozoaires chez l'humain.Autre facteur déterminant : les méthodes d'élevage changent.
La stabulation permanente augmente, qui permet de récupérer les fumiers.
En 1893, autour de Strasbourg, seules trois ou quatre communes ont encore plus de 12 % de leur superficie utilisable réservée aux pâtures.
Les surfaces en prairies naturelles (humides) diminuent au profit des terres labourées (assainies) – ce d'abord dans les régions d'agriculture riche.
Le nombre de bêtes augmente, ce qui diminue d'autant les attaques des moustiques sur l'humain.Un troisième facteur entre en jeu : l'aménagement du territoire, qui comporte plusieurs aspects.
Une loi est adoptée en 1821 pour le dessèchement des étangs insalubres.
Cette loi a été dans l'ensemble peu suivie ; cependant l'idée était lancée, et les étangs les plus proches des maisons furent les plus nombreux à être comblés (car plus faciles d'accès).
Or les moustiques adultes ne se déplacent pas à plus de 300 m de leur point d'origine.
Cet assèchement a donc certainement été une cause importante de la régression de la maladie.Autre aspect de l'aménagement du territoire : l'accroissement du nombre de fossés et leur meilleur entretien, qui permet de mieux drainer les terres.Dans les Landes et en Sologne la reforestation est un facteur également, les arbres drainant l'eau plus efficacement qu'un couvert végétal moindre.Le type de charrue change : la brabant double, qui permet un labour à plat, donne des sillons moins hauts (donc moins d'eau stagnante dans le creux des sillons en périodes humides) et permet par ailleurs un labour plus profond (donc un meilleur ressuyage des terres lourdes), commence à se répandre à partir de 1850 en Brie, remplaçant la charrue non réversible et ses dérivées qui donnaient des labours en billons.La pratique du chaulage se répand également, qui allège les sols lourds et en facilite donc le ressuyage.
Le marnage contribue à la résorption des eaux superficielles.Toutes ces dispositions agronomiques contribuent fortement à réduire les épidémies de paludisme et autres fièvres.
Au moment de la Première Guerre mondiale, il ne restait plus que quelques foyers très localisés.Le paludisme endémique a complètement disparu en France en 1960.Une quarantaine de personnes en France en vingt ans ont été contaminées dans des aéroports à cause de moustiques qui auraient voyagé dans des avions depuis des zones empaludées.Sur l'île de La Réunion et la République de Maurice, le paludisme était la première cause de mortalité il y a encore 60 ans.
L'éradication de la maladie a été confirmée par l’Organisation mondiale de la santé en 1979.Le paludisme d'importation s'observe principalement chez les voyageurs, migrants et militaires en provenance de pays endémiques.
Il fait l'objet d'une surveillance par un réseau d'une centaine d'hôpitaux volontaires bénévoles en lien avec le Centre national de référence (CNR) du paludisme.Ce paludisme est le reflet de la situation mondiale.
Par sa situation, la France fait office de « sentinelle » de ce qui se passe en pays endémiques, principalement l'Afrique subsaharienne.
Après une amélioration significative autour de la période 1990-2010, la situation mondiale marque le pas.
Selon l'OMS, onze pays ont enregistré une augmentation de cas depuis 2015.La France métropolitaine est le pays industrialisé qui recense le plus grand nombre de cas de paludisme d'importation, avec près de 5 000 cas annuels.
En 2017, 2721 cas ont été déclarés au CNR du paludisme, soit environ 5 220 cas estimés selon la représentativité du réseau de surveillance, en augmentation de 10,3 % par rapport à 2016.Toujours en 2017, 82,8 % des cas déclarés l'ont été chez des sujets d'origine africaine, et pour 95 % d'Afrique subsaharienne.
Sur un total de 59 pays de contamination, 15 pays représentent 92,4 % des cas déclarés.
Les trois premiers sont la Côte d'Ivoire (30 %), le Cameroun (20 %), et la Guinée (plus de 5 %).
Parmi ces pays d'Afrique, certains sont en baisse ou en hausse, selon le nombre de voyageurs ou de militaires provenant de zones où le paludisme baisse ou augmente.Au total, 13 décès ont été déclarés (létalité de 0,48 % sur l'ensemble des cas, et de 3,4 % pour les formes graves).
Le non-respect des recommandations de prévention (absence de protection contre les moustiques et de chimioprophylaxie) est à l'origine de la plupart des cas.
Un effort d'information supplémentaire est nécessaire envers les sujets originaires d'Afrique qui rendent visite à leurs proches dans leur pays d'origine.Le migrant, primo-arrivant d'une zone d'endémie, présente rarement un paludisme en raison d'une immunité acquise.
Cette immunité disparait en moins de 4 ans en France.
Le migrant contracte alors le paludisme lors d'un retour au pays pendant la période des vacances en France, ce qui correspond généralement en Afrique de l'Ouest à la saison des pluies, où la transmission est la plus intense.Après avoir sévi dans la presque totalité du monde habité, le paludisme touche 90 pays (99 pays selon le rapport 2011 de l'OMS), essentiellement les plus pauvres d'Afrique, d'Asie et d'Amérique latine.
Dans les années 1950, le paludisme avait été éradiqué de la majeure partie de l'Europe et d'une grande partie de l'Amérique centrale et du sud par des pulvérisations de DDT et l'assèchement des marais.La dégradation des forêts peut le favoriser ; « une étude réalisée au Pérou en 2006 révèle que le taux de piqûre par les moustiques porteurs de malaria est 278 fois moins élevé dans les forêts intactes que partout ailleurs.
»En 2006, l'Europe a connu de très nombreux cas de paludisme d'importation principalement en France (5 267 cas), au Royaume-Uni (1 758 cas) et en Allemagne (566 cas).
En France, 558 cas sont des militaires, mais la maladie touche également les touristes : sur cent mille d'entre eux se rendant dans une zone impaludée, trois mille rentrent dans leurs pays infectés par l'une des formes connues de Plasmodium, le reste sont des cas importés par des immigrants.L'altitude et la température ambiante sont des facteurs importants dans l'impaludation ou non dans une zone.Le programme mondial d'éradication de l'OMS a été précédé par les projets impulsés et dirigés successivement par l'International Health Board, puis par la Fondation Rockefeller à partir de 1915 mais surtout à compter des années 1920.
Ces deux organismes, émanations de la volonté philanthropique de John D. Rockefeller avaient déjà l’expérience de campagnes d'éradication de l'ankylostomose et de la fièvre jaune.
Rompant avec le consensus préconisant l’administration massive de quinine associée à des mesures de contrôle des populations de moustiques - notamment par des travaux de drainage -, les chercheurs de la Fondation Rockefeller basent dès 1924 leur stratégie sur la seule éradication des moustiques.
Ils disposent alors pour ce faire du Vert de Paris, une substance très toxique, toutefois inefficace sur les moustiques adultes.
L’Italie fut le premier théâtre d'opération à partir de la fin des années 1920, suivi par tous les autres lieux d'intervention de la Fondation dans la région méditerranéenne et les Balkans.
En dépit de résultats mitigés, cette ligne de conduite fut adoptée en Inde de 1936 à 1942.
Là, associées à d'autres, ces mesures aboutirent à des résultats spectaculaires, mais temporaires : en 1941 la situation est semblable à celle prévalant avant le début de ce programme.
La Seconde Guerre mondiale qui suspendit certains programmes leur donna aussi de l'extension : la Foundation Health Commission fut créée en 1942 pour soutenir les efforts des forces armées soucieuses de protéger leurs soldats sur les zones de front.
La mise au point du DDT, à laquelle les équipes de la Fondation participèrent, et la dispersion de cet insecticide à partir d'avions dans la zone inondée à l'ouest de Rome permirent le lancement de campagnes d'éradication de la malaria en Italie dès l'année 1946.
Le plus fameux de ces programmes eut lieu en Sardaigne de 1946 à 1951.
Basé sur l'utilisation massive du DDT, ce programme aux méthodes et aux conséquences environnementales discutables et discutées, aboutit à l'éradication des moustiques et par voie de conséquence de la maladie, qui y était toutefois déjà tendanciellement sur le déclin.En 1952, la Fondation Rockefeller mit fin à son programme de santé publique, et donc antipalustre, mais après que l'OMS ait créé (en 1948) un programme visant l'éradication du parasite en 1955 dans le monde hors Afrique sub-saharienne et Madagascar.
Les États-Unis, voulant se prémunir contre l'importation du paludisme via l'Amérique du Sud, en furent un acteur majeur ; des considérations politiques — lutte contre le communisme — motivèrent également leur engagement.
Après des succès notables (l'Espagne est le premier pays que l'OMS déclara officiellement exempte de paludisme en 1964), le programme rencontre vite des difficultés ; en 1969 la XXIIe Assemblée mondiale entérine ses échecs mais maintient ses objectifs d'éradication mondiale.
En 1972 un regroupement de pays décide à Brazzaville d'abandonner l'objectif d'éradication au profit d'un objectif de contrôle.
La 31e Assemblée mondiale de l'OMS se rallie à ce changement en 1978 : il ne s'agit plus alors de viser au niveau mondial à l'élimination et à l'éradication du paludisme mais à son contrôle.
En 1992 la Conférence ministérielle d'Amsterdam adopte la stratégie mondiale révisée de lutte contre le paludisme.
Revue par d'autres instances internationales, cette stratégie est définie en 2001 par l'OMS .L’OMS abandonne les procédures de certification d'éradication dans les années 1980 et les reprend en 2004.En 1998 un partenariat RBM (Roll Back Malaria) associe l'OMS, l'Unicef, le PNUD et la Banque mondiale.En 2007 la fondation Bill et Melinda Gates relance un projet d'éradication mondiale, étudié par une multitude de groupes d'expert, des articles scientifiques et aboutissant à des projets de stratégies de santé publique.Mais en 2019, la plausibilité d'une éradication mondiale reste débattue.
En août, l’OMS fait même savoir que selon ses experts, l’éradication du paludisme n'est pas envisageable dans un avenir proche, et que fixer une date limite pourrait saper les efforts contre la maladie, comme ce fut le cas quand l'OMS s'est fixé ce même objectif 64 ans plus tôt (la non-atteinte de tels objectifs peut fatiguer les donateurs et atténuer la volonté et les engagements politiques, et la date butoir peut insidieusement orienter les efforts là où il est plus facile de « faire du chiffre »).
Après 3 ans d'études, un rapport du Groupe consultatif stratégique sur l'éradication du paludisme (SAGme) de l'OMS indique : « Nous ne devons pas préparer le monde à l'échec d'un autre effort d'éradication du paludisme » et recommande de développer de nouveaux outils et approches contre le paludisme, dont en renforçant la couverture sanitaire universelle.
La Commission Lancet sur l'éradication du paludisme, qui réunit 26 universitaires du monde entier, souhaite au contraire fixer une date butoir (2050), principalement pour maintenir l'esprit du défi.On estime que les efforts mondiaux pour combattre et éliminer le paludisme ont sauvé 3,3 millions de vies de 2000 à 2013 en réduisant les taux de mortalité dus à cette maladie de 45 % dans le monde et de 49 % en Afrique.
La lutte contre le paludisme fait partie d'une des cibles de l'objectif de développement durable no 3 de l'ONU.Une étude publiée le 25 décembre 2019 met en avant que certaines populations d’insectes en Afrique ont développé une résistance aux insecticides massivement utilisés sur les moustiquaires.
Ils ont démontré que la surexpression d’une protéine nommée SPA2 dans les pattes des moustiques leurs confèrent une résistance aux insecticides contenant des pyréthrinoïdes.
Les protéines SPA2 se lient aux pyréthrinoïdes et empêchent la diffusion du composé toxique dans leur organisme.
La protéine SPA2 « Sensory appendage protein » fait partie de la famille des protéines chemosensorielles « CSP ».
La découverte de l’effet de cette protéine ouvre la voie à la création d’insecticide de 2e génération contenant des inhibiteurs spécifiques à la SPA2.
Ceux-ci permettront de continuer la lutte contre la propagation de la maladie.Le paludisme est communément associé à la pauvreté, mais il représente aussi une cause majeure de la pauvreté et un frein important au développement économique et humain.
La maladie a des effets économiques négatifs dans les régions où elle est répandue.
Une comparaison du PIB par habitant en 1995, ajustée par parité à pouvoir d'achat, entre les pays touchés par le paludisme et ceux non touchés, montrait des écarts de 1 à 5 (1 526 USD contre 8,268 USD).
De plus, dans les pays où le paludisme est endémique, le PIB pays habitant a cru de 0,4 % par an en moyenne de 1965 à 1990, contre 2,4 % pour les autres pays.
Cette corrélation ne montre toutefois pas que la causalité, et la prévalence du paludisme dans ces pays, est aussi en partie due aux capacités économiques réduites pour combattre la maladie.Le coût économique du paludisme est estimé à 12 milliards USD par an pour l'Afrique seule.
Un cas exemplaire est celui de la Zambie.
Si le budget que le pays consacrait pour lutter contre cette maladie en 1985 était de 25 000 USD, depuis 2008, grâce à l'aide internationale et au PATH (Program for Appropriate Technology in Health), il est de 33 millions répartis sur une période de neuf ans avec comme premier objectif la fourniture de moustiquaires à toute la population.Au niveau individuel, l'impact économique inclut les frais de soins et d'hospitalisation, les jours de travail perdus, les jours de présence à l'école perdus, la baisse de productivité due aux dommages cérébraux créés par la maladie ; pour les États, à ces impacts s'ajoutent des baisses d'investissement et du tourisme.
Dans certains pays particulièrement touchés par le paludisme, la maladie peut être responsable de 40 % des dépenses publiques de santé, 30 à 50 % des patients admis à l'hôpital, et jusqu'à 50 % des consultations.Le paludisme est causé par des parasites du genre Plasmodium, eux-mêmes transmis par les moustiques du genre Anopheles.Le paludisme est causé par un parasite protozoaire du genre Plasmodium (Phylum apicomplexa).
Chez les humains, le paludisme est, essentiellement, causé par P. falciparum (prépondérant en régions tropicales), P. malariae, P. ovale (espèce la plus rare, hormis l'Afrique de l'Ouest) et P. vivax (espèce la moins exigeante en température).P.
falciparum est la cause la plus commune des infections et responsable d'environ 80 % de tous les cas de paludisme ainsi que 90 % des décès.
Les Plasmodium infectent également les oiseaux, les reptiles, les singes, les chimpanzés et les rongeurs (animaux à sang chaud).
On a rapporté des cas d'infections humaines avec des espèces simiesques du paludisme, dont P. knowlesi, P. inui (en), P. cynomolgi, P. simiovale, P. brazilianum, P. schwetzi et P. simium.
Cependant, à l'exception de P. knowlesi, ces infections restent limitées et sans importance au regard de la santé publique.
Le paludisme aviaire peut tuer les poulets et les dindes, mais cette maladie ne cause pas de dommages économiques notables à l'agriculture.
Cependant, depuis qu'il a été introduit par les humains, le paludisme a décimé les espèces endémiques d'oiseaux d'Hawaii, qui avaient évolué, en son absence, sans défense contre celui-ci.Le Plasmodium se présente sous la forme d'un protozoaire très petit (1 à 2 µm selon les formes).
La coloration au May-Grünwald-Giemsa montre qu'il est constitué d'un cytoplasme bleu pâle entourant une vacuole nutritive claire et contenant un noyau rouge et du pigment brun-doré ou noir (hémozoïne).Le cycle évolutif du Plasmodium est assez complexe et nécessite deux hôtes, un hôte intermédiaire : l'humain et un hôte définitif : la femelle hématophage d'un moustique du genre Anopheles (du grec anôphelês signifiant : inutile).
D'un point de vue strictement biologique, le véritable hôte définitif est le moustique (la reproduction sexuée parasitant l'anophèle).
L'humain ne serait qu'un hôte intermédiaire dans son cycle réplicatif.
Néanmoins, pour des raisons anthropocentriques, on considère que le vecteur n'est pas l'humain mais le moustique et par conséquent que cette zoonose est du type zooanthroponose.Seules les femelles d'anophèles sont hématophages.
Les mâles dont les seules activités sont la reproduction de l'espèce et voler de-ci de-là pour se nourrir de sève de plantes et de nectar ne transmettent pas la maladie.Les femelles anophèles se nourrissent de préférence la nuit, et commencent à chercher leur repas au crépuscule, en continuant la nuit jusqu'à ce qu'elles l'aient trouvé.En respirant et en transpirant, les humains et animaux émettent du CO2, et leur corps dégage constamment de la chaleur et de l'humidité (transpiration) ainsi qu'un cocktail de substances potentiellement attractives (comme l'acide lactique) présentes dans l'haleine, la sueur ou le sébum.
Les moustiques femelles (ainsi que d'autres insectes piqueurs) peuvent détecter certaines de ces émanations corporelles depuis de longues distances (ex.
: ±20 m pour le CO2) et sont immédiatement attirés par ces sources.
Les moustiques pourraient être plus souvent attirés après ingestion d'alcool ou par les couleurs foncées et plus spécialement le noir (qui engrange aussi la chaleur).
Ils se déplacent (maximum 2 km) en utilisant leurs capteurs (chémorécepteurs).Il y a longtemps que l’on pense que certaines personnes « attirent » plus les moustiques que d'autres, et des chercheurs ont en outre en 2011 confirmé que les anophèles mâles et femelles ne répondent pas aux mêmes stimuli chimiques et odorants.D'un point de vue écologique et évolutionniste, ou écoépidémiologique, pour mieux se diffuser, ce parasite aurait intérêt à attirer les anophèles femelles vers les humains (ou des animaux) malades du paludisme.
Il est maintenant admis que de nombreux parasites peuvent dans une certaine mesure manipuler le comportement de leur hôte, et notamment chez des espèces préoccupantes pour la santé publique humaine.
Plusieurs études récentes ont montré que, lors des processus de coévolution parasite-hôte, des parasites ont acquis la capacité de modifier l’odeur de leur hôte à leur profit, en attirant des vecteurs.
Il a été confirmé en 2004 et 2005 que les malades de la malaria attirent plus les moustiques que les non-malades (un enfant malade du paludisme attire deux fois plus les anophèles piqueurs qu’un enfant non malade).
Ceci a aussi été démontré en 2013 chez des animaux (oiseaux), mais on ignorait par quel processus.En 2014, une étude montre que des souris de laboratoire infectées par un plasmodium (Plasmodium chabaudii dans ce cas) ont une odeur corporelle qui change très significativement (tant que la souris reste infectieuse), et qui attire plus les anophèles que celle de souris non infectées.En 2015, une autre étude apporte une probable explication à ce phénomène : en laboratoire, dans les cellules qu’ils infectent, les parasites (Plasmodium falciparum) se montrent capables de synthétiser une odeur terpénique attractive pour les anophèles femelles, grâce à leur apicoplaste (organite héritée - par endosymbiose - d'un organisme végétal, algue ou organisme intermédiaire entre l’algue et la bactérie (cyanobactérie).
Cet organite proche des chloroplastes a perdu sa capacité photosynthétique, mais reste capable de métaboliser des terpènes.C’est ce qu’a montré Audrey R. Odom, de l'École de médecine de l'Université de Washington à Saint-Louis, avec ses collègues (notamment de l’Université de Yale), dans une étude publiée par la revue MBIO.
Une partie de cette équipe avait déjà travaillé sur les apicomplexes et montré la capacité des apicoplastes à biosynthétiser des isoprénoïdes.
Une étude précédente n'avait pas détecté de production de terpènes, mais elle était basée sur une faible quantité de plasmodiums.
L’équipe de Saint-Louis a eu l’idée de cultiver cette fois une quantité plus importante de plasmodiums, comparable à celle qui est présente dans un organisme infecté.
La culture a été faite dans des lots de globules rouges humains infectés, dont les émissions gazeuses ont ensuite été comparées à celles de lots identiques mais non infectés, ainsi qu'au gaz trouvé dans les mêmes sachets de plastique mais vides (témoins).
Selon les résultats de cette étude publiés en 2015, seuls les sachets recelant des globules infectés contenaient des terpènes.
Les auteurs ont montré que pour faire cela (comme certaines plantes), P. falciparum mobilise une voie biochimique dite « plastidial isoprenoid biosynthesis pathway » pour synthétiser deux terpènes (limonène et pinanédiol, qui ont respectivement une odeur citronée et une évoquant le pin) et deux autres molécules (dont le rôle éventuel n’a pas été identifié).
Chaque échantillon gazeux provenant d'une culture de cellules sanguines contenant des globules porteurs du parasite contenait au moins l'un de ces deux terpènes.
On savait déjà (démontré en 2012) que ces deux terpènes (produits par les fleurs qui produisent le nectar le plus attractif pour les anophèles mâles) attirent les mâles d’anophèles (même à très faible dose).Des tests complémentaires ont confirmé que les anophèles femelles qui transmettent le paludisme (Anopheles gambiae) sont bien capables de détecter ces terpènes et qu’ils y réagissent, grâce au fait qu’ils contiennent la « machinerie cellulaire nécessaire pour détecter ces composés et y répondre », selon Odom (même si d’autres molécules sont aussi connues pour les attirer ; le CO2 a ainsi été présenté comme un facteur majeur d'attraction, mais on a montré (2014) que des souches d’Anopheles gambiae privées du récepteur au CO2, à la chaleur et à l'acide lactique restent parfaitement capables de localiser un hôte humain pour se nourrir de son sang, ce qui montre que d’autres molécules sont « pistées » par le moustique et le guident dans son choix d’hôte où effectuer son repas de sang.Ceci suggère que les humains (ou les animaux) infectés par le paludisme risquent plus d'être piqués par un moustique, et même d’être piqués plus d'une fois, en contribuant à la diffusion de l’épidémie, mais à la suite de cette démonstration in vitro, il reste encore à démontrer in vivo chez l’humain ou l’animal que ces terpènes sont effectivement relargués par la peau ou l’haleine et que, sous cette forme ou sous une forme modifiée, ils attirent effectivement les anophèles, ce que le laboratoire de St Louis souhaite faire rapidement.Ces informations ouvrent des pistes de nouveaux tests diagnostiques non invasifs pour le paludisme, basés par exemple sur l’analyse de l’odeur de la peau, de l’haleine (à la manière d’un alcootest) ou de la sueur.
Des pistes nouvelles de lutte contre la diffusion du parasite se dessinent aussi : en manipulant l'odeur perçue par le moustique, il serait peut-être possible de limiter l’attrait des anophèles pour les malades du paludisme, ou au contraire de produire des leurres moléculaires permettant de piéger les femelles d’anophèles avant qu’elles ne piquent.Le vecteur du parasite ainsi que son hôte primaire est la femelle d'un moustique du genre Anophèle.
Les jeunes moustiques ingèrent le parasite pour la première fois lorsqu'ils se nourrissent du sang (nécessaire à cette femelle pour sa production d'œufs) d'un sujet humain infecté.
Une fois ingérés, les gamétocytes de Plasmodium se différencient en gamètes mâles et femelles puis s'unissent pour former un zygote mobile, appelé ookinète, qui pénètre la paroi stomacale du moustique pour devenir un oocyste sphérique, dont le noyau va se diviser à de multiples reprises pour former des sporozoïtes.
La durée de cette maturation est étroitement dépendante de la température extérieure.
Par exemple pour P. falciparum : pas de maturation en dessous de 18 °C ou au-dessus de 35 °C, elle est maximale vers 24 °C.
Quand l'oocyste rompt, il relâche les sporozoïtes qui migrent dans le corps du moustique jusqu'aux glandes salivaires d'où ils peuvent, lors d'un nouveau repas de sang, infecter un nouvel hôte humain, en traversant la peau avec la salive,.Mince fuseau de 12 µm / 1 µm, le sporozoïte infectieux injecté à l'humain, lors de cette piqûre par une femelle d'anophèle infectée, circule rapidement (moins d'une demi-heure) dans le sang jusqu'au foie dans lequel il est séquestré en grande partie grâce aux motifs adhésifs de la protéine majoritaire de son enveloppe, la protéine circumsporozoïte ou CSP = Circumsporozoite protein, pour ensuite infecter les hépatocytes.
Cette crise pré-érythrocytaire hépatique qui va durer de 7 à 15 jours pour P. falciparum, de 15 jours à 9 mois pour P. vivax, de 15 jours à X mois pour P. ovale et 3 semaines pour P. malariae permettra au parasite de poursuivre son cycle.
Les sporozoïtes qui n'atteindront pas le foie seront soit éliminés par les phagocytes, soit incapables de poursuivre leur évolution s'ils atteignent d'autres organes.Une première transformation arrondit cette forme « cryptozoïte » (du grec κρυπτός (kruptos) signifiant « caché ») en un élément uninucléé (avec un seul noyau) appelé trophozoïte qui est l'occasion pour le parasite de se multiplier directement (il en est toujours ainsi pour P. falciparum), par schizogonie, pendant une semaine à quinze jours aboutissant à un énorme schizonte (nom donné au protozoaire lorsqu'il devient actif après la phase d'incubation) de 40  à   80 μm.
Ce corps bleu (parce que constitué d'un cytoplasme bleu pâle lorsqu'il est coloré au May-Grünwald-Giemsa) bourgeonne, tout en perdant de sa mobilité, de manière à émettre des vésicules, contenant les jeunes mérozoïtes qui seront transférés dans le sang, initiant ainsi le stade érythrocytaire, c'est-à-dire l'infection des globules rouges.Cependant, certains mérozoïtes de P. ovale ou P. vivax peuvent rester cachés dans le foie plusieurs années, voire la vie entière pour P. malariae, avant de se réactiver en vagues successives.
Il s'agit de cycles exo-érythrocytaires secondaires qui vont entretenir dans le foie la parasitose pendant deux ou trois ans pour P. Ovale, 3 à 5 ans ou plus pour P. Vivax et pendant la vie entière pour P. Malariae.
Cette phase du parasite est appelée « phase dormante ».
Ces parasites latents intra-hépatiques sont appelés « hypnozoïtes » (du grec Ὕπνος qui est Hypnos l'antique dieu grec du sommeil).Les vésicules sont libérées dans les sinusoïdes hépatiques (vaisseaux capillaires du foie faisant la jonction entre celui-ci et le réseau sanguin) pour rejoindre ensuite la circulation sanguine et y répandre un flot de jeunes mérozoïtes « pré-érythrocytaires » prêts à infecter les globules rouges.
Chaque cellule de foie infectée contient environ 100 000 mérozoïtes (chaque schizonte est capable de produire 20 000 mérozoïtes).
C'est une véritable technique de « Cheval de Troie » qui est ici utilisée pour passer des cellules hépatiques au sang.
L'imagerie in vivo a montré en 2005-2006 chez des rongeurs que les mérozoïtes étaient capables de fabriquer des cellules mortes leur permettant de quitter le foie pour la circulation sanguine en échappant ainsi au système immunitaire).
Ils semblent à la fois guider ce « véhicule » et s'y cacher en masquant les signaux biochimiques qui alertent normalement les macrophages.
Il y a peut-être là une piste nouvelle pour des médicaments actifs ou un vaccin anti-stade exo-érythrocytaire avant le stade de l'invasion des globules rouges.Au début de la longue phase sanguine : les mérozoïtes s'accolent aux globules rouges, les envahissent, s'y développent en trophozoïtes puis s'y divisent (schizontes).En 2011, une équipe internationale a découvert que parmi les récepteurs de surface du globule rouge permettant l'entrée du parasite, l'un d'eux est indispensable à cette pénétration (confirmé avec toutes les souches testées en ce qui concerne P. falciparum) ; ce récepteur devient de ce fait une cible pour de futures recherches d'un vaccin.En se diffusant, les mérozoïtes font éclater les globules rouges (c'est l'hémolyse).L'éclatement des schizontes mûrs ou « rosaces » termine le premier cycle schizogonique érythrocytaire en libérant dans le sang, une nouvelle génération de plasmodiums, les mérozoïtes « érythrocytaires » capables de réinfecter d'autres globules rouges.Une succession régulière de cycles semblables va suivre, qui seront progressivement remplacés (les défenses immunitaires s'organisant) par des cycles érythrocytaires gamogoniques préparant les formes sexuées.
Les trophozoïtes arrêtent de se diviser et modifient leur rapport nucléo-plasmatique.
Ces formes de trophozoïtes avec un noyau volumineux et un cytoplasme densifié sont des gamétocytes mâles et femelles, qui vont demeurer en attente dans le sang.Les parasites lors de cette phase n'ont aucune chance de survie dans l'être humain : ils restent vivants une vingtaine de jours puis disparaissent.
Ils ne pourront poursuivre leur évolution que chez le moustique.
À ce moment si un anophèle femelle pique une personne malade, il absorbe des gamétocytes contenus dans le sang, et un nouveau cycle, sexué cette fois, débute dans le moustique.
Les sporozoïtes produits par cette reproduction passent dans la salive du moustique, qui peut infecter un nouvel hôte, et ainsi de suite…Les hématozoaires inoculés par le moustique se localisent et se multiplient d'abord dans le foie.
Cette phase définit une période d'incubation minimale, sans aucun symptôme.Les manifestations cliniques du paludisme apparaissent au début de la phase sanguine, lorsque la parasitémie dépasse un seuil, variable selon les individus.
Cette multiplication asexuée des plasmodiums à l'intérieur des hématies fait du paludisme, au sens propre, une maladie parasitaire des globules rouges.La lyse des hématies parasitées (éclatement des schizontes mûrs ou rosaces) libère de nouveaux parasites (mérozoïtes) qui contaminent à leur tour d'autres hématies.
Cette destruction entraine aussi une libération des déchets du métabolisme plasmodial (pigments et débris cellulaires du globule rouge, ou hémozoïne), ces substances pyrogènes perturbent le fonctionnement de l'hypothalamus (production de cytokine comme le TNFα) et causent de fortes fièvres.Les premiers cycles sont d'abord asynchrones (paludisme de primo-invasion, avec fièvre continue ou anarchique), puis ils se synchronisent selon un rythme périodique, en fonction de l'espèce de Plasmodium.
Le temps qui s'écoule entre la pénétration d'un parasite dans un globule rouge et l'éclatement de celui-ci est assez constant et atteint chez l'être humain 48 heures pour P. vivax, P. ovale et P. falciparum (fièvres tierces), 72 heures pour P. malariae (fièvre quarte) ; et pour P. knowlesi, la dernière espèce confirmée chez l'Homme, 24 heures seulement.En cas de parasitisme intense, la destruction des globules rouges est telle qu'il apparait une anémie hémolytique et un ictère.
L'organisme réagit par une hyperplasie (production accrue) des macrophages, ce qui explique l'augmentation de taille du foie (hépatomégalie) et de la rate (splénomégalie).P.
falciparum se distingue des autres espèces de Plasmodium en ayant la capacité d'effectuer sa phase sanguine au niveau des capillaires viscéraux, notamment du tissu cérébral.
Il peut se former alors des « rosettes » (amas d'hématies saines et parasitées), formations qui adhèrent aux parois des capillaires.
Cette situation peut s'accompagner d'une hypoxie secondaire , de perturbations métaboliques et hydro-électrolytique, de lésion vasculaires (parois des petites vaisseaux) et tissulaires.Non traité, le paludisme par P. falciparum présente un risque vital immédiat (risque de syndrome de défaillance multiviscérale, par exemple).
Les différents paludismes sont susceptibles d'évoluer vers des formes chroniques (formes historiques), avec détérioration progressive de l'état général pouvant aboutir à la cachexie.Après plusieurs années d'infections répétées, l'hôte du Plasmodium peut acquérir une immunité, appelée prémunition (symptômes atténués d'une maladie qui protège contre une infection ultérieure de type sévère).
On constate une grande variabilité des réponses à l'infection palustre entre des individus vivant dans les mêmes zones d'endémie.
Dans des régions où la transmission est forte, une grande proportion des enfants sont souvent porteur de parasites de P. falciparum sans déclarer aucun symptôme ; c'est l'immunité clinique.
Avec l'âge et les contacts successifs être humain/parasite s'installe peu à peu cette prémunition, qui fait appel à des mécanismes de résistance à l'infection parmi lesquels les protéines « interférons » métabolisées et excrétées, entre autres, par le foie jouent un rôle majeur dans l'immunité anti-parasite.
On parlera, alors, de tolérance à l'infection ou d'immunité anti-parasite.
Une hypothèse est que le Plasmodium a besoin de fer pour se développer ; le déficit en fer dû à une première infection apporterait une protection relative et éviterait une « superinfection ».On dit souvent que cette immunité n'est pas stérilisante car il n'a jamais été démontré de façon formelle de disparition totale des parasites de P. falciparum en l'absence de traitement.
On dit aussi que cette immunité est labile car la prémunition disparait en l'absence de contacts fréquents entre l'être humain et le parasite (elle disparait après 12 à 24 mois si le sujet quitte la zone d'endémie) ainsi que chez la femme enceinte.Par ailleurs, l'immunité dirigée contre P. falciparum est fortement spécifique de la ou des souches parasitaires présentes.Ces particularités de la réponse immunitaire contre le paludisme sont à l'origine des difficultés pour élaborer un vaccin.Des facteurs génétiques peuvent protéger contre le paludisme (voir : avantage hétérozygote).
La majeure partie de ceux qui ont été décrits sont associés aux globules rouges.
En voici quelques exemples :D'autres facteurs génétiques existent, dont certains sont impliqués dans le contrôle de la réponse immunitaire.Le paludisme se manifeste par des accès de fièvre ou « accès palustres ».
Classiquement, il est habituel de décrire l'accès de primo-invasion survenant pour la première fois chez un patient « naïf » (n'ayant plus d'immunité contre le paludisme, ou n'ayant pas rencontré le parasite auparavant), et les accès palustres récurrents survenant chez les sujets déjà infectés par le Plasmodium.En pratique moderne, on distingue les accès simples et les formes graves.
Les accès simples sont susceptibles de se transformer en forme grave (surtout ceux à P. falciparum), non diagnostiqués ou non traités, ils peuvent aussi évoluer en formes chroniques.
Aussi, la suspicion d'un accès palustre est considérée comme une urgence diagnostique et thérapeutique.L'incubation est de 7 jours minimum jusqu'à 3 mois, selon les types de Plasmodium.La primo-invasion par des Plasmodium autres que falciparum peut être non ou peu symptomatique, passant inaperçue.
Sinon, le premier accès palustre est commun à toutes les formes de Plasmodium.
Il survient chez le patient non immun : adulte ayant perdu son immunité en résidant dans une zone non-endémique, ou voyageur arrivant en zone endémique, ou enfant né et atteint pour la première fois en zone endémique.La fièvre est le signe majeur dans 90 % des cas, elle est progressivement croissante jusqu'à plus de 40 °C.
Elle s'accompagne d'un syndrome pseudo-grippal (céphalées, douleurs musculaires ou articulaires) et de troubles digestifs (nausées, vomissements, diarrhées, etc.).
Chez l'enfant, les signes digestifs peuvent être dominants (tableau de gastro-entérite fébrile, etc.).Cette fièvre est continue ou anarchique (pas de périodicité), car les cycles érythrocytaires ne sont pas encore synchronisés (cycles asynchrones).La « crise de paludisme » est caractérisée par des accès fébriles intermittents.
Classiquement, chaque accès comporte 3 phases :Ces accès se répètent régulièrement, en fonction des cycles érythrocytaires.
Classiquement, on distingue la fièvre tierce (c'est-à-dire survenant tous les deux jours) due à Plasmodium vivax et Plasmodium ovale (fièvre tierce bénigne) et Plasmodium falciparum (fièvre tierce maligne) de la fièvre quarte (c'est-à-dire survenant tous les 3 jours) due à Plasmodium malariae (le terme « malaria » désignait spécifiquement la fièvre quarte).En absence ou insuffisance de traitement, ces accès palustres peuvent se répéter pendant des mois voire des années, avec P. ovale, P. vivax et surtout avec P. malariae, sauf s'ils sont correctement traités et en l'absence de réinfestation (cas du paludisme d'importation, en général).Avec P. falciparum, l'évolution est plus courte, mais avec des risques élevés de formes létales.P.
ovale et P. vivax sont très proches et ont été longtemps confondus.Il existe des infections mixtes par deux espèces de Plasmodium dans environ 3 à 4 % des cas.
Par exemple une co-infection par P. ovale et P. vivax réalise une superposition de cycles de deux populations de parasites, se manifestant par des accès palustres journaliers ou malaria tertiana quotidiana.
Elle était aussi appelée fièvre double tierce.D'où l'existence de nombreuses variantes à dénominations historiques telles que : fièvre demi-tierce (accès quotidiens alternativement faibles et intenses), fièvre double quarte (accès deux jours consécutifs séparés par un jour sans).
Les fièvres pseudo-palustres sont des fièvres intermittentes dues à d'autres causes que le paludisme.Le paludisme grave est dû très majoritairement à P. falciparum et survient généralement 6 à 14 jours après l'infection.
Il peut apparaître d'emblée, ou après un traitement inadapté ou tardif.Au XXIe siècle, il se définit par des critères cliniques et biologiques, internationaux (OMS) ou nationaux, régulièrement révisés.
En France 2017, les principaux critères d'un paludisme grave d'importation de l'adulte, sont :D'autres critères, moins fréquents mais indicateurs de gravité, sont les défaillances respiratoire et cardiocirculatoire et les états biologiques d'acidose et d'hyperlactatémie.Non traité, le paludisme sévère peut progresser rapidement et entrainer le coma et la mort en quelques jours voire quelques heures, surtout chez les jeunes enfants et les femmes enceintes qui sont particulièrement vulnérables.
D'où l'intérêt d'un diagnostic d'urgence sans retard de traitement.
Dans les cas les plus graves, le taux de mortalité peut dépasser 20 %, même avec un traitement correct sans trop de retard.Des formes graves à P. vivax peuvent se voir, notamment en Asie du Sud-Est, les principales complications sont alors respiratoires.
Le paludisme à P. knowlesi se présente le plus souvent comme un accès simple, mais il peut évoluer sous une forme grave (mais sans atteinte cérébrale).Un infarctus de la rate, ou une rupture de rate peut se voir avec toute espèce de Plasmodium, plus souvent P. falciparum et P. vivax.Il s'agit d'un accès palustre grave dominé par des manifestations neurologiques, le neuropaludisme étant lié à l'atteinte des capillaires du cerveau.
C'est la cerebral malaria des anglo-saxons, et historiquement chez les francophones l'accès pernicieux.Vers la fin du XXe siècle, les experts de l'OMS ont élargi la notion d'accès palustre grave, à d'autres manifestations autre que neurologiques, pour des raisons pragmatiques (même gravité du pronostic, même urgence du même traitement).
Aussi au XXIe siècle, les termes d'accès ou de forme grave (français), ou de severe malaria (anglais) sont plus souvent utilisés que neuropaludisme ou cerebral malaria, plus restrictifs.L'accès pernicieux survient progressivement ou brutalement.
Il associe fièvre et troubles de la conscience.
Des convulsions sont localisées ou généralisées à l'ensemble du corps, surtout chez l'enfant, et dans seulement 50 % des cas chez les autres adultes.
Cela est dû à un mauvais fonctionnement du foie et à une consommation exagérée de sucre par le parasite.
Les femmes enceintes sont particulièrement prédisposées à l'hypoglycémie et à la surproduction d'acide lactique entrainant une augmentation de l'acidité du sang.Les autres signes neurologiques sont variables dans le temps et la localisation.
Ils peuvent s'accompagner d'une anémie, d'une insuffisance hépatique, et d'une insuffisance rénale fonctionnelle et transitoire, ou d'une insuffisance rénale aiguë plus grave.
Un œdème pulmonaire est une complication rare mais grave, de très mauvais pronostic.
Il est mal expliqué, avec un taux de mortalité dépassant 80 %.Il s'agit d'une complication historique, surtout observée entre 1910 et 1940, et devenue rarissime vers la fin du XXe siècle.
Il s'agissait d'un syndrome survenant chez des européens expatriés en zone endémique tropicale, ayant des antécédents d'accès à Plasmodium falciparum, et prenant irrégulièrement de la quinine.Elle est d'origine immuno-allergique liée au médicament, avec hémolyse intravasculaire massive ( éclatement des globules rouges à l'intérieur des vaisseaux).Le début est brutal, survenant dans les heures qui suivent la prise du médicament, avec fièvre et lombalgies, ictère et chute tensionnelle.
L'anémie hémolytique entraîne une hémoglobinurie (présence d'hémoglobine dans les urines, leur donnant une couleur foncée, blackwater fever pour les Anglais, ou urines rouge porto pour les Français).
L'évolution peut se faire vers une insuffisance rénale aiguë par destruction des tubules rénaux (nécrose tubulaire aiguë).La parasitémie est faible ou nulle, ce qui distingue ce syndrome d'un accès pernicieux.Cette fièvre bilieuse hémoglobinurique a pratiquement disparu avec le remplacement de la quinine par des antipaludéens de synthèse tels que les amino-4-quinoléines (comme la chloroquine).
Cependant des cas ont été rapportés avec des médicaments chimiquement proches de la quinine, comme l'halofantrine ou la méfloquine.
Ces trois médicaments sont formellement contre-indiqués chez les sujets sensibles.Toute fièvre justifie la recherche d'antécédents de voyage ; et au retour d'une zone d'endémie palustre, toute fièvre ou histoire de fièvre est un paludisme jusqu'à la preuve du contraire, en raison du risque d'évolution rapide vers une forme grave.
En France, cela concerne principalement les voyageurs migrants au retour d'Afrique subsaharienne, même en cas de chimioprophylaxie (souvent mal prise) ou d'un traitement sur place.Les pièges classiques retardant le diagnostic de paludisme sont la gastro-entérite fébrile, surtout chez l'enfant ; un syndrome grippal en hiver ; l'absence de fièvre (traitement symptomatique inadapté) ; un tableau d'infection urinaire ; un tableau de dengue.La suspicion de paludisme implique, en urgence, un diagnostic biologique de confirmation.Dans de nombreux endroits, même un simple diagnostic en laboratoire n'est pas possible et l'interrogatoire d'un patient fébrile est utilisé comme indication pour poursuivre un traitement antipaludique ou non.
Mais cette méthode n'est pas la plus efficace : au Malawi, l'utilisation de frottis sanguins colorés par Giemsa a montré que les traitements antipaludiques inutiles ont diminué quand les indicateurs cliniques (température rectale, pâleur du lit des ongles, splénomégalie) ont été utilisés plutôt que l'histoire rapportée d'une fièvre (la sensibilité s'est accrue de 21 à 41 %).Le paludisme concernant les enfants est trop souvent mal diagnostiqué (mauvaise anamnèse, mauvaise utilisation des tests de diagnostic rapide) par les soignants de première ligne (membres de la communauté ayant reçu une formation de base leur permettant de prodiguer les soins élémentaires en l'absence de personnel médical qualifié) ; de même il est mal évalué, ce qui se traduit par un traitement inadapté ou insuffisant, empêchant ainsi un traitement efficace.Le diagnostic du paludisme repose sur la mise en évidence du parasite dans le sang.
Il s'agit d'un diagnostic d'urgence qui doit être fait dans les deux heures qui suivent le prélèvement sanguin.La méthode de diagnostic la moins chère (entre 0,40 et 0,70$US par lame), la plus fiable et la plus répandue est l'examen au microscope optique d'un frottis sanguin et d'une goutte épaisse de sang.Le frottis permet d'identifier les caractéristiques uniques de chacune des quatre espèces du parasite d'Homo sapiens car l'aspect du parasite est mieux conservé avec ce prélèvement.
La goutte de sang épaisse permet de parcourir un volume sanguin plus large pour faire le diagnostic et de ne pas passer à côté de Plasmodium.
Ces examens sont à réaliser par un biologiste qualifié et averti.Les renseignements attendus sont :La valeur prédictive négative des deux méthodes associées (frottis et goutte épaisse) n'est pas de 100 %.
Un examen négatif doit être renouvelé dans les 12 à 24 heures, si la suspicion clinique persiste.Lorsqu'un microscope n'est pas disponible, il est possible d'utiliser des tests de détection rapide d'antigènes, qui n'ont besoin que d'une goutte de sang, et qui ne nécessitent pas d'expertise particulière.Ces tests immunochromatographiques (également appelés tests de diagnostic rapide du paludisme ou TDR) peuvent se présenter sous la forme d'une bandelette réactive ou d'un « dipstick ».
Les premiers tests rapides utilisaient le glutamate déshydrogénase (GluDH) de P. falciparum comme antigène cible (pGluDH) mais ils ont été remplacés par ceux utilisant le lactate déshydrogénase (LDH) de P. falciparum (pfLDH), et le HRP2 (pour Histidin Rich Protein 2).La sensibilité des tests utilisés (200 produits disponibles sur le marché) est supérieure à 95 % lorsque la parasitémie est supérieure à 100 par μL de sang, et de 70 % pour les parasitémies plus faibles, et encore moins pour P. ovale.
Leur spécificité est de 90 à 95 %.Dans les pays développés, ces tests rapides sont associés au frottis-goutte épaisse.Cette méthode repose sur la détection des acides nucléiques des parasites par réaction en chaîne par polymérase (PCR), une technique plus sensible et plus spécifique que la microscopie.
Elle permet la détection de parasitémies très faibles, et l'identification précise des espèces de plasmodium (dont la distinction P. Knowlesi et P. malariae).Dans les pays les plus avancés, la PCR tend à devenir la méthode de référence pour le diagnostic de recours (situation de difficultés diagnostiques).
Des méthodes d'analyse plus rapides, comme la PCR en temps réel, avec obtention de résultats en moins d'une heure, sont disponibles dans des laboratoires de référence, et pourraient être compatibles avec un diagnostic d'urgence ou de routine,.Le bilan biologique standard permet d'évaluer un niveau de gravité, et d'aider au diagnostic différentiel : en particulier l'hémogramme, la protéine C-réactive, ionogramme, signes biologiques d'hémolyse, de souffrance hépatique ou rénale.
La prise de sang peut-être utilisée pour le dépistage d'autres infections, notamment virales, selon le contexte et en fonction des recommandations.Une co-infection avec le paludisme est toujours possible, mais la recherche du paludisme est prioritaire, étant donné sa plus grande fréquence et sa gravité immédiate potentielle,.Les complications aiguës et graves ne concernent en général que Plasmodium falciparum, mais celui-ci n'évolue pas en formes chroniques.Les formes subaigues et chroniques de paludisme s'observent lors d'infections à d'autres plasmodium : P. vivax, P. ovale et surtout P.malariae.
La maladie peut réapparaitre plusieurs mois ou années après l'exposition, en raison de la présence latente de parasites dans le foie.
Ainsi, on ne peut pas dire qu'un sujet est guéri du paludisme simplement en observant la disparition des parasites du flux sanguin.
La période d'incubation la plus longue rapportée pour P. vivax est de 30 ans.
Environ un cas de paludisme P. vivax sur cinq dans les zones tempérées implique l'hibernation par les hypnozoites (les rechutes commencent l'année après la piqûre du moustique).Autrefois appelée cachexie palustre, ce paludisme s'observe chez des enfants de 2 à 5 ans en zone d'endémie, chez des sujets expatriés en zone d'endémie sous traitement insuffisant, et chez les migrants ne vivant plus en zone d'endémie.Il associe une altération progressive de l'état général, avec une fièvre intermittente modérée (parfois absente), une anémie chronique avec cytopénie, une splénomégalie modérée (parfois importante).
La parasitémie est très faible, voire indétectable.Autrefois confondue dans un ensemble dit « splénomégalies tropicales », ce paludisme chronique correspond à une réponse immunologique anormale.
Plutôt rare, il se rencontre chez quelques individus qui vivent dans une zone où la malaria est endémique.Il se distingue du paludisme viscéral évolutif par une splénomégalie importante et une hépatomégalie, l'élévation d'un certain type d'immunoglobulines dans le sang (IgM, anticorps anti-palustres) et du nombre de lymphocytes à l'intérieur des sinusoïdes hépatiques.
La parasitémie est le plus souvent indétectable.La biopsie du foie et l'examen au microscope optique permettent de porter le diagnostic.
L'évolution très lente peut être défavorable par rupture de rate, surinfection, ou apparition d'un syndrome lymphoprolifératif malin.Il s'agit d'une complication rénale grave par infection chronique à Plasmodium malariae (responsable de la fièvre quarte, d'où son nom).
Elle survient le plus souvent chez l'enfant en zone endémique, après plusieurs années d'évolution.Le tableau est celui d'un syndrome néphrotique, par dépôt de complexes immunitaires (associations anticorps-antigène) au niveau des glomérules rénaux.La biopsie rénale permet d'identifier la lésion.
Cet examen met en évidence des dépôts de complément (éléments intervenant dans le système immunitaire) et d'immunoglobulines (variété de protéines jouant le rôle d'anticorps).
Le laboratoire détecte chez l'enfant des antigènes de Plasmodium malariae.L'évolution peut se faire plus ou moins rapidement vers une insuffisance rénale chronique, malgré le traitement (antipaludéens et corticoïdes).La grossesse avec infection du placenta par le Plasmodium est plus à risque de complications.
En zone endémique, la grossesse entraîne une diminution de l'immunité antipalustre, tandis que les lésions placentaires provoquent une baisse de la circulation foeto-maternelle.Chez la mère, les accès palustres sont plus fréquents et plus graves (risque d'avortement ou d'accouchement prématuré), et chez l'enfant : mortalité périnatale, anémie, petit poids de naissance.En 2018, près de 11 millions de femmes enceintes ont été exposées au risque de paludisme (en zones d'endémie modérée à forte) en Afrique subsaharienne, avec 872 000 nouveau-nés de faible poids de naissance.
L'Afrique de l'Ouest est la région où l'on trouve la plus forte prévalence des faibles poids de naissance, liés au paludisme durant la grossesse.La fréquence et la gravité des infections en zone endémique dépendent du niveau de transmission palustre.
Dans les zones de faible endémie instable comme l'Inde, ou la région Asie du Sud-Est Pacifique, le risque de formes graves chez la femme enceinte est trois fois supérieur à celui des femmes non-enceintes.
Dans ces régions, plus de 23 % de la mortalité maternelle est due au paludisme.Dans les régions de forte endémie stable comme l'Afrique subsaharienne, la plupart des formes sévères surviennent lors de la première grossesse ou du premier accouchement (femme primipare) alors que les femmes ayant déjà eu au moins une grossesse présentent moins de troubles, même avec une charge parasitaire élevée.
Ce phénomène s'expliquerait par l'acquisition d'une immunité placentaire spécifique par accumulation sélective de P. falciparum dans le placenta.Le passage transplacentaire du Plasmodium de la mère au fœtus est relativement fréquent, mais il se manifeste rarement comme une « maladie », à savoir le paludisme congénital qui survient entre les premiers jours et le premier mois après la naissance.
Son incidence exacte est discutée : il serait très rare en zone d'hyperendémie (moins de 3 pour mille naissances de mères infectées) mais plus commun ailleurs,.Les enfants de moins de 5 ans représentent le groupe le plus affecté par le paludisme.
En 2018, l'OMS estime à 24 millions le nombre d'enfants infectés par P. falciparum en Afrique subsaharienne, dont 1,8 million souffrant d'anémie sévère, et à 272 000 le nombre de décès, soit 67 % de la mortalité mondiale du paludisme.Cliniquement, les accès simples de paludisme chez l'enfant se présentent sous la forme de troubles digestifs et respiratoires, dont la gravité dépend du type de Plasmodium et de l'état génétique, nutritionnel et immunitaire de l'enfant,.Les formes graves, liées à P. falciparum avec parasitémie à plus de 4 %, peuvent combiner un neuropaludisme, une détresse respiratoire, une anémie sévère, une hypoglycémie, et des surinfections bactériennes ; et moins souvent une insuffisance rénale par rapport à l'adulte,.Le neuropaludisme de l'enfant se manifeste le plus souvent par des convulsions, une posture anormale en extension (opisthotonos), pouvant se compliquer d'une hypertension intracranienne évoluant vers un coma avec rétinopathie particulière au paludisme, ce qui permet de distinguer le coma palustre des autres comas.La plupart des enfants sortent du coma en 48 heures sans séquelles, mais 20 % en meurent, et 10 % gardent des séquelles neurologiques ou des retards cognitifs.Il s'agit d'un paludisme d'importation.
En France, pays européen le plus concerné, les enfants représentent 15 % du total des cas notifiés, soit près de mille enfants par an, dont 10 % sont des nourrissons.
Plus de 80 % de ces cas infantiles sont dus à P. falciparum.Les nourrissons atteints sont le plus souvent des migrants de deuxième génération, retournés en vacances au pays d'origine de leurs parents, essentiellement en Afrique subsaharienne.
L'accès palustre chez le nourrisson est plus grave que celui de l'enfant.
Dans les années 2000-2009, l'absence de mortalité chez l'enfant en France indique probablement une prise en charge adaptée dans la grande majorité des cas.En 2014, les États-Unis ont eu 1513 cas notifiés de paludisme d'importation, dont 55 cas de paludisme d'importation chez les enfants de moins de 5 ans (1 cas de paludisme congénital) et 241 cas chez les moins de 18 ans.
85 % des cas infantiles revenaient d'un voyage en Afrique.Les Plasmodiums, résistants à une température de 4 °C pendant plusieurs jours, sont susceptibles d'être transmis par transfusion sanguine de sang conservé et a fortiori de sang frais.Cliniquement, le paludisme transfusionnel ressemble à un paludisme de primo-invasion, mais d'incubation plus longue pour toutes les espèces de Plasmodium, P. falciparum et P. malariae sont le plus souvent mis en cause (respectivement 45 et 30 % en pays non endémiques).En zone d'endémie, le paludisme transfusionnel est fréquent mais bénin en raison de la semi-immunité des receveurs à qui, en outre, il est parfois proposé un traitement antipalustre.La plus forte prévalence de paludisme chez les donneurs de sang s'observe en Afrique.
En utilisant les techniques moléculaires : elle serait de l'ordre de 36 % en Afrique, alors qu'elle est de 4 % en Asie, de 2 % aux Amériques, et de 1 % en Europe.Les critères d'hémovigilance du paludisme sont proposés par l'OMS, et adaptés par chaque pays selon des recommandations nationales.
Quelques pays, comme les États-Unis, se basent sur un questionnaire pour trier les donneurs de sang potentiellement infectés.
D'autres comme la France, le Royaume-Uni ou l'Australie, utilisent en sus des tests sérologiques sur la base de ce questionnaire.Dans les années 1970, en pays non endémiques, deux « épidémies transfusionnelles » notables de paludisme sont survenues dans des pays non endémiques, aux États-Unis par des donneurs vétérans du Viêt Nam, et en 1971 en Espagne : 54 cas de paludisme transfusionnel par P. vivax, liés à une seule banque du sang de Barcelone.En France métropolitaine (centres de transfusion de Marseille et de Nice), dans les années 1960-1970, on constatait une recrudescence d'une telle transmission, liée à une insuffisance de tri de sélection des donneurs de sang.
Au début du XXIe siècle, ce risque est jugé faible, prévenu par l'exclusion des donneurs après un séjour récent en pays endémique (délai de moins de 6 mois, selon les critères européens) et par des tests biologiques (sérologie palustre).Plus précisément en France 2019, les candidats au don considérés à risque sont : 1) les personnes présentant un antécédent de paludisme, 2) les personnes présentant une fièvre non diagnostiquée évocatrice d’un accès palustre dans les 4 mois suivant un retour de zone d’endémie, 3) les personnes ayant effectué un séjour en région à risque, et 4) les personnes natives ou ayant résidé plus de 6 mois consécutifs dans une région à risque.
Les donneurs à risque sont ajournés provisoirement pour le don de sang ; la période d’éviction est de 4 mois ou de 3 ans selon les circonstances.Les produits sanguins le plus à risque sont les concentrés de globules rouges, alors que le plasma, qui ne contient pas d’hématies, est considéré à risque minime.
Les donneurs asymptomatiques dits immuno-silencieux (absence d’anticorps chez certains porteurs chroniques de parasites) représentent un risque résiduel.
En France 2019, la probabilité d'un paludisme posttransfusionnel est de 0,2 à 0,5 cas par million de transfusions, contre 1 à la fin des années 1990.
Entre 2000 et 2019, 4 cas de paludisme post-transfusionnel ont été rapportés en France, tous liés à des dons de sang issus d’une personne originaire d’une zone d’endémie.
Dans trois de ces cas, l’espèce en cause a été P. falciparum et les receveurs contaminés sont décédés.Il peut s'agir d'un paludisme par accident d'exposition au sang, lors de piqûre chez personnel soignant, ou d'échange de seringues souillées entre toxicomanes.L'inoculation peut être volontaire ou « contrôlée ».
Historiquement, l'inoculation de P. vivax ou de P. malariae a été utilisée comme moyen thérapeutique contre la neurosyphilis dans la premier tiers du XXe siècle.À la fin du XXe siècle, l'inoculation de P. falciparum est utilisée aux États-Unis chez des volontaires, lors d'essais de vaccination ou d'études de souches résistantes aux antipaludéens.En 2018, l'inoculation de Plasmodium dite Controlled Human Malaria Infection chez des sujets volontaires est un moyen de recherche expérimentales de nouveaux médicaments ou vaccins contre le paludisme.Dans les zones endémiques, les traitements sont souvent peu satisfaisants et le taux de mortalité global pour tous les cas de paludisme peut atteindre un sur dix.
L'utilisation massive de thérapies dépassées, de faux médicaments et la mauvaise anamnèse des symptômes sont responsables du mauvais bilan clinique.L'endoparasite peut être combattu par différentes molécules soit en traitements curatifs soit en prophylaxie.
Ces différentes thérapies sont plus ou moins efficaces suivant les régions et les taux de résistances acquis car, tout comme le DDT (insecticide le plus utilisé dans les années 1960), les médicaments efficaces il y a trente ans, comme la chloroquine, ne le sont plus aujourd'hui.Pourtant, ces formulations obsolètes sont encore massivement utilisées dans les pays touchés.
Faisant partie du tiers monde, ils n'ont pas les moyens de migrer leur protocole de soins vers un outil plus onéreux comme l'utilisation des ACT (Artemisinin-based combination therapy).
Pendant longtemps, les traitements ont fait appel à la chloroquine, la quinine et la SP (sulfadoxine-pyriméthamine) et dans une moindre mesure la méfloquine, l'amodiaquine et la doxycycline.Ces molécules furent des armes très efficaces pour lutter contre les parasites du paludisme mais leur prescription sans contrôle a favorisé l'émergence de souches résistantes.
Selon l'Organisation mondiale de la santé (OMS), un traitement est efficace si le taux d'échec est inférieur à 5 % ; s'il dépasse 25 %, il faut changer de protocole.La chloroquine a longtemps été administrée en priorité.
En se nourrissant de l'hémoglobine, le parasite la divise en acides aminés, ce qui libère les molécules d'hème contenues dans l'hémoglobine, toxiques pour le parasite lui-même, qu'il transforme et stocke dans sa vacuole digestive sous forme de cristaux inertes.
La chloroquine pénètre dans la cellule infectée et stoppe la transformation protectrice de l'hème en cristaux inertes, faisant s'accumuler ce fer toxique.
Le parasite est ainsi tué par ses propres déchets.C'était un médicament qui présentait de nombreux avantages, notamment son faible coût et l'absence d'effets secondaires.
Aujourd'hui, les soins à base de chloroquine échouent à plus de 25 % dans les pays d'Afrique subsaharienne touchés par le paludisme.
Or, ils sont toujours employés.Cette résistance est due à l'allèle mutant PfCRT (Plasmodium falciparum Chloroquine Resistance Transporter) K76T.
Cette mutation draine la chloroquine hors de la cellule infectée mais entraînerait toutefois une moins bonne adaptation du parasite à son milieu.
Le Malawi est le premier pays africain à avoir abandonné la chloroquine, et ce dès 1993, conduisant à une réapparition des souches sensibles qui redeviennent alors hautement majoritaires.Là où la chloroquine n'a plus d'effet, on utilise un médicament appelé « médicament de deuxième intention » : la SP (comme le Fansidar (sulfadoxine/pyrimethamine (en)) produit par Roche).
Cette molécule contourne la résistance à la chloroquine.
Cinq ans seulement ont suffi pour que des souches résistantes apparaissent.
On adapte alors le traitement en recourant à un « médicament de 3e intention » : la quinine, administrée per os dans les cas bénins ou par perfusion dans les cas aigus.
Mais, ces traitements sont aussi confrontés à de nouvelles résistances de la part du parasite.L’Artemisinin-based combination therapy, en français Thérapie combinée à base d'artémisinine et en sigle ACT, est une thérapie et une prévention tertiaire dans les cas de paludisme simple.
Elle est composée par l'association de deux molécules : une molécule semi-synthétique dérivée de l'artémisinine et une molécule synthétique ayant pour rôle d'augmenter l'effet de la première molécule mais aussi de retarder l'apparition de résistances et, ainsi, de mieux soigner le paludisme.Depuis la réussite, en 2001, de la phase III des essais cliniques de la première ACT jamais élaborée, elle est devenue le seul traitement médical recommandé par l'Organisation mondiale de la santé pour lutter contre cette maladieProduit en assez faibles quantités, les médicaments ACT sont plus chers que la chloroquine.
Un traitement par la chloroquine ou par la SP coûte actuellement entre 0,2  et   0,5 USD par, alors qu'un traitement ACT oscille entre 1,2  et   2,4 USD/, soit cinq à six fois plus.
Pour de nombreux patients, cette différence est le prix de leur survie.
Un prix que bien peu de personnes en Afrique peuvent payer.
Seule une fabrication à plus grande échelle ou une aide financière plus importante des pays riches pourrait faire significativement baisser les coûts de production.Des nouvelles voies sont explorées, dont :De faux médicaments supposément anti-paludiques circulent en Thaïlande, au Viêt Nam, au Cambodge et en Chine ; ils forment une cause importante de la mortalité, qui serait pourtant évitable.
En août 2007, la société pharmaceutique chinoise Holley-Cotec a été obligée de retirer vingt mille doses de son médicament à base d'artémisinine Duo-Cotecxin au Kenya parce que des contrefaçons, en provenance d'Asie, contenant très peu d'ingrédients actifs et incapables d'une quelconque thérapie, circulaient sur le marché à un prix cinq fois moindre.
Il n'existe pas de moyen simple pour les médecins comme pour les patients de distinguer un vrai médicament d'un faux, sans l'aide d'un laboratoire.
Les compagnies pharmaceutiques tentent de combattre les faux médicaments en utilisant de nouvelles technologies sécurisant le produit de la source à sa distribution.Les méthodes utilisées pour empêcher la maladie de se répandre, ou pour protéger les habitants des zones endémiques, incluent la prophylaxie par la prise de médicaments, l'éradication des moustiques et la prévention des piqûres de moustiques.
Pour que le paludisme puisse exister de façon continue à un endroit, il faut une combinaison de facteurs : forte densité de population, fort taux de transmission des humains aux moustiques et réciproquement.
Si un de ces facteurs diminue, le parasite finit par disparaître, comme en Amérique du Nord et en Europe.
Inversement, le parasite peut être réintroduit dans une région et y survivre si ces facteurs y sont réunis.Il n'existe pas encore de vaccin très efficace contre le paludisme mais la recherche progresse.
La technologie à ARN messager utilisée contre le SARS-CoV-2 ouvrant notamment de nouvelles perspectives,,,,,,.Des chercheurs affirment que la prévention du paludisme serait financièrement plus efficace que son traitement à long terme ; mais son coût reste trop important pour les plus pauvres (selon l'économiste Jeffrey Sachs, trois milliards de dollars américains par an seraient nécessaires).
Pour atteindre les objectifs du millénaire pour le développement, l'argent actuellement alloué à la lutte contre le Sida devrait être réaffecté à la prévention du paludisme, ce qui bénéficierait davantage à l'économie africaine.Certains pays (Brésil, Érythrée, Inde ou Viêt Nam) ont réduit leur taux de cas de paludisme.
L'analyse de ces cas montre que de nombreux facteurs ont dû pour cela être réunis : financements, action coordonnée de l'État et des ONG et action concrète des travailleurs sociaux.On peut combattre le vecteur du paludisme (l'anophèle femelle) par plusieurs moyens de prévention, qui peuvent s'avérer efficaces s'ils sont bien mis en œuvre.Le véritable problème de cette prévention est le coût très élevé des traitements pour les populations touchées.
En effet, elle peut être efficace chez les voyageurs, mais les pays en voie de développement, qui sont les principales victimes de cette maladie, peinent à organiser des actions très efficaces.
On peut donner pour preuve l'exemple de l'île de La Réunion où le paludisme sévissait comme dans les autres îles de la région (Madagascar et île Maurice) notamment.
La Réunion étant un territoire français d'outre-mer, le problème du coût trop élevé n'existait pas et la malaria a pu être éradiquée de cette île sans difficulté.Deux modes de prévention sont appliqués dans les pays concernés.
Ils visent d'une part à protéger les populations contre les piqûres de moustiques et, d'autre part, à éliminer ces derniers par la mise en place de moyens divers.
Le but principal de cette prophylaxie est de limiter la population de moustiques vecteurs de la maladie et ainsi de tenter d'éradiquer ce fléau.Dans les années 1960, la principale méthode utilisée pour éradiquer les anophèles femelles était l'utilisation massive d'insecticides.
Le plus utilisé était le DDT (Dichloro-Diphényl-Trichloréthane).
Cette méthode porta ses fruits dans de nombreuses régions où le paludisme fut totalement éradiqué.
L'utilisation intensive du DDT a cependant favorisé la sélection de moustiques résistants.
Cette résistance a été nommée KDR (Knock Down Resistance : « résistance à l'effet de choc »).
En outre, il peut engendrer intoxications et maladies dans la population comme ce fut le cas en Inde où il fut utilisé de manière abusive en agriculture.Le DDT a été interdit aux États-Unis en 1972, puis dans d'autres pays.
Il est classé comme polluant organique persistant depuis 2001, à la suite de la convention de Stockholm.
Néanmoins il a toujours été autorisé pour des raisons sanitaires et cela a été rappelé par l'OMS en 2005 .Les quatre critères d'un polluant organique persistant sont :Pour remplacer le DDT, des moyens alternatifs sont possibles afin de combattre le vecteur du paludisme :Ces mesures ne sont efficaces que sur un territoire limité.
Il est très difficile de les appliquer à l'échelle d'un continent tel que l'Afrique.Chacun, à titre individuel, peut éviter les piqûres d'anophèles par des mesures mécaniques, physiques et chimiques ;rappelons avant tout que l'anophèle a une activité nocturne, commençant à piquer à la tombée de la nuit, et se reposant la journée dans les habitations :Généralement, les produits concentrés entre 25 et 30 % de DEET sont les plus efficaces sur la plus longue période (± 8 h contre les insectes rampants et de 3 à 5 h contre les anophèles).
Ils sont également considérés comme inoffensifs pour des personnes adultes ou des enfants de plus de deux ans si la concentration ne dépasse pas 10 % pour ces derniers.
À proscrire chez la femme enceinte et le nourrisson de moins de trois mois.
Les produits concentrés à plus de 30 % ne sont plus homologués.Les produits commercialisés sont à appliquer à même la peau ou sur les vêtements ou les moustiquaires.
Attention cependant à ce qu'ils altèrent les matières plastiques, certains tissus synthétiques comme le nylon, le caoutchouc, le cuir et les surfaces peintes ou vernies.
Prendre également attention aux yeux et à l'inhalation directe avec les produits en atomiseur ainsi qu'à l'ingestion.
Les applicateurs munis d'une bille seront donc préférés.La résorption transcutanée est de 50 % en six heures et l'élimination sera urinaire.
La partie non éliminée (30 %) sera stockée dans la peau et les graisses.En 2022, des chercheurs de l'Université de Stockholm imaginent un "faux sang" à base de jus de betterave, qui pourrait détourner les moustiques et aider à la prévention du paludisme.Les études ont montré que les produits répulsifs à base d'eucalyptus qui contiennent de l'huile naturelle d'eucalyptol sont une alternative efficace et non toxique au DEET.
En outre, les plantes telles que la citronnelle ont prouvé leur efficacité contre les moustiques.
Une étude ethnobotanique conduite dans la région du Kilimandjaro (Tanzanie) montre que les répulsifs les plus largement utilisés, par les populations locales, sont des lamiacées du genre ocimée l' Ocimum kilimandscharicum et lOcimum suave.
L'étude portant sur l'utilisation d'huiles essentielles extraites de ces ocimées montre que la protection vis-à-vis des piqûres de certains anophèles vecteurs du paludisme augmente dans 83 à 91 % des cas et inhibe, chez l'insecte, son envie de succion dans 71,2 à 92,5 % des cas.D’autres solutions naturelles sont également recommandées.
Ainsi selon une étude conduite par le Ministère santé publique Cameroun, le fait de se frictionner la peau avec des espèces de plantes herbacées bisannuelles de la famille des Amaryllidaceae, telles que les oignons et l’ail permettrait de faire diminuer le taux de piqûres de 71 à 79 %.
Ce type de traitement préventif est fortement recommandé pour les personnes suivant un régime végétarien qui pourraient présenter des carences en fer et en protéines, source de succion chez l’insecte.L'icaridin aussi connu sous le nom de KBR 3023 est un nouveau répulsif de la famille chimique des pipéridines et de force comparable au DEET, mais il est moins irritant et ne dissout pas les plastiques.
Il a été développé par la société chimique allemande Bayer AG et commercialisé sous le nom de SALTIDIN.
La forme en gel avec 20 % de produit actif est actuellement la meilleure.
Attention, malgré tout, tous les effets secondaires possibles vis-à-vis des enfants ne sont pas encore tous connus.Un essai de divers répulsifs, lancés sur le marché, par une organisation indépendante du consommateur a constaté que les produits répulsifs synthétiques, y compris DEET, étaient plus efficaces que des produits répulsifs avec les substances actives naturelles.Ne pas utiliser directement sur la peau mais imprégner les vêtements ou les moustiquaires en prenant garde de ne pas irriter les muqueuses nasales ni d'en ingérer lors de la manipulation.
La durée d'efficacité est d'environ 6 mois (moins sur les vêtements qui subissent frottements, pluie, etc.).
La réimprégnation se fait après lavage au savon.Précaution : Ne pas porter des vêtements imprégnés de perméthrine sur la peau déjà traitée au DEET.Afin de prévenir toute contamination chez les touristes se rendant dans des pays où sévit le paludisme, les chercheurs ont mis en place une technique prophylactique.
Cette technique consiste à utiliser un arsenal thérapeutique de médicaments préventifs (se limitant à la chloroquine, au proguanil, à l'association pyriméthamine-dapsone, à l'association proguanil-atovaquone, à l'association chloroquine-proguanil chlorhydrate, à la méfloquine et la doxycycline) afin d'éviter l'infection en cas de pénétration du parasite dans l'organisme.La prise régulière d'un traitement préventif, en particulier pour les enfants et les femmes enceintes, qui ont un risque accru d'accès de paludisme grave est conseillée pour les courts séjours en zone de transmission intense de paludisme.
Mais en raison de l'accroissement de la pharmacorésistance parasitaire (résistance des parasites aux produits constituant l'arsenal thérapeutique) et des effets secondaires propres aux différents produits, il est de plus en plus difficile d'établir des directives chimioprophylactiques.Les médicaments antipaludéens ne garantissent pas une protection absolue contre l'infection et il est aussi important de se protéger des piqûres de moustiques (moustiquaires, produits antimoustiques) car même si un traitement adapté a été correctement suivi, il est possible de faire une crise de paludisme, parfois d'apparition tardive à cause de la forme hypnozoïte que peut prendre le Plasmodium.En Belgique, des cas de décès dus à la malaria surviennent, chaque année, chez les voyageurs de retour au pays.Au 9 mars 2006, la prévention du paludisme s'organise en trois niveaux, classés selon le niveau de chimio-résistance.
Chaque pays à risque se trouvant ainsi classé dans un groupe.
Bien avant de partir en voyage, il convient de demander l'avis de son médecin car ces traitements sont généralement à commencer à l'avance.La doxycycline (principe actif)La méfloquine ou Lariam (Roche)L'association atovaquone-proguanil comme le Malarone (GlaxoSmithKline) peut être conseillée en alternative à la méfloquine.En tout état de cause, l'avis d'un médecin est plus que souhaitable avant toute médication.Une technologie utilisant le SMS vient d'être testée avec succès en Tanzanie.Cette opération appelée SMS for Life consiste à éviter les ruptures de stocks en médicaments contre le paludisme, le Sida et la tuberculose dans un endroit donné, même le plus reculé, par l'interaction entre un serveur informatique et des téléphones mobiles.Les recherches tant en pharmacologie pour les traitements (cf.
section détaillée « Le futur - La pharmacologie ») qu'en vaccination pour la prophylaxie (cf.
section détaillée « Vaccins ») vont à un rythme de plus en plus accéléré grâce à des sponsors comme le Malaria Vaccine Initiative ou des ONG comme MSF.La prise de médicaments antipaludiques, même en respectant un schéma thérapeutique correct, ne suffit pas à protéger à cent pour cent contre le risque de paludisme.
Il faut aussi se protéger des moustiques, les empêcher d'entrer en contact avec leurs victimes, afin d'éviter la piqûre de l'insecte :L'utilisation de produits répulsifs ou anti-insectes (tels le DEET ou le DDT) et de moustiquaires réduit les risques d'infection, mais une chimioprophylaxie reste indispensable (Nivaquine, Savarine, Lariam, Malarone).
Il est déconseillé de boire de l'alcool en ayant pris ces médicaments.Selon la Ligue contre le paludisme, une famille touchée ne récolterait que 40 % de sa production agricole, du fait des journées de travail perdues.
L'OMS a même calculé que le PIB africain dépasserait de 115 milliards d'euros son niveau actuel, soit 32 % supplémentaires, si l'on avait éliminé le paludisme il y a trente-cinq ans.Sur le plan de la lutte, l'UNICEF estime que le coût moyen annuel des programmes antipaludiques dans chaque pays d'Afrique se monterait à environ 345 000 euros, soit, pour un pays de cinq millions d'habitants, moins de sept centimes d'euros par habitant.Les populations localisées dans des zones impaludées vivant dans leur immense majorité dans la pauvreté, les nouveaux médicaments, nettement plus efficaces mais plus coûteux que les anciens, sont bien souvent au-delà de leurs moyens.Il arrive même parfois qu'un patient ne suive pas entièrement son traitement et, se sentant guéri, qu'il aille vendre ce qui lui reste au marché noir, accélérant ainsi l'apparition de résistances aux traitements (voir chapitre sur la résistance du parasite).D'après les chiffres, le secteur privé consacrait, en 1990 et par victime, 789 dollars pour combattre l'asthme, 3 274 pour le sida (dont le virus concerne autant les pays en voie de développement que les pays développés) et seulement 65 dollars en ce qui concerne le paludisme.
Autrement dit, la somme consacrée à la recherche de vaccins et au développement de médicaments antipaludiques est minime lorsque l'on sait que près de cinquante pour cent de la population mondiale est menacée.De plus, la grande majorité des pays touchés par la malaria n'ont ni les moyens économiques ni les moyens technologiques de développer dans leur pays une réelle recherche dans le domaine médical.
Des pays aux moyens financiers très limités (le plus souvent croulant sous le poids de la dette extérieure), un manque de solide volonté politique, un budget recherche bien inférieur aux attentes et une aide internationale dérisoire comparée aux besoins des populations et au nombre de personnes touchées, rappellent que les conséquences aussi désastreuses de cette maladie du sous-développement ne sont pas entièrement dues à la nature, que l'être humain y est pour beaucoup.Cependant l'OMS a fondé en 2001 un Fonds mondial pour lutter contre la malaria mais aussi contre le SIDA et la tuberculose.Depuis 2003, la fondation Bill-et-Melinda-Gates a également versé plusieurs centaines de millions de dollars, entre autres, à la Malaria Vaccine Initiative, pour lutter contre la maladie.Créé en 2002, le Fonds mondial de lutte contre le SIDA, la tuberculose et le paludisme, ou Fonds mondial, regroupe des financements internationaux en faveur du traitement du paludisme.
Le zona est une dermatose virale, due au virus de l'herpes zoster, le même virus que la varicelle.
L'adjectif s'y rapportant est zostérien.L'affection se complique essentiellement de douleurs qui peuvent devenir chroniques et invalidantes par névrite post-zostérienne.Le zona est une maladie virale due à une réactivation du virus varicelle-zona ou VZV, pour Varicella Zoster Virus, appartenant à la famille des herpèsvirus, qui est le virus responsable de la varicelle.L'allergie à la viande, souvent induite par une morsure de tique semble prédisposer à des allergies à certains vaccins (ex.
contre le zona).Le virus VZV, après la guérison de la varicelle, reste quiescent dans les ganglions nerveux, sans s'intégrer aux chromosomes hôtes.
Le plus souvent à l'occasion d'une baisse de l'immunité (âge avancé, mononucléose, simple stress, SIDA déclaré, certains cancers, etc.), le virus se réactive dans un ou plusieurs ganglions nerveux.
De là, il remonte par les fibres nerveuses jusqu'à la peau (ou les muqueuses selon les nerfs touchés), provoquant une éruption caractéristique de la varicelle.
Cependant, à la différence de la varicelle, la topographie de l'éruption est limitée aux métamères des ganglions dans lesquels le virus s'est réactivé (c’est-à-dire dans une région de peau et/ou de muqueuse bien caractéristique, correspondant au territoire d'innervation du ou des nerfs correspondant aux ganglions nerveux infectés).Les lésions microscopiques de la peau sont identiques à celles de la varicelle (présences de cellules géantes multinucléées avec infiltration de mononucléaires).
Le diagnostic étant habituellement aisé, une analyse histologique n'est en général pas nécessaire.Le facteur de risque principal reste l'âge, probablement par baisse de l'immunité cellulaire.Les trois principales formes de zona sont la forme intercostale, notable par sa fréquence, et les formes ophtalmique et otitique, remarquables par le risque important de complications.L'éruption peut être précédée de quelques jours par des douleurs sur la future zone concernée.
Les lésions sont typiquement unilatérales.Tout comme pour la varicelle, les lésions apparaissent par poussées successives, mais limitées au territoire sensitif touché (topographie radiculaire dans le territoire du ganglion sensitif où la réactivation du virus s'est produite) : il en résulte ainsi des lésions d'âges différents, mélangeant ainsi des microvésicules, vésicules et pustules avec des croûtes sur des placards érythémateux.
Ces vésicules ont des parois et se remplissent d'un liquide purulent.
Les croûtes tombent au bout de sept à dix jours.Contrairement à la varicelle où le prurit est prédominant, le zona est plus souvent marqué par des douleurs, pouvant même se montrer invalidantes dans les territoires atteints (territoire radiculaire), même après la guérison : on parle alors de douleurs post-zostériennes, qui sont à classer dans les douleurs de type neurologique (douleur de désafférentation).
Les douleurs sont aussi décrites comme une sensation de brûlure, d'élancements, de sensation électrique, de sensation de piqûre d'orties.Le cas le plus fréquent est celui du zona intercostal, qui correspond à la réactivation du VZV au niveau d'un ganglion sensitif d'un nerf intercostal.
Il arrive que plusieurs racines nerveuses soient touchées simultanément.
Citons aussi les territoires abdomino-lombaires et pelviens, ainsi que la région cervicale (territoire d'Arnold, C2 et C3) comme régulièrement touchés, avec palpation d'adénopathies satellites.Le zona cervical, C4 et C5, est particulièrement douloureux car il y a une irritation importante des articulations de l'épaule.
Cette douleur est due à l'attaque des nerfs sensitifs par le virus.
Comme le zona thoracique donne des douleurs intercostales.Durée de l'affection : Pour une guérison cutanée complète, il faut compter (sans complication) 3 à 9 semaines ou plus.Il représente environ 10 % des zonas.
Le zona ophtalmique, en absence de soins, peut altérer la qualité de la vue en raison de l'atteinte de la cornée.
La réactivation du virus a lieu au niveau du ganglion de Gasser et atteint le territoire sensitif de la branche V1 du nerf trijumeau, correspondant au nerf ophtalmique.
L'éruption touche le front, le pourtour de l'œil (annexes de l'œil, paupières…) et la cornée, de façon unilatérale.
L'atteinte cornéenne n'est pas visible par un examen direct, et nécessite un examen par lampe à fente et instillation d'un produit de coloration à la lumière bleue.
Le diagnostic différentiel peut être une atteinte herpétique, un érysipèle, une dacryocystite, un eczéma de paupière, etc.Les principales complications du zona ophtalmique sont :C'est une forme très particulière, due à la réactivation du VZV dans le ganglion géniculé et qui touche par conséquent le nerf facial (VIIe paire crânienne), un nerf essentiellement moteur avec donc un risque de paralysie faciale.Ce type de zona débute généralement par une douleur dans la région d'une oreille puis une éruption, inconstante, se produit dans le conduit auditif externe (correspondant à la zone de Ramsay-Hunt (seul territoire d'innervation sensitive cutanée du nerf facial).
Il peut par ailleurs exister des acouphènes (perception de sons qui n'ont pas d'existence réelle) et des vertiges, ainsi qu'une baisse de l'audition.
La classique paralysie faciale peut survenir dès le stade douloureux ou dans les jours suivant l'éruption, avec un risque de persistance, plus ou moins importante.En règle générale, il reste clinique (description des symptômes et aspect des lésions) et il n'y a pas besoin, le plus souvent, de faire d'autres examens.L'antigène viral peut être retrouvé dans les lésions par immunofluorescence.
L'ADN viral peut être, lui, mis en évidence par PCR, ce dernier test ayant une sensibilité proche de 100 %, supérieure à l’immunofluorescence.
L'intérêt de ce test est essentiellement en cas de suspicion de formes viscérales, plus rares et atypiques.La majorité des atteintes par le zona sont tout à fait banales et guérissent spontanément, mais contrairement à la varicelle, le corps ne peut s'immuniser contre les récurrences sous forme de zona et la complication la plus fréquente est donc tout simplement « la récidive » (qui est cependant loin d'être systématique).Il peut cependant survenir des complications plus ou moins graves, dans l'immédiat ou ultérieurement.Une exposition à la varicelle à l'âge adulte en étant déjà immunisé permettrait de diminuer les risques de contracter le zona.Le vaccin contre la varicelle chez le nourrisson n'a pas démontré actuellement une efficacité sur la prévention du zona (essentiellement en raison du manque de recul, la vaccination ayant lieu dans l'enfance et le zona survenant après la soixantaine en général).Un vaccin contre le zona, Zostavax, plus fortement dosé et proche de celui utilisé pour les enfants contre la varicelle, est disponible en Europe,.
Destiné à être injecté chez la personne âgée, il permet de diminuer de près de 50 % le risque de développer un zona, et de 65 % la survenue des douleurs post-zostériennes.
Cette efficacité diminue cependant avec l'âge.Un second vaccin, Shingrix, a été développé par le laboratoire GlaxoSmithKline Vaccines.
Shingrix est un vaccin recombinant totalement différent du vaccin contre la varicelle de l'enfant.
La phase III des essais cliniques a été conclue en 2014, démontrant une efficacité de plus de 97 %.
Shingrix est autorisé en Europe depuis le 21 mars 2018 chez les personnes âgées de 50 et plus.
En mai 2021, Shingrix n'était pas encore disponible en France.
En Allemagne, Shingrix est disponible depuis le début 2018 et pris en charge par les assurances maladie depuis mai 2019.La vaccination par Zostavax n'est pas recommandée chez la personne immunodéprimée, car le risque d'infection par le virus est réel.
Par contre, le candidat-vaccin de GSK Vaccines n'étant pas un vaccin vivant atténué, il pourrait être indiqué chez les personnes immunodéprimées.En cas de greffe de moelle ou chez les malades du sida, l'aciclovir en traitement continu est une prévention possible et démontrée.En janvier 2022, les sociétés Pfizer et BioNTech annoncent vouloir développer un vaccin à ARNm contre le zona.La dernière conférence de consensus française sur le sujet, datant de 1998, pose les bases de cette partie de l'article.Des sensations de brûlure peuvent apparaître à la phase aiguë.
Le traitement du zona est en général purement symptomatique :Si le patient le supporte et qu'il n'y a pas de lésions à vif par grattage, l'alcool à 70° peut être utilisé.En cas de douleurs (brûlures, élancements) :Si la douleur persiste malgré ce traitement et le repos au lit, on peut envisager des opiacés mais seulement pour quelques jours.Les principales molécules utilisées, outre les antalgiques usuels, sont l'amitriptyline (Laroxyl, Elavil), la gabapentine (Neurontin) et la carbamazépine (Tegretol).
L'amitriptyline entraîne une diminution de moitié de l'intensité des douleurs chez 50 % des patients, avec une moindre fréquence des paroxysmes douloureux.
Une combinaison de traitements peut être utilisée.
Il existe aussi des traitements faisant appel à des techniques physiques, comme la neurostimulation transcutanée, ou l'injection intrathécale hebdomadaire de méthylprednisolone + lidocaïne.Antiprurigineux en cas de fortes démangeaisons, l'aggravation des lésions par le grattage entraînant un risque cicatriciel.
On peut prescrire de façon systématique des antihistaminiques (cétirizine, dimétindène, dichlorhydrate d'hydroxyzine).
En local, il y a peu de choses.
Le CBIP se positionne comme suit « antiprurigineux : l'efficacité des préparations contenant un antihistaminique et/ou un anesthésique local est souvent douteuse, et il existe un risque élevé de réactions allergiques.
» Il existe des corticostéroïdes à usage local, mais ils sont dans l'ensemble contre-indiqués en cas d'affection virale.
Il existe une crème à l'extrait de Chamomilla recutita, l'efficacité n'est pas prouvée, elle peut servir comme anti-irritant.
On peut utiliser les mêmes soins que pour la varicelle : compresses d'eau froide.Le traitement antiviral, qui agit directement sur l'agent infectieux responsable du zona, était précédemment réservé aux cas pour lesquels des complications sont à craindre.
Cela concernait essentiellement les patients immunodéprimés et la forme ophtalmique du zona.
Quand il est indiqué, le traitement doit être mis en route le plus précocement possible.La tendance actuelle est de prescrire systématiquement un traitement antiviral, de façon à éviter les douleurs zostériennes, atténuer les symptômes et accélérer la cicatrisation.
Il n'a cependant pas démontré d'efficacité dans la prévention des douleurs post zostériennes.Les molécules disponibles susceptibles d'être actives sur le VZV sont l'aciclovir (800 mg toutes les quatre heures sauf la nuit, pendant au moins sept jours), le valaciclovir (trois prises par jour) et le famciclovir (Oravir).
Le valaciclovir aurait une meilleure biodisponibilité mais est beaucoup plus coûteux.
L'efficacité du traitement est plus marquée s'il est débuté dans les trois premiers jours de l'apparition des lésions, l'idéal serait qu'un patient immunodéprimé connaisse les premiers signes d'apparition du zona, afin de démarrer le traitement le plus précocement possible.
Un traitement dans les 72 heures donne plus de chance dans l'éradication des douleurs zostériennes.Le foscarnet peut être utilisé en cas de virus résistant à l'aciclovir.Le traitement antiviral du zona ophtalmique est systématique.
L'aciclovir ou le valaciclovir, utilisés par voie orale sur une durée d'au moins une semaine, sont indiqués pour éviter les complications oculaires.
Le zona ophtalmique doit être systématiquement pris en charge en urgence par un spécialiste, qui jugera de l'opportunité de traitement complémentaire (aciclovir en pommade ophtalmique) selon le type d'atteinte oculaire.
Les corticoïdes sont formellement contre-indiqués car susceptible de provoquer une flambée de la maladie.
Un collyre mydriatique peut être associé afin d'éviter les synéchies (adhérences) cicatricielles.Le traitement du zona otitique, du fait du risque de persistance d'une paralysie faciale, occasionne un traitement antiviral systématique.
Malgré ce traitement, le risque persiste cependant.
À noter que la corticothérapie est contre-indiquée pour certains en début de traitement.Chez le patient immunocompétent, le traitement antiviral est proposé aux sujets de plus de 50 ans, pour prévenir les douleurs post-zostériennes plus fréquentes à partir de cet âge.
Il fait appel au valaciclovir ou au famciclovir par voie orale pendant 7 jours.Selon le CBIP (Centre belge d'information pharmacothérapique), l'aciclovir et le valaciclovir ont la même efficacité contre le virus Varicella-Zoster.
Le valaciclovir est la prodrogue de l'aciclovir.Chez l'adulte de moins de 50 ans, et dans le même but, certains proposent aussi le même traitement en cas d'éruption très floride, ou de douleurs intenses lors de la phase prodromique ou de la phase éruptive.
En France, le traitement antiviral du zona chez les sujets immunocompétents de moins de 50 ans ne fait pas l'objet d'une prise en charge par l'Assurance maladie, en Belgique seulement en cas de zona ophtalmique.Jean-Pierre Chaumont, Joëlle Millet-Clerc (2011) considèrent que l'aromathérapie constitue un traitement complémentaire appréciable.
Ils citent une formulation du Dr.
Jean Valnet (Tégarome, solution huileuse de 8 huiles essentielles) ou diverses huiles essentielles dont feuille de Ravensara aromatica appliquées en compresse.
Une publication académique (2017) rapporte un cas de dermatose érythémateuse et érosive des bras chez un patient après traitement d'un zona intercostal par huile essentielle Tegarome®.Étant donné que les vésicules et les croûtes du zona, de la même façon que celles de la varicelle, contiennent le VZV, il existe un risque contagieux pour les personnes non immunisées (c’est-à-dire celles qui n'ont jamais contracté la varicelle et non vaccinées) : ces personnes peuvent alors développer une varicelle (et non un zona qui est une réactivation interne d'une varicelle ancienne).
Pour un malade atteint du zona, les personnes à éviter sont donc les très jeunes enfants et les femmes enceintes, ainsi que les personnes immunodéprimées chez qui une varicelle pourrait avoir de graves conséquences.
Noter cependant que les nourrissons qui sont allaités au sein maternel seraient protégés par le caractère immunitaire de ce type d'alimentation.L'incidence annuelle est comprise entre 1,5 et 4 nouveaux cas pour mille.
Elle est beaucoup plus fréquente chez la personne âgée (avec un risque supérieur à 50 % de contracter la maladie après 85 ans) ainsi que chez le patient immunodéprimé (dont SIDA).
Elle tend à augmenter, du moins aux États-Unis.
La surveillance de l'évolution de l'incidence en France est effectuée par le réseau Sentinelles de l'INSERM.La fréquence des douleurs post-zostériennes atteint près de 40 % chez la personne âgée.
Un vaccin contre les infections à papillomavirus humain est un vaccin dont le but est de prévenir les infections dues aux souches sexuellement transmissibles du virus papillomavirus humain (HPV) responsable de plusieurs types de cancers et contre lesquels l'utilisation du préservatif s'avère inefficace.
Ces infections, très répandues, sont généralement bénignes au premier stade, et disparaissent spontanément mais peuvent réapparaître tout au long de la vie une fois la personne infectée et, lorsqu'elles persistent sont responsables de cancers dans environ 5 % des cas.
Le papillomavirus est en effet un agent nécessaire pour déclencher plus de 9 cas sur 10 de cancer du col de l’utérus, mais il est aussi responsable de cancers du vagin et de la vulve, de l'anus, du pénis et de certains cancers de la gorge.
Au total, le HPV ne touche pas que les femmes, plus de 4 cancers sur 10 dus au HPV surviennent chez les hommes.Trois types de vaccins sont commercialisés.
Le vaccin quadrivalent (Gardasil), est dirigé contre les papillomavirus de génotypes 6, 11, 16 et 18.
Le vaccin bivalent (Cervarix) est dirigé contre les génotypes 16 et 18.
En 2018, s'est ajouté un vaccin nonavalent (Gardasil 9, génotypes 6, 11, 16, 18, 31, 33, 45, 52 et 58).Cette vaccination est recommandée par les autorités de santé de 71 pays en complément au dépistage dans le but de faire baisser le risque du cancer du col de l'utérus dus aux génotypes 16 et 18, qui sont parmi les causes connues les plus fréquentes des lésions précancéreuses du col utérin (les génotypes 6 et 11 n'entraînent pas de telles lésions).
Le risque d'apparition de condylomes génitaux (lésions bénignes) est également réduit par le vaccin quadrivalent (les génotypes 6 et 11 sont responsables d'environ 90 % de ces affections).En matière épidémiologique, les résultats d’une méta-analyse sur 60 millions de sujets avec un suivi jusqu'à 8 ans post-vaccination parue en juin 2019 montrent l’impact des programmes de vaccination contre l’HPV sur les infections à HPV, notamment les néoplasies intra épithéliales du col utérin chez les jeunes filles et les jeunes femmes, avec une baisse du taux d'incidence de respectivement 31 et 51 %.
En France, en matière d'innocuité, le rapport bénéfice risque est jugé favorable, sans empêcher des controverses et des réticences à son utilisation.
La vaccination contre le papillomavirus humain est une prévention primaire du cancer de col de l'utérus.
La vaccination par le vaccin nonavalent pourrait réduire de 85 à 90 % le nombre de cancers du col de l’utérus à un horizon de 100 ans.
Les vaccins ne couvrant pas tous les papillomavirus oncogènes, et ne concernant qu'une minorité de femmes, le dépistage des infections doit être maintenu.
La vaccination empêche l'infection mais ne se substitue pas au dépistage d'une infection déjà présente.La recherche qui a conduit à la mise au point du vaccin a débuté dans les années 1980 au sein des universités américaines des universités de Rochester et de Georgetown.
En 1991 deux chercheurs de l'Université du Queensland à Brisbane en Australie trouvent le moyen de former des particules non infectieuses appelées virus-like particles (VLPs), ressemblant au virus et capables d'activer une réponse du système immunitaire.
En 1993, un laboratoire du National Cancer Institute aux États-Unis parvient à concevoir de telles particules d'après le génotype 16 du virus, ce qui ouvre la piste à la création du vaccin, mais débouche également sur des querelles concernant la propriété intellectuelle de la découverte.Le 8 juin 2006, la mise sur le marché du vaccin Gardasil de Merck & Co.
est approuvée aux États-Unis par la FDA pour un usage auprès des jeunes filles et des femmes de 9 à 26 ans.Le 22 septembre 2006, le Gardasil est approuvé par la Commission européenne pour un usage dans l'Union Européenne auprès des personnes de sexe féminin de 9 à 26 ans.La vaccination des jeunes filles avant le début de l’activité sexuelle est considérée par l'OMS comme une intervention de prévention primaire importante dans un programme complet de lutte contre le cancer du col de l’utérus.
Les vaccins ne traitent pas les infections à VPH et les maladies associées au VPH préexistantes, c’est pourquoi il est recommandé de vacciner les jeunes filles avant qu’elles ne commencent à avoir une activité sexuelle.
La quantité d’anticorps produits après la vaccination contre le VPH est plus importante chez les jeunes filles âgées de moins de 15 ans que chez les jeunes filles et jeunes femmes âgées de 15 ans et plus.La vaccination ne remplace pas les tests de dépistage de routine du cancer du col de l'utérus.
« Étant donné qu'aucun vaccin n'est efficace à 100 %, que Gardasil ne protège pas contre les types de papillomavirus non contenus dans le vaccin ou contre des infections déjà existantes dues au papillomavirus, le dépistage en routine du cancer du col de l'utérus reste très important et doit se faire selon les recommandations locales ».La vaccination peut être également proposée aux hommes jeunes, permettant de réduire très sensiblement la survenue de lésions dues au papillomavirus.
Elle pourrait aussi contribuer à la diminution de la propagation du papillomavirus, et ainsi, indirectement, à la prévention du cancer du col utérin.
La rentabilité estimée ne serait cependant pas très bonne (coût supplémentaire par cancer prévenu).
En France, les recommandations de vaccination ont été étendues aux garçons et jeunes hommes .Tous les vaccins contre le HPV sont des vaccins inactivés.
Il ne contiennent pas le virus mais des protéines du virus.Les vaccins diffèrent suivant le nombre de génotypes ciblés du virus (nombre de valences).
Ils peuvent être ainsi bivalents, contre les types 16 et 18 (vaccin Cervarix) ou quadrivalents contre les types 6, 11, 16 et 18 (vaccin Gardasil).
Un vaccin 9-valent, contre les types 6, 11, 16, 18, 31, 33, 45, 52 et 58 est commercialisé depuis 2018, après des phases de test.
Ce dernier serait actif sur les génotypes provoquant près de 90 % des cancers du col utérin contre 70 % pour le vaccin quadrivalent.Comme l'immunité acquise est moins importante chez les jeunes filles de 15 ans ou plus, deux injections sont suffisantes avant 15 ans et trois sont nécessaires après cet âge ..Le vaccin nonavalent est le vaccin recommandé par la HAS en 2019 pour les garçons.Il doit être conservé au réfrigérateur entre +2 et +8 °C et ne doit surtout pas être congelé ni même en contact pour court instant avec de la glace.
Le vaccin est administré par voie intramusculaire.
Le don du sang est autorisé après la vaccination .Les conditions de conservation du vaccin posent un problème logistique pour les pays à faible ou moyen revenu national brut.Tous les vaccins existent sous forme de seringue prête à l'emploi ou à préparer.1 dose (0,5 ml) contient environ : Protéine L1 de Papillomavirus Humain de type 16, 20 microgrammes Protéine L1 de Papillomavirus Humain de type 18, 20 microgrammes Protéine L1 sous la forme de pseudo particules virales non infectieuses produites par la technique de l’ADN recombinant, adsorbé sur hydroxyde d'aluminium hydraté avec adjuvant AS04 (contenant du 3-O-desacyl-4′-monophosphosphoryl lipide A).Ce vaccin a une plus grande capacité que le Gardasil à induire une protection croisée vis-à-vis des HPV oncogènes autres que les HPV 16 et 18.Ce vaccin est constitué de pseudo-particules virales (VLP) qui induisent une réponse immunitaire.Protéine L1 de Papillomavirus Humain de type 6, 20 microgrammes Protéine L1 de Papillomavirus Humain de type 11, 40 microgrammes Protéine L1 de Papillomavirus Humain de type 16, 40 microgrammes Protéine L1 de Papillomavirus Humain de type 18, 20 microgrammes Protéine L1 sous la forme de pseudo-particules virales obtenues sur cellules de levure (Saccharomyces cerevisiae CANADE 3C-5 (souche 1895)) par la technologie de l'ADN recombinant, adsorbée sur sulfate d'hydroxyphosphate d'aluminium amorphe (Al: 225 microgrammes) comme adjuvant.C'est aussi un vaccin contre le papillomavirus humain  (recombinant, adsorbé).
Il est indisponible sur le marché européen.
Il contient des antigènes contre 5 HPV supplémentaires par rapport au Gardasil: 31, 33, 45, 52 et 58 (impliqués dans 5 à 20% des cancers ano-génitaux), l’efficacité vaccinale de GARDASIL 9 a été de 97,4% soit une réduction absolue de 0,2 pour 100 personnes-années vis-à-vis des lésions de haut grade (anciennement nommées CIN 2/3) chez les femmes âgées de 16 à 26 ans non infectées par un HPV lors de la vaccination.
Il donne des réactions locales plus fréquentes que les vaccins tétra et bivalent dont la majorité sont bénignes et transitoires  : douleur au site d’injection (83%), céphalées (13%), fièvre (6%) et de nausées (3%).Lorsqu'un schéma vaccinal a été initié avec l'un des vaccins, il est recommandé de continuer avec le même, en l'absence de données d'interchangeabilité.
Il existe deux schémas vaccinaux: un schéma à deux doses et un schéma à trois doses.Une étude de janvier 2020 portant sur 67000 jeunes filles ayant reçu une, deux ou trois doses montre une protection équivalente de ce vaccin contre l'apparition de lésions -précancéreuses .
Si cette étude était confirmée elle pourrait aboutir à une injection unique.Concerne les jeunes filles ou garçons de 14 ans ou moins.
Concerne les jeunes filles et garçons de 15 ans ou plus, les jeunes filles immunodéprimés ou porteuses du VIH quel que soit leur âge.La durée de protection par les trois vaccins sur le marché n'est pas connue à ce jour.
Des études de suivi de personnes vaccinées (non immnodéprimées, non porteuses du VIH) montrent toutefois une durée d'efficacité minimale de 10 ans pour le vaccin quadrivalent, de plus de 9 ans pour le vaccin bivalent, et de 5 ans pour le vaccin nonavalent.
De ce fait, il n’y a actuellement pas de recommandation concernant des doses de rappel, d'autant que le rapport coût/efficacité ne serait favorable dans les pays à hauts revenus que pour une protection inférieure à 10 ans.
Par contre la durée de protection est inconnue chez les patientes porteuses du VIH ou immunodéprimées, l'efficacité vaccinale semblant par ailleurs relative pour ces populations.Depuis 2007 en France, l'assurance maladie prend en charge la vaccination contre certains types de papillomavirus des jeunes filles de 11 à 14 ans révolus (et celles de 15 à 19 ans révolus en rattrapage).
Pour le Gardasil, chaque injection coûte 121,36 € (données VIDAL au 28/10/2015) et est remboursée à 65 % par la Sécurité Sociale.
Cela représente aujourd’hui un coût total par personne de 242,72 € à 364,08 € selon le schéma vaccinal utilisé (dont 157,77 € à 236,65 € remboursés).
Pour le Cervarix, le prix de chaque injection est de 109,60 € et est remboursé au même taux.Le vaccin est prescrit par un médecin et est pris en charge à 65% par l’assurance maladie, le montant restant est généralement remboursé par les complémentaires santé (mutuelles).Le risque d'apparition de condylomes génitaux (lésions bénignes) est réduit par le vaccin quadrivalent (les génotypes 6 et 11 sont responsables d'environ 90 % de ces affections).En Suède, une réduction des lésions précancéreuses de 75 % a été observée chez les jeunes filles vaccinées avant l’âge de 17 ans en comparaison aux autres jeunes filles .L'immunité acquise par la vaccination est plus importante que celle acquise par une immunisation naturelle.
La quantité d’anticorps produits après la vaccination contre le VPH est plus importante chez les jeunes filles âgées de moins de 15 ans que chez les jeunes filles et jeunes femmes âgées de 15 ans et plus Des résultats préliminaires indiquent qu’en plus de la protection vis-à-vis du VPH de type 16 et 18, il y a une certaine protection croisée vis-à-vis d’autres types viraux responsables de cancers, l’intensité et la durée de cette protection restent incertains.Une étude de 2019 parue dans le Bristish Medical Journal étudie 138 692 femmes nées entre le 1er janvier 1988 et le 5 juin 1997 qui ont eu un frottis cytologique à l'age de 20 ans enregistrées dans le Scottish Cervical Call-Recall System une base de données destiné à surveiller le suivi des femmes.
ils ont donc comparé les femmes ayant eu un vaccin bivalent à celles qui n'ont pas eu de vaccin.
64 026 femmes n'étaient pas vaccinées et 68 480 avaient trois doses de vaccin (entièrement vaccinées).
Seulement 2051 femmes ont reçu une dose et 4135 femmes ont reçu deux doses.
Cette étude étudie non seulement l'efficacité du vaccin mais montre l'importance de la vaccination avant toute activité sexuelle.
Tim Palmer responsable pour le dépistage du cancer du col en Écosse se réjouit que grâce à la vaccination beaucoup moins de femmes devront vivre avec les implications physiques et psychologiques, y compris les avortements spontanés, de la colposcopie et du traitement des lésions précancéreuses.Le fait d'avoir reçu une vaccination complète ne change rien pour les femmes concernant le dépistage.
Elles doivent se soumettre au même type et fréquence que les femmes non vaccinées.L’incidence du cancer du canal anal (CCA) a augmenté de 56 % depuis 1990 et 93 % de ceux-ci sont attribuables à HPV (avec 80 % d’HPV 16 et 18)  .
L’incidence est plus grande chez la femme (65 %) ; dans les deux cas elle augmente en cas d’infection concomitante à VIH ; bien que les méthodes de détection ne soient pas standardisées comme pour le cancer du col, les lésions précancéreuses peuvent être recherchées par cytologie.
Mais l’évolutivité de ces lésions est mal évaluée ce qui peut conduire à des sur-traitements ; Une étude montre qu’en l’absence d’infection HPV préexistante, sur 602 hommes de 16 à 26 ans vaccinés(vaccin tétravalent) ayant des relations homosexuelles le taux de réduction des lésions anales prénéoplasiques (AIN) est de 74 % et la vaccination après traitement d’AIN de haut grade diminue le risque de récidives de 30,7 à 13,6 %, Le vaccin réduit également le taux de lésions précancéreuses du cancer de la vulve et du vagin.Il existe une nette augmentation depuis les années 1970 de la prévalence des cancers épidermoïdes oropharyngés malgré une diminution des intoxications alcooliques et tabagiques.
Cette augmentation est en rapport avec des cancers HPV induits (KOHPV) et concerne les cancers de la loge amygdalienne et de la cavité buccale .
Les cancers oropharyngés HPV induits ont une présentation clinique différente des cancers ORL liés à l’alcool et au tabac :L'efficacité du vaccin contre les infections orales dues au HPV est élevée : Il n’existe pas de prévention secondaire pour les cancers liés à ce type d'infections.Ses effets sur la mortalité liée au cancer lui-même au sein de la population globale se feraient sentir à long terme.
Une modélisation, parue dans The Lancet en janvier 2020, effectuée par le WHO Cervical Cancer Elimination Modelling Consortium prévoit que si 90% des jeunes filles de moins de 14 ans étaient vaccinées chaque année dans les 78 pays du monde les plus atteints par ce cancer à partir de 2020, on aurait une réduction de moins de 1% de la mortalité en 2030, mais cette réduction de mortalité atteindrait 60% en 2070 sauvant 4 800 000 vie.
En 2120 cette réduction de mortalité atteindrait 90% sauvant sur 100 ans 46 000 000 de vies .
En octobre 2020, une étude suédoise portant sur plus de 1,5 million de filles et femmes âgées de 10 à 30 ans, sur la période 2006-2017, montre une réduction du risque de cancer du col de 66 %, et de 88 % pour celles vaccinées avant l'âge de 17 ans.
Un effet d'immunité collective est attendu pour une couverture vaccinale de plus de 50 %, comme cela a déjà été observé en Suède avec les verrues génitales dues au HPV.Toutes les études concernant l'efficacité contre le CCU ne prennent pas en compte l'impact d'une vaccination des garçons.Ce vaccin, comme tous les vaccins, est rejeté par beaucoup de personnes pour des motifs divers ; néanmoins une association temporelle entre une vaccination et un événement médical sérieux n'est pas suffisante pour faire un lien de cause à effet.
L'exemple typique est celui de Natalie Morton , jeune fille de 14 ans de Coventry , qui est morte deux heures après une injection de Cervarix.
L'autopsie a révélé qu'elle souffrait d'une tumeur intra-thoracique gauche ayant infiltré profondément le cœur et le poumon.Selon un bilan de pharmacovigilance de l'Agence Nationale de Sécurité du Médicament (ANSM) datant de février 2014 concernant le vaccin Gardasil, ce dernier a été suivi de la déclaration de 503 cas d’effets indésirables graves dont 127 de maladies auto-immunes incluant 17 cas de sclérose en plaques (sur 5,5 millions de doses).
L’ensemble de ces données de surveillance disponibles n’ont pas mis en évidence d’éléments remettant en cause le bénéfice attendu au regard des risques de ce vaccin.
L'ANSM poursuit la surveillance renforcée de Gardasil.Aux États-Unis environ 67 millions de doses de vaccin ont été administrées entre juin 2006 et mars 2014.
Le Vaccine Adverse Event Reporting System (Vaers, Système de déclaration spontanée de réactions au vaccin, accessible à quiconque) a enregistré environ 25 000 cas de réactions chez les jeunes filles et les femmes ayant reçu l'injection, dont 92 % ont été déclarés non graves; les cas graves n'ayant pas été attribués au vaccin par le Vaccine Safety Datalink (VSD, système de vérification des données du VAERS).Les réactions secondaires les plus fréquentes sont : douleur au site d’injection, céphalées, fièvre et nausées.
La douleur au site d'injection est fréquente et transitoire.
Les autres effets secondaires surviennent dans moins de 10% des cas.
Des cas d’évanouissement ont été signalés après l’administration du vaccin contre le VPH.
C’est pourquoi il est recommandé que les jeunes filles soient assises et restent sous observation pendant et durant les 15 minutes qui suivent l’administration du vaccin contre le HPV.
Les manifestations indésirables graves sont extrêmement rares.
Il existe une relation de causalité entre la survenue éventuelle d’une anaphylaxie et la vaccination contre le VPH, et des précautions doivent être prises afin d’éviter de vacciner les jeunes filles concernées par les doses suivantes du vaccin contre le VPH ou d’autres vaccins contenant des composants similaires.
Le risque d’anaphylaxie a été caractérisé comme étant approximativement de 1,7 cas par million de dose.Deux augmentations statistiquement significatives ont été observées entre l’exposition aux vaccins contre les infections à HPV et le syndrome de Guillain-Barré d’une part (risque observé multiplié par 4) et les maladies inflammatoires chroniques de l’intestin d’autre part (risque observé multiplié par moins de 1,2).
Si le second résultat statistiquement trop faible pour représenter un sur-risque, l’augmentation du risque de syndrome de Guillain-Barré après vaccination contre les infections à HPV apparaît probable au regard de la force et de la robustesse de l’association.
Le risque d’apparition de ce syndrome serait alors de l’ordre de 1 à 2 cas supplémentaires pour 100 000 personnes vaccinées.
Compte tenu de cette rareté, les auteurs du rapport estiment que ces résultats de cette étude ne remettent pas en cause la balance bénéfice-risque pour les vaccins concernés.D'autres études menées sur le sujet n'ont observé aucune différence d'apparition du syndrome de Guillain-Barré entre personnes vaccinées et non vaccinées,.C'est une affection invalidante et douloureuse d'un membre, associée à des changements moteurs, sensoriels, vasomoteurs, sudoraux, et dystrophiques après une lésion de ce membre.
Les CRPS sont le plus souvent une sorte de traumatisme, comme des fractures, des entorses, ou une chirurgie, mais peut également survenir après des injections, des infections locales, des brûlures, des gelures, même une grossesse, ainsi qu'un accident vasculaire cérébral ou un infarctus du myocarde.
Le diagnostic de CRPS repose sur l'examen clinique et sur l'existence de certains critères (Critère de Budapest).L'incidence du CRPS dans la population générale serait de 14,9 et 28,0 pour 100 000 années-personnes chez les femmes de 10 à 19 ans et 20-29 ans.
Les taux correspondants sont plus faibles chez les hommes, rapportés à 1,8 et 6,2 par 100 000 années-personnes chez les hommes de 10 à 19 ans et de 20 à 29 ans.
Un lien entre la vaccination et cette pathologie n'a pas été retrouvéLes patients atteints de POTS (syndrome de tachycardie orthostatique posturale) présentent généralement une tachycardie en position debout sans hypotension orthostatique.
Ceux-ci sont accompagnés de symptômes (par exemple étourdissements, syncope, faiblesse, fatigue, céphalées, douleurs chroniques, et symptômes gastro-intestinaux) qui diffèrent selon le patient.
Les estimations disponibles suggèrent que dans la population générale, environ 150 filles et jeunes femmes par million de 10 à 19 ans peuvent développer un syndrome douloureux régional complexe (SDRC) chaque année, et au moins 150 filles et jeunes femmes par million peut développer POTS chaque année.
Aucune preuve d’un lien causal entre la vaccination et ces pathologies n'a été relevée.La fréquence de survenue de ces maladies au décours de la vaccination resterait faible vis-à-vis du nombre de personnes vaccinées.
Une étude scandinave montre que les risques de sclérose en plaques et autres atteintes démyélinisantes sont équivalents entre populations vaccinée et non-vaccinée.En France, l’Agence nationale de sécurité du médicament et des produits de santé et la Caisse nationale de l'assurance maladie ont suivi jusqu’à fin 2013 un peu plus de 2,2 millions de jeunes filles affiliées au régime général de la sécurité sociale et âgées de 13 à 16 ans révolus entre janvier 2008 et décembre 2012.
Environ 840 000 avaient été vaccinées contre les infections à HPV par Gardasil ou Cervarix et 1,4 million n’avaient pas été vaccinées.
La fréquence de survenue de maladies auto-immunes a été comparée chez les jeunes filles vaccinées et les jeunes filles non vaccinées.
Quatorze maladies auto immunes ont été étudiées, dont la sclérose en plaques.Dans le rapport final publié en 2015, près de 4 000 cas de ces maladies ont été diagnostiquées dont près de 1 000 après vaccination, et le risque global de maladie auto immune n’a pas été trouvé augmenté par la vaccination.En France, aucun lien entre vaccins anti-HPV et maladies auto-immunes n'a été démontré sur plus de 200 millions de doses distribuées .Des liens entre la vaccination et l’insuffisance ovarienne prématurée, la défaillance ovarienne primaire, le risque de thrombose veineuse ou la maladie cœliaque ont été évoqués.
Les études n'ont pas permis de confirmer un lien causal entre le vaccin et ces pathologies.Les vaccins contre le VPH ne doivent pas être administrés aux personnes ayant présenté des réactions allergiques sévères après une dose précédente du vaccin ou après une exposition à l’un de ses composants (p. ex.
Les symptômes d’une réaction allergique peuvent comprendre des démangeaisons, une éruption cutanée, de l’urticaire ou des vésicules.
Si l’un de ces symptômes apparaît après la vaccination contre le VPH, aucune dose supplémentaire ne doit être administrée et il faut éviter d’utiliser d’autres vaccins pouvant comprendre les mêmes composants.Une affection fébrile doit faire surseoir la vaccination.La grossesse bien que les données soient très rassurantes en cas d'injection du vaccin chez une femme enceinte…Plus de 92 000 cas de femmes enceintes ayant reçu la vaccination ont été reportés.
Aucune issue défavorable de la grossesse, qu’il s’agisse d’un problème obstétrical ou d’une anomalie congénitale ou structurale, n’a été observée.
L’administration par inadvertance du vaccin anti-HPV pendant la grossesse ne provoque d’issue défavorable connue ni chez la mère, ni chez l’enfant .En 2017, 71 pays ont intégré la vaccination contre le VPH dans la lutte contre le cancer du col de l'utérus en complément au dépistage .En France, en 2011, l'InVS relayant les avis de la HAS préconise, en complément au dépistage des lésions précancéreuses et cancéreuses du col de l'utérus qui doit rester prioritaire, de vacciner les jeunes filles de 11 à 14 ans inclus, tout en rappelant que cette vaccination s'avère inopérante dans 30 % des cas,, afin de les protéger avant qu'elles ne soient exposées au papillomavirus.
En 2013, la HAS préconise une vaccination à titre de rattrapage entre 15 et 19 ans inclus.
La HAS précise que l'efficacité du Gardasil 9 en matière de prévention des cancers reste à démontrer.Elle recommande en décembre 2019 la vaccination des garçons, avec maintien d’une recommandation vaccinale spécifique pour les hommes ayant des relations sexuelles avec des hommes jusqu’à 26 ans révolus .Le plan cancer 2014-2019 avait fixé une couverture minimale contre les HPV de 60% chez les filles.Aux États-Unis, les recommandations préconisent la vaccination de toute femme entre 11 et 26 ans.L’État du Michigan demande la vaccination de toutes les jeunes filles de 11-12 ans de cet État.
Il existe cependant une certaine résistance vis-à-vis de ce traitement ayant fait, en particulier, une telle politique vaccinale au Texas et en Illinois.Une vaccination de masse a débuté au Québec en 2008.Une vaccination de masse a débuté en Australie en 2007, en 2008.En juin 2013, le ministère de la santé japonais cesse de recommander les vaccins anti-papillomavirus pour les jeunes filles de 12 à 16 ans, sans pour autant en suspendre totalement l'utilisation,.
3,28 millions de femmes ont reçu le vaccin et 1968 cas d"effets indésirables ont été rapportés.Le coût élevé des vaccins pose la question de la stratégie à utiliser en matière de santé publique : faut-il privilégier une vaccination systématique alors que les dépistages (frottis) gardent leur utilité à court et moyen terme et que les femmes risquent de moins se faire surveiller, se sentant protégées ?
Par ailleurs, selon un expert de l'OMS, les coûts pourraient être abaissés à 7 euros pour des génériques à destination de l'Inde.Les vaccins contre le col de l'utérus représentent un chiffre d'affaires non négligeable pour les laboratoires : plus d'un milliard de dollars pour le Gardasil seul aux États-Unis.
En 2006 Didier Hoch, qui dirigeait la joint-venture Sanofi Pasteur déclarait attendre " entre 500 millions et 1 milliard d'euros de revenus annuels de ce produit pour l'Europe d'ici à « trois ou cinq ans » ", pour une coentreprise dont le chiffre d'affaires était inférieur à 700 millions d'euros en 2005.Une revue de littérature systématique a identifié 103 articles uniques sur les déterminants de l'hésitation au vaccin contre le VPH en Europe.
Dans les études européennes, les préoccupations les plus courantes concernaient: les informations insuffisantes et inadéquates sur la vaccination contre le VPH; effets secondaires potentiels du vaccin; les problèmes de confiance des autorités sanitaires, des médecins et des nouveaux vaccins; et faible efficacité vaccinale perçue .Certains s'insurgent contre l'utilisation du vaccin sur de très jeunes filles, en mettant en avant les risques éventuels.
C'est notamment le cas d'Henri Joyeux, qui signe en 2014 une tribune intitulée « Non à la vaccination massive des enfants contre les papillomavirus ».
Cette position a valu au professeur Joyeux une procédure de radiation, finalement abandonnée en juin 2018, au motif de la liberté d'expression.
Ainsi, selon le conseil de l'ordre, « si le professeur Joyeux a le droit d'exprimer une position personnelle, il devait préciser qu'elle n'est pas validée par la communauté scientifique ».C'est un vaccin qui ne protège que dans 70 % des types de virus, les 30 % restant étant représentés par des génotypes de papillomavirus non couverts par le vaccin.
Les virus non représentés sont responsables de 50 % des lésions précancéreuses et de 30 % des cancers invasifs.
Il existe donc un risque que la vaccination donne une illusion de protection totale aux personnes peu informées.Bien qu'il soit le second cancer le plus répandu au monde, notamment dans les pays en voie de développement, le cancer du col de l'utérus est considéré comme rare en France, pays qui compte parmi les pays à faible incidence : le nombre de nouveaux cas était de 3 387 cas en 2000, 2 810 en 2011 et 3028 en 2012, le nombre de décès liés étant de 904 en 2002, 998 en 2011 et 1102 en 2012.
L'incidence est de 10 pour 100 000 femmes par an selon les régions, soit environ 3 000 nouveaux cas par an, ce qui le situe au 11e rang des cancers de la femme en France.
Par ailleurs, la mortalité liée à ce cancer est fortement associée à des indicateurs de vulnérabilité socio-économique : c'est un cancer plus présent dans les populations défavorisées.En outre, le déclenchement du cancer est lié à une série de cofacteurs : ceux liés à l’hôte (précocité de l’activité sexuelle, multiplicité des partenaires sexuels, immunodéficience, nombre de grossesses élevé), ceux liés au virus lui-même (charge virale), ainsi que des cofacteurs exogènes : tabagisme, co-infection par le VIH ou une autre infection sexuellement transmissible (IST) telle que le virus herpes simplex 2.Par ailleurs, la modélisation faite par l'Institut de Veille Sanitaire indique s'attendre à une réduction de l’incidence du cancer du col de l’utérus de 34 % et une réduction de la mortalité liée à ce cancer de 32 %, si 80 % des jeunes filles sont vaccinées.
Pourtant, la durée de la protection vaccinale n'est pas connue au-delà de 5-6 ans, or le pic d'activité sexuelle se situe autour de 20 à 25 ans.
Une vaccination dès l'âge de 9 ans pourrait donc exiger des vaccins de rappel à 14 ans puis à 19 ans.
C'est ainsi que, selon la Haute Autorité de Santé la prévention des cancers du col de l’utérus par le vaccin est attendue, mais non démontrée, et ne pourra être démontrée qu’à long terme, puisque le délai entre l’infection par le papillomavirus humain et la survenue d’un cancer invasif est de 15 à 25 ans.
Or le cancer du col de l’utérus est un candidat idéal au dépistage par son évolution lente et l’existence de nombreuses lésions précancéreuses curables.
Le test de dépistage de référence des lésions précancéreuses et cancéreuses du col de l’utérus repose sur un prélèvement cervico-utérin avec examen cytologique (le frottis cervico-utérin) avant 30 ans ou test HPV après 30 ans tous les 5 ans.
En 2010, l'Institut National contre le Cancer écrivait que la vaccination "ne se substitue pas au dépistage par frottis mais constitue un moyen complémentaire d’agir face au cancer du col de l’utérus.
"En France, le 11 décembre 2015, une nouvelle plainte a été enregistrée par Marie-Océane Bourguignon.
Elle est la pionnière du combat judiciaire contre ce vaccin et a porté plainte en 2013 pour « atteinte involontaire à l’intégrité de la personne » contre Sanofi-Pasteur MSD, le laboratoire fabriquant le Gardasil, et aussi contre l’Agence nationale de sécurité du médicament.
De plus, 25 plaintes ont été enregistrées en avril 2014 pour le même motif et 9 en décembre 2013 pour « blessures involontaires, violation d’une obligation manifeste de sécurité et méconnaissance des principes de précaution et de prévention » .La controverse perdure en juin 2014 avec le dépôt de plainte d'un avocat espagnol contre Merck-Sanofi Pasteur et l’État espagnol pour négligence, arguant que les essais cliniques du Gardasil ont omis de faire appel à un placebo inerte, ce qui aurait conduit à une représentation inexacte des données cliniques, et que les autorités de santé ibériques n'auraient pas cherché à vérifier les données fournies par le laboratoire ; ce qui aurait résulté par la non prise en compte du risque réel d'effets secondaires.L'efficacité de la vaccination anti-HPV est souvent débattue, cependant la littérature sur le sujet montre que la vaccination permet de diminuer significativement les infections dues aux souches de virus les plus communes.En 2020, une étude émanant de la Royal Society of Medicine estime que l’efficacité des vaccins anti-HPV a été « surestimée », et que ces vaccins n’ont pu cibler que les CIN, néoplasies cervicales intra-épithéliales, c’est-à-dire les stades précurseurs et bénins ; cependant, cette étude ne porte que sur les phases de test (II et III) du vaccin : elle permet donc de remettre en cause la méthodologie utilisée pour ces tests sans remettre en cause les données obtenues sur les populations.En France, 50 acteurs du domaine de la santé (académies, collèges, sociétés et syndicats médicaux), lancent en 2019 un appel à un dépistage systématique et à une vaccination universelle, incluant la population masculine,.15 médecins et pharmaciens indépendants de l'industrie pharmaceutique publient une tribune argumentant le manque de preuves actuelles du dossier, les liens d'intérêt d'intervenants du débat, et les «incertitudes majeures qui pèsent sur leur rapport bénéfice-risque et coût-efficacité», ainsi que le retard à la mise en place du dépistage organisé du CCU préconisé depuis 2007, avant l'AMM du vaccin.Le 20 août 2008, un article du New York Times dénonce les pressions exercées par l’industrie pharmaceutique au sujet du vaccin anti-HPV.
En 2016, Des médecins danois accusent l’Agence européenne des médicaments d’avoir biaisé une expertise sur les vaccins contre le cancer du col de l’utérus.
Les services de la médiatrice européenne ont déclaré recevable les aspects majeurs d’une plainte déposée contre l’Agence européenne des médicaments (EMA) par le Nordic Cochrane Centre, ainsi que d’autres institutions, médecins ou chercheurs.
Le 16 octobre 2017, la décision est rendue dans le dossier 1475/2016/JAS sur le traitement par l’Agence européenne des médicaments de la procédure de saisine relative aux vaccins contre les infections à papillomavirus humain : Le rôle de la médiatrice ne consiste pas à se prononcer sur le bien-fondé des évaluations scientifiques menées par des agences scientifiques spécialisées, telles que l’évaluation de la sécurité d’un médicament par l’EMA.
mais la médiatrice peut toutefois chercher à déterminer, d’une part, si des organismes scientifiques comme l’EMA ont mis en place les garanties procédurales nécessaires pour que l’examen des preuves scientifiques soit complet et indépendant, et, d’autre part, si ces garanties ont été appliquées correctement dans une procédure donnée.
Enfin, la médiatrice considère que la politique de l’EMA en matière de conflits d’intérêts a été pleinement respectée pendant la procédure de saisine relative aux vaccins contre les infections à papillomavirus humain.
Aucun conflit d’intérêts n’a été identifié.
La médiatrice a donc estimé que la procédure en cause avait été conduite en toute indépendance par les experts scientifiques concernés.
Elle a conclu qu’il n’y a pas eu de mauvaise administration de la part de l’EMA dans le traitement de la procédure de saisine relative aux vaccins contre les infections à papillomavirus humain.En 2018, alors que la collaboration Cochrane, réputée pour la fiabilité de ses études, émet un avis favorable sur l'efficacité et l'innocuité du Gardasil, les conclusions de cette méta-revue sont remises en cause par 2 membres de la collaboration et un membre du Centre pour la médecine basée sur les preuves.
Ils dénoncent des études de base, entièrement financées par le fabricant, les conflits d'intérêts des auteurs de la méta-revue, liés au fabricant, les méthodologies inappropriées utilisées dans la conception de certains tests, les biais de sélection ayant conduit à rejeter certaines études, tous éléments susceptibles de fausser les résultats.
Ces accusations sont contestées au sein de Cochrane, aboutissant à une grave crise interne et à l'exclusion du conseil de gouvernance de Cochrane d'un des auteurs de la critique.En 2019, parait un article rédigé par deux journalistes et un médecin, à la suite d'une investigation menée en parallèle sur la méta-revue Cochrane, et qui aboutit aux mêmes critiques.
Selon l'une de ces journalistes, Catherine Riva, les données négatives sur l'efficacité et l'innocuité ne sont pas assez prises en compte, et il aurait été nécessaire d'avoir des études plus fiables avant de faire la promotion massive du vaccin
La classe ATC J07, dénommée « Vaccins », est un sous-groupe thérapeutique de la classification anatomique, thérapeutique et chimique, développée par l'OMS pour classer les médicaments et autres produits médicaux.
Le sous-groupe présenté ici est celui établi par l'OMS, et peut donc différer des versions dérivées utilisées dans certains pays.
Il fait partie du groupe anatomique J de la classification, intitulé « Anti-infectieux (usage systémique) ».Dans la classification ATC vétérinaire, ces produits sont répertoriés au sein du groupe ATCvet QI (produits immunologiques).J07 Vaccins.Article détaillé en anglais à en:Anthrax vaccines (en)Article détaillé en anglais à en:Brucellosis vaccine (en)Article détaillé en anglais à en:Cholera vaccine (en)Article détaillé en anglais en:Plague vaccine (en)Article détaillé en anglais : en:Typhoid vaccine (en)
Le vaccin bilié de Calmette et Guérin, le plus souvent dénommé vaccin BCG, est un vaccin contre la tuberculose.Il est préparé à partir d'une souche atténuée de bacille tuberculeux bovin (Mycobacterium bovis) vivant qui a perdu sa virulence sur l'homme par culture spéciale sur des milieux artificiels pendant des années.
Ce bacille proche de Mycobacterium tuberculosis, responsable de la tuberculose humaine, confère une antigénicité croisée suffisamment forte pour devenir un vaccin effectif pour la prévention de la tuberculose humaine.
Il a également été utilisé en médecine vétérinaire.Depuis les arrêts d'approvisionnement par Sanofi, le BCG est en France produit par le groupe MEDAC, avec des pénuries périodiques (dont une en 2020).Le développement du vaccin BCG s'est fait dans un cadre de pensée et une pratique influencés par la vaccination antivariolique qui recourait alors à un microorganisme animal (cow-pox) pour se prémunir d'une affection humaine (variole ou smallpox en anglais).
L'agent de la tuberculose bovine, Mycobacterium bovis, qui peut induire des infections tuberculeuses chez l'homme, fut ainsi utilisé dans l'espoir de trouver un vaccin contre la tuberculose humaine.
L'inoculation de Mycobacterium bovis à des humains dans l'Italie de la fin du XIXe siècle eut des conséquences désastreuses.
Dans les années 1920, le Conseil de la recherche médicale tentera de mettre au point son propre vaccin, sans succès.Avant le vaccin mis au point par Calmette et Guérin, Emil Adolf von Behring avait développé un vaccin contre la tuberculose bovine qu'il croyait être la cause des tuberculoses pulmonaires humaines (via l'ingestion de lait de vaches porteuses de Mycobacterium bovis).
Ce vaccin, constitué de bacilles de type humain vivants et desséchés, s'avérera inefficace et même dangereux.
Il n'en inspira pas moins les travaux de Calmette qui, en 1908, partageait les vues de Berhring quant à l'étiologie de la tuberculose humaine ainsi qu'il s'en expliqua à un Congrès international.
Saturnin Arloing avait déjà conduit des travaux très aboutis dans le domaine de la vaccination contre la tuberculose bovine.
À l'Institut Pasteur de Nantes, Gustave Rappin suivait aussi depuis 1894 une piste prometteuse, à des fins tant préventives que thérapeutiques ; n'aboutissant pas avant 1924, ces efforts seront éclipsés par ceux de Calmette et Guérin, tandis que leur simple souvenir aura sans doute eu à pâtir des prises de position ultérieures de Rappin lui-même.En 1888, Pavlovsky réussit à ensemencer la surface de tranches de pommes de terre, milieu riche en amidon, avec des parcelles de culture du Bacille de la tuberculose (humaine) sur gélose glycérinée.
En 1893, Sander montre que l'apport d'air accélère la croissance des cultures ; comme terrain de nutrition, la pomme de terre lui paraît devoir être préférée à la gélose glycérinée, et aux milieux d'origine animale.En 1903, von Behring avance au congrès de Cassel que la tuberculose, quel que soit le siège de ses lésions, serait presque sans exception d'origine intestinale (contredisant ainsi la Baumgarten-Tangl law (en)).En 1890, Grancher et H. Martin réussissent à vacciner quelques lapins par l'inoculation à virulences croissantes de cultures de tuberculose aviaire, tout d'abord affaiblies par le vieillissement.
A. Möller obtient des résultats positifs d'immunisation (sur lui-même et sur des animaux) en se servant des cultures de tuberculose humaine, mais modifiées par un passage préalable sur l'orvet.
Friedmann obtient une vaccination active chez des bovidés au moyen des bacilles tuberculeux de la tortue.À son retour d'Indochine (où il essaya la tuberculine en traitement du lupus tuberculeux et une forme cutanée et muqueuse de la lèpre), et après un court séjour à Paris, Albert Calmette prend la responsabilité du nouvel Institut Pasteur de Lille en 1895.
Rejoint par le vétérinaire Camille Guérin en 1897, il y entame ses recherches sur la tuberculose (mécanisme de l'infection bacillaire, immunité antituberculeuse) en 1900 .« Calmette et Guérin font ingérer des cultures de tuberculose d'origine bovine, humaine, aviaire et phléolique à des chevreaux, à des chèvres et boucs adultes par différents procédés : introduction directe de cultures dans les voies digestives, ou contamination du lait d'alimentation.
Leur conclusion est que dans l'immense majorité des cas, la tuberculose se contracte non par l'introduction des bacilles dans les voies aériennes, mais par l'ingestion de produits bacillifères ».Nocard leur fournit une culture de Mycobacterium bovis isolée d'une vache tuberculeuse en 1902.En 1905-1906, ils constatent que de jeunes bovins guéris d'une tuberculose expérimentalement provoquée ne sont pas réinfectés.
En 1906 les comptes-rendus hebdomadaires des séances de l'Académie des Sciences publient un article de Calmette et Guérin intitulé Sur la vaccination contre la tuberculose par les voies digestives.
Cette même année, les annales de l'Institut Pasteur publiaient leur mémoire – le troisième ainsi nommé – intitulé Origine intestinale de la tuberculose pulmonaire.Le 12 juin 1906, le journal Le Matin fait état des travaux de Calmette et Guérin ; le quotidien, qui évoque d'abord la possibilité prochaine du développement d'un vaccin destiné aux bovins, rapporte la conviction de Calmette que ce vaccin trouvera vite une utilisation en médecine humaine.En 1908, une observation - ainsi peut-être qu'une indication du chercheur norvégien Kristian Feyer Andvord (en) – les met sur la voie de la découverte.
Afin de rendre émulsifiable une culture glycérinée de la souche Nocard, ils y ajoutent de la bile de bœuf ; ils s'aperçoivent que les cultures faites ainsi perdent de leur virulence.
Ils cultivent l'agent de la tuberculose bovine – Mycobacterium bovis – sur des tranches de pommes de terre immergées dans de la bile de bœuf stérile.
En 1909, Calmette dépose sur le bureau de l’Académie des sciences une note décrivant le « bacille tuberculeux bilié ».En 1912, après 96 mises en culture successives, ils parviennent à modifier la souche initiale qui devient inoffensive sur les bovins (elle reste pathogène pour le cheval).
Ce bacille partiellement atténué prend alors le nom de « bilié Calmette-Guérin » (BCG).En 1913, le vaccin est testé sur de jeunes bovins et des singes de différentes espèces.Les recherches deviennent difficiles à poursuivre pendant la Première Guerre mondiale : Lille est alors occupée par les Allemands ; les vaches sont réquisitionnées pour nourrir les troupes d'occupation ; Calmette autopsie les animaux et les déclare sains.En 1919, Albert Calmette reconstitue à l'Institut Pasteur de Paris une équipe de travail (Camille Guérin, Auguste Boquet et Léopold Nègre) sur le bacille tuberculeux (Boquet, Nègre et Jean Valtis auront la responsabilité de la préparation du vaccin BCG jusqu'en 1928, date d'arrivée de Guérin à Paris).
Les expériences de vaccination des bovidés avec la souche biliée, entreprises en 1912, furent reprises entre 1921 et 1927.
Conçu à l'origine pour un usage vétérinaire, le vaccin est testé par Henri Vallée en 1921 dans une ferme expérimentale modèle à Fécamp : Vallée procède par injections intraveineuses ou par insertion sous la peau ; il n'obtient pas un taux de protection à 100 %.La toute première inoculation humaine, en intraveineuse sur un homme adulte, en montre l'innocuité.Le vaccin est aussi essayé sur des nouveau-nés le 18 juillet 1921 à la crèche de la maternelle de l'hôpital de la Charité, à Paris.
Le pédiatre Benjamin Weill-Hallé et le Dr Raymond Turpin vaccinent d'abord un nouveau-né dont la mère était morte de la tuberculose quelques heures après l'accouchement et qui était appelé à vivre dans un milieu contaminé.
La santé de l'enfant étant établie après une période d'observation de six mois, la vaccination est étendue à d'autres nouveau-nés de l'hôpital de la Charité, d'abord de 1921 à 1922 puis de 1922 à 1924.
Les résultats de ces vaccinations sont présentés devant l'Académie de médecine par A. Calmette, C. Guérin et leurs collaborateurs le 24 juin 1924.
Le premier juillet 1924, l'Institut Pasteur créée le premier centre de production et de distribution gratuite de BCG ; le vaccin est distribué gratuitement aux médecins qui en font la demande ; en échange ceux-ci s'engagent à retransmettre un certain nombre d'informations.Le vaccin a aussi été testé sur des singes anthropoïdes sur le site de l'Institut Pasteur établi en Guinée, à Kindia, dont Calmette fut un temps directeur.
C'est en 1922 qu'est signée une convention entre l'Institut Pasteur et le gouvernement général de l'Afrique-Occidentale française fondant en Guinée française l'établissement auquel sera donné le nom de Pastoria.
La direction de l'établissement, qui couvre 35 ha, est confiée au vétérinaire-commandant R. Wilbert en 1923 ; Maurice Delorme en devient l'assistant en 1925.
À partir de 1937 une production de vaccin BCG se fait sur place.La vaccination se développe à partir de 1924, notamment dans les dispensaires.
Calmette distribue alors sa souche à de très nombreux bactériologistes, qui la repiquent de nouveau, donnant ainsi naissance à des centaines de souches « filles ».
Cette même année 1924, les ministères de la Défense nationale et des Colonies décident que les laboratoires de Tananarive, Saïgon et Dakar devront procéder à la vaccination de la population infantile et des troupes indigènes.
Si les vaccinations débutent effectivement dès 1924-1925 à Madagascar et en Indochine, l'Institut Pasteur de Brazzaville ne commence les premiers essais de vaccination qu'en septembre 1930,.Benjamin Weill-Hallé et Raymond Turpin effectuent des vaccinations à l’École de puériculture de Paris.
Entre 1925 et 1927, Couvelaire vaccine à Baudelocque : 305 nouveau-nés.Entre septembre 1926 et août 1927 la Compagnie des mines de Béthune vaccine 850 enfants.
En 1927, Calmette publie une étude faite sur 21 200 enfants vaccinés qui conclut à l'efficacité du vaccin.
Ces publications de l'année 1927 rencontrent très rapidement des critiques, en France d'abord où le Dr José Lignières remet en question l'innocuité totale du BCG, mais aussi à l'étranger avec le Britannique Greenwood et le Suédois Arvid Wallgren qui soulignent, eux, la fragilité des preuves statistiques de Calmette (Wallgren fut cependant un promoteur actif du BCG en Suède).Dès 1925, au Canada, le Conseil de la recherche médicale met en place l'Associate Committee for research on tuberculosis and BCG pour étudier tant l'utilisation humaine que vétérinaire.
A. Baudouin initie des essais cliniques en 1925.
Armand Frappier y conduit également des recherches.En 1927, Petroff affirme avoir réussi à isoler d'une culture BCG une variante virulente.
Les travaux de Petroff reçoivent un écho important et suscitent de nombreuses études en Europe (on objectera aux résultats de Petroff une possible contamination accidentelle ; le décès de Petroff de tuberculose apportera un argument à cette hypothèse).
Entre 1927 et 1941, la Fondation Rockefeller, en lien avec l'Henry Phillips Institute et l'université de Pennsylvanie, conduit un programme en Jamaïque ; y est notamment étudié un vaccin expérimental élaboré à partir de bacilles tués par la chaleur (contrairement au BCG qui est un vaccin dit vivant, c'est-à-dire atténué).
D'abord effectuée sur des malades mentaux, après que son innocuité ait été testée sur des cobayes, l'essai clinique est étendu à 11 000 personnes de Kingston.À partir de 1927, Olaf Scheel et Johannes Heimbeck de l'hôpital de l'école d'infirmière Ullevaal Hospital à Oslo, conduisent deux programmes de vaccinations distincts chez des élèves infirmières (respectivement jusqu'en 1936 et 1939).
C'est la première fois que le vaccin était proposé en injection à des adultes.
Ces études, critiquées pour n'avoir pas recouru à des groupes de contrôle, ont été d'une très grande importance : c'est sur la base de leurs résultats que le programme norvégien de vaccination BCG d'après guerre fut conçu ; il servit de référence à d'autres pays,.La vaccination ne se développe que lentement en France dans les années 1920 (en Scandinavie en revanche elle se généralise plus facilement).
Elles sont à ce moment surtout le fait des dispensaires et des services hospitaliers.En 1928, Ludwik Rajchman le directeur d'une agence sanitaire de la Société des Nations convie à Paris une conférence au sujet du BCG.
Présidée par Émile Roux, elle organise son travail autour de trois commissions, clinique, vétérinaire, bactériologique.
La conférence confirme sans hésitation l'innocuité du vaccin.
Concernant son efficacité en revanche, elle est moins affirmative ; d'après ses conclusions le vaccin engendre seulement « un certain degré d’immunité »,.
La commission, qui a accordé toute son attention aux arguments d'ordre statistique développés par Greenwood, assortit son avis de recommandations devant guider ultérieurement la recherche.
Est notamment recommandée l'introduction, lors des essais, de groupes de contrôle.
La même année, une commission vétérinaire internationale, comprenant l'Italie, les Pays-Bas, l'Autriche, la Pologne, l'Allemagne et la France, préconise d'étendre la vaccination BCG au bétail.En 1930, éclate le drame de Lübeck : sur 251 enfants vaccinés, 72 enfants meurent d'une tuberculose généralisée, 131 autres développent une tuberculose clinique avec guérison et 41 ne présentent aucun symptôme mais font une conversion tuberculinique.
Le gouvernement allemand intente un procès contre l'Institut Pasteur.
Léopold Nègre démontre que le BCG n'est pas en cause : une erreur a été commise par le laboratoire qui a préparé le vaccin sur place : il a été accidentellement contaminé.
Le tribunal exonère le BCG et conclut à une contamination accidentelle.
À l'époque, en l’absence de connaissances génétiques, la question d'un retour à la virulence ne peut toutefois être exclu.Le 19 avril 1932, une circulaire du ministre de la Santé publique rappelle « le grand intérêt » de la vaccination par le BCG.En 1933, les recommandations officielles portant sur la lutte contre la tuberculose bovine n’instituent pas l'obligation de la vaccination BCG.
Celle-ci est laissée à la discrétion des éleveurs.En 1935 est créée la Commission du BCG de l'institut Pasteur dont Antoine Marfan est le directeur (Calmette est décédé en 1933).
Cette même année, en réponse aux objections formulées par la commission internationale en 1928, Calmette conçoit, avec l'aide du statisticien Yves Biraud, un programme randomisé avec groupe de contrôle en Algérie, dans la Kasbah.
C'était une entreprise alors novatrice, qui ne sera surpassée en taille d'échantillon que par l’essai sur la streptomycine après la deuxième guerre mondiale.
En 1935 toujours, Aronson et Palmer organisent les premiers essais, au hasard, du BCG dans des réserves indiennes aux États-Unis et en Alaska,, (R. G. Ferguson (en), directeur de la ligue antituberculeuse de la Saskatchewan, conduit des campagnes de vaccination entre 1933 et 1943 chez des enfants aborigènes et des infirmières).Dans les années 1940, Jörgen Lehmann (en) met en évidence l'activité antituberculeuse de l'acide para-aminosalicylique, qui ne commencera véritablement à être utilisé qu'à compter de 1948.En 1944, la Suède légifère.En 1946, la Croix-Rouge danoise organise la vaccination par le BCG en Pologne, Autriche, Hongrie et Yougoslavie ; l’année suivante, elle étend son action aux zones d’occupation américaine et britannique en Allemagne.En 1947, la Norvège rend la vaccination obligatoire pour les personnes testées négatives à la tuberculine.En lien avec l'UNICEF (décision de Lake Success du 12 mars 1948), les organisations de la Croix-Rouge danoise, norvégienne et suédoise fondent l'International Tubercolisis Campaign ou Joint Enterprise, un programme qui se propose d'aider tout pays européen à mener une vaccination pédiatrique de masse et qui s'étendra ensuite à d'autres parties du monde.
L'OMS apporte une aide technique.En juin 1948, le premier congrès international du BCG, organisé à l'Institut Pasteur, admet que le vaccin occasionne une immunité « relative ».En 1949, le Joint Enterprise, le Danish Statens Seruminstitut et l'OMS coordonnent leurs efforts pour étudier différentes questions soulevées à l'occasion des campagnes de vaccination généralisées.Après la guerre, des études de grande ampleur sont menées, suivant des méthodologies distinctes, en Grande-Bretagne et aux États-Unis.En 1950, la vaccination est rendue obligatoire en France.Dans les années 1950 est mise en évidence l'activité antituberculeuse de l'isoniazide, qui commence à être utilisée à partir de 1952.En 1974, le vaccin BCG est intégré par l'UNICEF dans son programme de vaccination infantile.En 1997, dans un document mettant en avant la Stratégie DOTS, l'OMS attribue l'échec de la lutte mondiale contre la tuberculose à plusieurs raisons, dont une « confiance exagérée dans le BCG », avec ainsi des moyens de lutte moindre mis en oeuvre (dépistage, traitement), sans pour autant remettre en cause l'efficacité du vaccin.Le premier nouveau vaccin utilise un vecteur viral présentant l'antigène 85A porté par la souche Ankara de la vaccine (code de ce vaccin MVA85A).
Cette première tentative a déçu dans un essai conduit en Afrique du Sud chez les enfants.
Deux autres vaccins mettant en œuvre des souches de mycobactéries modifiées génétiquement sont en cours d'étude : VPM1002 et MTBVAC.
Les premières évaluations ont été faites chez des enfants pour améliorer la protection vaccinale.La société GlaxoSmithKline a développé un vaccin antituberculeux constitué d'une protéine recombinante :M72.
Cette protéine est dérivée de deux antigènes immunogéniques de Mycobacterium tuberculosis (Mtb32A et Mtb39A).
On associe à cette protéine antigénique un système adjuvant dénommé  AS01.
Ce candidat vaccin est connu sous son nom de code M72/AS01E.
L'étude de phase II a montré une innocuité acceptable et l'apparition d'immunité humorale et cellulaire aussi bien chez des volontaires sains que chez des personnes atteintes du VIH .Un essai portant sur des personnes porteuses de Mycobacterium tuberculosis mais ne présentant pas de symptômes de la maladie, montre que les personnes vaccinées ont une probabilité plus faible de développer une tuberculose .Le BCG est un germe injecté vivant.
Son efficacité est basée sur le principe de l'immunité de surinfection, c'est-à-dire qu'il n'a d'efficacité que tant qu'il reste vivant dans l'organisme (généralement tapi dans un ganglion lymphatique).
Il s'agit d'une immunité à médiation cellulaire.
Cela explique que le vaccin peut « ne pas prendre ».
Dans ce cas, les tests restent négatifs, et une nouvelle vaccination s'impose.
Cela explique aussi que les tests peuvent devenir négatifs (disparition du BCG vivant dans l'organisme).
Il faut alors vacciner de nouveau.En 1921, Benjamin Weill-Hallé procéda à la vaccination par voie orale.
Ce mode d'administration a les faveurs des médecins français jusqu'après l'instauration de l'obligation vaccinale en 1950 alors que les pays scandinaves préconisent dès avant la Seconde Guerre mondiale l'administration par voie sous-cutanée, voire intradermique.
La voie intradermique est initiée par le Professeur Arvid Wallgren en 1927 à Göteborg.
En 1939, le Dr Sol Roy Rosenthal envisage l'administration du BCG par multi-ponction en raison de l’incidence élevée des réactions indésirables avec la voie intradermique.
La voie sous-cutanée occasionnait de nombreux abcès froids qui devaient être aspirés ou traités chirurgicalement ; à compter de 1935, ce mode d'administration est délaissé.En France, la vaccination se pratique actuellement plutôt par scarification (chez les nourrissons) ou par voie intradermique.Sous sa forme fraîche, le vaccin est très fragile car sensible à la lumière et à la chaleur.
Conditionné sous forme desséchée, il se conserve plusieurs mois à +4 °C mais doit être utilisé dans les 24 heures de sa mise en suspension.L’article 9 du décret du 9 juillet 1951 prévoyait : « les sujets soumis à la vaccination obligatoire et qui vivent dans un milieu comportant un risque de contamination, devront, avant la vaccination, être mis à l’abri de la contamination pendant une durée de 2 mois.
» Inapplicable en pratique, cette disposition fut ensuite abrogée.D'après une méta-analyse de 2014, le BCG conserve une efficacité importante contre la maladie, et souligne l'importance de vacciner les enfants dès la naissance.
D'après cette même méta-analyse, il n'existe pas de différence d'efficacité entre les différentes souches de BCG.
Si on étudie l'évolution de la régression de la tuberculose depuis le XIXe siècle dans de nombreux pays, on constate objectivement qu'elle a régressé avant la découverte des antituberculeux, ou de la vaccination.
Les épidémiologistes l'interprètent essentiellement par l'amélioration des conditions d'hygiène et nutritionnelles,,.Les taux d'effets indésirables varient selon la souche du vaccin, la dose et la méthode d'immunisation, ainsi que l'âge du vacciné.Les effets indésirables sont plus fréquents chez les plus jeunes vaccinés et sont généralement associés à une mauvaise technique d'administration et surtout une dilution insuffisante.
Le vaccin actuel est administré par injection intradermique, et non pas intramusculaire.
En France, le flacon BCG comprend 10 à 20 doses de vaccins.Les effets indésirables du BCG sont habituellement localisés (bécégite), bénins et ne nécessitent pas de traitement :C'est lorsqu'il préexiste un déficit immunitaire que s'observent des complications plus graves.Une enquête parrainée par l'Union internationale contre la tuberculose et les maladies respiratoires, a permis de répertorier 10 371 complications à la suite de 1,5 milliard de vaccinations par le BCG chez des adultes et des enfants.En France, le vaccin est d'abord rendu obligatoire, par voie de circulaire, en 1947 pour certains groupes professionnels (élèvesinfirmières ou assistantes sociales, étudiants en biologie et en médecine et pupilles de l’État).
En 1949 des projets de loi, gouvernementaux puis parlementaires évoquent la généralisation de l'obligation.
Celle-ci intervient en 1950 (Loi no 50-7 du 5 janvier 1950).
De 1950 à 2007 pour les enfants scolarisés.
L’obligation de vaccination par le BCG chez l’enfant et l’adolescent a été suspendue officiellement au cours de l'été 2007 (décret no 2007-1111 du 17 juillet 2007), au profit d’une recommandation de vaccination d'une population plus ciblée.Saisi le 22 janvier 2008 par le directeur général de la santé sur l'opportunité du maintien de l'obligation vaccinale chez les professionnels de santé, le Haut Conseil de la santé publique (HCSP) recommande le 5 mars 2010 la levée de l’obligation de vaccination par le BCG pour les professionnels et étudiants des carrières sanitaires et sociales mentionnés aux articles L.3112-1, R.3112-1 C et 2 du Code de la santé publique, accompagnée d’un maintien du test tuberculinique comme test de référence lors de prise de poste.
Le HCSP recommande une vaccination par le BCG, au cas par cas, après évaluation des risques par le médecin du travail uniquement pour les professionnels de santé très exposés tuberculino-négatifs.
Une évaluation de l'impact épidémiologique de la suspension de l’obligation vaccinale par le BCG et mesure de la couverture vaccinale a été faite par l'INVS (publication 2012).Selon l'avis du CSHPF du 9 mars 2007, les enfants à risque élevé de tuberculose et relevant donc d'une recommandation forte de vaccination, sont les suivants :Le CSHPF recommande également la vaccination de tout enfant dont les parents sont demandeurs, sauf contre-indication.Les zones géographiques à forte incidence tuberculeuse sont, d'après l'OMS :Du fait qu'il s'agit d'un germe vivant, le vaccin est contre-indiqué chez les personnes immuno-déprimées, y compris les personnes porteuses du VIH ou celles traitées par corticoïdes ou autres immuno-dépresseurs, ainsi qu'aux personnes porteuses d'affections malignes.Chez la femme enceinte, le vaccin est déconseillé, même en cas de risque de tuberculose.
Dans cette situation, la surveillance radiologique de la future mère permet de détecter des lésions pulmonaires débutantes, et d'introduire après des prélèvements bactériologiques un traitement antituberculeux si nécessaire.
Le but est d'éviter une contamination du nouveau né.
Cet enfant sera à vacciner dès sa naissance par le BCGLe site d'injection ne doit pas être porteur d'eczéma.Enfin, le vaccin est illogique chez les personnes traitées par médicaments antituberculeux.Plusieurs études expérimentales, sur le modèle animal ou humain, ont mis en avant un rôle immunomodulateur des mycobactéries notamment des études ciblant les mécanismes immunitaires de développement des troubles atopiques dans le cadre de l'«Hypothèse hygiéniste».
Il a été postulé puis démontré que l'exposition précoce à Mycobacterium tuberculosis ou à des mycobactéries non-tuberculeuses comme Mycobacterium vaccae diminue le risque d'atopie,.
Le BCG est lui même utilisé comme adjuvant immunologique.On a aussi remarqué que des« vaccins vivants » autres que le BCG (dont le vaccin contre la rougeole ou celui, oral, contre la polio) provoquent chez l'enfant des changements métaboliques et épigénétiques durables qui améliorent la réaction du système immunitaire inné face à d'autres infections que la tuberculose.
Cet effet collatéral des vaccins vivants, a priori positif, est mal compris.
Il semble passer par un processus dit d'« entraînement immunitaire », ; qui pourrait être une sorte de reprogrammation épigénétique d'une partie du système immunitaire.
Le système immunitaire réagit alors mieux et plus rapidement à un large éventail d'infections (pulmonaires notamment) ; au delà de la seule tuberculose et la convalescence serait moins longue.Ainsi :  Le BCG fausse la réaction à la tuberculine, compliquant le dépistage de la tuberculose.
Cela explique, en partie, le choix de santé publique fait aux États-Unis de ne pas systématiquement vacciner les enfants, puisque cela irait à l'encontre de la politique de détection et de guérison des formes latentes de la tuberculose.Toujours aux États-Unis, lorsque le test tuberculinique est positif et que la personne déclare avoir été vaccinée, une radio pulmonaire est systématiquement réalisée pour écarter l'hypothèse d'une infection réelle.À l'origine, vaccin BCG signifie vaccin bilié de Calmette et Guérin.
Cela vient du fait que la souche bactérienne en question a été obtenue par passage sur un milieu bilié comme mentionné ci-dessus.
Ainsi, on parle du vaccin bilié de Calmette et Guérin lorsque l'on parle du vaccin BCG.
Cependant, beaucoup traduisent « Bacille de Calmette et Guérin ».On ne dispose pas d'échantillons des souches originales du vaccin BCG développé par Calmette en 1921 ni même de la souche de Mycobacterium bovis à partir de laquelle il fut développé.Toutes les souches utilisées pour produire le vaccin sont issues de celle préparée entre 1908 et 1921 par Calmette et Guérin.
Ces souches se sont différenciées jusque dans les années 1960/1965, moment à partir duquel les techniques de stockage par lyophilisation stoppèrent ce processus de différenciation.
En 2001 on comptait 18 fabricants de vaccin pour 7 souches utilisées qui se distinguent par leur immunogénicité et par les procédés industriels dont elles sont issues.
Les souches Copenhague, Tokyo (ou tokyo-172 apportée par Kiyoshi Shiga au Japon en 1924), Glaxo et Pasteur sont les plus utilisées.Mycobacterium microti découvert par Wells dans les années 1930, et nommé par lui, vole bacillus, fut nommé plus tard Mycobacterium tuberculosis var.
muris, faute de pouvoir être distingué alors de Mycobacterium tuberculosis.
Un vaccin atténué fut utilisé en Tchécoslovaquie de 1951 à 1969 tandis que des essais furent conduits en Grande-Bretagne de 1950 à 1952 avec des formes non atténuées.Une étude de 2019 a montré qu'une immunisation par voie intraveineuse pourrait considérablement accroitre l'efficacité du vaccin contre la tuberculose (sur le modèle animal ; macaque rhésus) alors que jusqu'ici, le BCG était placée juste sous la peau (voie sous-cutanée).
Ces résultats aident à mieux comprendre les mécanismes de la protection vaccinale contre la tuberculose.
Reste à montrer que cette voie améliorerait aussi l'efficacité vaccinale chez enfants, adolescents et adultes humains, sans effets secondaires inacceptables.Le BCG fait partie de la liste des médicaments essentiels de l'Organisation mondiale de la santé (liste mise à jour en avril 2013).Un bâtiment de l'École nationale vétérinaire d'Alfort (ENVA), inauguré en 2014, a été nommé en l'honneur des créateurs de ce vaccin.
Ce bâtiment s'appelle bâtiment Camille-Guérin (ou BCG).Le 29 juillet 1981, la poste française émet un timbre pour Wallis-et-Futuna dans le cadre de l'anniversaire de la « 1re inoculation du BCG ».
La dessinatrice du timbre est Huguette Sainson.
Un bacille est une bactérie de forme allongée dite « en bâtonnet » — du latin baculus ou baculum, bâton — par opposition à la forme cocci (« ronde »).La forme des bactéries et la coloration de Gram sont des critères permettant de les classer.Le bacille de Koch : bactérie qui est responsable de la tuberculose.
Il s'infiltre dans l'organisme par les voies respiratoires, et se développe dans les os, les reins, la peau, les méninges, mais le plus souvent dans les poumons.Le bacille du tétanos : il se trouve dans la terre et peut pénétrer dans l'organisme par des plaies profondes.
Ce bacille libère des toxines qui, dans un premier temps, paralysent les muscles, et, si la maladie n'est pas traitée, peuvent être mortelles.Les bacilles selon leur genre, peuvent s'organiser de différentes façons :
La poliomyélite, également appelée paralysie spinale infantile ou simplement polio, est une maladie infectieuse aiguë et contagieuse spécifiquement humaine causée par le poliovirus.
L'infection, transmise par voie digestive, est le plus souvent asymptomatique ou s'exprime par des symptômes le plus souvent bénins et non spécifiques.
La poliomyélite antérieure aiguë proprement dite est l'atteinte de la moelle spinale.
Elle peut entraîner une paralysie touchant le plus souvent les membres inférieurs et pouvant atteindre l'appareil respiratoire.
Dans le premier cas, le pronostic est fonctionnel avec risque de séquelles paralytiques ; dans le deuxième cas, le pronostic peut être vital avec risque d'arrêt respiratoire.
Dans tous les cas, le traitement est symptomatique, la médecine ne reconnaissant pas de traitement curatif.Heine et Medin l'étudient et la décrivent au XIXe siècle.
Des années 1880 jusqu'à la seconde moitié du XXe siècle, la maladie sévit dans le monde entier sur un mode épidémique et handicape ou tue plusieurs millions de personnes.
Les progrès de l'hygiène et surtout la vaccination font considérablement reculer son incidence.
Les travaux de Salk dans les années 1950, puis de Sabin, mènent à la création de deux vaccins efficaces, le premier injectable et le second oral, permettant ainsi de combattre la maladie.Depuis 1988, l'éradication de la poliomyélite fait l'objet d'une initiative mondiale sous l'égide de l'OMS, de l'Unicef et du Rotary International.
Ce programme a ainsi permis de faire passer l'incidence annuelle de 350 000 cas par virus sauvage en 1988 à 37 cas en 2016, avec une maladie qui reste endémique dans seulement deux pays : le Pakistan et l'Afghanistan.
Depuis 2017, le nombre de cas par virus dérivé du vaccin oral est plus élevé que le nombre de cas par virus sauvage.
Bien que les premières épidémies de poliomyélite n'aient été identifiées qu'au XXe siècle, le poliovirus est probablement pathogène pour l'homme depuis plusieurs millénaires.
Il est difficile cependant de dater les grandes épidémies d'avant le XXe siècle, l'obligation officielle de notifier les cas de poliomyélite, dans chaque pays, n'ayant été prise qu'au début du vingtième siècle (d'abord en Suède et en Norvège en 1905, puis aux États-Unis en 1909, en Grande-Bretagne en 1911 et en France par le décret du 28 septembre 1916).Jusqu'au XIXe siècle, le poliovirus est un agent endémique et quiescent ; à partir de 1910, les épidémies deviennent régulières dans tout le monde industrialisé, principalement dans les villes et durant les mois d'été.
Conjointement au progrès des savoirs, cette évolution de la maladie, avec ses crises épidémiques parfois dramatiques, conditionne la connaissance que les médecins — et la population — ont pu en avoir.Certaines gravures de l'Égypte antique représentent des personnages handicapés moteurs avec certaines caractéristiques de la poliomyélite (adultes aux membres amyotrophiés, enfants marchant à l'aide de cannes) et des égyptologues anglais ont, dans les années 1960, reconnu des traces de poliomyélite sur un squelette datant de 3 400 ans av.
Dans ce que la tradition impute à Hippocrate d'abord et à Galien ensuite, on trouve quelques mentions de paralysies qui peuvent évoquer la poliomyélite.Si les médecins Michael Underwood en 1784, puis Giovanni Battista Monteggia en 1813, sont crédités des premières descriptions de la poliomyélite (affection caractérisée par une période fébrile de quelques jours, suivie par une paralysie des jambes), ce n'est qu'à partir des années 1860 que les médecins commencent à décrire les dommages spécifiques causés à la moelle spinale par la maladie.
Celle-ci ne se voit baptisée de son nom scientifique de « poliomyélite » — du grec polios (πολίός) « gris », -myelos (µυελός) « moelle » et -ite « inflammation », qui signifie donc « inflammation de la substance grise de la moelle épinière » — qu’en 1874 (l'expression poliomyelitis anterior acuta est d'Adolphe Kussmaul).
Jusqu'alors les symptômes de la poliomyélite avaient été décrits successivement, au début du XIXe siècle, sous les noms de « paralysie dentaire », « paralysie spinale infantile », « paralysie essentielle de l'enfant », « paralysie régressive », « myélite des cornes antérieures », « téphromyélite » (du grec tephros, « cendre grise ») et « paralysie du matin ».C'est à Jakob Heine que l'on doit la première description précise, quoiqu'incomplète, de la maladie exposée dans son ouvrage de 1840 Beobachtungen über Lähmungszustände....
Il n'introduit toutefois le terme de Spinale Kinderlähmung que dans la seconde édition publiée en 1860 sous le titre Spinale Kinderlähmung.
Cet orthopédiste allemand crée l'entité clinique qu'il distingue clairement de la paralysie cérébrale infantile, et de l'hémiplégie.
Il émet l'hypothèse du caractère épidémique de la maladie et suggère la localisation des lésions dans la corne antérieure de la moelle spinale.Cette dernière hypothèse, également émise par Guillaume Duchenne de Boulogne dans De l'électrisation, est confirmée par les autopsies pratiquées par Victor André Cornil en 1863 et par son élève Jean-Martin Charcot en 1870, qui y trouvent effectivement des altérations histologiques.
Il semble qu'avant Duchenne, la localisation des lésions dans les cornes antérieures ait été acceptée concernant les paralysies spinales de l'enfant ; l'originalité de Duchenne est de suggérer une semblable localisation pour la paralysie spinale de l'adulte.À l'automne 1881, le médecin suédois Nils August Bergenholtz diagnostique treize cas de poliomyélite antérieure aiguë et en suggère le caractère épidémique.
N'ayant pas été publiée, cette observation est restée inaperçue de ses contemporains.
En 1885, le neurologue allemand Adolf Strümpell décrit une maladie — la paraplégie spastique familiale — qu'il prend alors pour une forme cérébrale de la poliomyélite.En 1887, un pédiatre suédois expérimenté, Karl Oskar Medin, qui n'a jusqu'alors rencontré que des cas isolés de poliomyélite, fait face d'un coup à 44 cas à la polyclinique de Stockholm.
Ses observations attentives lui permettent d'établir que la paralysie qui définit jusqu'alors la maladie, est en fait la deuxième phase d'un processus signalé d'abord par de la fièvre, des maux de tête et des malaises.
Il établit aussi que la maladie peut se limiter à cette première phase.
Enfin Medin est aussi le premier à signaler le caractère épidémique de la maladie.
Il publie ses travaux en 1890, année même où il acquiert une reconnaissance internationale lors du 10e Congrès médical international de Berlin.Sur la base d'observations méthodiques faites pendant l'épidémie de 1905 en Suède (qui a fait 1 031 victimes), le docteur Ivar Wickman apporte des preuves épidémiologiques de la contagiosité signalée précédemment par Oskar Medin.
Enquêtant sur plus de 1 000 cas, visitant les domiciles de plus de 300 patients, cherchant auprès des médecins des informations précises sur les autres, il conclut que la poliomyélite est souvent transmise par des personnes apparemment en bonne santé mais atteintes de façon mineure par la maladie, ce que Wickman appellera « poliomyélite abortive ».
Sur ce point, l'originalité de Wickman n'est pas tant de signaler ces cas bénins, que de souligner leur grande occurrence et leur rôle dans la propagation de la maladie.
Par ailleurs, Wickman établit différents temps d'incubation de la maladie et en relève aussi la saisonnalité marquée.
Il s'étonne également de ce qu'elle ne touche pas que des enfants : 21,4 % des patients ont plus de 14 ans.
Enfin, c'est lui qui la nomme « maladie de Heine-Medin ».
Ses travaux conduisent la Suède à rendre obligatoire la déclaration des cas de poliomyélite ; l'épidémie de 1911-1913 donne aux chercheurs l'occasion de confirmer ses travaux, ce qui lui apporte une reconnaissance internationale.La preuve définitive du caractère infectieux de la maladie est toutefois apportée par Karl Landsteiner et Erwin Popper en 1908,.
Landsteiner injecte un extrait de la moelle spinale d'un jeune garçon décédé de poliomyélite à des rats, des cobayes, des souris ainsi qu'à deux singes : les singes — et seulement eux — sont rapidement paralysés ; à l'examen microscopique, leur moelle spinale présente le même aspect que celle d'enfants décédés de poliomyélite.Lors de ces expériences, Landsteiner et Popper ne réussissent toutefois pas à démontrer le caractère contagieux ; ils ne peuvent pas transmettre la maladie de singe à singe.
Cette transmission est réalisée en 1909 par plusieurs équipes : Römer, Flexner et Lewis, Leiner et von Wiesner, enfin Landsteiner et Levaditi (Landsteiner ayant rallié provisoirement l'Institut Pasteur pour profiter de son animalerie).
La nature de l'agent infectieux ne peut être établie.
N'ayant pu mettre en évidence aucun agent bactérien, Flexner et Lewis concluent qu'il doit s'agir de ce qui est alors appelé un virus filtrant (la nature bactérienne de l'agent a eu ses défenseurs au moins jusqu'en 1952,).
Malgré ces découvertes, aux États-Unis la grande presse continuera encore à affirmer pendant des années que le germe de la poliomyélite n'a pas encore été découvert.Sur la base d'expériences pratiquées sur des singes par Flexner et Lewis, mais aussi par Leiner et Von Wiesner, les deux équipes avancent en 1910 que le poliovirus accède au système nerveux central le long des voies nerveuses à partir de la muqueuse nasale.
Une des raisons de cette conception erronée tient au fait que Flexner a conduit ses expériences sur une des rares espèces de singes à ne pouvoir être infectée que par des injections dans le système nerveux central.
Par ailleurs, ainsi qu'on n'a pu le mettre en évidence qu'à la suite des découvertes d'Enders en 1949, les expériences réitérées de Flexner conduisent à une sélection des souches virales qui ne peuvent plus se développer que sur des tissus d'origine nerveuse et n'induisent donc qu'une faible virémie.
Dominante jusque dans les années 1930, cette conception d'un neurotropisme exclusif du poliovirus, ainsi que de son entrée par la voie nasale occulte les résultats d'expériences qui ne rentrent pas dans son cadre explicatif.C'est ce qui est arrivé aux travaux du Suédois Carl Kling (en collaboration avec Wilhelm Wernstedt et Alfred Pettersson) : prolongeant l'expérience de Lansteiner de 1909, il peut montrer que l'injection d'extraits de tissus de la gorge, du larynx ou des intestins provenant d'adolescents décédés de poliomyélite produit également une paralysie chez les singes.
Il en conclut que la contamination peut se faire par un virus présent dans la salive ou les intestins des personnes atteintes : c'est la théorie de la voie intestinale (infection oro-fécale).
Par ailleurs, Kling peut confirmer de manière expérimentale ce que Wickman a conclu de ses observations, à savoir que des personnes ne présentant aucun symptôme peuvent héberger le virus dans leur gorge ou leur intestin.
Quand Kling et son équipe présentent leurs travaux à une conférence à Washington en 1912, Flexner, directeur du Rockfeller Institute for Medical Research, alors le pôle principal de recherche sur la poliomyélite, ne leur accorde aucune crédibilité.
N'ayant pu aboutir aux résultats présentés par les Suédois après avoir repris leurs expériences, les chercheurs américains se détournent longtemps de la théorie de la voie intestinale.
Il faut attendre les travaux de Trask et de Paul de l'université Yale et surtout ceux d'Albert Sabin et de Robert Ward en 1941 pour que s'impose définitivement l'importance de la voie intestinale ; toutefois dès les années 1920 en Suède, les vues de Flexner s'accommodent de celles de Kling, fût-ce de façon marginale.Les travaux de Kling ont sans doute souffert d'arriver aux États-Unis au moment où les chercheurs américains, dans le sillage des travaux de Milton Rosenau et bientôt sous la pression de devoir agir à cause d'épidémies de poliomyélite en 1916, sont enclins à voir dans la mouche des étables le vecteur de la maladie.Au même moment Simon Flexner découvre des « substances germicides », appelées aujourd'hui « anticorps ».
Ayant d'abord extrait du sang de singes convalescents un sérum, puis en avoir injecté à d'autres singes en même temps que de la moelle infectée, il constate que ses sujets d'expérience ne manifestent aucune paralysie.
Arnold Netter a fait une découverte semblable en 1909-1910 avec Constantin Levaditi.
En 1915, il s'implique dans la promotion de ce sérum (issu de convalescents, humains ou simiens) qui sera largement utilisé lors de la sérieuse épidémie de 1916 aux États-Unis.
Faute tant d'évaluations que de traitements alternatifs, cette sérothérapie sera utilisée jusqu'en 1935 aux États-Unis, jusqu'en 1940 au Canada.Entre 1928 et 1931, Pierre Lépine démontre la survivance du virus de la poliomyélite dans les milieux extérieurs et, en particulier dans l'eau, la transmission du virus par la voie digestive au singe, l'action du chlore sur le virus.
En 1929 dans le cadre de l’Office international d’hygiène publique, Carl Kling et Constantin Levaditi montrent sur la base d'études épidémiologiques menées en Saxe et en Roumanie, que la majorité des cas de poliomyélite ont lieu dans le voisinage de cours d'eau : c'est l’hypothèse hydrique.En 1931, comparant la souche Rockefeller MV avec une souche locale isolée à Melbourne, Frank Macfarlane Burnet et Jean MacNamara montrent qu'il existe au moins deux souches de virus,.
Provenant de chercheurs inconnus situés sur un continent éloigné, ces résultats sont accueillis avec beaucoup de scepticisme.
Leur importance sera reconnue par Hammon, Francis et Rivers, à la lumière de l'échec des vaccins de 1935.Dans les années 1934 et 1935 apparaissent deux vaccins américains rivaux et indépendants : l’un de type « inactivé » mis au point par le docteur Maurice Brodie, l’autre étant une version « atténuée » élaborée par le docteur John Kolmer.
Leur utilisation à la hâte dans certaines parties des États-Unis se révèle inefficace, voire, dans certains cas, fatale.
Pendant les vingt années qui suivent cette expérience infructueuse, les chercheurs hésitent à créer ou tester un autre vaccin.
C'est à cette période que le docteur Claus W. Jungeblut propose un traitement préventif et curatif par la vitamine C. Albert Sabin — déjà une autorité à l'époque — ne peut obtenir les mêmes résultats et l'idée est alors abandonnée.
De la même façon, à la même époque, divers traitements par instillation nasale sont proposés et évalués, qui sont rejetés une fois leur inefficacité et leur nocivité établies.En 1939 Charles Armstrong réussit à multiplier la souche Lansing dans le corps de souris, ce qui facilite la recherche.
Max Theiler, mais aussi Maurice Brodie semblent y être parvenus précédemment sans que cela soit relevé à l'époque.
En 1941, une équipe de l'hôpital Johns-Hopkins à Baltimore précise le cycle du virus dans le corps humain.
Elle montre notamment que le virus doit pénétrer dans le sang avant de pouvoir accéder à la moelle spinale.
Cette découverte ouvre des perspectives pour un futur vaccin : si l'on arrivait à induire des anticorps dans le sang, alors le virus pourrait être neutralisé avant de provoquer des atteintes bulbaires.En 1945, les médecins s'interrogent encore sur l'éventualité de réservoirs animaux du virus autres que les singes, par exemple les chiens,.
Dans un autre ordre d'idées, en 1946, Thomas Francis rappelle que les populations afro-américaines ne sont pas moins exposées à la poliomyélite ainsi que l'opinion commune semble le croire,.En 1949, au moment même où deux spécialistes éminents de la poliomyélite, Sir MacFarland Burnet et William Hammon, expriment leur pessimisme quant aux perspectives de contrôle de la maladie, trois Américains font une découverte majeure.
Dans un court article paru dans la revue Science du 28 janvier 1949, Enders, Weller et Robbins, font savoir qu'ils sont parvenus à cultiver le virus poliomyélitique (souche Lansing) sur des cellules embryonnaires humaines, sur des prépuces, des reins humains puis des reins de singes,.
Cette découverte, dont l'importance n'est pas immédiatement perçue par tous les chercheurs, va rapidement donner un nouvel élan à la recherche.
Dorénavant les chercheurs peuvent disposer de grandes quantités de virus à moindre frais : jusqu'alors, en dépit de la découverte d'Armstrong d'une part, et de la publication de Sabin et Olitsky de 1936 de l'autre, le virus n'est multiplié qu'in vivo, et sur des singes.
(Constantin Levaditi a pourtant montré dès 1913 qu'il est possible de cultiver le virus sur des cellules d'origine non nerveuses).
Dans l'éventualité de la mise au point d'un vaccin c'est aussi une garantie de sécurité.
On connaît en effet les risques de paralysie et de mort (0,4 % des inoculés) attachés au vaccin antirabique de Pasteur : en cultivant le virus destiné au vaccin sur des cellules autres que d'origine nerveuse, on peut s'affranchir de ce risque.Dans le cadre de leurs travaux, Enders, Weller et Robbins ont aussi montré le moyen de détecter et mesurer facilement la multiplication effective de l'invisible virus de la poliomyélite : les cellules tissulaires dans les tubes à essais inoculés sont visiblement de plus en plus détruites avec le temps (jusqu'alors la présence du virus n'est avérée que lorsqu'un singe a été paralysé à la suite d'une injection).
Ces découvertes leur vaudront le prix Nobel de physiologie ou médecine en 1954,.
Peu de temps après, en 1952, les laboratoires Lederle font savoir que deux de leurs équipes ont réussi à cultiver un des virus de la poliomyélite (souche MEFI) sur des embryons de poulet.En 1949 toujours, Bodian, Morgan et Howe établissent que quatorze souches différentes de poliovirus se ramènent à trois sérotypes.
En 1951, un comité de la National Foundation for Infantile Paralysis précisera que toutes les souches se regroupent en trois sérotypes seulement.La découverte par Gibert Dalldorf et Graces Sickles en 1948 d'un virus différent du poliovirus, mais pouvant provoquer des paralysies semblables, a brièvement semé le trouble dans la communauté des chercheurs.
Ce trouble a rapidement été dissipé par la mise au point et la diffusion des vaccins Salk et Sabin.
Au Japon, dans les années 1960 apparut une maladie présentant des symptômes semblables à ceux de la poliomyélite et qui recevra son nom officiel en 1964 : « Subacute myelo-optic neuropathy » (SMON) ; l'origine virale, d'abord activement recherchée, a été récusée : c'est un médicament, le Clioquinol, qui a été désigné comme la cause de cette maladie qui a fait 11 007 victimes.Très tôt, on a essayé de mettre au point un vaccin.
En 1913, Römer et Flexner s'inspirent du vaccin antirabique de Pasteur ; puis Maurice Brodie et John Kolmer, Jungeblut et Sanders et Alexandre Jezierski, ainsi que Blanc et Martin en 1950.
Différentes modalités de sérovaccination sont même envisagées.
Ce n'est que dans les années 1950 que les conditions scientifiques, techniques, mais aussi financières sont réunies pour la réalisation de vaccins suffisamment sûrs et efficaces : celui de Salk d'abord, suivi en France par celui de Lépine, puis celui de Sabin (précédé par celui de Koprowski et concurrent de celui de Cox).En 1948, Isabel Morgan démontre sur des singes l'efficacité d'un vaccin inactivé, ce qui revêt une grande importance théorique.
En effet, le consensus scientifique de l'époque veut que, pour ce qui est de la poliomyélite, seul un vaccin vivant est capable de conférer une immunité.Les 17 et 27 février 1950, Hilary Koprowski, assisté de Jervis et de Norton, inocule avec succès un vaccin vivant atténué (souche TN) à quelques enfants,.
En 1951, lors d'un congrès, ses résultats sont reçus avec incrédulité.
Ils attirent cependant l'attention de Sabin, dont les travaux seront soulignés plus tard.
Sur le territoire américain, Koprowski poursuit ses essais en 1952, en 1953, en 1954 et en 1955.En 1952 Dorothy Hortsmann de l'université Yale met en évidence la présence du virus dans le sang, ce que confirmera David Bodian à l'hôpital Johns-Hopkins.Le 21 octobre 1952, le docteur Howard Howe de l'université Johns-Hopkins fait état d'un essai de vaccin trivalent à virus inactivé au formaldéhyde pratiqué sur six enfants handicapés, cinq autres enfants servant de contrôle.
Les enfants n'ont pas été soumis au virus : on mesure leur taux d'anticorps à la suite de l'inoculation des souches vaccinales,.Fin 1952, utilisant le milieu 199 de Hanks fourni par Connaught et après se l'être injecté à lui-même et à sa famille, Salk administre le vaccin aux résidents d’une institution pour enfants infirmes,.
Il conduit un autre essai dans une école de Pennsylvanie ; à l'automne 1953, Salk teste son vaccin sur 600 personnes dans la région de Pittsburgh.
La même année, il publie les résultats de ces essais, ce qui lui vaut des critiques car il utilise un virus inactivé, méthode jugée inefficace.La National Foundation for Infantile Paralysis demande aux laboratoires de lui fournir la quantité de fluide viral nécessaire pour conduire un essai sur le terrain en double aveugle sans précédent aux États-Unis, qui doit commencer le 26 avril 1954.
L’essai est l’une des plus vastes expériences médicales de l’histoire.
Il implique en effet le suivi détaillé de près de 1 800 000 enfants de 5 à 8 ans qui, ayant reçu soit le Milieu 199 comme placebo soit le vrai vaccin, doivent être observés pour voir s’ils contractent ou non la poliomyélite.
Le 12 avril 1955, l'annonce du succès de l'expérience est un énorme événement médiatique.
Les fabricants américains lancent en hâte leur vaccin pour répondre à la demande, dans le cadre de la Poliomyelitis Vaccination Assistance Act.Le 25 avril 1955, c'est l'« incident de Cutter ».
En Californie, les laboratoires Cutter, un des laboratoires retenus pour diffuser le vaccin Salk commencent à distribuer celui-ci presque immédiatement après l'annonce du succès du test.
Quelques jours plus tard, des enfants tombent malades.
Il s’avérera après analyse que certains lots contenaient encore des virus vivants.
Le 27 avril, le Surgeon General des États-Unis fait retirer tous les vaccins de Cutter du marché et le 8 mai, après le lancement d'une vaste enquête, tout le programme de vaccination aux États-Unis est interrompu par crainte d'un défaut plus large impliquant tous les vaccins.
L'incident de Cutter contaminera 220 000 personnes, dont 70 000 malades, 164 paralysies sévères et 10 décès.
Certains lots Salk produits par la société Wyeth générèrent également quelques cas de poliomyélite.Entre 1955 et 1963, des millions de personnes sont exposées au virus simien 40 présent dans les vaccins antipoliomyélitiques.
Découvert en 1960, ce virus oncogène (qui induit le cancer) puissant, sera éliminé des vaccins antipoliomyélitiques.
Les conséquences de cette contamination sont, en 2000, encore discutées.En Afrique du Sud, James Gear produit un vaccin de type Salk qu'il inocule à 15 000 enfants en 1955.En 1956, Albert Sabin inocule son vaccin à 9 000 singes, 150 chimpanzés, ainsi qu'à 133 jeunes adultes dans une prison de l'Ohio.
La même année, George Frederick Dick — connu pour avoir travaillé sur le vaccin atténué contre la fièvre jaune — invite Hilary Koprowski à conduire un vaste essai en Irlande.
Dick interrompt l'essai après avoir constaté que la souche vaccinale atténuée a regagné de sa virulence.En 1957, Salk et Pierre Lépine publient à quelques semaines d'intervalle les résultats de leurs travaux.
Pour prévenir tout risque d'infection, Lépine — qui utilise une souche différente — a procédé à une double inactivation du virus, d'abord par le formol, puis par adjonction de bêta-propiolactone.
En juillet 1957, l'Organisation mondiale de la santé (OMS) appelle à l'organisation d'essais à grande échelle pour les vaccins atténués qui respecteraient six critères de sécurité.
C'est dans le prolongement de cette déclaration que le vaccin oral d'Albert Sabin est testé à partir de 1957 sous l'égide de l'OMS en dehors des États-Unis sur 80 millions de personnes (Russie, Pays-Bas, Mexique, Chili, Suède et Japon).
Le 18 août 1958, Hilary Koprowski lance une vaste campagne de vaccination au Congo belge, qui se prolongera jusqu'en 1960,,.
De 1958 à 1960, il vaccine également 40 000 enfants en Allemagne et plus de 7 millions en Pologne (CHAT (sérotype 1) ou W-Fox (sérotype 3)) ; de 1960 à 1961, des essais ont lieu en Suisse et en 1961 en Croatie.
Les essais conduits par Cox en Floride et à Berlin montrant que des souches vaccinales redeviennent virulentes, les laboratoires Lederle abandonnent les recherches avec les souches utilisées par Cox.En 1959, le comité spécial, créé un an auparavant par les National Institutes of Health afin d'évaluer les souches destinées au vaccin oral, établit la supériorité des souches de Sabin sur celles de Koprowski et de Cox (et sur celles cultivées à l'université Yale), ce qui conduit le Surgeon General à en recommander l'usage,.
Le 24 avril 1960, c'est le Sabin Sunday (« Dimanche de Sabin »), premier test massif du vaccin Sabin aux États-Unis.
Le vaccin oral monovalent de type 1 (MOPV1) et celui de type 2 (MOPV2) sont autorisés en 1961 aux États-Unis, le MOPV3 l'est en 1962.En mai 1962, le Congrès des États-Unis examine un projet visant à édifier le cadre de futures campagnes de vaccinations massives (US Congressional Hearings HR 10541).
À l'occasion d'auditions menées à cet effet, le Congrès prend connaissance notamment de la position critique du Dr Bernard Greenberg qui signale l'existence de différents biais statistiques ayant conduit à surestimer l'effet des premières vaccinations antipoliomyélitiques – avec le vaccin Salk – qu'il juge responsables au contraire d'une augmentation des cas de poliomyélite.
La loi est cependant adoptée la même année sous le nom de Vaccination Assistance Act PL 87-868.
Elle débloque des fonds fédéraux pour l'achat de vaccins et pour l'établissement de statistiques.En 1963, le vaccin oral Sabin trivalent (tOPV) obtient son autorisation.
Le recours au vaccin Salk diminue rapidement pour ne représenter que 2 % des vaccins antipoliomyélitiques utilisés annuellement aux États-Unis.
En France, la vaccination devient obligatoire, et par conséquent gratuite, en 1964.
Elle a été introduite dans le calendrier vaccinal français en 1958 (Salk), puis en 1962 (Sabin).Vingt ans plus tard, en 1987, le « vaccin Salk amélioré » (« enhanced-potency IPV ») obtient son autorisation aux États-Unis ; il a été mis au point en 1978 selon le procédé de culture sur cellules diploïdes humaines,.
En 1997, l'Advisory Committee on Immunization Practices (ACIP) recommande l'usage du vaccin inactivé pour les deux premières injections, les deux autres étant pratiquées avec un vaccin oral.
Le 17 juin 1999, l'ACIP ne recommande plus que le seul vaccin inactivé.Dans les années 2000, suivant une hypothèse posée dans les années 1990, le journaliste Edward Hooper postule que l'origine du sida se trouve dans les campagnes de vaccination antipoliomyélitiques menées par Koprowski au Congo belge à la fin des années 1950, mais son hypothèse est rejetée par des spécialistes,.En 1948, le docteur Fred R. Klenner met au point une approche curative basée sur l'injection de doses massives (plusieurs dizaines de grammes par jour) de vitamine C.
Sur 60 malades lors de l'épidémie de 1948 en Caroline du Nord, tous guérissent sans séquelles en 3 à 5 jours.
Il fait connaitre sa méthode lors de la session annuelle de l'Association médicale américaine et publiera ultérieurement des articles, sur le sujet, mais le manque d'intérêt de la part de la presse scientifique et des spécialistes faisant autorité dans le domaine à une époque où tout le monde pensait plutôt à la possibilité d'une vaccination, fait qu'il est peu suivi et sa méthode tombe dans l'oubli.À la même époque, un traitement par le chlorure de magnésium est proposé par le Dr Auguste Neveu en se basant sur les travaux du Dr Pierre Delbet ; il revendique également des cas de guérisons.En 1950, William Hammon purifie des gamma globulines à partir du plasma sanguin de patients guéris de la poliomyélite.
Il propose l'injection de sérum anti-poliomyélitique pour prévenir la maladie et réduire la sévérité des symptômes chez les patients atteints.
Un grand essai clinique donne des résultats encourageants, laissant supposer que les gamma globulines anti-poliomyélitiques peuvent prévenir la survenue d'une poliomyélite paralytique dans environ 80 % des cas.
Cependant l'immunisation passive par sérothérapie s'avère impossible à mettre en œuvre à grande échelle, principalement en raison de la quantité insuffisante de sérum disponible.
La recherche se détourne alors de cette stratégie et se focalise sur la mise au point d'un vaccin.Historiquement, les atteintes les plus sévères ont demandé le recours à la ventilation non invasive à pression négative, plus communément appelée poumon d'acier ; cette méthode a permis à des milliers de patients d'être ventilés de façon acceptable dans l'attente de la récupération d'une autonomie respiratoire (généralement au bout d'une à deux semaines dans les meilleurs cas).
Lors de la grande épidémie de poliomyélite au Danemark en 1952, le médecin anesthésiste danois Björn Ibsen a développé l'assistance respiratoire à long terme par ventilation invasive à pression positive (d'abord) manuelle à l'aide d'un insufflateur.
Le taux de mortalité des patients est passé de 87 % à environ 25 % en l'espace de quelques semaines.
Depuis, les patients atteints de détresse respiratoire nécessitent une prise en charge réanimatoire et peuvent nécessiter l'assistance ventilatoire à domicile à l'aide de respirateurs artificiels portatifs.Au-delà de son importante contribution à l'avancée du savoir médical et scientifique dans les domaines de la virologie et de l'immunologie, l'étude de la poliomyélite est aussi à l'origine d'avancées importantes dans le domaine de la rééducation dont profitent par exemple les personnes victimes de traumatisme crânien, d'accidents vasculaires cérébraux ou de maladies neurodégénératives.
En France, dans le sillage de la création à Garches en 1949 du Centre national du traitement des séquelles de poliomyélite, aujourd'hui partie de l'hôpital Raymond-Poincaré, se sont développés l’hydrothérapie et la balnéothérapie, la kinésithérapie respiratoire ainsi que les transports médicalisés.
La diffusion et l'amélioration des orthèses des membres et du rachis, l'établissement d'un savoir concernant l'évolutivité de la scoliose et des déformations rachidiennes, ainsi que la naissance de la chirurgie fonctionnelle sont aussi le fruit des efforts déployés à cette époque.En 1985, le Pan American Health Organization (PAHO), section régionale de l'OMS, décide d'éradiquer la poliomyélite des Amériques.
En 1988, la quarante et unième Assemblée mondiale de la Santé, composée alors des délégués de 166 États membres, adopte une résolution visant l’éradication de la poliomyélite dans le monde.
C’est ainsi que l’Initiative mondiale pour l’éradication de la poliomyélite est née, sous la direction de l’OMS, de l’UNICEF, des Centers for Disease Control and Prevention des États-Unis (CDC) et du Rotary International (Global Polio Eradication Initiative).
Ce programme est mis sur pied à la suite de la certification de l’éradication de la variole en 1980, des progrès accomplis au cours des années 1980 grâce aux opérations d’élimination du poliovirus dans les Amériques et de l’engagement pris par Rotary International de mobiliser des fonds pour protéger tous les enfants de cette maladie.La surveillance de la poliomyélite s’effectue grâce à un réseau de laboratoires qui recherchent les poliovirus sauvages chez tous les enfants de moins de 15 ans atteints de paralysie flasque aiguë (PFA), le symptôme qui caractérise la maladie.
La PFA pouvant être le symptôme d'autres maladies, des échantillons de selles doivent être rapidement prélevés et analysés en laboratoire pour confirmer la cause de la paralysie.En 1992 est découvert un foyer de poliomyélite aux Pays-Bas, dans un groupe qui refuse la vaccination.
Fin 1999, le nombre de cas a reculé de 95 % avec 7 094 nouveaux cas recensés pour 20 000 malades au total et le nombre de pays atteints est passé de 125 à 30.Pour mettre en œuvre l’effort intensifié d’éradication de la poliomyélite en 2007-2008, le financement classique par les partenaires de l’aide au développement a été largement complété par des ressources intérieures des pays d’endémie restants.
L'Inde, le Nigeria et le Pakistan annoncent des engagements dans la lutte contre le poliovirus.
Le Rotary International et la Fondation Bill-et-Melinda-Gates annoncent en novembre 2007 un partenariat destiné à injecter 200 millions US$ dans le programme.
Le Rotary affirme que sa participation au programme, grâce à ce partenariat de financement, dépassera 1,2 milliard US$.
Les cas sont essentiellement confinés géographiquement aux endroits où la couverture vaccinale est sub-optimale (30 % d'enfants non vaccinés au Nigéria, les cas indiens étant limités également à une région réticente aux vaccinations).
La présence de cas sporadiques chez des personnes dûment vaccinées soulève des questions.L'OMS recommande un taux de 90 % de vaccination des populations, qui est atteint dans la plupart des pays riches.
En 2009-2010 apparaît une forte recrudescence des cas au Tadjikistan (pays récemment certifié indemne de poliomyélite, devenu le premier pays à voir ressurgir la maladie, avec 75 % des cas de poliomyélite recensés dans le monde ; taux très supérieur à celui relevé en Inde et au Nigeria).
Le taux de vaccination était au Tadjikistan d'environ 75 % mais diminue à la suite de doutes de la population sur la sécurité de la vaccination, notamment portés par des courants religieux ou anti-gouvernementaux.
L'OMS y encourage une campagne de vaccination et certains auteurs craignent une diffusion du virus vers d'autres régions du monde (en Ontario, le taux de vaccination est comparable à celui du Tadjikistan) alors même que le tourisme se développe dans certains pays à risque.En 2012, la maladie est encore endémique dans trois pays, Nigéria, Pakistan et Afghanistan qui concentrent la quasi-totalité des cas.Un premier cas de poliomyélite sur le territoire américain, a été détecté en juillet 2013 peu de temps après la découverte de cas à Londres et à Jérusalem.
Des études génétiques suggèrent que les virus américains et israéliens ont été importés de Londres, trois régions du monde qu’on pensait débarrassées de la maladie.En 2014, durant la période habituelle de faible circulation du virus, une dissémination a lieu dans plusieurs régions : Asie centrale, Moyen-Orient et Afrique centrale, et la circulation du virus concerne au total 10 pays.
L'OMS estime que ce risque constitue une urgence de santé publique à portée internationale et publie des recommandations spécifiques,,.En août 2020, l'OMS annonce l'éradication de la poliomyélite par virus sauvage en Afrique, le Nigeria n'ayant plus connu de cas depuis quatre ans,.
Tandis que seulement deux pays connaissent encore des cas de contamination par le virus sauvage: l'Afghanistan (29 cas) et le Pakistan (58 cas).Toutefois, plus de 200 cas causés par un virus dérivé d’une souche vaccinale sont survenus en Afrique, en 2019-2020, dont ceux signalés au Soudan en août 2020.L'OMS indique qu'à ce stade un budget de 19 milliards de US$ a été engagé dans le programme d'éradication sur 30 ans.
Cependant le 2 avril 2020, la direction de The Global Polio Eradication Initiative annonce la pause de ses activités de vaccination pour une durée de quelques mois, afin de mettre ses ressources en priorité à disposition de la lutte contre la COVID-19 dans les pays concernés.
Seules les fonctions critiques de la lutte contre la polio sont maintenues : à savoir les moyens de surveillance, et la gestion et conservation des vaccins.
Certains considèrent d'ailleurs que cette quête de l'éradication a un coût démesuré et qu'elle a lieu aux dépens d'autres opérations (amélioration sanitaire par exemple) qui apporteraient un bénéfice plus important.En septembre 2022, la propagation du virus a nécessité de déclarer l'état d'urgence au nord-ouest de New York, afin de freiner l'épidémie qui sévit depuis 2013.
La poliomyélite est causée par les poliovirus, virus à ARN du genre Entérovirus et de la famille des Picornaviridae ; ils ressemblent au virus de l'hépatite A qui ont la même taille et sont de la même famille.
Ils ont les mêmes propriétés, les mêmes affinités pour aller s'installer dans l'intestin, la même contamination par la bouche.L'Homme est le seul réservoir du virus.
Les poliovirus ont un tropisme préférentiel pour le tractus digestif.
Leur structure est très simple, composée d'un génome ribonucléique de sens positif entouré d'une capside.
La capside protège le matériel génétique et rend possible l'infection de certains types de cellules par le virus.
Trois sérotypes de poliovirus ont été identifiés : poliovirus type 1 (PV1), type 2 (PV2) et type 3 (PV3), chacun différant légèrement des autres par les protéines de sa capside.
Tous trois sont extrêmement virulents et produisent les mêmes symptômes.
PV1 est la forme la plus régulièrement rencontrée, et la plus fréquemment associée à la paralysie.En de rares circonstances, des poliomyélites peuvent survenir des suites d'infections produites par des entérovirus autres que les poliovirus.
S'il peut « survivre » dans les eaux, la vase, etc., le poliovirus — comme tout virus — n'est capable de se multiplier qu'au sein de cellules vivantes : dans le milieu extérieur, faute de pouvoir se multiplier, il est donc voué à disparaître au bout de quelques mois.La poliomyélite est très contagieuse et se transmet facilement par contact interhumain.
En zone d'épidémie, les souches sauvages de poliovirus sont théoriquement capables d'infecter la totalité de la population humaine.
La transmission est habituellement saisonnière sous les climats tempérés, avec un pic en été et en automne.
Ces différences saisonnières sont beaucoup moins prononcées sous les climats tropicaux.
La période d'incubation, qui sépare la première exposition des premiers symptômes, est habituellement comprise entre six et vingt jours, avec des valeurs extrêmes allant de trois à trente-cinq jours.
Des particules virales sont excrétées dans les fèces durant plusieurs semaines après l'infection initiale.
La transmission de la maladie est ainsi essentiellement digestive par voie oro-fécale, via l'ingestion d'aliments ou d'eau contaminés.
Occasionnellement, la maladie peut être transmise par voie oro-orale via la salive, voie qui semble prépondérante dans les zones à haut niveau d'hygiène.
La transmission peut se faire par les sécrétions respiratoires (postillons émis lors de toux ou d’éternuements) d’une personne contaminée car celle-ci élimine le virus dans les sécrétions rhinopharyngées pendant les premiers jours de l’infection.
La contagiosité est maximale entre les sept à dix jours qui précèdent et les sept à dix jours qui suivent l'apparition des symptômes, mais la transmission est possible tant que le virus persiste dans la salive et les matières fécales.Parmi les facteurs qui augmentent le risque d'infection ou influencent péjorativement la sévérité de la maladie ont été cités l'immunodépression, la malnutrition, l'amygdalectomie, l'activité physique suivant immédiatement la survenue de la paralysie, l'injection intramusculaire de vaccins ou de médicaments et la grossesse.
Bien que le virus franchisse le placenta durant la grossesse, le fœtus semble n'être atteint ni en cas d'infection maternelle ni en cas de vaccination.
Les anticorps maternels franchissent également la barrière placentaire, apportant au fœtus une immunité passive protectrice durant la grossesse et les premiers mois de la vie.Le poliovirus pénètre dans l'organisme par la bouche et infecte les premières cellules avec lesquelles il entre en contact dans le pharynx puis dans la muqueuse intestinale.
Il infecte les cellules par l'intermédiaire d'une glycoprotéine transmembranaire de la famille des immunoglobulines située à la surface de la cellule, le récepteur CD155 ou récepteur du poliovirus.
Le virus prend alors le contrôle des processus génétiques de la cellule hôte et commence sa réplication.
Le poliovirus se multiplie au sein des cellules gastro-intestinales durant une semaine environ, puis migre vers les amygdales (spécifiquement les cellules dendritiques folliculaires des centres germinaux amygdaliens), le tissu lymphoïde intestinal (dont les cellules M des plaques de Peyer) et les ganglions lymphatiques cervicaux et mésentériques, où il se multiplie activement.
Il peut alors passer dans la circulation sanguine.La phase de circulation sanguine du virus, ou virémie, permet sa distribution à différents sites de l'organisme.
Le poliovirus peut survivre et se multiplier dans le sang et dans la lymphe pendant des périodes prolongées allant parfois jusqu'à 17 semaines.
La virémie est responsable du syndrome grippal généralement observé dans la première phase des infections à poliovirus symptomatiques.
Dans une faible proportion de cas, il peut migrer et se répliquer dans le tissu adipeux, le système phagocytaire mononucléé et les muscles.
Le passage du virus dans le système nerveux central est responsable d'une réponse inflammatoire locale.
Dans la plupart des cas, celle-ci est limitée aux méninges et définit une méningite aseptique non paralytique.
L'infection du parenchyme cérébral définit une encéphalite aiguë.
Le mécanisme par lequel le poliovirus infecte le système nerveux central n'est pas entièrement élucidé en 2005, mais il semble indépendant de l'âge, du sexe et du niveau socioéconomique du sujet.Le contact avec le virus (par infection ou par vaccination) est immunisant.
Chez les sujets immunisés, des anticorps de type IgA sont sécrétés au niveau des amygdales et de la muqueuse digestive qui sont capables de bloquer la réplication virale.
Les IgG et IgM sont protecteurs vis-à-vis de l'atteinte du motoneurone.
L'infection ou la vaccination par un sérotype de poliovirus n'immunise pas contre les deux autres, l'immunité complète requiert donc l'exposition à chaque sérotype.La poliomyélite touche principalement les enfants, sans distinction de sexe.
Chez les adultes, les personnes immunodéprimées sont aussi à risque.Il semble admis que, dans les climats tempérés, la poliomyélite survient le plus souvent en été, tandis que dans les climats tropicaux, il n'y a pas de variabilité saisonnière.
Néanmoins, d'après une autre source, la poliomyélite présenterait deux pics de transmission en Afrique, de février à mai et d'août à novembre, le deuxième pic étant plus important ; tandis que dans les pays à climat tempérés, la transmission serait plus élevée en hiver.Concernant la mortalité, pour la poliomyélite paralytique, elle est plus élevée chez l'adulte, mesurée à 15-30 %, contre 2-5 % chez l'enfant.
Pour la forme bulbaire, le taux est plus élevé que pour la forme paralytique, il est mesuré aux alentours de 25-75 %.Dans le monde, la polio (virus sauvage) a été déclarée officiellement éradiquée aux Amériques (1994), dans le Pacifique occidental (2000), en Europe (2002), dans l'Asie du Sud-Est dont l'Inde (2014), en Afrique (2020) et ne subsiste plus qu'au Pakistan et en Afghanistan.
En France, le dernier cas de poliomyélite autochtone remonte à 1989 et le dernier cas importé a été déclaré en 1995.Le virus sauvage type 2 a été certifié éradiqué en 2015 (dernier cas en 1999), et le sauvage type 3 en 2019 (dernier cas en 2012).
À cette date, le virus type 1 est ainsi le seul type de virus sauvage encore en circulation.Cependant avec la baisse des cas par virus sauvage, le nombre de cas par virus vaccinaux est devenu majoritaire.En 2018, 33 cas mondiaux par virus sauvage ont été notifiés (21 en Afghanistan et 12 au Pakistan), et 104 par virus vaccinal (77 en Afrique et 27 en Asie).En 2019, on compte 176 cas par virus sauvage, 29 en Afghanistan et 147 au Pakistan, et 378 cas par virus vaccinal dans 19 pays.En 2020, on compte 140 cas par virus sauvage, 56 en Afghanistan et 84 au Pakistan, et 1039 cas par virus vaccinal dans 26 pays pour la plupart africains.Chez la plupart des sujets immunocompétents, l'infection à poliovirus reste asymptomatique, les anticorps neutralisants, sécrétés au niveau digestif, assurent en effet un rôle protecteur vis-à-vis du virus.
Le terme « poliomyélite » se réfère à une infection symptomatique causée indistinctement par les trois sérotypes de poliovirus.
Deux formes principales d'infection symptomatique sont décrites : une forme extra-neurologique parfois qualifiée de « poliomyélite abortive » (97 % des cas) d'évolution le plus souvent favorable, et une forme neurologique avec atteinte du système nerveux central (3 % des cas environ) qui peut être paralytique ou non paralytique,,.Si le virus franchit la barrière digestive, l'infection se traduit par des manifestations générales mineures et non spécifiques allant de l'infection des voies respiratoires (maux de gorge, toux, fièvre) aux signes digestifs (nausées, vomissements, douleurs abdominales, constipation ou, rarement, diarrhée) en passant par le syndrome grippal.
Myocardite et péricardite sont possibles et parfois associées.Le virus atteint le système nerveux central dans environ 3 % des cas, parmi lesquels une majorité développe un syndrome méningé fébrile (céphalées, douleurs cervicales et dorsales, fièvre, nausées, vomissements, léthargie) traduisant une méningite à liquide cérébrospinal clair, d'évolution favorable.
L'absence de paralysie est alors la règle,.
Les formes encéphalitiques sont rares et surviennent presque exclusivement chez les nourrissons, s'accompagnant d'une fièvre élevée, de modifications du comportement, de crises convulsives généralisées et de paralysie spastique.
Une paralysie faciale périphérique isolée est possible.Entre 1 sujet sur 200 et 1 sujet sur 1 000 évolue vers une maladie paralytique qui se traduit par la survenue d'une faiblesse musculaire croissante jusqu'à la paralysie complète.
Après incubation, la maladie se traduit par un syndrome infectieux fébrile non spécifique (pharyngite, troubles digestifs) suivi de l'installation rapide, en quelques heures, de paralysies flasques sans atteinte sensitive.
L'atteinte est toujours asymétrique.Le poliovirus migre le long des trajets nerveux et atteint les motoneurones de la corne antérieure de la moelle spinale, du tronc cérébral ou du cortex moteur dans lesquels il se réplique et qu'il détruit.
La paralysie qui en résulte définit la poliomyélite paralysante, dont les diverses variantes (spinale, bulbaire, spinobulbaire) diffèrent par l'étendue des dommages causés aux motoneurones, par l'inflammation subséquente et par les régions du système nerveux central qui sont touchées.
Les lésions s'étendent au ganglion spinal, parfois à la formation réticulée, aux noyaux vestibulaires, au vermis cérébelleux et aux noyaux gris centraux.
L'inflammation associée à la destruction neuronale altère souvent la couleur et l'apparence de la substance grise de la moelle spinale, qui apparaît rougeâtre et tuméfiée.
Des lésions du prosencéphale sont également associées à la poliomyélite paralytique, touchant particulièrement le thalamus et l'hypothalamus.
En 2008, les mécanismes moléculaires qui conduisent à la paralysie restent mal compris.La propension à développer une poliomyélite paralytique augmente avec l'âge, de même que le risque de paralysie étendue.
Chez les enfants, la méningite non paralytique est la conséquence la plus fréquente de l'infection du système nerveux central.
La paralysie ne survient que dans 1 cas sur 1 000 et, avant l'âge de cinq ans, ne concerne généralement qu'un membre inférieur.
Chez l'adulte, la paralysie survient dans 1 cas sur 75.
Elle s'étend plus volontiers aux muscles du thorax et de l'abdomen, voire aux quatre membres (quadriplégie).
Le taux de paralysie varie également selon le sérotype viral.
Ainsi le PV1 (poliovirus 1) en est-il le premier pourvoyeur (1 cas sur 200) devant le PV3 et le PV2 (1 cas sur 2 000).La poliomyélite antérieure aiguë se traduit par une symptomatologie précoce qui associe fièvre élevée, céphalées, raideur cervicale et dorsale, myalgies, faiblesse asymétrique de plusieurs muscles, sensibilité au toucher, troubles de la déglutition, disparition des réflexes ostéotendineux, paresthésies, irritabilité, constipation, difficultés mictionnelles.
La paralysie survient en général de un à dix jours après le début des symptômes, progresse durant deux ou trois jours, et cesse de s'étendre au moment de la défervescence.La poliomyélite spinale est la forme la plus courante de poliomyélite paralytique.
Elle résulte de l'invasion par le poliovirus des motoneurones de la corne antérieure de la moelle spinale (partie ventrale de la substance grise), qui véhiculent l'ordre transmis par le cortex moteur et sont responsables des mouvements.
Les nerfs moteurs spinaux innervent les muscles du tronc (dont les muscles intercostaux et le diaphragme) et des membres.L'infection virale cause une inflammation des cellules nerveuses, conduisant à la destruction partielle ou totale du ganglion des motoneurones.
La mort des motoneurones entraîne leur dégénérescence wallérienne.
Les cellules musculaires ne recevant plus de signaux en provenance du cortex moteur ni de la moelle spinale s'atrophient, s'affaiblissent et deviennent rapidement inactives.
La destruction partielle totale de l'innervation d'un muscle détermine l'intensité de sa paralysie.
L'évolution vers une paralysie maximale est rapide (de deux à quatre jours) et s'associe généralement à une fièvre et des myalgies.
L'arc du réflexe ostéotendineux étant interrompu, les réflexes ostéotendineux sont abolis.
En revanche, l'intégrité des nerfs sensitifs permet la préservation de la somesthésie.La distribution de la paralysie spinale dépend de l'étage médullaire atteint, qui peut être cervical, thoracique, lombaire ou combiné.
L'atteinte peut être bilatérale, mais elle est toujours asymétrique.
La paralysie est souvent plus marquée pour les muscles proximaux (proches de la racine des membres) que pour les muscles distaux (doigts et orteils).La poliomyélite bulbaire représente 2 % des cas de poliomyélite paralytique.
Elle est la conséquence de l'invasion et de la destruction par le poliovirus des motoneurones de la région bulbaire du tronc cérébral qui entraîne la paralysie des muscles innervés par les nerfs crâniens, des signes d'encéphalite, des difficultés respiratoires, des troubles de la phonation et de la déglutition.
Les trois nerfs crâniens les plus critiques sont le nerf glossopharyngien (IXe paire), qui contrôle les mouvements de l'oropharynx et la déglutition, le nerf vague (Xe paire) qui joue notamment un rôle majeur dans la phonation et le nerf accessoire (XIe paire) qui innerve le sterno-cléido-mastoïdien et le trapèze.
L'atteinte du nerf trijumeau (Ve paire) et du nerf facial (VIIe paire) expose à des troubles de la mastication et à une paralysie faciale.
L'atteinte des nerfs oculomoteurs (IIIe et VIe paires) entraîne une diplopie.Forme combinée des deux précédentes, la poliomyélite spinobulbaire représente 19 % des cas de poliomyélite paralytique.
Elle est parfois qualifiée de « poliomyélite respiratoire ».
Le virus s'attaque à la partie supérieure de la moelle cervicale (de C2 à C5) exposant à la paralysie diaphragmatique par atteinte du nerf phrénique.
Cette forme redoutable peut ainsi nécessiter le recours à la ventilation mécanique.
Elle peut conduire également à la paralysie des membres, à des troubles de la déglutition et de la fonction cardiaque.La guérison est la règle chez les sujets porteurs d'une poliomyélite abortive.
En cas de méningite aseptique, les symptômes peuvent persister de deux à dix jours mais l'évolution est presque toujours favorable.
En cas de poliomyélite spinale, la paralysie est définitive si l'innervation motrice du muscle est entièrement détruite.
Les cellules endommagées mais survivantes peuvent récupérer une partie de leur fonctionnement quatre à six semaines après les premiers signes.
La moitié des patients atteints de poliomyélite spinale récupère totalement, un quart récupère avec des séquelles modérées et un quart présente un handicap sévère.
Le degré de paralysie à la phase aiguë et de paralysie résiduelle semble proportionnel à l'intensité de la virémie, et inversement proportionnel au degré d'immunité.
La poliomyélite spinale est rarement mortelle.En l'absence d'assistance respiratoire, les formes s'accompagnant d'atteinte respiratoire évoluent vers les pneumopathies d'inhalation et vers l'asphyxie.
Au total, de 5 à 10 % des poliomyélites paralytiques évoluent vers la mort par paralysie des muscles respiratoires.
Le taux de mortalité varie selon l'âge : de 2 à 5 % des enfants et de 15 à 30 % des adultes décèdent des suites de la maladie.
La poliomyélite bulbaire est la plus meurtrière, constamment mortelle en l'absence de traitement et d'assistance respiratoire et tuant de 25 à 75 % des patients pris en charge,.
La ventilation mécanique en pression positive, méthode de ventilation artificielle de référence en 1994, permet de réduire la mortalité à 15 %.Trente à quarante ans après la phase aiguë de la maladie, alors que leur état général est depuis longtemps stabilisé, les malades peuvent ressentir une grande fatigue, une faiblesse musculaire progressive et des douleurs articulaires.
Parfois ces symptômes s'accompagnent de difficultés respiratoires ou d'atrophie musculaire : c'est le syndrome post-poliomyélite, décrit pour la première fois par les neurologues Jean-Martin Charcot et Fulgence Raymond en 1875, mais qui n'a été ainsi nommé que dans les années 1980.
Il toucherait un survivant sur deux.
En 2002, 55,000 personnes auraient des séquelles de poliomyélite en France, 700,000 en Europe et plus d'un million aux États-Unis.Le Dr Richard L. Bruno signale la similitude du syndrome post-poliomyélite avec le syndrome de fatigue chronique ; ce serait la conséquence de lésions cérébrales en rapport avec une infection préalable par un poliovirus ou un autre type de virus.L'homme est le seul hôte naturel connu chez qui le virus provoque la maladie, ce qui a permis d'envisager un programme d'éradication.
Si, dès 1909, il est établi que les singes de certaines espèces peuvent développer la maladie à la suite d'inoculations, il a fallu du temps pour déterminer non seulement la sensibilité de chaque espèce de singe au virus — et à ses différents sérotypes — mais aussi pour savoir s'ils peuvent héberger le virus et être source de contagion en conditions naturelles : en 1948, cet inventaire se poursuit encore,.Les singes et les chimpanzés développent une paralysie lorsque le virus est inoculé dans leur cerveau ou leur moelle spinale.
Les chimpanzés et les singes Cynomolgus (macaques crabiers) peuvent être infectés par la voie orale, mais ne présentent qu'exceptionnellement des signes cliniques.
Ils peuvent parfois développer une virémie et, en des cas très rares, une paralysie.
Une poliomyélite paralytique a été décrite chez des chimpanzés, des orang-outans et des gorilles en captivité, ainsi que chez des chimpanzés sauvages.
Cependant, ces espèces sont probablement des hôtes accidentels et leurs populations vivant à l’état sauvage sont trop petites et trop dispersées géographiquement pour pouvoir permettre la transmission du poliovirus ou constituer une menace de réintroduction du virus dans les populations humaines une fois éradication obtenue.Les singes rhésus (Macaca Mulatta) font partie de ces rares espèces de singes qui ne développent pas d'infection à la suite de l'ingestion du poliovirus (qui ne se développe tout simplement pas dans son appareil digestif).
Si Flexner a défendu son hypothèse erronée de neurotropisme exclusif, c'est en grande partie du au fait qu'il avait justement expérimenté sur ces singes rhésus.Des sérums neutralisant le poliovirus ont été retrouvés chez d’autres vertébrés, par exemple chez des vaches, des chevaux, des poulets, des chiens, des chèvres et des moutons, mais sans signes d’infection.L'analyse du liquide cérébrospinal (LCS) recueilli par ponction lombaire révèle un liquide clair, une hypercytose (nombre élevé de cellules dans un liquide organique) modérée à prédominance de lymphocytes, une glycorachie normale, une protéinorachie normale ou modérément augmentée, traduisant une méningite aseptique.
Répété 15 jours plus tard, l'examen montre généralement une régression du nombre de cellules et une majoration de la protéinorachie.
Le recours à la ponction lombaire n'est toutefois pas dénué de risque, notamment en période épidémique avérée.La sérologie poliomyélitique est sensible et précoce, mais le diagnostic de certitude nécessite la mise en évidence directe du poliovirus sur un écouvillonnage pharyngé, dans les selles ou dans le LCS.
Celle-ci n'est pratiquée que de façon exceptionnelle en zone d'endémie car coûteuse et non indispensable.
Elle s'avère nécessaire en revanche dans les cas douteux, et particulièrement dans les régions où la maladie a disparu.
L'identification du matériel génétique viral par réaction en chaîne par polymérase permet en outre de distinguer les souches sauvages des souches vaccinales utilisées pour la vaccination orale.
Cette distinction est importante puisque pour chaque cas rapporté de poliomyélite paralytique, on estime qu'il existe 200 à 3 000 autres cas asymptomatiques mais contagieux.Le diagnostic différentiel est très difficile dans les formes non paralytiques, cette maladie passant souvent pour une infection banale rhinopharyngée ou digestive.
Lorsqu'il existe un syndrome méningé, il ne diffère pas des autres méningites virales.La poliomyélite paralytique est cliniquement suspectée devant la survenue aiguë de paralysies flasques d'un ou de plusieurs membres avec diminution ou abolition des réflexes ostéo-tendineux, sans atteinte sensitive ni trouble des fonctions cognitives.
D'autres caractéristiques cliniques d'une paralysie flasque aiguë pouvant orienter vers une poliomyélite peuvent être le caractère asymétrique, la rapidité de progression, l'association à de la fièvre et la survenue de séquelle.
Le diagnostic est évoqué facilement chez les autochtones des zones endémiques, plus rarement chez les sujets voyageurs non immunisés.Le diagnostic de poliomyélite nécessite l'exclusion d'une autre cause notamment inflammatoire (syndrome de Guillain-Barré, myélite transverse aiguë) ou mécanique (compression médullaire ou radiculaire, traumatisme lié à une injection intramusculaire).
D'autres types d'entérovirus pourraient causer une paralysie de type poliomyélitique.
Des arboviroses peuvent aussi être évoquées.
La fièvre du Nil occidental en est un exemple,.
On peut également citer des maladies d'origine bactérienne comme la diphtérie ou le botulisme.
D'autres diagnotics peuvent être évoqués tels que le syndrome de Kugelberg-Welander ou une dystrophie myotonique.La médecine ne reconnaît pas de traitement curatif de la poliomyélite.
Les formes extra-neurologiques et les méningites aseptiques, si elles sont diagnostiquées comme telles, ne relèvent que de mesures symptomatiques.
En cas de poliomyélite paralytique, les objectifs de la prise en charge thérapeutique portent sur l'atténuation des symptômes, l'accélération de la récupération et la prévention des complications.
Le traitement comporte des antalgiques pour lutter contre la douleur, des antibiotiques pour traiter les surinfections bactériennes, l'exercice physique modéré et un régime alimentaire adapté.
Le traitement nécessite souvent une convalescence prolongée assortie d'une rééducation physique, de l'utilisation d'orthèse, de chaussures orthopédiques, d'aide à la mobilité (chaise roulante, canne...) et, dans certains cas, d'interventions orthopédiques.La prévention non spécifique repose essentiellement sur le respect des règles d'hygiène alimentaire et sur la propreté des mains.
La vaccination constitue le seul moyen de prévention spécifique.En France, l'obligation vaccinale concernant la poliomyélite est instituée par la loi no 64-643 du 1er juillet 1964 et par plusieurs décrets d'application, comme celui no 65-213 du 19 mars 1965,.Deux vaccins antipoliomyélitiques sont disponibles : l'un inactivé administré par injection sous-cutanée ou intra-musculaire, l'autre vivant atténué administré par voie orale.
Les deux confèrent une immunité efficace contre l'infection à poliovirus et préviennent sa transmission de personne à personne.
Ils permettent ainsi la protection individuelle et l'immunité collective.Le vaccin antipoliomyélitique injectable (VPI), à virus inactivé, a été développé en 1952 par l'équipe de Jonas Salk et officiellement annoncé le 12 avril 1955.
Il a été élaboré à partir de poliovirus cultivés sur lignée cellulaire simienne, puis inactivés chimiquement par le formaldéhyde.
Il confère une immunité protectrice chez 90 % des sujets après deux injections et chez plus de 99 % des sujets après trois injections.
Trivalent, il protège contre les trois souches de poliovirus (PV1, PV2 et PV3).
Il peut être administré dès l'âge de six semaines.Ce vaccin « induit essentiellement une immunité sérique mais peu, voire aucune, immunité locale.
Il n'a de ce fait qu'un effet très limité sur la multiplication intestinale, sur l'excrétion du virus, et donc sur le nombre potentiel de porteurs du virus.
» Même si le VPI exige des injections de rappel et est d'un coût supérieur au vaccin vivant atténué, il est encore utilisé car le vaccin oral ne peut suffire sous certaines conditions.Malgré la faible immunité locale induite, le VPI s'est montré capable d'éliminer la poliomyélite dans les pays industrialisés qui l'ont utilisé exclusivement (Pays-Bas, Suède et Finlande).
Le VPI est à utiliser en cas de risque imminent d’exposition au poliovirus, comme première intention, et non pour lutter contre une apparition de la maladie (épidémie).Le vaccin injectable est contre-indiqué en cas d'allergie à l'un de ses constituants et déconseillé en cas d'infection intercurrente.
Les effets indésirables sont des réactions localisées au point d’injection à type de douleur, tuméfaction ou rougeur.
D'après la National Academy of Medicine, aucun événement indésirable grave n’a été associé au vaccin.Le vaccin antipoliomyélitique oral (VPO) a été mis au point en 1957 par Albert Sabin.
Il utilise un poliovirus vivant mais atténué par un passage répété dans des cellules non humaines à des températures infra-physiologiques.
Il a été testé dès 1957 et a été autorisé en 1962.
Administré par voie orale, il reproduit une infection digestive de faible effet et entraîne la synthèse active d'anticorps protecteurs par la barrière digestive.Les vaccins antipoliomyélitiques oraux monovalents (VPOm) sont spécifiques contre les poliovirus sauvages de type 1 (VPOm1), 2 (VPOm2) et 3 (VPOm3).Le vaccin antipoliomyélitique oral trivalent (VPOt), contre les 3 types de poliovirus sauvages, est d'efficacité comparable au vaccin atténué VPO (95 % de protection après trois doses).
Il peut être administré dès la naissance.
Peu coûteux, efficace et facile à administrer, le vaccin oral est le mieux adapté à la vaccination de masse et est le plus employé dans le monde, particulièrement dans les pays en voie de développement.
Des phénomènes d'interférence virale sont parfois responsables d'échecs.Le vaccin antipoliomyélitique oral bivalent (VPOb), contre les sérotypes 1 et 3, d'après des données de l'OMS en 2009, donne des résultats similaires au VPOm, mais est plus efficace que le VPOt sur ces 2 types de virus.Ils sont contre-indiqués, comme tout vaccin vivant, chez les sujets immunodéficients et chez les femmes enceintes.De rares cas de poliomyélite paralytique liée au vaccin peuvent survenir chez les individus vaccinés ou dans leur entourage proche.
Par ailleurs, des virus dérivés des souches vaccinales (PVDV) peuvent apparaître dans des zones de couverture vaccinale faible.
Ceux-ci peuvent être responsables d'épidémies (PVDVc - circulant) ou persister à long terme chez des individus ayant un déficit immunitaire touchant les lymphocytes B (PVDVi - associé à une immunodéficience).
Enfin, d'autres cas sont identifiés isolément et sans contexte de déficit immunitaire (PVDVa - ambigu),.Ainsi en 2013, le PVDVc était retrouvé chez 117 cas et 27 contacts dans 7 pays, le PVDVi touchait 10 nouvelles personnes dans 8 pays tandis que le PVDVa était retrouvé chez 11 personnes dans 13 pays.
Ces cas sont relativement rares ; entre 2005 et 2015, près de 500 cas de paralysie sur 2,5 milliards d'enfants vaccinés.
La détection de ces souches nécessite en principe une intensification de la campage de vaccination,,.La majorité des cas est liée au virus dérivé du type 2 du virus sauvage (PVDV2).
Aussi l'OMS prévoit de retirer cette valence du vaccin, ce d'autant que le dernier cas détecté de poliovirus sauvage de type 2 date de 1999.
Un préalable serait toutefois l'arrêt de la circulation de la souche dérivée.
Dans l'attente, pour diminuer le risque, une autre possibilité est de remplacer une des doses du vaccin par une dose de VPI,,.Dans les pays endémiques, le vaccin oral trivalent n'est plus utilisé depuis avril-mai 2016, il est remplacé par le vaccin oral bivalent 1 et 3, lequel est prévu pour être abandonné en 2019-2020, car l'OMS propose un passage universel au vaccin inactivé injectable (au moins une dose en intramusculaire ou en intradermique).
Au 31 août 2016, 173 (89 %) des 194 pays membres de l'OMS utilisent le vaccin polio injectable.En 2020, l'OMS recommande toujours que tous les enfants du monde soient vaccinés bien que le virus polio sauvage ne circule plus qu'en Afghanistan et au Pakistan.
Et justifie cette position par le fait que le virus polio dérivé de souche vaccinale circule encore dans 16 pays de la région africaine et que « tant que toutes les souches ne seront pas éradiquées dans le monde, les progrès incroyables faits contre la poliomyélite seront menacés ».
Les lymphocytes B à mémoires dérivent des lymphocytes B. Après reconnaissance des antigènes par les lymphocytes B (lors de la réponse immunitaire primaire), certains se différencient en lymphocytes B mémoires et d'autre en plasmocytes.Les lymphocytes B à mémoires ont pour rôle de mémoriser les propriétés de l'antigène les ayant activés, afin de créer une réponse immunitaire plus rapide, plus longue, plus intense et plus spécifique dans le cas d'une seconde infection par ce même antigène (réponse immunitaire secondaire).
De plus, les lymphocytes B à mémoires ont une durée de vie beaucoup plus longue que les plasmocytes.C'est sur le principe de cette mémoire immunitaire que les vaccins sont réalisés.
Mais le rôle de ces cellules n'est toutefois pas clair, car leur nombre ne semble pas varier au cours du temps, contrairement au taux d'anticorps spécifiques.Cette caractéristique de la réponse immunitaire spécifique a été reconnue il y a 2 400 ans par l'historien grec Thucydide d'Athènes qui remarqua que « nul ne souffrait de la peste à deux reprises ».Dans la moelle osseuse, les précurseurs des lymphocytes se différencient en lymphocytes B immuno-compétents qui expriment des IgD et IgM.
Ils peuvent alors reconnaître leur antigène spécifique par leur immunoglobuline (Ig) de membrane, également appelé récepteur des cellules B, et participer à la réponse immunitaire dite à médiation humorale.
Si l'antigène est T-dépendant, alors les lymphocytes B activés coopèrent avec les lymphocytes T auxiliaires dans les organes lymphoïdes secondaires.
Il se forme alors un centre germinatif au sein duquel ils subissent la maturation d'affinité et la commutation de classe leur permettant de produire des immunoglobulines A, E ou G. Ils se différencient ensuite en plasmocytes à courte durée de vie, plasmocytes à longue durée de vie ou lymphocytes B mémoire.Les lymphocytes B mémoires ont déjà subi le processus de maturation d'affinité et la commutation de classe, ce qui se traduit par la présence de mutations somatiques sur les gènes codant les immunoglobulines.Parmi ces lymphocytes B mémoires, on trouve de nombreuses sous-populations caractérisées par le type d'Ig synthétisée (IgA, IgE, IgG ou IgM) et le niveau d'expression de molécules de surface (CD27 notamment, mais aussi FCRL4).
Cependant, le rôle spécifique de chaque sous-population dans la mémoire immunitaire est encore débattu.On estime que les lymphocytes B mémoires peuvent persister plus de 50 ans chez l’homme et ceci sans nouvelle exposition à leur antigène spécifique.
Cependant les mécanismes demeurent encore mal connus : ils reposeraient notamment sur une modification de l'expression génique provoquant une augmentation de l’expression de molécules anti-apoptotiques.Les lymphocytes B mémoires sont capables de proliférer et se différencier très rapidement en plasmocytes producteurs d’anticorps à la suite d'une deuxième exposition à leur antigène spécifique.
Cette capacité à réagir plus rapidement avec un très court temps de latence est liée à différents mécanismes :La mémoire du système immunitaire est utilisée à des fins médicales : la vaccination qui permet à l'organisme d'acquérir préventivement et durablement une mémoire immunitaire relative à un micro-organisme déterminé.
Ceci se fait grâce à l'injection d'un antigène sous une forme non pathogène mais provoquant une réaction immunitaire avec mise en place d'une réponse mémoire protectrice.
La plupart des vaccins induisent une réponse anticorps : il y alors une production de lymphocytes B mémoires qui en cas d'une deuxième infection par l'antigène se réactiveront rapidement et protègeront l'organisme de l'infection.
Procyon lotor • Raton laveur communLe raton laveur, ou plus exactement le raton laveur commun (Procyon lotor Linnaeus, 1758), est une espèce de mammifères omnivores de l'ordre des carnivores.
Originaire d’Amérique du Nord, cette espèce a été introduite pour la dernière fois en Europe dans les années 1930 (après la disparition un siècle plus tôt de la dernière population introduite).
Il doit son nom à l’observation répétée de son habitude de tremper tous ses aliments dans l’eau ; en fait, avant de les manger, il peut déterminer ainsi qu’ils sont bien comestibles.
L’animal, de la famille des procyonidae, est essentiellement nocturne et grimpe facilement aux arbres grâce à ses doigts agiles et à ses griffes acérées.
Il a le pelage poivre et sel avec de légères teintes de roux.
On le reconnaît facilement à son masque noir bordé de blanc autour des yeux et à sa queue alternant anneaux clairs et noirs.
Le raton laveur s’adapte à de nombreux milieux naturels.
Opportuniste et facile à apprivoiser, il s’aventure également dans les villes nord-américaines (Canada, États-Unis).
Son comportement varie selon le sexe et la région où il vit.
Il est toujours chassé pour sa fourrure.Le raton laveur adulte mesure 80 cm en moyenne, généralement entre 60 cm et 105 cm selon les individus, queue comprise.
Les mâles sont plus grands et plus lourds que les femelles.La masse du raton laveur est comprise entre 3,9 et 9 kg en moyenne.
Les individus les plus gros vivent dans les régions septentrionales (8,5 kg en moyenne au Canada) ; record jusqu’à 28 kg,,,.
Le poids fluctue selon la saison, atteignant un maximum à l’automne : sa masse peut alors augmenter de 50 % dans les régions situées au nord.La fourrure est généralement gris-brun, tirant plus ou moins vers le gris ou le brun.
Le visage blanc porte de larges taches noires autour des yeux en forme de masque et une bande noire sur le nez.
Quelques individus sont blancs, mais l’albinisme est très rare.
La mue débute au printemps et peut s’étaler sur trois mois.
Le pelage estival du raton laveur est court.La tête est large, le museau pointu, les yeux noirs et les oreilles courtes (4 à 6 cm).
L’animal possède de longues canines comme tous les carnivores.
Les pattes sont dotées de cinq doigts munis de griffes non rétractiles.Les pattes avant, très mobiles, sont dotées de nombreuses terminaisons nerveuses qui fonctionnent de manière optimale en milieu humide et c’est grâce à ce sens du toucher exceptionnel qu’il est capable de déterminer, même sans le voir, si l’objet qu’il tient est comestible ou non.
La queue du raton laveur est généralement longue de 20 à 28 cm et peut mesurer jusqu’à 40 cm.
Elle compte 5 à 7 anneaux bruns ou noirs, et son extrémité est toujours noire.Le raton laveur ne doit pas être confondu avec le chien viverrin (ou tanuki), un canidé dont la fourrure est plus brune, la queue plus courte et de couleur unie, la rayure faciale interrompue sur le museau.Quatre sous-espèces de raton laveur endémiques à l'Amérique centrale et aux Caraïbes ont souvent été considérées comme des espèces distinctes après leur découverte.
Ce sont le raton laveur des Bahamas et le raton laveur de la Guadeloupe qui sont très semblables l'un à l'autre, le raton laveur de Tres Marias, qui est plus grand que la moyenne et a un crâne anguleux, et le raton laveur de la Barbade aujourd'hui éteint.
Les études de leurs caractères morphologiques et génétiques en 1999, 2003 et 2005 ont conduit à répertorier tous ces ratons laveurs comme des sous-espèce du raton laveur commun dans la troisième édition de Mammal Species of the World (2005),,.Un cinquième raton laveur insulaire, le raton laveur de Cozumel (Procyon pygmaeus), qui ne pèse que 3 à 4 kg et a notamment de petites dents, est toujours considéré comme une espèce distincte.Les quatre plus petites sous-espèces de raton laveur, d'un poids moyen de 1,8 à 2,7 kg, se trouvent le long de la côte sud de la Floride et les îles adjacentes ; un exemple en est le Procyon lotor marinus.
La plupart des 15 autres sous-espèces ne diffèrent que légèrement les unes des autres par la couleur de leur robe, leur taille et quelques autres caractéristiques physiques.
Les deux sous-espèces les plus répandues sont le raton laveur de l'Est (Procyon lotor lotor) et le raton laveur de la haute vallée du Mississippi (Procyon lotor hirtus).
Les deux partagent un pelage relativement sombre avec de longs poils, mais le second est plus grand que le premier.
Le raton laveur de l'Est se rencontre dans tous les États américains et provinces canadiennes au nord de la Caroline du Sud et du Tennessee.
Le raton laveur de la haute vallée du Mississippi vit dans tous les États américains et provinces canadiennes au nord de la Louisiane, du Texas et du Nouveau-Mexique.Selon MSW :Originaire d'Amérique du Nord, l’espèce occupe le sud du Canada et la majeure partie des États-Unis, du Mexique et de l’Amérique centrale, dans la zone intertropicale.
Il est plus rare dans les Antilles, où il est une espèce protégée.
Il est absent de certains secteurs des montagnes Rocheuses à cause de l’altitude, des déserts et du Grand Nord canadien.
En Europe, il est naturalisé en Suisse, en France, en Allemagne, en Belgique, aux Pays-Bas, au Danemark, en Autriche, en République tchèque, en Slovaquie, en Espagne, en Biélorussie ainsi que dans les pays du Caucase.
Il n'a jamais vécu naturellement au Japon.Le raton laveur fréquente la forêt mixte, la forêt de feuillus et les régions agricoles.
On le retrouve en bordure des forêts, le long des cours d’eau et dans les marécages sous presque toutes les latitudes de l’Amérique du Nord.
Il peut aussi vivre dans les parcs urbains et les banlieues.Le territoire du raton laveur varie entre 1 et 50 km2 en fonction des densités humaines.
La femelle ne défend pas de territoire.
La densité moyenne est de 4 à 20 individus par km2 sur les terres cultivées et jusqu’à 100 par km2 en ville.
Le domaine vital d’un mâle compte entre 2 et 12 femelles en période de reproduction.Dans les années 1930, le raton laveur est introduit une nouvelle fois en URSS et en Allemagne pour sa fourrure, dans des fermes d’élevage.
Parfaitement acclimaté et en l’absence de ses prédateurs naturels américains, il a proliféré depuis.
Aujourd’hui, on compte environ 100 000 ratons laveurs en Europe.Aujourd’hui, il est considéré comme une menace pour la biodiversité et a été classé par le Conseil de l'Europe comme espèce invasive dont l’éradication est conseillée en raison de son impact sur la faune locale.
En Europe, le raton laveur est inscrit depuis 2016 dans la liste des espèces exotiques envahissantes préoccupantes pour l’Union européenne.
Cela signifie que cette espèce ne peut pas être importée, élevée, transportée, commercialisée ou libérée intentionnellement dans la nature, et ce nulle part dans l’Union européenne.
En France, il est classé nuisible depuis juin 2016.
Au Japon, il est responsable du déséquilibre de la biodiversité dans plusieurs biomes, notamment à cause de sa prédation envers les invertébrés aquatiques, comme Helice tridens.Omnivore, le raton laveur a un régime alimentaire varié mais préfère néanmoins les invertébrés, les insectes, les vers et les larves.
Étant protégé des piqûres par son épaisse fourrure, il s’attaque aussi aux nids d’insectes.Il mange de petits animaux aquatiques : palourdes d’eau douce, moules, écrevisses, poissons, grenouilles, tortues, amphibiens et huîtres.
Il s’alimente aussi de petits mammifères (rats musqués, mulots).
Il peut aussi s'attaquer aux poules.
En été et en automne, il privilégie le maïs, les fruits, les baies, les glands et les noix.
Dans les villes, il fouille dans les poubelles qu’il ouvre aisément avec ses doigts agiles.
Il lui arrive de manger des charognes.La croyance populaire selon laquelle le raton laveur lave sa nourriture avant de la consommer vient du fait qu’il se nourrit généralement de petits animaux aquatiques et frotte souvent sa nourriture entre ses mains comme pour la pétrir.
Ainsi, des amas de coquilles de palourdes sur la rive d’un cours d’eau ou de tiges rompues dans les champs de maïs sont des signes de sa présence.Le raton laveur s’abrite dans les arbres creux, les souches, les cavernes, les terriers de marmottes abandonnés, les granges ou les hangars.
Vers mi-octobre, l’animal se réfugie dans son gîte et y passe l’hiver en état de torpeur, ne se réveillant que de temps à autre.
Comme l’ours noir et le blaireau, il cesse de manger et survit grâce à ses réserves de graisse accumulées pendant l’été.
Contrairement à ce qu’on a longtemps cru, la température de son corps et son métabolisme demeurent élevés.
Les mâles sortent de leur gîte fin janvier, les femelles vers mi-mars.En ville, on peut trouver l’animal dans les greniers, les égouts et les cheminées auxquels il accède grâce à ses griffes qui lui permettent de grimper facilement à plusieurs mètres du sol.
Chaque gîte abrite entre un et cinq individus (jusqu’à 23 dans le Minnesota,).
Il fréquente plusieurs abris en dehors de l’hiver.Les accouplements ont lieu en janvier ou en février dans les régions du nord, en mars dans les autres régions.
Les femelles n’ont qu’une seule portée par année et peuvent avoir des petits dès leur première année,.
Le mâle est polygame et peut se reproduire dès sa deuxième année.
La femelle monogame est réceptive pendant trois à six jours et la gestation dure 63 jours,,.Une portée comprend entre un et trois ratonneaux au sud contre trois à sept au nord et parfois jusqu’à neuf.
Les petits naissent en avril ou en mai.
Ils sont aveugles, pèsent entre 60 et 75 g, et ont le dos et les flancs poilus.
Les premières dents apparaissent au bout d’une vingtaine de jours.
Leurs yeux s’ouvrent à trois semaines,,.
Les ratonnes s’occupent seules de l’élevage des petits qui sont sevrés à quatre mois.
Le masque noir de la fourrure autour des yeux ainsi que les anneaux de la queue apparaissent avant dix semaines.
Leur cri est semblable au pépiement d’oiseau et ils se nourrissent du lait maternel.
Les ratonneaux peuvent à leur tour se reproduire à l’âge d’un ou deux ans selon le sexe.
Ils passent leur premier hiver avec leur mère et ne se dispersent qu’au début de l’été suivant.Les jeunes se laissent facilement apprivoiser par les hommes.
À l’âge adulte, les mâles deviennent agressifs et reviennent facilement à la vie sauvage après un temps de captivité.Le raton laveur est un bon grimpeur et un bon nageur.
Sur terre, il se déplace assez lentement, ce qui le rend vulnérable.
Il peut descendre d’un tronc la tête la première, en tournant ses pieds de derrière à 180°.
Animal curieux et intelligent, il sort de sa tanière surtout la nuit, sauf pendant la période de reproduction et en ville.
Le raton laveur émet des grognements lorsqu’il est en danger.En été et en automne, il emmagasine des réserves de graisse pour la saison froide et peut gagner jusqu’à deux fois son poids d’origine.
L’épaisseur de la couche de graisse peut atteindre 2,5 cm sur le dos.
En hiver, le raton laveur n’hiberne pas mais entre dans une période d’inactivité et de dormance, sauf dans les régions du Sud où l’animal continue d’être actif.Le raton laveur vit généralement entre 3 et 5 ans en milieu naturel et parfois jusqu’à 14 ou 16 ans.
En captivité, il peut dépasser les 16 ans,, voire 21 ans,.
Les jeunes meurent généralement de malnutrition, de maladie ou tués par un prédateur.Le principal prédateur du raton laveur est l’homme.
À l’époque précolombienne, il était chassé par les Amérindiens qui appréciaient sa chair et sa fourrure.
Aux temps modernes et au XIXe siècle, les trappeurs et les coureurs des bois le capturaient et pratiquaient la traite des fourrures.
L’apogée de ce commerce fut atteint dans les années 1920 ; entre 1941 et 1989 plus de 1,7 million de ratons furent tués pour leurs fourrures rien que dans l’État du Nebraska.
Aujourd’hui, la fourrure du raton ayant peu de valeur et étant difficile à travailler, cette activité est tombée en désuétude.Bien que principalement chassés pour leur fourrure, les ratons laveurs ont également été longtemps une source de nourriture importante pour les Amérindiens et les Américains et le raton laveur au barbecue était un plat traditionnel dans les fermes américaines.
C'était souvent un repas de fête.
Les esclaves américains mangeaient du raton laveur à Noël, mais ce n'était pas forcément un plat de pauvres ou de paysans; Dans le quotidien The Golden Era de San Francisco du 21 décembre 1856, le raton laveur figure parmi les spécialités conseillées pour les fêtes et le raton laveur Rebecca reçu par le président américain Calvin Coolidge lui avait été envoyé initialement pour être servi au dîner de Thanksgiving de la Maison-Blanche,.
La première édition de The Joy of Cooking, publiée en 1931, contenait une recette pour la préparation du raton laveur avec de l’écureuil et de l’opossum.
Elle suggérait d’enlever les glandes de musc et la graisse avant de faire rôtir l’animal et de l’accompagner avec des patates douces.Parce que les ratons laveurs sont généralement considérés comme attachants, mignons ou porteurs de vermine, beaucoup de consommateurs ordinaires ont une peur répulsive d'en manger,.
Cependant, plusieurs milliers de ratons laveurs sont encore consommés chaque année aux États-Unis,.
Bien que le Coon Feed à Delafield dans le Wisconsin soit un événement annuel depuis 1928, sa principale utilisation culinaire se rencontre dans certaines régions du sud des États-Unis comme l'Arkansas où le Gillett Coon Supper est un événement politique important,.Chaque année, 2 à 4 millions d’individus sont tués par les automobilistes ou les chasseurs.
Le raton laveur est perçu comme une menace pour les agriculteurs lorsqu’il s’attaque aux vergers, aux œufs, aux champs de maïs, aux greniers, aux cabanes à sucre ou aux ruches.
En Suisse, il est chassé et jugé indésirable pour l’équilibre naturel.Autrefois recherché par l’homme pour sa fourrure, le raton laveur est toujours la proie de la martre d'Amérique, du lynx roux, du puma, du coyote, du loup gris, du renard roux mais aussi du chien domestique.
Le grand-duc d'Amérique capture parfois des petits.
Il est attaqué par les alligators dans le Sud des États-Unis.Le raton laveur peut être porteur de la rage, de la maladie de Carré ou de la gale mais aussi de parasites (infection à parvovirus, leptospirose et Baylisascaris procyonis).
Selon l'Agence canadienne d'inspection des aliments, la rage est transmissible à l’homme par la salive.En anglais, « raton laveur » se traduit par le mot raccoon, lui-même issu de l’algonquin ärähkun, déverbal de ärähkuněm « il gratte avec les mains,, ».
Les trappeurs de la Nouvelle-France auraient ensuite formé le mot « raton », par analogie avec raccoon.
Au Québec, chez les plus vieilles générations, il est connu sous le nom de « chat sauvage ».
Les Acadiens le nomment quant à eux la « mascouèche, marchouèche ou machecouèche », les Cadiens le « chaoui », tous les deux empruntés aux langues amérindiennes.Dans les premières décennies après sa découverte par les membres de l'expédition de Christophe Colomb, qui a été la première personne à laisser une trace écrite sur l'espèce, les taxonomistes ont pensé que le raton laveur était apparenté à de nombreuses espèces différentes, comme les chiens, les chats, les blaireaux et plus particulièrement les ours.
Carl von Linné, le père de la taxonomie moderne, a placé le raton laveur dans le genre Ursus, d'abord comme Ursus cauda elongata (« ours à longue queue ») dans la deuxième édition de son Systema Naturae, puis comme Ursus lotor (« ours laveur ») dans la dixième édition.
En 1780, Gottlieb Konrad Christian Storr a placé le raton laveur dans son propre genre -Procyon- qui peut se traduire soit par « avant le chien » ou « qui ressemble au chien ».
Il est également possible que Storr ait eu son mode de vie nocturne à l'esprit et ait choisi l'étoile Procyon comme éponyme pour le genre.
L'épithète spécifique du raton laveur est lotor, lotor signifiant « laveur » en latin.Sur la base de preuves fossiles en France et en Allemagne, les premiers membres connus de la famille des Procyonidae vivaient en Europe à la fin de l'Oligocène, il y a environ 25 millions d'années.
Les dents et les structures du crâne semblables suggèrent que les Procyonidés et les Mustelidés partagent un ancêtre commun, mais les analyses génétiques indiquent une relation plus étroite entre les ratons laveurs et les ours.
Après avoir traversé le détroit de Béring au moins six millions d'années plus tard, l'espèce de l'époque a eu son centre de répartition se situant probablement en Amérique centrale.
Les coatis (genres Nasua et Nasuella) et les ratons laveurs (genre Procyon) ont été considérés comme pouvant éventuellement partager une origine commune, une espèce du genre Paranasua présente il y a entre 5,2 et 6,0 millions d'années.
Cette hypothèse, basée sur des comparaisons morphologiques, est en conflit avec une analyse génétique de 2006 qui indique que les ratons laveurs sont plus étroitement apparentés aux Bassariscus.
Contrairement à d'autres procyonidés, comme le Raton crabier (Procyon cancrivorus), les ancêtres du raton laveur commun ont quitté les zones tropicales et subtropicales et migré vers le nord il y a environ 4 millions d'années, une migration qui a été confirmée par la découverte de fossiles dans les Grandes Plaines datant du milieu du Pliocène.Plusieurs légendes décrivent les origines de la race de chats Maine coon.
La plus répandue raconte que le maine coon est le fruit d'un croisement entre des chats et des ratons laveurs (familièrement coon en anglais, abrégé de racoon), ce qui expliquerait leur couleur (la plus répandue est le brown tabby, c'est-à-dire tigré brun) et leur queue très touffue.
Bien sûr, il est génétiquement impossible de réaliser un tel hybride, mais la race garde de cette légende son nom.
En biologie, et notamment en parasitologie, un hôte est un  organisme qui héberge un parasite, un partenaire mutuel ou un partenaire commensal, nécessaire à son cycle de vie.Dans le cas du parasitisme, l'organisme hébergé peut provoquer des effets néfastes pour l'hôte.
L'hôte doit s'adapter pour ne pas rencontrer le parasite (par exemple en modifiant son comportement).
Si la rencontre a eu lieu, l'hôte doit s'adapter pour se débarrasser du parasite (immunité).
Les lymphocytes B, ou cellules B, sont des globules blancs particuliers faisant partie des lymphocytes.
Ce sont des cellules synthétisées dans la moelle osseuse, et qui circulent dans le sang et la lymphe pour participer aux défenses naturelles de l'organisme.Ils sont responsables de l'immunité humorale et fabriquent les immunoglobulines appelées anticorps.Chaque cellule B a plus de 100'000 anticorps membranaires (ou récepteurs antigéniques) identiques et spécifiques a un seul antigène.
Pour qu'un lymphocyte B soit actif, un de ces récepteurs doit entrer en contact direct avec l'antigène en question (soit soluble dans la lymphe ou le sang, soit apportée par une cellule présentatrice d'antigène) via l'épitope de ce dernier.
La cellule B ainsi activée se multiplie et donne naissance à deux types cellulaires : les plasmocytes et les lymphocyte B mémoire.
Les plasmocytes ont un réticulum endoplasmique et un appareil de Golgi extrêmement développés afin de produire et de sécréter une quantité massive d'anticorps qui, une fois sécrétés, vont pouvoir se lier à l'antigène qui a provoqué l'activation de la cellule B, et ainsi neutraliser l'agent pathogène possédant cet antigène en l'empêchant d'infecter d'autres cellules ou de se propager.
Le pathogène et les anticorps seront ensuite éliminés par les phagocytes du système immunitaire.
Les cellules mémoire, quant à elles, ont une longue durée de vie et vont être conservées dans le corps (sang, lymphe et organes lymphoïdes), prêtes à proliférer et se différencier en plasmocyte rapidement en cas d'une nouvelle infection du même pathogène.Les lymphocytes B sont des lymphocytes participant à la réponse immunitaire adaptative (propre aux vertébrés), c'est-à-dire qu'un lymphocyte B donné ne peut réagir que contre un antigène précis.
Cette spécificité est donnée par le récepteur des cellules B, complexe membranaire similaire au TCR des lymphocytes T.
Le récepteur des cellules B est également issu d'une recombinaison V(D)J.Les cellules B sont des lymphocytes qui jouent un grand rôle dans l'immunité humorale (par opposition à l'immunité cellulaire).« B » est l’abréviation de « bourse de Fabricius »,, un organe des oiseaux dans lequel les cellules B sont produites et arrivent à maturité, et non celle de la moelle osseuse (en anglais : bone marrow) dans laquelle les cellules B sont produites chez tous les autres vertébrés, notamment chez l'humain.Le corps humain produit des centaines de milliers de types différents de cellules B, et chaque type a sur sa membrane un récepteur des cellules B particulier, qui se liera à un antigène particulier ; à chaque instant des millions de cellules B circulent dans le sang et la lymphe, sans produire d'anticorps.Il y a plusieurs types de cellules B :L'immunité humorale (la création d'anticorps circulant dans le plasma et la lymphe) implique l'activation des cellules B. L'activation cellulaire peut être mesurée au moyen de la technique ELISPOT ou de cytométrie en flux (FACS) qui peut déterminer le pourcentage de cellules B sécrétant n'importe quel anticorps particulier.Les cellules B se caractérisent sur le plan immunohistochimique par la présence de CD79b, (chaine d'immunoglobine transmembranaire qui est un composant du récepteur des cellules B sur leur membrane plasmique).Susumu Tonegawa a obtenu le Prix Nobel de physiologie ou médecine en 1987 pour avoir démontré de quelle manière les cellules B créent une énorme diversité d'anticorps au départ d'un petit nombre de gènes.Les anticorps sont composés de chaînes de protéines lourdes et légères, chaque type contenant une partie constante (C) et une partie variable (V).
Les gènes codant ces chaînes légères ou lourdes se situent à différents endroits du génome.
NB : il y a donc deux allèles de chaque gène, puisque le génome humain est diploïde.Les régions V sont codées par des gènes qui comportent trois types de segments.
Par exemple, le locus de la chaîne lourde contient environ 50 gènes Variables (V), 30 gènes de Diversité (D) 6 gènes de Jonction (J) et 9 gènes C (Constant), ce qui donne V x D x J = 50 x 30 x 6 = 9000 possibilités.
Les gènes codant les chaînes légères possèdent également de nombreux segments V et J, mais aucun gène D.
La recombinaison entre les fragments VDJ permet de générer environ 2 x >106 combinaisons possibles : 9000 x 320 (120 possibilités pour la chaîne légère lambda (λ) + 200 pour la chaîne légère kappa (κ)).Dans les lymphocytes B en développement, la première recombinaison à avoir lieu se fait entre un segment D et un segment J d’un locus de chaîne lourde.
Toute la chaîne d’ADN située entre ces deux segments est éliminée.
Cette recombinaison D-J est suivie par la jonction d’un segment V venant d’un locus en amont du gène DJ nouvellement formé.
Cette fois encore, tout le locus situé auparavant entre le segment V et le DJ est éliminé du génome.
Lors de la transcription du gène, l’ARN messager contient la région VDJ recombinee de la chaine lourde, ainsi que les segments constants mu et delta (Cμ et Cδ).
Ce premier transcrit subit des modifications post-transcriptionelles classiques (polyadénylation, epissage des introns) et un épissage alternatif conduisant des gènes codant les segments constants.
La traduction de cet ARNm produit la chaîne lourde Ig μ.Les locus des gènes codant les chaînes légères kappa (κ) et lambda (λ) réarrangent d’une façon très similaire, à ceci près que les chaînes légères sont dépourvues de segment D.
En d’autres termes, la première étape de la recombinaison des chaînes légères concerne les segments V et J pour former un complexe VJ, avant l’addition du segment constant de la chaîne légère lors de la transcription.
La traduction de l’ARNm épissé des chaînes kappa ou lambda produit des chaînes légères Ig κ ou Ig λ.L’assemblage de deux chaînes lourdes Ig μ et de deux chaînes légères conduit à la formation de la forme membranaire de l’immunoglobuline IgM exprimée à la surface des lymphocytes B, le récepteur des cellules B. L’assemblage d’une chaîne légère avec une chaîne lourde forme un paratope unique.
Le vaccin contre l'hépatite B (en anglais, Hepatitis B vaccine ou HBV) prévient la contamination par le virus de l'hépatite B depuis 1982.
Le vaccin ne guérit pas les porteurs chroniques, mais il est efficace de 90 à 95 % pour prévenir l'apparition de cet état.
Le vaccin anti-VHB est aussi le premier vaccin susceptible de protéger contre un cancer et le premier vaccin contre une infection sexuellement transmissible.Grâce aux actions de l’OMS, depuis quelques années, beaucoup de pays ont ajouté le vaccin contre l’hépatite B à leur programme national de vaccination.
Cependant, dans les pays pauvres, là où les zones endémiques sont les plus importantes, le coût de cette vaccination pose un problème.
L’OMS a alors lancé en 1999 la création de l’Alliance mondiale pour les vaccins et la vaccination (GAVI), dont un des buts est de vacciner le plus d'enfants possible afin de les prémunir contre certaines maladies pour lesquelles il existe un vaccin, comme l’hépatite B.L'infection par le virus de l'hépatite B peut évoluer vers un carcinome hépatocellulaire, un type de cancer du foie.
Par conséquent, les vaccins contre l'hépatite B sont des vaccins efficaces pour la prévention d'un cancer.
Selon les Centers for Disease Control and Prevention (CDC), le vaccin contre l'hépatite B est le premier vaccin anti-cancer,,.Le vaccin contre l’hépatite B est constitué d’antigène HBs (antigène de surface de l’hépatite B ou AgHBs).
Le plus ancien est préparé à partir d’antigènes HBs purifiés à partir de plasma de porteurs sains, il a été entièrement remplacé dans le monde par un vaccin préparé par génie génétique.
C’est une protéine recombinante obtenue par insertion du gène du VHB codant la protéine d’enveloppe virale (antigène HBs) dans des cellules de levures ou des cellules ovariennes de hamster.
Après la vaccination l’antigène de surface de l’hépatite B peut être détecté dans le sérum pendant plusieurs jours, ce phénomène est connu sous le nom d'« antigènémie vaccinale ».Après un protocole de trois injections vaccinales, le système immunitaire produit des anticorps contre l’antigène HBs qui sont libérés dans la circulation sanguine.
L'anticorps est connu sous le nom d’anticorps « anti-AgHBs ».
Cet anticorps et la mémoire du système immunitaire confèrent alors une immunité contre l’infection par le virus de l'hépatite B. Même si le taux d’anticorps baisse ultérieurement au-dessous du niveau de 10 mUI mL−1, le patient reste protégé : la période d'incubation variant de 45 à 180 jours (durée moyenne de 60 à 90 jours), en cas de contamination le système immunitaire dispose de suffisamment de temps pour produire des anticorps anti-Hbs à un niveau suffisant pour qu’il soit protecteur, avant que la maladie se développe.
Dans cette hypothèse on observera une trace sérologique d’infection révélée par la présence d’anticorps anti-Hbc.Un taux d’anticorps anti-HBs protecteurs (10 mUI mL−1) est obtenu 2 à 3 mois après le début de la vaccination.Le vaccin a été préparé à l’origine à partir de plasma sanguin provenant de patients porteurs de longue date d’une infection par le virus de l'hépatite B. À la suite des travaux de Baruch Blumberg qui a découvert en 1963 l’antigène Hbs (initialement appelé « antigène Australia » parce qu’il avait mis en évidence une réaction inhabituelle entre le sérum de malades polytransfusés et celui d’un aborigène australien),.Blumberg reçut d’ailleurs en 1976 le prix Nobel de médecine pour la découverte de cet antigène et pour la conception de la première génération de vaccins contre l’hépatite.Le premier vaccin utilisé chez l’Homme a été mis au point en France en 1976 par le professeur Philippe Maupas virologue à la faculté de médecine et de pharmacie de Tours.
D'abord testé chez le personnel du service d’hémodialyse, très exposé à la maladie,,, un essai clinique a ensuite été mené (1978-1981), avec l'aide du Professeur Iba Mar Diop, à Niakhar au Sénégal.Les vaccins fabriqués par la technologie de l'ADN recombinant sont disponibles depuis 1986.
Les deux types de vaccins sont considérés comme étant d’une efficacité comparable.
Aux États-Unis, les deux nouveaux vaccins recombinants sont l’Engerix-B (fabriqué par GlaxoSmithKline), et le Recombivax HB (fabriqué par Merck).
Les vaccins recombinants sont composés de protéines produites par des cultures de levure modifiée.
Contrairement aux vaccins dérivés du plasma, ces vaccins recombinants ne sont pas produits par des lignées de cellules ou de tissus humains,.Il est recommandé d’administrer aux bébés nés de mères infectées par le virus de l'hépatite B un traitement pour réduire le risque de transmission mère-enfant de la maladie.
Dès que possible et au plus tard dans les 48 heures qui suivent la naissance, les nouveau-nés sont vaccinés avec l’antigène de surface de l'hépatite B (AgHBs) et reçoivent une injection d’immunoglobulines contre l'hépatite B (HBIG).En 2015, 185 pays (95 % des membres de l'OMS) vaccinent les nourrissons contre l'hépatite B. L'exemple de Taïwan, où la mise en œuvre en 1984 d’un programme national de vaccination contre l'hépatite B a été associée à une baisse de l'incidence de carcinome hépatocellulaire chez les enfants, a permis de supposer que dans les pays où existait des taux élevés d'infection par l'hépatite B, la vaccination des nouveau-nés était susceptible de réduire non seulement le risque d'infection, mais conduire également à une réduction marquée du cancer du foie.La transmission fréquente de l'hépatite B par voie parentérale ou sexuelle a fait recommander la vaccination aux usagers de drogue injectables, aux sujets ayant des partenaires sexuels multiples, aux consultants de MST et aux adolescents,.Dans de nombreuses régions, la vaccination contre l'hépatite B est également exigée pour tous les professionnels de santé et le personnel de laboratoire.
Cette prévention est essentielle car le risque pour ces professionnels est 5 à 8 fois plus élevé que celui de la population générale.En France, la vaccination est obligatoire pour le personnel de Santé depuis le 18 janvier 1991 et pour les nourrissons nés après le 1er janvier 2018.
Elle est recommandée chez les enfants et adolescents jusqu'à l'âge de 15 ans, ainsi que pour les personnes à risque.
Sauf pour les personnes vaccinées avant l’âge de 13 ans, un contrôle sérologique est préconisé 6 à 8 semaines après le rappel.
Un taux d’anticorps de 10 mUI mL−1 est considéré comme protecteur, auquel cas aucun rappel ultérieur n’est recommandé.
Pour les soignants exerçant une activité qui expose particulièrement leurs patients au risque de contamination par un professionnel, il est exigé un taux d'anticorps de 100 mUI mL−1.
À défaut, l'absence d'antigène Hbs doit être vérifiée chez le soignant.En pratique on ne cherche à quantifier la réponse vaccinale que pour les professionnels de santé particulièrement exposés au risque de contamination.
À la suite d’une primo-vaccination comportant trois injections, une analyse de sang doit être faite dans un délai de 1 à 4 mois pour établir s'il y a eu une réponse immunitaire adéquate, définie par un niveau d’anticorps contre l’antigène de surface du virus de l'hépatite B (Anticorps Anti-HBs) supérieur à 10 mUI mL−1.
Une telle réponse complète se produit chez environ 85-90 % des individus.Un taux d'anticorps situé entre 1 et 10 mUI mL−1 est considéré comme une mauvaise réponse, et les personnes concernées (mauvais répondeurs) devraient recevoir une injection de rappel à ce moment-là, mais n'ont pas besoin d’autres tests sérologiques ultérieurs.
En pratique en l’absence de réponse après 6 injections au total, il est inutile de pratiquer une injection supplémentaire.Les personnes qui ne répondent pas correctement (taux d’anticorps anti-HBs inférieur à 10 mUI mL−1) doivent être testées pour exclure une hépatite B en évolution ou une hépatite ancienne, et doivent subir un nouveau protocole de trois injections vaccinales, suivi d’un nouveau dosage d’anticorps 1 à 4 mois après la deuxième série.
Ceux qui sont encore non-répondeurs, devraient recevoir des immunoglobulines contre l'hépatite B (HBIG) si elles sont par la suite exposées au virus de l'hépatite B.Bien qu’on ait pensé initialement, que le vaccin contre l'hépatite B ne conférait pas une protection de durée illimitée, ce n'est plus le cas actuellement.Les premières études avaient suggéré que la vaccination pouvait fournir une couverture efficace pendant cinq à sept ans,, mais ensuite il a été prouvé qu’il existait une immunité à long terme découlant de la mémoire immunologique qui persistait après la baisse du taux d'anticorps et donc que le suivi du taux d’anticorps et l’administration de doses de rappel n'était pas nécessaire pour les individus immunocompétents vaccinés avec succès,.Avec le recul du temps et une expérience plus longue, il a été démontré que la protection persistait au moins pendant 25 ans chez les personnes qui avaient présenté une bonne réponse initiale au premier protocole vaccinal.
Les recommandations au Royaume-Uni suggèrent maintenant que pour les bons répondeurs initiaux qui ont besoin d’une protection à long terme, comme les professionnels de santé, un seul rappel est préconisé à 5 ans.
En France aucun rappel n’est préconisé pour les professionnels de santé présentant un taux d’anticorps supérieur à 10 mUI mL−1 après un protocole initial complet de trois injections.Selon l'OMS, les vaccins anti-hépatite B sont disponibles sous forme monovalente pour les vaccinations à la naissance et celles des adultes à risque.Pour la vaccination des nourrissons, la vaccination anti-hépatite B se fait en association avec d’autres vaccins : antidiphtérique-antitétanique-anticoquelucheux (DTC), le vaccin contre Haemophilus influenzae type b (Hib) et le vaccin antipoliomyélitique inactivé (VPI).
En outre, un vaccin combiné contre l’hépatite B et l’hépatite A est également disponible.Ces vaccins reposent sur des procédés de fabrication différents, avec des adjuvants différents, et ciblent des populations différentes.
La dose pédiatrique standard contient 5-10 μg d’AgHBs et la dose adulte standard est de 10-20 μg; une dose vaccinale de 40 μg est utilisée pour les personnes immunodéprimées et les patients sous dialyse.La dose vaccinale destinée aux nourrissons, aux enfants et aux adolescents est inférieure de 50 % à celle des adultes.
L’OMS a formulé des recommandations pour garantir la qualité, l’innocuité et l’efficacité des vaccins recombinants contre l’hépatite B.A la date du 17 février 2017 et pour faire suite aux tensions d'approvisionnement concernant Engerix B20, vaccin contre l'Hépatite B pour les adultes, le Haut Conseil pour la Santé Publique émet un avis détaillé sur de nouveaux schémas de vaccination des adultes et les personnes prioritaires.
Il comporte également un tableau récapitulatif des vaccins utilisables et plusieurs études et résultats d’immunogénicité.
Cette pénurie ne concerne pas les vaccins hexavalents.En France, le schéma initial (1981-1994) était le suivant :Le schéma recommandé depuis 1994 est le suivant :Un soupçon de corrélation a été soulevé, prétendant que l'hydroxyde d'aluminium, utilisé comme adjuvant des vaccins contre l'hépatite B, serait à l'origine de la myofasciite à macrophages ; l'ANSM considère cependant qu'il n'est pas démontré que la myofasciite à macrophages soit autre chose qu'un phénomène histologique local et ait des effets cliniques.
Des médecins cliniciens et des tribunaux reconnaissent une présomption d'imputabilité,,,,,,,.
L'Organisation mondiale de la santé (OMS) qui a en 1999 demandé d'entreprendre des recherches afin d’évaluer les aspects cliniques, épidémiologiques, immunologiques et biologiques de cette maladie rare, n'a pas pu établir de lien entre l'hydroxyde d'aluminium et le myofasciite à macrophages,.Les réactions, à la suite de la vaccination, les plus couramment observées sont des réactions cutanées mineures au point d’injection ou des douleurs musculaires et articulaires transitoires.
Les autres effets indésirables sont « rarement » et « très rarement rapportés », : Arthrites, Périartérite noueuse, péricardites aiguës, vascularites, Réaction anaphylactique grave, Affections du système nerveux central et périphérique.
Dans beaucoup de cas, la relation causale avec le vaccin n'a pas été établie.
À la date de 2017, de nombreuses études à long terme n’ont relevé aucune manifestation indésirable grave imputable à la vaccination contre l’hépatite B. L'Organisation mondiale de la santé (OMS)  précise que "les données n’indiquent pas de lien de causalité entre le vaccin anti-hépatite B et les affections neurologiques (y compris le syndrome de Guillain-Barré et la sclérose en plaques), le diabète sucré, les troubles démyélinisants, le syndrome de fatigue chronique, l’arthrite, les maladies auto-immunes, l’asthme, la chute de cheveux ou le syndrome de mort subite du nourrisson.
".Ces populations non ou faibles répondeurs sont :Les non-répondeurs devraient recevoir des immunoglobulines contre l'hépatite B (HBIG) au cas où elles seraient ultérieurement exposées au virus de l'hépatite B (cas des soignants victimes d’un accident d'exposition au sang par exemple).Un vaccin à base d’antigènes de surface PréS2 et S produit par la levure induit des titres en anticorps protecteurs après 2 injections chez 80 à 91 % des sujets qui n’avaient pas été protégés auparavant avec un vaccin « conventionnel ».Un autre vaccin renfermant les antigènes PréS1, PréS2 et S (vaccin Hepa-Gene-3) a été testé sur des sujets souffrant d’insuffisance rénale et non-répondeurs au vaccin classique.
Au bout d’un an, 70 % d’entre eux avaient des titres d’anticorps protecteurs.
D’autres approches existent et sont en cours de recherche comme les vaccins à base d’ADN plasmidique.Des résultats prometteurs ont été publiés en 2006 en faveur d'un vaccin ADN,.Ce type de vaccin est basé sur une injection directe d’ADN nu (sans vecteur protéique ou lipidique associé) par voie intramusculaire ou intradermique.
L’ADN est capturé par des cellules et le génome viral est exprimé par celles-ci.
La protéine correspondante est donc synthétisée par les cellules.
Un des avantages majeurs d’un tel vaccin est l’expression à long terme de l’antigène, ce qui pourrait permettre d’obtenir une réponse immunitaire plus soutenue et plus durable et donc permettre de supprimer les injections de rappel.
Un autre avantage est la synthèse in vivo de l’antigène et sa présentation sous forme de peptides antigéniques associés aux molécules CMH de classe I, permettant d’induire une réponse cytotoxique médiée par les lymphocytes T CD8+.L’injection d’ADN chez l’homme suscite des interrogations concernant le devenir de cet ADN injecté et la possibilité de son intégration dans un chromosome des cellules hôtes.
Si cela était le cas, une mutagénèse insertionnelle serait possible.
Le choix de l’injection d’un tel vaccin au niveau de cellules musculaires n’est pas arbitraire.
En effet, les cellules musculaires sont post-mitotiques et donc, l’absence de divisions favorise peu les intégrations.Ce vaccin fait partie de la liste des médicaments essentiels de l'Organisation mondiale de la santé (liste mise à jour en avril 2013).
Le vaccin contre la poliomyélite a pour but de prévenir une maladie causée par un virus appartenant à un sérotype de poliovirus.
L'efficacité de ce vaccin destiné à prévenir la poliomyélite est élevée et ses effets secondaires sont le plus souvent sans gravité.
Il fait partie des vaccins recommandés tout au long de la vie.La poliomyélite est due à un virus parmi les 3 sérotypes de poliovirus.
Il s'agit d'une maladie touchant le tractus gastro-intestinal et pouvant atteindre les tissus nerveux.
La gravité est liée à la survenue d'une forme paralytique, de l’ordre de 1 pour 1 000 infections chez le petit enfant et de 1 pour 75 infections chez l’adulte.Un vaccin est développé par Jonas Salk en 1955.
Parallèlement, en collaboration, Mikhaïl Tchoumakov en URSS de  1958-1959 a organisé la première production massive et les tests cliniques du vaccin contre la poliomyélite (VVACP) créé à partir de virus vivants atténuées développés par Albert Sabin.
Cela fait de l’Union soviétique le premier pays à produire, breveter et largement utiliser ce vaccin très efficace qui a pratiquement éliminé la poliomyélite du pays après seulement quelques années d'utilisation.
Un  vaccin  est  dévéloppé  quasiment simultanément à  l'Institut Pasteur par le Professeur Pierre Lepine,,.
Albert Bruce Sabin Invente le vaccin antipoliomyélitique oral dans les années 1960, quelques années après la mise au point du vaccin inactivé.
Sabin a refusé de breveter son vaccin, renonçant à toute exploitation commerciale par les industries pharmaceutiques, afin que le bas prix garantisse une diffusion plus large du traitement et puisse être accessible à toutes les populations mondiales mêmes les plus pauvres.
Depuis 2019, grâce au soutien de la Fondation Bill-et-Melinda-Gates, un vaccin très bon marché est produit par Univercells pour les pays en voie de développement (Pakistan, Afghanistan, Nigéria).
De fausses rumeurs dissuadent souvent les populations concernées de se faire vacciner.Le vaccin contre la poliomyélite existe sous forme inactivée ou atténuée.
Le vaccin inactivé se compose d'antigènes viraux des 3 sérotypes.
En France, seul le vaccin inactivé est disponible.Le vaccin inactivé existe également sous forme combinée :Le vaccin inactivé est administré par voie intramusculaire, tandis que le vaccin atténué est disponible sous forme orale.En France, la primo-vaccination recommandée des nourrissons se compose de 2 injections à 2 mois d'intervalle, aux âges de 2 et 4 mois, suivies d'un rappel à l'âge de 11 mois.
Les rappels ultérieurs recommandés sont aux âges de 6 ans puis entre 11 et 13 ans chez l'enfant.
Par la suite chez l'adulte, les vaccinations sont recommandées aux âges de 25 ans, 45 ans et 65 ans, puis tous les 10 ans.La primo-vaccination du nourrisson et le premier rappel sont obligatoires.
Les rappels aux ages de 6 et 13 ans sont recommandés.Avec le vaccin inactivé, les anticorps apparaissent après la deuxième injection et persistent 5 ans après le premier rappel.
L'efficacité clinique est de 85 %.Le vaccin inactivé est bien toléré, avec comme effets indésirables principaux des réactions au site d'injection, telles que douleur, érythème, induration et œdème.
Avec le vaccin atténué, une paralysie peut exceptionnellement survenir, y compris dans l'entourage du sujet vacciné.Les deux types de vaccins sont contre-indiqués en cas d'hypersensibilité à un de leurs composants, et la vaccination est à différer en cas de maladie fébrile ou d'infection aiguë.
En outre, le vaccin atténué est également contre-indiqué en cas de déficit immunitaire (tel que le Sida ou la prise d'un traitement immunosuppresseur) chez le sujet à vacciner ou dans son entourage, ou en cas de maladie maligne évolutive.
Goëmar ou (Laboratoire Goëmar) est une entreprise bretonne créée en 1971 et basée à Saint-Malo, spécialisée dans les technologies pour l’agriculture, qui propose des produits phytosanitaires pour le traitement des plantes sur la base d'algues.Fondée en 1971 par René Hervé, inventeur des brevets de base et ultérieurs, Goëmar développe depuis 1975 son activité de recherche autour d’extraits d'algues brunes (goémon) pour élaborer et commercialiser des produits destinés au traitement des plantes.
L'entreprise a son siège dans le parc Atalante à Saint-Malo.En 2001, l'entreprise annonce la mise au point d'un premier vaccin pour les plantes, extrait d'algues et dont le principe actif est la laminarine (éliciteur oligosaccharidique des défenses chez le tabac).
En 2002, elle reçoit l'homologation sur blé de ce produit phytosanitaire revendiquant un mode d’action de type stimulateur des défenses naturelles des plantes, commercialisé en 2003 sous le nom Iodus 40.
Cette découverte est le fruit d'une collaboration de quinze ans avec le CNRS et la station biologique de Roscoff.En 1998 et 2005, l’INPI et le ministre français de l’industrie ont récompensé la recherche Goëmar avec le trophée régional et national de l’innovation.
Entre 1993 et 2003, 17 brevets sont déposés par Goëmar.En 2006 est créé le « laboratoire de la mer », une filiale consacrée à la santé humaine.
Le 30 septembre 2008, Goëmar cède cette filiale à CH-Pharma afin de recentrer son activité sur les végétaux .Depuis juin 2010, un nouvel actionnaire majoritaire accompagne Goëmar : la société d’investissements BeCapital.
En 2010 également Goëmar rejoint le projet Défi-Stim et construit une nouvelle usine.En mai 2014, Goëmar passe sous le contrôle du groupe japonais Arysta Lifescience Limited, l'un des leaders mondiaux de l'agrochimie et des produits phytopharmaceutiques,.
La politique vaccinale contre la Covid-19 a pour but de définir la meilleure utilisation possible des vaccins contre la Covid-19 afin de protéger l'ensemble de la population contre les risques de la maladie à coronavirus 2019.
Elle inclut tous les objectifs de santé publique à atteindre dans le contexte particulier d'une pandémie d'évolution incertaine due à la circulation d'un virus émergeant, le SARS-CoV-2, pour lequel les connaissances sur la transmission et le pouvoir pathogène évoluent très rapidement.Les groupes prioritaires ciblés sont les soignants en première ligne pour qui le risque d'infection est élevé, les personnes âgées et les personnes chez qui le risque de décès est élevé en raison d'affections chroniques, telles les cardiopathies ou le diabète.
Au 18 avril 2021, 905 millions de doses de vaccin anti-Covid ont été administrées dans le monde.
L'OMS et la CEPI planifient le déploiement mondial de plusieurs vaccins anti-Covid-19 dans les pays en développement à forte densité de population.Le développement de vaccins anti-Covid-19 est le fait d'entités nord-américaines (40 %), asiatiques (30 %), européennes (26 %).
Une compétition d'influence existe entre le monde anglo-saxon, la Russie, la Chine et l'Inde pour approvisionner le monde en vaccins dans un schéma pré-contractuel.La politique vaccinale est tributaire de l'économie des vaccins mise en œuvre par les entreprises pharmaceutiques.
Le prix final des vaccins inclut les coûts de recherche et développement, les essais cliniques, la production du produit (mise en flacons, emballage, contrôle qualité), la distribution, la propriété intellectuelle (Brevet), les marges bénéficiaires tout au long de la chaîne logistique.Enfin, dans le monde, une partie de la population hésite à se faire vacciner.
Déjà en 2019, un Français sur trois ne croit pas que les vaccins soient sûrs.
Avec l'apparition de la Covid-19, cette défiance est exacerbée par des controverses et une opposition aux vaccins menées, entre autres, par des complotistes de la mouvance QAnon.
Des mesures comme la vaccination obligatoire ou la mise en place d'un passe (ou passeport) sanitaire pour les activités et les voyages internationaux ont été mis en place dans de nombreux pays.Afin de coordonner la réponse mondiale à la pandémie de Covid-19, en avril 2020, l'Initiative ACT-A est mise en place par le G20 et l'OMS.
Elle réunit des gouvernements, des scientifiques, des entreprises, la société civile, des organismes philanthropiques et des organisations mondiales telles que la Fondation Bill-et-Melinda-Gates, la Coalition pour les innovations en matière de préparation aux épidémies (CEPI), la Fondation pour de nouveaux outils diagnostiques novateurs (FIND), Gavi L'Alliance du Vaccin, le Fonds mondial, Unitaid, Wellcome, et la Banque mondiale.L'Initiative ACT-A est organisée en quatre piliers : (1) les vaccins (également appelés « COVAX »), (2) les diagnostics, (3) la thérapeutique et (4) une coordination des systèmes de santé.
Le dispositif COVAX (COVID-19 Vaccines Global Access) est co-dirigé par l'OMS, la CEPI et l'alliance Gavi.
Son objectif est d'accélérer la mise au point de vaccins contre la Covid-19 et d'« en assurer un accès juste et équitable » à l'échelle mondiale ».Certains vaccins ont été jugés prioritaires et ont été soutenus financièrement et institutionnellement par la Coalition pour les innovations en matière de préparation aux épidémies (CEPI) : le vaccin à vecteur développé par Oxford pour AstraZeneca, ceux à ARNm de CureVac et Moderna, celui à ADN d'Inovio Pharmaceuticals, celui à protéines recombinantes de Novavax et celui de l'université du Queensland.
Différents pays ont ainsi été incités à passer des commandes auprès de ces industriels, sous réserve que l'efficacité et l'innocuité des vaccins soient démontrées.
Au 15 octobre 2020, le budget consacré à ces pré-commandes est de 12 milliards de dollars aux États-Unis et de 2,3 milliards d'euros en Europe.Le coût total de l'accélérateur ACT-A est estimé à 38 milliards de dollars.
En décembre 2020, il manquait encore 28,2 milliards.
En février 2021, le gouvernement américain s'engage à financer le programme COVAX pour la vaccination dans 200 pays.La Chine est le premier pays à approuver un vaccin (CanSino), le 24 juin 2020, pour une utilisation limitée dans l'armée et pour une utilisation d'urgence dans les professions à haut risque.
Le 11 août 2020, la Russie approuve son vaccin Spoutnik V pour une utilisation d'urgence, alors même que les essais de phase 3 ne commencent qu'un mois plus tard.
À l'automne, le Bahreïn et les Émirats arabes unis accordent une autorisation de mise sur le marché d'urgence pour le BBIBP-CorV, fabriqué par le Chinois Sinopharm,.
Le 20 novembre 2020, le partenariat Pfizer-BioNTech soumet une demande d'autorisation aux autorités sanitaires américaines, la Food and Drug Administration (FDA), pour son vaccin à ARNm BNT162b2, qui est autorisé le 11 décembre,.
Entretemps, le 2 décembre 2020, la Medicines and Healthcare products Regulatory Agency (MHRA) du Royaume-Uni donne une approbation temporaire pour le vaccin Pfizer – BioNTech, devenant le premier pays à approuver ce vaccin et le premier pays du monde occidental à approuver l'utilisation de tout vaccin anti-Covid-19.
Le 18 décembre, la FDA approuve l'mRNA-1273, le vaccin de Moderna.
Le 21 décembre, l'Agence européenne des médicaments (AEM) approuve à son tour le vaccin Pfizer-BioNTech.Alors que les campagnes de vaccination sont lancées au niveau mondial, des variants du SARS-CoV-2 problématiques commencent à apparaître.
À partir de décembre 2020, le variant anglais se distingue par au moins 17 modifications (mutations ou délétions), toutes protéines virales confondues, un record.
La plus connue des mutations est N501Y qui a amélioré la liaison du RBD avec le récepteur ACE2.
Le variant anglais multiplie par deux l’infectivité du virus.
En parallèle apparaissent les variants sud-africain et brésilien, qui ont la particularité de partager avec le variant anglais la mutation N501Y.
Cependant, ces deux variants contiennent surtout des mutations comme E484K qui affaiblissent l’efficacité des anticorps des vaccins de première génération et facilitent les réinfections au SARS-CoV-2.L'Institut Pasteur, qui a mené en 2020 un projet de vaccin basé sur le virus de la rougeole, annonce son abandon le 25 janvier 2021 après que des résultats intermédiaires d'essai clinique de phase I ont montré que son efficacité était insuffisante.Des organisations telles que HuffPost, The Guardian, ou La European Chamber - EuCham ont également établi un système de comparaison des vaccins en matière d'efficacité, de prix et pour d'autres variables.L'OMS tient à jour la liste de l'ensemble des projets de vaccin contre la Covid-19 sur son site internet.Au 5 mars 2021, 10,6 des milliards de doses de vaccin anti-covid ont été administrées dans le monde sur la base des rapports officiels des agences nationales de santé rassemblés par Our World in Data.
L'OMS et la CEPI planifient actuellement le déploiement mondial de plusieurs vaccins anti-covid dans les pays en développement à forte densité de population,.SourcesAu 16 août 2021, d'après Bloomberg, 4 710 652 925 doses ont été mondialement administrées dans 183 pays, atteignant le rythme de 38 249 275 doses par jour.L’Organisation mondiale de la santé (OMS) a déploré, mardi 24 août 2021, les « inégalités choquantes d’accès aux vaccins » contre le coronavirus (SARS-CoV-2), à l’occasion d’une réunion des ministres de la santé du continent africain.En Afrique, face au Covid-19, l’OMS exhorte d’accélérer la vaccination.
L’arrivée de plusieurs livraisons de vaccins par le mécanisme de solidarité internationale Covax, les commandes réalisées par l’Union africaine (UA) et les dons « devraient permettre aux différents pays de vacciner leur population cinq à six fois plus rapidement », le but est d'« atteindre l’objectif de 10 % de couverture vaccinale d’ici à septembre » 2021.La politique vaccinale contre le covid a été critiquée: en mettant 100 doses de vaccin par 100 habitants dans les pays riches contre 1,8 % en Afrique.En août 2021, sur les 700 millions de doses que Covax s'était fixé comme objectif, seules 60 millions ont été disponibles pour l'Afrique Seulement 1,39 % du 1,3 milliard d’Africains sont complètement vaccinés.l'UA travaille avec plusieurs pays africains possédant une industrie pharmaceutique pour nouer des partenariats Nord-Sud afin que le continent puisse fabriquer d’ici à 2040 environ 60 % des vaccins nécessaires à la protection de sa population, toutes maladies confondues.L’Afrique du Sud, en première ligne dans la bataille pour l’accès aux vaccins, a été choisi pour accueillir la première plateforme de transfert de technologie de vaccins à ARN messager contre le SARS-CoV-2 .Les premiers pays à avoir commencé à vacciner leur population ont été la Chine dès l'été 2020 et la Russie le 5 décembre 2020.
En Occident, les premiers ont été le Royaume-Uni le 8 décembre, les États-Unis et le Canada le 14 décembre, la Suisse le 23 décembre et la Serbie le 24 décembre 2020,.Selon l'OMS, l'accès aux vaccins doit être le plus rapide possible en commençant par les personnes les plus à risques, en fonction de la situation épidémiologique.
« Les groupes prioritaires ciblés sont, par exemple, les soignants en première ligne pour qui le risque d’infection est élevé, les personnes âgées et les personnes chez qui le risque de décès est élevé en raison d’affections chroniques, comme les cardiopathies ou le diabète.
»Cette stratégie fait l'objet de débats publics dans différents pays,.
La décision optimale ne peut résulter que de modélisations,,,, assez complexes.
Un modèle étudiant les populations à risque peut identifier de petites fractions de la population (moins de 5 %) susceptibles de présenter un taux de mortalité très élevé, et permettre d'orienter les stratégies de distribution des vaccins.
À l'inverse, si l'on privilégie une diminution de la mortalité, sans tenir compte par ailleurs des situations épidémiques particulières, la définition des populations les plus à risque peut être affinée au-delà du critère d'âge.
Ainsi, une étude montre par exemple que dans la population des plus de 60 ans, ceux ayant une insuffisance rénale ou une pathologie cardiaque ont un taux de mortalité pour la Covid plus élevé que les autres, tandis qu'une autre montre que près de 75 % des décès dans la classe d'âge  ont pour la France au moins une comorbidité.On peut grossièrement résumer le débat comme le choix entre :Il n'est toutefois pas exclu de définir une stratégie permettant de concilier au mieux les deux approches,, une moindre diffusion impliquant une moindre mortalité à moyen terme.En raison des différentes forces des réponses immunitaires de différentes parties de la population, par exemple une réponse immunitaire réduite chez les personnes âgées ou immunodéprimées, qui peut influencer l'efficacité de la vaccination, le profil d'effets secondaires différent de divers vaccins, et la disponibilité limitée des vaccins lors d'une vague pandémique, les stratégies de vaccination sont recherchées qui optimisent le bénéfice individuel ou social de la vaccination par un choix personnalisé du nombre de rappels ou de la dose du vaccin : par exemple, une personnalisation de la dose de vaccin et l'adaptation d'une stratégie de vaccination à la phase pandémique et aux caractéristiques démographiques ont un potentiel important pour minimiser les décès et maîtriser rapidement la pandémie, lorsqu'une vague de variants préoccupants frappe un pays dans un contexte de disponibilité vaccinale limitée.Les vaccins traditionnels peuvent être conservés pendant 3 mois dans un réfrigérateur à une température de l'ordre de 4 °C.
Certains vaccins à ARN nécessitent des températures très inférieures, tandis que d'autres peuvent être conservés dans un réfrigérateur ordinaire :De ce fait, une logistique très particulière doit être mise en place pour transporter certains vaccins :Pour les compagnies aériennes, dont les réseaux ont été considérablement réduits par la crise de la Covid-19, le transport de ces vaccins est un défi considérable.
Aux États-Unis, l'armée contribue à cette logistique exceptionnelle, sous la direction du général quatre-étoiles Gustave Perna.Les spécifications techniques de la mise en flacon du vaccin Pfizer (contenance) semblent assez incompréhensibles puisqu'elles aboutissent dans le meilleur cas à investir dans des seringues d'un type particulier pour extraire la totalité du contenu du flacon, et dans le pire à perdre des millions de doses du vaccin.Lorsqu'une personne a été vaccinée contre la Covid-19, qu'elle a reçu toutes les doses de vaccin nécessaires et que les délais fixés après la vaccination sont passés, elle reste susceptible de contracter une covid (avec ou sans symptômes) et peut en cela propager l'infection.
Il est recommandé aux personnes vaccinées de continuer à utiliser les comportements-barrière (se laver les mains avec du savon, porter des masques, garder une distance sociale) pour éviter d'infecter les autres, en particulier les personnes vulnérables.
Ces restrictions devraient prendre fin lorsqu'il n'y aura plus de dangers avec la pandémie.Révisant une décision prise deux mois auparavant, le Center for Disease Control and Prevention (CDC) a déclaré le 27 juillet 2021 que les personnes vaccinées contre le coronavirus devraient recommencer à porter des masques dans les espaces publics intérieurs dans les régions du pays où le virus fait une poussée.Le CDC a déclaré que les Américains devraient recommencer à porter des masques dans les zones où l'on enregistre plus de 50 nouvelles infections pour 100 000 habitants au cours des sept jours précédents, ou si plus de 8 % des tests sont positifs pour l'infection au cours de cette période.
Les responsables de la santé doivent réévaluer ces chiffres chaque semaine et modifier les restrictions locales en conséquence, a indiqué l'agence.Ces recommandations, qui semblaient annoncer un ralentissement de la pandémie, étaient fondées sur des données antérieures indiquant que les personnes vaccinées étaient rarement infectées et ne transmettaient presque jamais le virus, ce qui rendait le masquage inutile.
L'arrivée du variant Delta a changé la donne.L'agence a déclaré que même les Américains vaccinés dans les régions sans poussée épidémique pourraient envisager de porter un masque dans les lieux publics intérieurs si eux-mêmes ou un membre de leur famille ont un système immunitaire déficient ou risquent de contracter une maladie grave, ou si un membre de leur famille n'est pas vacciné.Les responsables du CDC  ont été convaincus par de nouvelles preuves scientifiques montrant que même les personnes vaccinées peuvent être infectées et porter le virus en grandes quantités, peut-être même similaires à celles des personnes non vaccinées.Selon la Coalition pour les innovations en matière de préparation aux épidémies (CEPI), le développement de vaccins anti-Covid19 est surtout le fait d'entités nord-américaines (40 %), asiatiques (30 %), européennes (26 %).Les pays se sont engagés à acheter des doses de vaccin COVID-19 avant que les doses ne soient disponibles.
Les pays à revenu élevé qui représentent 14 % de la population mondiale, avaient préréservé en novembre 2020, 51 % de toutes les doses.
Certains pays à revenu élevé ont acheté plus de doses qu'il n'en faudrait pour vacciner l'ensemble de leur population.
Le 18 janvier 2021, le directeur général de l'OMS, Tedros Adhanom Ghebreyesus, met garde contre les problèmes de distribution équitable.
Le 10 mars 2021, l'Occident et d'autres membres de l'OMC refusent de renoncer aux droits de brevet sur les vaccins anti-covid.Selon l'immunologiste Dr Anthony Fauci, les souches mutantes de virus et la distribution limitée de vaccins posent des risques, il déclare : « nous devons vacciner le monde entier, pas seulement notre propre pays.
».En Europe, les pays aux revenus élevés bénéficient davantage des vaccins que les pays à revenus intermédiaires.Les États-Unis ont précommandé 700 millions de doses de vaccins, notamment à :Dans les Royaumes du Commonwealth :En mars 2021, il a été révélé que les États-Unis avaient tenté de convaincre le Brésil de ne pas acheter le vaccin Spoutnik V, craignant «l'influence russe» en Amérique latine.
La Palestine a accusé Israël de bloquer la livraison de vaccins à Gaza,.Au premier juillet 2021, les États-Unis ont distribué 382 283 990 doses dont 328 152 304 (ou 85 %) ont été administrées.Au 22 aout 2021, 201 425 785 personnes (soit 61 % de la population) a reçu au moins une doses; 170 821 621 personnes soit 52 % de la population totale a été pleinement vaccinée.L'Union européenne met en place une collaboration sur différents sujets :L'Union européenne a passé des précommandes de 1,5 milliard de doses de vaccins à :Les prix des vaccins contre la Covid-19 ont été négociés par la Commission européenne avec les entreprises pharmaceutiques.
Chaque pays a un droit de tirage en fonction de sa population à un prix garanti avec un engagement d'achat.
Lors de ces négociations, la Commission européenne a accepté les exigences de l’industrie pharmaceutique en lui accordant « une confidentialité quasi totale sur les aides accordées pour la recherche et sur le coût des achats de vaccins ».
Au 12 janvier 2021, l’Union a déboursé près de trois milliards d’euros.En mars 2021, la commissaire européenne aux Affaires intérieures, Ylva Johansson annonce la mise en place d'un « passeport vert » qui regroupe les tests PCR négatifs et la vaccination avec un vaccin approuvé par l'Union européenne.
Les vaccins Sinopharm et Spoutnik V sont pour le moment exclus du passeport.
Le 9 avril 2021, l'Union européenne annonce vouloir commander 1,8 milliard de doses de vaccins supplémentaires après les 2,6 milliards déjà commandées.Au 3 juillet 2021, l'Union européenne a distribué 426 922 366 doses à ses États membres, où ont été administrées 361 484 751 doses.Le 17 juillet, l'Union européenne a vacciné une plus grande partie de sa population en première dose que les États-Unis (55,5 %/55,4 %).Dans l'Union européenne, le vaccin est reconnu par le passe sanitaire européen depuis le 1er juillet 2021.Le 27 juillet 2021, en moyenne, 70 % de la population adulte a reçu au moins une dose de vaccin contre le covid-19 alors que 57 % des citoyens de l'UE sont vaccinés avec deux injections.
Toutefois le taux de vaccination varie selon le pays, de 83 % aux Pays-Bas et au Danemark à 17 % en Bulgarie.En ayant produit plus d'un milliard de doses, l’Union européenne est le continent comptant le plus de personnes vaccinées et le premier exportateur mondial de vaccins contre le Covid-19 d'après le commissaire au marché intérieur Thierry Breton.Au 5 août 2021, l'espace économique européen compte 260 millions de personnes ayant reçu une dose (73 % des adultes) dont 216 millions complètement vaccinées (60 % des adultes).
Pour l'union européenne les chiffres sont de 256 millions de personnes ayant reçu une dose (73 % des adultes) dont 214 millions complètement vaccinées (61 % des adultes).
Les taux varient pas pays pour la première dose : 9 pays ont un taux supérieur à 80 % dont l'Irlande et Malte 87 %; la Bulgarie est à 19 %.Au 12 août 2021, l'espace économique européen compte 496,7 millions de doses administrées, avec 270 millions d'adultes ayant reçu au moins une dose dont 230 millions complètement vaccinées.Au 15 août 2021, la Pologne a vendu à l'Australie plus d'un million de doses achetées par l'union européenne.Au 16 aout 2021, plus de 500 000 000 doses ont été administrées dans l'espace économique européen.Au 13 août, plus de 505 millions de doses (première et seconde cumulées) de vaccins contre le Covid-19 ont été administrées dans toute l'Union européenne.Au 24 août, 75 % de la population adulte de l'EEE a reçu au moins une dose et 599 millions de doses ont été distribuées aux pays membres.Au 25 août, 600 millions de doses ont été distribuées aux pays membres de l'Union européenneAu 29 aout 2021, 250 millions d'européens ont été vaccinés dans l'Union européenne à 27.Au 15 septembre 2021, 300 432 471 personnes ont reçu au moins une dose dans l'espace économique européen, et 272 095 185 y sont pleinement vaccinées.
Sur la population totale, 66 % a reçu au moins une dose et 60 % est complètement vaccinées, ce qui correspond à des taux de 78 % et 71 % dans la population adulte, pour 558 153 234 doses administrées.Au 9 octobre 2021, 309 672 576 personnes ont reçu au moins une dose dans l'espace économique européen, et 286 773 632  y sont pleinement vaccinées.
Sur la population totale, 68 % a reçu au moins une dose et 63 % est complètement vaccinées, ce qui correspond à des taux de 80 % et 74 % de la population adulte, pour 581 209 031 doses administrées.80 % des adultes de l'espace économique européen ont bénéficié d'une première dose de covid.Au 22 janvier 2022 un milliard de doses ont été distribuées dans l'espace économique européen, 334 781 580 personnes ont reçu au moins une dose dans l'espace économique européen, et 315 669 944 y sont pleinement vaccinées.
Sur la population totale, 73,9 %  a reçu au moins une dose et 69,7 % est complètement vaccinées, ce qui correspond à des taux de 84,7 % et 81,1 % de la population adulte, pour 814 522 122 doses administrées.En France, les données statistiques ameli sur la population, les effectifs vaccinés et les taux de vaccinés dans ces populations sont disponibles par département, les effectifs non vaccinés étant la différence entre la population totale et les effectifs vaccinés.Les quatre départements où les populations non vaccinées sont les plus nombreuses avec des effectifs supérieurs à 400 000 sont le Nord avec 643 592 non vaccinés, les Bouches-du-Rhône avec 640264 non vaccinés, la Seine-Saint-Denis avec 584457 non vaccinés et le Rhône avec 454429 non vaccinés.Dans le Nord, sur 614 512 non-vaccinés, 434 592 (71 %) sont des enfants, 146 937 (24 %) ont entre 18 et 64 ans ; 32 983 (5 %) ont plus de 65 ans.En Seine-Saint-Denis, sur 560 767 non-vaccinés, 363 172 (65 %) sont des enfants, 174 138 (31 %) ont entre 18 et 64 ans ; 23457 (4 %) ont plus de 65 ans.Les trois départements où les populations non vaccinées sont les moins nombreuses avec des effectifs inférieurs à 30 000 sont le Cantal avec 28709 non-vaccinés, la Creuse avec 27544 non-vaccinés et la Lozère avec 20853 non-vaccinés.En Lozère sur 19 993 non-vaccinés, 10 125 (51 %) sont des enfants, 7 221 (36 %) ont entre 18 et 64 ans ; 2 647 (13 %) ont plus de 65 ans.Les personnes non-vaccinées présentent un taux supérieur de fréquentation des hôpitaux.
Pour convaincre les personnes à se faire vacciner, certaines personnalités politiques – dont Joe Biden et Ursula Von der Leyen – ont parlé d'une « épidémie de non-vaccinés ».
Ce slogan s'est révélé erroné car, même si la vaccination participe à freiner la propagation de l'épidemie, les personnes vaccinées continuent à jouer un rôle important dans la transmission.
En France, les premières estimations de la protection vaccinale contre le variant Omicron ont établi que, parmi les patients infectés ou hospitalisés, la part touchée de la population est plus élevée chez les personnes vaccinées.Entre le 1er et le 28 novembre 2021, les personnes non vaccinées (9 % de la population de 20 ans et plus) représentaient :Selon certains professionnels de santé, les personnes non-vaccinées poseraient différents problèmes comme l'occupation des hôpitaux — jusqu'à 80 % à l'APHP — ce qui conduit à des appellations péjoratives selon l'Express, comme parasites, irresponsables, ou « passagers clandestins ».— docteur Mathieu Acquier, médecin-réanimateur au CHU de Bordeaux— professeur Alexandre Boyer, du service médecine intensive et réanimationDe nombreux pays, dans lesquels la vaccination contre la Covid-19 n'est pas obligatoire, ont mis en place des mesures pour contraindre les populations non-vaccinées à s'engager dans un schéma de vaccination : passe vaccinal en Allemagne, soins payants à Singapour ou confinement en Autriche.La Suède met en place un passe vaccinal pour les évènements de plus de 100 personnes.Aux États-Unis, la vaccination obligatoire pour les employés des entreprises de plus de 100 personnes, souhaitée par l'administration Biden, a été rejetée par la Cour suprême en janvier 2022.Certaines personnes restent volontairement non vaccinées parce qu'elles croient que les vaccins sont à 100 % efficaces.
En réalité, avec le nombre de non-vaccinés augmente la circulation du virus et donc le risque subi par les personnes vaccinées.
Ainsi une réduction de risque quelle qu'elle soit ne suffit pas à compenser les effets de la croissance exponentielle d'une épidémie qui ne serait pas controlée.Interprétation abusive ?Les non vaccinés sont interdits d'entrée sur le territoire finlandais.En Chine, cinq entreprises sont autorisées à faire des essais cliniques de vaccins anti-Covid, et trois projets sont avancés :Après le développement de trois vaccins, la Chine assure début 2021 être capable de distribuer 400 millions de doses à l'échelle planétaire.
Selon les géopolitologues, cette politique chinoise de distribution a pour but de se placer comme un leader mondial sur le plan sanitaire et d'étendre l'influence chinoise dans le monde.
Les fabricants de vaccins chinois sont accusés de refuser de vendre leurs vaccins au Paraguay si celui-ci n’acceptait pas de rompre ses relations diplomatiques avec Taïwan.
En février 2021, Taiwan accuse la Chine d'entraver ses efforts pour se procurer des doses de vaccin.Le 10 avril 2021, Gao Fu, directeur du centre chinois de contrôle et de prévention des maladies, indique que les vaccins chinois  « n’ont pas des taux de protection très élevés ».
Selon des chercheurs brésiliens le vaccin de Sinovac ne dépasserait pas 50,4 % d'efficacité contre 97 % pour le vaccin Pfizer-BioNTech.L'institut Gamaleya (Moscou) a développé le vaccin Spoutnik V, qui utilise comme vecteurs des adénovirus rAd5 et rAd26 (virus de rhume génétiquement modifié pour exprimer la protéine S) ne pouvant pas se répliquer.Les études de phase III impliquent plus de 40 000 participants en Russie et en Biélorussie.
Fin novembre 2020 sont communiqués les résultats d'un essai de phase III, qui indiquent une efficacité de 91,4 %,.
Le 19 janvier 2021, une demande d'homologation est déposée auprès de l'Agence européenne du médicament, tandis que l'Allemagne déclare être prête à aider la Russie à la production du vaccin.
En février 2021, la revue médicale The Lancet relaye dans une publication une efficacité de 91,6 %.Le 4 mars 2021 l'agence européenne du médicament EMA informe qu'elle débute l'examen d'évaluation (rolling review) du vaccin Spoutnik V. Elle précise que cet examen se poursuivra jusqu'à la disposition de preuve suffisante pour une demande officielle d'autorisation de mise sur le marché .Un second vaccin développé par l'institut Vector (Sibérie) serait entré en phase II en septembre 2020.Cuba mène des recherches pour développer son propre vaccin, mais peine à effectuer des tests vu le faible nombre de cas sur son territoire.
En janvier 2021, un accord est signé avec l'Institut Pasteur de Téhéran pour tester son candidat vaccin le plus avancé, le SOBERANA 02, en Iran, le « guide suprême » Ali Khamenei refusant les vaccins anglo-saxons.
En mars 2021 Vicente Vérez, directeur de l'Institut Finlay de Cuba, annonce un début de vaccination de la population cubaine en juillet 2021.Le pays développe son propre vaccin, QazCovid-in.
Sa campagne vaccinale s'appuie principalement sur le vaccin russe Spoutnik V.Une compétition d'influence existe entre le monde anglo-saxon, la Russie, la Chine et l'Inde pour approvisionner le monde en vaccins dans un schéma précontractuel.En Amérique latineEn AsieEn OccidentEn Afrique du Nord et au Moyen-OrientDans le reste de l'AfriqueLes principaux fabricants de vaccins auraient reçu les commandes suivantes :Les vaccins à ARNm de Pfizer-BioNTech et de Moderna qui ont été développés en moins d'un an, reposent en partie sur des brevets déposés en 2005 sur une technologie conçue par l’université de Pennsylvanie pour fabriquer l'ARN messager utilisé.
Les deux laboratoires ont payé chacun 75 millions de dollars pour pouvoir l’exploiter.La technique de stabilisation de la protéine de spicule est issue de la recherche publique et est soumise à une licence d’utilisation estimée jusqu’à 1,8 milliard de dollars.
versé ces droits à l’Etat américain.Selon L’hebdomadaire Alternatives économiques, relayant l'étude étude de l’Imperial College de Londre qui a fait tourner les modèles du département de génie chimique dirigé par le professeur Nilay Shah, un vaccin de Pfizer-BioNTech reviendrait à 88 cents et un vaccin de Moderna à 2,29 dollars.
Le chercheur Zoltan Kis complète pour le journal Le Monde « Le prix final du vaccin va inclure d’autres éléments comme les coûts de R&D recherche et développement, les essais cliniques, la distribution, la propriété intellectuelle et les frais juridiques, etc.
Il faut ajouter une marge bénéficiaire certaines de ces sociétés ont investi des milliards de dollars dans le développement de la technologie de plate-forme de vaccins à ARNm au cours de la dernière décennie ».
Il faut y ajouter les coûts de finition du produit (flacons, packaging, contrôle qualité).
Le prix de vente en Europe peut atteindre quarante fois le coût de production.L'Union Européenne a centralisé la négociation de prix et de quantités avec les fournisseurs de vaccins, afin d'éviter une surenchère entre les différents pays pour accéder aux vaccins.Lors de ces négociations, la Commission européenne a accepté les exigences de l’industrie pharmaceutique en lui accordant « une confidentialité quasi totale sur les aides accordées pour la recherche et sur le coût des achats de vaccins ».
Au 12 janvier 2021, l’Union a déboursé près de trois milliards d’euros.La négociation a été mené par la Commission européenne avec les entreprises pharmaceutiques, chaque pays a un droit de tirage en fonction de sa population à un prix garanti avec un engagement d'achat.Le 9 avril 2021, l'Union européenne annonce vouloir commander 1,8 milliard de doses de vaccins supplémentaires après les 2,6 milliards déjà commandées.Le prix des vaccins négocié dans les contrats est l'objet de clauses de confidentialité.
Pour une dose du vaccin de Pfizer et BioNTech, les Américains paieraient 25 dollars et les Européens environ 18 dollars.En Europe la disparité des prix entre les différents vaccins est importante : 1,78 euro pour AstraZeneca, 6,93 euros pour Janssen, 10 euros pour CureVac, 12 euros pour Pfizer-BioNTech(19,50 euros depuis avril 2021, 15,50 euros  depuis janvier 2021, augmentation 25 %), 14,70 euros pour Moderna,, soit « une différence de 1 à 8 entre le vaccin le moins cher et celui le plus coûteux ».
Le vaccin russe Spoutnik V, non encore validé par l'Union européenne, serait commercialisé à un prix d'environ 8 euros la dose.Certaines entreprises pharmaceutiques comme Johnson & Johnson et AstraZeneca (politique poussée par l’université d’Oxford jusqu’à la fin de la pandémie) ont fourni leurs vaccins à prix coûtantSelon Libération, repris par Le Canard enchaîné et confirmé par L'Est républicain, l'utilisation d'une 6e dose par flacon de vaccin, vendu initialement pour 5 doses, permet à la firme Pfizer de faire un surprofit de 1,5 milliard d'euros sur la commande européenne.
L'entreprise "promet" de faire profiter les pays pauvres de flacons correspondant à 20 millions de doses de vaccin, mis de côté sur la livraison de l'UE, à prix coutant,.Aux Etats-Unis, AstraZeneca, Moderna et Johnson & Johnson sous-traitent le conditionnement à Catalent, qui a une gigantesque usine à Bloomington,.Selon l'Organisation mondiale de la propriété intellectuelle 417 demandes de brevets liés au vaccin contre la Covid-19 avaient déjà été déposés entre le début de l'année 2020 et la fin du mois de septembre 2021 (et il faut en moyenne 18 mois entre une demande déposée auprès d'un office des brevets et une publication du brevet) et beaucoup d'autres sont attendus.Face à l’urgence sanitaire due à la pandémie de Covid-19, la question « faut-il libérer les brevets des vaccins pour en produire plus ?
Cette idée se heurte aux contraintes de la propriété intellectuelle protégée par les brevets déposés par les entreprises.En décembre 2020, l'OMC débat sur le caractère brevetable des vaccins anti-Covid.
En effet, l'une des règles portant sur les licences obligatoires et licences d'office est que « le propriétaire du brevet ne peut s’opposer à la production d’un médicament ».L'avocat Matthieu Dhenne rappelle que cette « libération » des brevets sur les vaccins est un faux débat, car le système de la licence d'office, qui est prévu à l'article 31 de l'accord sur les ADPIC conclu au sein de l'OMC (repris en substance à l'article L.
613-16 du Code de la propriété intellectuelle) permet déjà une limitation de l'exercice du droit de brevet, afin qu'il soit conforme à l'intérêt de la santé publique,.Il conviendrait cependant d'engager la procédure de la « licence d'office » (ou « licence obligatoire »), après l'avoir réformée un minimum (pour la rendre effective).
Une telle réforme de la licence d'office a déjà été recommandée par un rapport de l'Institut de Boufflers de mai 2020 puis par une tribune collective rassemblant 16 spécialistes du droit des brevets et du droit de la propriété.
Une proposition de loi déposée au Sénat le 8 avril 2021 fait suite à ces recommandations.En mai 2021, emmenés par l’Inde et l’Afrique du Sud, une centaine d’États demandent à l'Organisation mondiale du commerce la levée des droits de propriété intellectuelle, mais « Big Pharma » défend son monopole (Pfeizer notamment).Les États peuvent théoriquement octroyer à des acteurs locaux des licences, sans que les détenteurs des brevets puissent s'y opposer.
Cela permettrait de multiplier les sites de production, et par conséquent de réduire l’écart qui se creuse entre les pays riches et vaccinés et les nations les plus pauvres.En 2021, les États-Unis soutiennent la suspension des brevets pour les vaccins contre le Covid-19 et l'Union Européenne est prête à en discuter, pour accélérer la production mondiale,,.Selon Maurice Cassier, chercheur au Centre national de la recherche scientifique (CNRS), « les fabricants ont bénéficié de milliards d’euros d’aides publiques pour développer leurs vaccins, aucun n’est purement le fruit des recherches industrielles, tous ont profité de décennies de recherches académiques ».
En outre, Pfizer (qui a avec BioNTech, livré plus de 3 milliards de vaccins à ARNm) a déclaré en 2022 un bénéfice net de presque 22 milliards de dollars américains pour 2021 (doublement des bénéfices par rapport à 2020).En 2022, alors que (deux ans après le début de la pandémie) moins de 15 % des gens de pays pauvres ont reçu au moins une dose vaccinale, pendant que les "riches" se voyaient proposer une troisième puis quatrième dose, l'Inde et l'Afrique du Sud sont maintenant soutenus par de nombreux chercheurs, ONGs et par des publications d'importance mondiales comme la revue Nature, qui  appellent, devant l'OMC, à temporairement alléger la propriété intellectuelle liée au COVID-19 au moins la durée de la pandémie.
La Chine, les États-Unis et plus de 100 autres pays le souhaitent, mais les nations européennes ont freiné le processusL'UE a rappelé que le droit international permet déjà de déroger à la propriété intellectuelle en cas d'urgence pandémique (via des licences obligatoires).
Mais après deux ans, aucun groupes pharmaceutiques n'a accepté de délivrer une licence obligatoire pour un vaccin contre la COVID-19, et les dérogations pour un seul vaccin peuvent concerner des dizaines de procédés brevetés, ce qui freine le traitement des demandes.Le groupe propose que les entreprises des pays à revenu faible ou intermédiaire soient autorisées à faire une seule demande par vaccin.Un autre problème est l'accès aux formes de données éventuellement nécessaires à la production des vaccins, non couvertes par un brevet mais confidentielle.
Les demandeurs d'une dérogation doivent dresser une liste de tous les brevets à annuler – ce qui prendrait trop de temps en période de pandémie.En mars 2022, la position des pays d'Europe semble s'assouplir, hormis pour le Royaume-Uni et la Suisse (où sont basées plusieurs des plus grandes sociétés pharmaceutiques du monde).En juin 2022, l’OMC entérine un accord à minima sur la levée des brevets sur les vaccins contre la Covid-19.
Il donne le droit aux pays en développement d'accorder des licences de production pour les vaccins à des fabricants locaux en se passant de l’autorisation des titulaires des brevets.Dans le cas de la production des vaccins à ARN messager, la duplication des brins d'ARN n'est pas techniquement très difficile (culture de plasmides dans un réacteur), et pourrait être faite par presque n'importe quel laboratoire.Les nanoparticules lipides d'encapsulation des brins (LNP) semblent être en grande partie à la source de la limitation des capacités de production des vaccins.
Elles sont pour le vaccin BioNTech une coproduction d'entreprises autrichienne et canadienne mais non de l'entreprise dépositaire du brevet du vaccin.
Elles n'ont pas non plus été conçues par Moderna, l'autre laboratoire disposant, en février 2021, d'une autorisation de mise sur le marché en Europe, d'un vaccin ARN.
Il serait donc légal pour un laboratoire tiers d'utiliser une licence du brevet employé par Moderna pour la production des LNP de son vaccin.
De plus, Moderna s'est engagé à ne pas poursuivre un tel laboratoire dans le cas de production d'un vaccin ARN anti-Covid.
Ainsi en Suisse, la société Lonza produit le vaccin Moderna.
En France, Sanofi n'avait pas début février donné suite à la demande de la ministre de l'industrie de faire de même, alors que la production est insuffisante par rapport aux besoins,, et qu'un aggravation de l'épidémie se profile pour mars 2021,.
Par ailleurs, la majorité des capacités de production des LNP est en 2021 utilisée pour la cosmétique et celles affectées au domaine pharmaceutique le sont pour la production de médicaments anti-cancéreux,.Depuis le début de la pandémie de Covid-19 jusqu'àu mois d'août 2021, le programme d’achat commun de vaccins de l’Union Européenne(UE) a fourni 330 millions de doses du vaccin BioNTech-Pfizer, 100 millions de l’AstraZeneca, 50 millions du Moderna et 20 millions du Johnson & Johnson.Le contrat passé en mai entre l’UE et BioNTech-Pfizer pour livrer 1,8 milliard de doses de vaccin livrables jusqu’en 2023 inclut des vaccins de deuxième génération.En décembre 2020, les analystes estiment que Pfizer and Moderna pourraient atteindre 32 milliards de dollars de chiffres d'affaires en 2021 sur les vaccins développés pour combattre la Covid-19.
L'estimation  est réévaluée en mai 2021 à 44 milliards de dollars, 26 milliards et 18 milliards de dollars pour, respectivement, Pfizer et Moderna.La capitalisation boursière des entreprises de Biotechnologies atteignent, pour Moderna 69,5 milliards de dollars, pour BioNTech(partenaire de Pfizer) 43 milliards de dollars.La politique vaccinale est la cible de désinformations et fait face aux hésitations de certaines personnes.Pour répondre à la problématique de l'immunité collective, la politique vaccinale peut notamment avoir recours à la vaccination obligatoire ou à un document numérique dont la dénomination varie localement entre passeport vaccinal et passe sanitaire.En France, la controverse et l'opposition aux vaccins anti-covid sont menées depuis le printemps 2020 par différents youtubeurs tels Silvano Trotta et Thierry Casasnovas qui reprennent à leur compte la rhétorique complotiste pro-Trump de la mouvance QAnon,.Dans le mouvement QAnon, le Président des États-Unis Donald Trump et le Premier ministre britannique Boris Johnson sont présentés comme des messies qui vont sauver l’humanité d’une cabale de pédophiles marxistes, assoiffés d’adrénochrome, et dont l’objectif ultime est le grand reset.
Le mouvement QAnon a été un relai essentiel aux films complotistes Plandemic ou Hold-Up.
Ces films qui mêlent désinformation et fantasmes d'extrême-droite, entretiennent un folklore autour de la 5G, de Bill Gates ou encore d'un « grand reset » un projet visant à réduire la population et à instaurer un régime totalitaire communiste.Sur internet, les théories complotistes du QAnon ont été véhiculées par l’Internet Research Agency, une organisation russe qui a activement pris part à l’élection américaine de 2016 en favorisant le candidat Trump.
L’IRA est une usine à troll sur internet : elle emploie des milliers de personnes pour propager sur le net des idées d’extrême droite.
Une des maximes de l’IRA est : « white is black and black is white », ce qui se traduit par une inversion entre le bien et le mal.
L'IRA a des liens avec le SAIMR, une organisation héritée de l'Apartheid qui est aujourd'hui accusée d'avoir répandu intentionnellement le VIH en Afrique australe.
Pour plus de détails, consulter : Origine du virus de l'immunodéficience humaine.Durant l'année 2021, de nombreux témoignages de gens capables de fixer un aimant sur l'emplacement de leur vaccination contre la Covid-19 ont été associés avec la magnétofection mais démentis.Dans le monde, environ 10 % du public perçoit les vaccins comme dangereux ou inutiles, refusant la vaccination.
Selon un sondage effectué par Ipsos en octobre 2020 dans une quinzaine de pays, les Français sont les plus réticents à se faire vacciner : 46 % ne souhaitent pas être vaccinés contre 36 % aux États-Unis, 31 % au Japon, 30 % en Allemagne, et 21 % au Royaume-Uni.
En mars 2021, 19 % des adultes américains déclarent avoir été vaccinés et 50 % des adultes américains prévoient de se faire vacciner.
Dans un effort pour démontrer l'innocuité du vaccin, des personnalités l'ont reçu à la caméra, d'autres s'engageant à le faire,.Avant la pandémie de Covid-19, la France est en tête des pays les plus sceptiques envers les vaccins.
En 2019, un Français sur trois ne croit pas que les vaccins soient sûrs.
Cette défiance existe également chez les professionnels de la santé.
Une étude officielle de Santé publique France publiée le 4 décembre 2020 suggère que 80 % des médecins généralistes et globalement 68 % des professionnels de santé libéraux souhaitent se faire vacciner, mais seulement 55 % des infirmiers y sont prêts.La persistance en mars 2021 de réticences au sein de cette population à la vaccination avec le vaccin AstraZeneca pourrait notamment être liée aux multiples changements intervenus dans les décisions politiques et administratives prises quant à la définition des populations ciblées et aux conditions d'utilisation (espacement des doses), et à la relative indigence des références et/ou données scientifiques rigoureuses (conflits d'intérêts par exemple) connues en matière d'efficacité et de suivi post-vaccinal dans le cadre des autorisations provisoires de mise sur le marché (AMM) délivrées en Europe concernant ce vaccin,.Très peu de pays ont rendu obligatoire la vaccination à toute leur population adulte.
L'Indonésie est le premier pays à imposer, début 2021, une vaccination obligatoire à l'ensemble de ses concitoyens.
La vaccination y est conduite avec le vaccin chinois Sinovac,.
Le Tadjikistan, le Turkménistan, le Vatican, les États fédérés de Micronésie, l'Autriche et l'Équateur adoptent à leur tour la vaccination obligatoire dans le courant de l'année 2021,.
En Équateur, la vaccination est rendue obligatoire dès l'âge de cinq ans, ce qui constitue une première mondiale pour ce groupe d'âges.
La vaccination est également obligatoire à partir de décembre 2021 en Nouvelle-Calédonie, territoire français disposant d'une large autonomie,.Dans certains pays comme la France et le Royaume-Uni, le débat concernant l'importance d'une vaccination collective et la liberté individuelle de refus est ravivé,.
A la suite de la prise de position de Yannick Jadot pour que le vaccin soit rendu obligatoire, Emmanuel Macron déclare le 24 novembre 2020 : « Je ne rendrai pas la vaccination obligatoire ».Aux États-Unis, un sondage publié en décembre 2020 sur un échantillon représentatif de la population américaine (près de 2 700 personnes âgées de 18 ans et plus) porte sur l'obligation vaccinale Covid-19 (acceptable ou inacceptable) pour les écoliers, les adultes, et les employés.
Près de la moitié (48,6 %) la jugent acceptable chez les écoliers contre 38,4 % qui la jugent inacceptable (le reste ne se prononce pas) ; l'obligation pour les adultes est acceptable pour 40,9 % contre 44,9 %, et pour les employés 47,7 % contre 38,1 %.
Aux Etats-Unis, l'acceptation ou pas de l'obligation vaccinale Covid-19 est associée à des caractéristiques démographiques et à des préférences partisanes.
Sont plus enclins à accepter d'être vaccinés : ceux qui votent démocrate (plus que républicain ou indépendant), et ceux qui ont un niveau de diplôme égal ou supérieur au bac.
Il n'y a pas de différence entre hommes et femmes, mais les noirs sont plus réticents que les non-noirs.Le 24 août 2021, la Cour européenne des droits de l’homme rejette le recours de 672 sapeurs-pompiers français (professionnels et volontaires des services départementaux d’incendie et de secours de France ou travaillant dans le milieu hospitalier) qui s’opposaient à l’obligation de vaccination qui leur était faite par la loi du 5 août 2021 relative à la gestion de la crise sanitaire.En France à la suite de l'augmentation du nombre de cas, de la huitième vague et l'apparition du variant centaure en septembre 2022, le docteur Emmanuel Hirsch a demandé une cousultation sur ce sujet très délicat.Israël, qui a vacciné la moitié de sa population, lance le 21 février 2021 un « passeport vert » téléchargeable sur le site gouvernemental, qui permet d'accéder aux théatres, cinémas, restaurants, salles de sport, événements culturels, etc.
Il est délivré 8 jours après la 2e dose vaccinale.
L'Espagne prépare un passeport vaccinal pour mai 2021, qui doit remplacer les tests PCR.
La Chine annonce le 10 mars 2021 le lancement d'un « passeport sanitaire » pour les chinois qui voyagent à l'étranger, disponible sur WeChat.Dans l'Union européenne, un projet de passeport vert est rendu public le 17 mars 2021.
Ce document européen, électronique ou papier, doit être mis en place fin juin 2021.Ce Passe sanitaire européen est un certificat officiel depuis le premier juillet 2021.Il contient les informations suivantes concernant le détenteur, à la fois dans la langue du pays et en anglais :Certaines compagnies aériennes souhaitent rendre obligatoire la vaccination de leurs passagers internationaux.
C'est notamment le cas de Qantas, principale compagnie aérienne australienne.
L'instauration de carnets électroniques de vaccination est envisagée.
Certaines compagnies aériennes, comme EasyJet, Japan Airlines et Ryanair, estiment qu'elles ne rendront pas une telle vaccination obligatoire.
Certaines considèrent que le vaccin ne sera pas obligatoire sur les vols intérieurs dans l'Union européenne.
En attendant le passeport vaccinal, Air France expérimente un passeport sanitaire basé sur un test PCR pour les voyages vers la Martinique et la Guadeloupe.En avril 2021, à l'issue de la septième réunion du comité d'urgence de l'OMS sur le covid, l'Organisation Mondiale de la Santé indique ne pas être favorable à l'utilisation d'un passeport vaccinal obligatoire pour les voyages internationaux.
Dans un communiqué, l'OMS enjoint les États à reconnaître que l'utilisation obligatoire d'un tel passeport pourrait aggraver les inégalités et favoriser une liberté de circulation différenciée.En France, les personnees vaccinés (par une dose du vaccin de Johnson&Johnson ou deux doses sinon) se voient remettre une attestation sur papier.
Pour obtenir une attestation numérique, sur smartphone, on peut par exemple photographier l'attestation sur papier (puis se l'envoyer par messagerie), télécharger une attestation numérique sur le site attestation-vaccin.ameli.fr, ou télécharger l'application TousAntiCovid.Au 13 octobre 2021, 591.728.344 certificats ont été émis dans l'espace économique européen, dont 136.901.354 certificats en France, 123.254.466 en Allemagne, 97.058.162 en Italie, et 43.058.575 en Autriche.
Ces 591 728 344 certificats cumulent 437.509.564 certificats vaccinaux, 84.009.810 tests rapides de détection d’antigènes, 60.162.592 tests d’amplification des acides nucléiques et 10.046.378 certificats de rétablissement.Une étude, publiée lundi 11 octobre 2021 par EPI-Phare sous l'égide l’Agence nationale de sécurité du médicament (ANSM) et de la Caisse nationale d’assurance-maladie (CNAM), sur la population française en conditions de vie réelle, confirme l’efficacité des vaccins sur plus de 22 millions de personnes.
« Les personnes vaccinées de 50 ans et plus ont neuf fois moins de risque d’être hospitalisées ou de mourir du Covid-19 que les non-vaccinées », et cela, jusqu’à cinq mois après avoir reçu une seconde dose des vaccins Pfizer, Moderna ou AstraZeneca.
La variole ou petite vérole était une maladie infectieuse d'origine virale, très contagieuse et épidémique, due à un poxvirus.
Le mot variole vient du latin variola, -ae (qui signifie « petite pustule », avec l'influence du mot varius, « varié, bigarré, tacheté, moucheté »).
En effet, la variole se caractérise en quelque sorte par un « mouchetage de pustules ».
La variole a été responsable jusqu'au XVIIIe siècle de dizaines de milliers de morts par an rien qu'en Europe.La variole a été déclarée éradiquée en 1980, grâce à une campagne de l'Organisation mondiale de la santé (OMS) combinant des campagnes de vaccination massive, dès 1958, avec une « stratégie de surveillance et d'endiguement », mise en œuvre à partir de 1967.
Au XXIe siècle, seuls des échantillons de ce virus sont conservés à des fins de recherche par des laboratoires habilités par l'OMS.La variole est surnommée « petite vérole », et c'est en référence à cette maladie que la syphilis a été surnommée « grande vérole », mais les deux maladies n'ont rien en commun étiologiquement.Le substantif féminin variole (prononcé ) est un emprunt au bas latin médical variola,,, terme utilisé pour la première fois par Marius d'Avenches pour qualifier une épidémie sévissant en France et en Italie en 570.
Le terme variola (« maladie tachetée ») est un diminutif dérivé de varius (tacheté, varié, changeant) et varus (pustule).La variole se présente sous l'aspect d'une dermatose pustuleuse, qui peut ressembler à une forme grave de varicelle, mais qui évolue en une seule poussée (toutes les lésions sont identiques, étant de même âge).
La variole était un fléau redouté.
Elle tuait un malade sur cinq (chez les adultes, près d’un malade sur trois).
Quand elle ne tuait pas, elle laissait souvent un visage grêlé, marqué à vie.
Elle est toujours restée hors de portée d’un traitement efficace.La forme classique ou variole régulière dite aussi ordinaire (80-90 % des cas) connaît trois sous-types : la forme confluente (éruption cutanée sur tout le corps), la forme semi-confluente (éruption cutanée presque exclusivement sur le visage) et la forme discrète (pustules très clairsemées).Silencieuse, la période d'incubation est en moyenne de 12 jours (extrêmes 7 à 17 jours).La phase d'invasion est brutale et aiguë, durant trois jours.
Elle comporte une fièvre très élevée, à 40 °C ou plus, de grands frissons, un syndrome douloureux (maux de tête, douleurs dorsales), des nausées et vomissements fréquents.Une éruption précoce transitoire (rash) de divers types, généralisée ou localisée, peut survenir durant cette phase de début.
En dehors d'un contexte épidémique, le diagnostic clinique n'est pas possible à ce stade.Au début de cette phase, lors de l'apparition de l'éruption définitive, la fièvre et les autres symptômes s'atténuent le plus souvent.Vers le quatrième jour de la maladie, un exanthème érythémateux (taches rouges) apparaît à la face (front et tempe) et aux extrémités des membres (notamment aux poignets).
Il s'étend en une seule poussée éruptive : tous les éléments sont au même stade évolutif dans un même territoire cutané.
L'extension se fait du visage et des extrémités (mains et pieds), où les éléments sont les plus nombreux, vers le tronc.
Cette distribution est dite centrifuge, elle se fait en deux ou trois jours.Cet exanthème peut s'accompagner, ou être précédé, d'un énanthème (langue, pharynx) évoluant vers des vésicules rapidement érodées avec ulcérations douloureuses.Chaque élément éruptif est d'abord une macule, puis une papule de 2 à 3 mm, devenant une vésicule de 2 à 5 mm au troisième jour de l'éruption.
Ces vésicules sont enchâssées dans le derme comme une « perle dans un chaton », elles sont très dures à la palpation, donnant l'impression d'un grain de plomb.
Elles sont emplies d'une sérosité claire,.À partir du cinquième jour de l'éruption, le liquide des vésicules se trouble.
Les vésicules évoluent en pustules, de 4 à 6 mm, reposant sur une base très inflammatoire.
Elles tendent à se déprimer en leur centre (ombilication).
Le stade de pustule ombiliquée était historiquement la phase critique, celle où la fièvre et les douleurs revenaient, et où la mort pouvait survenir.À partir du huitième jour de l'éruption, les pustules se dessèchent, soit par rupture (croûte jaunâtre d'aspect mielleux), soit sans rupture (croûte noire ou brune).
Cette phase s'accompagne d'une chute définitive de la fièvre pour se terminer entre le 15e et le 30e jour de l'éruption.
Chaque élément peut laisser une cicatrice déprimée, blanche et définitive (indélébile),.L'étendue de l'éruption est variable, présumant de l'évolution (une éruption de plus grande ampleur est un critère de gravité).
Les dernières lésions à persister sont celles de la paume des mains et de la plante des pieds.Les complications les plus courantes étaient les surinfections bactériennes cutanées, pulmonaires et oculaires, ainsi que le sepsis généralisé.Les principaux organes atteints étaient les reins, les articulations, le cœur (myocardite) et le système nerveux (encéphalite, neuropathies…).
L'encéphalite de la variole survient dans environ 1 cas sur 500.Chez la femme enceinte, la variole entraine l'avortement ou l'accouchement prématuré, l'enfant pouvant naitre infecté et porteur de lésions cutanées.Les séquelles les plus communes étaient les cicatrices du visage, présentes chez 65 à 80 % des survivants, puis la cécité par atteinte oculaire (1 % des survivants), et les déformations des membres par lésion articulaire ou cutanée (2 % des enfants survivants).La classification de l'OMS distingue 5 formes principales, les trois premières survenant chez les non-vaccinés, les deux dernières pouvant se voir chez les sujets déjà vaccinés :Ce nom vient du portugais alastrar signifiant ce qui se propage vite et fort.L'alastrim ou variole mineure, variola minor est due à un virus variolique très proche de celui de la variole majeure, mais moins virulent.
La maladie est moins intense, plus courte, laissant peu ou pas de cicatrices, avec une létalité inférieure à 1 %.
Elle est très contagieuse, mais un malade atteint d'alastrim ne transmet que l'alastrim et jamais la variole majeure.Cette forme se rencontrait surtout en Amérique du Sud et en Afrique du Sud.
Elle a d'abord été observée en 1904 chez les Cafres sous le nom de variole des Cafres, variole blanche ou laiteuse (Kaffir milk-pox),.Le diagnostic positif était purement clinique et relativement facile en contexte épidémique.
Au cours du XXe siècle, il devient plus difficile avec la rareté de la maladie (dernier cas autochtone en France en 1936).
Lors de la dernière épidémie française à la suite d'un cas importé (Vannes, 1954), les premiers cas ont été considérés comme des varicelles graves, et la variole suspectée après le premier décès.À partir des années 1950, le diagnostic virologique est principalement fait, de façon rapide en quelques heures par examen au microscope électronique du liquide vésiculaire, et confirmé de façon spécifique par culture du virus sur œuf embryonné (délai de 2 à 3 jours).Au début du XXIe siècle, le diagnostic virologique se fait par techniques moléculaires de PCR, qui permet de préciser la nature exacte de la souche virale.
Les tests sérologiques ne sont guère utiles dans la variole, car ils ne permettent pas de distinguer entre les différents orthopoxvirus.Au stade pré-éruptif, peuvent se discuter une grippe, une méningite, et diverses fièvres tropicales (paludisme, arboviroses…).Au début de l'éruption, le diagnostic différentiel doit être fait avec la varicelle.
Dans le cas de la variole, la fièvre précède de quelques jours l’éruption alors que pour la varicelle, la fièvre est concomitante de l'éruption.
Dans la varicelle, les lésions se font en plusieurs poussées successives, il peut y avoir en même temps les quatre types de lésions, d'âges différents dans un même territoire.
L'apparition des croûtes dans la varicelle est plus rapide, les éléments déjà crouteux coexistant avec des éléments jeunes.
La distribution des lésions dans la varicelle est variable et désordonnée, elle n'est pas centrifuge comme dans la variole.
Les vésicules de la varicelle sont superficielles, alors que celles de la variole sont enchâssées (implantées dans le derme).Il faut aussi éliminer les autres dermatoses bulleuses.Selon les données génomiques disponibles, la variole humaine regroupe deux types de souches dites majeures (hautement pathogènes) et mineures.Les virus « majeurs » semblent originaires d'Asie, certains isolats humains ayant toutefois une origine africaine.Les virus mineurs proviendraient d'Amérique du Sud et d'Afrique de l'Ouest.
Tous ces virus auraient divergé assez récemment (16 000 ans à 68 000 ans) à partir d'un ancêtre commun, poxvirus, dont les hôtes supposés auraient été des rongeurs africains.
On ignorait encore en 2010 si le virus mineur est un mutant du virus majeur, ou si au contraire le majeur en est une forme plus pathogène apparue ensuite, ou si ces deux virus proviennent d'une autre souche disparue.Sur les mêmes bases (génomique du virus), les virologues ont estimé que, d'après son taux moyen de mutation (d'environ 10−6 substitutions nucléotidiques par site et par an), selon ce chiffre, le virus humain aurait commencé à évoluer de façon indépendante il y a environ 3 400 (± 800) ans.L'ancêtre commun aux orthopoxvirus actuels est inconnu, mais pourrait être apparenté aux souches actuelles de virus de la variole bovine (ou la vaccine) ou cowpox.En mars 2004, des échantillons de virus variolique furent découverts à Santa Fe dans une enveloppe insérée entre les pages d'un livre de médecine datant de la guerre de Sécession ; ces échantillons font l'objet d'analyse par le CDC pour comprendre l'histoire de la variole au cours des siècles.En novembre 2012, le virus est détecté dans le corps gelé d'une femme morte dans les années 1730 en Sibérie.
L'intérêt pour la recherche est notamment de montrer la rapide évolution du virus.Le virus de la variole fait partie des poxvirus.
Il en existe deux variantes humaines, Variola minor et Variola major (cette dernière étant communément appelée Variole classique ou encore Variole asiatique) difficilement distinguables en laboratoire, mais présentant pourtant des taux de létalité très différents (respectivement 1 et 30 %) ce qui a pu faire douter de l'unicité des maladies.
L'existence de deux formes de variole était pressentie depuis l'époque d'Edward Jenner au XIXe siècle, mais ce n'est qu'à partir de 1929 que le terme de Variola minor s'impose.
Pour Variola minor, on distingue encore Variola alastrim, propre à l'Amérique du Sud, du Variola minor trouvé en Afrique : il fut un temps proposé d'y voir deux espèces différentes mais cela ne fut pas retenu.
S'il y a de légères différences de formes cliniques entre les infections par variole mineure et variole majeure, ces dernières ne peuvent être véritablement distinguées que par la constatation des taux de létalité ou par des analyses de laboratoire.
La variole majeure, qui prédominait dans le monde jusqu'à la fin du XIXe siècle, laissant la place à la variole mineure, ne subsistait plus qu'en Asie en 1971.Le virus est très stable et peut subsister des années dans des croûtes.
Dans la plupart des conditions naturelles toutefois, le virus, s'il subsiste, ne conserve son pouvoir pathogène guère plus que quelques semaines.Des corpuscules furent observés par John Brown Buist en 1887 puis de nouveau par Enrique Paschen en 1906 tandis qu'Amédée Borrel avait observé des corpuscules semblables dans des tissus d'oiseaux infectés de variole aviaire en 1904.
En 1903, il était encore question de « streptocoque variolique ».
Eugène Woodruff et Ernest William Goodpasture montreront en 1929 que ces inclusions contenaient des virus de la variole.Si la variole est une maladie exclusivement inter-humaine, il existe des virus génétiquement proches (famille poxviridae, genre orthopoxviridae) affectant divers animaux, donnant des maladies de gravité variable.Il s'agit d'une maladie exclusivement inter-humaine.
Il n'y a aucun réservoir de virus animal et pas de transmission par les insectes.La variole se transmet de personne à personne par voie respiratoire rapprochée (postillons, aérosols, etc.) à partir des voies aérodigestives supérieures des personnes infectées et par contact cutané direct à partir des lésions cutanées.Le varioleux est contagieux dès le début de la maladie (à partir de l'apparition des premiers symptômes), le virus étant déjà présent en quantité importante dans ses voies supérieures.
Cette présence est maximum durant la première semaine de la phase éruptive, le malade excrétant des virus jusqu'au 14e jour de la maladie.
La transmission était particulièrement élevée au sein des familles (et moins au sein d'une communauté), car la variole est une maladie qui, dès son début, force le malade à s'aliter.
Il n'y a pas de transmission durant la phase d'incubation, ni de transmission par porteur sain ou sans symptômes.Au niveau des lésions cutanées, le virus reste présent contagieux jusqu'à plus de deux semaines après le début de l'éruption, et peut se communiquer par contact direct jusqu'à la disparition totale des croûtes.
La literie et les vêtements d'une personne infectée sont source d'infection et doivent être passés à l'autoclave, sinon les croûtes infectées ou les vêtements infectés pourraient être contagieux indirectement à longue distance, ou longtemps après.
Toutefois cette dernière contagiosité est contestée, le virus ne pouvant survivre longtemps à l'extérieur à température ambiante habituelle.
Des cas de contamination à la suite de blessures provoquées par du matériel souillé ont également été constatés.Le virus pouvait être transmis aux personnes en contact avec un sujet vacciné par variolisation, procédé abandonné en Europe au début du XIXe siècle, mais encore en usage dans les années 1970 en Afghanistan et en Éthiopie.La dose infectieuse de la variole n'est pas connue, mais elle est estimée très faible, de l'ordre de quelques virions.La porte d'entrée est, usuellement, celle des voies respiratoires, même si d'autres voies de contamination sont possibles.
Une première réplication virale se fait au niveau de l'épithélium des bronches, sans occasionner aucun symptôme.
Le virus se diffuse ensuite dans le système réticulo-endothélial, et se multiplie dans les ganglions lymphatiques.
Une virémie, toujours asymptomatique, se produit au 3e jour de l'incubation, avec multiplication du virus dans la rate et la moelle osseuse.Une deuxième virémie se produit quelques jours plus tard en provoquant les premiers signes de la maladie (forte fièvre, douleurs).
La première lésion se situe fréquemment au niveau du pharynx, permettant ainsi le relargage des virus dans l'atmosphère.
La phase éruptive débute lorsque la peau est atteinte par transfert du virus à ce niveau par les macrophages.
Les lésions seraient plus importantes à la face et aux extrémités parce que le virus se multiplie d'autant mieux à des températures inférieures à 37 °C.Les anticorps neutralisants commencent à apparaitre vers le 6e jour de la maladie.
Ils persistent plusieurs années, puis une immunité à médiation cellulaire prend le relais.La maladie, si elle ne tue pas le patient, est immunisante : toute réinfection par le même virus est impossible pendant des années voire des décennies.
D'autres sources affirment que l'immunité est durable à vie, c'est-à-dire tant qu'il reste immuno-compétent.Les incertitudes de pathogenèse tiennent au fait que les méthodes d'études qui permettraient de les lever n'ont été mises au point qu'à partir des années 1980-1990, c'est-à-dire après l'éradication mondiale de la variole.
Ainsi, il est probable que les cas de variole maligne ou hémorragique surviennent à la suite d'un défaut de la réponse immunitaire.
De même, la vaccination antivariolique est contre-indiquée chez le sujet immuno-déficient, susceptible de multiplier et excréter du virus vaccinal.La létalité était due à la réplication du virus lui-même mais aussi aux surinfections microbiennes notamment cutanées et pulmonaires.La réplication du virus entraine une toxémie (accumulation de produits nocifs dans le sang), faite de complexes immuns circulants et d'antigènes varioliques solubles.
La mort survient par œdème aigu du poumon, choc septique ou collapsus cardiovasculaire.L'antibiothérapie a permis de réduire la létalité de la variole due aux surinfections microbiennes.La létalité dépend du virus (souche virale, dose infectieuse) et de l'état immunitaire du malade (plus ou moins immunisé, plus ou moins immunocompétent).
Pour la variole mineure (alastrim) et les sujets vaccinés à jour et immunocompétents, elle était inférieure à 1 %.
Pour la variole majeure et classique de 15 à 30 % au XXe siècle (près du double aux siècles précédents) et plus de 90 % pour les formes les plus graves.Il n'existait pas de traitement spécifique des personnes infectées dont, éventuellement, les symptômes peuvent être soignés.Le tecovirimat inhibe la protéine P37 fabriquée uniquement par les orthopoxvirus et permet une guérison de la plupart des formes animales de la maladie.La maladie serait apparue de façon sporadique, dans les villages du néolithique, à partir de la domestication ou d'une proximité animale (ancêtre commun du virus humain et d'autres animaux, comme celui de la variole du singe, la vaccine (bovidés et équidés), ou la variole des camélidés),.Une population minimale de 200 000 habitants serait nécessaire pour maintenir une circulation permanente de virus variolique (variole endémique ou épidémique).
Cette densité humaine a été atteinte par plusieurs civilisations antiques, d'abord en Égypte et au Moyen-Orient.La variole serait donc apparue vers le IVe millénaire av.
selon les données épidémiologiques et historiques et il y a 3 400 ± 800 ans selon les données d'horloge moléculaire.Deux origines géographiques sont possibles, l'Inde et l'Égypte.
L'origine égyptienne est la plus probable, les données de phylogénie indiquant qu'un orthopoxvirus ancestral devait exister chez des rongeurs africains.
La première mention écrite de la variole vient d'un médecin d'Alexandrie, Aaron, vers le VIIe siècle.Des traces de cicatrices trouvées sur les visages de momies égyptiennes ont été considérées comme l'indice qu'une ou plusieurs formes de variole sévissaient au Moyen-Orient il y a plus de 3 000 ans.
La variole est probablement exportée vers l'Inde par voie commerciale au cours du premier millénaire avant J-C.
La maladie aurait été introduite en Chine en l'an 49 de notre ère (selon des descriptions d'éruptions pustuleuses laissées par des auteurs chinois du IVe siècle).Il n'existe pas de terme original grec ou latin pour désigner la variole, bien que la maladie soit très caractéristique.
Il est probable que les grandes épidémies qui ont frappé l'Empire romain au IIe siècle et au IVe siècle soient la variole.
La peste antonine vers l'an 165 de notre ère, pourrait aussi avoir été une épidémie de varicelle ou de rougeole ou d'un type différent de la variole moins mortelle, et qui aurait depuis disparu, selon Hendrik Poinar (de l'Université McMaster d'Hamilton, au Canada).À partir du Ve siècle, des épidémies probables de variole sont signalées en Europe.
Saint Nicaise, évêque de Reims, survécut à une épidémie et devint le saint patron des victimes de la variole, avant d'être martyrisé par les Huns vers 451.
De telles épidémies sont mentionnées au VIe siècle par Grégoire de Tours et Marius d'Avenches.
Durant le même siècle, une épidémie de variole aurait décimé, près de la Mecque en 572, une armée éthiopienne conduite par le prince chrétien Abraha.
La variole serait mentionnée de façon allégorique dans le Coran « Dieu envoya des volées d'oiseaux qui firent pleuvoir des pierres sur les assaillants ».Dans les années 730, la variole atteint le Japon qui perd environ un tiers de sa population, ou de façon moins certaine dès 585, à partir de la Corée,.La maladie accompagne les conquêtes musulmanes en Afrique du nord et dans la péninsule ibérique.
Le médecin persan Rhazes, dans son fameux traité, est le premier à distinguer cliniquement la rougeole et la variole vers 910.
La variole est présente chez les enfants, sous forme d'épidémies saisonnière au Moyen-Orient et en Asie centrale.
C'est une étape décisive dans la connaissance des fièvres éruptives.Vers l'an mille, la variole s'est établie par la guerre ou le commerce, d'une part sur le littoral méditerranéen, et d'autre part dans les parties de l'Eurasie les plus densément peuplées (Route de la soie, Inde, Chine, Corée, Japon).
Toutefois, il reste de nombreuses régions indemnes en Europe centrale et du nord, qui seront plus ou moins touchées après les retours des Croisades.Au XVe siècle, la variole est signalée comme une maladie des enfants à Paris, en Espagne et en Italie, mais sous une forme de gravité intermédiaire entre la variole mineure et majeure.
En revanche, quand la variole touche pour la première fois des populations insulaires isolées, elle peut être explosive et meurtrière, comme celle de l'Islande en 1241, qui perd près d'un tiers de sa population.La présence de la variole en Espagne est à la source de l'introduction de la variole en Amérique du Sud par les conquistadors.Au XVIe siècle, un nouveau variant du virus apparait, d'origine possiblement zoonotique ou dû à une mutation dans une souche en circulation.
Il s'est ensuite répandu dans le monde conjointement à des formes parfois bénignes, parfois effroyablement mortelles, source d'une pandémie responsable de dizaines de millions de morts.Une étude récente (2016) publiée dans Current Biology porte sur l'ADN viral d'une souche de variole découverte dans une momie occidentale d'enfant du milieu du XVIIe siècle trouvée dans la crypte de l'église dominicaine du Saint-Esprit de Vilnius.
Cet échantillon a été séquencé et c'est le plus ancien virus séquencé connu en 2016.
Il était génétiquement très proche des souches récentes, ce qui laisse penser que la forme la plus mortelle de la variole était le variant embarqué par les explorateurs du Nouveau Monde qui a décimé les Amérindiens.
Les auteurs ont construit un arbre généalogique de 49 souches modernes et anciennes connues, et retracé leur évolution depuis un ancêtre commun qui aurait surgi entre 1530 et 1654, un siècle environ avant la mort de l'enfant momifié.C'est durant cette période que les Français appellent « grosse vérole », la syphilis, pour la distinguer de la variole dite « petite vérole ».
Les Anglais font de même, la variole étant dite small pox et la syphilis great pox.
Les épidémies de variole deviennent plus fréquentes avec l'urbanisation croissante.
La pandémie qui démarre en Europe et au Proche Orient en 1614 est probablement responsable de l'introduction de la variole en Amérique du Nord (colonies françaises et britanniques).
De la même façon, à la même époque, l'exploration et la conquête de la Sibérie par les Russes s'accompagne d'épidémies dévastatrices de variole dans les populations sibériennes.À partir du XVIIe siècle, plusieurs pays européens inaugurent un système d'enregistrement statistique des cas de variole et des décès par variole.
Au XVIIIe siècle, environ 95 % de la population française est touchée par cette maladie, et un décès sur dix est dû à celle-ci.
Les enfants en sont les premières victimes : 90 % des morts par variole en Angleterre sont âgés de moins de 5 ans, 10 % des enfants meurent chaque année de variole en Suède, un enfant sur sept meurt de variole en Russie.La variole n'épargne pas les maisons royales, tuant entre autres la reine Marie II d'Angleterre, 32 ans (1694), l'empereur Joseph Ier, (33 ans) le dauphin Louis de France, 50 ans, le prince Louis de Lorraine (7 ans) et ses sœurs les princesses Élisabeth-Charlotte (10 ans) et Marie-Gabrielle (9 ans) (1711), le prince Léopold-Clément de Lorraine, 16 ans (1723) le roi Louis Ier d'Espagne, 17 ans (1724), le prince Léopold d'Anhalt-Köthen, 32 ans (1728), le tsar Pierre II de Russie, 15 ans (1730), la reine Ulrique-Éléonore de Suède, 53 ans (1741), l'impératrice Marie-Josèphe (28 ans) et sa belle-sœur l'archiduchesse Marie-Josèphe, 16 ans (1767), le roi Louis XV de France, 64 ans, (1774), ce qui incite les souverains à promouvoir la variolisation.Il semble démontré que la variole pénétra dans l’île de Saint-Domingue en 1516, à la suite de l’arrivée dans l’île, à bord d’un navire portugais, d’esclaves noirs infectés.
Selon une théorie commune, la variole fut introduite sur le continent américain par un esclave noir de Pánfilo de Narváez, au moment où les troupes de ce dernier débarquaient au Mexique en 1520 pour y combattre Hernán Cortés.
Cependant, sur le site archéologique de Tiwanaku (ou Tiahuanaco) en Bolivie, dans le temple semi-souterrain dit des Têtes, on trouve des représentations de maladies sur différents visages humains, dont une tête au visage parsemé de lésions où d’aucuns ont voulu voir les séquelles de la variole ; on relève en outre, dans plusieurs codex mexicains précolombiens, des visages couverts de lésions pouvant être imputées à la variole.Quoi qu’il en soit, il est certain qu’on assista à un accroissement de la virulence de la maladie pendant et après la conquête espagnole.
Ensuite, en 1525, le virus, véhiculé par l’expédition militaire de Pizarro, infesta l’empire inca, puis parvint entre 1558 et 1560 dans le Río de la Plata et en 1562 au Brésil.Les sources indiquent que les épidémies de variole, dont on soulignait par ailleurs le caractère cyclique, frappaient plus violemment les indigènes que les Européens, non à cause d’une constitution plus faible chez les premiers, mais en raison d’une part de leurs coutumes et de leur mode de vie, propices à la propagation et à la contagion, et d’autre part de leur situation immunitaire au moment de l’arrivée du virus, les Indiens n’ayant en effet pas eu, ou peu, l’occasion de bâtir de mémoire immunitaire contre la maladie.
Il en résulta une catastrophe démographique majeure : des 18 millions d’habitants que comptait le Mexique avant l’apparition des conquistadors, il ne restera vers 1600 qu’un peu plus d’un million.
Dans un titre de chapitre, l'historien Sheldon Watts utilise le terme d'holocauste.La zone où, dans toute l’Amérique, la variole occasionna le plus de ravages fut la Caraïbe, celle-ci ayant en effet pendant longtemps joué un rôle de nœud de communication et se trouvant donc confrontée au trafic commercial le plus intense.
Les Antilles étaient le centre de distribution, la plaque tournante du système commercial monopolistique espagnol, et c’était là en outre qu’accostait le vaisseau de permission concédé, aux termes du traité d'Utrecht, par l’Espagne à l’Angleterre, vaisseau qui permettait l’acheminement d’esclaves noirs vers tout le continent américain, c'est-à-dire de ceux-là mêmes qui seront identifiés comme la cause involontaire de nombre d’épidémies de variole, en particulier dans l’île de Cuba.En Amérique du Nord, la variole arrive avec les premiers colons britanniques, français et hollandais.
Une première épidémie touche la côte du Massachusetts en 1617-1619, qui décime les Indiens Massachusetts.
La densité de population était toutefois insuffisante (aussi bien pour les amérindiens que pour les premiers colons) pour que la variole se maintienne de façon endémique.
Il y avait de long intervalles de répit (population immunisée) entrecoupées de fortes épidémies frappant les plus jeunes, nés après la dernière épidémie et lors de l'arrivée de nouveaux colons.
Des épidémies à peu-près décennales frappent les ports comme Boston (1636, 1659, 1666, 1677, etc.), New York, Jamestown ou Charleston.L'association entre les cas survenus à bord des navires et ces épidémies portuaires étant évidente, cela a permis de justifier la mesure des quarantaines, lesquelles iront en se généralisant au cours du XVIIIe siècle.
La première quarantaine s'est effectué à Boston en 1647, à propos d'une épidémie probable de fièvre jaune.
La mesure s'est ensuite appliquée contre les importations de variole.La grande majorité des colons nés américains était faiblement immunisée par rapport aux Britanniques.
Pour beaucoup de jeunes Américains, étudier en Angleterre faisait courir un grand risque de contracter la variole.
La fondation des Universités en Amérique du Nord au XVIIIe siècle est liée en partie au refus de courir ce risque.Les guerres intercoloniales entre Français, Anglais et leurs alliés Indiens ont été l'occasion de plusieurs épidémies de variole (voir Agent de guerre biologique).
Avec la croissance urbaine du XVIIIe siècle (côte atlantique et berges du Saint Laurent), la variole devient plus fréquente et plus intense.
Durant la guerre d'indépendance, lorsque les Anglais abandonnent Boston, le 17 mars 1777, George Washington ordonne que « mille hommes qui ont déjà eu la variole » s'emparent de la ville.Aux Indes, la première épidémie de variole décrite par les Européens est celle de l'enclave portugaise de Goa en 1545.
Les descriptions les plus complètes sont celles du XVIIIe siècle, avec l'établissement des Britanniques, notamment dans le Bengale (épidémie de 1769-1770).
Les médecins anglais notent une situation endémique avec des pics saisonniers (saison sèche de printemps), ponctuées d'épidémies sévères tous les 5 ou 7 ans.En Chine et en Asie du Sud-Est, la variole est endémique dans toutes les zones très peuplées.
Des peuples tribaux du nord, comme les Mongols, craignent les contacts avec les Chinois.
Les empereurs de Chine mandchous de la dynastie des Qing eux-mêmes choisissent comme successeurs parmi leurs fils ceux qui ont déjà eu la variole.
Certains dalaï-lama et panchen-lama ont refusé des invitations d’empereurs de Chine par crainte de la variole.
En 1780, le panchen-lama Lobsang Palden Yeshe accepte une invitation et meurt de variole quelques semaines après son arrivée.
Des voyageurs européens notent qu'il est difficile de trouver un Chinois adulte qui ne soit porteur d'aucune cicatrice de variole.Le Japon connaît des épidémies de variole tous les 15 ans en moyenne, par introduction répétée provenant de Chine ou de Corée.En Indonésie et aux Philippines, défavorisées aussi par la proximité de la Chine, le problème apparaît plus important encore.
La population est encore trop petite pour que la variole devienne endémique, mais des épidémies violentes peuvent survenir à l'occasion, apportées par navires (épidémie de Sumatra en 1780-1783).En 1788, les Britanniques installent leur première colonie en Australie, près de Sydney.
Un an plus tard, des cas de variole se produisent chez des Aborigènes voisins.
Toutefois, la variole ne s'établit pas, à cause du peu de contact entre Européens et Aborigènes et du faible peuplement des deux communautés.
L'origine des premières épidémies australiennes n'a pas été éclaircie, mais la variole aurait joué un rôle important dans le déclin de la population aborigène (sud-est de l'Australie) dans la première moitié du XIXe siècle.Après l'Afrique du nord lors de la conquête musulmane, la variole est introduite le long des côtes d'Afrique de l'est par des colonies arabes (cités portuaires comme Mombasa), probablement à partir du XIVe siècle.
Les sources écrites connues apparaissent lorsque les commerçants portugais remplacent les marchands arabes.
Des tribus africaines de l'intérieur attaquèrent des villes côtières, ce qui provoqua en 1589, une grave épidémie de variole frappant les Africains de tout âge, et les jeunes enfants portugais alors que les Portugais adultes restaient indemnes pour la plupart.Il est probable que les relations commerciales entre l'Afrique de l'est et de l'ouest, et le pèlerinage à La Mecque, ont contribué à l'établissement de la variole en Afrique.
La variole africaine aurait été déjà endémique avant le commerce d'esclaves vers les Amériques.
Toutefois, en Angola, la variole est introduite à la suite de la fondation de Luanda par les Portugais en 1484.En Afrique du Sud, la variole atteint Le Cap en 1713 par un navire venu des Indes.
Là encore, les Hollandais adultes, nés en Europe, sont immunisés alors que des clans entiers de Khoïkhoï disparaissent.
D'autres épidémies surviennent en 1755 et 1767, frappant les colons nés en Afrique, les Khoïkhoï et les Bantous.En 1729, la variole est introduite à La Réunion, par un navire apportant des esclaves de Madagascar.L'Afrique centrale est touchée par la variole au cours du XIXe siècle, par le commerce arabe des esclaves (par caravanes, comme en Ouganda dans les années 1840), les chasseurs d'ivoire et l'ouverture du commerce européen.
Les épidémies sont très sévères dans des populations tribales (80 % de mortalité) comme dans le bassin du Congo.Finalement, vers la fin du XIXe siècle, une nouvelle forme de variole est signalée, la variole mineure ou alastrim, à peu près simultanément en Afrique du Sud et en Floride.L'histoire de la lutte contre la variole peut se diviser en plusieurs périodes : d'abord la phase de la variolisation, ensuite celle de la vaccination, et enfin celle de la campagne mondiale d'éradication (1958-1977).En Inde, la variole est décrite dans les livres ayurvédiques.
Le traitement curatif ayurvédique passait par l'inoculation d'un « matériau varioleux » vieux d'un an, issu des pustules de personnes ayant contracté la variole l'année précédente.Dès le XIe siècle, les Chinois pratiquaient la variolisation : il s'agissait d'inoculer une forme espérée peu virulente de la maladie en mettant en contact la personne à immuniser avec le contenu de la substance suppurant des vésicules d'un malade.
C'est le premier ministre Wang Dan qui après la perte d'un de ses fils de la variole avait convoqué divers praticiens de toute la Chine pour mettre au point une prophylaxie.
Un moine taoïste apporta la technique d'inoculation qui se diffusa progressivement dans toute la Chine.
Mais ces origines précoces sont remises en cause par certains auteurs, et la première mention indiscutable de la variolisation apparaît en Chine au XVIe siècle.
Le résultat restait cependant aléatoire et risqué, le taux de mortalité pouvant atteindre 1 ou 2 %.
La pratique s'est progressivement diffusée le long de la route de la soie.En 1701, Giacomo Pylarini réalise la première inoculation à Constantinople.
À partir des années 1710, les mentions concernant l'inoculation pratiquée en Orient se multiplient dans les journaux européens.La technique est importée en Occident au début du XVIIIe siècle, par Lady Mary Wortley Montagu, femme de l'ambassadeur de Grande-Bretagne en Turquie, qui l'apprend du docteur Emmanuel Timoni (v. 1670-1718), médecin de l'ambassade de Grande-Bretagne à Constantinople.
Diplômé de l'université de Padoue, membre de la Royal Society de Londres depuis 1703, le docteur Timoni publie en 1713 dans les Philosophical transactions de la Royal Society son traité sur l'inoculation.
Son travail est publié de nouveau l'année suivante à Leipzig.
À partir de cette date, les publications sur ce sujet se multiplient, Pylarino en 1715, Leduc et Maitland en 1722… L'efficacité de la méthode ayurvédique a été attestée par le médecin britannique J.Z.
Holwell dans un rapport au College of Physicians à Londres en 1767.Elle est introduite en France plus tard.
Au temps de la Régence, la pratique de l'inoculation est discutée et étudiée par les cercles médicaux et en Conseil du roi ; malheureusement, des problèmes plus urgents la rejettent dans l'oubli pour presque vingt-cinq ans, en dépit d'une campagne menée par Voltaire en 1727, tandis que la pratique se diffuse lentement en Europe.
Un des rares moments de paix sur le continent - entre la guerre de Succession d'Autriche et celle de Sept Ans - permet au débat de se développer et de prendre même la forme d'une vive controverse nourrie par un afflux de livres, d'articles dans les journaux, de pamphlets, d'échanges de lettres et de mémoires présentés à l'Académie.
Faute de données précises sur les taux de mortalité de la petite vérole naturelle ou artificielle, les débats manquent d'un point d'appui solide.
Les dangers de l'inoculation, non négligeables, sont d'ailleurs rapportés par les inoculateurs eux-mêmes, souvent prompts à dénoncer les erreurs, échecs ou abus de leurs confrères et concurrents.
La technique employée consiste à placer des fils imprégnés de pus varioleux dans de profondes incisions : l'abondante suppuration ainsi provoquée devait, suivant les croyances de l'époque, drainer hors du corps le pire effet de la petite vérole (avec un bénéfice secondaire pour l'inoculateur qui se fait rémunérer pour les pansements compliqués qu'il est amené à renouveler).Deux personnalités, les docteurs Tissot et Théodore Tronchin, s'illustrent dans les débats : n'étant pas sujets du roi de France, protestants, ils sont plus libres de leur parole tant vis-à-vis de la Sorbonne que de Versailles.
S'y adjoint le mathématicien La Condamine, qui le 24 avril 1754 introduit l'argument probabiliste lors de son intervention remarquée en faveur de l'inoculation à l'Académie des sciences.
Leurs adversaires les plus notables sont De Haen, un brillant médecin, et Roncalli dont l'argumentation est surtout d'ordre moral.
La première inoculation véritablement médiatisée est celle pratiquée par le docteur Théodore Tronchin en 1756 sur les enfants du duc d'Orléans.
En 1758 La Condamine compte à peine cent inoculés à Paris ; dix ans plus tard il n'en comptera qu'un peu plus de mille dans la France entière.
En 1760, lors d'un exposé devant l'Académie Royale des Sciences de Paris, Daniel Bernoulli démontre que, malgré les risques, la généralisation de cette pratique permettrait de gagner un peu plus de trois ans d'espérance de vie à la naissance.
Le travail de Bernoulli, qui jette les bases du modélisme épidémiologique, n'a probablement pas eu de conséquences pratiques immédiates.
La variolisation continue à susciter l'hostilité de nombreux médecins.Avant 1760, la pratique de la variolisation est parfois inefficace voire catastrophique : les médecins européens ont remplacé l'aiguille, qui servait en Turquie à l’inoculation, par un instrument plus « chirurgical », la lancette, qui permet de faire une incision plus profonde.
À compter de 1760, l'incision superficielle préconisée par une famille de médecins du nom de Sutton, augmente la fiabilité de l'inoculation.Le 8 juin 1763, le Parlement de Paris, en attendant les avis des Facultés de Théologie et de Médecine de Paris, interdit temporairement sur son territoire les inoculations urbaines hors d'enceintes spécialement affectées.
Seulement après quatre ans de discussions, le 15 janvier 1768, la Faculté de Médecine de Paris décrète que la pratique de l'inoculation serait « admissible ».
L'avis de la Faculté de Théologie semble avoir été oublié et n'est toujours pas connu, bien que La Condamine signale la : «  question résolue affirmativement dès 1723 par neuf docteurs de la Sorbonne consultés »,.
La Condamine se réfère à l'épisode raconté en 1723 par le docteur M. de la Coste dans une lettre adressée à M. Dodart, conseiller d’État et premier médecin du Roy : « Puisque dans une conférence que j'eus en Sorbonne il y a environ cinq semaines avec M. le Doyen & neuf de leurs plus fameux Docteurs  j'eus la satisfaction de les voir enfin conclure, qu'il étoit licite, dans la vûe d'être utile au public, de faire des expériences sur cette pratique»L'inoculation est accusée de contrecarrer la volonté de Dieu et d'accroître l'épidémie à Paris comme à Londres.La controverse de l'inoculation atteignit son acmé en 1768 avant de s'éteindre en 1774.
C'est l'année où le médecin suisse Louis Odier approfondit une correspondance avec Anton de Haen pour enquêter sur la portée réelle de la vaccination contre la variole à Londres, ville dont il extrapole les tables de mortalité grâce à des données remontant à 1661.
Il entrevoit des progrès fulgurants dans l'espérance de vie et son estimation, après avoir étudié les tables de mortalité de ceux qui se sont intéressés à la maladie, Antoine Deparcieux (1746), Théodore Tronchin (1748), Pehr Wilhelm Wargentin (1749), Thomas Simpson (1752), ou Johann Peter Süssmilch (1761).
Plus tard, Louis Odier dénoncera avec virulence les curés savoyards et valaisans, selon lui responsables des lenteurs de la diffusion de la vaccine aux portes mêmes de Genève.En 1785, la Société royale de médecine, fondée en 1776 pour étudier le problème des épizooties, des épidémies et des eaux minérales, indique, comme moyen de lutter contre la maladie, la mise en quarantaine.Pour la première fois, des années 1770 jusqu'en 1791, au moins six personnes ont testé, chacune de façon indépendante, la possibilité d'immuniser les humains de la variole en leur inoculant la variole des vaches, présente sur le pis de la vache.
Parmi les personnes qui ont fait les premiers essais, figurent en 1774, un fermier anglais au nom de Benjamin Jesty, et en 1791, un maitre d'école allemand du nom de Peter Plett.
En 1796, le médecin anglais Edward Jenner fera la même découverte et se battra afin que le bon résultat de l'immunisation soit officiellement reconnu.Le 14 mai 1796, Jenner inocule à un enfant du pus prélevé sur la main d'une fermière (Sarah Nelmes) infectée par la vaccine (via le contact avec le pis de la vache infectée), ou variole des vaches (cowpox en anglais).
Trois mois plus tard, il variolise l'enfant, qui ne développe aucune pustule, se révélant ainsi immunisé contre le virus.
Cette pratique se répand progressivement dans toute l'Europe.
Néanmoins, la variole reste endémique pendant tout le XIXe siècle et n’a progressivement disparu d'Europe qu’après la Première Guerre mondiale.La controverse resurgit à l'occasion de l'introduction de la vaccination jennérienne qui se présente à un moment où la France est en conflit avec l'Angleterre.
E. Jenner a publié ses résultats en juin 1798 : dès octobre de cette année, une revue de vulgarisation scientifique éditée à Genève, La Bibliothèque britannique, en fait état.Pour l'anecdote, la vaccination de l'époque consiste à prélever du pus directement des pustules et à infecter les hommes avec celui-ci (ne pas oublier que Louis Pasteur et l'asepsie viendront plus tard).
Et plutôt que de transporter une vache infestée, il est plus simple de se déplacer avec un homme récemment « vacciné » et qui présente les pustules de la cowpox.Cette pratique, nommée « vaccination de bras-à-bras », pose de nombreux problèmes.
En effet, les populations, pour des raisons culturelles, sont parfois opposées au mélange du sang.
Les réticences proviennent des populations et des médecins ; ces derniers acceptant mal d'engendrer le mal volontairement (voir tradition hippocrato-galénique).
Par ailleurs, cette forme de variolisation tend à transmettre d'autres maladies, à l'instar de la syphilis, maladie terrifiante par excellence.
À cela s'ajoute un autre problème : le taux de mortalité n'est pas nul, de l'ordre de 2 %.
Ainsi, en France, de 1760 à 1787, il n'y a que 60 000 inoculations volontaires de la cowpox.En France, c'est un professeur de botanique de Rochefort, le docteur Bobe-Moreau qui le premier promeut la vaccination jennérienne par ses écrits, puis par la pratique.
Obtenant du docteur Pictet un fil imprégné de vaccin, il expérimente le procédé avec succès fin mars 1800 et entreprend ensuite la première vaccination publique.À la même époque, le 19 janvier 1800, l’École de médecine de Paris et l'Institut National (l'Académie des sciences) nomment chacun une commission d'étude, qui décident de joindre leurs efforts.
Missionné par ces deux institutions, le Genevois Colladon se forme à Londres aux méthodes anglaises qui seront expérimentées, sans succès, à la Salpêtrière sous la direction de Pinel.
Parallèlement, fin janvier 1800, le duc de La Rochefoucauld-Liancourt, récemment revenu d'émigration en Angleterre, fonde le Comité national de la vaccine grâce à une souscription publique.
En mai 1800, la société des souscripteurs nomme un Comité de médecins (dont la plupart des membres sont issus des commissions de l’École de médecine et de l'Académie des sciences).
Grâce à l'appui de personnalités importantes comme Lucien Bonaparte et Talleyrand, ce comité entre en contact avec des médecins de Londres qui leur envoient, le 2 juin 1800, du fluide vaccinal.
À Vaugirard, le Dr François Colon vaccine trente enfants qui exhibent des signes de fausse vaccine.
Un médecin britannique, Woodville, est alors invité en France.
Des enfants vaccinés selon ses instructions à Boulogne est extraite une lymphe qui permet de vacciner à Paris avec succès 150 enfants.
Cela se sait, et conduit à un timide développement de la pratique.
Instruit, fin janvier 1801, par le premier rapport du Comité de la Vaccine, le préfet de la Seine octroie le 7 février un premier établissement au Comité afin d'y procéder à des vaccinations.
Dans les semaines qui suivent d'autres établissements seront confiés au Comité.
En février celui-ci, avec l'appui du préfet, appelle les maires des douze arrondissements de Paris à se doter d'un centre de vaccination - gratuite - ce qui sera effectif en avril.
Tous les établissements publics parisiens font vacciner leurs pensionnaires.
Devant ces résultats, des comités et des centres de vaccination sont créés, rapidement, dans les principales villes de province.Le 6 mars 1801, Parmentier rédige un rapport pour Chaptal, alors ministre de l’Intérieur de Napoléon, sur l’inoculation gratuite de la vaccine aux enfants des familles indigentes.
Le 4 avril 1804, est fondée la Société pour l’extinction de la petite vérole par la propagation de la vaccine au sein de laquelle un comité central, présidé par le docteur Guillotin, a pour mission le développement de cette pratique dans tous les départements.
En 1805 une circulaire explicative instituant l’usage de la vaccine est adressée aux préfets sans aboutir à de notables résultats.
Un décret du 16 mars 1809 fait obligation aux grandes villes de conserver du vaccin pour en fournir aux médecins qui en auraient besoin.
La véritable campagne de vaccination débutera en 1811, lorsque Napoléon fera vacciner le roi de Rome et qu’une instruction ministérielle (du 29 mai) rendra la vaccination obligatoire dans l’armée.Les ministres de l'Intérieur Chaptal puis Fouché imposent aux journaux — y compris médicaux — d'obtenir l'accord du Comité de vaccine avant toute publication sur le sujet.
Pour le transport, Bretonneau substitue les tubes en verre capillaire aux fils de lin imprégnés de la lymphe vaccinale.Le Comité Central de la Vaccine créé en 1803 et rattaché à l'Académie de Médecine en 1820 ordonne les campagnes de vaccination.
La circulaire du 26 août 1880 réserve l'acte vaccinal aux seuls diplômés (jusqu'alors, les prêtres, religieuses, notables, instituteurs, etc. avaient prêté leur concours).
La vaccination de bras à bras restera la plus répandue jusque dans les années 1880.
Les autorités se plaignent du faible nombre d'enfants vaccinifères - on  récoltait sur leurs pustules la pulpe vaccinale servant aux vaccinations - imputé à l'opposition des familles.
Cet obstacle disparaîtra dans la dernière décennie du siècle à la suite de l'adoption d'abord de la « vaccine animale » puis du procédé de conservation de la pulpe vaccinale qui permettra de s'affranchir de la présence de génisses lors des séances de vaccination.
Si les vaccinations sont souvent dispensées gratuitement aux indigents, il s'en faut de beaucoup que la gratuité soit largement pratiquée.
La création d'un service public de vaccination fait l'objet de débats dans lesquels le statut libéral de la médecine pèse d'un poids certain.
De nombreuses voix appellent à une obligation vaccinale, seule capable de venir à bout de populations rétives et peu accessibles à quelque éducation sanitaire que ce soit.
Dans les colonies, cette obligation fut instituée plus tôt qu'en métropole, ainsi en 1876 en Cochinchine.
En 1843, 1858 et 1880, plusieurs projets de loi ayant en vue une obligation vaccinale échouent.
Toutefois, l'obligation est imposée à différentes catégories de la population : les enfants placés en nourrice et leur gardienne en 1874, les conscrits en 1876, les écoliers en 1882, les lycéens et collégiens en 1883, les étudiants en médecine et pharmacie en 1891.La variolisation, confrontée au scepticisme des milieux médicaux, et en l’absence d’encouragement officiel, n'est introduite en Espagne que tardivement et, si elle finit par être appliquée, sa diffusion est moindre qu’en Grande-Bretagne par exemple, où l'on estime que 200 000 personnes sont inoculées entre 1766 et la fin du siècle.
Quelques années après la découverte de la vaccination jennérienne, les autorités médicales du pays conçoivent l’idée d’une campagne de vaccination de masse dans tout l’Empire espagnol (y compris les Philippines) ; soutenu par le roi Charles IV, le projet prend corps et, entre 1803 et 1814, l’expédition Balmis (ainsi nommée d’après son directeur, le médecin et homme de science Francisco Javier Balmis) accomplit un voyage autour du monde, d’abord conjointement, puis, après la scission décidée au Venezuela, en deux équipes distinctes, l’une desservant l’Amérique centrale et le Mexique, et de là les Philippines, l’autre se dirigeant vers le sud pour apporter la vaccine en Nouvelle-Grenade, à Quito, au Pérou, dans le Haut-Pérou (Bolivie actuelle), et jusqu’au Chili.
Concomitamment, des structures administratives sont mises en place pour perpétuer l’œuvre des expéditionnaires et garantir notamment, par une chaîne ininterrompue et bien organisée d’enfants vaccinifères, la disponibilité de lymphe vaccinale sur plusieurs générations.
Globalement, l’expédition est un succès, même si les guerres d’indépendance ne laisseront quasiment rien subsister de l’œuvre de Balmis.Certains soldats prussiens ayant contracté la variole en France pendant la guerre de 1870 sont à l'origine d'une épidémie, une fois de retour en Allemagne.
Les autorités sanitaires de l'Empire allemand imposent une vaccination obligatoire à travers le Reichsimpfgesetz du 8 avril 1874 (mais qui ne sera effective que le 1er avril 1875).En 1899, la découverte par Saint-Yves Ménard du maintien de l’activité du virus conservé dans la glycérine permet les vaccinations en série, et à distance de la génisse.En Allemagne, l'obligation portant sur la première immunisation, chez les jeunes enfants donc, est levée le 31 janvier 1975.
Le 31 mai 1976, une loi limite l'obligation vaccinale à quatre catégories de la population.
L'obligation prend totalement fin en 1983.Le 15 février 1902, la Loi sur la protection de la santé publique, en son article 6, rend la vaccination antivariolique obligatoire au cours de la première année de vie ainsi que les re-vaccinations des 10e et 21e années.En 1917, André Fasquelle met au point, avec Lucien Camus, la dessiccation sous vide de la pulpe vaccinale congelée, ce qui en permettra le conditionnement et l’emploi dans les pays tropicaux.La dernière épidémie de variole date de l'hiver 1954-1955 à Vannes et Brest.
Le sergent Roger Debuigny est rapatrié dans le Morbihan après la fin de la guerre d'Indochine, bien que vacciné, il a contracté la variole.
Il y a 20 morts sur 98 cas à Vannes et à Brest,.La vaccination n'est plus obligatoire en France depuis 1979 et les rappels ne sont plus obligatoires depuis 1984, mais il existe un Plan national de réponse à une menace de variole (2006).
C'est pourquoi la majorité de la population est considérée comme vulnérable à tous les orthopoxvirus (virus de la famille variole), à l'occasion de l'épidémie de variole simiesque de 2022.En 1950, l'Organisation Sanitaire pan américaine (OSPA), s'appuyant sur un nouveau procédé développé par le virologue Leslie Collier, entreprend d'éradiquer la variole des Amériques (ce résultat sera atteint en 1967, sauf au Brésil).
L'Union soviétique propose à l'Organisation mondiale de la santé, en 1958, d'éradiquer entièrement la variole, qui faisait alors 2 millions de victimes par an dans le monde.
La stratégie initiale, prévue pour l'éradication dans les pays du Tiers-Monde, estimait qu'un taux de vaccination de 80 % au moins (seuil de l'immunité grégaire) était nécessaire pour éradiquer le virus.
La campagne de vaccination se révèle ardue à mettre en œuvre.Le rapport final de la Commission mondiale pour la certification de l'éradication de l'OMS note :L'OMS change alors de stratégie en 1967, mettant en œuvre la « stratégie de surveillance et d'endiguement », qui consiste à isoler les cas et à vacciner tous ceux qui vivaient aux alentours de foyers d'épidémie.
Une équipe internationale est constituée sous la direction de l'Américain Donald Henderson.La campagne d'éradication se heurte d'abord au problème d'identification des foyers d'infection, tous n'étant pas nécessairement recensés.
Le contexte social, culturel et politique joue aussi un rôle important.
Ainsi, en Inde et au Bangladesh, beaucoup d'Hindous s'opposent à la vaccination par peur d'offenser Shitala Devi, la déesse associée à la variole.
Des prêtres bénissent toutefois des lots de vaccin.
En outre, une année, les pluies violentes lors de la mousson rompent les barrages et les digues, forçant la population à fuir, ce qui a pour effet d'étendre à nouveau le foyer d'infection, lequel sera éradiqué au bout d'un an d'efforts.Le Soudan, lui, est plongé en pleine guerre civile, exposant à des risques accrus les équipes de santé (qui n'auront néanmoins aucune victime à déplorer).En Europe, un foyer d'infection se déclare en Suède (mai-juillet 1963), éradiqué via des mesures de quarantaine et de vaccination.La dernière grande épidémie européenne de variole a lieu en 1972 en Yougoslavie.
Un jeune Kosovar revenant d'un pèlerinage à la Mecque et en Irak déclare la variole.
L'épidémie frappe 38 personnes, dont 6 meurent.
Le régime titiste déclare alors la loi martiale, impose la quarantaine et entreprend une campagne massive de re-vaccination de la population, avec l'aide de l'OMS et de l'équipe de Henderson.
L'épidémie est endiguée en deux mois.Le dernier cas spontané de la forme la plus grave de variole (Variola major) est enregistré au Bangladesh, en octobre 1975, chez une petite fille de deux ans, Rahima Banu.
À partir de cette date, la variole est considérée comme éradiquée de la quasi-totalité du globe, à l'exception de la Corne de l'Afrique.
En effet, la pauvreté des infrastructures sanitaires et routières d'Éthiopie et de Somalie rendent très difficile la vaccination de masse qui est un succès ailleurs.
S'y ajoutent les conflits armés, les famines et les migrations de réfugiés qui compliquent encore la tâche.Néanmoins, par une intensification des mesures de vaccination, de surveillance, de confinement, au début de 1977, le dernier cas de variole contracté de manière naturelle est diagnostiqué à Merca en Somalie, le 26 octobre 1977.L'éradication globale de la variole est certifiée par une commission d'experts le 9 décembre 1979 et déclarée officiellement par l'OMS le 8 mai 1980 dans la résolution WHA33.3,.
À la suite de ce succès, la vaccination systématique n'est plus appliquée, elle n'est employée aujourd'hui que dans les forces armées et les laboratoires.À partir de 1976, l'éradication mondiale étant imminente, le nombre de laboratoires détenant des virus varioliques est réduit.
Dans le monde, il passe de 75 en 1975 à 7 en 1979, puis à 4 en 1981 (Afrique du Sud, URSS, Royaume-Uni, États-Unis).
Ce processus a été accéléré par l'accident de laboratoire survenu en 1978.Dix mois après la détection du dernier cas de variole dans le monde (Somalie, 1977), en août 1978, Janet Parker, photographe de l'École de Médecine de l'Université de Birmingham se présenta à l'hôpital avec des symptômes de variole.
Les analyses sérologiques et la microscopie électronique confirmèrent son état et elle mourut le 11 septembre de la même année des suites de la maladie.
Le professeur Henry Bedson (en), responsable des recherches sur la variole dans ce laboratoire, tomba malade le 2 septembre, après une apparente tentative de suicide, et mourut le 7 septembre.Janet Parker, 40 ans, avait été vaccinée en 1966 et n'avait pas voyagé récemment, ni été en contact avec une personne revenant de l'étranger.
290 personnes ayant été en contact avec Janet Parker durant sa maladie furent identifiées, vaccinées ou revaccinées, et isolées à leur domicile.
Le père de Janet Parker développa une fièvre et mourut subitement le 5 septembre d'un arrêt cardiaque.
La mère de Janet Parker, 70 ans, tomba malade le 7 septembre et la variole fut confirmée, mais elle se rétablit et put sortir de son isolement le 22 septembre.L'enquête révéla que le laboratoire de photographie où travaillait Janet Parker se trouvait immédiatement au-dessus du laboratoire de virologie où se trouvaient les cages d'animaux d'expériences.
La voie de contamination la plus probable aurait été la voie aérienne par le conduit contenant les câbles téléphoniques d'un étage à l'autre.Cet épisode représente la dernière épidémie de variole dans le monde, et la mère de Janet Parker le dernier cas mondial connu de variole.Dès lors, il fut décidé en 1980 que tous les stocks connus de ce virus seraient détruits ou transférés à l'un des deux laboratoires habilités par l'OMS, l'un à Atlanta (les CDC - Center for Disease Control, ou Centres pour le contrôle et la prévention des maladies - aux États-Unis), l'autre à Moscou (Institut de recherches virologiques en URSS), tous deux de haute sécurité.
Ce dernier a été transféré en 1982 au Centre national de recherche en virologie et biotechnologie (Vector) de Koltsovo, en URSS.En 1986, l'OMS recommanda finalement la destruction totale de tous les stocks de ces virus pour la date du 30 décembre 1993.
Mais après un premier ajournement au 30 juin 1995, puis comme « dernier délai fixé par l'OMS » au 30 juin 1999, cette décision fut reportée jusqu'en 2002.
En effet, la décision de destruction totale ne faisait plus consensus lors de la 52e Assemblée mondiale de la santé en 1999, même si la destruction totale des stocks diminuait le risque d'un accident menant à une nouvelle éruption de la maladie.
Plusieurs États-membres, dont les États-Unis, arguèrent que ces virus pourraient se révéler utiles pour la recherche biomédicale (poursuite du séquençage du génome du virus de la variole) comme pour le développement de nouveaux vaccins, de médicaments antiviraux, etc.La désintégration de l'URSS, l'importance de sa recherche virologique militaire et le départ des scientifiques ex-soviétiques vers des pays abritant des groupes terroristes ont joué un rôle dans ces décisions de report.Au lendemain des attentats du 11 septembre 2001 et des attaques au bacille du charbon aux États-Unis en 2001, la question de l'usage possible de la variole en tant qu'arme biologique a pris de l'ampleur.
En 2003, la probabilité d'une action bioterroriste utilisant le virus de la variole a été qualifiée de mineure par le professeur François Bricaire.En 1999, un comité de l'OMS avait indiqué que les réserves de vaccins disponibles (évaluées mondialement à 90 millions de doses en 1998), étaient trop limitées et qu'il fallait relancer la production de vaccins.
Dès lors, les États-Unis et d'autres pays sous l'égide de l'OMS relancèrent la reconstitution de stocks et la recherche sur de nouveaux vaccins contre la variole.En France, le plan national de réponse à une menace de variole, institué par le décret no 2003-313 du 3 avril 2003, prévoit diverses mesures à prendre en cas d'attaque bioterroriste (plan Biotox).
Ces mesures sont graduées selon le niveau de menace et d'alerte, pouvant aller au maximum (épidémie échappant à tout contrôle, et en dernier recours) jusqu'à un dispositif de vaccination de l'ensemble de la population.
Un stock de vaccin est d'ores et déjà constitué.
Ce plan (dernière version en 2006) est en cours de révision, et en 2016, ces travaux sont couverts par le secret de la défense nationale.Pour l'OMS, la vaccination mise en œuvre pour combattre une flambée éventuelle doit se limiter aux personnes en contact étroit avec les malades et aux intervenants de première ligne.En 2016, le stock actuel détenu par l'OMS est de 2,4 millions de doses en Suisse, et 32 millions dans des pays donateurs.
À cela s'ajoutent les stocks nationaux, gérés par chaque pays, qui représentent 600 à 700 millions de doses à l'échelle mondiale, ce qui, selon l'OMS, est suffisant pour faire face à une épidémie.Ainsi, pour faire face à toute menace variolique (bioterrorisme, accident de laboratoire…), la recherche de moyens thérapeutiques continue.
La mise au point d'un nouveau vaccin est la principale voie empruntée.
Les antiviraux font également l'objet de recherche.
En 2010, un laboratoire a redécouvert une plante carnivore, Sarracenia purpurea L.
/oreille de cochon, ayant une activité anti-orthopoxvirus.Depuis la reconnaissance de l'éradication de la variole en 1980, en attendant qu'il y ait consensus scientifique mondial sur la disparition du risque sanitaire lié à une réapparition naturelle du virus (jugée de moins en moins plausible) ou à un usage illicite, la recherche se poursuivra sans doute encore après l'éventuelle « destruction des stocks existants de virus variolique » vivants.Elle est pluridisciplinaire et se fait dans des conditions très encadrées de « sûreté biologique » et de biosécurité sous l'égide de l'OMS, d'un comité consultatif OMS de la recherche sur le virus variolique » (ACVVR) et d'un groupe consultatif d’experts indépendants (AGIES), comprenant des représentants de tous les secteurs de la recherche et du développement dans le domaine des orthopoxvirus (OPV), supposés indépendants (ayant rempli et signé une déclaration d'intérêts et issus d'un domaine autre que la recherche variolique ») et agréés par le comité précédent et l'OMS.En 2010, L’AGIES a conclu qu'au vu des données disponibles et des progrès techniques, « les virus varioliques vivants ne sont pas nécessaires à la poursuite du développement des tests de diagnostic ni à leur validation sur le plan technique », mais qu'il faut par d'autres moyens « poursuivre les tentatives en vue de mettre au point des vaccins qui soient plus sûrs et au moins aussi efficaces que les vaccins originaux et/ou les vaccins antivarioliques actuellement homologués » (page 9/44 du rapport AGIES2010).En 2014, l'Assemblée mondiale de la santé a demandé à des groupes d'experts d'analyser les conséquences des derniers progrès réalisés en biologie de synthèse.
La conclusion est que le risque de réémergence de la variole a globalement augmenté depuis le début des années 2000.
La synthèse de virus variolique est devenue « plus aisée et moins coûteuse, susceptible d'être réalisée par des laboratoires de petite taille dont les conditions de sûreté et de sécurité biologiques sont insuffisantes ».En 2016, la situation de la recherche sur la variole et les contre-mesures médicales est la suivante :Selon l'OMS, il convient de se préparer, mondialement et nationalement, à un évènement variolique de toute nature (réémergence naturelle, accident de laboratoire, bioterrorisme).
Les mesures de santé publique prévues étant applicables de manière générale à tous les autres agents pathogènes dangereux.
« Un niveau de préparation mondiale élevée contre les maladies infectieuses émergentes représente un investissement indispensable pour tous les États membres ».Durant le siège de Fort Pitt, au cours des guerres intercoloniales (1754–1763), les Britanniques se proposèrent d’utiliser la variole contre leurs adversaires indiens.
S’il n’est pas établi que ce dessein fut avalisé officiellement, un certain William Trent, négociant local, écrivit le 24 juin 1763 qu’« en signe d’égard pour eux (= les émissaires des assaillants indiens), nous leur donnâmes deux couvertures et un mouchoir provenant d’un hôpital de varioleux.
J’espère que cela aura l’effet désiré,, ».
Les historiens ne s’accordent pas sur le point de savoir si cette tentative de disséminer la maladie réussit.
Jeffery Amherst aurait également évoqué cette forme d'empoisonnement collectif, contre les Lenapes.
Il a également été affirmé que la variole fut utilisée comme arme pendant la Guerre d'indépendance des États-Unis (1775–1783),.Selon une théorie exposée dans Journal of Australian Studies (JAS) par un chercheur indépendant, des troupes d’infanterie de marine britanniques utilisèrent en 1789 la variole contre des tribus aborigènes en Nouvelle-Galles du Sud ; ce même évènement avait déjà été évoqué dans Bulletin of the History of Medicine, puis par David Day dans son ouvrage Claiming a Continent.
Dès avant l’article du JAS, cette théorie avait du reste déjà fait l’objet de discussions entre certains universitaires.
Le professeur Jack Carmody objecta qu’il est plus probable que l’épidémie en question ait été provoquée par la varicelle qui, à cette époque, était parfois identifiée comme une forme bénigne de variole.
Cependant, si l’on avait tout d’abord souligné qu’il n’y eut aucun cas signalé de variole parmi les colons lors du voyage de huit mois de la « Première flotte », ni au cours des quatorze mois suivants, et qu’il est improbable, compte tenu que la période d'incubation de la variole est de 10 à 12 jours, que des germes de la maladie aient été emportés par ladite Première flotte, l’on sait aujourd’hui en revanche que des flacons de virus variolique détenus par les médecins de la Première flotte furent la source probable, et qu’il y eut bien, en réalité, un cas signalé de variole chez les colons, chez un matelot nommé Jefferies.Pendant la Seconde Guerre mondiale, des scientifiques du Royaume-Uni, des États-Unis et du Japon (plus précisément l’Unité 731 de l’armée impériale japonaise) menèrent des recherches visant à produire une arme biologique à base de variole.
Toutefois, la production à grande échelle ne fut jamais décidée car la disponibilité universelle d’un vaccin rendait l’arme peu efficace.En 1947, l’Union soviétique érigea une usine de fabrication d’armements à base de variole dans la ville de Zagorsk, à 75 km au nord-est de Moscou.
En 1971 éclata une épidémie de variole dont le virus responsable provenait d’armes biologiques en phase d’essai dans une installation sur une île de la mer d'Aral.
Le général et professeur Peter Burgasov, ancien médecin militaire en chef dans l’armée soviétique et cadre supérieur du programme soviétique d’armements biologiques, décrivit ainsi l’incident :D’autres auteurs inclinent cependant à penser que la première patiente contracta la maladie lorsqu’elle visita Uyaly ou Komsomolsk, dans l’Oust-Ourt, le bateau ayant fait escale dans ces deux villes côtières,.En 1991, cédant aux pressions internationales, le gouvernement soviétique autorisa une équipe conjointe d’inspecteurs américains et britanniques à effectuer une tournée d’inspection dans quatre des principaux sites de Biopreparat.
Les inspecteurs furent confrontés à des réponses évasives et à des dénégations de la part des scientifiques soviétiques, pour s’entendre finalement donner l’ordre de quitter l’installation.
En 1992, le défecteur soviétique Ken Alibek affirma que le programme soviétique d’armements biologiques à Zagorsk avait produit un vaste stock — quelque vingt tonnes — de variole à usage militaire (utilisant peut-être un virus génétiquement manipulé capable de résister aux vaccins, selon ce qu’ajouta Alibek), en même temps que des ogives réfrigérées pour diriger le produit vers sa cible.
Toutefois, les assertions d’Alibek sur les activités autour de la variole menées dans le cadre de l’ancien projet soviétique n’ont jamais pu être vérifiées de façon indépendante.En 1997, le gouvernement russe annonça que tous ses échantillons de variole restants allaient être transférés à l’institut Vector à Koltsovo.
Après l’effondrement de l'Union soviétique et la mise au chômage de nombreux scientifiques naguère actifs dans les programmes d’armement, des représentants du gouvernement américain se dirent préoccupés à l'idée que le virus de la variole et le savoir-faire permettant de le conditionner à un usage militaire puissent tomber entre les mains d’autres gouvernements ou de groupes terroristes désireux d’utiliser des virus comme agents de guerre biologique.
Les allégations spécifiques faites à l’encontre de l’Irak à cet égard se sont toutefois révélées fausses.En juin 2015, les experts de l'AGIES (Advisory Group of Independant Experts), ou Groupe consultatif indépendant de l'OMS sur la recherche variolique, ont exprimé leurs préoccupations sur les progrès réalisés en biologie de synthèse permettant à des laboratoires de petite taille de manipuler le virus, voire de le recréer à partir de génomes numérisés (informations sur les séquences de l'ADN viral dans les banques de données).
En effet, l’insertion, dans des orthopoxvirus existants, d’ADN variolique synthétique pourrait permettre de reconstituer le virus, ce qui augmente les risques d'accident de laboratoire et d'utilisation à des fins bioterroristes ou militaires.
La première étape dans la réduction de ce risque devrait, selon certains, consister à détruire les stocks de virus restants, de sorte que toute détention ultérieure du virus puisse être criminalisée sans ambiguïté.La mise en circulation délibérée d'un aérosol de virus variolique entraînerait une vaste dissémination compte tenu de la grande stabilité du virus dans l'environnement et de sa faible dose infectieuse.
La survie du virus dans le milieu extérieur est inversement proportionnelle à la température et à l'humidité (favorisée par le froid et le sec).
Selon ces conditions, le virus resterait viable de 6 heures (en été humide) à un peu plus de 24 heures (hiver sec).En France, le Haut Conseil de la santé publique estime que la mortalité induite serait de 30 à 50 % chez les malades non vaccinés.
Le risque de développer la maladie chez les sujets contacts serait de 95 % chez les non-vaccinés, de 12 % chez les anciens vaccinés (plus de 10 ans), et de 4 % chez ceux à jour de leur vaccination.
En 2012, il existait une absence totale d'immunité chez les moins de 35 ans, les rendant plus sensibles à la variole, mais aussi aux complications des vaccins de première génération.L'importance de la variole se traduit par l'existence de nombreux cultes visant à s'en protéger.En Europe médiévale, le saint protecteur de la variole est saint Nicaise, évêque de Reims, guéri de la variole mais décapité par les Huns en 452.En Inde, la déesse de la variole est Shitala Devi.
Divinité populaire ancienne, son association avec la variole serait plus récente (XVIIIe siècle).
Elle est représentée dans de nombreux temples et lieux de pèlerinage dans toute l'Inde.
Ce rôle est amené à évoluer avec l'éradication de la variole.
En Inde du sud, chez les Tamouls, la divinité de la variole est Mariamman.En Chine, la sainte de la variole est T'ou-Shen Niang-Niang, une religieuse bouddhiste qui aurait introduit la variolisation en Chine au XIe siècle.
Au XIXe siècle, son culte est des plus populaires, car suivi par les chinois quelle que soit leur religion (temples dédiés dans toute la Chine).Au Japon, l'archer héros Tametomo du XIIe siècle est réputé pour avoir terrassé le démon de la variole.
Son effigie peinte en rouge (couleur associée à la variole et supposée faciliter la guérison) était accrochée dans les salles de malades atteints de la variole.En Afrique, Sakpata (nombreuses variantes, comme « Sopona ») est le dieu de la variole parmi les Yorubas (Royaume d'Oyo, royaume du Dahomey...) et leurs proches voisins du Nigeria, Togo et Bénin.
Au XVIIIe siècle, le culte de Sakpata est assuré par des « féticheurs » qui proposent aussi pèlerinage et variolisation.
Ce culte est transmis au Brésil par le commerce des esclaves (de langue ou population yoruba), le dieu changeant de nom pour devenir Omolu ou Obaluaye.Plusieurs personnages historiques ont contracté la variole (voir catégorie « mort de la variole ») :On pense que le pharaon Ramsès V (-1150 à -1145) en serait mort, car des lésions cutanées évocatrices sont présentes sur le visage de sa momie ; de même les empereurs chinois Kangxi (1654-1722), Shunzhi (1638-1661) et peut-être Tongzhi (1856-1875) ; le daimyo (seigneur) japonais Date Masamune (1567-1636), qui perdit un œil à la suite de la maladie.
Guru Har Krishan, 8e gourou des sikhs en 1664 ; le maharajah Ranjît Singh, « Lion du Pendjab », qui en perdit la vision de l’œil gauche.
Cuitláhuac, dixième tlatoani (souverain) aztèque est mort de la variole en 1520, peu après que celle-ci eut été introduite en Amérique.
L'empereur inca Huayna Capac en est mort de la variole en 1527.
Pierre II fut victime de la maladie le 30 janvier 1730 à l'âge de 14 ans.
Le prince-électeur Maximilien III Joseph de Bavière est mort de la variole en 1777.En Europe, les conséquences de la variole ont souvent changé l’ordre des successions dynastiques : Louis XV succède à son arrière-grand-père Louis XIV à la suite de la mort des premiers en la ligne de succession et il meurt lui-même de cette maladie en 1774.
Le seul fils survivant d'Henri VIII, Édouard VI, est probablement mort de complications peu de temps après avoir guéri de la maladie.
Ses successeurs immédiats furent des femmes.Guillaume III d'Angleterre perd sa mère de la maladie alors qu'il n'a que dix ans en 1660, et son oncle Charles devient son tuteur légal.
Son épouse et cousine Marie II meurt elle aussi de la variole en 1694.
Cela déclenche une chaîne d’évènements qui aboutit à l'éviction permanente de la lignée des Stuart du trône britannique.Mirabeau et Danton, ainsi que Mozart et Beethoven, ont contracté et survécu à la maladie étant enfants ; tous les quatre étaient porteurs de cicatrices visibles au visage.
Goethe en revanche, qui contracta la maladie dans la décennie 1750, n’en garda aucune séquelle, ce qu'il relata ainsi :Les deux présidents des États-Unis George Washington et Abraham Lincoln contractèrent la maladie et en guérirent.
Joseph Staline, qui fut durement marqué par la maladie tôt dans sa vie, a souvent fait retoucher des photos pour rendre ses cicatrices moins apparentes.Le criminel Lucky Luciano contracta la maladie en 1907 à l'âge de dix ans, avant d’émigrer à New York depuis la Sicile.
L’actrice indienne Geeta Bali est morte de la variole en 1965.
Le poète turc Âşık Veysel Şatıroğlu fut rendu aveugle par la variole à l'âge de sept ans.
Sehzade Mehmet, le fils de Soliman le Magnifique et de son épouse Hurrem sultan Roxelane, meurt de la variole en 1543 à l'âge de 21 ans.
La liste modèle de l'OMS des médicaments essentiels est publiée par l'Organisation mondiale de la santé (OMS) depuis 1977 et mise à jour au moins tous les deux ans (en anglais).
Depuis 2007, l'OMS publie également une liste distincte destinée aux enfants jusqu'à 12 ans.
Ces listes recensent les médicaments essentiels dont les systèmes de santé à travers le monde devraient permettre l'accès à l'ensemble de la population en vertu de la déclaration de Montréal sur le droit fondamental aux médicaments essentiels.
Il s'agit d'un modèle de liste destiné à être décliné localement par les autorités sanitaires des différents pays pour répondre à leurs besoins prioritaires en matière de santé publique.
Les médicaments retenus doivent être essentiels pour répondre à ces besoins prioritaires et doivent présenter des preuves suffisantes de leur innocuité, de leur efficacité, d'un rapport coût/efficacité acceptable et d'une disponibilité suffisante sur le marché.La liste ci-dessous reproduit l'édition OMS de mars 2011 (en français), mise à jour dans certains cas avec la liste OMS publiée en avril 2013 (en anglais).
Cette liste est introduite par les définitions et précisions suivantes :On trouvera à l'annexe 1 les principaux termes employés pour les formes galéniques dans la liste des médicaments essentiels.
L'OMS définit bon nombre de ces termes et les normes de qualité et d'assurance-qualité applicables aux différentes catégories,.Les médicaments indiqués dans le traitement de la lèpre ne doivent être administrés qu'en association.
Le traitement par une association thérapeutique est indispensable pour empêcher la survenue d'une pharmacorésistance.
On utilisera des plaquettes thermoformées (blister packs) chromocodées, contenant une association classique de deux médicaments (lèpre paucibacillaire) ou de trois médicaments (lèpre multibacillaire) destinée à l'adulte ou à l'enfant.
Ces plaquettes peuvent être obtenues gratuitement en s'adressant à l'OMS.En l'état actuel des connaissances et d'après l'expérience de leur utilisation, les médicaments entrant dans les trois classes d'antirétroviraux ci-dessous sont inscrits sur la liste des médicaments essentiels pour le traitement et la prévention de l'infection à VIH (prévention de la transmission mère-enfant et prophylaxie post-exposition).
Le Comité insiste sur l'importance d'utiliser ces produits conformément aux directives internationales et nationales.
Il recommande et approuve l'emploi d’associations fixes et le développement de nouvelles associations fixes appropriées, notamment de formes pharmaceutiques modifiées, de produits n'ayant pas besoin d'être réfrigérés et de formes pédiatriques de qualité pharmaceutique assurée.
Les comprimés sécables peuvent être utilisés chez l'enfant et on peut donc envisager de les inclure dans la liste des comprimés, pour autant que des produits de qualité suffisante soient disponibles.Le choix des inhibiteurs de protéase à partir de la liste modèle devra être établi par chacun des pays en tenant compte des directives thérapeutiques internationales et nationales et des données de l’expérience.
Le ritonavir est recommandé dans les associations en tant que potentialisateur pharmacologique et non comme antirétroviral à part entière.
Tous les autres inhibiteurs de protéase doivent être utilisés sous des formes renforcées (par exemple, avec du ritonavir).Les médicaments destinés au traitement du paludisme à P. falciparum doivent être utilisés en association.
La liste recommande actuellement les associations mentionnées dans les directives thérapeutiques.
Le Comité admet qu'il n'existe pas encore toutes les associations et encourage leur développement et leur essai rigoureux.
Il encourage également le développement et l'essai de formes destinées à la voie rectale.Le Comité OMS d'Experts reconnaît l'importance de faire figurer des médicaments spécifiques dans la section consacrée aux soins palliatifs.
Certains médicaments utilisés dans les soins palliatifs figurent dans la section de la liste modèle correspondant à leur usage thérapeutique, par exemple les analgésiques.
Les directives sur les soins palliatifs mentionnées dans la précédente édition de la liste doivent être mises à jour.
Le Comité prévoit que des demandes en vue de l'inscription des médicaments nécessaires pour les soins palliatifs lui seront présentées pour la prochaine réunion.Toutes les fractions plasmatiques doivent satisfaire aux normes de l'OMS relatives à la collecte, au traitement et au contrôle de qualité du sang, de ses constituants et des dérivés du plasma (révision 1992).
(OMS, Série de Rapports techniques, no 840, 1994, annexe 2).Toutes les tuberculines doivent être conformes aux normes de l'OMS relatives aux tuberculines (révision 1985).
Comité OMS d’Experts de la Standardisation biologique, trente-sixième rapport (OMS, Série de Rapports techniques, no 745, 1987, annexe 1).Toutes les fractions plasmatiques doivent être conformes aux normes de l'OMS relatives à la collecte, au traitement et au contrôle de qualité du sang, de ses constituants et des dérivés du plasma (Révision 1992).
Comité OMS d'Experts de la Standardisation biologique, quarante-troisième rapport (OMS, Série de Rapports techniques, no 840, 1994, annexe 2).Le choix des vaccins à partir de la liste modèle devra être établi par chaque pays en tenant compte des recommandations internationales, des données épidémiologiques et des priorités nationales.
La liste ci-dessous indique les vaccins pour lesquels il existe une recommandation du Strategic Advisory Group of Experts on Immunization (SAGE) et/ou une note de synthèse de l'OMS.
Ce site est mis à jour à mesure de la publication de nouvelles notes de synthèse et contient les informations et recommandations les plus récentes.Tous les vaccins doivent être conformes aux normes de l'OMS pour les substances biologiques.Le Comité d'Experts a demandé l'examen de cette section lors de sa prochaine réunion.Cette section sera réexaminée lors de la prochaine réunion du Comité d'Experts.
Les lymphocytes T à mémoire font partie des lymphocytes T jouant un rôle dans la réponse immunitaire secondaire contre un antigène déjà rencontré.
Cette réponse est caractérisée par sa rapidité et son efficacité.Lors de la première rencontre entre un lymphocyte T et son antigène, on observe une réponse primaire, c'est-à-dire l’activation et la multiplication des cellules spécifiques de cet antigène.
Ces lymphocytes « naïfs » se différencient en lymphocytes « effecteurs », capables de sécréter des cytokines, des substances cytotoxiques, etc. nécessaires à la destruction de l'antigène (en général un agent pathogène), ou en lymphocytes auxiliaires.
Une fois l'antigène éliminé, la plupart des lymphocytes T, devenus inutiles, meurent par apoptose.
Une petite partie, environ 5 %, restent.
Ils correspondent aux lymphocytes T à mémoire.
Le pourcentage de lymphocytes à mémoire représente cependant une population supérieure en nombre à la population initiale des lymphocytes T naïfs.Les lymphocytes T à mémoire sont capables de réagir plus rapidement, plus efficacement, et plus vigoureusement que les lymphocytes T naïfs lors d’une rencontre ultérieure avec le même pathogène.
C’est la réponse secondaire.Il existe deux types de lymphocytes T à mémoire :Cette localisation dans différents tissus, au plus près du site d'entrée de l'antigène, favorise une rencontre ultérieure avec l’antigène et les lymphocytes T à mémoire.
Les Lymphocytes T à mémoire se localisent préférentiellement vers les tissus où s'est produite la première infection.En l’absence de stimulation antigénique, la population de TEM évolue lentement en TCM.Les lymphocytes T à mémoire sont des cellules à longue durée de vie.
Elles sont sensibles à l’interleukine 7 qui augmente leur résistance à l’apoptose et à l’interleukine 15 qui engendre une prolifération suffisante permettant de compenser les cellules qui meurent,.
Les cellules à mémoire ont des propriétés particulières qui leur permettent d’être plus réactives face à l’antigène que des cellules naïves, grâce notamment à l’expression de très nombreuses molécules qui sont absentes ou très faiblement exprimées à la surface des lymphocytes T naïfs.
Certaines de ces molécules sont impliquées dans les interactions avec les autres cellules, qu’elles fassent partie du système immunitaire ou non : par exemple, les molécules d’adhésion, les récepteurs de facteurs de croissance, de chimiokines ou de cytokines.
Ceci permet aux lymphocytes T à mémoire d’établir des interactions différentes avec leur environnement,.Les lymphocytes à mémoire ont des propriétés différentes de celles des cellules naïves, ce qui explique l’expansion très importante et la rapidité d’action des cellules à mémoire pendant les réponses secondaires.
Leur capacité de division est supérieure, elles se divisent plus tôt et plus rapidement à la suite d'un contact avec l’antigène.Les lymphocytes T à mémoire se différencient beaucoup plus rapidement que les lymphocytes naïfs en T effecteurs à la suite de la restimulation par l'antigène.
Ils produisent alors une quantité importante de facteurs cytotoxiques, de cytokines, etc..Une cellule à mémoire a la capacité d’exprimer simultanément et de manière plus forte deux ou trois fonctions effectrices, comparée à une cellule naïve qui exprime une fonction effectrice unique.
Un lymphocyte à mémoire équivaut donc à deux ou trois cellules naïves différentes.Les lymphocytes T à mémoire gardent leurs propriétés particulières, même longtemps après le contact primaire : il semblerait que ces cellules à mémoire n’aient pas besoin de contacts réguliers avec l’antigène pour leur persistance dans l'organisme.
Cependant, ils ont un besoin impératif d’un contact avec le complexe majeur d’histocompatibilité de l'organisme pour recevoir des signaux de survie.La vaccination consiste à introduire dans l’organisme un agent (virus, bactérie ou molécule) qui va sensibiliser le système immunitaire – ou l’immuniser – sans être pathogène.L’efficacité du procédé repose sur l’induction d’une réponse immunitaire mémoire protectrice (lymphocytes T à mémoire).
La compréhension de la différenciation et du maintien des lymphocytes T à mémoire représente un enjeu important pour la mise au point de nouveaux vaccins.En effet, les lymphocytes T à mémoire qui ne sont en compétition avec aucun autre lymphocyte T survivent à long terme.
Cette vaccination ne nécessite donc pas de rappel.En revanche, certains lymphocytes T à mémoire peuvent entrer en compétition, ce qui entraîne une diminution de taux de cellules à mémoire.
De ce fait, ce phénomène induit la nécessité de rappels.Depuis 1999, il a été démontré que les cellules T à mémoire spécifiques de certains antigènes sont capables de se maintenir en nombre relativement constant, même longtemps après la réponse primaire engendrée par un antigène et en situation de compétition.Encore peu connu, ce phénomène représente, à ce jour, la théorie la plus plausible pour expliquer que certains vaccins ne nécessitent pas de rappels.
Un excipient désigne toute substance autre que le principe actif dans un médicament, un cosmétique ou un aliment.
Son addition est destinée à conférer une consistance donnée, ou d'autres caractéristiques physiques ou gustatives particulières, au produit final, tout en évitant toute interaction, particulièrement chimique, avec le principe actif.Un excipient n'est donc pas défini par une composition chimique particulière mais par son utilisation, qui découle de ses propriétés physico-chimiques qui le rendent aptes à remplir son rôle d'excipient.Le médicament est constitué d'une (ou plusieurs) substances actives et de substances associées (les excipients) qui vont lui conférer des qualités de stabilité, forme, dissolution, ciblage, goût, couleur, esthétique, et caetera.Ces substances identifiées dans les formules dans leur ordre pondéral sont extrêmement variées.Les excipients participent pleinement au mode d'action du médicament et surtout à son processus de fabrication.
L'art de la mise en forme médicamenteuse, c'est la pharmacie galénique.
Les excipients sont donc des substances associées étroitement aux substances actives des médicaments qui :Leur insertion dans les médicaments répond donc la plupart du temps à des considérations médicamenteuses proprement dites.L'excipient est le vecteur ou véhicule du principe actif.
Il permet au principe actif de parvenir là où il est censé agir.
L'excipient n’interfère donc pas avec le principe actif.
Les excipients possèdent parfois certaines propriétés cosmétologiques et peuvent alors jouer le rôle de substance active.
L'excipient est toujours bien plus important en volume que les principes actifs.
De plus, c'est lui qui définit la galénique du produit c’est-à-dire sa consistance (crème, gel…) et son aspect.
Les excipients les plus utilisés sont les huiles, l'eau et l'alcool.
Par exemple, l'amande douce, l'avocat ou le beurre de karité sont des excipients d'origine végétale.
Les silicones sont un exemple d'excipient d'origine synthétique.Les excipients jouent dans les aliments le même rôle que dans les médicaments, mais leur insertion obéit plus souvent à des considérations davantage commerciales, en participant à l'attrait du produit : aspect, goût, prix au kilogramme, etc.
Selon Christophe Brusset, leur utilisation est très fréquente, notamment pour les épices moulues.
Certains, comme les gousses de vanille épuisées à l'hexane dans la crème glacée, servent de « marqueur visuel », c'est-à-dire donnent l'impression d'un produit artisanal ou authentique.Il joue aussi un rôle important dans les arômes alimentaires.
La maltodextrine étant l'excipient le plus utilisé dans les arômes en poudre.
Ce sont l'éthanol et le propylène glycol dans les  arômes liquides.
La toux de chenil, également appelée trachéobronchite infectieuse ou trachéobronchite contagieuse, est une maladie canine extrêmement contagieuse caractérisée par une inflammation de la partie supérieure de l'appareil respiratoire ayant des répercussions sur l'état général.
Elle peut être causée par une variété de virus et de bactéries, isolés ou associés.
Affectant parfois des chiens isolés, elle est le plus fréquemment observée en élevage — d'où son nom vernaculaire — où elle peut causer des dégâts considérables.La contagion intervient par voie aérienne, à partir des aérosols produits par les chiens toussant ou éternuant.
La contagion peut également avoir lieu à partir de surfaces contaminées ou à partir d'un contact direct avec un animal malade.
L'affection est très contagieuse, même des jours ou des semaines après que les symptômes ont disparu.Les symptômes apparaissent généralement de trois à cinq jours après la contagion.
En élevage, les chiens de tous âges présentent une toux sèche, rauque et douloureuse, que l'on peut déclencher aisément en palpant simplement la trachée.
L'irritation des voies aériennes supérieures provoque des quintes de toux sèche, des nausées, des éternuements, des reniflements ou des vomissements.
L'appétit est le plus souvent conservé.
La fièvre peut être présente ou non.
La maladie évolue sur trois à six semaines, avec des séquelles de toux qui peuvent persister longtemps après.Dans un chenil touché par la maladie, la mortalité (le plus souvent par complications de pneumonie), peut atteindre 20 % des animaux affectés.
La maladie dure environ vingt jours mais une rechute peut avoir lieu si l'animal est mis en situation de stress qui affaiblit son système immunitaire.Parmi les agents responsables figurent des virus, comme le parainfluenza virus SV5, les adénovirus CAV1 (responsable de l'hépatite de Rubarth) et CAV2, des herpésvirus et des réovirus, ainsi que des bactéries, comme Bordetella bronchiseptica ou Pseudomonas aeruginosa,.Les éléments cliniques peuvent être confortés par des examens de laboratoire : sérologie, PCR, virologie ou bactériologie.Les antibiotiques sont administrés, de préférence en aérosolthérapie, pour traiter la composante bactérienne de l'infection.
Ils peuvent être accompagnés par des antitussifs si la toux n'est pas productive.La prévention passe par la vaccination (DA2PPC (en)).
Les vaccins actuels contiennent la valence parainfluenza atténuée, associée à celle de la maladie de Carré, à l'adénovirus CAV2, à Bordetella et au parvovirus canin.Dans les chenils, la meilleure prévention réside dans l'hygiène des locaux, une bonne aération, la maîtrise de la température et de l'hygrométrie, le respect de la quarantaine et des programmes vaccinaux.
La blennorragie, ou gonorrhée,, (aussi appelée familièrement chaude-pisse,, chaude-lance, castapiane, ou chtouille) est une infection sexuellement transmissible.Cette infection touche principalement les organes génitaux et urinaires.
Elle est due au gonocoque (Neisseria gonorrhoeae, découvert par Albert Neisser en 1879 dans un pus d’urétrite aiguë et isolé en 1885 par Bumm).
Elle fait partie des gonococcies qui font l'objet d'un suivi par le Programme mondial de surveillance des antimicrobiens gonococciques (GASP) et a été considérée le 7 juillet 2017 par l'OMS comme « menace sanitaire émergente » nécessitant une collaboration internationale urgente.Des douleurs dans les organes génitaux, le rectum, l'anus ou la gorge sont possibles.
Les complications touchent principalement les femmes (inflammations pelviennes, grossesse extra-utérine et stérilité, voire risque d'infection du cerveau ou du cœur sans traitement) alors que 75 % des cas féminins sont asymptomatiques et passent donc inaperçus.
Chez l’homme la maladie est plus visible et les complications sont généralement la prostatite ou l'épididymite.
La période d’incubation est habituellement de 2 à 7 jours.
Une gonorrhée génitale peut secondairement faciliter la transmission du VIH.Un des moyens de prévention primaire est le préservatif.
Le traitement curatif est l'antibiothérapie, mais les souches antibiorésistantes sont de plus en plus fréquentes, y compris face aux céphalosporines (médicaments de dernier recours, dits « de troisième génération »).
L'OMS a confirmé de 2014 à 2017 en Afrique du Sud, en Australie, en Autriche, au Canada, en France, au Japon, en Norvège, au Royaume-Uni, en Slovénie et en Suède des souches résistantes.
En 2003, l'OMS recommandait les quinolones (la ciprofloxacine notamment) comme traitement mais 3 ans plus tard (en 2006) recommandait leur abandon ne laissant que les céphalosporines comme antibiotique (dont la ceftriaxone ; mais en 2016 « quarante-six pays ont déjà signalé des souches de gonorrhée moins sensibles à la ceftriaxone, et 10 pays ont signalé des cas résistants à tous les antibiotiques habituellement efficaces ».
Les thérapies associant plusieurs antibiotiques sont possibles mais très délicates à mettre en œuvre en attendant de nouveaux médicaments espérés pour 2020.La gonorrhée, déjà évoquée par l'Ancien Testament (Bible) a été en France décrite il y a au moins 700 ans comme présente dans les quartiers des « bordeaux » ou « clapiers » (bordels) de Paris, regroupant des maisons de prostitution mais elle a durant des siècles été confondue avec la syphilis, avant d'en être différenciée par Jean-François Hernandez (1812), Humpston (1822) , puis surtout par Ricord (1838).Elle est devenue moins préoccupante pour la santé publique des années 1920 aux années 1980 (où les médecins disposaient de plusieurs antibiotiques efficaces), mais des résistances (aux sulfamides) sont signalées dès les années 1940, faisant à nouveau progresser la maladie notamment dans les populations pauvres (y compris aux Etats-Unis dans les populations pauvres et rurales par exemple).
La maladie redevient au début du XXIe siècle un problème grave de santé publique.En 2017, elle figure en tête de la liste des microorganismes pour lesquels l’OMS et l’initiative de l’ONG « Médicaments pour les maladies négligées » (DNDi ; Drugs for Neglected Diseases initiative) cherchent à inventer et développer de nouveaux médicaments efficaces et de meilleures techniques de prévention (peut-être à un coût moindre que par les moyens classiques de l'industrie pharmaceutique).Dans la nature, c'est une des rares maladies infectieuses qui ne semble pas zoonotique (c'est-à-dire qu'elle ne touche que l'humain).La bactérie N. gonorrhoeae utilise les molécules de porine (Por) de sa membrane externe pour se lier à une protéine humaine C4b (C4bp), ce qui lui permet de se soustraire au système immunitaire humain.Des souches de N. gonorrhoeae résistant aux globules blancs du sérum humain sont rapidement attaquées et tuées par des sérums provenant de rongeurs, lagomorphes et de primates (qui eux ne peuvent que difficilement  être expérimentalement infectés par cette bactérie, car elle ne peut pas chez eux se lier à la protéine C4bp), ce qui complexifie la recherche quand elle passe par l'expérimentation animale par exemple pour la recherche de vaccin.Le taux de gonorrhée augmente dans le monde.
Et il est nettement plus élevé chez les hommes ayant des rapports sexuels avec d'autres hommes (HSH) que chez les hétérosexuels stricts.On sait depuis peu que la gonorrhée chez les HSH ne se transmet pas comme on le pensait auparavant.
Il a été montré dans cette population que les sites d'infection asymptomatiques (pharynx et oropharynx) jouent un rôle majeur dans la persistance de la gonorrhée dans la population générale.
Chez de nombreuses personnes symptomatiques, la salive, souvent utilisée comme lubrifiant lors des actes sexuels ou masturbatoires, contient généralement la bactérie responsable de la gonorrhée, alors potentiellement source d'infection ou de réinsertion.
In vitro, et in vivo le bain de bouche antibactérien s'est montré capable de réduire la gonorrhée de l'oropharynx (généralement asymptomatique), et un modèle mathématique récemment publié laisse aussi penser que des bains de bouches efficaces permettraient de considérablement diminuer la prévalence de cette maladie chez les homosexuels ou bisexuels, mais « plus de recherche est nécessaire avant que ceci puisse être recommandé, même si cette suggestion s'est avérée efficace dans un essai clinique » (des bains de bouche trop fréquents pourraient aussi conduire à l'apparition de souches résistantes aux antibiotiques qu'ils contiennent, ou affecter la flore intestinale).Tous les pays sont touchés, et le nombre de nouveaux cas augmente à nouveau dans le monde (source 2018) après une phase de diminution (il était passé de 106 millions environ en 2008 à au moins 78 millions en 2015-2017.
Cette maladie est en outre sous-déclarée car souvent asymptomatique (principalement chez les femmes).Dans quelques pays dont en France, la gonococcie a reculé pour des raisons encore mal comprises ; en partie sans doute grâce aux précautions prises à la suite de l'épidémie de SIDA et grâce à un déclin qui s’était amorcé avant que le SIDA ne fût médiatisé, peut être aussi grâce à l’incitation dans les pays riches (tels que le Royaume-Uni ou le Canada) à une utilisation mieux ciblée des antibiotiques afin de limiter le risque de résistance.
Toutefois, le recul de l'utilisation du préservatif et le tourisme sexuel  seraient encore un obstacle important à l’éradication de cette maladie en France.Comme pour la syphilis ce sont les jeunes et adolescents (ex : Au Québec en 1980 environ 50 % des cas déclarés de syphilis et de gonorrhée l'étaient chez des jeunes de 15 à 19 ans) et en particulier les femmes de 16 à 24 ans et les hommes de 21 à 30 ans.Le risque de contracter cette maladie est plus élevé en cas de :Le nouveau-né est parfois contaminé par la mère au moment de l'accouchement.
Plus tard l'enfant ou l'adolescent peut aussi être infecté en cas d'inceste, de viol ou de certains abus sexuel sur mineur ou à l'occasion de jeux sexuels et de la découverte de la sexualité (en 1980, la moitié des cas de gonorrhée déclarés au Québec l'étaient chez des 15-19 ans).Elle passe par une meilleure connaissance des risques (éducation sexuelle et médicale) et une mise en pratique plus générale des seules précautions adéquates (port du préservatif, safer sex, utilisation de lubrifiants intimes sûrs et non de la salive).L'OMS appelle aussi à un effort international visant à améliorer le diagnostic précoce (développement d'examens précis, rapides et idéalement capables de prédire la sensibilité de la souche à tel ou tel antimicrobien).
Le diagnostic doit être suivi de soins appropriés et d'une information des partenaires sexuels.L'OMS souhaite aussi une surveillance accrue des évolutions des stratégies de résistance du microbe via un suivi mieux partagé des échecs de traitements.Il se fait par test d'urine, ou par prélèvement de la région infectée à l'aide d'un tampon d'ouate (au niveau du méat de l'urètre chez l'homme et du col de l'utérus chez la femme, et au niveau du rectum et du pharynx pour les deux sexes)Les premiers signes d'alerte sont, chez l'homme:Les manifestations d'une infection à Neisseria gonorrhoeae peuvent se révéler sous la forme de :Séquelles possibles chez l'homme :Les risques de complication sont plus importants pour la femme.
Cette infection, si elle n'est pas traitée, se complique parfois de cystite chronique et surtout de rétrécissement urétral.Les manifestations d'une infection à Neisseria gonorrhoeae peuvent se révéler sous la forme de :Séquelle possibles chez la femme :Sans traitement, les risques d'évolution vers une stérilité irréversible sont très importants, chez les deux sexes.Parfois (moins de 3 à 4 % des cas d'infections génitales) les gonocoques diffusent.
Ils peuvent alors se localiser :Le traitement consiste en la prise d'antibiotiques.
Malgré divers dépôts de brevets et plusieurs décennies de recherches sur le sujet,,,,, il n'existe encore en 2018 aucun vaccin contre cette maladie.L'évolution de la résistance aux antibiotiques du germe a modifié sa prise en charge suivant l'époque : de la sulfonamide à la fin des années 1930, on est passé à la pénicilline à doses croissantes, cette dernière n'étant plus utilisée à partir des années 1980.
Les fluoroquinolones et les céphalosporines ont pris alors le relais, avec l'apparition de résistances dès les années 1990.
Cette évolution pose un réel problème de santé publique d'autant que certaines souches peuvent être résistantes à plusieurs antibiotiques à la fois.
La proportion de ces dernières varie de façon importante suivant les pays.
La résistance aux Quinolones s'est largement répandue.Tous les patients traités pour une gonococcie devraient également être traités pour une chlamydiose, cette infection étant très fréquemment associée.Dans les cas de blennorragie les moins sévères, un « traitement minute » (une seule prise d'antibiotique, orale ou injectable, traitement développé dans les années 1960) suffit en général.
Si le stade de l'infection est plus sévère, le traitement peut s'étendre de 5 à 15 jours.Un traitement sous observation directe de la prise d’une seule dose est souhaitable pour garantir l’observance.Tous les partenaires qui ont eu des relations sexuelles avec le malade au moins dans les 60 jours précédant l’apparition des symptômes, ainsi que les parents de nouveau-nés infectés doivent subir le même traitement que le cas index.
Les personnes traitées pour une infection gonococcique devraient également être traitées pour une chlamydiose.Toujours associer un traitement pour Chlamydia trachomatis :Pour cause d'allergie au traitement de choix, il y a ces possibilités :Depuis la fin des années 1980, la maladie devient plus difficile à soigner.Mi 2017, un article paru dans Nature rappelle que la gonorrhée devient aussi incurable qu’au début du XXe siècle, avant l’apparition des premiers antibiotiques capables de la traiter.Mi-2017, plus de 60 % des pays ont déclaré à l’OMS des souches de gonorrhées fortement antibio-résistantes, y compris aux médicaments de derniers recours (OMS) et surtout aux médicaments les plus anciens et les moins coûteux.Début 2017 97 % des pays ont déclaré des cas résistant à la ciprofloxacine (le traitement le moins cher et le plus disponible) ; 81 % ont rapporté des cas de gonorrhée résistant à l'azithromycine ; Et 66 % aux céphalosporines.
L’évolution des pratiques sexuelles (diminution de l’usage du préservatif notamment) la croissance de l’urbanisation et des déplacements associée à un faible taux de détection des infections et à un traitement parfois  inadéquat contribuent à cette augmentation.…Et d’éventuels nouveaux médicaments ne sont pas prêts (ex.
potentiel : phages (virus tueurs de bactéries), en partie à cause d’une pénurie de financement des investisseurs (la zoliflodacine, 1re molécule issue d’une nouvelle classe d'antibiotiques proposée par Entasis Therapeutics (entreprise de biotechnologie basée à Waltham, dans le Massachusetts) a donné de bons  résultats aux premiers tests et les essais de phase 2 ont lieu en 2018.
Un essai de phase III de zoliflodacine a été annoncé, devant impliquer à partir de novembre 2018 environ 650 personnes en Afrique du Sud, aux États-Unis et en Thaïlande notamment..
Si le médicament est approuvé par les organismes de réglementation, le fabricant (Entasis) a annoncé qu’il autoriserait une fabrication de génériques dans la plupart des pays à revenu faible ou intermédiaire, mais qu'il conservera l'exclusivité du traitement dans les pays à revenu élevé.Le DNDi dit qu'il payera les études de santé publique utiles pour éviter un mauvais usage de ce médicament (mais ces études pourraient ne pas suffire car la bactérie peut aussi contourner ce nouvel antibiotique ; l’économiste Ramanan Laxminarayan (qui dirige le « Center for Disease Dynamics, Economics and Policy » de Washington) suggère que ce nouvel antibiotique ne devrait être délivré qu’après un test rapide de résistance (de la souche en cause), uniquement aux porteurs et porteuses d’une gonorrhée résistant aux alternatives existantes.DNDi continue à chercher un test rapide de ce type, mais il n’existe pas encore.Le 7 juillet 2017, l'Organisation mondiale de la santé (OMS) lance à nouveau une mise en garde contre une résistance répandue aux anciens antibiotiques, se basant sur les données de 77 pays.Le séquençage génétique permet de mieux comprendre la génétique de cette bactérie et de certaines de ses protéinesLa maladie est évoquée dans de nombreux textes de littérature et parfois dans le cinéma :
Une substance active, principe actif ou ingrédient actif désigne une substance chimique qui entre dans la composition d'un médicament parce que ce composé bioactif a un effet thérapeutique ou préventif.
Par métonymie, le terme médicament peut être aussi utilisé pour désigner la substance active.
Cependant, une substance active, en soi, peut être bénéfique ou nocive.
La pharmacologie a pour objectif de sélectionner les substances actives bénéfiques et de déterminer les doses appropriées.
Le principe actif est généralement en très faible proportion par rapport aux excipients.
Ce peut être une substance pure dont on connaît la structure chimique et qui est obtenue par des méthodes de synthèse chimique ; dans ce cas, on la désigne aussi par le terme « molécule » quand on veut mettre en avant sa structure.
Cela peut aussi être un mélange de plusieurs substances chimiquement proches (par exemple des isomères) ou encore une substance définie par son mode d'obtention : sens original de principe actif, c'est-à-dire ce qui est actif dans un mélange.
Par exemple, l'acide salicylique est un principe actif extrait de l'écorce du saule blanc (Salix alba).L'alchimiste, astrologue et médecin suisse Paracelse découvre la notion de principe actif au cours du XVIe siècle.
Des recherches se font sur la morphologie des plantes pour expliquer leur activité thérapeutique.
On parle de la théorie des signatures.On utilise souvent le terme de molécule pour parler du principe actif d'un médicament.
Il ne faut pas confondre l'idée ancienne de principe actif, associée à celle de sa purification réalisée à partir de substances naturelles, avec celle, moderne, de molécule.
S'il existe encore des médicaments qui contiennent des principes actifs extraits de plantes, notamment, la plupart des produits pharmaceutiques modernes contiennent des substances actives dont on connaît bien la structure chimique, donc, de leur molécule.
Il existe par ailleurs de nombreux cas où les molécules utilisées dérivent du principe actif initial afin d'améliorer l'activité thérapeutique et de réduire la toxicité.
Par ailleurs, il faut souligner que de nombreux médicaments contiennent un mélange de molécules, de manière à atteindre l'effet thérapeutique désiré (dans certains cas, il s'agit d'une véritable synergie, où l'activité d'un mélange est supérieure à la somme de l'activité des molécules constituant le mélange).De nombreuses substances ont une activité pharmacologique, parfois bénéfique.
Afin de tester leur activité et de mesure leur efficacité, on effectue des tests sur des cellules, des tissus ou des organes isolés, puis chez des animaux et, à la fin, chez l'homme dans le cadre d'études cliniques.
L'étape clinique est divisée en quatre phases.Une préparation pharmaceutique peut contenir plusieurs substances actives.
La substance active s'oppose aux ingrédients en principe « inertes » (pas d'activité pharmacologique recherchée), désignés par le mot « excipient ».
Pour un suppositoire, ce sera le beurre de cacao ou un triglycéride modifié pour avoir un point de fusion proche de 35 °C.
Pour une solution aqueuse, ce sera, à la base, de l'eau.
Les colorants et les autres additifs sont aussi des excipients.
Certains excipients ne sont cependant pas totalement inertes pour certaines personnes : présence de sel (ions Na+), de sucre, de composés potentiellement allergènes, etc.
On parle alors d'« excipient à effets notoires ».L'emploi du terme substance active a été étendu aux biocides et phytopharmaceutiques, mais aussi aux cosmétiques, voire au domaine alimentaire.
On parle aussi de xénobiotique, mais ce terme est plutôt employé sous un angle environnemental.
En soi, une substance active peut avoir des effets bénéfiques ou non : il existe un terme ancien qui correspond parfaitement à cette définition, c'est pharmacon.
Le terme principe actif connote plutôt le monde du médicament.Un principe actif peut avoir plusieurs codes ATC (anatomique, thérapeutique et chimique ; voir la classification ATC) si ceux-ci correspondent à des indications franches et reconnues.
Comme l'indication principale peut varier d'un pays à l'autre, l'ATC peut varier d'un pays à l'autre pour un même principe actif.
Par ailleurs, le nom des principes actifs médicamenteux fait l'objet d'une liste tenue et validée par l'Organisation mondiale de la santé (OMS) appelée dénomination commune internationale (DCI).Quelle que soit l'origine d'un principe actif, son obtention à l'échelle industrielle est une question de coût.
Il est possible d'obtenir certains composés par extraction d'une source naturelle renouvelable ou à partir de bactéries ou de cellules génétiquement modifiées.
En revanche, pour des molécules simples, la synthèse chimique est souvent la voie la plus efficace.
Entre les deux dernières solutions, il existe la voie de l'hémisynthèse : on extrait un précurseur du principe actif d'une source naturelle renouvelable, puis on le transforme chimiquement pour obtenir la molécule désirée.Les molécules simples sont, le plus souvent, synthétisées par une voie purement chimique.
Les limitations sont que la qualité des produits chimiques de départ doivent être de grade « pharmaceutique » et que certains réactifs sont interdits à cause des résidus qu'ils peuvent laisser dans le produit final.Un des plus célèbres exemples est la bataille juridique entre les États-Unis et la France sur les brevets concernant le paclitaxel (Taxol) et le docetaxel (Taxotère), tous deux issus de l'if (leur nom vient de la dénomination de l'if : Taxus baccata).
Le paclitaxel était alors extrait de l'écorce de l'if, ce qui signifiait la mort de l'arbre.
A contrario, le docetaxel est obtenu par hémisynthèse à partir d'un extrait des épines de l'if (donc l'arbre ne meurt pas).
Tous deux sont utilisés comme anticancéreux.Exemples :L'insuline est une protéine (ce qui empêche sa synthèse par une voie chimique à cause de sa trop grande complexité).
Le génie génétique a, en revanche, permis d'insérer le gène codant cette protéine dans l'ADN de bactérie.
En cultivant ces bactéries, elles produisent de l'insuline en grande quantité et il est possible de l'extraire et de la purifier pour l'injecter ensuite chez les personnes diabétiques.Dans les années 1980-1990, la France était indépendante dans la production des principes actifs, puis les entreprises ont progressivement externalisé la fabrication avant de la délocaliser.
C’est d’ailleurs ce qui a motivé la création d’Axyntis en 2007.
La crise de 2008-2009 a accentué le comportement des grands groupes, à la recherche de solutions pour améliorer leurs coûts de production.
Résultat : 80 % des médicaments vendus légalement en Europe et aux États-Unis sont désormais fabriqués à partir de principes actifs importés d’Inde et de Chine, contre 20 % à la fin du XXe siècle.
La pandémie du Covid-19 a fait prendre conscience de la forte dépendance de la France et de l'Europe vis-à-vis de l'Asie, ce qui pose un problème de souveraineté.
La fièvre jaune, anciennement appelée fièvre amarile, typhus amaril, ou vomito negro (vomi noir), est une zoonose due à un flavivirus, le virus de la fièvre jaune.
C'est une arbovirose des singes de la forêt équatoriale et elle est transmise de singe à singe par divers moustiques du genre Aedes.
Le moustique jouant le rôle de réservoir et de vecteur, le singe celui d'hôte amplificateur.L'homme traversant ces foyers sauvages d'endémie est sporadiquement piqué par les moustiques infectés et fait alors une fièvre jaune humaine dite forme sylvatique.
Revenu vers les centres habités, il joue le rôle de réservoir de virus et, piqué par le moustique commensal qu'est Aedes aegypti, hôte vicariant très efficace, il est à l'origine d'une fièvre jaune purement humaine et épidémique : la forme urbaine.La fièvre jaune est longtemps restée un obstacle à la colonisation de l'Amérique du Sud et de l'Afrique.
Elle demeure toujours une cause importante de maladies hémorragiques dans plusieurs pays africains et sud-américains, malgré l'existence d'un vaccin efficace.
Vers 2010, elle tuait environ 29 000 à 60 000 personnes par an dans les territoires d'Afrique et d'Amérique du Sud et elle est la maladie la plus sévère portée par les moustiques sous les tropiques.
Elle n'est pas éradicable, à cause de la présence d'un réservoir naturel permanent (moustiques-singes) en forêt tropicale.La phylogénétique des flavivirus indique que le virus de la fièvre jaune aurait divergé d'un flavivirus ancestral, il y a 1 500 à 3 000 ans en Afrique de l'Est.
Une nouvelle divergence se produit en Afrique de l'Ouest, 300 ans avant la découverte de l'Amérique, pour y être introduite, avec l'insecte vecteur, par le commerce des esclaves.Une ancienne hypothèse suggérant une origine américaine de la fièvre jaune américaine est restée longtemps minoritaire jusqu'aux années 1990.
Elle a été invalidée depuis par les études de génétique moléculaire.Les marins européens rencontrent la fièvre jaune au XVIe siècle aux îles Canaries, du Cap Vert, de Sao Tomé, et dans le golfe du Bénin.La première épidémie connue semble dater de 1648 et eut lieu au Yucatan, en étant mentionnée sous le terme de vomito negro (vomissements de sang - noir - ou hématémèse).
Le virus et son insecte vecteur auraient été introduits aux Amériques par le commerce des esclaves à partir de l'Afrique de l'Ouest.Depuis, de nombreuses épidémies ont été décrites.
Le terme de « fièvre jaune » est utilisé pour la première fois lors d'une épidémie à la Barbade en 1750.
Au XVIIIe siècle, la fièvre jaune est un obstacle lors de la colonisation en Amérique centrale et du Sud, et en Afrique de l'Ouest.
Elle frappe préférentiellement les européens nouveaux arrivants, en particulier les troupes militaires (arrivée massive de non-immunisés).
Au XIXe siècle, c'est l'une des raisons principales de l'échec français du percement du Canal de Panama (de 1881 à 1889, parmi les ouvriers, plus de 5 600 décès selon les Français, plus de 22 000 selon les Américains).La fièvre jaune est introduite de façon répétée dans les ports par les navires infestés de moustiques vecteurs jusqu'au début du XXe siècle.
Les épidémies les plus marquantes furent :En Europe, la première apparition de la fièvre jaune eut lieu à Lisbonne en 1723.
L'Espagne est régulièrement touchée durant les XVIIIe siècle et XIXe siècle (Cadix, Barcelone) ; la Grande-Bretagne à partir de 1777 (Falmouth, Southampton, Swansea) ;  la France en 1802 (Brest, Marseille) et en 1861 (Saint-Nazaire).
La dernière apparition de la fièvre jaune eut lieu à Saint-Nazaire en 1908 (11 cas dont 7 décès),.Des médecins français au début du XIXe siècle, et en particulier Pierre Lefort et Jean Guyon à la Martinique dès 1818, ou Nicolas-Pierre Gilbert et Antoine Dalmas à Saint-Domingue, cherchent l'origine de cette maladie, alors appelée « mal de Siam », dans la transmission aérienne de miasmes provenant d'eaux sales et usées, ou de matières organiques en décomposition, sans faire de liens direct avec les moustiques.L'hypothèse de la transmission par moustiques a été émise dès 1881 par Carlos Finlay, à Cuba.
Cette hypothèse est démontrée par Walter Reed en 1901 qui précise également le rôle du moustique Aedes aegypti, agent de transmission d'un virus filtrant.
Les campagnes d'éradication de ce vecteur en Amérique centrale (suppression des gîtes larvaires en zone urbaine)  permettent la quasi-disparition de la maladie dans ces zones (La Havane, Panama).Toutefois, dans les années 1920, les mêmes campagnes menées par la fondation Rockfeller échouent dans le nord du Brésil, ainsi que dans les pays partageant des portions de la grande forêt amazonienne, ce qui amène l'épidémiologiste Fred Soper (en) à découvrir, en 1933, l'existence d'une fièvre jaune forestière ou sylvatique.En 1925, la Fondation Rockefeller crée un centre d'étude sur la fièvre jaune à Lagos, Nigeria.
Le virus est isolé en 1927 par Adrian Stokes (1887-1927), la souche isolée est dite souche Asibi du nom du malade ghanéen originaire.
En établissant cette souche par passages sur des singes de laboratoire, Stockes contracte la maladie et en décède la même année.
L'Institut Pasteur de Dakar isole aussi une souche, la même année, dite souche française.Dans les années 1925-1930, la recherche se porte, entre autres, vers l'atténuation de ces deux souches pour l'obtention d'un vaccin vivant atténué.
Les accidents de contamination en laboratoire causeront 32 cas de fièvre jaune, dont 6 décès, parmi les chercheurs : outre Stockes, on trouve parmi les victimes connues : Lazear et Noguchi.À partir des années 1930, Max Theiler parvient à atténuer la souche Asibi qui conserve un pouvoir immunogène, ouvrant la voie au vaccin en 1936.
Celui-ci recevra en 1951 le prix Nobel de médecine pour ses travaux.
L'autre souche française atténuée conduit à un second vaccin, mis au point et introduit en 1934 par Jean Laigret, de l'Institut Pasteur, et largement utilisé en Afrique jusqu'en 1982, où les complications neurologiques (encéphalites chez l'enfant) le font abandonner.Le virus est séquencé en 1985.
Des études ultérieures montrent que les souches Asibi et Française sont de séquence identiques à 99,8 %.La maladie est provoquée par un arbovirus de la famille Flaviviridae (qui comprend également les virus à l'origine de la dengue, l'encéphalite de Saint Louis et de la fièvre du Nil occidental).
C'est un des plus petits virus à ARN que l'on ait réussi à isoler chez l'homme.Le cycle de transmission implique des singes arboricoles (colobe, cercopithèque, babouin… en Afrique) et des moustiques simiophiles (piquant préférentiellement le singe) comme Aedes africanus en Afrique, ou Hæmagogus en Amérique du Sud.
Ces moustiques se développent dans les creux d'arbres de la canopée de la forêt tropicale humide.La majorité des singes africains peuvent présenter une virémie transitoire (présence de virus dans le sang), suffisante pour être transmise de singe à singe par les moustiques, mais sans avoir de maladie grave (infection inapparente).
Cela indique une adaptation africaine très ancienne du virus dans le cadre d'une coévolution entre singe, moustique et virus.Il n'en est pas de même des singes sud-américains (singe hurleur, atèle, capucin…) qui peuvent présenter des infections mortelles, comme chez l'homme.
Aussi en Amérique tropicale, les épidémies humaines sont toujours précédées par une forte mortalité des singes forestiers, indiquant une mauvaise adaptation du virus à son hôte.Durant la saison humide, la densité des moustiques s'accroit, et ceux-ci peuvent s'étendre à des zones de savanes en dehors du bloc forestier (forêts-galeries, mosaïques de forêt-savane).
Les moyens de survie du virus durant la saison sèche ne sont pas entièrement élucidés.
Il existe une transmission des moustiques femelles infestées à leurs œufs (transmission trans-ovarienne).
Ces œufs peuvent résister longtemps à la dessication dans les trous d'arbres, en attendant le retour des pluies.
Le véritable réservoir naturel du virus serait alors le moustique.
Une hypothèse secondaire implique le rôle de tiques dans le maintien du cycle, durant la saison sèche.Les virus de la fièvre jaune se maintiennent ainsi dans un système naturel tropical, constitué d'un chaînon long de moustiques, d'une année à l'autre, jouant le double rôle de vecteur et de réservoir, et d'un chaînon court de singes, de quelques jours, jouant le rôle d'amplificateur (le virus se multiplie dans le sang — virémie —, durant la phase d'infestation).Il y a peu d'éléments qui permettent de penser que d'autres mammifères, autres que les primates, pourraient jouer un rôle dans le cycle naturel de transmission.
En laboratoire, dans des conditions expérimentales, les rongeurs (souris, hamsters, cobayes...) sont des espèces sensibles développant des complications cérébrales (encéphalites), alors que le hérisson européen présente plutôt des complications viscérales (hépatiques et rénales).
Les singes asiatiques comme le macaque rhésus sont très sensibles et ils ont été utilisés comme modèles d'études.On distingue deux grands cycles de transmission chez l'homme : le cycle de la fièvre jaune sylvatique (singe — moustique — homme) où l'homme entre accidentellement dans le cycle (cas isolés ou sporadiques), et le cycle de la fièvre jaune urbaine (homme - moustique - homme) où l'épidémie humaine évolue pour son propre compte.La fièvre jaune sylvatique survient chez les personnes vivant ou travaillant en forêt : la chasse intensive ou la déforestation peuvent réduire la population de singes, et les hommes servir d'hôtes de remplacement.
Elle peut aussi exister en lisière de forêt, où les singes vivent à proximité d'exploitations agricoles.
Les souches virales issus de moustiques vivant en forêt sont beaucoup moins virulentes pour l'homme que celles issues de zone rurale, évoluant loin de la forêt (fièvre jaune rurale, intermédiaire entre la sylvatique et l'urbaine).La fièvre jaune urbaine implique une transmission par des moustiques diurnes qui piquent préférentiellement l'homme (moustiques « domestiques »), comme Aedes aegypti en Afrique, ainsi que les Hæmagogus et Sabethes en Amérique du Sud.
Aedes aegypti se développe dans les récipients et tout objet pouvant retenir de l'eau stagnante.
La fièvre jaune dépend alors de plusieurs variables : la densité humaine (urbanisation croissante), les déplacements humains (personnes non immunisées, moyens de transport emportant des moustiques), les zones péri-urbaines dégradées (favorisant le lien entre zones sylvatique et urbaine), le relâchement des précautions d'hygiène et de vaccination, le réchauffement climatique et les pluies excessives.
Il s'agit d'autant de facteurs qui peuvent augmenter la transmission de la fièvre jaune.En 2016, la fièvre jaune est endémique dans 47 pays tropicaux d'Afrique et d'Amérique du Sud représentant 900 millions d'habitants.
90 % des cas surviennent en Afrique subsaharienne.
Il existe des pays où la fièvre jaune est absente, mais susceptible de se propager à cause de la présence du moustique Ædes ægypti, ces pays peuvent exiger un certificat international de vaccination.La fièvre jaune n'a jamais été observée dans les zones tropicales humides d'Asie (Inde, Asie du Sud-Est) et du Pacifique, où le virus reste absent (population originelle séro-négative).
Pourtant toutes les conditions sont réunies pour que le virus s'y implante : présence du vecteur, urbanisation croissante, voyages aériens...
Cette absence de la fièvre jaune en Asie est toujours inexpliquée.
Au moins trois hypothèses ont été suggérées : Selon T.P.
Monath, « il est probable que les trois mécanismes se combinent pour réduire le risque ».
Une quatrième hypothèse est celle de l'absence de singes amplificateurs.
Pour l'OMS, et les autorités sanitaires des pays concernés, le risque d'introduction de fièvre jaune reste réel et potentiel.Après infection lors d'une piqûre de moustique, le virus se réplique dans les ganglions lymphatiques et infecte en particulier les cellules dendritiques.Le virus possède deux grandes propriétés biologiques, le « viscérotropisme » avec atteintes sanguines et viscérales préférentielles (hémorragiques, hépato-rénales...) et le « neurotropisme » avec atteintes cérébrales (encéphalites).
L'une ou l'autre de ces deux propriétés peut être prédominante selon la souche virale, l'espèce-hôte en cause, et l'âge de l'individu-hôte.Dans les atteintes hépatiques, probablement indirectement par le biais des cellules de Küpffer, on constate une dégradation des granulocytes éosinophiles et une libération de cytokines, avec apparition de corps de Councilman dans le cytoplasme des hépatocytes,.L'évolution fatale de la maladie entraîne une insuffisance cardiaque ou une défaillance multiviscérale associée à un fort accroissement des niveaux de cytokine (choc cytokinique).La fièvre jaune peut être asymptomatique ou de gravité variable.
Dans la forme complète et sévère, le tableau est celui d'une fièvre hémorragique virale.Après la piqûre infestante, l'incubation muette, très courte de 3 à 6 jours, est suivie d'une invasion brutale avec malaise, maux de tête violents, sensation de « coup de barre » dorsal et poussée fébrile à 39 °C.Classiquement dans la forme complète (environ 15 % des personnes infectées), la période d'état comporte 2 phases fébriles séparées par une défervescence en V de 24 heures :Le bilan biologique est très perturbé : leucopénie, transaminases hépatiques élevées, protéinurie régulièrement croissante.La phase critique de la maladie survient entre le 5e et le 10e jour après son début, où le patient meurt ou guérit.
En cas d'évolution favorable, une défervescence en lysis sur 48 heures, accompagnée d'une reprise de la diurèse, amène la guérison après 10 jours de maladie, durée maximale pathognomonique de la fièvre jaune.
Cette guérison est habituellement complète : les patients qui survivent à la fièvre jaune ne présentent pas de séquelles hépatiques, rénales ou autres complications chroniques.Dans 20 à 50 % des cas, la mort survient par insuffisance aiguë hépatique et rénale, en hypothermie, après rémission brutale ou au début de la reprise, ou en hyperthermie vers le 8e jour, sans rémission.
Ce tableau s'apparente à un syndrome de réponse inflammatoire systémique avec défaillance multiviscérale.Le diagnostic est clinique, mais les formes très variables de la maladie peuvent le rendre difficile, surtout au début de la maladie, devant un cas isolé.
Cette difficulté entraîne une sous-estimation de la morbidité (taux de malades dans une population) et une surestimation de la mortalité (taux de décès) par la prise en compte des seules formes complètes et abouties de la fièvre jaune.Le diagnostic est orienté par l'aspect de la courbe de température (bi- ou triphasique), la conjonctivite, la langue rouge vif, l'ictère et la dissociation pouls-température, chez un sujet non-vacciné résidant ou ayant voyagé récemment en zone endémique de fièvre jaune.Il faudra éliminer :La confirmation pourra être obtenue d'un laboratoire spécialisé ou d'un centre de référence de l'OMS :Il n'existe aucun traitement spécifique de la fièvre jaune, c'est pourquoi la vaccination préventive est si importante.Le malade devra être isolé sous moustiquaire pendant au moins 5 à 6 jours.Seul un traitement symptomatique est possible, notamment contre la fièvre et la déshydratation.
Il permet d'améliorer l'évolution de la maladie.
Dans les cas les plus graves, des actions plus lourdes sont nécessaires, comme des transfusions sanguines ou des dialyses, mais elles ne sont guère disponibles dans les zones défavorisées.Le risque d'un voyageur non vacciné de contracter la fièvre jaune dépend de la zone géographique, de la saison, de la durée du séjour, des activités exposant à des piqûres de moustique, et de l'intensité de la transmission virale.
En situation épidémique (risque maximum), pour un séjour de 2 semaines, ce risque a été estimé à 1 sur 267, et celui de décès à 1 sur 1333.En situation endémique (inter-épidémique), pour un séjour de deux semaines, le risque pour un voyageur non vacciné de contracter et de décéder de fièvre jaune a été estimé à respectivement 50/100 000 et 10/100 000  en Afrique de l’Ouest et 5/100 000 et 1/100 000 pour un voyage en Amérique du Sud.Les insecticides, les vêtements de protection et l'installation de moustiquaires aux fenêtres sont des mesures individuelles utiles, mais pas toujours suffisantes, contre cette maladie.
Des campagnes de lutte contre les moustiques dans les zones touchées font également baisser le nombre de cas.Après l'isolement du virus en 1927, trois pays (États-Unis, France, Brésil) se lancent dans la recherche d'un vaccin inactivé, ces recherches n'aboutissent pas.À partir de 1932, l'Institut Pasteur met au point un vaccin à virus vivant atténué par passages sur cerveau de souris (dit vaccin neurotropique).
Ce vaccin est largement utilisé en Afrique francophone (au total 14 millions de personnes vaccinées, en 1947).
En 1948, ce vaccin est homologué par l'OMS.
En 1953, 56 millions de doses sont administrées entrainant un déclin de la fièvre jaune dans les pays francophones, contrairement au Nigéria et au Ghana, pays non vaccinateurs.Toutefois, ce vaccin s'accompagne de graves effets secondaires, comme l'encéphalite post-vaccinale, dont le risque est estimé dans les années 1950 à 1 sur dix mille, risque d'abord considéré comme acceptable, l'encéphalite étant le plus souvent réversible.
Dans les années 1960, le risque d'encéphalite est évalué entre 1 et 2 sur mille avec une mortalité de 9 %.
L'utilisation du vaccin neurotropique se restreint, et sa production est définitivement arrêtée en 1982.Les causes de cette encéphalite n'ont pas été éclaircies : à l'origine, une contamination par un virus murin (provenant de la souris) a été envisagée, il est apparu par la suite qu'une instabilité génétique de la souche vaccinale était plus probable.Les vaccins actuels contre la fièvre jaune - vaccin anti-amarile - sont des vaccins vivants issus d'une souche virale atténuée par passage sur embryon de poulet, dite 17D.
Ce vaccin 17D a été découvert en 1936 par Max Theiler et Smith, pour lequel Theiler reçoit le prix Nobel en 1951.
Le médecin allemand Eugen Haagen fut le collaborateur de Theiler en 1932, pour la mise au point de la culture du virus.Il apporte en une semaine une protection immunitaire efficace chez 95 % des sujets vaccinés.
Certaines sources avancent une protection de 85 % à 95 %, et un délai de dix jours pour que la protection soit efficace.Classiquement, la durée de protection était évaluée à dix ans, mais une seule dose vaccinale donnerait une protection durable au moins trente à trente-cinq ans, voire à vie.Les effets secondaires sont assez courants : douleur au point d'injection, fièvre ou céphalées dans un peu moins d'un tiers des cas.
Les manifestations postvaccinales indésirables (MAPI) graves (maladie viscérotrope, maladie neurologique, réactions d’hypersensibilité) sont rares selon les estimations de l'OMS publiées en 2008.
De manière exceptionnelle (moins d'un cas pour cent mille vaccinations) survient un effet « viscerotropique » avec des symptômes proches de ceux d'une fièvre jaune et pouvant aboutir au décès dans environ la moitié des cas.
Un vaccin inactivé, et donc ne comportant pas théoriquement ce risque, est en cours de test.La vaccination peut être rendue obligatoire par les pays concernés, pour les voyageurs entrant dans les pays où sévit la fièvre jaune, et ceux où la fièvre jaune risque de s'y propager.
En effet, le RSI (Règlement Sanitaire International) autorise tout État se trouvant en zone de réceptivité à exiger de toute personne âgée de 1 an au moins pénétrant sur son territoire un certificat de vaccination international à jour.Un pays peut demander la mise en quarantaine d'un voyageur venant d'un pays où le risque de transmission existe, s'il ne peut produire un certificat valable de vaccination, ou de contre-indication à la vaccination.
La durée maximale de cette quarantaine est de 6 jours.Les politiques de rappel vaccinal sont en cours de réévaluation, à la suite d'un amendement du RSI, adopté en mai 2014 par l'Assemblée mondiale de la santé.
Cet amendement déclare que la durée de protection des vaccins de la fièvre jaune est étendue à la vie entière et que la durée de validité du certificat international devait être prolongée en conséquence.
Cette modification est en principe applicable à l’ensemble des pays à partir de juin 2016.En France, le Haut Conseil de la santé publique prend acte de cette décision de l'OMS, et recommande une seconde dose de vaccin (un seul rappel dix ans après la vaccination) dans des cas particuliers.
D'autres pays ont pris des positions analogues comme les États-Unis.En France, en Belgique, en Suisse, en Allemagne et au Québec, cette maladie est sur la liste des maladies infectieuses à déclaration obligatoire (MADO).
Un vaccin contre la varicelle entraîne et prépare le système immunitaire à reconnaître et à combattre le virus varicelle-zona, ce qui permet de prévenir cette maladie.La mise en place du vaccin contre la varicelle constitue un point marquant en virologie.
D’ailleurs, c’est le seul vaccin conçu contre un virus de l’herpès de nos jours.
Il s’agit également du premier vaccin à avoir été administré à un patient immunodéprimé avec succès.La souche de vaccin atténué a été faite à partir d’un jeune garçon de trois ans atteint de varicelle.
Le virus VZV a subi 11 passages dans des cellules pulmonaires humaines, 6 à 7 passages dans les embryons de cochon d’Inde et finalement, de 2 à 6 passages dans des cellules diploïdes humaines.La vaccination est possible afin de prévenir l’infection par le VZV.
Il s’agit de vaccins à virus atténué contre la varicelle,.
Les avantages du fait que ce sont des vaccins atténués sont une protection élevée dès l’administration d’une première dose, la durée de l’immunité ainsi que la présence de réponses humorale et cellulaire.Deux vaccins sont sur le marché dans les pays occidentaux : Varivax III, de la société Merck and Co.
(États-Unis, Canada)/MSD (reste du monde), et Varilrix, de la société GlaxoSmithKline Vaccines.
D'autres vaccins sont en développement ou commercialisé en Inde et en Chine.Les deux sont des vaccins atténués.
Varivax III dérive de la souche Oka/Merck.
Il a été précédé de deux autres vaccins, Varivax et Varivax II ; Varilrix dérive de la souche Oka/Rix.Des études démontrent que le vaccin, lorsqu’il est administré en une seule dose chez des enfants en santé, permet une immunisation durant environ sept ans.
L’efficacité de l’immunisation a été mesurée grâce aux anticorps anti-VVZ présents dans le sérum.
Le pourcentage trouvé variait entre 96 et 100 % sur la période de l’étude.Suite à l'administration d'une seule dose de vaccin, l'âge du pic d'apparition de la varicelle se décale vers de 9-12 ans, particulièrement dans la population non vaccinée.
Cependant, le nombre de cas de varicelle observé entre 9 et 12 ans après l'introduction de la vaccination est similaire au nombre de cas avant la vaccination.
Il est remarquable de constater que le nombre de cas de varicelle diminue globalement fortement.La protection contre la varicelle semble diminuer avec le temps, et préconise une seconde dose vaccinale.L'administration d'une seconde dose du vaccin permet de réduire significativement le risque de décalage de la maladie vers un âge plus avancé, de même qu'elle permet de réduire le risque de cas de varicelle grave (par la réduction du nombre d'hospitalisation).
En 15 ans — depuis l'introduction de la vaccination aux États-Unis — il n'a pas été observé de décalage de la maladie vers des groupes plus âgés.
L'incidence de la maladie a été diminué de 90 à 95 % dans toutes les catégories d'âge, quel que soit le statut vaccinal.
Le nombre d'hospitalisations liées à la vaccination a été réduit de 90 %, dans toutes les catégories, y compris les adolescents et les adultes.
D'autre études corroborent ces conclusions,,,.La vaccination contre la varicelle (avec deux doses) a la capacité de réduire très fortement la prévalence de la varicelle, à la fois directement, et indirectement par l'immunité collective,.
En effet, le seul réservoir de la maladie est humain.
La varicelle n'existe dans aucune autre espèce vivante.
Une éradication totale de la maladie est alors possible.Le Centre européen pour la prévention et le contrôle des maladies (ECDC) a récemment publié un document de référence mettant en évidence les bénéfices de la vaccination contre la varicelle, tout en relevant certains points, encore à étudier, comme la persistance à long terme de l'immunité (aujourd'hui assurée jusqu'à 15 ans avec deux doses),, etc.Le risque de zona n'est pas démontré comme diminué, en raison de l'absence de recul.
Cependant, le zona correspond à une réactivation du virus de la varicelle VZV, resté quiescent dans les ganglions nerveux.
La vaccination contre la varicelle pourrait donc diminuer le risque de zona à l'âge adulte et chez les personnes âgées en évitant  la quiescence du virus.
Aucune étude n'a pour l'instant démontré cet effet.
Les réactions fréquemment observées sont généralement bénignes : douleur ou œdème au site d’injection (environ 20 % des enfants vaccinés et 33 % des adolescents et adultes vaccinés).
Une fébricule de faible intensité survient dans 15 % des cas.
Un faible nombre de vaccinés (environ 5,5 % après la première injection et 0,9 % après la seconde injection) présenteront une éruption ailleurs qu’au point d’injection, caractérisée par un petit nombre de papules ou vésicules varicelliformes.
Les lésions apparaissent habituellement dans les cinq à vingt-six jours suivant l’injection (moins de 10 %) et un léger rash pseudo-varicelleux dans le mois suivant l’injection (moins de 5 %).La survenue de convulsions d’intensité modérée consécutives à une poussée fébrile est peu fréquente (1 cas sur 1 000 vaccinés).
Les effets indésirables doivent être déclarés au centre régional de pharmacovigilance correspondant au lieu d’exercice du médecin traitant/spécialiste du patient.La transmission du virus vaccinal (qui est un virus vivant) d'une personne vaccinée à une personne non vaccinée a été observée.Au Canada, la population ciblée par le vaccin est surtout les enfants âgés de plus de 12 mois et en bonne santé.
Par ailleurs, les personnes placées dans des situations jugées à risque peuvent également être vaccinées contre le VVZ.
La société canadienne de pédiatrie décrit trois situations :Le vaccin est toutefois contre-indiqué pour les personnes ayant une hypersensibilité à l’une des composantes du vaccin.
Les personnes immunodéprimées ne devraient également pas recevoir le vaccin puisqu’étant fait à partir de virus atténué, il pourrait causer une réaction chez le patient.
Il est également non recommandé pour les femmes enceintes.
Une grossesse est à éviter le mois suivant la vaccination.Aux États-Unis, la vaccination se fait systématiquement chez les enfants en santé.
À cet égard, une diminution de l’incidence, de la morbidité et de la mortalité a été observée.La vaccination contre la varicelle chez l’adulte entraîne la production d’anticorps ainsi qu’une réponse immunitaire à médiation cellulaire dans les trois mois suivant l’injection.
La réponse à médiation cellulaire est supérieure à la réponse humorale surtout parce que le système immunitaire réagit dans le but de protéger l’organisme d’une seconde infection, c’est-à-dire d’une réactivation du virus.
Deux doses du vaccin sont nécessaires pour mettre en place une réponse à médiation cellulaire similaire,.La vaccination contre le VVZ chez les immunosupprimés vise surtout une protection contre le zona.
Les types de vaccins administrés sont différents de celui utilisé pour la varicelle.
Le vaccin contre la varicelle administré chez les personnes en santé peut être donné dans le cas où le patient n’est pas encore dans un état d’immunosuppression, c’est-à-dire avant une thérapie immunosuppressive, par exemple.L’utilisation du virus inactivé est également faite.
Il est plus sécuritaire que le vaccin atténué puisque la souche virale a été traitée à la chaleur.
Toutefois, il s’avère que ce type de vaccin est moins efficace étant donné que la présentation d’antigène dans le contexte du complexe majeur d’histocompatibilité de type I est plus faible.
La réponse des cellules T spécifiques au virus est alors inférieure comparativement à celle obtenue avec un vaccin élaboré à partir d’une souche virale atténuée.D’autres approches peuvent permettre la protection des gens immunodéprimés contre le VVZ.
Dans certains cas, la personne reçoit une première dose de vaccin inactivé avant de recevoir le vaccin atténué.
Cela a pour effet de créer une première réponse immunitaire qui sera capable d’empêcher l’infection par le virus atténué.
Des vaccins préparés à l’aide de protéines virales peuvent également être injectés de façon sécuritaire aux patients plus à risque.
Les régions qui vont activer une réponse par les cellules T cytotoxiques sont les zones codant les protéines 4, 62 et 63 en plus des glycoprotéines C, E et I. L’ajout d’adjuvant pourrait être bénéfique puisqu’il permettrait à la réponse immunitaire d’être augmentée vu qu’aucune réplication n’est présente dans ce type de vaccin.Il serait possible de modifier génétiquement la souche sauvage Oka en lui enlevant les gènes essentiels à sa réplication.
Théoriquement, le virus devrait être apte à infecter une cellule, activer le système immunitaire sans se répliquer, causant ainsi une varicelle ou un zona, selon le cas.Depuis septembre 2004, le vaccin est disponible en France.
Cependant, il n’est pas recommandé dans le cadre d'une vaccination de masse.
Il n'est recommandé (et remboursé) que dans quatre cas :Les indications pour la vaccination contre la varicelle sont les suivantes :En cas d’anamnèse incertaine, une sérologie peut, être, obtenue, mais on peut aussi procéder directement à la vaccination.
Dans les indications ci-dessus, le coût de la vaccination est pris en charge par les caisses dans le cadre de l’assurance maladie obligatoire.Le vaccin contre la varicelle est inclus dans le vaccin RRO-Var (vaccin combiné contre la rougeole, la rubéole, les oreillons et la varicelle) habituellement administré aux enfants vers l'âge de 18 mois.
Depuis le 1er avril 2016, une 2e dose a été ajoutée au calendrier de vaccination et est administrée aux enfants âgés de 4 à 6 ans.Dans d'autres pays, la vaccination est beaucoup plus systématique (États-Unis, Allemagne, Canada, Australie, Taïwan…), entraînant une forte diminution de la maladie et des formes graves de celle-ci dans toutes les classes d'âge, ainsi qu'une diminution significative pour ce qui est du coût : médicaments, absentéisme, garde d'enfant…Les vaccins contre la varicelle font partie de la liste des médicaments essentiels de l'Organisation mondiale de la santé (liste mise à jour en avril 2013).
La liste modèle de l'OMS des médicaments essentiels est publiée par l'Organisation mondiale de la santé (OMS) depuis 1977 et mise à jour au moins tous les deux ans (en anglais).
Depuis 2007, l'OMS publie également une liste distincte destinée aux enfants jusqu'à 12 ans.
Ces listes recensent les médicaments essentiels dont les systèmes de santé à travers le monde devraient permettre l'accès à l'ensemble de la population en vertu de la déclaration de Montréal sur le droit fondamental aux médicaments essentiels.
Il s'agit d'un modèle de liste destiné à être décliné localement par les autorités sanitaires des différents pays pour répondre à leurs besoins prioritaires en matière de santé publique.
Les médicaments retenus doivent être essentiels pour répondre à ces besoins prioritaires et doivent présenter des preuves suffisantes de leur innocuité, de leur efficacité, d'un rapport coût/efficacité acceptable et d'une disponibilité suffisante sur le marché.La liste ci-dessous reproduit l'édition OMS de mars 2011 (en français), mise à jour dans certains cas avec la liste OMS publiée en avril 2013 (en anglais).
Cette liste est introduite par les définitions et précisions suivantes :On trouvera à l'annexe 1 les principaux termes employés pour les formes galéniques dans la liste des médicaments essentiels.
L'OMS définit bon nombre de ces termes et les normes de qualité et d'assurance-qualité applicables aux différentes catégories,.Les médicaments indiqués dans le traitement de la lèpre ne doivent être administrés qu'en association.
Le traitement par une association thérapeutique est indispensable pour empêcher la survenue d'une pharmacorésistance.
On utilisera des plaquettes thermoformées (blister packs) chromocodées, contenant une association classique de deux médicaments (lèpre paucibacillaire) ou de trois médicaments (lèpre multibacillaire) destinée à l'adulte ou à l'enfant.
Ces plaquettes peuvent être obtenues gratuitement en s'adressant à l'OMS.En l'état actuel des connaissances et d'après l'expérience de leur utilisation, les médicaments entrant dans les trois classes d'antirétroviraux ci-dessous sont inscrits sur la liste des médicaments essentiels pour le traitement et la prévention de l'infection à VIH (prévention de la transmission mère-enfant et prophylaxie post-exposition).
Le Comité insiste sur l'importance d'utiliser ces produits conformément aux directives internationales et nationales.
Il recommande et approuve l'emploi d’associations fixes et le développement de nouvelles associations fixes appropriées, notamment de formes pharmaceutiques modifiées, de produits n'ayant pas besoin d'être réfrigérés et de formes pédiatriques de qualité pharmaceutique assurée.
Les comprimés sécables peuvent être utilisés chez l'enfant et on peut donc envisager de les inclure dans la liste des comprimés, pour autant que des produits de qualité suffisante soient disponibles.Le choix des inhibiteurs de protéase à partir de la liste modèle devra être établi par chacun des pays en tenant compte des directives thérapeutiques internationales et nationales et des données de l’expérience.
Le ritonavir est recommandé dans les associations en tant que potentialisateur pharmacologique et non comme antirétroviral à part entière.
Tous les autres inhibiteurs de protéase doivent être utilisés sous des formes renforcées (par exemple, avec du ritonavir).Les médicaments destinés au traitement du paludisme à P. falciparum doivent être utilisés en association.
La liste recommande actuellement les associations mentionnées dans les directives thérapeutiques.
Le Comité admet qu'il n'existe pas encore toutes les associations et encourage leur développement et leur essai rigoureux.
Il encourage également le développement et l'essai de formes destinées à la voie rectale.Le Comité OMS d'Experts reconnaît l'importance de faire figurer des médicaments spécifiques dans la section consacrée aux soins palliatifs.
Certains médicaments utilisés dans les soins palliatifs figurent dans la section de la liste modèle correspondant à leur usage thérapeutique, par exemple les analgésiques.
Les directives sur les soins palliatifs mentionnées dans la précédente édition de la liste doivent être mises à jour.
Le Comité prévoit que des demandes en vue de l'inscription des médicaments nécessaires pour les soins palliatifs lui seront présentées pour la prochaine réunion.Toutes les fractions plasmatiques doivent satisfaire aux normes de l'OMS relatives à la collecte, au traitement et au contrôle de qualité du sang, de ses constituants et des dérivés du plasma (révision 1992).
(OMS, Série de Rapports techniques, no 840, 1994, annexe 2).Toutes les tuberculines doivent être conformes aux normes de l'OMS relatives aux tuberculines (révision 1985).
Comité OMS d’Experts de la Standardisation biologique, trente-sixième rapport (OMS, Série de Rapports techniques, no 745, 1987, annexe 1).Toutes les fractions plasmatiques doivent être conformes aux normes de l'OMS relatives à la collecte, au traitement et au contrôle de qualité du sang, de ses constituants et des dérivés du plasma (Révision 1992).
Comité OMS d'Experts de la Standardisation biologique, quarante-troisième rapport (OMS, Série de Rapports techniques, no 840, 1994, annexe 2).Le choix des vaccins à partir de la liste modèle devra être établi par chaque pays en tenant compte des recommandations internationales, des données épidémiologiques et des priorités nationales.
La liste ci-dessous indique les vaccins pour lesquels il existe une recommandation du Strategic Advisory Group of Experts on Immunization (SAGE) et/ou une note de synthèse de l'OMS.
Ce site est mis à jour à mesure de la publication de nouvelles notes de synthèse et contient les informations et recommandations les plus récentes.Tous les vaccins doivent être conformes aux normes de l'OMS pour les substances biologiques.Le Comité d'Experts a demandé l'examen de cette section lors de sa prochaine réunion.Cette section sera réexaminée lors de la prochaine réunion du Comité d'Experts.
Le plus souvent, on entend par expérimentation humaine, l'expérimentation scientifique sur l'être humain dans le cadre de recherches sur la maladie et la santé (sujet de cet article).
Cette expérimentation sur le sujet humain ne se limite pas à la médecine : elle peut concerner de nouvelles méthodes pédagogiques, la pratique de nouvelles technologies, ou le vol spatial.Les expériences médicales sur les êtres humains s'inscrivent dans le processus des essais cliniques pour élaborer des traitements.
Dans ce cadre, se posent les questions du consentement éclairé des patients concernés et du contrôle bioéthique de l'expérience.En français le terme « expérience » recouvre deux concepts distincts, celui d'avoir de l'expérience (être expérimenté, avoir les compétences) et faire une expérience (être expérimental, tenter un essai), c'est alors une « expérimentation ».Le caractère ambigu du terme expérience a son origine dans les termes grec empeiria (savoir acquis par la pratique) et peira (essai, épreuve concrète).
Le terme latin experientia a le même double sens (savoir acquis par l'expérience et essai pour un savoir à acquérir),.
Pour les distinguer, on trouve chez Cicéron le terme experimentum pour désigner l'essai.Dans son sens large (expérience/expérimentation), l'expérimentation humaine est alors aussi vieille que la médecine.
Pour Canguilhem : « Les médecins ont toujours expérimenté, en ce sens qu'ils ont toujours attendu un enseignement de leurs gestes, quand ils en prenaient l'initiative (...) Soigner, c'est faire une expérience.
Toute nouvelle pratique de soin (remède, appareil et procédure...) implique un premier participant avec les risques et les bénéfices inhérents à cette première participation.De l'Antiquité jusque vers le XVIIe siècle, les médecins se réfèrent à un experimentum qui relève en fait de l'essai empirique, qui consiste à observer et reproduire des routines apprises, sans stratégie de recherche.
Ici « l'expérience », même nouvelle ou renouvelée, ne vise qu'à illustrer une théorie ou la prolonger en pratique.Au cours du XIXe siècle, la médecine adopte une méthode « expérimentale », en mettant en doute les idées reçues.
C'est la recherche d'une démonstration par la preuve, qui consiste à n'admettre pour vrai que ce qui est contrôlé par les faits.Jusqu'à la deuxième guerre mondiale, les problèmes éthiques des expériences médicales sur l'homme ont été relativement peu discutés ; alors même que l'expérimentation animale faisait largement débat depuis le début du XIXe siècle, surtout en Grande-Bretagne et en Allemagne.
Les restrictions légales de l'utilisation d'animaux de laboratoire ont ainsi précédé de plus d'un demi-siècle les premières règlementations de l'expérimentation humaine.Ces règlements et codes éthiques de l'expérimentation humaine, élaborées par la suite, ont mis l'accent sur les concepts de consentement, de respect de la personne, d'évaluation des risques, et les principes de justice et de bienfaisance ou solidarité.Néanmoins plusieurs dimensions de l'expérimentation humaine restent en discussion, sur la légitimité ou pas de distinguer entre l'expérimentation dite thérapeutique (pour soigner)  et l'expérimentation dite cognitive (recherche pure) ; sur celle qui porte sur un individu et celle sur un ensemble (population) ; sur l'expérimentation humaine  (règlementée dans l'espace public sur des sujets de droit) et l'expérimentation sur l'homme (faite à discrétion sur des sujets avilis, réduits à l'état d'objet et privés de droits),.L'expérimentation humaine est alors au croisement de la science et du droit, de la philosophie morale et de la philosophie politique.L'existence d'une expérimentation biologique quantitative dans l'Antiquité est controversée.
Selon le texte Hippocratique De l'Ancienne médecine, la médecine se serait constituée par une approche empirique d'essais et d'erreurs, similaire à l'art culinaire (préparation des aliments).
Cette approche ne serait plus nécessaire, l'art médical étant établi désormais (selon l'auteur) par le raisonnement, le médecin ne doit plus faire pour voir, mais observer avec les yeux de la raison qui dicte sa conduite.
Le fameux principe primun non nocere « d'abord ne pas nuire » est attribué à Hippocrate (Épidémies I, V).
De même l'adage Ars longa, vita brevis « l'art est long et la vie est courte », dans Aphorismes 1, I), qui se poursuit par experimentum periculosum (l'original grec étant ἡ δὲ πεῖρα σφαλερή).
Ici les interprétations divergent, par exemple Littré donne la traduction « l'expérience est trompeuse » (un médecin même expérimenté peut se tromper) et d'autres « l'expérimentation est faillible » ou « l'essai est dangereux » (pour le patient).
Dans le Serment d'Hippocrate, la fourniture de poisons ou la pratique chirurgicale risquée sont condamnées, mais de telles expériences ont été plus ou moins tentées dans l'Antiquité.
des essais de médicaments dangereux par maîtrise du dosage apparaissent, avec l'utilisation (controversée à l'époque) de l'ellébore (plante toxique).
J.C., l'école de médecine d'Alexandrie pratique la dissection de cadavres, et la vivissection de condamnés à morts, rapportées par Hérophile et Érasistrate.
Quoique rarement signalée dans le reste de l'Antiquité, cette pratique est défendue par le romain Celse qui la justifie comme un sacrifice de coupables pour le bien des innocents.
D'autre part, Scribonius Largus (Ier siècle ap.
J.C) insiste sur le fait que la prescription de drogues dangereuses est possible si le médecin respecte les principes éthiques d'Hippocrate.
signale que des rois d'Orient comme Mithridate VI et Attale III s'intéressent à l'étude des poisons et des antidotes sur des condamnés ou des esclaves.
Ces mentions ne sont que de vagues échos, et les questionnement éthiques rares.
Par exemple, Galien préfère la dissection du porc à celle du singe « pour ne pas voir la déplaisante figure du singe en train d'être disséqué vivant ».À partir du XIVe siècle, la dissection de cadavre devient un moyen d'enseigner l'anatomie dans les universités européennes, la première à le faire étant celle de Bologne.
Les anatomistes médiévaux et de la Renaissance demandent aux autorités, ou les obtiennent de façon clandestine, les corps des condamnés à mort ou ceux des pauvres destinés à être enterrés sur argent public.Selon Chamayou, c'est l'époque où l'experimentum periculosum posé par Hippocrate, prend une tournure nouvelle.
La question n'est plus « peut-on expérimenter sur l'homme ?
», mais devient « sur quels hommes peut-on expérimenter ?
».La réponse est illustrée par l'anecdote arrivée au philosophe Marc Antoine Muret (1526-1585).
Réfugié en Italie, déguisé en mendiant, il tombe malade ; et des médecins à son chevet discutent et l'un d'eux declare Faciamus experimentum in corpore vili  « faisons l'expérience sur ce corps vil » (ou anima vili, âme vile, selon les versions).
Au nom de ce principe, l'expérimentation humaine devient licite lorsqu'elle s'applique à des êtres de peu de valeur, méprisables et sans dignité.
Initialement le corps vil s'opposait au corps glorieux de la résurrection.Au XVIIe siècle, l'expérimentation animale devient un moyen essentiel de la recherche, notamment lors de la découverte de la circulation sanguine par William Harvey en 1628.
Après la fondation de la Royal Society en 1660, quelques expérimentations humaines sont menées sur une nouvelle catégorie de sujets, non seulement les condamnés ou les misérables, mais aussi les fous et les insensés.
L'exemple le plus connu est celui des transfusions sanguines de l'animal à l'homme, tentées par l'anglais Richard Lower sur un pauvre clergyman contre salaire, ou par le français  Jean Baptiste Denis sur un fou, pour le guérir de sa folie.Ces démonstrations publiques (comme l'étaient les dissections humaines dans les théâtres anatomiques) n'ont guère suscité de débats éthiques.
Après quelques échecs retentissants, la transfusion sanguine est abandonnée et oubliée, pour réapparaître à la fin du 19e siècle.Le XVIIIe siècle élucide de nombreuses questions biologiques et médicales par une démarche de type expérimental, sur l'animal et sur l'homme.
Par exemple, la nature chimique de la digestion (Réaumur 1752, Spallanzani 1783), ou les premiers essais comparatifs du traitement du scorbut, effectués par James Lind en 1747,.
Pour la première fois des essais sont tentés à l'échelle d'une population, comme la prévention par variolisation, d'abord testée en 1721 sur des détenus de la prison de Newgate,  et qui sera suivie par la vaccination de Jenner en 1798.Au cours du XIXe siècle, la médecine devient vraiment « expérimentale » avec la médecine hospitalière où les malades commencent à être soumis à des essais méthodiques.
En 1831, Pierre Louis publie son travail sur les effets de la saignée sur la pneumonie, où il démontre l'inefficacité de la saignée.
Tout au long du siècle, les médecins apprennent à travailler sur des séries de cas suffisamment nombreux, à codifier les symptômes, à standardiser les traitements, etc.
Une médecine statistique d'évaluation et de calcul de risques se développe, ce qui ne va pas sans résistances, car il faut faire abstraction des particularités individuelles.En sus des criminels et détenus, des fous, et des pauvres hospitalisés, de nouvelles catégories de sujets d'expérimentation apparaissent.
Aux États-Unis, ce sont les esclaves noirs, ainsi le médecin sudiste James Marion Sims (1813-1883) expérimente de nouvelles techniques de réparation chirurgicale chez des accouchées noires.
Une fois la technique opératoire rodée sur esclave noire, il consent à l'appliquer aux femmes blanches.
Même après l'émancipation des esclaves (années 1860), la pratique d'utiliser le corps des noirs persistera aux États-Unis pendant des décennies,.La situation est analogue dans les empire coloniaux britanniques, français ou allemands, où « les corps vils ont été racisés ».
Les indigènes sont l'objet d'inoculations ou d'essais thérapeutiques, soit dans des prisons comme détenus, soit dans des camps-hôpitaux d'expérimentation comme malades.Dans d'autres cas, l'expérimentateur obtient plus ou moins la coopération du sujet, tel fut le cas du trappeur canadien français Alexis Saint Martin (1794-1880) suivi par le médecin militaire américain William Beaumont (1785-1853).L'expérimentation est parfois justifiée (par les expérimentateurs) par la pratique de l'auto-expérimentation.
Celle-ci est assez répandue dans les universités américaines, chez les professeurs-chercheurs, comme chez les étudiants, qui s'inoculent des maladies et testent des remèdes ou des procédures.
Par exemple, James Simpson (1811-1870) a d'abord voulu tester le chloroforme sur lui-même.
Après l'avoir inhalé, il se réveilla étendu sur le sol de son laboratoire.
D'autres expérimentateurs, enthousiastes et pressés, prennent leurs proches comme sujets d'expérience : enfants, épouse, parents, voisins..À la fin du XIXe siècle, l'éthique de l'expérimentation humaine ne suscite guère de débats.
Ainsi dans les pays anglo-saxons, les médecins se réfèrent au code éthique de Thomas Percival(1740-1804) rédigé en 1803.
Les nouveaux remèdes et traitements doivent être administrés « selon une saine raison et une conscience scrupuleuse », et l'on doit d'abord consulter ses pairs.
Ce code est adopté par la médecine américaine dès 1847, et plusieurs fois révisé.
En France, Claude Bernard dans son Introduction à l’Étude de la Médecine Expérimentale (1856) se présente comme le tenant d'une morale moderne.
Il réprouve des pratiques anciennes et dangereuses sur les condamnés à mort qui offraient la grâce en échange.
Toutefois, il considère comme très utiles des études expérimentales sur le corps et la tête des guillotinés aussitôt après la décapitation ; de faire avaler des œufs ou larves de vers intestinaux à l'insu des condamnés pour démontrer leur présence adulte dans l'intestin ; ou encore de tenter des essais sur les mourants atteints de phtisie.
Il écrit que des expériences ne peuvent être concluantes que sur l'homme : En 1872, Claude Bernard rappelle, dans ses Leçons de pathologie expérimentale que « La morale condamnerait avec raison, d'une façon absolue, toute expérience sur l'homme qui pourrait nuire au patient ou qui n'aurait pas pour but son utilité directe et immédiate.
».Le point de vue de Claude Bernard parait triompher avec l'avènement de la révolution microbiologique, lorsque Louis Pasteur (1822-1895) et Robert Koch (1843-1910) montrent que les essais  sur l'homme peuvent mener à des résultats prestigieux sur des sujets comme la tuberculose ou la rage ;  ou encore sur la fièvre jaune, avec les expériences menées par Walter Reed (1851-1902).Pour la plupart des chercheurs, il apparait que l'expérimentation médicale humaine n'a pas besoin d'être légalement restreinte ou encadrée, notamment sur la question du consentement du sujet.
En 1916, lors du débat de révision du code d'éthique des médecins américains sur cette question, l'AMA décida qu'une protection formelle n'était pas nécessaire.
De même dans les autres pays, notamment en France, le droit à l'essai relève de principes professionnels basés sur les impératifs de responsabilité et de prudence.
C'est aux médecins et chirurgiens eux-mêmes de trouver la limite où le désir d'expérimenter s'oppose au devoir de soigner.
Cependant cette éthique professionnelle ne peut plus prétendre résoudre cette contradiction à elle seule.
Quelques controverses et procès publics montrent déjà  qu'il faudrait placer l'expérimentation humaine non plus sous contrôle corporatiste, mais sous un régime de Droit.
Au tournant du XXe siècle, l'émergence de la microbiologie conduit à une bactériologie expérimentale, dans le cadre d'une pathologie expérimentale, qui se fait en principe sur l'animal (mise en œuvre des postulats de Koch).
Mais il existe des maladies spécifiquement humaines qui ne peuvent être reproduites sur l'animal, la tentation est alors grande d'expérimenter sur l'homme.
Selon la logique interne de la preuve, la méthode expérimentale conduit à expérimenter sur l'homme.Des chercheurs résolvent le dilemme en expérimentant sur eux-mêmes, d'autres succombent involontairement par accident de contamination en laboratoire.
Dans une première vague d'enthousiasme pour la microbiologie, les chercheurs travaillant sur des pathologies sans modèle animal convenable, se tournent alors vers de nouveaux sujets humains : orphelins ou handicapés en institution, prostituées, aliénés en asile, immigrés, malades hospitalisés (incurables, moribonds...).Dans ce contexte, plusieurs expériences menées à grande échelle ont suscité un scandale rétrospectif en raison de leur manque d'éthique.
Par exemple, celui de l'Unité 731 de l'Armée impériale japonaise  ou de l'étude de Tuskegee sur la syphilis aux États-Unis (1932-1972).
Cependant, le désastre le plus retentissant pour les contemporains a été celui des vaccinations mortelles de Lübeck survenues en 1930 en Allemagne.
Près de 70 nourrissons décèdent dans la maternité de l'hôpital de Lübeck, après administration d'un vaccin BCG par voie orale, contaminé localement par une souche virulente de M. tuberculosis.
Cet accident conduisit à l'abandon de la voie orale pour le BCG, et à l'élaboration d'un code spécifique d'éthique des thérapies expérimentales en 1931.Par une ironie de l'Histoire, l'Allemagne de Weimar dispose alors du texte éthique le plus avancé au monde en matière d'expérimentation médicale humaine, le Reichsrundschreiben.
Son objectif est la protection des sujets et des patients, tout en permettant la recherche.
Les principes sont la responsabilité individuelle des chercheurs, la recherche du risque minimum, le respect absolu des enfants, des faibles et des mourants, et surtout le consentement « non équivoque » et « non ambigu » des patients ou sujets de l'expérience.
Ce texte (une circulaire ministérielle) ne sera jamais abrogé sous le IIIe Reich, mais son impact sera nul sur les pratiques nazies,.Au cours de la seconde guerre mondiale, l'expérimentation médicale nazie a été couramment pratiquée chez les prisonniers et déportés des principaux camps de concentration.
Cela a mené au procès des médecins (décembre 1946-août 1947), tenu à Nuremberg, où furent jugés 23 responsables nazis (dont 20 médecins).
Dans les attendus du jugement, figure une liste de 10 principes règlementant l'expérimentation humaine, dont le premier et le plus important est le consentement libre du sujet informé, hors de toute situation de contrainte.
Ces principes sont connus sous le nom de « code de Nuremberg ».Cependant, la recherche médicale alliée elle-même ne satisfaisait guère aux principes édictés par le jugement de Nuremberg.
De 1941 à 1945, la recherche américaine a mené des expériences à grande échelle, plus ou moins clandestines, sur des populations incapables de donner leur consentement, comme des orphelins ou des handicapés mentaux.
Savoir si les détenus, les militaires ou les objecteurs de conscience sont des sujets en situation, ou pas, de contrainte restait une question discutée.L'Office of Scientific Resarch and Development a ainsi mené des études sur des maladies comme la dysenterie, la typhoïde, l'hépatite, le paludisme, la grippe et des MST ; comme sur la transfusion de substituts au sang ; ou encore sur le gaz moutarde ou le plutonium.Le « code de Nuremberg » est considéré comme le premier texte international de référence sur l'éthique de l'expérimentation humaine, mais il a très peu d'effet sur la communauté médicale qui ne se sent guère concernée.
Nuremberg apparait comme « un code bon pour les barbares » mais pas pour les nations civilisées.Dès 1948, l'Association médicale mondiale (AMM) fondée en 1947, élabore une Déclaration de Genève, puis un Code international d'Éthique Médicale, où les principes de l'expérimentation humaine se basent sur ceux de Nuremberg.
De nouveaux textes autorisent la recherche dans certaines conditions, en introduisant la notion de consentement des parents proches ou représentants dans le cas des enfants, des patients inconscients ou psychiatriques, mais sans préciser la notion de risque inadmissible.À la suite de la tragédie du Thalidomide (1960), l'AMM, après quatre ans de débats, précise ces principes sous le titre de Recommandations Guiding Physicians in Biomedical Research Involving Subjects, texte connu sous le nom de Déclaration d'Helsinki (1964).Au total, pour la période 1947-2000, on compte près de 326 versions de ces différents textes, amendés ou révisés au niveau international ou national, le plus souvent à la suite d'affaires ou de scandales retentissants .
L'histoire de l'expérimentation médicale humaine de cette période montre des abus continus et persistants malgré la multiplication de textes éthiques.
Par exemple, de l'expérimentation sur la syphilis au Guatemala (1946-1948) jusqu'au problème des essais cliniques dans les pays en développement, moins règlementés.Plusieurs auteurs soulignent la fragilité des déclarations de principe, soumises aux différents conflits de pouvoirs qui traversent une société, notamment si les administrations ne les font pas appliquer, ou si aucune sanction n'est prévue contre les contrevenants,.
Malgré les progrès effectués dans le domaine de l'expérimentation humaine, ce sujet restera probablement un problème éthique pour les décennies à venir au cours du XXIe siècle .
L'adage souvent cité  « ce qui n'est pas scientifique n'est pas éthique » représente une éthique de la connaissance basée sur un postulat d'objectivité.
Pour Jacques Monod : « L'éthique de la connaissance, créatrice du monde moderne, est la seule compatible avec lui, la seule capable, une fois comprise et acceptée, de guider son évolution.
La « connaissance vraie » serait alors la seule valeur transcendantale où « L'éthique de la connaissance est également, en un sens, "connaissance de l'éthique".
».Cette approche est discutée, notamment quand l'adage se retourne en « ce qui n'est pas éthique n'est pas scientifique (ou est pseudo-scientifique) ».
Des expérimentations scientifiquement valides peuvent être contraires à l'éthique.
Les débats sur les expériences nazies d'hypothermie ont montré qu'elles étaient inacceptables, non pas en raison de leurs protocoles pseudo-scientifiques, mais bien d'abord parce que contraires à l'éthique,.Selon la formule de Jean Bernard, l'expérimentation est « moralement nécessaire et nécessairement immorale ».
Nécessaire pour la vérité et le bien de tous, immorale puisque conduite sur quelques individus à leurs risques.
L'expérimentation se placerait alors dans un contrat social, équivalent à celui qui fonde les rapports entre une société et des individus, au nom de la solidarité sociale.
La bioéthique s'inscrit dans une biopolitique.Il en résulte que les limites de l'expérimentation humaine ne sont pas à chercher dans la science ou la vérité scientifique, mais bien dans l'éthique elle-même, voire dans une philosophie politique des rapports de pouvoir.Jusque là peu abordée, la question du consentement est apparue en pleine lumière dans le code de Nuremberg : « le consentement volontaire du sujet humain est absolument essentiel ».
La personne sujet d'expérience doit avoir la capacité légale de consentir, hors d'une situation de contrainte, être informée et pouvoir à tout moment quitter l'expérimentation.
Ce principe a permis de se démarquer des pratiques nazies.Ce principe est resté insuffisant, car de nombreuses personnes n'ont pas la capacité légale de consentir (sujets en réanimation ou comateux, enfants, handicapés mentaux...).
Demander le consentement aux proches, aux représentants ou aux autorités de tutelle, a fait que les expérimentations ont été conduites dans des institutions comme les orphelinats, les asiles...
Depuis les années 1970, la plupart des pays ont renoncé à solliciter les détenus pour la recherche bio-médicale.
De même, la notion de consentement éclairé reste discutable quand il s'agit d'expérimenter sur des populations analphabètes ou trop culturellement éloignées d'une recherche médicale.Enfin, l'expérimentation peut s'inscrire dans le cadre d'une action thérapeutique, et la limite entre le consentement aux soins et le consentement à l'expérimentation peut rester floue.
Au cours du  XXe siècle, le médecin était le seul juge de l'intérêt de son malade, dans le cadre d'une relation médecin-malade « paternaliste ».
Un médecin pouvait ainsi estimer qu'informer sur les risques était nuisible à l'intérêt du patient, et qu'en tant que médecin c'était à lui de décider sans « jamais faire courir de risque grave », cette dernière notion restant à la discrétion du médecin.Une approche de la notion de « risque admissible » apparaît dans le rapport Belmont (1978), texte de la Commission nationale américaine sur les principes de l'expérimentation humaine.
Ce texte rappelle qu'aucune activité humaine n'est sans risque, et que tout projet de recherche doit être soumis à une évaluation des risques courus par les sujets de recherche.
Il propose une distinction entre les « risques minimes » qui sont ceux de la vie quotidienne, et des risques « plus que minimes » qui ne seraient admissibles que par la qualité du consentement, ce qui exclut le recrutement de sujets « vulnérables ».Ce texte dénonce l'injustice consistant à expérimenter sur des populations pauvres des traitements destinés à ne bénéficier qu'aux populations les plus aisées.
En 1982, l'OMS critique la tendance des pays développés à délocaliser la recherche vers des régions du Tiers-Monde.Le principe de bienfaisance ou de solidarité implique des conflits entre plusieurs biens : comme le risque individuel pris pour un bien collectif attendu (pour les malades futurs), l'intérêt de la connaissance et le bien des malades inclus dans l'essai.
Dans les sociétés libérales, il existe une inégalité entre les personnes qui acceptent de participer à un essai, et celles qui attendent qu'on ait testé sur d'autres, qui est parfois compensée par de l'argent.En 1975, la Déclaration de Tokyo de l'AMM stipule que les chercheurs doivent d'abord rédiger un projet de recherches soumis à un comité indépendant créé à cet effet.
C'est le début des comités d'éthique.
Dans la loi française de 1988, la Loi Huriet-Sérusclat, ces comités sont composés pour un tiers de personnes extérieures aux professions de la santé.Toutefois, les procédures mises en place dans les pays développés, même si elles contrôlent et encadrent mieux les pratiques, sont loin de résoudre tous les problèmes., notamment au niveau international, dans les pays sans assurance-maladie obligatoire, où les malades sont soignés gratuitement, mais aussi sujets à essais en contrepartie.L'existence d'une contradiction, ou d'un conflit, au sein même de l'expérimentation humaine, et le manque de vérité définitive sont largement reconnus.
D'autant plus que de nouveaux problèmes sont apparus à la fin du XXe siècle comme les expérimentations sur l'embryon, les gamètes, les tissus, cellules, et molécules humaines, qui sont aussi des « expérimentations sur l'Homme ».L'approche dominante est de considérer que l'homme doit être traité comme une fin et pas seulement comme un moyen.
Il y aurait une part tragique de l'homme qui se traduit existentiellement par l'obligation du choix et du risque.
L'expérimentation humaine serait alors un carrefour menant au meilleur ou au pire.Pour d'autres, le concept de sujet universel, ou de transcendance de la personne (sujet ou être humain), ne peut rendre compte de l'expérimentation humaine réelle et concrète.
Celle-ci ne relèverait pas d'une philosophie morale, mais d'une philosophie politique, celle des rapports de pouvoirs sur des « corps vils » ou « populations effacées du regard » .
L'hépatite B est une hépatite virale due à une infection par le virus de l'hépatite B (VHB) et entraînant une inflammation du foie.Les symptômes de la maladie aiguë sont essentiellement une inflammation du foie, avec ou sans ictère et des troubles digestifs avec nausées et vomissements.
À ce stade l’évolution est souvent bénigne même si l’hépatite B est la forme la plus grave des hépatites virales.
Cependant, il existe bien que rarement, des formes fulminantes à évolution mortelle.
L'infection passe souvent inaperçue lors de l'infection aiguë et chez le patient porteur du virus.
Dans près d'un cas sur dix, l'hépatite B aiguë ne guérit pas et devient une infection chronique.
Le porteur chronique n'a pas de symptôme apparent mais est susceptible de contaminer son entourage.
En cas d'hépatite chronique active, les symptômes peuvent être une fièvre modérée, une grande fatigue, des troubles digestifs (nausées, vomissements, douleurs abdominales), une jaunisse, des urines foncées ou des selles décolorées.La gravité potentielle de l’hépatite B est constituée par le risque d’évolution vers une hépatite chronique B qui peut se compliquer d’une cirrhose et d’un cancer du foie, une maladie mortelle avec un taux de réponse très faible à la chimiothérapie actuelle.La transmission du virus se fait par l'intermédiaire des liquides et sécrétions biologiques.
Les principaux modes de transmission sont les rapports sexuels, les injections chez les toxicomanes, les transfusions sanguines à risques, la transmission de la mère à l'enfant lors de l'accouchement et le contact étroit avec une personne infectée.
Une fois dans le sang, le virus atteint le foie et se multiplie dans ses cellules, les hépatocytes.
Le système immunitaire détruit les cellules infectées, entraînant une inflammation du foie.Il s'agit d'un virus à ADN responsable d’une forme particulière d’hépatite virale, une maladie initialement connue sous le nom d’hépatite sérique et à l’origine d’épidémies dans certaines parties de l’Asie et de l’Afrique.
L'hépatite B est endémique en Chine et diverses autres parties de l’Asie.L'hépatite B est l'une des maladies humaines les plus fréquentes.
La proportion de la population mondiale actuellement infectée par le virus est estimée, suivant les différentes évaluations entre 3 et 6 %, mais jusqu'à un tiers de la population a été exposé.
Dans le monde en 2005, environ 2 milliards de personnes ont été infectées dont plus de 350 millions deviennent des porteurs chroniques pouvant transmettre le virus pendant des années.
Ces porteurs chroniques ont un risque élevé de décéder des suites d'une cirrhose ou d'un cancer du foie, ces deux maladies faisant environ un million de morts chaque année.Le virus de l'hépatite B est le seul virus provoquant une hépatite virale chronique contre lequel on dispose d'un vaccin,.Le virus de l'hépatite B (VHB) est un virus à ADN appartenant à la famille des Hepadnaviridae.
La particule virale (virion) se compose d'une enveloppe extérieure lipidique et d’un noyau, un nucléocapside de forme icosaédrique composé de protéines.
Le nucléocapside entoure l’ADN viral et une ADN polymérase, qui a également une activité de transcriptase inverse.Le VHB, comme le Virus de l’Hépatite C (VHC), peut survivre à la dessiccation contrairement au VIH.
Le VHB est encore infectieux après sept jours de dessiccation, alors que le VHC reste infectieux pendant quelques semaines.
Il résiste également à des procédés de stérilisation à température insuffisante.Le réservoir du virus de l’hépatite B est humain et la contagiosité élevée du virus, 50 à 100 fois supérieure à celle du VIH.Dans le sang d'un malade en phase active de synthèse virale, 3 types de structures sont observées : L'enveloppe extérieure contient des protéines qui protègent la structure virale, et lui permettent de pénétrer dans les cellules cibles.
Ces particules ne sont pas infectieuses et sont composées de lipides et de protéines, qui font partie de la surface du virion, qu’on appelle l'antigène de surface (AgHBs), et qui est produit en excès pendant la durée de vie du virus.Le génome du virus de l'hépatite B est fait d’ADN circulaire, mais il est inhabituel parce que l'ADN n'est pas totalement bicaténaire.
Une extrémité est liée à l’ADN polymérase du virus.
Le génome est composé de 3 020 à 3 320 nucléotides (pour le brin le plus long) et de 1 700 à 2 800 nucléotides (pour le brin le plus court).
La partie enroulée en sens négatif, (non codante), est complémentaire de l'ARNm viral.
L'ADN viral est retrouvé dans le noyau peu de temps après l'infection de la cellule.
La partie d'ADN double brin est rendue totalement bicaténaire par l'appariement du brin (+) et l'élimination d'une molécule de protéine du brin (-) et d’une courte séquence d'ARN à partir du brin (+).Les bases non codantes se retirent de l’extrémité du brin (-) et les brins sont appariés.
Il existe quatre gènes codants connus dans le génome, ils sont appelés C, X, P et S.
La protéine du core est codée par le gène C (AgHBc), et son codon de départ est précédé par un autre codon en amont de formule AUG qui initie la production de la protéine pré-core.
L’AgHBe est produit par traitement protéolytique de la protéine du pré-core.
L'ADN polymérase est codée par des gènes p. Le Gène S est le gène qui code l'antigène de surface (AgHBs).
Le gène AgHBs est une longue suite de nucléotides codants, mais qui contient trois séries de codons start (ATG) qui divisent le gène en trois sections, pré-S1, pré-S2, et S.
En raison des multiples codons de départ, il se forme des polypeptides de trois tailles différentes, grande, moyenne et petite (pré-S1 + pré-S2 + S, pré-S2 + S, ou S).
La fonction de la protéine codée par le gène X n'est pas totalement élucidée.Le cycle de vie du virus de l'hépatite B est complexe.
L'hépatite B est l'un des rares virus connus en dehors des rétrovirus qui utilise la transcription inverse dans le cadre de son processus de réplication.
Le virus parvient à se fixer sur la cellule en se liant à un récepteur situé sur la surface de la cellule et entre par endocytose.
Parce que l'ADN du virus se réplique par l'intermédiaire de l'ARN synthétisé par une enzyme de la cellule hôte, l'ADN doit être transféré dans le noyau de la cellule hôte par des protéines appelées chaperones moléculaires.
La partie partiellement bicaténaire de l’ADN viral devient alors totalement double brin et se transforme en anneau fermé d’ADN (cccDNA) superenroulé qui sert de matrice pour la transcription de quatre ARNm viraux.
Le plus grand ARNm, (qui est plus long que le génome viral), est utilisé pour faire de nouvelles copies du génome et pour fabriquer la capside du noyau de protéines et l’ADN polymérase virale.
Ces quatre transcriptions virales subissent un traitement supplémentaire pour former des virions qui sont libérés par la cellule ou retournent dans le noyau et son recyclées pour produire d’autres copies,.
Le long ARNm retourne ensuite vers le cytoplasme où la protéine P du virion synthétise l'ADN par l'intermédiaire de son activité de transcriptase inverse.Le virus est divisé en quatre grands sérotypes (adr, adw, Ayr, ayw) sur la base des épitopes antigéniques présents sur les protéines de son enveloppe, et en neuf génotypes (A-I), sur la base de la similarité d'au moins 92,5 % des séquences géniques au sein d'un même génotype.
Les génotypes ont une répartition géographique et sont utilisés pour retrouver la trace de l'évolution et de la transmission du virus.
Les différences entre les génotypes affectent la gravité de la maladie, son cours évolutif, les risques de complications, la réponse au traitement et peut-être à la vaccination,.La première épidémie enregistrée d'hépatite B est observée par Lurman en 1885 : un foyer de variole a été signalé à Brême en 1883 et 1 289 employés des chantiers navals ont été vaccinés avec la lymphe d'autres personnes ; après plusieurs semaines, et jusqu'à huit mois plus tard, 191 des travailleurs vaccinés sont tombés malades et ont présenté un ictère, une hépatite sérique a alors été diagnostiquée.
Les autres employés, inoculés avec des lots de lymphe différents, sont restés en bonne santé.
La publication de Lurman, aujourd'hui considérée comme un exemple classique d'étude épidémiologique, prouve que la contamination lymphatique était à l'origine de l’épidémie.
Plus tard, de nombreux cas similaires sont signalés à la suite de l'introduction, en 1909, des aiguilles hypodermiques, utilisées et réutilisées de nombreuses fois pour l'administration de Salvarsan dans le traitement de la syphilis.L’existence d’un virus est soupçonnée dès 1947 mais le virus n'est découvert qu'en 1963 quand Baruch Blumberg, un généticien travaillant alors au NIH américain, met en évidence une réaction inhabituelle entre le sérum d’individus polytransfusés et celui d’un aborigène australien.
Il pense avoir découvert une nouvelle lipoprotéine dans la population autochtone, qu’il désigne sous le nom d’antigène « Australia » (connu plus tard sous le nom d’antigène de surface de l'hépatite B, ou AgHBs).
En 1967, Blumberg publie un article montrant la relation entre cet antigène et l’hépatite.
Le nom HBs s'imposera par la suite pour désigner cet antigène.
Pour la découverte de l'antigène et pour la conception de la première génération de vaccins contre l’hépatite, Blumberg recevra le prix Nobel de médecine en 1976.
Les particules virales sont observées en 1970, au microscope électronique.
Le génome du virus est séquencé en 1979 et les premiers vaccins sont expérimentés en 1980.
Différents génotypes (au moins neuf, notés de A à I) sont identifiés, et leur répartition géographique étudiée,.
L'étude en 2018 de 12 génomes du virus dans des ossements vieux de 800 à 4 500 ans, combinée à des résultats moins complets sur 304 autres squelettes anciens, retrace l'évolution du virus et sa parenté avec des virus de l'hépatite B chez les grand singes.
La répartition géographique des génomes anciens n'est pas identique à la répartition actuelle mais elle est compatible avec ce qu'on sait des migrations humaines à l'âge du bronze et à l'âge du fer.
La dérive génétique est estimée à 8–15 × 10−6 substitutions de nucléotides par site et par an, ce qui implique pour la racine de l'arbre généalogique des virus de l'hépatite B un âge compris entre 8 600 et 20 900 ans.La période d'incubation varie de 45 à 180 jours, mais la moyenne est de 60 à 90 jours, la durée pouvant augmenter ou diminuer selon la gravité de l'infection.La transmission de la maladie résulte d’une exposition au sang infectieux ou à des liquides organiques contenant du sang.
Parmi les voies possibles de transmission, il est noté (mais la liste n’est pas limitative) :Sans intervention, une mère qui est positive pour l’antigène de surface de l'hépatite B présente 20 % de risque de transmettre l'infection à sa progéniture au moment de la naissance.
Ce risque est supérieur à 90 % si la mère est également positive pour l’antigène e (voir réplication, ci-dessus).
Le virus de l'hépatite B peut être transmis entre les membres de la famille dans la vie domestique, par contact possible entre la peau lésée ou les muqueuses avec la salive ou des sécrétions contenant le VHB.
Cependant, au moins 30 % des cas d’hépatite B rapportés chez l’adulte ne peuvent pas être reliés à un facteur de risque identifiable.Le principal mode de transmission reflète la prévalence du virus de l'hépatite B chronique dans une zone donnée.
Dans les pays à faible prévalence des régions telles que les États-Unis et l’Europe de l'Ouest où moins de 2 % de la population est chroniquement infectée, l'abus de drogues par injection et les rapports sexuels non protégés sont les principales voies de transmission, bien que d'autres facteurs puissent avoir leur importance.
Dans les zones de prévalence modérée, qui comprennent l'Europe de l'Est, la Russie, et le Japon, où 2 à 7 % de la population est chroniquement infectées, la maladie est essentiellement répandue chez les enfants.
Dans les zones de haute prévalence des régions comme la Chine et l’Asie du Sud-Est, la transmission pendant l'accouchement est la plus fréquente, bien que dans d'autres zones de forte endémicité comme l’Afrique, la transmission au cours de l'enfance soit un facteur important.La prévalence de l'infection chronique par le virus de l'hépatite B dans les zones de forte endémicité est d'au moins 8 %.Des niveaux variés de séroprévalence du VHB sont expliqués par le contexte socio-économique et de vaccination : il permet de faibles prévalences, par exemple dans l’Ile de La Réunion (où seulement 0,7 % de la population est touchée), alors qu'en Afrique noire ou à Madagascar il dépasse souvent 15 % (ex.
: à Madagascar, la prévalence est de 16 %, en raison de fréquentes transmission mère-enfant et du faible usage du préservatif, ce qui favorise une fréquente transmission sexuelle).En France métropolitaine, une enquête réalisée en 2004 par l'Institut de veille sanitaire a montré que 0,65 % des adultes, soit plus de 280 000 personnes, étaient porteurs chroniques de l'antigène HBs.
Seule une personne sur deux savait qu'elle était séropositive.Depuis l'essor de la vaccination, la prévalence de l'hépatite B est en forte diminution dans les pays qui ont mis en place une stratégie de vaccination universelle.Le virus de l'hépatite B interfère d’abord avec les fonctions du foie en se répliquant dans les cellules hépatiques, connues sous le nom d’hépatocytes.
Au cours de l'infection par le virus de l'hépatite B, la réponse immunitaire hépatocellulaire est responsable à la fois des lésions hépatiques et de l’élimination du virus.
Bien que la réaction d’immunité naturelle ne joue pas un rôle important dans ces processus, la réponse immunitaire adaptée, en particulier celle des cellules T cytotoxiques spécifiques du virus (CTLs), contribue à la formation de la plupart des lésions hépatiques associées à l'infection par le VHB.
En tuant les cellules infectées et en produisant des cytokines antivirales capables d’éliminer le virus de l'hépatite B des hépatocytes viables.
Bien que l'atteinte hépatique soit initiée et réalisée par les CTLs, les cellules inflammatoires non spécifiques d’un antigène peuvent aggraver les lésions immunopathologiques induites par les CTL, et l’activation des plaquettes sur le site de l'infection peut faciliter l'accumulation des CTLs dans le foie.L’infection par le virus de Hépatite B peut, soit être aiguë (guérison spontanée) soit chronique .
Les personnes dont le système immunitaire peut contrôler l'infection guérissent spontanément dans un délai d’une semaine à plusieurs mois.Les enfants sont moins susceptibles que les adultes de guérir de l'infection.
Plus de 95 % des personnes qui sont infectés tardivement dans l’enfance ou à l’âge adulte se rétabliront complètement et développeront une immunité protectrice contre le virus.
Toutefois, seulement 5 % des nouveau-nés qui contractent l’infection de leur mère à la naissance peuvent éliminer le virus.
Parmi ceux qui sont infectés entre l'âge de un à six ans, 70 % guérissent de l'infection.L’hépatite B aiguë est peu fréquente, elle se caractérise par un syndrome pré-ictérique (coloration jaune de la peau et des muqueuses par défaillance d’une enzyme hépatique).
Elle survient après une période d'incubation de 2 à 3 mois.
L'hépatite B aiguë se présente sous différentes formes :L’effet cytopathogène du virus lui-même est peu important.
Les lésions hépatiques sont, en réalité, dues à un ensemble de réactions immunologiques à médiation principalement cellulaire.
La destruction des hépatocytes par le système immunitaire conduit à la libération d’enzymes hépatiques, comme l’alanine aminotransférase (ALAT) et l’Aspartate Aminotransférase (ASAT).
L’augmentation des taux de transaminases sériques est donc facilement détectable et signe une cytolyse hépatique importante.Dans le cas d’une hépatite chronique active, la réaction immunologique est dirigée contre les hépatocytes où a lieu la réplication virale et qui expriment à leur surface les antigènes HBc et HBe.
L’absence d’efficacité absolue des thymocytes cytotoxiques peut être liée :L’infection chronique est définie par la persistance de l’antigène HBs pendant plus de 6 mois après la contamination virale.
Elle est le plus souvent asymptomatique.
Le plus courant des symptômes étant une asthénie, qui peut être due à de multiples causes.
Ainsi, l’infection au VHB est très souvent découverte tardivement et de manière fortuite.
Par exemple, lors d’un don du sang, d’une grossesse ou d’un bilan sanguin.
Le portage chronique du VHB est confirmé par l’absence d’anticorps anti-HBs.
L’hépatite chronique est caractérisée histologiquement par des lésions hépatiques associant nécrose hépatocytaire, infiltrat inflammatoire et fibrose.Le passage à la chronicité est inversement proportionnel à l’âge auquel survient l’infection.
Ce risque est majeur quand l’infection survient avant l’âge de 5 ans (90 % des enfants infectés avant l'âge d'un an, et 30 % à 50 % des enfants infectés entre un an et quatre ans, vont développer une infection chronique).Classiquement, une infection chronique par le VHB sauvage évolue en 3 phases successives.Sur le plan de la sérologie, la première phase, multiplication intense du VHB, est caractérisée par la présence des marqueurs de réplication virale dans le sérum, à savoir ADN du virus et antigène HBe.
Cette phase dure de une à plusieurs années.La deuxième phase, phase dite de séroconversion HBe, au cours de laquelle la réponse immunitaire s’intensifie.
Il y a diminution, puis disparition dans le sérum des marqueurs de réplication virale, d’abord l’ADN puis l’antigène HBe.
L’activité de la maladie hépatique est à ce moment très forte et peut conduire à des lésions sévères : fibrose extensive, voire cirrhose.
Plusieurs tentatives de séroconversion, finalement abortives, sont remarquables au cours de cette phase.Elle ne survient pas dans tous les cas.
Elle est caractérisée par l’absence des marqueurs de réplication et la présence de l’anticorps anti-HBe.
Toutefois, bien que l’ADN ne soit plus détectable dans le sérum par les techniques d’hybridation classiques, il persiste une faible multiplication détectable par PCR.
Durant cette phase, l’activité de la maladie hépatique est faible, voire nulle.
Mais, il peut se reproduire une réactivation pendant cette phase.Ces trois phases ont en commun la présence de l’antigène HBs dans le sérum.La cirrhose représente environ 20 % des évolutions naturelles des hépatites chroniques.Une forte consommation d’alcool, supérieure à 20 grammes par jour pour les femmes et supérieure à 30 grammes par jour pour les hommes, est un facteur de risque important dans le développement d’une cirrhose.Le virus de l’hépatite B est un puissant carcinogène.
Le risque de développer un hépatocarcinome est multiplié par 100 chez les porteurs du virus de l’hépatite B.Après vaccination contre le VHB, il a été démontré une diminution de la fréquence d’apparition de carcinomes hépatocellulaires.Plusieurs mécanismes, directs et indirects, ont été suggérés pour l’induction de l’hépatocarcinogénèse par le VHB.
Les mécanismes indirects incluent les lésions, comme la nécro-inflammation et la fibrose, induites par une infection du foie par le VHB.
La cirrhose peut régresser partiellement sous traitement antiviral.La complication classique de la cirrhose est le risque de survenue d'un cancer du foie.
Le génome du VHB ne renferme pas d’oncogène.
L’intégration du génome viral peut parfois activer l’expression d’oncogènes cellulaires contrôlant la multiplication cellulaire, par mutagenèse insertionnelle.
Dans des tumeurs hépatiques associées au VHB, l’activation de certains facteurs de croissance a pu être montrée.
La dérégulation de facteurs suppresseurs de tumeurs a aussi été mise en évidence dans certains cas.Par exemple, une mutation ponctuelle dans le gène de p53 conduirait à une protéine mutée responsable de la prolifération des hépatocytes.
Une intégration de la région X du génome viral du VHB dans le génome cellulaire peut également être responsable de mécanismes de transformation cellulaire par transactivation de gènes.L’infection par le virus de l’Hépatite D peut se produire seulement en cas d'infection concomitante par le virus de l'hépatite B parce que le virus de l'hépatite D utilise l’antigène de surface du virus de l'hépatite B pour former une capside.
La co-infection par l'hépatite D augmente le risque de cirrhose et de cancer du foie.
La périartérite noueuse est plus fréquente chez les personnes infectées par le virus de l'hépatite B.La gravité de l’infection par le VHB est essentiellement liée à l’évolution possible de l’hépatite chronique vers la cirrhose et l’hépatocarcinome.
Le diagnostic repose largement sur la sérologie.L’examen clinique, chez un porteur chronique de l’hépatite B, est normal, si ce n’est l’existence d’une asthénie modérée dans certains cas.
Dans le cas d’une hépatite chronique active, certains symptômes peuvent apparaître.
Ce sont une petite fièvre, une augmentation du volume du foie et/ou de la rate (hépatomégalie et/ou splénomégalie), des poussées ictériques (symptômes d’allure pseudo-grippale : céphalées, douleurs articulaires et musculaires, mais aussi nausées, diarrhée, urines foncées) et des manifestations extra-hépatiques, dues aux dépôts de complexes immuns (exemple : péri artérite noueuse).En cas de cirrhose, des signes cliniques d’insuffisance hépatocellulaire et d’hypertension portale sont constatés.Le diagnostic spécifique d’hépatite virale à VHB repose sur la détection de certains marqueurs sériques :La détection des antigènes se fait via des tests RIA (Radio Immuno Assay).
La recherche d’ADN du VHB sérique se fait par des techniques d’hybridations moléculaires (PCR).Les dosages utilisés pour la détection de l’infection par le virus de l’hépatite B comprennent des tests plasmatiques ou tests sanguins qui détectent soit l’antigène viral (une protéine produite par le virus) ou des anticorps produits par l’hôte.
L’interprétation de ces tests est complexe.L’antigène de surface de l'hépatite B (AgHBs) est le plus souvent utilisé pour le dépistage de cette infection.
Il est le premier antigène viral détectable à apparaître au cours de l'infection.
Toutefois, au début de l'infection, cet antigène peut ne pas encore être présent et il peut être indétectable plus tard dans le cours d’évolution de l'infection car il est éliminé par le patient.
Le virion infectieux contient un noyau le « core » réceptacle du génome viral.
Le core est une particule icosaédrique contenant 180 à 240 exemplaires d’une protéine, connue sous le nom d’Antigène du core du virus de l'hépatite B, ou AgHBc.
Au cours d’une « fenêtre » pendant laquelle l’hôte reste infecté mais se défend avec succès contre le virus, les anticorps IgM contre l’antigène du core du virus de l'hépatite B ( IgM anti-HBc ) peuvent être la seule trace sérologique de la maladie.Peu de temps après l'apparition de l'AgHBs, un autre antigène nommé antigène e (AgHBe) apparaît.
Traditionnellement, la présence de l'AgHBe dans le sérum est associée à un taux beaucoup plus élevé de réplication virale et à un renforcement de l'infectiosité.
Toutefois, certains variants du virus de l'hépatite B ne produisent pas l'antigène « e », aussi cette règle n'est-elle pas toujours vérifiée.
Pendant le cours de l’évolution naturelle d'une infection, l'AgHBe peut être éliminé, et des anticorps contre l’antigène « e » (anti-HBe) apparaîtront immédiatement après.
Ce changement est généralement associé à une baisse spectaculaire de la réplication virale.Si l'hôte est en mesure de contrôler l'infection, l'AgHBs deviendra indétectable et sa disparition sera suivie par l’apparition d’anticorps IgG contre l’antigène de surface de l'hépatite B et contre l'antigène du core, (anti-HBs et IgG anti-HBc ).
Une personne négative pour l’AgHBs, mais positive pour les anticorps anti-HBs a, soit guéri d’une infection antérieure, soit été vaccinée auparavant.Les personnes qui restent AgHBs positifs pendant au moins six mois sont considérés comme porteurs du virus de l'hépatite B. Les porteurs du virus peuvent développer une hépatite B chronique, qui se traduira par un taux sérique élevé de transaminases et une inflammation du foie, révélée par la biopsie.
Les porteurs qui sont AgHBe négatifs, en particulier ceux qui ont contracté l'infection à l’âge adulte, ont très peu de réplication virale et, par conséquent, peuvent présenter peu de risque de complications à long terme ou de transmission de l'infection à d'autres personnes.L'hépatocyte dont l'ADN viral s'intégré dans le génome peut continuer produire l'HBs sans qu'il n'y a plus de production de virions complets, ni AgHBc ou AgHBe, alors le sérum n'est plus infectieux.Toutefois, des cultures en lignée continues d'hépatocarcinome humain produisent de l'HBs (particules de 22 nm) mais pas d'HBc ni donc de virus.Plus récemment, les tests PCR ont été développés pour détecter et mesurer la quantité d'acide nucléique viral dans des échantillons biologiques.
Ces tests servent à mesurer la charge virale et sont utilisés pour évaluer le statut infectieux d’une personne et de choisir le traitement à suivre.L'infection par le virus de l'hépatite B ne nécessite habituellement pas de traitement parce que la plupart des adultes guérissent spontanément de l'infection.
Un traitement antiviral précoce n’est requis que pour moins de 1 % des patients, dont l'infection a un cours très agressif (hépatite fulminante) ou qui sont immunodéprimés.Le traitement a pour but d’influer sur l’histoire naturelle de l’hépatite B chronique en raccourcissant sa durée.
Il permet dans certains cas d’éviter l’évolution vers la cirrhose et donc éviter la survenue du carcinome hépatocellulaire.
Le traitement interrompt la réplication du VHB et donc, avance le moment de la séroconversion HBs.Les personnes chroniquement infectées avec persistance d’un taux sérique élevé d’ALAT, un marqueur des lésions hépatiques, et un niveau élevé d'ADN viral du VHB sont des indications du traitement.Bien qu'aucun des médicaments disponibles ne soit capable d’éliminer l'infection, certaines molécules peuvent arrêter la réplication du virus, et prévenir les atteintes du foie comme la cirrhose et le cancer du foie.
Les traitements utilisés sont des médicaments antiviraux tels que la lamivudine, l’Adéfovir et l’entecavir et les modulateurs du système immunitaire tels que l’interféron alpha.
Toutefois, certaines personnes sont beaucoup plus susceptibles de répondre que d'autres et c'est peut-être en raison du génotype du virus infectant ou de l'hérédité du patient.
Le traitement agit en réduisant la charge virale (la quantité de particules virales mesurée dans le sang), ce qui réduit la réplication virale dans le foie.Le 29 mars 2005, aux États-Unis la Food and Drug Administration (FDA) a approuvé l’utilisation de l’entecavir pour le traitement de l'hépatite B. Le 25 février 2005, la Commission européenne approuve le Peginterféron alfa-2a (Pegasys),.
Le 27 octobre 2006, la telbivudine obtient l'approbation de la FDA.
Le médicament est commercialisé sous la marque Tyzeka aux États-Unis et Sebivo en dehors des États-Unis.
Il est autorisé en Suisse.Les nourrissons nés de mères connues comme porteuses de l'hépatite B peuvent être traitée avec des anticorps contre le virus de l'hépatite B (immunoglobulines hépatite B ou IgHB).
Lorsque le traitement est administré avec le vaccin dans les douze heures qui suivent la naissance, le risque de contracter l'hépatite B est réduit de 95 %.
Ce traitement permet à une mère d’allaiter son enfant sans danger.Les analogues nucléosidiques, ou nucléotidiques, sont administrés sous forme de prodrogues.
Les kinases cellulaires vont les phosphoryler dès leur entrée dans la cellule et ainsi former le principe actif.
Dès lors, les analogues nucléosidiques entrent en compétition avec les substrats naturels de la polymérase.
Si cette dernière incorpore un analogue antiviral, l’élongation de la chaîne d’ADN en cours de synthèse se trouve bloquée.
La drogue ne possède pas la structure chimique permettant de former une liaison phosphodiester avec le nucléotide suivant (absence de -OH en 3').Il existe une meilleure affinité de ces analogues antiviraux pour l’ADN polymérase virale que pour la polymérase cellulaire, qui n’est pas encore expliquée.
Cependant, la sélectivité n’est pas absolue et les effets secondaires provoqués par ces drogues s’expliquent en partie par leur action sur les enzymes cellulaires.Les recherches menées sur le VIH ont été mises à profit pour le traitement anti-VHB.
En effet, plusieurs molécules inhibant la transcriptase inverse du VIH sont également actives sur la polymérase du VHB.
La première de ces molécules, autorisée en France, pour traiter une infection chronique au VHB, était la lamiduvine.La lamivudine est un L-nucléoside analogue de la didésoxycytidine.
Elle inhibe la polymérase du VHB par incorporation compétitive avec la didésoxycytidine.
Lors d’un traitement à la lamivudine, par administration quotidienne de 100 mg, le taux sérique d’ADN du VHB chute considérablement, jusqu’à devenir indétectable dans certains cas.
Cependant, dès l’arrêt du traitement, le taux revient rapidement à ses valeurs pré thérapeutiques.Le problème réside dans le mode d’action de cette molécule.
En effet, la lamivudine inhibe la polymérase mais n’a pas d’action sur la formation initiale d’ADN superenroulé et le maintien du pool de cet ADN dans les hépatocytes.
Dans l'hépatite chronique, elle réduit la progression vers la fibrose hépatique.Le composé ARA-AMP, l’adénine arabinoside monophosphate, est un analogue de l’adénosine et inhibe également l’activité de l’ADN polymérase du VHB.
Mais, ce composé étant peu sélectif de l’ADN polymérase virale, il s’est révélé très toxique.Le famciclovir est la prodrogue du penciclovir.
Le penciclovir est un nucléoside analogue de la désoxyguanosine.
Après absorption orale, le famciclovir est transformé en penciclovir par des enzymes hépatiques et digestives.
Le famciclovir est surtout utilisé dans la lutte contre les virus de l’herpès (HSV-1 et HSV-2), du zona (VZV) et le virus Epstein-Barr (EBV).L’Adéfovir, ou PMEA (9-(2-phosphonylméthoxyéthyl) adénine), appartient à une famille récente de drogues antivirales, les phosphonates de nucléotides acycliques.
La forme active di-phosphorylée de l’adéfovir inhibe les virus à ADN et certains rétrovirus.
Le PMEApp, le métabolite actif du PMEA, est un inhibiteur compétitif du désoxy-ATP, substrat naturel de la polymérase du VHB.
Le PMEApp inhibe également les polymérases de VHB mutants résistants à la lamiduvine ou au famciclovir.
Dans l'hépatite chronique, il en améliore l'évolution et rend indétectable l'ADN viral dans 40 % des cas.L’entécavir est un analogue de la cyclopentylguanosine et inhibe spécifiquement la polymérase du VHB.
Cette molécule a une action inhibitrice à la fois sur la synthèse du brin L- (inhibition de l’activité transcriptase inverse) et sur celle du brin S+ (inhibition de l’activité ADN polymérase ADN-dépendante).
Son effet sur les polymérases cellulaires est faible.
Il s’agit d’un L-nucléoside analogue de la thymidine, qui inhibe spécifiquement l’activité de la polymérase du VHB.
Les premiers essais cliniques indiquent une plus grande efficacité de cette molécule par rapport à la lamiduvine, concernant la baisse de la charge virale.
Tout comme l’entécavir, cette drogue bloque la synthèse des deux brins d’ADN viral.Le ténofovir est une molécule proche de l’adéfovir, c’est un analogue de la didésoxy-adénosine.
Il inhibe la polymérase du VHB et du VIH, même dans les formes résistantes à la lamiduvine.
L’efficacité du ténofovir a été démontrée dans les cas d'hépatites chroniques et chez des sujets co-infectés par le VIH et le VHB.D’autres molécules sont en cours d’évaluation clinique, l’emtricitabine (structure proche de la lamiduvine), la clévudine (analogue de pyrimidine), l’elvucitabine et la thymosine peuvent être cité.L’interféron alpha (IFN α) est une cytokine naturellement produite par le système immunitaire.
Au cours des hépatites B chroniques, il existe un défaut de production de l’IFN α par les cellules mononucléées qui pourrait être lié à un effet inhibiteur du virus lui-même.
L’IFN α a un effet antiviral sur l’infection par le VHB via deux mécanismes.
Il a un effet antiviral direct et rapide en inhibant les ARN viraux et en activant des enzymes ayant une activité antivirale, la 2’5’oligoadénylate synthétase et une protéine kinase.La 2’5’oligoadénylate synthétase polymérise 3 à 5 molécules d’ATP par une liaison 2’-5’.
Les oligonucléotides ainsi formés vont activer une RNase, qui va fragmenter les ARN messagers.La protéine kinase, activée par l’IFN α, phosphoryle une sous-unité du facteur d’initiation eIF-2 (eucaryotic Initiation Factor), qui en temps normal, fixe l’ARNt-Met initiateur.
Le complexe d’initiation est ainsi bloqué, tout comme le ribosome sur l’extrémité de l’ARNm à traduire.
Le facteur eIF-2 n’est pas recyclable, la synthèse protéique est bloquée.Cet effet de la kinase sur les ARNm viraux est valable sur les ARNm cellulaires.
La cellule infectée est donc vouée à mourir.De plus, l’IFN α augmente l’efficacité de la réponse immunitaire vis-à-vis des cellules hépatiques infectées, en augmentant l’expression des antigènes d’histocompatibilité de classe I.
Il stimule également l’activité des lymphocytes T helpers et des cellules NK (Natural Killer).La destruction des cellules hépatiques infectées, lors d’un traitement à l’interféron α, conduit donc à une libération du contenu cellulaire dans la circulation, d’où un pic du taux plasmatique des transaminases, ALAT et ASAT.
L’infection conjointe par le VIH semble diminuer l’effet antiviral de l’interféron.Il existe actuellement deux types d’IFN pégylés : IFN pégylé α-2a et IFN pégylé α-2b.
Il s’agit d’IFN alpha auxquels on a attaché un groupement polyéthylène glycol permettant d’allonger la demi-vie de la molécule.
En effet, cette modification chimique augmente le poids moléculaire de la molécule, diminuant ainsi sa clearance rénale.
Cette pégylation de l’IFN alpha a également optimisé sa pharmacocinétique et a permis de rendre son administration hebdomadaire.
L’activité antivirale de l’IFN pégylé est identique à celle de l’IFN α.
Une réponse prolongée et durable après l’arrêt du traitement par l’interféron n’est observée que chez 30 % des patients en moyenne.Lors d’un traitement à l’ARA-AMP (l’adénine arabinoside monophosphate), il peut se développer une neuropathie périphérique, autrement dit, des lésions aux nerfs périphériques pouvant provoquer des engourdissements, des picotements voire une perte de mobilité.D’une manière générale, les traitements à base d’analogues nucléosidiques peuvent provoquer des nausées, maux de tête, vomissements, diarrhées, étourdissements, etc.Lors d’un traitement à l’IFN, un syndrome pseudo-grippal, d’intensité variable, peut survenir chez certains sujets.
La prise de paracétamol permet, habituellement, de bien corriger ce trouble.Elle est indiquée en cas de cirrhose sévère, d’hémorragie digestive ou d’encéphalopathie.
Elle pose essentiellement le problème de la récidive de l’infection par le VHB.
Le risque d’infection du greffon est très élevé, de l’ordre de 80 %.
Le mécanisme de réinfection est mal connu.
Il pourrait se faire à partir de virions persistants dans le sérum ou à partir d’autres sites d’infection comme les cellules mononucléées sanguines.Il s'agit de mutations affectant l’expression de l’antigène HBe.
La détection dans le sérum de cet antigène indique une réplication virale active.
La séroconversion anti-HBe est généralement accompagnée d’une forte élévation des transaminases, indiquant une destruction des hépatocytes infectés.
Cette séroconversion a longtemps été considérée comme le signe de la fin de la réplication virale et le début de la guérison.
Mais, certains patients anti-HBe positifs sont observés et restaient infectieux.
La raison en est l’existence d’une mutation dans la région Pré-C du génome viral.
Elle entraîne l’apparition d’un codon stop prématuré (codon TGG codant un tryptophane remplacé par un codon TAG) lors de la transcription de la protéine p25c, précurseur de l’antigène HBe, et donc, l’absence de synthèse de cet antigène.
Les hépatocytes ne présentent donc pas les épitopes de cet antigène à leur surface et le système immunitaire ne détruit pas ces cellules, pourtant infectées.Il existe également des mutations sur le promoteur du gène pré-C qui vont permettre de conserver la synthèse des protéines HBc, mais dans de moindres quantités.
Les deux mutations les plus courantes à ce niveau sont le remplacement de la base Adénosine par la base Thymidine en position 1762 et le remplacement de la base Guanosine par la base Adénosine en position 1764.Le type de mutants, mutants de l’antigène HBs, est retrouvé chez des groupes d’individus non vaccinés, en tant que population virale minoritaire, mais aussi chez des groupes de sujets vaccinés, où ce type de mutant représente la population virale majoritaire, voire unique.
La plupart des mutations se trouvent dans le déterminant a de l’antigène.
Il semblerait que cette altération de la conformation de ce déterminant soit responsable de l’échappement du virus au système immunitaire.Les hépatocytes et l’ADN superenroulé ont un temps de demi-vie très élevé, ce qui implique, lors d’un traitement par la lamivudine par exemple, que 5 à 10 ans de traitements sont nécessaires pour éradiquer le VHB.
Or un tel délai entraîne l’apparition de mutants résistants aux drogues antivirales.
Au bout de quelques années de traitement, voire quelques mois seulement, la charge virale sérique commence à s’élever.
Dans le cas de la lamivudine, au bout d’un an, 20 % des patients développeront un VHB résistant, et 70 % après quatre ans de traitement.
Une mutation dans le site actif de la polymérase modifie son activité enzymatique mais préserve tout de même la fonction.
Concernant un traitement par l’adéfovir, l’apparition de mutants est moindre, 2 % de cas au bout de 2 ans et 29 % au bout de 5 ans.
la résistance est moindre avec les autres antiviraux mais sont plus récents.L’Organisation Mondiale de la Santé (OMS) estime à 2 milliards le nombre de personnes qui sont ou ont été infectées, dont 370 à 400 millions (100 000 en France) sont des porteurs chroniques.
L’hépatite B entraîne le décès d’un à deux millions d’individus par an, dont près de 1 500 en France.
En effet, la contagiosité élevée du virus est liée à sa présence dans la majorité des liquides biologiques : sang, sperme, sécrétions vaginales et même, en moindre proportion, dans la salive.Le VHB a des facteurs de risques communs avec le VIH, le VHC et le VHD (Virus des hépatites C et D).L’hépatite B est à la fois :Elle repose sur la vaccination, mais aussi sur la détection des porteurs de virus et sur certaines mesures destinées à empêcher la diffusion de ce dernier.Ainsi le dépistage chez tout donneur de sang a entraîné une baisse très sensible de ce mode de contamination, de même les programmes d'échanges de seringues chez les toxicomanes.Dans certains cas, une immunothérapie par injection d'immunoglobulines spécifiques chez le sujet récemment contaminé peut prévenir la survenue de l'hépatite.Depuis 1982, on peut éviter l’infection grâce à un vaccin.
Le vaccin contre l'hépatite B ne guérit pas les porteurs chroniques, mais il est efficace de 90 à 95 % pour prévenir l'apparition de cet état.
Le vaccin anti-VHB est aussi le premier vaccin contre une infection sexuellement transmissible et peut être considéré comme le premier vaccin contre un cancer.La cible dépend de la prévalence de l'hépatite dans le milieu considéré.
Elle est conseillée pour toute la population dans les pays de forte endémie mais peut concerner seulement les personnes jugées les plus à risque dans les pays à faible endémie, même si cette attitude est discutée.Le schéma initialement prévu était le suivant :Le schéma actuellement recommandé est le suivant :De nombreuses études ont documenté l’innocuité du vaccin anti-VHB.
Les réactions à la suite de la vaccination, les plus couramment observées sont des réactions cutanées mineures au point d’injection ou des douleurs musculaires et articulaires transitoires.
Un peu plus d’une centaine d’atteintes démyélinisantes centrales ont été notifiées entre 1989 et 1995 pour environ 17,5 millions de sujets vaccinés en France, soit moins de 0,06 ‰ d’entre eux.
Compte tenu du sexe et de l’âge des sujets vaccinés, les fréquences de scléroses en plaques observées ne sont pas supérieures à celles attendues dans la population générale.En février 2001, deux études, publiées dans la revue New England Journal of Medicine, disculpaient le vaccin de l'hépatite B, accusé de pouvoir entraîner l'apparition de cas de sclérose en plaques : « Vaccinations and the Risk of Relapse in Multiple Sclerosis » (par C. Confavreux et al.)
et « Hepatitis B Vaccination and the Risk of Multiple Sclerosis » (par A. Ascherio et al.)
.En France, l'Académie nationale de médecine rappelle en 2008 que « 8 études nationales et internationales ont démontré l’absence de relation statistiquement significative entre la SEP et la vaccination contre l’hépatite B »,.Cependant, dans l'affaire judiciaire C-621/15 N. W e.a./Sanofi Pasteur MSD e.a., la Cour de justice de l'Union européenne a rendu un arrêt reconnaissant la responsabilité du vaccin dans la survenue d'une sclérose en plaques.Les non ou faibles répondeurs sont :Le tabagisme et l’obésité sont aussi des facteurs favorisant la non-réponse au vaccin.Un vaccin à base d’antigènes de surface PréS2 et S produit par la levure induit des titres en anticorps protecteurs après 2 injections chez 80 à 91 % des sujets qui n’avaient pas été protégés auparavant avec un vaccin « conventionnel ».
Un autre vaccin renfermant les antigènes PréS1, PréS2 et S (vaccin Hepa-Gene-3) a été testé sur des sujets souffrant d’insuffisance rénale et non répondeurs au vaccin classique.
Au bout d’un an, 70 % d’entre eux avaient des titres d’anticorps protecteurs.
D’autres approches existent et sont en cours de recherche comme les vaccins à base d’ADN plasmidique.Ce type de vaccin est basé sur une injection directe d’ADN nu (sans vecteur protéique ou lipidique associé) par voie intramusculaire ou intradermique.
L’ADN est capturé par des cellules et le génome viral est exprimé par celles-ci.
La protéine correspondante est donc synthétisée par les cellules.
Un des avantages majeurs d’un tel vaccin est l’expression à long terme de l’antigène.
Ce qui pourrait permettre d’obtenir une réponse immunitaire plus soutenue et plus durable et donc permettre de supprimer les injections de rappel.
Un autre avantage est la synthèse in vivo de l’antigène et sa présentation sous forme de peptides antigéniques associés aux molécules CMH de classe I, permettant d’induire une réponse cytotoxique médiée par les lymphocytes T CD8+.L’injection d’ADN chez l’humain suscite des interrogations concernant le devenir de cet ADN injecté et la possibilité de son intégration dans un chromosome des cellules hôtes.
Si cela était le cas, une mutagénèse insertionnelle serait possible.Le choix de l’injection d’un tel vaccin au niveau de cellules musculaires n’est pas arbitraire.
En effet, les cellules musculaires sont post-mitotiques et donc, l’absence de divisions favorise peu les intégrations.En Chine, les porteurs de l'hépatite B, plus de 100 millions, feraient l’objet d’une discrimination à l'emploi et l'éducation.
Il existerait environ une vingtaine de lois à caractère discriminatoire.
Des examens sanguins sont demandés dans le cadre professionnel et éducatif.
Les porteurs de l'hépatite B sont exclus d’éducation dès l’école maternelle dans certaines provinces chinoises.
En 2009, l'association Yirenping (yirenping.org), qui fait campagne depuis quelques années en Chine contre la discrimination à l’égard des porteurs de l'hépatite B Chine a lancé une pétition sur Internet, et malgré la fermeture demandée par la cyber police chinoise, a recueilli 2040 signatures adressées à Wen Jiabao.
Un anticorps est une substance produite par le système immunitaire adaptatif dans un organisme vivant pour détecter et neutraliser les agents pathogènes de manière spécifique.
Ce faisant, les anticorps se lient à l'agent pathogène et dirigent vers lui, dans le but de le détruire, les cellules immunitaires dites phagocytes (macrophages, polynucléaires neutrophiles) et/ou les agents du complément.
L'organisme devient alors réfractaire à l’agent envahisseur : il s’immunise.Le terme anticorps réfère à la fonction de lutte contre les agents étrangers à l'organisme qui sont eux appelés antigènes.
Les antigènes et les anticorps, dont la combinaison est à la base de la réaction immunologique d’un organisme contre un agent extérieur, n’ont pas de définition en eux-mêmes, mais se définissent l’un par rapport à l’autre :Il arrive que l'organisme produise des anticorps contre des constituants de lui même, comme on peut l'observer dans les maladies auto-immunes.
On parle alors d'auto-anticorps.La structure générale des immunoglobulines a été décrite en 1959 par Porter à la suite des travaux d'Edelman.
Ces deux chercheurs ont été associés pour le prix Nobel décerné en 1972.
Les immunoglobulines sont des glycoprotéines formées de 4 chaînes polypeptidiques (150 000 uma ou dalton) : deux chaînes lourdes (H pour heavy de 50 000 uma chacune, en violet sur la figure 1), et deux chaînes légères (L pour light de 25 000 uma chacune, en vert) qui sont reliées entre elles par un nombre variable de ponts disulfures (en rouge) assurant une flexibilité de la molécule.
Pour une molécule d'immunoglobuline donnée, les deux chaînes lourdes sont identiques, de même que les deux chaînes légères.
Les immunoglobulines ont une forme en Y (chaque chaîne légère constitue pour moitié un bras du Y) et sont constituées de domaines immunoglobulines de 110 acides aminés environ.
Chaque chaîne légère est constituée d'un domaine constant et d'un domaine variable ; les chaînes lourdes sont composées d'un domaine variable et de trois ou quatre domaines constants selon l'isotype.
Les domaines de type immunoglobuline sont retrouvés dans de nombreuses protéines de fonctions très variables mais toujours impliquées dans des mécanismes d'interactions inter-cellulaires.
Cela a amené à la définition d'une superfamille des immunoglobulines regroupant toutes ces protéines.Les domaines constants sont caractérisés par une séquence en acides aminés très proche d'un anticorps à l'autre, caractéristiques de l'espèce et de l'isotype.
Chaque chaîne légère en possède un exemplaire noté CL.
Les chaînes lourdes comportent, selon l'isotype, trois ou quatre domaines constants CH1, CH2, CH3, (CH4).Les domaines constants ne sont pas impliqués dans la reconnaissance de l'antigène, mais interviennent dans l'activation du système du complément ainsi que dans l'élimination des complexes immuns (anticorps lié à son antigène) par les cellules immunitaires possédant les récepteurs aux fragments constants (RFc).Un anticorps possède quatre domaines variables situés aux extrémités des deux « bras ».
L'association entre un domaine variable porté par une chaîne lourde (VH) et le domaine variable adjacent porté par une chaîne légère (VL) constitue le site de reconnaissance (ou paratope) de l'antigène.
Ainsi, une molécule d'immunoglobuline possède deux sites de liaison à l'antigène, soit un au bout de chaque bras.
Ces deux sites sont identiques (mais destinés à différents épitopes), d'où la possibilité de lier deux molécules d'antigène par anticorps.Le clivage enzymatique spécifique des immunoglobulines permet d'isoler différents fragments :C’est Jacques Oudin qui a forgé, à partir de 1956 les trois mots : isotypie, allotypie et idiotypie, qui sont maintenant utilisés par la communauté scientifique tout entière, et qui expriment l’infinie possibilité d’adaptation de notre système de défense immunitaire.Les immunoglobuline sont subdivisées en classes ou « isotypes », selon la structure des domaines constants des chaînes lourdes : les chaînes γ, α, μ, ε et δ correspondent respectivement aux immunoglobulines IgG, IgA, IgM, IgE et IgD (voir Tableau 1).
Il existe également des sous-classes d'immunoglobulines, reflétant des différences plus fines entre chaînes lourdes.
L'être humain possède ainsi quatre sous-classes d'IgG et deux sous-classes d'IgA.
Il existe également des isotypes de chaînes légères, celles-ci pouvant être κ (kappa) ou λ (lambda).L’allotypie des protéines a été découverte, et nommée, en 1956 par Jacques Oudin.
On pensait auparavant que tous les individus d’une même espèce animale avaient la même spécificité antigénique (il l’a alors appelé spécificité isotypique).
Il a montré que les spécificités antigéniques (allotypiques) varient selon les groupes d’individus d’une même espèce et sont transmises héréditairement suivant les lois de Mendel.C'est en 1956 que Grubb et Laurell ont découvert le système Gm, système de groupe des immunoglobulines IgG, par une technique d'inhibition d'antiglobuline.
Les divers allotypes des chaînes lourdes constituent ce système.
Il permet également de différencier les molécules des quatre sous-classes, IgG1, IgG2, IgG3, IgG4.C.
en 1961 ont découvert le système Km (à l'origine appelé Inv), porté par la chaîne légère Kappa, cet allotype est donc présent sur toutes les classes d'immunoglobulines.Enfin le système ISF situé sur la chaîne lourde γ1 des IgG1, l'expression de cette spécificité augmentant avec l'âge, de 25 % des sujets avant 20 ans à 60 % au-delà de 70 ans, chez les caucasiens.Les allotypes définis par le système Am sont situés sur les IgA, et plus précisément sur les chaînes α2.
Il existe deux isotypes α1 et α2 de chaînes α, caractérisant les sous-classes Am1 et Am2 des IgA.L’idiotypie des anticorps a été découverte, et nommée, en 1963 par Jacques Oudin, en observant que les anticorps possèdent des spécificités antigéniques autres que les spécificités allotypiques et apparemment liées à la fonction anticorps.
Il observa que certains immunsérums ne reconnaissaient que les anticorps ayant servi à leur préparation… Ainsi, les anticorps possédaient-ils des spécificités antigéniques apparemment liées à leur fonction de combinaison avec un antigène et à sa spécificité.
Le système immunitaire de l’individu qui produit des anticorps est capable de réagir, dans des conditions non pathologiques, contre leurs spécificités idiotypiques et contribuer ainsi à la régulation de leur production,.L'idiotype est un paratope propre à une molécule issue d'un seul clone.
Cet épitope fait partie ou est très proche du site de reconnaissance de l'antigène, et est donc situé sur la partie variable, Fab (fragment antigen binding), de l'immunoglobuline.
Autrement dit, le paratope ou sa région voisine d'une immunoglobuline peut être reconnu comme un épitope par certains lymphocytes.
D'où la notion de réseau idiotypique.Au cours de la réponse immunitaire, les anticorps ont trois fonctions principales : se lier à l'antigène, activer le système du complément et recruter des cellules immunocompétentes.Les anticorps ont la capacité de reconnaître et de se fixer de manière spécifique sur un antigène.
Cette spécificité est conférée par la présence de domaines extrêmement variables aux extrémités des anticorps.
La reconnaissance entre antigène et anticorps est par exemple mise à profit dans la lutte contre les toxines bactériennes.
Ces toxines agissent en se fixant sur des récepteurs présents à la surface des cellules de l'organisme, ce qui provoque des dérèglements importants de l'activité cellulaire.
En se fixant sur ces toxines, les anticorps anti-toxine les neutralisent et empêchent les liaisons avec les récepteurs cellulaires (voir figure 2).De la même manière, de nombreux virus et bactéries n'exercent leur pathogénicité qu'après fixation aux cellules de l'organisme.
Les bactéries utilisent des adhésines qui sont des molécules d'adhésion aux membranes cellulaires et les virus possèdent des protéines de fixation sur leur enveloppe externe.
Les anticorps anti-adhésines et anti-protéines de la capside virale bloquent l'action de ces agents pathogènes en se liant sur les molécules de fixation.Les anticorps protègent également l'organisme en déclenchant la cascade du complément.
Il s'agit d'un ensemble de protéines du plasma dont l'activation (par la voie classique dans le cas d'anticorps) permet de détruire des bactéries par perforation et de faciliter la phagocytose, l'élimination des complexes immuns et la libération de molécules chimiotactiques.
Ce qui amène à la lyse de l'élément pathogène.
Ces protéines sériques sont des médiateurs de l'inflammation.Après avoir reconnu un antigène grâce à sa partie variable, un anticorps peut se lier à des cellules du système immunitaire par sa partie constante.
Ces interactions revêtent une grande importance dans le déroulement de la réponse immunitaire.
Ainsi, les anticorps fixés sur une bactérie peuvent se lier aux macrophages et déclencher une phagocytose.
Les lymphocytes NK (Natural Killer) peuvent exercer leur cytotoxicité et lyser des bactéries opsonisées par des anticorps.Les gènes des immunoglobulines subissent une recombinaison V(D)J dans les lymphocytes B. Cette recombinaison est, en association avec les phénomènes d'hypermutation somatique et de variabilité jonctionnelle, la source de leur diversité.
Cela conduit à l'apparition de clones de lymphocytes B, chaque clone exprimant une seule immunoglobuline spécifique d'un seul antigène.
Dans le système lymphatique, les clones exprimant des immunoglobulines d'intérêt seront sélectionnés pour être conservés tandis que ceux exprimant des immunoglobulines reconnaissant des motifs protéiques appartenant au soi seront éliminés.
C'est le principe de sélection clonale.Les IgM sont les premières immunoglobulines produites par les lymphocytes B après la recombinaison V(D)J.Lors de la maturation d'un lymphocyte B, et suivant les stimuli qui ont accompagné cette maturation, les clones de cellules B reconnaissant l'épitope subissent une commutation de classe.
Les cellules B qui expriment des IgM et des IgD peuvent évoluer pour ne plus produire qu'un seul isotype (IgE, IgA et  IgG), en opérant une recombinaison du gène codant le fragment constant (Fc) des chaînes lourdes, mais en gardant intact le fragment variable.
Ce changement de fragment constant est également et plus souvent appelé commutation isotypique.Ce phénomène est possible par le réarrangement des gènes codant les domaines CH : sur le génome, les segments de gène codant un isotype sont successifs et précédés d'une séquence de commutation.
À la réception d'un signal extracellulaire de commutation, le lymphocyte B synthétise une recombinase qui forme une boucle non fonctionnelle entre les séquences de commutation : cette boucle rapproche un segment codant un domaine constant et l'association VDJ déjà formée.Exemple : La production d'interleukine 4+++ aussi IL13 par le lymphocyte Th2 entraîne une commutation isotypique d'une IgM vers une IgE.Un agent pathogène (bactérie, virus, etc.) est reconnu par le système immunitaire par l'intermédiaire d'antigènes.
Un antigène possède généralement plusieurs épitopes différents qui sont autant de sites de liaison aux anticorps.
On peut classer une population d'anticorps selon sa capacité à reconnaître un seul ou plusieurs épitopes.
On parle alors respectivement d'anticorps monoclonaux et polyclonaux.Les anticorps monoclonaux sont des anticorps ne reconnaissant qu'un seul type d'épitope sur un antigène donné (voir figure 3).
Ils sont par définition tous identiques et produits par un seul clone de plasmocyte.Les anticorps monoclonaux sont très largement utilisés en biologie et en médecine, à la fois comme outils de diagnostic et dans des buts thérapeutiques.
Les anticorps monoclonaux utilisés comme médicaments ont tous une DCI se terminant par « mab », acronyme de monoclonal antibody par exemple le rituximab.
Ils sont par exemple utilisés dans les tests de grossesse du commerce, ainsi que dans de nombreux domaines de la recherche en biologie et par de nombreuses techniques (cytométrie en flux, western blots…).
Ils sont aussi de plus en plus utilisés dans les tests en laboratoire d'immuno-hématologie pour rehausser les réactions positives.Produire des anticorps monoclonaux in vitro a longtemps été difficile, en raison de la faible durée de vie des cellules sécrétrices d'anticorps, les plasmocytes.
Les anticorps étaient alors obtenus in vivo en injectant chez l'animal un antigène donné et en recueillant les anticorps dans son sang.
Cette méthode coûteuse ne donnait qu'une faible quantité d'anticorps, pollués par de nombreuses impuretés.À la fin des années 1970, César Milstein et Georges Köhler ont développé la technique des hybridomes.
L'antigène est injecté chez l'animal, et des cellules de rate en sont prélevées après quelques semaines.
Dans ces cellules se trouvent des plasmocytes sécrétant des anticorps dirigés spécifiquement contre l'antigène choisi.
Ces plasmocytes sont alors fusionnés in vitro avec des myélomes, qui sont des cellules tumorales ayant la propriété de se multiplier indéfiniment.
Les cellules hybrides obtenues (dites hybridomes) sont sélectionnées puis multipliées dans un milieu de culture approprié.
Elles y produisent des anticorps monoclonaux, très purs et en quantités importantes.Le génie génétique permet aujourd'hui de produire des anticorps monoclonaux utilisables en pratique clinique humaine.
Mais la plupart des anticorps étant produits dans des cellules de rongeurs (souris, rat, hamster, lapin plus rarement poulet, mulet), ils déclenchent une réaction immunitaire lors de leur injection à un patient.
Cette immunité inactive diminue progressivement l'action bénéfique de l'anticorps.
Pour éviter cela, on cherche à produire des anticorps chimériques « humanisés », modifiés par génie génétique pour remplacer au maximum les fragments constants Fc de l'espèce d'origine par des fragments humains.En cas de pandémie (de grippe aviaire) par exemple, l’immunothérapie passive des malades par des anticorps monoclonaux est une des solutions envisagées par les chercheurs qui en 2007 testaient déjà son efficacité sur l'animal, avec des résultats laissant penser que des anticorps monoclonaux d'origine humaine pourraient être produits à partir du sang de patients ayant guéri d'une grippe à H5N1 (ou de convalescents le cas échéants) et contribuer à enrayer une épidémie et à limiter le nombre de morts (en prophylaxie unique, ou comme traitement complémentaire).Les anticorps polyclonaux sont un mélange d'anticorps reconnaissant différents épitopes sur un antigène donné, chaque idiotype étant sécrété par un clone de plasmocytes différent.
Au cours de la réponse immunitaire, un organisme synthétise des anticorps dirigés contre plusieurs épitopes d'un antigène : la réponse est dite polyclonale.
In vivo, la réponse est toujours polyclonale, sauf cas exceptionnels (vaccination par exemple).
Cet exemple est en fait un exemple d'anticorps polyclonal monospécifique qui est en fait un anticorps qui reconnaît différents épitopes du même antigène.
Un autre exemple concerne les anticorps anti-RH1.
Une personne immunisée produit une multitude d'anticorps, donc polyclonaux, qui reconnaissent différents épitopes de la protéine RHD.
Les anticorps monoclonaux utilisés au laboratoire ne reconnaissent chacun qu'un seul épitope de cette molécule.
D'où le fait que certains variants de cette molécule peuvent être reconnus par un réactif — et donc étiquetés comme Rhésus Positif dans un laboratoire — et ne pas être reconnus par un second réactif — et donc étiquetés comme Rhésus Négatif dans un autre laboratoire.Les anticorps comptent aujourd'hui « parmi les outils les plus couramment utilisés dans les sciences biologiques » et notamment dans le domaine biomédical, de la biologie moléculaire, de l'épigénétique, de la protéomique, mais aussi en microscopie à fluorescence, pour la sérologie ou encore comme abzyme.
Le dosage sanguin des immunoglobulines spécifiques permet d'établir ou confirmer certains diagnostics médicaux.Autrefois les chercheurs devaient produire eux-mêmes les anticorps qu'ils utilisaient, puis des entreprises les ont commercialisés (vers 2010, environ 300 entreprises commercialisent plus de 2 millions d'anticorps, vendus aux chercheurs dans un marché qui en 2011 a atteint environ 1,6 milliard $, selon le consultant américain Frost & Sullivan).
Or, de nombreux travaux ont montré que beaucoup des anticorps commercialisés ne sont pas fiables (ex.
: en 2011, une évaluation de 246 anticorps utilisés en épigénétique a démontré qu'un quart de ces anticorps échouaient aux tests de spécificité (ce qui signifie qu'ils se lient à deux cibles ou plus).
De plus, quatre de ces 246 anticorps se liaient très spécifiquement à une protéine, mais qui n'était pas la protéine-cible).En octobre 2015, un sondage réalisé par le GBSI montrait que 52 % des chercheurs n'arrivaient pas à authentifier l'identité de lignées cellulaires, qui peuvent facilement être contaminées avec des variétés indésirables de cellules à croissance rapide.
C’est un problème qui peut induire de graves biais scientifiques d’interprétation.
Une alerte était également donnée sur l'utilisation anarchique des anticorps.
Plusieurs études mettent en cause la reproductibilité de nombreuses expériences scientifiques.
De nombreux auteurs pensent que les anticorps sont l'un des moteurs importants de la « crise de reproductibilité » (ex.
: les conclusions de 47 sur 53 travaux de recherche historiques sur le cancer basés sur l'utilisation de marquage par des anticorps n'ont pas pu être reproduites.
L'une des évaluations les plus larges a été faite par et pour l'Atlas des protéines humaines, un consortium suédois visant à produire des anticorps pour chaque protéine du génome humain.
Il a étudié environ 20.000 anticorps commerciaux mis sur le marché et conclu que moins de 50 % pouvaient être utilisés efficacement pour cartographier la distribution des protéines dans des échantillons conservés de tissus ; souvent ils sont efficaces dans certaines conditions, mais sources d'erreurs catastrophiques dans d'autres).
Selon des fabricants comme NeuroMab qui produit des anticorps pour les neurosciences, ses anticorps sont livrés avec une liste explicite des types d'expériences pouvant les utiliser, « mais les scientifiques ne suivent pas toujours ces instructions ».
Abgent (société de San Diego en Californie, vendant des anticorps) qui est aussi une filiale de WuXi AppTec basé à Shanghai a testé tous ses anticorps il y a environ un an.
Au vu des résultats, l'entreprise a retiré de son catalogue environ 1/3 de ses références pour monter en qualité devant ses clients, ce qui a permis de faire chuter le nombre de plaintes.Un problème encore plus grave selon Leonard Freedman, président de la GBSI est qu’un nombre encore plus important de chercheurs ne valident pas les anticorps qu’ils utilisent de plus en plus souvent et massivement dans leurs expériences, or il est aussi essentiel que la recherche utilise des anticorps standardisés et ayant une cible précise et parfaitement connue dans les conditions où se fera l'expérimentation car des anticorps peu performants peuvent donner des faux positifs s’ils se lient à d’autres protéines que leur cible supposée.
Ils peuvent aussi produire des « faux négatifs » quand ils ne parviennent pas à se lier à la protéine qu’ils sont supposés cibler.Ces problèmes ont plusieurs fois conduit des scientifiques et des journaux à se rétracter pour des études déjà publiées.
Ils ont aussi conduit des chercheurs à tirer des conclusions fausses ou contestables dans plusieurs études.
Ceci explique en partie aussi le manque de reproductibilité constatée pour certaines études.En 2016, un nouveau sondage fait par le GBSI révèle que dans près d'un tiers des cas, les jeunes scientifiques ne prennent pas le temps de valider les anticorps qu’ils achètent aux fournisseurs commerciaux, même s'ils savent que la pertinence et l’exactitude de leurs résultats dépendent du bon fonctionnement et de l’adéquation de ces réactifs à leur travail.
Deux raisons sont le manque de temps et une confiance excessive dans les produits du marché.
Mais cette enquête révèle aussi que plus de 50 % ont répondu ne pas avoir reçu une formation spécifique sur la manière d'évaluer les anticorps.« Ceci est très inquiétant », commente Matthias Uhlen (de l'Institut royal de technologie de Stockholm, qui dirige un groupe de travail international sur la validation d'anticorps, mais qui n'a pas été directement impliqué dans l'enquête publiée en 2016), notamment car il est important de vérifier par des essais l’adéquation d’un anticorps du commerce à la fonction qu’on veut lui attribuer, car par exemple certains anticorps détectent bien une protéine dans son « dénaturé » (dans les préparations cellulaires) mais pas dans sa forme naturelle qui est replié — ou inversement.
De plus, un anticorps fonctionnant correctement pour un type de tissu ou dans une certaine préparation pourrait produire de faux signaux dans d'autres contextes.Or valider un anticorps est plus compliqué qu'authentifier correctement une lignée cellulaire, et aussi parce que l’étude montre que les jeunes chercheurs (5 ans d’expérience ou moins) le font encore moins que leurs aînés : ils ne sont que 43 % à valider les anticorps qu’ils achètent dans le commerce (« la raison la plus souvent invoquée était le temps à passer pour le faire ») alors que 76 % des chercheurs ayant plus de 10 ans d’expérience disent le faire.18 % des chercheurs en biologie médicale interrogés dans l'enquête de la GBSI ont reconnu qu'ils n’appliquaient aucune des procédures de validation requises, et 15 % des répondants n’étaient pas certains de le faire.Selon Freedman, les problèmes de reproductibilité attribués aux anticorps peuvent être imputés à la fois à un déficit de formation et à l’usage d’anticorps inappropriés, deux causes encouragées par un manque de lignes directrices claires dans les bonnes pratiques.
En outre, les entreprises qui vendent des anticorps ne donnent pas assez d’informations sur leurs performances en tant que réactif, et les auteurs d'articles ne citent pas toujours les numéros de catalogue ni les numéros de clone des anticorps qu'ils ont utilisé).De multiples tentatives ont été faites pour améliorer à la fois la manière dont les chercheurs valident les anticorps, et la manière dont ils rendent compte des anticorps.
Les chercheurs qui utilisent des anticorps dans leurs travaux doivent les enregistrer correctement afin de permettre à leurs recherches d'être reproductibles (et donc testées et qualifiées par d'autres chercheurs).
Moins de la moitié des anticorps de recherche référencés dans les articles universitaires peuvent être facilement identifiés.
Des articles publiés dans F1000 en 2014 et 2015 fournissent aux chercheurs un guide pour signaler l'utilisation d'anticorps de recherche,.À partir de 2015, quelques groupes de chercheurs se sont organisés pour tenter de faciliter la circulation et validation des informations sur les anticorps du commerce en créant les outils suivants : Ces outils ne sont cependant pas très connus de la communauté scientifique.Quelques revues scientifiques (dont le journal Nature) ont également commencé à demander à leurs auteurs de préciser si les anticorps utilisés dans leurs articles scientifiques ont été profilés pour l'application qu'ils en ont fait.Un groupe de scientifiques a demandé en 2015 une révision radicale des procédés de fabrication et de vente des anticorps, et de diffusion de l'information associée.
Ainsi, dans la revue Nature en 2015, Andrew Bradbury (Los Alamos National Laboratory), avec plus de 100 cosignataires, demandait que l'on ne mette plus sur le marché que des anticorps définis jusqu'au niveau de la séquence d'ADN qui les produit, puis fabriqué dans des cellules génétiquement modifiées « recombinantes », de manière à obtenir que des produits strictement standardisés, et que l'on évite la variabilité introduite par la production du même anticorps chez les animaux d'élevage.
Cette proposition rendrait les anticorps 10 à 100 fois plus coûteux mais éviteraient des millions de dollars de pertes dues à des études ratées ou des résultats biaisés.
Cependant, A. Bradbury réclame aussi des informations précises sur les anticorps individuels, or ces informations sont considérées par de nombreuses entreprises comme relevant du secret commercial.
Il faudrait en outre une information complète sur les fonctions avérées de chacun de ces « anticorps recombinants ».Une autre possibilité serait de les faire synthétiser par des virus.En septembre 2016, ces questions seront à nouveau évoquées (et peut-être solutionnées) lors d'une réunion de 3 jours qui réunira des fournisseurs et utilisateurs d'anticorps ainsi que des bailleurs de fonds et des journaux scientifiques à Asilomar (Californie) en septembre 2016, lieu rendu célèbre pour la production de directives sur l'ADN recombinant.
L'hydroxyde d'aluminium, de formule chimique Al(OH)3, est la forme la plus stable de l'aluminium dans les conditions normales de température et de pression.
L'oxyhydroxyde d'aluminium AlO(OH) et l'alumine Al2O3 ne diffèrent de l'hydroxyde d'aluminium que par la perte d'une ou plusieurs molécules d'eau.
L'aluminium possède le même degré d'oxydation dans ces trois composés, qui constituent à eux trois la majeure partie du minerai d'aluminium, la bauxite.Il existe dans la nature plusieurs minéraux de composition Al(OH)3 : la gibbsite, la bayérite, la doyleite et la nordstrandite, dont le plus courant est la gibbsite.La nature chimique exacte de l'hydroxyde d'aluminium est controversée.
La représentation Al(OH)3, constituée d'un ion Al3+ lié à trois ions OH−, est très simplifiée, et le composé est généralement plus ou moins hydraté.
Une représentation plus rigoureuse serait donc Al2O3.xH2O pour les trois oxydes/hydroxydes.L'hydroxyde d'aluminium est amphotère (il peut agir à la fois comme un acide ou une base).
Dans un milieu très acide, la forme présente est Al(OH)2+, et dans un milieu très basique il s'agit de la forme Al(OH)4−.
Ces ions sont les formes prépondérantes en solutions diluées.
En solutions plus concentrées, une polymérisation inorganique peut avoir lieu.
Les ions polymérisés présents peuvent alors être assez complexes.Les sels de l'anion Al(OH)4− (ou des anions similaires comme AlO2−) sont parfois appelés aluminates.L'hydroxyde d'aluminium est utilisé comme adjuvant immunologique dans certains vaccins (vaccins contenant des antigènes purifiés), ce qui a donné lieu à des controverses médicales et médiatiques, notamment sur la myofasciite à macrophages.
L'hydroxyde d'aluminium est également utilisé dans les pâtisseries industrielles.L'hydroxyde d'aluminium est également très présent dans les cosmétiques (« anti-transpirant »).
Certains fabricants de cosmétiques proposent des produits marqués « sans hydroxydes d'aluminium », comme cela a été le cas pour le parabène et le bisphénol A (BPA).L'hydroxyde d'aluminium constitue aussi la base de nombreux médicaments destinés à lutter contre les troubles gastriques.Ce sel trouve une application industrielle comme charge ignifugeante ; son mode d'action est le même que celui de l'hydroxyde de magnésium (déshydratation endothermique).On connaît quatre polymorphes de l'hydroxyde d'aluminium, tous présents dans la nature :
Le sérum est le liquide sanguin débarrassé de ses cellules et des protéines de la coagulation.
C'est le liquide surnageant obtenu après coagulation et centrifugation du sang dans un tube « sec », c'est-à-dire sans inhibiteur de la coagulation.
À l'inverse du plasma, qui lui est obtenu par simple centrifugation sans coagulation préalable (donc prélevé dans un tube contenant des anticoagulants), le sérum est débarrassé des facteurs de coagulation et du fibrinogène, consommés par la coagulation.Ce liquide principalement constitué d'eau, contient des substances dissoutes, qui sont essentiellement : La sérothérapie a pour principe l'injection de sérum pour prévenir ou soigner une infection.
Le terme de sérum s'applique à :
Une toxine est une substance, produite par un être vivant, toxique pour un ou plusieurs organismes vivants.
Elle provoque des troubles chez un autre être vivant pouvant aller jusqu'à sa mort.
Les toxines sont des substances toxiques aux côtés des substances chimiques non produites par des êtres vivants.Le terme biotoxine est parfois employé pour préciser que la substance toxique est produite par les activités métaboliques de certains êtres vivants.
Les toxines sont produites par :Les virus peuvent élaborer des substances toxiques mais généralement pas considérées comme des toxines.La variété des toxines est très grande : il est très difficile de les définir tant leurs modes d'actions, leur nature chimique… sont variés.
Certaines sont mortelles, d'autres provoquent des troubles limités…Elles sont, le plus souvent, sécrétées et qualifiées d'exotoxines les opposant à des endotoxines, substances appartenant à la structure même de l'être vivant et libérées par a lyse microbienne.
Cette distinction n'est plus aujourd'hui considérée comme pertinente.Beaucoup d'entre elles sont des protéines tant chez les bactéries que chez les animaux, avec ou non une activité enzymatique.Elles sont souvent des antigènes capables de déclencher la production d'anticorps.
Ces anticorps sont parfois nommés antitoxines.
Pour les petites molécules non antigéniques, elles sont souvent des haptènes, c'est-à-dire capables de provoquer la formation d’anticorps spécifiques quand elles sont liées à des macromolécules.Distinguer les toxines peut aussi se fonder sur le mode d'administration :Le rôle des toxines n'est pas toujours facile à déterminer.
Il est assez évident pour des prédateurs utilisant le venin pour immobiliser ou tuer l'animal chassé.
Pour une bactérie comme celle de la diphtérie, pas simple de trouver un intérêt de la toxine pour la bactérie !
On peut résumer, au moins pour les toxines animales, (d'après wikipedia en anglais) en :Dans leur mode d'action, deux types peuvent être distingués :Le mode d'action de nombreuses toxines est spécifique :Le pouvoir toxique d'une toxine peut être neutralisé sans perte du pouvoir antigénique.
La toxine détoxifiée devient une "anatoxine" pouvant servir de vaccin.À compléter.La mort de Socrate fait de la cigüe un prototype de poison végétal.Autre molécule toxique pour l'homme :  la ricine.Ces toxines sont essentiellement celles de Dinoflagellés, eucaryotes du règne des Chromista.
Elles sont nommées dinotoxines.Ce sont de petites molécules qui peuvent être des neurotoxines paralysantes ou amnésiantes, des toxines diarrhéinogènes (consommation de coquillages le plus souvent).
Voir l'article Dinophyta.Les venins de serpents sont l'exemple le plus important de toxines animales mais d'autres animaux peuvent produire des toxines dangereuses (hyménoptères comme l'abeille, batraciens par exemple…).Les myotoxines sont de petits peptides basiques trouvés dans les venins de serpent et de lézard.
Ils causent des dommages aux tissus musculaires par un mécanisme basé sur des récepteurs non enzymatiques.
Les organismes qui possèdent des myotoxines comprennent :Les champignons microscopiques produisent assez rarement des toxines.Quelques champignons formant des fructifications bien visibles dans les forêts sont très toxiques quand ils sont consommés.
Le prototype est l'amanite phalloïde.Les champignons microscopiques produisent assez rarement des toxines.
Notons toutefois des toxines produites par des moisissures (Aspergillus, Penicillium…) :  les aflatoxines, l'ochratoxine A, la patuline…L'article mycotoxine décrit les différentes toxines mycéliennes et leurs effets.En 1877, Pasteur veut tester l'hypothèse selon laquelle le bacille du charbon ne causerait l'état morbide que de façon indirecte, en produisant un « ferment diastasique soluble » qui serait l'agent pathogène immédiat.
Il prélève le sang d'un animal qui vient de mourir du charbon, le filtre de façon à en ôter les bacilles et inocule le filtrat à un animal sain.
L'animal récepteur ne développe pas la maladie et Pasteur estime (erronément) que cette expérience « écarte complètement l'hypothèse du ferment soluble ».
Dans une publication ultérieure, toujours en 1877, Pasteur note toutefois que le sang filtré, s'il ne cause pas la maladie, rend les globules agglutinatifs, autant et même plus que dans la maladie, et envisage que ce soit l'effet d'une « diastase » formée par les bacilles.Après ce demi-échec de Pasteur, Loeffler, en 1884, constate que, chez les animaux morts à la suite d'une inoculation du bacille de la diphtérie, les microbes restent proches du point d'inoculation et en conclut que le bacille « doit sécréter un poison, une toxine, qui, elle, ne reste pas in loco, mais envahit tous les organes vitaux du corps ».
Cette toxine (toxine diphtérique) pressentie par Loeffler fut isolée en 1888 par les pasteuriens Roux et Yersin, qui démontrèrent son caractère pathogène.
C'était l'entrée officielle de la notion de toxine dans la microbiologie.De nombreuses bactéries produisent des toxines provoquant des troubles importants.Quelques exemples :Les propriétés de ces toxines sont aussi variées que leur nature.
La plupart sont thermosensibles (sauf le LPS et les entérotoxines staphylococciques), antigéniques (le LPS plus faiblement).Le dosage des toxines est réalisé comme celui de nombreuses molécules par des techniques utilisant le plus souvent (au moins pour les protéines) des anticorps spécifiques.
Il s'agit d'immunoenzymologie, de immunochimiluminescence…Le pouvoir pathogène est très rarement utilisé, avec utilisation d’anticorps neutralisants (toxinotypie).
C'est le cas de la toxine botulinique :
Un agent pathogène est un facteur capable d'engendrer une lésion ou de causer une maladie (processus morbide) aussi bien chez les humains que chez les animaux ou chez les plantes.Il existe des agents pathogènes exogènes et endogènes.Les agents pathogènes exogènes sont :Les agents pathogènes endogènes sont :
Un acide aminé est un acide carboxylique qui possède également un groupe fonctionnel amine.
De tels composés organiques ont donc à la fois un groupe carboxyle –COOH et un groupe amine, par exemple une amine primaire –NH2 ou une amine secondaire –NH–.
Dans le monde vivant, on connaît environ 500 acides aminés, dont environ 149 sont présents dans les protéines.
Ces acides aminés peuvent être classés de nombreuses manières différentes : on les classe ainsi souvent en fonction de la position du groupe amine par rapport au groupe carboxyle en distinguant par exemple les acides α-aminés, β-aminés, γ-aminés ou δ-aminés ; on peut également les classer en fonction de leur polarité, de leur point isoélectrique ou de leur nature aliphatique, aromatique, cyclique ou à chaîne ouverte, voire de la présence de groupes fonctionnels autres que le carboxyle et l'amine qui définissent cette classe de composés.En biochimie, les acides α-aminés jouent un rôle crucial dans la structure, le métabolisme et la physiologie des cellules de tous les êtres vivants connus, en tant que constituants des peptides et des protéines.
Ils constituent à ce titre l'essentiel de la masse du corps humain après l'eau.
Ils présentent, à de rares exceptions près, une structure générique du type H2N–HCR–COOH, où R est la chaîne latérale identifiant l'acide α-aminé.
Toutes les protéines de tous les êtres vivants connus ne sont constituées — à quelques exceptions près — que de 22 acides aminés différents, parfois légèrement modifiés, dits acides aminés protéinogènes.
Parmi ceux-ci, 19 acides aminés ne contiennent que quatre éléments chimiques : le carbone, l'hydrogène, l'oxygène et l'azote ; deux acides aminés contiennent en plus un atome de soufre, et un acide aminé assez rare contient un atome de sélénium.
Ces acides aminés forment de longs biopolymères linéaires, appelés polypeptides, dans lesquels les monomères sont unis entre eux par des liaisons peptidiques.
Un acide aminé engagé dans une ou deux liaisons peptidiques au sein d'un polypeptide est un résidu d'acide aminé.
L'ordre dans lequel ces résidus se succèdent dans les polypeptides est la séquence peptidique et est déterminé par les gènes à travers le code génétique, qui établit une relation entre les codons de trois bases nucléiques et chacun de ces résidus.Les acides aminés sont quasiment tous des molécules chirales, dont les représentants naturels sont essentiellement les énantiomères L ; il existe également des acides aminés D dans les parois bactériennes et certains antibiotiques, comme la gramicidine, qui est un peptide non ribosomique.
Outre leur rôle dans les protéines, les acides aminés protéinogènes peuvent également être précurseurs de biosynthèses importantes.
C'est par exemple le cas de la glycine, précurseur de la porphyrine, laquelle donne l'hème des globules rouges, ainsi que de l'acide inosinique, qui donne les bases puriques des acides nucléiques.
En outre, plusieurs acides aminés, protéinogènes ou non, jouent également un rôle central dans la physiologie de l'organisme, indépendamment de leur contribution aux protéines.
Ainsi, la carnitine, un acide aminé non protéinogène, intervient dans le transport des lipides.
Le glutamate (protéinogène) et l'acide γ-aminobutyrique (GABA, non protéinogène) sont, dans le cerveau, respectivement le principal neurotransmetteur excitateur et le principal inhibiteur du système nerveux central.
Il existe par ailleurs de très nombreux autres acides α-aminés biologiques non protéinogènes, dont certains dérivent des acides aminés protéinogènes par modification post-traductionnelle sur les protéines — par exemple la citrulline, qui dérive de l'arginine, et l'acide pyroglutamique, par lactamisation de l'acide glutamique — ou n'entrent pas dans la constitution des protéines — par exemple la DOPA et l'ornithine.
Certains acides α-aminés naturels peuvent également être toxiques, comme l'acide domoïque, qui est une phycotoxine.Neuf des 22 acides aminés protéinogènes sont dits essentiels pour l'homme car ils ne peuvent pas être produits par le métabolisme humain et doivent par conséquent être apportés directement par l'alimentation.
D'autres acides aminés peuvent également être essentiels selon l'âge ou l'état de santé.
La liste des acides aminés essentiels diffère selon les espèces : les ruminants, par exemple, obtiennent plusieurs acides aminés, qu'ils ne synthétisent pas eux-mêmes, à partir des produits de digestion par les microorganismes dans leur réticulorumen.
En raison de leur importance biologique, les acides aminés sont des éléments importants en nutrition et sont couramment utilisés dans les compléments alimentaires.
Diverses technologies font également appel aux acides aminés, par exemple comme engrais, en technologie alimentaire dans l'industrie agroalimentaire, en pharmacie, en chimie fine et en synthèse organique (synthèse asymétrique par exemple).Les acides aminés naturels les plus abondants sont les acides α-aminés, dont font partie tous les acides aminés protéinogènes.
Hormis la glycine, dont la chaîne latérale se réduit à un simple atome d'hydrogène et dont le carbone α n'est donc pas un centre stéréogène, tous ces acides aminés sont des composés chiraux présentant une stéréoisomérie D/L.
Les acides aminés protéinogènes incorporés dans les protéines par les ribosomes sont tous des énantiomères L, mais des acides aminés D peuvent être présents dans des protéines à la suite de modifications post-traductionnelles, notamment dans le réticulum endoplasmique, comme c'est le cas chez certains organismes marins tels que les gastéropodes du genre Conus.
Des acides aminés D sont également des constituants importants du peptidoglycanne de la paroi bactérienne, et la D-sérine jouerait le rôle de neurotransmetteur dans le cerveau.La désignation D/L provient de la position respectivement à droite ou à gauche du groupe –NH2 dans la projection de Fischer, le carboxyle se trouvant en haut dans cette représentation, avec comme ordre de priorité des groupes (selon les règles de Cahn, Ingold et Prelog) :Les acides aminés L naturels ont le plus souvent une configuration absolue S tandis que les acides aminés D ont une configuration R ; la L-cystéine et la L-sélénocystéine, acides α-aminés protéinogènes, présentent cependant une configuration absolue R en raison respectivement de l'atome de soufre et de sélénium liés au carbone β de leur chaîne latérale : les groupes –CH2SH et –CH2SeH prennent la deuxième place devant le groupe –COOH, ce qui inverse la configuration absolue par rapport aux autres acides aminés L.Ces énantiomères sont optiquement actifs : chaque isomère dévie la lumière plane polarisée et est dextrogyre (+) ou lévogyre (-) suivant que la rotation du plan de polarisation de la lumière suit un sens horaire ou antihoraire.
Il n'y a pas de corrélation entre le sens de rotation du plan de polarisation (ou pouvoir rotatoire) et la configuration de l'acide aminé : ainsi la L-alanine est lévogyre et se note L(-)-alanine.
Par convention, il y a correspondance entre la représentation des oses et celle des acides aminés.Certains de ces acides aminés, comme la thréonine et l'isoleucine, possèdent un 2e carbone asymétrique.
Dans ce cas, le composé naturel (2S, 3R) est appelé L, son énantiomère (2R, 3S) est appelé D, les deux autres stéréoisomères (2S, 3S et 2R, 3R) dont les positions relatives des substituants sont différentes sont appelés allo.Les atomes de carbone des acides aminés qui ont une chaîne latérale liée au carbone α, par exemple la lysine représentée ci-contre, sont désignés successivement par les lettres grecques β, γ, δ, etc.
On parle ainsi d'acide α-aminé, β-aminé, γ-aminé, δ-aminé selon l'atome de carbone sur lequel se trouve le groupe amine.On a l'habitude de classer les acides aminés en quatre groupes en fonction des propriétés de leur chaîne latérale :On parle d'acides aminés ramifiés en référence aux acides aminés dont la chaîne latérale est aliphatique et n'est pas linéaire.
Il s'agit de la leucine, de l'isoleucine et de la valine.La proline est le seul acide aminé protéinogène ayant une amine secondaire.
Elle a longtemps été qualifiée d'acide iminé pour cette raison, bien que cette qualification soit désormais obsolète dans la mesure où, en chimie, la fonction imine est distincte d'une amine secondaire.Le groupe carboxyle –COOH est un acide faible, ce qui signifie qu'il tend à libérer un proton pour donner un carboxylate –COO− chargé négativement.
La forme carboxylate est prédominante à pH supérieur au pKa de l'acide carboxylique, c'est-à-dire environ 2,2 pour les acides aminés protéinogènes.
De façon symétrique, le groupe amine –NH2 est une base faible, ce qui signifie qu'il tend à recevoir un proton pour donner un ammonium –NH3+.
La forme ammonium prédomine à pH inférieur au pKa de l'amine, c'est-à-dire environ 9,4 pour les acides aminés protéinogènes.Dans la mesure où, par définition, les acides aminés ont à la fois un groupe carboxyle et un groupe amine, ce sont des molécules amphotères :La présence de deux groupes fonctionnels portant des charges électriques opposées +1 et –1 sur des atomes non adjacents définit un zwitterion.
La forme non ionisée des acides aminés est une espèce chimique extrêmement minoritaire en solution aqueuse — moins de 0,1 ppm — puisque généralement au moins l'un des deux groupes est ionisé.
Les acides aminés sont également présents sous forme de zwitterions en phase solide et ils cristallisent en présentant des propriétés semblables aux cristaux de sel, contrairement à la plupart des acides et amines organiques.Les différents types de courbes de titrage correspondant aux groupes d'acides aminés sont représentés ci-contre.
La forme zwitterionique prédomine aux pH compris entre les deux pKa mais coexiste cependant avec de petites quantités de formes porteuses d'une charge électrique nette positive et de formes portant une charge nette négative.
Au milieu exact entre les deux valeurs de pKa, les quantités de formes chargées positivement et de formes chargées négativement se compensent exactement, de sorte que la charge électrique résultante de toutes les espèces en solution est exactement nulle.
C'est le point isoélectrique, défini par pI = ½ (pKa1 + pKa2), auquel les acides aminés ont une mobilité nulle par électrophorèse.La solubilité des zwitterions est la plus faible à leur point isoélectrique et certains acides aminés, notamment ceux qui ont une chaîne latérale non polaire, peuvent être isolés d'une solution aqueuse par précipitation en ajustant le pH de la solution à la valeur de leur point isoélectrique.Chaque acide aminé ayant des valeurs de pKa légèrement différentes les unes des autres, leurs points isoélectriques diffèrent également légèrement les uns des autres.
Les acides aminés qui ont une chaîne latérale électriquement chargée font en plus intervenir le pKa de cette chaîne, noté pKR.
Ainsi, l'aspartate, le glutamate mais aussi la cystéine ont une chaîne latérale chargée négativement — celle de la cystéine reste cependant faiblement chargée à pH neutre — de sorte que leur point isoélectrique vaut pI = ½ (pKa1 + pKR).
Symétriquement, l'histidine, la lysine et l'arginine ont une chaîne latérale chargée positivement, de sorte que leur point isoélectrique s'exprime par pI = ½ (pKR + pKa2).La plupart des acides aminés subissent facilement la solvatation par les solvants polaires tels que l'eau, ou l'alcool éthylique (particulièrement la proline et l'hydroxyproline) dans lesquels ils sont solubles.
D'autre part, les acides α-aminés sont solubles, mais à un degré moindre, dans les solvants apolaires.
Cette solubilité est largement dépendante des propriétés de la chaîne latérale : la solubilité diminue avec le nombre d'atomes de carbone du radical, mais augmente si ce radical est porteur de fonctions polaires (NH2, COOH) ou hydrophiles (OH).
La tyrosine, en raison son noyau aromatique, est ainsi peu soluble dans l'eau, à raison de 0,38 g L−1 à 20 °C, tandis que la valine, aliphatique mais plus petite, l'est davantage, à raison de 24 g L−1 ; l'arginine, très basique et donc très polaire, est soluble à raison de 150 g L−1, tandis que la cystéine, avec une chaîne latérale courte terminée par une fonction thiol, est très soluble, à raison de 280 g L−1, et la sérine, analogue de la cystéine avec un hydroxyle à la place du sulfhydryle, est particulièrement soluble, à raison de 360 g L−1.Les solutions d'acides aminés sont incolores.
Les acides aminés aromatiques absorbent les rayonnements ultraviolets entre 260  et   280 nm.
Au-dessus de 260 nm, la plus grande partie de l'absorption ultraviolette des protéines provient de leur teneur en tryptophane et parfois en tyrosine et en phénylalanine.
Ces acides aminés ont une telle absorption à cause de leur nature aromatique due à la présence d'un cycle benzénique.Les acides aminés protéinogènes sont les unités de base de construction des protéines.
Ils polymérisent en formant des polypeptides linéaires dans lesquels les résidus d'acides aminés sont unis par des liaisons peptidiques.
La biosynthèse des protéines se déroule sur les ribosomes, qui réalisent la traduction de l'ARN messager en protéines.
L'ordre dans lequel les acides aminés sont liés à la chaîne polypeptidique est spécifié par la succession des codons portés par la séquence de l'ARN messager, lequel est une copie de l'ADN du noyau cellulaire ; ces codons, qui sont des triplets de nucléotides, sont traduits en acides aminés par des ARN de transfert selon le code génétique.
Celui-ci spécifie directement 20 acides aminés, auxquels s'ajoutent deux autres acides aminés à travers un mécanisme plus complexe faisant intervenir, pour la sélénocystéine, un élément SECIS qui recode le codon-stop UGA et, pour la pyrrolysine, un élément PYLIS qui recode le codon-stop UAG.
La planche ci-dessous présente la structure chimique des 22 acides aminés protéinogènes :La page Acide aminé protéinogène donne davantage d'informations sur ces composés.Outre les 22 acides aminés protéinogènes, il existe un grand nombre d'acides aminés dits non protéinogènes.
Certains ne se rencontrent pas dans les protéines, comme la carnitine ou l'acide γ-aminobutyrique, d'autres peuvent être présents dans les protéines à la suite de modifications post-traductionnelles, comme le γ-carboxyglutamate et l'hydroxyproline, ou par substitution à la place d'un acide aminé analogue, comme la sélénométhionine.
Les modifications post-traductionnelles sont souvent essentielles pour assurer la fonctionnalité ou la régulation de la protéine.
Ainsi, la carboxylation du glutamate permet d'accroître la fixation des cations de calcium, et l'hydroxylation de la proline est essentielle à la cohésion des tissus conjonctifs.
Un autre exemple est la formation d'hypusine dans le facteur d'initiation eucaryote (en) EIF5A (en) à la suite de la modification d'un résidu de lysine.
De telles modifications déterminent également la localisation des protéines dans la cellule, dans la mesure où l'addition de groupes hydrophobes est susceptible de permettre à la protéine de se lier à une membrane phospholipidique.La plupart des acides aminés non protéinogènes ne sont jamais naturellement présents dans les protéines.
Ce sont par exemple la lanthionine, le 2-aminoisobutyrate, la déshydroalanine ou encore l'acide γ-aminobutyrique.
Ce sont souvent des intermédiaires sur la voie métabolique de biosynthèse des acides aminés, comme l'ornithine et la citrulline, qui font partie du cycle de l'urée comme intermédiaires de dégradation des acides aminés.
Si les acides α-aminés sont de très loin les principaux acides aminés biologiques en tant que constituants des protéines, la β-alanine offre un exemple d'acide β-aminé biologiquement important, étant utilisée par les plantes et certains microorganismes pour la synthèse de l'acide pantothénique (vitamine B5), un constituant de la coenzyme A, laquelle est un groupe prosthétique très important dans le métabolisme.Les vingt acides aminés protéinogènes encodés directement par le code génétique sont dits standard ; tous les autres acides aminés sont dits non standard.
Deux acides aminés non standard, la pyrrolysine et la sélénocystéine, sont cependant des acides aminés protéinogènes : ils sont en effet encodés de façon indirecte par l'intermédiaire de séquences d'insertion qui recodent des codons-stop en codons de pyrrolysine ou de sélénocystéine.
Ainsi, un élément PYLIS en aval d'un codon UAG recode ce dernier en pyrrolysine, tandis qu'un élément SECIS avec un codon UGA recode ce dernier en sélénocystéine.
En 2003, vingt-cinq sélénoprotéines humaines étaient dénombrées, c'est-à-dire de protéines contenant au moins un résidu de sélénocystéine.Les autres acides aminés non standard sont non protéinogènes.Les acides aminés qui possèdent un cycle aromatique présentent un certain nombre de propriétés particulières.
On compte quatre acides aminés protéinogènes aromatiques : l'histidine, la phénylalanine, le tryptophane et la tyrosine.Il existe par ailleurs un grand nombre d'acides aminés non protéinogènes aromatiques, par exemple la thyroxine, la DOPA ou encore le 5-HTP.Il existe trois acides aminés protéinogènes ramifiés : l'isoleucine, la leucine et la valine.
Ce sont tous les trois des acides aminés essentiels pour l'homme.
Ils représentent 35 % des acides aminés essentiels des protéines musculaires et 40 % des acides aminés essentiels pour les mammifères.Il existe par ailleurs de nombreux acides aminés non protéinogènes ramifiés, par exemple la norvaline et l'acide 2-aminoisobutyrique.La digestion des protéines au niveau intestinal a pour effet de cliver, en les hydrolysant, les liaisons peptidiques qui unissent les résidus d'acides aminés dans les chaînes polypeptidiques.
Cela se produit dans l'estomac et le duodénum sous l'effet d'enzymes digestives, notamment des peptidases, dont la pepsine du suc gastrique et la trypsine et la chymotrypsine du pancréas sont les principales.
Les acides aminés libérés par la digestion des protéines peuvent traverser la paroi intestinale et atteindre la circulation sanguine.
D'autres protéines sont dégradées à l'intérieur même des cellules, libérant également les acides aminés qui les constituent.Les acides aminés eux-mêmes sont dégradés au sein des cellules pour produire de l'énergie métabolique et divers métabolites susceptibles d'être utilisés à leur tour dans le foie pour biosynthétiser d'autres biomolécules, telles que des glucides pour les acides aminés glucoformateurs et des lipides pour les acides aminés lipoformateurs ; les acides aminés cétoformateurs, quant à eux, tendent à produire des corps cétoniques par cétogenèse.
La production de glucose à partir de métabolites cellulaires est la néoglucogenèse, celle d'acides gras est la lipogenèse.
L'élimination du groupe amine –NH2 par une transaminase libère de l'ammoniac NH3, qui est détoxiqué en urée par le foie, tandis que la cétone résultante est oxydée à travers le cycle de Krebs puis à travers la chaîne respiratoire jusqu'à formation de dioxyde de carbone CO2.Les acides aminés qui ne peuvent être synthétisés par l'organisme et doivent être apportés par l'alimentation sont dits « essentiels ».
Chez l'Homme, ils sont au nombre de neuf (voir encadré).
Les douze autres sont produits in vivo par le métabolisme des cellules, l'un d'entre eux, contenant un atome de sélénium, étant finalisé alors qu'il est déjà sur son ARN de transfert.
Certains régimes alimentaires ne permettent pas de synthétiser en quantité suffisante tous les acides aminés non essentiels, et certains d'entre eux doivent alors également être apportés par l'alimentation : l'arginine, la cystéine, le glutamate et la tyrosine.Outre leur rôle de constituants des protéines, les acides aminés protéinogènes peuvent être des métabolites précurseurs de composés biochimiques variés.
Par exemple :Certains acides aminés non standard peuvent être utilisés par les plantes contre les herbivores.
Ainsi la canavanine est un analogue structurel de l'arginine présent chez de nombreux légumes, et notamment chez Canavalia gladiata ou haricot sabre.
Cet acide aminé protège la plante de prédateurs tels que les insectes et peut rendre malade le consommateur humain s'il absorbe des légumes qui en contiennent sans les cuire.
La mimosine est un autre acide aminé présent chez d'autres légumes, notamment Leucaena leucocephala.
Cette molécule est analogue à la tyrosine et peut empoisonner les animaux qui broutent ses plantes.La fonction de tous les acides aminés non protéinogènes, qui peuvent être abondants dans les tissus biologiques, est encore loin d'être comprise pour chacun d'eux.Dans la mesure où les acides aminés sont des composés organiques qui possèdent à la fois une fonction acide carboxylique et une fonction amine, ils peuvent subir la plupart des réactions associées à ces groupes fonctionnels, comme l'addition nucléophile, la formation de liaisons amide et la formation d'imines pour le groupe amine, l'estérification et la décarboxylation pour le groupe carboxyle.
La combinaison de ces groupes fonctionnels permet aux acides aminés d'être des ligands polydentates efficaces pour des chélates métal-acide aminé.
Par ailleurs, les différentes chaînes latérales des acides aminés peuvent elles aussi donner lieu à des réactions chimiques.
La nature de ces réactions dépend de la nature des groupes fonctionnels portés par ces chaînes latérales et varient donc significativement d'un acide aminé à l'autre.Le carboxyle peut former des amides avec les amines :Ra–COOH + RbNH2 → Ra–CO–NHRb + H2OAsparagine et glutamine sont deux exemples de dérivés physiologiques formés suivant cette réaction.L'amidation peut être obtenue in vitro en utilisant des carbodiimides (Ra–N=C=N–Rb).
Le groupe carboxyle est dans une première étape activé par la carbodiimide, puis le dérivé activé ainsi formé réagit avec l'amine.Il existe plusieurs sortes de décarboxylation.
Chimique ou enzymatique par une décarboxylase.
Les décarboxylases sont spécifiques de chaque acide aminé.
La décarboxylation est importante en biochimie car elle aboutit aux « amines biologiques » correspondantes très actives :Ce sont des propriétés générales d'amines primaires.
Deux types de groupes aminos peuvent être distingués: les amines en alpha et l'amine en epsilon de la chaîne latérale de la lysine dont le pK est légèrement plus basique (>8).
La différence des valeurs de pK peut être utilisée pour des modifications sélectives, en contrôlant le pH du milieu réactionnel.L'acétylation des groupements aminos des acides aminés par l'anhydride acétique réduit leurs charges positives et change leurs interactions avec les composants de l'environnement.Avec le méthanal : il se forme le dérivé hydroxyméthyl de l'acide aminé.
Avec les aldéhydes aromatiques, on obtient des bases de Schiff (imine).Une réaction du même type peut se produire in vivo entre acides aminés et oligosaccharides (réaction de glycation des protéines avec les résidus d'acides aminés ayant une fonction amine libre).
Dans les enchainements saccharidiques, le sucre réducteur terminal existe de façon prédominante sous forme cyclique, avec seulement des traces sous forme ouverte.
Une base de Schiff (imine) peut se former avec cette forme minoritaire, consommant ainsi la forme cyclique.In vitro, cette réaction avec les saccharides est généralement réalisée en présence de cyanoborohydrure de sodium (NaCNBH3).
La base de Schiff (imine) formée est ainsi rapidement réduite par les anions cyanoborohydrure en amine secondaire plus stable.La substitution d'un atome d'hydrogène de la fonction amine primaire –NH2 par un groupe aryle (aromatique) conduit à une fonction amine secondaire –NH–.
Par exemple, avec le dinitrofluorobenzène (réactif de Sanger, ou DNFB) il se forme un dinitrophényl-acide aminé coloré, donc dosable.
Il s'agit d'une substitution nucléophile aromatique d'ordre 2, le groupe partant étant l'ion fluorure F−.Cette réaction peut également se produire avec un acide aminé incorporé dans une protéine.
Les dinitrophényl-acides aminés formés correspondent aux acides aminés dont les groupes NH2 sont libres dans la protéine (extrémité N-terminale de la chaîne polypeptidique).Cette réaction a permis en 1953 à Frederick Sanger d'établir la première structure primaire d'une hormone peptidique, l'insuline, ce pour quoi il a obtenu le prix Nobel de chimie en 1958.Elle a lieu avec les isocyanates, en particulier le phénylisothiocyanate (PITC).Le PITC est particulièrement utilisé pour déterminer l'enchaînement des acides aminés dans les chaînes peptidiques.Le phénylthiocarbamyl-aminoacide (PTC-AA) (thiourée) résultant est un composé caractéristique de chaque acide aminé (nature du groupement R).
Il est très stable et détectable dans l'ultraviolet (245 nm).Exemple :C6H5–N=C=S + H2N-CH2–COOH → C6H5–NH–CS–NH–CH2–COOH.Ces réactions permettent de transformer l'amine de l'acide aminé en amide, protégeant l'amine ou y fixant un groupement acyle ayant des propriétés intéressantes (fluorescence...), avec élimination du groupement réactif: Il s'agit d'une transamidificationCes réactions sont utilisées pour la synthèse de dérivés d'acides aminés ou de protéines "marquées" sur leurs fonctions amines libres (dérivés fluorescents, biotinylation par la biotine-N-hydroxysuccinimide...); pour la synthèse de supports chromatographiques par greffage d'acides aminés ou de protéines...Ces chélates stables sont utilisés pour effectuer des réactions chimiques au niveau de R, en synthèse.Certains oxydants attaquent l'acide aminé et réalisent une désamination associée à une décarboxylation.
Au cours de la réaction il y a production de CO2, de NH3 et d'un aldéhyde ayant un atome de carbone de moins que l'acide aminé dont il provient :R–CH(NH2)–COOH → R–CHO + NH3 + CO2.Les oxydants sont variés : eau oxygénée, hypochlorite etc.
Pour rendre cette réaction quantitative, on peut doser CO2 par alcalimétrie ou NH3 par colorimétrie.
L'oxydant le plus utilisé est la ninhydrine (voir la page correspondante).Lorsqu'un acide aminé en solution est chauffé en présence de ninhydrine en excès, il conduit à un chromophore avec un maximum d'absorption à 570 nm (bleu-violet).
L'intensité de la coloration est à la base d'une méthode quantitative pour doser les acides aminés.
La réaction s'effectue en trois étapes.
La première correspond à l'action d'une première molécule de ninhydrine sur l'acide aminé conduisant à un iminoacide et à une molécule de ninhydrine réduite.
La deuxième correspond à l'action d'une deuxième molécule de ninhydrine sur l'iminoacide pour donner un aldéhyde.
Cette deuxième molécule se condense finalement avec la molécule de ninhydrine réduite pour former le chromophore.La coloration n'est pas spécifique des acides aminés.
Elle se produit avec d'autres composés ayant des groupements aminos libres : glucosamine, peptides et protéines.
Cette méthode colorimétrique est une bonne technique pour le dosage d'un acide aminé pur, mais elle est moins valable pour un dosage global car les acides aminés réagissent en donnant des colorations d'intensité variable.
Les iminoacides donnent avec la ninhydrine, une coloration jaune.Les premiers acides aminés protéinogènes ont été découverts au début du XIXe siècle.
Au cours des années comprises entre 1805 et 1935, de nombreux chimistes de renom participent à l'isolement et à l'élucidation de la structure des acides aminés.
Les chimistes français Louis-Nicolas Vauquelin et Pierre Jean Robiquet isolent l'asparagine en 1806 à partir d'asperges, ou Asparagus sativus, synonyme d’Asparagus officinalis, d'où son nom.
Le chimiste britannique William Hyde Wollaston découvre la cystine en 1810 dans un calcul rénal, mais il faut attendre 1884 pour que le chimiste allemand Eugen Baumann isole la cystéine, qui en est le monomère.
En 1819, les chimistes français Henri Braconnot et Joseph Louis Proust isolèrent respectivement la glycine et la leucine.
Justus von Liebig isole la tyrosine en 1846, tandis que la structure de cet acide aminé est élucidée en 1869 par son élève Ludwig Barth zu Barthenau.
Le chimiste germano-autrichien Eugen Freiherr von Gorup-Besanez (en) isole la valine en 1856.
Le biochimiste allemand Karl Heinrich Ritthausen (en) isole l'acide glutamique à partir du gluten en 1866.
La structure de la glutamine et de l'acide glutamique est déterminée en 1872 par William Dittmar.
Le chimiste allemand Ernst Schulze (en) isole la glutamine en 1877, la phénylalanine en 1881 et l'arginine en 1886, et participe à la découverte de quelques autres acides aminés.
La lysine est découverte en 1889 par le chimiste allemand Edmund Drechsel (de).
Le médecin allemand Albrecht Kossel établit la structure de l'histidine en 1896, le chimiste allemand Richard Willstätter celle de la proline en 1900, et le chimiste britannique Frederick Gowland Hopkins celle du tryptophane en 1901 ; ils obtiennent tous trois un prix Nobel par la suite.
Le chimiste allemand Emil Fischer établit la structure de la sérine en 1901, de la lysine en 1902, de la valine en 1906 et de la cystéine en 1908.
La méthionine est découverte en 1922 par John Howard Mueller et sa structure décrite en 1928 par les chimistes britanniques George Barger et Philip Coine.
Le dernier acide aminé standard à avoir été découvert est la thréonine en 1935 par William Cumming Rose (en), qui identifie également les acides aminés essentiels pour l'Homme ainsi que l'apport journalier minimum de chaque acide aminé pour assurer un développement optimal.
Le système Rhésus (parfois appelé groupe) est, avec le système ABO, un des principaux systèmes antigéniques érythrocytaires.
Il doit son nom à un singe d'Asie du Sud-Est, Macaque rhésus (Macaca mulatta), qui servit d'animal d'expérience à la fin des années 1930 dans les recherches sur le sang.
L'association du système antigénique érythrocytaire ABO et du système Rhésus définit les groupes sanguins.Le système antigénique érythrocytaire (Rh) est l'un des 36 systèmes antigéniques érythrocytaires humains connus.
C'est le deuxième système antigénique érythrocytaire le plus important, après le système antigénique  ABO.Les globules rouges présentent à leur surface des antigènes qui varient suivant les personnes.
Un antigène est une macromolécule naturelle ou synthétique qui, reconnue par des anticorps ou des cellules du système immunitaire d’un organisme, est capable de déclencher chez celui-ci une réponse immunitaire.Le système rhésus fait référence spécifique à un de ces antigènes.
Cet antigène est désigné par la lettre D,.
La présence de cet antigène correspond au rhésus positif et l'absence de cet antigène correspond au rhésus négatif.
Si du sang rhésus positif est injecté chez un individu rhésus négatif, celui-ci fabriquera des anticorps anti-rhésus, ceux-ci peuvent agglutiner du sang du macaque rhésus,, ainsi que des personnes Rh+.Le système antigénique Rh comprend en réalité 49 variétés connues de l'antigène, parmi lesquels les cinq antigènes D, C, c, E et e sont les plus importants (D est le plus important).
Le statut Rh(D) d'un individu est normalement décrit par un suffixe positif ou négatif après le type ABO (par exemple, une personne qui est A Positive possède l'antigène A et l'antigène Rh(D), alors qu'une personne qui est A Négative n'a pas l'antigène Rh(D)).
Les termes facteur Rh, « Rh positif » et « Rh négatif » font uniquement référence à l'antigène Rh(D).Les transfusions sont possibles de Rh- vers Rh+ mais pas de Rh+ vers Rh-.
Autrement dit, les personnes ne possédant pas l'antigène et dont le sang est mis en contact avec celui-ci vont développer une réaction immunitaire contre les globules rouges possédant l'antigène et les détruire.Les anticorps anti-RHD sont des anticorps irréguliers de type IgG, acquis à l’occasion d’une transfusion ou d’une grossesse.
Lorsque les globules rouges n’ayant pas l’antigène D, des anticorps contre cet antigène peuvent être produits par l’individu dans le cas d’une exposition.Les anticorps aux antigènes Rh peuvent être impliqués dans des réactions transfusionnelles hémolytiques et les anticorps aux antigènes Rh(D) et Rh(c) confèrent un risque significatif de maladie hémolytique du fœtus et du nouveau-né.La présence du seul antigène e (donc Rh+) entraîne chez une personne transfusée Rh- la production d'anticorps qui vont détruire ses globules rouges.
C'est pour cela qu'il n'est possible de transfuser que des personnes ayant le même groupe ABO et le même rhésus que le receveur.Le nom Rhésus vient de l'extraction du premier sérum test obtenu à partir du sang de lapins traités avec des érythrocytes de singes rhésus (Macaca mulatta).
Les scientifiques ont donc découvert par hasard ce groupe sanguin en premier chez les singes rhésus.
Le terme « Rh » était à l'origine une abréviation de « facteur Rhésus ».
Il a été découvert en 1937 par Karl Landsteiner et Alexander S. Wiener, qui, à l'époque, pensaient qu'il s'agissait d'un antigène similaire présent dans les globules rouges du singe rhésus.
On a appris par la suite que le facteur humain n'est pas identique au facteur du singe rhésus, mais à cette époque, le « groupe Rhésus » et d'autres termes similaires étaient déjà largement utilisés dans le monde entier.
Ainsi, bien qu'il s'agisse d'une appellation erronée, le terme survit.Certaines formes de molécules Rhésus se retrouvent dans la plupart des formes de vie.
Le facteur Rhésus a une origine très ancienne.
Il pourrait descendre d'une molécule appelée protéine de transport de l'ammonium (Amt).
L'Amt se trouve dans tous les êtres vivants, y compris l'Archaea, qui est probablement la plus ancienne forme de vie sur Terre,.
85 % des Suisses ont l'antigène RHD et sont donc rhésus positif.
Les chiffres sont similaires dans la population française, 85 % des personnes sont rhésus positif contre 15 % rhésus négatif.Il existe deux systèmes antigéniques érythrocytaires rhésus : le système antigénique + et -.
L'existence de l'antigène rhésus, suspectée en 1939 par Philip Levine et Rufus E. Stetson, a été découverte par Karl Landsteiner et Alexander Solomon Wiener en 1940.
Leur idée initiale était de mettre en évidence une communauté antigénique entre le singe et l'homme, par immunisation d'un animal afin d'obtenir un sérum test comme cela avait été fait antérieurement pour les antigènes M, N et P1 en 1927.L'expérience a consisté à immuniser un cobaye lapin avec des érythrocytes de singes, et à tester le sérum de ce cobaye ainsi obtenu vis-à-vis de globules rouges humains.Ils ont alors constaté que les globules rouges humains s'agglutinent ou non en présence du sérum de ce cobaye immunisé par des globules rouges de singe rhésus.
Ce sérum contient des anticorps dit anti-rhésus.
Ce même sérum donne une réaction d'agglutination avec les érythrocytes de 85 % environ des sujets testés dans la population caucasoïde.
On dit alors que le sang de ces sujets est rhésus positif (Rh +) ou rhésus négatif (Rh -) dans le cas contraire.Dans la réalité, on s'est rendu compte plus tard que ce sérum test ne reconnaissait pas exactement le même épitope que l'anticorps rencontré chez les sujets rh négatif immunisés décrits par Levine en 1939, et était en fait un anti-LW.
Cette protéine fut nommée, sur proposition de Levine, LW (également ICAM4), faisant partie du complexe membranaire RH avec RHD, RHCE, Rh50 (RHAG), CD47, GPB (glycophorine B, système MNS) à la surface de l'érythrocyte, du nom des auteurs de cette expérience initiale, Landsteiner et Wiener.
Cependant le nom d'origine, rhésus, qui avait déjà donné lieu à de nombreuses publications, a été conservé, et ne s'applique en fait plus à l'épitope initialement découvert, mais à l'épitope Rhésus D ou RH1 dans la nomenclature internationale.En ce qui concerne les nomenclatures RH, il en existe trois, dont deux historiques, mais toujours utilisées.La première, dite nomenclature Wiener, utilise Rh pour les Rhésus positif standard D et rh pour les rhésus négatifs.
R et r représentent les gènes (écrits en italique ou soulignés), Rh et rh les phénotypes (antigènes en caractères romains).
Wiener pensait que ce système ne comportait qu'un gène, à un seul locus, avec plusieurs allèles.La seconde, dite nomenclature de Fisher et Race, est apparue lors de la découverte des autres antigènes du système C, c, E et e. D correspond à l'antigène Rh.
Fisher (statisticien) et Race (immuno-hématologiste) raisonnaient sur trois gènes, à trois locus étroitement liés, avec 2 allèles chacun (D/d, C/c, E/e).Il existait donc la correspondance suivante entre les haplotypes des deux nomenclatures, avec leur fréquence génique constatée en France : et la correspondance suivante des phénotypes : pour le génotype Wiener R1/r, le génotype Fisher Race DCe/dce et les phénotypes correspondants Rh1rh = DCcee.
Inversement on remarquera qu'à un phénotype peuvent correspondre plusieurs génotypes possibles.
Ainsi un sujet DCcEe peut avoir pour génotypes : DCe/DcE = R1/R2 (le plus fréquent en France), DCE/Dce = Rz/R0, DCE/dce = Rz/r, DCe/dcE = R1/r", DcE/dCe = R2/r', Dce/dCE = R0/ry, alors qu'un sujet ddCcee ne peut être que de génotype dCe/dce = r'/r.La troisième nomenclature, actuelle (de R.E. Rosenfield et coll.
au départ), numérique :D = RH1, C = RH2, E = RH3, c=RH4, e = RH5, ... Cw = RH8...G = RH12 ...jusqu'à plus de 50.Cette nomenclature, contrairement aux précédentes, ne préjugeait pas de la génétique sous-jacente.
Il est maintenant connu qu'il y a deux locus avec le gène D ou d (gène d en fait inexistant) au premier locus RHD, et le gène CE synthétisant une protéine avec les deux épitopes (C-c, E-e) au second locus RHCE.
Ces deux gènes, d'orientation opposée, les exons 10 étant proches, sont situés sur le chromosome no 1, en 1 p36.2-p34.Ainsi, un sujet Rh1rh' (Wiener) sera DCCee (Fisher Race) et RH(1,2,-3,-4,5) maintenant.Ces trois nomenclatures sont toujours utilisées dans le milieu transfusionnel, selon les endroits et les us et coutumes locales.
Il est plus simple de demander un « R1 petit r » ou un « moins 3 » qu'un « Grand D, grand C, petit c, petit e, petit e » ou qu'un « RH 1, 2, moins 3, 4, 5 ».
Bref, on pense en Fisher Race, on parle en Wiener (génotype probable) ou en numérique abrégé, en n'indiquant que les antigènes absents, et on écrit en numérique.Les protéines RH sont codées par deux gènes, RHD et RHCE, étroitement liés, située sur le chromosome 1 en 1p36.13-p34.3 séparés de 30 kilobases contenant le gène SMP1 (small membrane protein 1), orientés tête-bèche selon la séquence : centromère-....-5'-Rh box-RHD-3'-Rhbox-gène SMP1-3'-3'-RHCE-5' en 1p34.3-p36.13.
Ces deux gènes, présentant 96 % d'homologie, sont composés de 10 exons chacun, les exons 1 à 7 codant 50 à 60 AA chacun, les exons 8 à 10 codant les 58 derniers AA C-terminaux.
Une délétion de RHD est responsable du phénotype RH:-1 (dd).
Un troisième gène homologue RHAG localisé sur le chromosome 6 en 6p11-p21.1 code la glycoprotéine associée au RH (Rh-associated glycoprotein) RHAG ou RH50, essentielle pour l'expression des antigènes Rhésus.
Ce gène a dix exons répartis sur 30 kilobases.
Quoique présentant une forte homologie, la glycoprotéine RHAG, dont la localisation du gène est différente, ne peut faire partie du système rhésus.
Du fait de la forte homologie entre les deux gènes RH, indépendamment des mutations ponctuelles, expliquant par exemple le polymorphisme C/c (Cys16Trp, Ile60Leu, Ser68Pro et Sr103Pro), E/e (Pro226Ala) ou Cw (Gln41Arg) de la protéine RHCE, de nombreuses translocations ont eu lieu, de telle sorte que diverses molécules hybrides ont été observées, un ou des exons de l'un étant échangés avec les exons homologues de l'autre.
Il existe ainsi, comme dans le système MNS, des gènes RH(D-CE-D), ou RH(CE-D-CE).
Ces gènes hybrides expliquent les nombreux variants rencontrés dans le système Rhésus, certaines molécules ayant perdu un ou des antigènes, et en en ayant acquis d'autres.
C'est ainsi que 54 antigènes différents sont homologués par la Société internationale de transfusion sanguine dans le système RH, du no 001 à 053, les nos 013 à 016, 024, 025 et 038 n'étant plus attribués à un antigène particulier.Les deux protéines RHD et RHCE, de 417 AA chacune, se situent dans la membrane de l’érythrocyte qu'elles traversent à douze reprises, les C et N terminaisons étant intracytoplasmiques.
Ces protéines ne sont pas glycosylées, mais portent 3 acides palmitiques intramembranaires.Dans la nomenclature Fisher-Race, l'allèle D est évidemment dominant par rapport à d, dont nous savons maintenant qu'il s'agit d'une délétion.
Les allèles C / c d'une part et E / e d'autre part sont codominants.
Ainsi deux parents d / d ne pourront pas avoir un enfant D, RH:1, mais deux parents D / d (Rhésus positif standard D, RH:1) pourront avoir un enfant d / d (Rhésus négatif) avec une probabilité de 25 %.
Deux parents C / c pourront avoir des enfants présentant l'un des trois génotypes possibles C / C, C / c ou c / c.
Le même raisonnement s'applique aux allèles E et e. Il est évidemment plus simple de raisonner sur les haplotypes.
Deux parents DCe / dce et DcE / dce pourront avoir des enfants DCe / DcE, DCe / dce, DcE / dce et dce / dce.Cependant, comme dans pratiquement tous les systèmes de groupes sanguins (ABO, MNs, FY, JK, DO…), il est possible de rencontrer d'apparentes exclusions de paternité ou de maternité.Il existe ainsi un rarissime haplotype RHnull dans le système Rhésus.
Cet haplotype, qui ne synthétise aucune des deux protéines RH, ni RHD, ni RHCE, est noté RH:---.
Supposons un père déterminé comme D+, C+, E-, c-, e+, c'est-à-dire possédant les antigènes D, C, et e, et ne possédant pas les antigènes c et E. Nous en déduisons le génotype vraisemblable de ce père comme étant DCe / DCe, ou DCe / dCe.
Or, ce père, uni à une femme de génotype dce / dce, pourra avoir un enfant D-, C-, E-, c+, e+, c'est-à-dire ne possédant pas l’antigène attendu C.
Cet enfant sera considéré à tort comme de génotype dce/dce.
Nous constatons alors une apparente exclusion de paternité, l'enfant étant supposé avoir reçu un haplotype dce qui n'existe pas chez son père.
Or ceci peut être parfaitement expliqué par le génotype DCe / --- de ce père, qui a transmis son haplotype « --- » à son enfant dont le génotype réel est dce / --- .En conclusion, une anomalie apparente de transmission d’un groupe sanguin ne permet en aucune façon à elle seule de conclure à une exclusion de paternité ou de maternité.
Une telle conclusion doit s’appuyer sur plusieurs systèmes, et maintenant sur la biologie moléculaire (analyse directe au niveau des chromosomes).Les gènes RHD et RHCE étant étroitement liés, nous devons considérer la fréquence des haplotypes dans une population plutôt que la fréquence des divers allèles de chaque gène.
Ces fréquences haplotypiques permettent de retrouver facilement les fréquences phénotypiques, selon le principe de Hardy-Weinberg visualisé par l'échiquier de Punnett, dans les populations concernées.Pour la France, les haplotypes DCe (0.42527) et DCwe (0.00264) ont été regroupés en DCe (0.4279)À l'origine, était considéré comme de phénotype Du un groupe Rhésus donnant de faibles réactions avec les réactifs habituellement utilisés pour déterminer le groupe sanguin RH1, D.
Cette recherche était faite par une technique à l'antiglobuline, voire par une technique de fixation-élution.
Compte tenu de l'amélioration des réactifs (anticorps monoclonaux, réactifs qui ont l'avantage d'être très puissants, mais l'inconvénient de ne concerner qu'un seul épitope par clone) et des techniques (filtration sur gel) le nombre de Du dépistés est maintenant très faible.
En cas de réelle nécessité, la biologie moléculaire (B.M.)
peut maintenant être utilisée, et montre très souvent qu'il s'agit en réalité d'un variant du gène RH1.On a considéré très longtemps, avant la biologie moléculaire, qu'il s'agissait d'un antigène normal, mais en quantité moindre, donc à considérer comme positif.
Cependant, non mis en évidence par une technique simple de groupage, le Du est souvent étiqueté comme négatif lors de la détermination du groupe rhésus de malades.
Ceci n'a pas de conséquences graves, à l'exception de consommer beaucoup d'unités de sang rh négatif en cas de transfusion, ou de faire une injection inutile d'immunoglobulines anti-D chez une accouchée, si elle est Du avec un enfant Rh+.Ne pas faire cette injection d'anti-D serait plus grave si la mère est rh négatif et l'enfant Du.
Cette recherche de Du, faite pendant de nombreuses années (jusqu'au début des années 2000) à la naissance chez la mère et l'enfant, pour poser l'indication d'une prévention de la maladie hémolytique du nouveau-né par injection d'anti-D, n'est plus faite aujourd'hui, sauf cas particuliers de discordance de détermination de groupe, du fait de l'amélioration de nos réactifs monoclonaux.Par contre, en tant que donneur de sang, il est absolument impératif de considérer le D faible comme Positif, car l'antigène Du est immunogène.
Ceci explique le fait que certaines personnes peuvent être déterminées comme RH1 Positif (D) en tant que donneur de sang et RH1 Négatif (dd) en tant que malade susceptible d'être transfusé.Chez un sujet D partiel la proteine est qualitativement anormale dû au manque d'epitopes mais son expression quantitatif reste normale.Par la suite, on s'est aperçu que certains sujets Rh positif, ou Du, pouvaient faire un anticorps anti-D.
On les considère alors comme des D partiels, que l'on doit transfuser en rh négatif.Depuis le début des années 2010, selon les réactions que l'on observe au laboratoire, le sujet concerné (peau blanche, noire…), les anticorps utilisés, et avec un peu d'expérience, le Du sera considéré soit comme Rh Positif, soit suspecté d'être un variant et donc un possible D partiel.
Il sera alors contrôlé en biologie moléculaire, où sera révélée la mutation concernée.
Si une réponse anticorps a déjà été observée chez de tels sujets transfusés avec des sangs Rh +, ce sujet sera considéré, en tant que malade, comme un rhésus négatif.
Un commentaire accompagnera le résultat, car cette personne peut très bien être retrouvée Rh Positif sans aucun problème dans un autre laboratoire, tout dépend de l'anticorps monoclonal employé et de l'épitope reconnu.
Ces sujets sont donc considérés comme receveurs Rh négatifs (RH:-1, dd) et donneurs positifs (RH:1, D) parfois seulement en dons de plasma ou plaquettes, le don de globules rouges risquant d'entraîner l'apparition d'un anticorps contre certains variants chez le receveur.Le Du, ou du moins le phénotype considéré comme tel, est de plus en plus rare.
En cas de discordance de résultats avec différents réactifs, un variant ou un « D partiel » susceptible de produire une réponse anti-D est le plus souvent suspecté, cas qui reste exceptionnel.
Enfin, les antigènes associés C ou E trouvés chez un RH D négatif, compte tenu de leur fréquente association à l'antigène D, sont des indicateurs à surveiller.Encore dénommé antigène Cw dans la nomenclature Fisher-Race, de fréquence phénotypique de 1 à 9 % selon les populations (2 % chez les personnes à peau blanche), il s'agit d'une particularité de la molécule RHCE C+ (RH:2) le plus souvent (exceptionnellement d'une molécule ce), due à une substitution Gln41Arg.
Cette particularité n'a aucune conséquence clinique, mais un anticorps anti-Cw naturel (c’est-à-dire apparaissant en dehors de toute immunisation par transfusion ou grossesse) et sans danger même en cas de transfusion, est souvent dépisté lors d'une recherche d'anticorps irréguliers (RAI).Cet épitope, nommé également rhG, est dû à la présence d'une sérine en position 103 tant sur la molécule RHD que sur la molécule RHCE de type C (RH:2), la molécule de type c (RH:4) ayant une proline en 103.
L'antigène G (RH:12) est donc un antigène commun aux molécules D (RH:1) et C+ (RH:2).
Rares sont les molécules D+ et G- ayant une proline en 103.
Ceci explique la survenue d'immunisations dites anti D+C qui sont en fait très souvent des anti D+G.Antigène rencontré dans la population africaine, de fréquence phénotypique 1 %, il s'agit d'une molécule hybride due à un gène RH(CE-D-CE) dans lequel l'exon 4 du gène RHCE est remplacé par l'exon 4 du gène RHD.
Cet antigène est également présent chez d'exceptionnels phénotypes D partiels de génotype RH(D-CE-D) où les exons -5 à 7 ou 5 à 9 de RHD sont remplacés par les exons homologues de RHCE.
Les sujets RH32 homozygotes (de génotype RN/RN selon la nomenclature Wiener) peuvent présenter un anticorps immun (apparaissant après grossesse ou transfusion) et très dangereux contre l'épitope RH46 qu'ils ne possèdent pas.
Or, cet épitope RH46 existe sur toutes les protéines RHCE qui ne sont pas RH32.
On dit des antigènes RH32 et RH46 (tout comme RH2 et RH4 ou RH3 et RH5) qu'ils sont antithétiques : si l'un est absent, l'autre est normalement présent.
Lorsqu'ils possèdent cet anticorps anti-RH46, les sujets RH:32,-46 ne peuvent plus être transfusés, sauf par des sangs de même phénotype.
En France, ces sujets ont donc une carte nationale de groupe rare, et leur sang est conservé congelé à la Banque nationale de sang de phénotype rare à Créteil.Cet antigène, encore dénommé antigène VS, est rencontré dans la population noire, avec une fréquence phénotypique de 26 à 40 %.
Il est dû à une substitution Leu245Val sur la molécule RHCE de type ce, ou sur la molécule hybride RHD-CE-D.
Cet anticorps peut être naturel, et n'entraîne que des réactions cliniques mineures.Certains haplotypes ne codent pas l'ensemble des antigènes attendus.
L'antigène absent est remplacé par le signe — dans la nomenclature Fisher Race.Les haplotypes RH en délétions pourraient faire croire à une exclusion de parenté, l'enfant ne possédant pas un haplotype attendu, ou paraissant posséder un haplotype non mis en évidence chez le parent lui ayant transmis l'un de ces haplotypes.
De même, un parent RHnull de type régulateur peut transmettre un haplotype normal à son enfant, le problème génétique étant évident dans ce dernier cas.Ces deux types de RHnull sont indiscernables sérologiquement.
On ne retrouve sur aucun l'antigène RH29, que l'on retrouve sur toutes les hématies qui ne sont pas RHnull.
Ce phénotype entraîne le syndrome RHnull, caractérisé par une fragilité des hématies, marquée par une sphérocytose et une fragilité osmotique.
D'où une anémie hémolytique chronique, souvent bien compensée (réticulocytose), mais dans certains cas pouvant nécessiter une splénectomie.
Le tableau est en fait proche de la sphérocytose héréditaire, ou maladie de Minkowski-Chauffard.
Mais la gravité de l'atteinte clinique, au sein d'une même famille, est très variable d'un sujet à l'autre.Ces personnes posent un rarissime mais énorme problème transfusionnel.
Elles peuvent être transfusées une fois, mais pas deux si elles produisent un anticorps.
Hors leur famille, il sera très difficile de trouver un donneur compatible.
Il est donc nécessaire, grâce à un protocole d'auto-transfusion, de conserver congelé le sang de ces personnes dans un centre national.
Ou de faire appel aux autres centres nationaux de transfusion sanguine qui pourraient avoir de tels sangs congelés en stocks.Il s'agit toujours d'anticorps irréguliers.
C’est-à-dire que l'absence de l'antigène n'entraîne pas la présence de l'anticorps correspondant (contrairement au système ABO où l'absence de l'antigène A ou B sur le globule rouge doit entraîner systématiquement la présence de l'anticorps dans le plasma).Il peut s'agir d'allo-anticorps, chez le sujet sain, ou d'auto-anticorps dans les maladies et anémies auto-immunes.Ces anticorps peuvent être naturels, c'est le cas le plus fréquent pour les anti-E et anti-Cw.
Les autres anticorps de système RH sont le plus souvent immuns, c’est-à-dire qu'ils résultent de transfusions ou de grossesses.
Il s'agit essentiellement des anti-D, anti-c, les plus fréquents et entraînant les conséquences les plus graves.
Mais tous les autres anticorps, moins fréquents, peuvent se voir.
Très souvent, associé à l'anti-D, nous trouvons un anticorps que nous identifions comme un anti-C.
En fait, l'anti-C pur est très rare, et il s'agit souvent non pas d'un anti-C, mais d'un anti-G (anti-RH12) qui est une spécificité commune à la molécule D et à la molécule RHCE C+.
L'anti-G reconnaît donc à la fois le D (RH1) et le C (RH2).
Ainsi, ce que nous appelons un anti-D+C peut très bien être un anti-G, un anti-D+G, un anti-C+G ou un anti-D+C+G.
Seules, des techniques de fixation-élutions permettraient de différencier ces divers anticorps, ce qui n'a aucun intérêt pratique dans ce cas.
Nous rencontrons aussi dans le système RH des anticorps vis-à-vis d'antigènes composés, c’est-à-dire reconnaissant l'association de deux épitopes sur la même protéine : anti-Ce (RH7), anti-cE (RH 27), anti-ce (RH6, f), anti-CE (RH22), mais ne reconnaissant pas chacun de ces épitopes isolés.
Ainsi, chez un sujet DCCee transfusé avec un sang DCcEe (de génotype DCe/DcE), nous pouvons avoir l'association de trois anticorps : anti-c + anti-E + anti-cE.Les auto-anticorps chauds (en règle actifs à 37 °C, de type IgG) rencontrés dans les maladies auto-immunes, ont souvent une spécificité RH.
La spécificité en est suspectée par les différences de sensibilité d'hématies normales.
Les hématies de phénotype RH : EE, dépourvue de l'antigène e, réagissant moins que les autres, ou ne réagissant pas dans certaines techniques, par exemple, nous pouvons alors en conclure qu'il s'agit, dans ce cas, d'un auto-anticorps à spécificité préférentielle anti-e.La preuve définitive pourrait en être apportée -ce qui ne présente aucun intérêt en pratique- par le fait que certaines hématies RH en délétion, de phénotype DC-, D--, ou --- (RHnull) ne réagissent pas du tout, et qu'elles ne possèdent donc pas l'épitope RH reconnu par ces auto-anticorps.
Mais ces hématies rarissimes ne sont utilisées que pour l'identification d'allo-anticorps susceptibles d'entraîner des accidents transfusionnels.La découverte du système Rhésus a permis de rendre plus sûre la transfusion sanguine, de comprendre et de prévenir les incompatibilités fœto-maternelles de groupe sanguin au cours de la grossesse.La règle est qu'on peut transfuser des produits sanguins Rh - (qui ne contiennent pas l'antigène D ou RH1) à un individu Rh +, mais pas le contraire.
L'individu Rh - fabriquerait des anticorps anti-RH1 (D) destructeurs des globules rouges Rh +, ce qui provoquerait un accident transfusionnel lors d'une nouvelle transfusion incompatible.Il existe un risque d'immunisation au cours de la grossesse d'une femme Rh - par un fœtus Rh + dans certaines circonstances :Dans ces cas, la mère doit recevoir rapidement, dans les 48 heures (ou 72 heures au plus tard, l’efficacité diminuant rapidement au-delà) des immunoglobulines anti D (RH1) qui préviennent sa possible immunisation afin de pouvoir mener sans encombre une grossesse ultérieure.
D’où le nom de prévention de la maladie hémolytique du nouveau-né donné à cette méthode.
Les immunoglobulines anti-D entraînent d’une part la disparition rapide des globules rouges fœtaux de la circulation maternelle, par hémolyse intra ou extra-vasculaire, disparition qui peut être mise en évidence par le test de Kleihauer, et bloquent d’autre part la réponse immunitaire primaire.
Ainsi, l'organisme de la mère ne garde pas la mémoire immunologique de son contact avec l’antigène RH1, D.Maintenant que cette prévention est faite systématiquement à la naissance, et est même recommandée à la 28e semaine de grossesse, nous observons beaucoup moins d'incompatibilités par anti-D.
Mais nous observons toujours des incompatibilités par anti-c (donc chez des femmes Rhésus + DCCee, accouchant d'un enfant hétérozygote DCcee) et anti Kell.
D'où la règle transfusionnelle de respecter la totalité des phénotypes Rhésus et Kell pour la transfusion chez une fille ou une jeune femme.En France, leur répartition est la suivante, par groupe sanguin :La région du monde qui compte la plus forte proportion de rhésus négatifs est le Pays basque.
La protéomique désigne la science qui étudie les protéomes, c'est-à-dire l'ensemble des protéines d'une cellule, d'un organite, d'un tissu, d'un organe ou d'un organisme à un moment donné et sous des conditions données.Dans la pratique, la protéomique s'attache à identifier de manière globale les protéines extraites d'une culture cellulaire, d'un tissu ou d'un fluide biologique, leur localisation dans les compartiments cellulaires, leurs éventuelles modifications post-traductionnelles ainsi que leur quantité.Elle permet de quantifier les variations de leur taux d'expression en fonction du temps, de leur environnement, de leur état de développement, de leur état physiologique et pathologique, de l'espèce d'origine.Elle étudie aussi les interactions que les protéines ont avec d'autres protéines, avec l'ADN ou l'ARN, ou d'autres substances.La protéomique fonctionnelle étudie les fonctions de chaque protéine.La protéomique étudie enfin la structure primaire, secondaire et tertiaire des protéines.Le terme de protéomique est récent.
Il a été utilisé pour la première fois dans une publication scientifique en 1997 par P. James .
dans son article Identification des protéines dans l'ère post-génomique : l'ascension rapide de la protéomique.
Il dérive de protéome, terme inventé en 1995, par analogie avec génomique qui dérive lui-même du terme génome, l'ensemble des gènes d'un organisme.
L'analyse protéomique est une étude dynamique.
Un seul génome peut conduire à différents protéomes en fonction des étapes du cycle cellulaire, de la différenciation, de la réponse à différents signaux biologiques ou physiques, de l'état physiopathologique...
Le protéome reflète les répercussions de ces événements cellulaires au niveau tant traductionnel que post-traductionnel.
De ce point de vue, seule une analyse protéique directe peut donner une image globale des systèmes biomoléculaires dans leur complexité.Les scientifiques se sont intéressés aux protéines bien avant la naissance de la protéomique.
Dès 1833, Anselme Payen et Jean-François Persoz isolèrent d'un extrait de malt une enzyme capable de catalyser la dégradation de l'amidon en sucre.
en 1965, André Lwoff, François Jacob et Jacques Monod reçurent le prix Nobel de physiologie ou médecine « pour leurs recherches sur la manière dont la production des enzymes est réglée au niveau des gènes », publiées en 1961.De nombreuses techniques, encore largement utilisées, ont été développées.La technique d'électrophorèse a été développée en 1892 par S.E.
Le principe de la chromatographie date de 1861 par Friedrich Goppelsröder.// mettre une fresque reprenant la chronologie de l'étude des protéinesDepuis une dizaine d'années, la protéomique est devenue une science à part entière, avec ses techniques propres et ses méthodes.
La protéomique est récompensée en 2002 par l'obtention d'un Prix Nobel de chimieElle a emprunté de nombreuses technologies, auparavant utilisées dans d'autres disciplines, et les a appliquées à l'étude des protéines.
On peut citer par exemple l'utilisation de la spectrométrie de masse, provenant de la physique et de l'analyse chimique, dans l'identification des protéines, dans la quantification de l'expression des protéines, dans la localisation de peptides dans un tissu, dans la recherche de biomarqueurs spécifiques de pathologies.Finalement, les enjeux et résultats de projets de séquençage (du génome humain notamment) justifient une étude approfondie du protéome.
La découverte « surprenante » que ce génome contenait bien moins de gènes que prédits démontre l'importance des protéines comme acteurs centraux des processus biologiques.Les méthodologies mises en œuvre pour l’analyse du protéome peuvent schématiquement être séparées en deux grands groupes : dans le premier peuvent être regroupées les méthodes expérimentales réalisées dans le « laboratoire réel » (wet laboratory), reposant principalement sur les techniques de séparation et d’analyse des protéines.
Un second groupe de méthodes, mises en œuvre dans le « laboratoire virtuel » (dry laboratory), fait appel à l’analyse d’images et à la bio-informatique.
Laboratoires réel et virtuel sont mis à contribution lors des principales étapes de l’analyse.Dans la pratique, les protéines sont d’abord extraites d’une population cellulaire ou d’un tissu, puis séparées avant d’être identifiées.La première étape consiste généralement à extraire les protéines d'un échantillon biologique.
Cette étape est cruciale : une mauvaise extraction peut produire la dégradation des protéines et compliquer, voire rendre impossible, l'identification des protéines.
Les protéines membranaires, comportant de nombreux acides aminées hydrophobes et donc peu soluble, restent difficiles à étudier.Certaines techniques ne nécessitent pas d'extraire les protéines du tissu étudié.
Dans l'immunolocalisation, le tissu est fixé puis découpé en fines lamelles de quelques microns d'épaisseur.
Les protéines sont ensuite détectées in situ par des anticorps marqués.
Dans l'imagerie par spectrométrie de masse, des coupes de tissus sont analysées directement par un spectromètre de masse de type MALDI-TOF.Pour simplifier l'analyse, l'extraction est souvent réalisée en éliminant les modifications post-traductionnelles.
Seule la structure primaire des protéines, c'est-à-dire leurs séquences, est conservée.
Mais si le sujet de l'analyse est l'étude de ces modifications post-traductionnelles, il convient de prendre les précautions nécessaires pour les garder.La seconde étape permet de séparer les protéines en fonction de leurs caractéristiques physiques ou chimiques ou en fonction de leurs affinités pour un ligand.L'électrophorèse sépare les protéines dans un gel polyacrylamide en fonction de leur poids moléculaire lorsqu'elles sont soumises à un champ électrique.
La méthode d'électrophorèse de référence pour la protéomique est l’électrophorèse bidimensionnelle.La chromatographie utilise la différence d'affinité des protéines entre une phase mobile et une phase stationnaire.L'électrophorèse bidimensionnelle permet à partir de mélanges protéiques complexes de séparer et visualiser des centaines voire des milliers de protéines sous forme de taches ou « spots ».
La résolution obtenue est suffisante pour mettre en évidence la présence d'isoformes.Son principe consiste à effectuer dans un premier temps une séparation des protéines en fonction de leur charge (focalisation isoélectrique), suivie d'une séparation orthogonale, en fonction de leur poids moléculaire.
La résolution de la première dimension est de l'ordre de 0,01 unité pH.Les gels obtenus sont ensuite colorés, puis numérisés.
Le résultat est une semi-quantification.Il existe aujourd’hui deux grandes approches partant de l’analyse d’images des gels 2-DE permettant d’aborder la protéomique quantitative.
L’une de ces méthodes utilise une comparaison statistique entre plusieurs gels et l’autre utilise un procédé chimique de dérivation des protéines par des sondes fluorescentes permettant l’analyse combinée de plusieurs échantillons sur un gel unique.
Pour ce faire on utilise dans les deux cas des logiciels d'imagerie.
En effet, il est impossible d’appréhender individuellement le nombre considérable de spots (parfois jusqu’à 2000) résolues sur un gel 2D (Fig.
Ces multiples spots correspondent aux isoformes des protéines séparées en deux dimensions.
La position sur le gel des spots polypeptidiques est reproductible dans les systèmes de séparation en gradient d’Immobilines.
Un changement de position est par conséquent un indicateur d’une modification post-traductionnelle affectant sa charge et/ou sa taille.L’analyse d’images repose sur la numérisation de l’image du gel 2-DE après coloration.
Au cours de cette étape le logiciel  découpe l’image en pixels (contraction de picture element) pour la transmission et le stockage des données.
Chaque pixel  de l’image est enregistrée à une position en x et en y associée à une valeur de densité optique (DO) proportionnelle à l’intensité du signal enregistré par la caméra ou le scanner.
Pour que la DO soit un bon paramètre de mesure et un reflet de l’expression de la protéine, la coloration appliquée doit présenter une gamme dynamique importante et si possible linéaire.
Dans un gel, en termes de DO le rapport d’intensité entre le plus petit spot détectable et le spot le plus gros est de l’ordre de 104 alors que la dynamique d’expression des protéines dans la cellule est comprise entre 105 et 106.
On constate donc un déficit important de la gamme analytique qui doit être pris en compte au cours de l’analyse.La coloration des protéines en gel 2-DE reposent principalement sur l’emploi de colorants organiques tel que le bleu de Coomassie, de métaux tels que le nitrate d’argent, ou encore par sur des sondes fluorescentes.
La gamme de détection varie d’un facteur d’environ 10000 entre les méthodes utilisant le bleu de Coomassie (détection de spots contenant une quantité de protéine de l’ordre du µg) et  celles utilisant le nitrate d’argent qui permettent d’atteindre 0,1 ng.
Les colorants fluorescents sont moins sensibles que le nitrate d’argent, cependant ont une plus grande reproductibilité et gamme dynamique.Les logiciels d’analyses d’images actuels incorporent des éléments de visualisation 3D des spots du gel, permettant des changements d’angles en x, y, et z  qui sont extrêmement utiles pour séparer des spots proches.
L’utilisation de tels outils permet d’élargir considérablement le goulot d’étranglement lié à l’analyse des gels.
Cependant, une analyse différentielle fiable nécessite d’établir une comparaison entre des séries d’au moins trois à quatre gels.
Des tests statistiques comme l’analyse heuristique ou l’analyse par correspondance permettent objectivement de déterminer la dispersion entre les gels de différentes séries expérimentales.La multiplication des gels 2D nécessaire à l’obtention d’une quantification différentielle statistiquement fiable est cependant un handicap aux analyses à haut débit pour lesquelles la technique du gel unique est intéressante.
L’analyse différentielle sur un gel unique: (technologie DIGE pour differential in gel-electrophoresis) a été introduite sur le marché par GE (anciennement) Amersham Biosciences.
Le principe repose sur le marquage covalent à l’aide de cyanines fluorescentes  (p. ex.
Cy2, Cy3 et Cy5) des protéines contenues dans deux extraits à analyser.
Trois structures sont disponibles avec des spectres de fluorescences différents.
Elles possèdent en outre un groupement N-hydroxy-succinimidyl ester qui permet par une réaction de substitution nucléophile avec le groupe amine en epsilon des lysines des protéines de former une amide.
L’analyse d’images d’un gel DIGE est plus aisée puisque les deux échantillons ont migré sur le même gel.
Les images acquises aux deux longueurs d’onde sont superposées et comparées quantitativement à l’aide de logiciels adaptés avec l’ajout d’une référence interne.
L’étude comparative en deux couleurs aboutit à la mise en évidence des protéines qui différent ou qui sont identiques dans les deux échantillons.
La possibilité offerte d’avoir un étalon interne augmente la fiabilité des mesures quantitatives.
Quelle que soit la méthode d’analyse utilisée, les spots d’intérêt une fois détectés sont excisés du gel afin d’être identifiés par des méthodes spectrométriques (spectrométrie de masse en mode MALDI-TOF ou en mode tandem MS/MS).
En plus de l’analyse différentielle, l’analyse d’images permet de construire et d’annoter des cartes de référence servant de base à des banques de données consultables sur le WEB.L'identification par SM repose sur une mesure précise de la masse de peptides ionisés.D’une façon très générale les protéines sont digérés par une endopeptidase (le plus souvent la trypsine) et, ensuite analysées par SM.Une des approches utilisée est l’établissement de cartes peptidiques massiques (en anglais, peptide mass fingerprinting, en français empreinte de masse peptidique (en) ou empreinte peptidique massique).
La masse des peptides obtenus après digestion protéasique est comparée aux cartes de masses théoriques des protéines répertoriées dans les banques de données.
Différents algorithmes ont été développés pour faciliter cette recherche.
Les logiciels d’analyse de données de SM vont rechercher une série de protéines (selon des critères définis par l’expérimentateur) dans une base de données de séquences et générer pour chacune un spectre théorique pour voir lequel se rapproche le plus du spectre expérimental.Selon des logiques différentes pour chaque algorithme, ils établiront un score pour chaque séquence analysée « in silico » qui conduira à un classement des protéines candidates.
Cette approche souffre pourtant de limites objectives et dans le cas d’identifications difficiles différents logiciels fourniront des listes de protéines candidates différentes.
Par exemple, un logiciel prenant en compte le nombre de masses communes entre le spectre théorique de la protéine candidate et le spectre expérimental favorisera les protéines de haute masse moléculaire pour lesquelles un plus grand nombre de peptides virtuels peuvent être déduits de la séquence.Le problème est contourné en séquencant partiellement les protéines par spectrométrie de masse tandem (MS/MS).
Certains fragments peptidiques analysés lors d'une première SM sont alors choisis et fragmentés.
Les pics de masse obtenus constituent une représentation de la séquence protéique, dans laquelle deux pics adjacents diffèrent par la masse d’un acide aminé perdu lors de la fragmentation du peptide analysé.
Une analogie à la courte séquence protéique peut alors être cherchée dans les banques de données.
Si ces séquences sont communes à un groupe de protéines, le point isoélectrique et la masse apparente déterminés lors de la séparation par électrophorèse permettent de trancher.
Recouper des informations (courtes séquences de quelques acides aminés, localisation d’une fenêtre comprenant le spot en électrophorèse 2D, espèce animale et type cellulaire dont provient l’échantillon) augmente la fiabilité de l'identification d'un polypeptide.Au lieu de simplement déterminer une séquence peptidique à partir du spectre de masse d’un peptide et de l’utiliser pour miner une base de données de protéines ou d’ADN, le spectre MS/MS peut être comparé à une série de spectres MS/MS virtuels dérivés des séquences protéiques des bases de données.
Sur le même principe, on peut d'abord séparer les peptides issus de la digestion trypsique par une nanométhode de chromatographie liquide (nanoLC) et réaliser une MS/MS sur ces différents peptides.
La multiplication des informations sur différents segments de la protéine permettra alors non seulement de conforter l’identification, mais également d’obtenir des informations structurales en particulier sur les modifications post-traductionnelles, telles que l’addition de groupements phosphates (phosphorylation) ou de chaînes d’oligosaccharides (glycosylation).
D’un point de vue fonctionnel, ces informations sont fondamentales.
Les phosphorylations sont à la base de la conduction de signaux dans la cellule, de l’extérieur de celle-ci par ses récepteurs membranaires jusqu’au noyau où sont centralisées les informations régulant la vie cellulaire.
Quant aux chaînes oligosaccharidiques, elles jouent un rôle crucial dans la modulation des propriétés chimiques de certaines protéines (glycoprotéines) et gouvernent parfois leur activité biologique.
Pour identifier ces groupements, la SM utilisera les fragments résultant de leur séparation de la chaîne peptidique ou de leur propre fragmentation.C'est la dernière étape pour le protéomicien, permise par les progrès de la bio-informatique.
Les différentes informations récoltées sur les protéines (masse apparente, masse réelle, point isoélectrique, taille des fragments après digestion enzymatique, séquence partielle) sont comparées aux bases de données génomiques ou protéomiques en ligne.
Les logiciels fournissent alors une liste de protéines et leurs probabilités associées.Cas d'organismes dont le génome n'a pas encore été séquencé ; Seuls certains organismes, dits « organismes modèles », ont un génome complètement séquencé et disponible en ligne.
Les autres organismes sont étudiés par homologie avec les organismes connus.Elle permet de quantifier les variations de leurs taux d'expression en fonction du temps, de leurs environnements, de leurs états de développement, de leurs états physiologiques et pathologiques, de l'espèce d'origine.Les techniques les plus couramment utilisées sont :Elle étudie aussi les interactions que les protéines ont avec d'autres protéines, avec l'ADN ou l'ARN, avec des substances.Une autre manière de considérer les interactions protéiques est de faire du double hybride.
En criblant une banque d'ADNc avec sa protéine en tant qu'appât on peut déceler tous les interractants dans un organisme ou un tissu spécifique (animal ou végétal).
Correctement utilisée, cette technique est très efficace.
La qualité des résultats dépend souvent de la qualité de la banque et de l'efficacité de la transformation de la levure ou de la bactérie.La protéomique fonctionnelle étudie les fonctions de chaque protéine.La protéomique étudie enfin les structures primaires, secondaires et tertiaires des protéines.Les études comparées des kinomes de cellules cancéreuses permettent d'étudier des mécanismes de résistance et d'identifier de nouvelles cibles thérapeutiques.
Un antigène est une macromolécule naturelle ou synthétique qui, reconnue par des anticorps ou des cellules du système immunitaire d’un organisme, peut déclencher une réaction immunitaire.
Les antigènes sont généralement des protéines, des polysaccharides et leurs dérivés lipidiques.
Des fragments d'antigènes appelés haptènes peuvent aussi provoquer une allergie.Les antigènes (de l'acronyme anglais antigen, pour antibody generator) et les anticorps, dont la combinaison est à la base de la réaction immunologique d’un organisme contre un agent extérieur, n’ont pas de définition intrinsèque, mais se définissent l’un par rapport à l’autre :Ainsi toute substance étrangère, tout microbe, introduit dans le corps, peut se comporter en antigène, c’est-à-dire y provoquer la fabrication de protéines spéciales, les anticorps qui ont la propriété de neutraliser les effets nocifs de la substance étrangère ou du microbe et des toxines qu’ils produisent.
Ce faisant, le corps devient réfractaire à l’agent envahisseur ; on dit qu'il s’immunise.Les antigènes, en tant que marqueurs d'agents étrangers à l'organisme, sont à la base de la réaction immunitaire adaptative.
C'est la reconnaissance de l'antigène par les cellules immunocompétentes, directement ou via les cellules présentatrices d'antigène (CPA), qui active l'immunité spécifique.Dans le cas d'antigènes protéiques, on nomme « épitope » ou « déterminant antigénique » la partie de l'antigène reconnue par un anticorps ou un récepteur lymphocytaire.
Un même antigène peut comporter plusieurs épitopes (identiques ou différents) et ainsi provoquer une réaction immunitaire variée.
Il existe des épitopes séquentiels, correspondant à une séquence d'acides aminés, et des épitopes conformationnels, liés à la structure de la protéine et donc sensibles à la dénaturation.
La reconnaissance de l'antigène par les lymphocytes dépend de la nature de l'épitope.
Les lymphocytes B se lient directement aux épitopes conformationnels grâce aux immunoglobulines de leur membrane.
Les lymphocytes T reconnaissent les épitopes séquentiels présentés par les cellules présentatrices d'antigènes.C’est le potentiel d’un antigène à provoquer une réaction immunitaire.
Elle dépend :C’est la capacité de l’antigène à être reconnu par le système immunitaire.
Une substance peut être antigénique mais pas immunogène.Ils sont étrangers à l’individu et peuvent être :Ce sont des antigènes propres à l’hôte (auto-antigènes) et pouvant être considérés comme étrangers (dans le cadre de maladies auto-immunes notamment ; ces antigènes sont dits cryptiques, c'est-à-dire qu'ils ne sont pas reconnus par le système immunitaire en situation normale.
Du grec ancien κρυπτικός, kriptikós : "caché").
Ils sont présentés par les molécules HLA de classe 1 aux CD8.Les antigènes de type protéique sont très immunogènes et souvent utilisés pour fabriquer des vaccins (pour cela, il faut un PM minimum de 1 500 Da).Ce sont des polymères à structure ordonnée constitués d’épitopes identiques se répétant.Deux types :Les polyosides sont des constituants ubiquitaires à la surface cellulaire, ils sont également très immunogènes.Ils sont généralement très peu immunogènes sauf s’ils sont associés à des protéines.Leur immunogénicité est très faible même s’il existe des anticorps anti-ADN.
De la même manière que pour les lipides, on peut augmenter leur pouvoir immunogène en les associant à des protéines.Quand une molécule fait moins de 1 500 Da, elle ne présente qu’un seul déterminant antigénique, on l’appelle alors : haptène.Un haptène est non immunogène.
En l’associant à une protéine porteuse (carrier) qui apporte au moins un déterminant supplémentaire, le complexe devient immunogène.Il s’agit de macromolécules de synthèse obtenues par polymérisation d’acides aminés.C’est le nombre d’anticorps capables de se lier simultanément sur une molécule.
La valence est donc proportionnelle à la surface de la molécule mais ne reflète pas le nombre d'épitopes à cause de l’encombrement stérique que peuvent occasionner les anticorps.Il existe aussi des réponses immunitaires dites indépendantes de l'interaction avec des lymphocytes T auxiliaires.
Ces réponses sont très faibles voire absentes chez le nourrisson avant 2 ans.
Toutefois la plupart des antigènes sont thymo-dépendants.Ils sont impliqués dans une coopération avec les lymphocytes T.
La CPA doit dégrader l’antigène (structure complexe, ex : protéine) et le présenter à sa surface par les molécules CMH de classe II.
Les antigènes thymo-dépendants impliquent toutes les Immunoglobulines.
Le lymphocyte B peut en effet commencer sa maturation après le contact avec le lymphocyte T auxiliaire, il rejoint un centre germinatif dans l'organe lymphoïde secondaire où il se trouve et entame son processus de maturation : hypermutations somatiques, commutation isotypique, maturation d'affinité.
Ainsi une telle réponse immunitaire est de plus grande qualité, mais plus longue à mettre en place par le corps (temps de latence).L’agrégation de l’antigène à motifs répétés (par exemple des antigènes exogènes de nature polyosidiques) à la surface des lymphocytes B suffit à activer ces LB.
Ce type d’antigène n’implique que les Immunoglobulines M puisqu'il n'y a pas maturation de ces lymphocytes B et donc pas de commutation isotypique, qui normalement a lieu pendant la maturation des lymphocytes B après un contact entre le lymphocyte B et le lymphocyte T auxiliaire et la migration des lymphocytes B dans un centre germinatif de l'organe lymphoïde secondaire en question, où il mature.
Ces antigènes induisent donc une réponse immunitaire plus rapide, mais de moins grande qualité.Il faut noter que la réponse thymo-indépendante est de deux types : un type I et un type II, selon le mode d'activation des lymphocytes B impliqués (et donc selon la nature de l'antigène TI).
La réponse TI-1 implique une voie commune d'activation parmi plusieurs lymphocytes B différents, la réponse n'est donc pas spécifique et l'activation est polyclonale (ce qui est différent de la notion d'anticorps polyclonaux).
Une réaction analogue, mais toutefois non comparable, se produit lors de la réponse immunitaire avec un superantigène.
Une telle réponse immunitaire s'explique parce que ces antigènes peuvent être reconnus par des récepteurs communs à plusieurs lymphocytes B, et donc plusieurs types de lymphocytes B différents réagissent.
La réponse immunitaire est régulée par le phénomène de tolérance périphérique, médié principalement par les lymphocytes T régulateurs et B régulateurs (découverts récemment).La réponse TI-2, quant à elle, provoque une stimulation monoclonale (ce qui est différent de la notion d'anticorps monoclonaux) des lymphocytes B. Comme dans une réponse immunitaire classique seuls les lymphocytes B capables de reconnaître l'antigène dont ils sont spécifiques vont être activés et réagir.
Cette fois-ci la reconnaissance de l'antigène passe par le récepteur des cellules B (BCR), qui est spécifique d'un seul type de lymphocyte B, ce qui explique pourquoi la réponse est cette fois-ci spécifique et donc monoclonale.Un état immunodépressif caractérise un organisme dont le fonctionnement du système immunitaire est altéré de façon négative, la personne immunodépressive voit ses défenses immunitaires affaiblies.
Plusieurs causes sont possibles : des médicaments immunosuppresseurs (dans ce cas l'immunodépression est réversible), des infections par certains virus (comme le VIH-1), un état de fatigue transitoire, la malnutrition ou encore la présence de maladies qui ne concernent pas obligatoirement directement le système immunitaire, mais qui jouent un rôle dans son affaiblissement (soit directement soit par les traitements médicamenteux lourds).Pour une personne immunodéprimée au niveau de la lignée des lymphocytes T (T CD4+ par exemple) les antigènes thymo-dépendants peuvent être un facteur de risques, celui-ci évoluant selon le niveau de gravité de cette immunodépression.
Ces antigènes nécessitant une coopération des lymphocytes B avec les lymphocytes T auxiliaires, si ces derniers ne sont pas en nombre suffisant le corps peut avoir du mal à se défendre, voire en être incapable et être agressé par des maladies opportunistes causant la mort (par exemple dans le cas de la phase SIDA de l'infection par le VIH-1 où la lignée CD4+ est gravement touchée).
Une personne immunodéprimée au niveau de cette lignée peut tout de même réagir de façon convenable aux antigènes TI.
Cependant rares sont les antigènes induisant une réponse de type TI.
De plus cela ne change rien à la gravité d'un état immunodépressif prononcé, puisque c'est le corps lui-même qui développe des affections, soit parce qu'il ne maintient plus son intégrité (il ne supprime plus les cellules anormales, ce qui débouche sur des cancers), soit parce qu'il est beaucoup plus fragile à des agents pathogènes externes (virus, bactéries…).Dans le cas d'une immunodépression touchant la lignée humorale, les conséquences sont tout aussi graves mais l'immunité à médiation cellulaire reste active.
Dans le cas de personnes immunodéprimées il convient donc de rechercher la cause de cette immunodépression et la lignée touchée, pour adapter les traitements et les vaccinations, qui sont différentes des personnes en bonne santé
Le système du complément est un groupe d'environ 50 protéines connues du sérum, faisant partie de l'immunité innée.
Douze (12) de ces protéines sont directement impliquées dans les mécanismes d'élimination des pathogènes, les autres régulent finement l'activité des premières afin d'éviter une réaction auto-immune (réaction contre le soi).
Il y a trois voies biochimiques qui activent le système du complément : la voie classique du complément, la voie alterne du complément et la voie des lectines liant les résidus mannose des membranes bactériennes.
Le complément peut s'activer en l'absence d'anticorps, dans les trois voies, raison pour laquelle il est considéré comme faisant partie de l'immunité innée.
Néanmoins, la voie dite classique d'activation, la première découverte, peut aussi débuter par la reconnaissance d'anticorps et fait à ce titre partie de l'immunité acquise (dite aussi adaptative).
L'enfant allaité reçoit les compléments C1 à C9 via le lait maternel,.De façon générale, le complément montre qu'immunité innée et immunité acquise doivent être considérées comme deux systèmes collaborant pour élaborer la réponse immunitaire et non comme deux systèmes indépendants.
Le complément stimule l’inflammation et l'opsonisation, lyse directement les cellules pathogènes par formation du complexe d'attaque membranaire, recrute les lymphocytes B (initiant ainsi la réponse adaptative) ainsi que les macrophages phagocytant les pathogènes.À la fin du XIXe siècle, on découvrit que le sérum du sang contenait un « facteur » ou un « principe » capable de tuer les bactéries.
En 1895, Jules Bordet, un jeune scientifique belge à l’Institut Pasteur de Paris, démontra que cet élément pouvait être décomposé en deux composants : un thermostable et un thermolabile.Il a été découvert que le composant thermostable conférait une immunité contre des microorganismes spécifiques, alors que le composant thermolabile était responsable d’une activité non spécifique, conféré par tous les sérums.
Ce composant thermolabile est ce que nous appelons maintenant « complément ».Le terme « complément » fut introduit par Paul Ehrlich à la fin des années 1890, dans une partie de sa grande théorie sur le système immunitaire.
D’après cette théorie, le système immunitaire est constitué de cellules qui possèdent des récepteurs spécifiques à leur surface afin de reconnaître des antigènes.
Après l’immunisation par un antigène, beaucoup de ces récepteurs sont formés, et ils empêchent ainsi ces cellules de circuler dans le sang.Ces récepteurs que l’on appelle maintenant « anticorps », étaient nommés par Ehrlich « Amboceptors », afin d’appuyer sur leur double capacité d’attache : Ils reconnaissent et fixent un antigène spécifique, mais ils peuvent aussi être reconnus et être fixé par le composant antimicrobien thermolabile du sérum.Ehrlich nomma « complément » ce composant thermolabile, parce que c’est un élément présent dans le sang qui « complète » les cellules du système immunitaire.Ehrlich croyait que chaque « amboceptor » spécifique à un antigène avait son propre complément, alors que Bordet croyait qu’il n’y avait qu’un seul type de complément.
Au début du XXe siècle, la controverse fut résolue lorsqu’on comprit que le complément peut agir en combinaison avec des anticorps spécifiques, ou peut aussi agir par sa propre voie non spécifique.Le système du complément est un ensemble de protéines circulantes ou membranaires du sang, principalement sécrétées par le foie.
Leur rôle initialement reconnu était de compléter l'action des immunoglobulines sériques, d'où leur nom.
En l'absence des protéines thermolabiles (qui perdent leur qualités à une température déterminée), les immunoglobulines thermostables spécifiques sont incapables d'entraîner la lyse de leur cible.
Il convient de signaler que le procédé visant à décomplémenter un sérum destiné à un usage en culture cellulaire se fait selon ce principe.
En effet, en portant le sérum à une température de l'ordre de 56 °C, on lui retire ses activités lytiques non spécifiques et spécifiques qui seraient néfastes pour son utilisation ultérieure.
Les protéines du complément représentent environ 5 % des globulines plasmatiques.
Les différentes protéines du complément sont des proenzymes inactives et qui sont activées en cascade par clivage.
Le clivage libère une fraction ayant une activité enzymatique de protéase, et un petit fragment qui possède souvent un rôle sur les cellules inflammatoires.
Le système du complément possède plusieurs fonctions importantes : la cytolyse d'une cellule ou d'un agent pathogène, l'activation du système immunitaire par les petits fragments de clivage proinflammatoires, l'opsonisation de certains agents permettant leur phagocytose, et le métabolisme des complexes immuns circulants grâce aux récepteurs des fragments du complément.
Les différentes voies activant le complément aboutissent à la formation d'une C3 Convertase, point de départ de la voie effectrice commune qui détruit la cible en formant un canal transmembranaire, permettant l'entrée de molécules d'eau dans la cellule.
Les principales protéines du complément sont notées de C1 à C9, elles migrent en électrophorèse dans la fraction des Beta Globulines et ont un poids moléculaire de 100 à 200 kDa.Il existe trois voies principales : la voie classique, la voie alterne, et la voie des lectines, C3 étant le pivot de chacune des voies.Les fragments C3a et C5a sont des molécules appelées « anaphylatoxines » : elles ont pour rôle de libérer l'histamine, de plus C5a a une activité chimiotaxique importante.
Lorsqu'elles sont produites en trop grand nombre, elles peuvent provoquer un choc anaphylactique.
C5a peut aussi activer la voie des lipoxygénases et augmenter l’adhésion leucocytaire.
Tandis que C3b et C3bi fonctionnent comme des opsonines.Les protéines de C5 à C9 en s'assemblant forment le « complexe d'attaque membranaire » (en anglais membrane attack complex, MAC), qui est en l'occurrence l'élément permettant la lyse des cellules pathogènes.La voie classique commence par l'activation du complexe C1, un détecteur de pathogènes qui interagit aussi bien directement avec des pathogènes (immunité innée) qu'avec des  antigène-anticorps (immunité adaptative).
C1 est un gros complexe, composé de trois sous-composants : C1q, le plus gros de ses éléments composé de 6 trimères se terminant chacun par une tête globulaire et dotés d'une queue de type collagène, et qui porte la fonction de reconnaissance du pathogène, C1r et C1s, deux sérine-protéases, qui sont inactives au début du processus.
Lorsque deux têtes globulaires ou plus de C1 se lient à un ligand (pathogène ou anticorps), C1 active C1r, qui devient protéolytique, et clive C1s pour désamorcer la cascade de protéolyse.
Chaque clivage libère un petit fragment : C4a, C2a et C3a qui agissent sur les cellules inflammatoires.Le C1s activé clive alors le C4 en C4a (qui va dans le sang) et C4b qui se fixe sur la membrane de la cellule à lyser et va recruter C2.
C2 sera également clivé par C1s mais aussi via C4b.
Le fragment C2 se divise en C2a et C2b et C2a reste fixé à C4b alors que C2b reste libre.
Le complexe C4bC2a ainsi formé s'appelle la C3-convertase dont le rôle est de scinder C3 en C3a (qui part dans le sang) et C3b.
Ce dernier se fixe sur la membrane de la cellule à lyser et forme le complexe C4bC2aC3b : c'est la C5 convertase.
En immunité innée, C3b se lie ensuite directement au pathogène pour l'opsoniser, selon les cas directement à ses éléments de surface, ou via la Protéine C réactive.
Ces liaisons restent cantonnées à la surface du pathogène.En immunité adaptative, le processus est le même qu'en immunité innée, à cette différence que C3b se lie aux régions Fc d'anticorps.
Seules les IgG1, IgG3, les IgM, et faiblement les IgG2 sont capables d'entraîner la cascade des évènements.
La fixation de deux ou plusieurs immunoglobulines d'IgG ou une molécule d'IgM pentamérique, à la surface d'un microorganisme, permet à leur région Fc de fixer le premier composant de la voie classique.
Ce sont bel et bien les têtes globulaires qui vont interagir avec les fragments Fc des immunoglobulines ayant lié l'antigène.Plusieurs mécanismes interviennent dans la régulation du système de complément :La voie alterne est la première défense mise en jeu lors d'une infection par un germe inconnu de l'organisme infecté avant une réponse immune spécifique.
Elle est activée quant à elle par les surfaces cellulaires des bactéries gram+ ou gram-, quelques cellules infectées par un virus, quelques levures, et parasites.
Également par les polysaccharides, comme le zymosan ou l'inuline, par les LPS (lipopolysaccharides) bactériens, et diverses substances, comme les fibres d'amiante, le gluten, l'hémoglobine, certains produits de contraste fortement iodés et quelques cellules tumorales.
À noter qu'une membrane cellulaire est d'autant plus activatrice de la voie alterne qu'elle est pauvre en acide sialique.
La voie alterne d'activation résulte de la fixation du C3b sur un site accepteur.
En permanence de faibles quantités de C3 sont clivées spontanément en C3a et C3b.
Ce dernier possède, pendant un très court instant, un site hautement réactif capable de se fixer sur des groupements chimiques présents sur virtuellement toutes les surfaces biologiques, principalement bactériennes.
En l'absence de ce site accepteur, le C3b réagit avec l'eau et donne le C3b soluble.Le C3b fixé à une surface peut alors lier le facteur B qui est clivé, en présence d'ions Mg2+, par le facteur D en Bb et Ba, formant la C3-convertase alterne, ou C3bBb.
Cette C3-convertase clive des molécules de C3 pour former un complexe C3bBbC3b, ou C5-convertase alterne.
Cette dernière va à son tour cliver le c5 rejoignant ainsi la voie classique.Elle s'effectue grâce à différentes protéines : Au niveau des membranes, la régulation de l'activation de la voie alterne se fait grâce à différentes protéines membranaires: le récepteur du C, CR1, le facteur d'accélération de dissociation (DAF), la protéine cofacteur de membrane (MCP) ou CD46.
Ces protéines agissent comme cofacteur du facteur I pour dégrader C3b et C4b ou comme accélérateur de la dissociation des C3/C5 convertase alterne ou classique (CR1 et DAF).Une protéine globulaire, la Mannose Binding Lectin (MBL) appartenant à la famille des collectines, peut interagir avec les résidus mannose ou N-acétylglucosamine (GlcNac) des microorganismes.
Sa structure est homologue au C1q.
Sa fixation sur des mannoses de bactéries active 2 sérine-protéases MASP1 et MASP2 ou MASP3 qui clivent et activent C4 et C2, rejoignant ainsi la voie classique.Dans les trois cas, les composants précoces activent localement C3, qui est le facteur pivot du complément, et dont le clivage conduit non seulement à l'assemblage du complexe qui attaque la membrane, mais aussi au recrutement des différents globules blancs.Le C3b, qui est le plus grand fragment de la lyse de C3 par la C3-convertase, se lie de façon covalente à la surface de la cellule.
Le plus petit fragment, C3a, agit quant à lui comme signal diffusible qui provoque une réponse inflammatoire, en stimulant la migration des globules blancs vers le site de l'infection.Le fragment C3b fixé à la membrane, produit à la fois par la voie classique et la voie alterne, et même la voie des lectines, amorce la cascade des réactions qui conduit à la formation du complexe d'attaque membranaire, à partir des composants tardifs du complément.
Il est donc fixé sur la membrane de façon covalente, et il clive le facteur C5 en C5a et C5b.
C5b reste faiblement lié à C3b et s'assemble rapidement à C6 et C7 pour former le complexe C5b67 qui va s'ancrer à la membrane via C7.
Ce complexe lie ensuite C8, pour former le complexe C5b678.
La liaison du facteur C9, qui expose une région hydrophobe après changement de conformation, entraîne son insertion dans la membrane plasmique de la cellule.
Il s'ensuit alors une réaction en chaîne où les C9 de nouvelle conformation vont lier des C9 de l'ancienne, entraînant le changement conformationnel qui leur permet de s'insérer dans la double couche lipidique.
C'est ainsi qu'il se forme un canal au travers de la membrane cellulaire (Complexe d'attaque membranaire (CAM)).
Dès lors, la perméabilité de la cellule est perturbée, les petites molécules pénètrent et sortent de la cellule au voisinage de ces pores, et à travers ceux-ci.
Les macromolécules ne peuvent cependant pas passer.
De ce fait, le mécanisme cellulaire contrôlant l'équilibre des échanges est bouleversé.
L'eau entre par osmose dans la cellule, faisant augmenter son volume jusqu'à la lyse.
On observe ce même phénomène de lyse avec des globules rouges en solution hypotonique.
Ce système est très efficace puisqu'il a été observé que la présence d'un seul de ces canaux permet la lyse d'un globule rouge.Les maladies liées à un déficit en complément sont rares :Les maladies accompagnées de dysfonctionnements du complément sont nombreuses.Bien que certains agents pathogènes soient capables d'inactiver le complément, la plus grande majorité ne le peut pas, et au contraire, active la voie alterne de la C3 convertase.
Ces agents pathogènes favorisent la production des molécules de la voie alterne d'activation, en particulier C3a, C3b, C5a et le complexe d'attaque membranaire C56789.
Celui-ci étant formé sur le site de la C3-convertase, son activité de dégradation s'exerce sur les pathogènes et non sur les cellules de l'hôte.
Les fragments solubles du complément C3a et C5a qui sont formés possèdent des propriétés pro-inflammatoires.
Par exemple, la liaison du C5a aux récepteurs des cellules endothéliales augmente la perméabilité vasculaire et l'infiltration des protéines plasmatiques dans les tissus inflammés.
Rodney Robert Porter (8 octobre 1917 - 7 septembre 1985) est un biochimiste anglais prix Nobel de physiologie ou médecine en 1972 pour la détermination de la structure chimique d'un anticorps.Porter naît à Newton-le-Willows dans le Lancashire en Angleterre.
Il reçoit son baccalauréat universitaire ès sciences de l'université de Liverpool en 1939.
Durant la Seconde Guerre mondiale, il participe à l'invasion de l'Algérie en 1942, puis à celle de la Sicile et de l'Italie.
Il quitte l'armée début 1946 après être allé en Autriche et en Grèce.En 1948, il obtient son doctorat dans le domaine de la biochimie à l'université de Cambridge.
Il travaille au National Institute of Medical Research de 1949 à 1960 avant de rejoindre l'école médicale du St Mary's Hospital où il occupe la chaire Pfizer d'immunologie.
En 1967, il est engagé comme professeur de biochimie à l'université d'Oxford.En 1972, Porter reçoit, avec Gerald Edelman, le prix Nobel de physiologie ou médecine « Pour leurs découvertes concernant la structure chimique d'un anticorps ».Porter meurt dans un accident de la circulation en 1985.Alors que la nature protéinique des anticorps est déjà établi, leur structure exacte est inconnue.
Porter au départ considère qu'un anticorps est composé d'une seule chaîne peptidique.
En 1958 et 1959, il montre qu'un enzyme, la papaïne, permet de découper un anticorps provenant d'un lapin en trois parties.
Une des trois portions cristallise et Porter pense d'abord qu'elle est due à un artefact de la méthode de préparation.
De son côté Gerald Edelman, entre 1959 et 1961, montre que les anticorps humains sont composés de chaînes peptidiques multiples liées entre elles par des ponts disulfures.Porter à partir de cette découverte utilise des techniques connues de réduction du pont disulfure pour fragmenter un anticorps en quatre parties, deux semblables de 20 000 uma environ et deux autres semblables de 50 000 uma.
Des analyses supplémentaires le conduisent à postuler la structure d'un anticorps.
Faculty of 1000, abrégé « F1000 », est un éditeur de services pour les chercheurs dans les sciences de la vie.
Il fournit des révisions et une notation des recherches publiées en biologie.
Un réseau de près de 1 000 chercheurs ou professeurs universitaires en sciences évalue les articles selon le principe de l'évaluation par les pairs.Faculty of 1000 a été fondé en 2000 par l'entrepreneur Vitek Tracz, un pionnier de l’édition scientifique et fondateur des journaux BioMed Central et Current Opinions.
L'entreprise fait partie du groupe Science Navigation, qui possède également Web of Stories (en).En mars 2015, Tracz est apparu dans un article de Library Journal titré « F1000’s Vitek Tracz: Redefining Scientific Communication », discutant des problèmes de l’évaluation par les pairs et de sa vision du fait que ce procédé est sur ses fins.F1000Research est une plate-forme de publication en open access, évaluée par les pairs, couvrant les sciences de la vie.
Les articles sont d'abord publiés, et, ensuite, des relecteurs invités commentent la publication.
Leurs noms et commentaires sont visibles sur le site.
Les données utilisées pour chaque article sont également publiées.
La plate-forme a été critiquée pour l’opacité de ses critères de relecture,.
F1000Research publie également des posters et des diapositives (slides) de conférences dans les domaines de la biologie et de la médecine.
Un milieu de culture est un support qui permet la culture de cellules, de bactéries, de levures, de moisissures afin de permettre leur étude.
En principe, les cellules trouvent dans ce milieu les composants indispensables pour leur multiplication en grand nombre, rapidement, mais aussi parfois des éléments qui permettront de privilégier un genre bactérien ou une famille.
Ainsi, selon le but de la culture, il est possible de placer les micro-organismes dans des conditions optimales, ou tout à fait défavorables.Il se compose d'une base (agar-agar, eau, minéraux, etc.) ainsi que d'un indicateur coloré de pH ou de réaction d'oxydoréduction pour permettre  de formuler des hypothèses sur le genre.Il existe aussi des bouillons de culture qui possèdent la même fonction, mais ces milieux ne contiennent pas d'agar-agar, ils sont donc totalement liquides.Cet article détaille les caractéristiques des milieux de culture se rapportant à la microbiologie.Un milieu minimum ou milieu défini est un milieu comportant les éléments chimiques strictement nécessaires à la croissance bactérienne, sous une forme utilisable par des bactéries n'ayant pas d'exigence particulière.Composition d'un milieu minimum :En l'absence de l'un de ces composants, les bactéries ne se développent pas, car elles ne peuvent synthétiser ces produits.
C'est l'adjonction de facteurs de croissance appropriés qui permet à des bactéries exigeantes de se développer.Un milieu de culture dit « empirique » est un milieu contenant des produits d'origine naturelle et dont on ne connaît pas exactement la composition.Dans le milieu type cœur-cervelle, il y a de l'eau, de l'agar-agar, de l'hydrolysat de cœur et de cervelle sans que l'on en connaisse les aspects qualitatifs et quantitatifs.
Il sera donc utilisé uniquement pour la croissance des bactéries.
Il n'a pas d'effet sélectif.Les premières recherches sur les virus, à partir des années 1930, utilisent comme milieu de culture l'œuf de poule embryonné.
L'agent à multiplier est inoculé dans les membranes amniotiques ou allantoïques.
Dans ce système ont pu être étudiés les virus de la variole, de l'herpès, de la grippe, des oreillons, de la rage, etc., ainsi que des bactéries intracellulaires comme les rickettsies.
Dans les années 1950, ce système a été le plus souvent supplanté, dans les laboratoires de recherche, par la culture cellulaire.
Il reste utilisé pour la production du vaccin antigrippal.Les milieux de culture dits « sélectifs » permettent uniquement la culture de certains genres de micro-organismes.
Pour cela, on ajoute des éléments qui inhibent la croissance des micro-organismes indésirables comme le chlorure de sodium à forte concentration, le thiosulfate de sodium, le cristal violet ou certains antibiotiques.Les éléments ajoutés sont sélectionnés selon les caractéristiques du micro-organisme recherché.
Ces milieux sont utilisés pour l'analyse d'un prélèvement polybactérien.
Ce milieu permet de sélectionner uniquement en cas de crible positif : résistance à un antibiotique, la prototrophie, etc.Exemples de milieux sélectifs :Les milieux de culture enrichis contiennent, outre les composants de base, des composants indispensables aux bactéries, que celles-ci ne peuvent pas synthétiser.
Ce sont des milieux utilisés pour l'obtention des bactéries dites « exigeantes » et auxotrophes.
Par exemple : les milieux au sang frais (le sang est riche en nutriments divers comme le fer, principal facteur de croissance des bactéries) : gélose au sang frais ou cuit.Les milieux avec du sérum, du jaune d'œuf : gélose Baird Parker ou dite « BP ».Le  milieu de culture dit « différentiel » ou « indicateur » permet de distinguer deux types de microorganismes se développant dans un même milieu.
Ce type de milieu met en évidence certaines caractéristiques biochimiques des microorganismes (principalement l'aptitude à dégrader un substrat) en présence d'indicateur(s) de la réaction chimique : des indicateurs colorés de pH ou d'oxydoréduction (tels que le rouge neutre, rouge de phénol, l'éosine ou le bleu de méthylène).On retrouve parmi les milieux différentiels :Ce milieu peut être sélectif ou non.
Son principe repose sur la présence d'un ou plusieurs substrat(s) couplé(s) à une molécule chromogène.
Lorsque ce substrat est métabolisé par une enzyme bactérienne spécifique, le chromogène associé prend une couleur particulière (il devient un chromophore) directement lisible sur la colonie.
Si l'enzyme n'existe que chez une espèce bactérienne donnée, l'identification est immédiate.Parmi ces milieux, on trouve :Depuis 2014, la norme ISO 1133 impose des contrôles sur la performance des milieux.
Ceci sont à réaliser à des fréquences régulières telles que :
Le secret commercial, proche ou équivalent francophone du « trade secret » des anglophones, est défini comme « toute information, y compris mais non limitée aux données techniques ou non techniques, formules, recettes, compilations, programmes d'ordinateur, méthodes, techniques, procédés, données financières, ou aux listes des clients ou fournisseurs actuels ou potentiels ».
En droit français et européen, le secret des affaires ou le secret d'affaires se sont récemment substitués au secret commercial.Il peut englober le secret industriel et n'est pas nécessairement associé à la notion de propriété commerciale ou de propriété industrielle, lesquelles offrent des droits privatifs (en échange de redevance), alors que le « régime du secret » ne confère en tant que tel aucun droit de propriété à son détenteur.
Parfois (au Canada par exemple), l'expression secret commercial peut être assimilée à celle de secret industriel.La recherche des secrets d'entreprises concurrentes n’est pas fautive en elle-même,  elle ne le devient que lorsque des moyens déloyaux sont utilisés.Le secret des affaires n'a de sens que quand l'information associée à l'élément devant rester « secret » a — en restant cachée — une valeur réelle (actuelle ou potentielle), du point de vue de l'intérêt commercial.Soit que le secret donne un avantage à l'entreprise, soit qu'elle prive ses concurrents d'avantages auxquels ils pourraient sans cela accéder.Dans les entreprises, le secret est presque toujours partagé entre plusieurs personnes (associés, employés, sous-traitants) mais alors sous le sceau de la confidentialité.
Un élément « substantiel » de confidentialité doit exister pour que l'on puisse parler de secret commercial, associé à un avantage (économique actuel ou potentiel).Le secret commercial peut être constitué d'une combinaison particulière de données toutes présentes dans le domaine public, mais qui prennent une valeur commerciale spécifique(avantage compétitif de type amélioration ou moindre coûts de la production, ventes facilitées…) quand elles sont assemblées.On considère souvent que la condition de confidentialité est « remplie dans le cas où il serait difficile et coûteux pour les tiers d'obtenir et d'exploiter les informations sans adopter un comportement fautif ».la protection des informations ayant une valeur commerciale pour l'entreprise doit être assurée par celle ci par des « dispositions raisonnables de protection ».
Contourner ces protections constitue un moyen illégitime d'accéder à un secret des affaires.L'une des limites de ce concept est que dans certains cas (quand il n'a pas été précisément défini devant un tiers officiel autorisé ou agréé comme on le fait pour un procédé breveté), le « secret » (qui peut être la connaissance d'un contexte particulier, ou un assemblage de procédés du domaine public, non déposé et non breveté) peut aussi être révélé par un acteur ne connaissant ni son utilité ni son caractère secret, ce qui ne peut alors lui être reproché.De plus, dans tous les cas, un secret commercial « ne confère pas de droits exclusifs, et n’empêchera personne de mettre au point une invention, création semblable à la vôtre et de la commercialiser »Des ententes de confidentialité signées sont possibles, mais peuvent parfois être assimilées à des ententes illicites, dans le cas où elles permettraient une concurrence déloyale.En Europe et en France, l'extension de la législation relative à la protection du secret des affaires, promulguée fin juillet 2018 en France, pose des questions relatives à l'opacité du monde industriel et financier, ainsi qu'au respect des droits et libertés fondamentales des individus et collectivités,.
Cette loi a été rédigée à l'occasion de la transposition d'une directive du Parlement européen de 2016.
Le but est de fixer une définition et un cadre juridique communs pour l'Union Européenne.En 2018, 138 parlementaires de gauche ont dénoncé « une atteinte grave, excessive et injustifiée à la liberté d’expression et de communication » et ont saisi le Conseil constitutionnel.
Celui-ci a jugé cette loi conforme à la Constitution Décision n° 2018-768 DC du 26 juillet 2018.
Le Conseil constitutionnel fait valoir à ce sujet l’existence d’une « exception à la protection du secret des affaires bénéficiant aux personnes physiques exerçant le droit d’alerte », mais aussi « toute personne révélant, dans le but de protéger l’intérêt général et de bonne foi, une activité illégale, une faute ou un comportement répréhensible ».
La directive a été transposée en droit national par la loi n° 2018-670 promulguée le 30 juillet 2018, relative à la protection du secret des affaires et le décret n° 2018-1126 du 11 décembre 2018,.En juin 2022, un jugement du tribunal administratif de Paris donne droit aux représentants syndicaux CFE-CGC et CGT « d'accéder aux lettres d'engagements négociés avec l'État français lors du rachat d'Alcatel-Lucent en 2016 » par Nokia.
Ce qui devrait permettre de vérifier les contreparties sur l'emploi contenues dans l'accord en dépit du secret des affaires allégué.La vidéo dénonçant la directive européenne sur le secret des affaires de Nicole Ferroni, humoriste et chroniqueuse à France Inter, a déjà été vue plus de 12 millions de fois.De nombreuses associations de journalistes et d’organisations non gouvernementales (ONG) dénoncent des conséquences désastreuses des lois sur le secret des affaires pour tous ceux qui seraient amenés à dévoiler au public des manquements importants de la part des entreprises.
Selon l’ONG Anticor, les laboratoires Servier auraient échappé au scandale du Mediator.
Personne n’aurait entendu parler « des Panama Papers, des Paradise Papers, du Diesel Gate ou de l’affaire UBS ».L'Agence nationale de sécurité du médicament et des produits de santé (ANSM) se réfère au secret des affaires pour empêcher la transmission d’informations sur la provenance du principe actif du Levothyrox, dont la nouvelle formule est au cœur d’une polémique.La Commission d’accès aux documents administratifs(CADA) invoque le secret des affaires concernant une demande d'information sur les dispositifs médicaux (défibrillateurs, pompes à insuline, prothèses de hanche, etc.), formulée par Le Monde au cours de l’enquête des « Implant Files ».
Le Laboratoire national de métrologie et d'essais, LNE/G-MED, seule société habilitée à contrôler les dispositifs en France, avait déjà refusé de communiquer ses données.
La non-transparence au nom du secret commercial a été l’un des principaux obstacles aux 1 500 demandes d’accès aux documents publics effectuées au cours de l’enquête internationale par le Consortium international des journalistes d'investigation.
Le Monde obtient une demi-victoire devant le tribunal administratif qui oblige la CADA à donner certaines informations sur une partie des dispositifs médicaux commercialisés en France.Dans l'affaire des LuxLeaks, le statut de lanceur d’alerte a été reconnu au Luxembourg pour Antoine Deltour, sa condamnation a été annulée en cour de cassation du Luxembourg.
Il avait mis en évidence, lors de l’émission Cash Investigation puis lors d'une enquête du Consortium international des journalistes d'investigations, le contenu de centaines d’accords fiscaux secrets, dits « rescrits fiscaux », conclus entre l’administration luxembourgeoise et PwC pour le compte de grandes multinationales.Des journalistes et des ONG dénoncent des poursuites  de la part du groupe Bolloré pour les dissuader d’enquêter et les réduire au silence, l'entreprise évoque le « secret des affaires », alors  celles-ci ont des conséquences potentiellement néfastes pour l’intérêt général.La justice allemande enquête sur le journaliste à l’origine des « CumEx Files »(enquête de 18 médias internationaux, dont Le Monde) qui ont permis de révéler l’ampleur de la fraude européenne aux dividendes pour violation du secret des affaires.Le magazine économique Challenges se retrouve devant la cour d’appel de Paris pour défendre la liberté d’informer.
Il avait dû retirer de son site, en janvier 2018, un article consacré aux déboires financiers de Conforama.En 2020, selon la cellule Investigation de France Inter, la Commission européenne, confrontée à la pandémie du Covid-19, a cédé aux exigences de l’industrie pharmaceutique qui lui a demandé une confidentialité quasi totale sur les aides accordées pour la recherche et sur le coût des achats de Vaccin contre la Covid-19, faisant partie des contrats considérés comme secrets.En 1917, dans le contexte de la guerre mondiale, Lénine, dans ses écrits, critique violemment le « secret commercial ».
Il le décrit comme une condition-clé du capitalisme et il souhaite que ce secret soit définitivement aboli (par décret ; c'est une des 3 « mesures de contrôle » qu'il propose ;car selon lui :
Les macrophages (du grec macro-, gros et -phagein, manger) sont des cellules appartenant aux globules blancs, qui sont définis historiquement par leur capacité de phagocytose.
Ce sont des grosses cellules arrondies avec un noyau excentré et des vacuoles dans leur cytoplasme.
Ils ont deux origines : certains macrophages ont une origine embryonnaire et résident dans les tissus tout au long de la vie de l'individu, d'autres proviennent de la différenciation de leucocytes sanguins circulants, les monocytes.Les macrophages sont des phagocytes et sont donc capables de phagocytose.
Leur rôle principal est de phagocyter les débris cellulaires et les agents pathogènes.
La reconnaissance de motifs microbiens par les récepteurs situés à la surface des macrophages conduit à la phagocytose et à la destruction des agents infectieux, par le processus d'explosion oxydative (oxidative burst en anglais) et la production de radicaux libres de l'oxygène.
Les macrophages produisent également des chimiokines, permettant le recrutement d'autres cellules sur le site de l'infection.Comme les cellules dendritiques, ils sont capables de se comporter comme des cellules présentatrices d'antigène.
Ils participent à l’immunité innée en tant que défense non spécifique, mais sont capables de participer à l’immunité adaptative via le phénomène d’opsonisation.Ils ont été découverts par le biologiste russe Elie Metchnikoff en 1883.
Leur nom provient du grec : « gros mangeur », μάκρος, makros = grand et φαγεῖν, phagein = manger.La plupart des macrophages résidents des tissus sont des macrophages embryonnaires.
Ils dérivent directement de cellules de la vésicule vitelline sans passer par un état monocytaire et sont capables d'auto-renouvellement et de maintenance indépendamment des monocytes.Les macrophages de la lignée monocytaire (ou macrophages monocytaires) ont été davantage étudiés pour des raisons pratiques.
Ils sont différenciés à partir des monocytes, qui sont des phagocytes sanguins, eux-mêmes dérivés de la moelle osseuse.
Quand un monocyte infiltre un tissu en traversant l’endothélium vasculaire par diapédèse, il subit sa différenciation terminale pour devenir un macrophage.
Les monocytes, puis les macrophages sont attirés vers le lieu d’une inflammation par chimiotactisme.
Les signaux d’appel sont constitués de différents stimuli, dérivés de cellules endommagées (par nécrose ou apoptose), de pathogènes, et de produits libérés par les cellules présentes au site : l’histamine relarguée par les mastocytes et les granulocytes basophiles, et des chimiokines et cytokines libérées par des macrophages.Contrairement aux granulocytes neutrophiles, qui sont les cellules phagocytaires présentes le plus vite au lieu de l’inflammation et qui ne vivent que quelques jours, la durée de vie d’un macrophage va de plusieurs mois à des années.
Au cours du temps, on a un remplacement de la plupart des macrophages embryonnaires par des macrophages d'origine monocytaire.
Ce remplacement n'est pas observable pour la microglie, une population de macrophage embryonnaire qui peuple le système nerveux central.Les macrophages peuvent se définir par les marqueurs membranaires CSF1R et CD64.Ils interagissent grâce à la présence de plusieurs types de récepteurs : les récepteurs PAMP et DAMP, les récepteurs opsioniques, les récepteurs cytokinétiques et chimiokinétique, les récepteurs de  signalisation, les récepteurs d'adhésivité cellulaire et des récepteurs modulant leur activé par un rétrocontrôle négatif.
L'existence de deux catégories de macrophages nommées M1 et M2 a été proposée depuis les années 2000.
Les M1 sont impliqués dans la destruction des agents pathogènes.
Les M2 sont impliqués dans la réparation et cicatrisation cellulaire.
Cette différenciation se fait par une dégradation différente de l'arginine  en oxyde nitrique dans le cas de M1 et en ornithine dans le cas de M2.
Toutefois, cette distinction ne semble appropriée que dans des modèles in vitro.
L'hétérogénéité des populations de macrophages dans les modèles in vivo suggèrent que cette distinction est artificielle et ne traduit pas une réelle dichotomie dans les fonctions des macrophages.
Les macrophages forment une population "plastique" : ils peuvent changer d'un phénotype à l'autre in vivo.
On parle de polarisation des macrophages pour désigner le processus par lequel les macrophages exhibent un phénotype spécifique et une réponse fonctionnelle aux stimuli du microenvironnement et aux signaux rencontrés par les macrophages dans des tissus spécifiques.
La fonctions des macrophages est spécifiques des tissus considérés : il est délicat de leur attribuer une fonction générale.
Si on doit catégoriser les fonctions des macrophages, elles peuvent être considérées comme étant des fonctions immunitaires ou des fonctions homéostatiques.Un des rôles principaux des macrophages est le nettoyage de corps nécrotiques et de corps apoptotiques, de débris et de poussières dans le cas des poumons.
L’élimination des cellules mortes est importante dans le cadre des phases précoces de l’inflammation chronique.
Cette élimination est dominée par l’action des granulocytes neutrophiles, qui seront eux-mêmes phagocytés par les macrophages une fois vieillis (voir CD31 pour plus de détails).L’élimination de la poussière et des tissus nécrotiques est prise en charge à une plus grande échelle (hors inflammation), par des macrophages résidents qui restent à des endroits stratégiques comme les poumons, le foie, les tissus nerveux, les os, la rate et les tissus conjonctifs, et qui digèrent les particules étrangères comme la poussière et les débris, mais aussi les pathogènes, recrutant en cas de besoin des monocytes circulants pour leur différenciation locale en macrophages tissulaires.Lorsqu’un macrophage ingère un pathogène, la vésicule intracellulaire formée est nommée phagosome.
Elle va fusionner avec un lysosome.
Les enzymes lysosomiales et les radicaux libres de l’oxygène (notamment l’hypochlorite) vont tuer et digérer l’intrus.
Cependant, certains organismes peuvent résister à ce processus et survivre dans le macrophage, comme Mycobacterium tuberculosis ou les Leishmania.
Un macrophage peut digérer une centaine de bactéries avant de succomber lui-même à ses propres enzymes de digestion.Après avoir digéré un pathogène, un macrophage peut se comporter en cellule présentatrice d'antigène, c’est-à-dire présenter un antigène de manière à stimuler un lymphocyte T spécifique.
La stimulation lymphocytaire par un macrophage est moindre que celle induite par une cellule dendritique, mais les macrophages sont capables de présenter des antigènes associés  aux molécules du complexe majeur d'histocompatibilité de classe deux, et donc de stimuler des lymphocytes CD4+.Une immunisation se traduit également par la production d'anticorps dirigés contre les antigènes immunisants.
Ces anticorps vont se lier aux antigènes de surface des pathogènes.
Certains isotypes sont opsonisants, c'est-à-dire qu’il existe sur les phagocytes des récepteurs spécifiques des fragments constants des chaînes lourdes des anticorps.
(Dans le cas des IgG (immunoglobuline d'isotype G), ce sont les CD16, CD32 et CD64.)
Les macrophages possèdent ce type de récepteurs et la liaison d’un complexe immun à ces récepteurs déclenche la phagocytose.
Ainsi, un pathogène qui sera invisible aux yeux d’un macrophage deviendra visible une fois opsonisé.Les macrophages sont capables de sécréter un grand nombre de cytokines comme l'interleukine 1 (IL-1), l'interleukine 6 (IL-6), le facteur nécrosant des tumeurs (TNF-α).
Ils participent de façon active au recrutement des autres cellules de l'immunité innée.
In vitro, les macrophages M1 activés libèrent des cytokines pro-inflammatoires dont le TNF-α, l'IL-1α, l'IL-1β, l'IL-6, l'IL-12, l'IL-18 et l'IL-23.
Ils produisent de l'oxyde nitreux (NO), des espèces réactives de l'oxygènes (ROS) et des espèces réactives de l'azote (RNS).
Ils expriment également des récepteurs aux chimiokines (CCR1 et CCR5).In vitro, les macrophages M2 activés libère plutôt des cytokines de résolution de l'inflammation comme l'IL-10 ou le TGF-β.Les macrophages jouent un rôle important au niveau de la peau qui est un organe important pour l'immunité.
Ils  stimulent également les cellules impliquées dans la cicatrisation ou la régénération du derme (et un défaut de cette fonction de réparation peut conduire à des phénomènes inflammatoires et au cancer).
Les macrophages peuvent aussi stimuler les cellules souches des follicules pileux qui produisent poils et cheveux via des signaux moléculaires émis par les macrophages et reçus par les cellules souches du follicule pileux au repos (HF-SCs).Un type particulier de macrophages, les ostéoclastes, sont responsables de l'homéostasie tissulaire dans l'os.
Ils jouent un rôle de contrôle de la quantité d'os fabriqué.Certains macrophages résidents des poumons libèrent le surfactant pulmonaire.Les macrophages contribuent de façon importante dans la progression de maladies inflammatoires comme le diabète, le cancer, et l'athérosclérose.
Parmi leur rôles en pathologie humaine :La majorité des macrophages (en situation non inflammatoire) résident à des endroits stratégiques du corps.Ils sont ainsi présents aux endroits les plus susceptibles d’invasion microbienne ou d’accumulation de débris de toutes sortes.Les macrophages portent un nom différent selon leur localisation :
Le terme biomédical peut se rapporter à :
Un épitope, aussi appelé déterminant antigénique, est une molécule qui peut être reconnue par un paratope (partie variable d'un anticorps ou d'un récepteur membranaire des lymphocytes B (BCR) et lymphocytes T (TCR)), pour déterminer si elle appartient au domaine du soi ou au domaine du non-soi.
Un antigène est caractérisé par ses épitopes, si ses épitopes sont reconnus comme appartenant au non-soi alors il est lui-même immédiatement reconnu comme appartenant au non-soi.
Cette reconnaissance épitope/paratope est donc à la base de la réponse immunitaire spécifique : elle permet la sélection clonale, c’est-à-dire la sélection des acteurs capables de s'attaquer spécifiquement à l'antigène correspondant à un épitope particulier.Il existe plusieurs types d'épitopes : les épitopes B et les épitopes T.Les épitopes B sont des parties d'antigène présents sous la forme entière de l'antigène et susceptibles d'être reconnus par un paratope de type anticorps.
La structure de l'épitope B doit donc être complémentaire avec le site de fixation de l'anticorps, la structure mise en jeu peut être la structure primaire dans le cas d'un épitope séquentiel ou la structure tertiaire dans le cas d'un épitope non-séquentiel (ou épitope de conformation).
Un épitope B est donc un représentant de l'identité d'un antigène sous sa forme entière.Si un épitope B est reconnu par un BCR (pour B cell receptor, récepteurs propre des lymphocytes B), alors le lymphocyte B en question est activé contre cet antigène.
Si l'anticorps est thymo-dépendant il aura besoin d'un signal (cytokines) de la part des lymphocytes T helper 2 (Cellule CD4 plus CD4+ différencié) pour parfaire son activation.
Le lymphocyte B peut ensuite se multiplier et se différencier en plasmocyte : lymphocyte B sécréteur d'anticorps spécifiques de l'épitope B concerné.
Ces anticorps pourront donc réaliser une reconnaissance de l'épitope B comme expliqué ci-dessous.Si un épitope B est reconnu par un anticorps circulant, alors l'antigène porteur de l'épitope B et l'anticorps correspondant formeront un complexe immun qui neutralisera l'antigène (inhibition de la toxicité) et amènera ensuite à sa destruction par phagocytose.Les épitopes B sont donc la clé de l'immunité humorale.Les épitopes T sont des parties de protéine (ou dans certains cas particuliers des polysaccharides) présentés à la surface des cellules de l'organisme ce qui permet la reconnaissance par le système immunitaire de l'hôte.Ces polypeptides sont la plupart du temps des résidus de protéines dégradées par la cellule hôte, ils sont ensuite associés à des complexes protéiques appelés CMH (pour Complexe majeur d'histocompatibilité), qui en se fixant sur la membrane plasmique de la cellule hôte permettront la présentation de l'épitope aux cellules immunitaires.Les épitopes T peuvent être présentés par deux types de molécules CMH, les molécules CMH de classe I et les molécules CMH de classe II.Les molécules CMH de classe I sont présentes dans presque toutes les cellules de l'organisme et permettent de présenter des épitopes issus de protéines endogènes, c’est-à-dire codées et produites à partir du génome de la cellule puis dégradées en peptides de 9 acides aminés par le protéasome.
Ces épitopes sont donc exclusivement de type séquentiel.
Les CMH I présentent leur épitopes aux TCR (pour T cell receptor) des lymphocytes T8 CD8+.Si la protéine ayant abouti à un épitope particulier est une protéine virale, c’est-à-dire qu'elle est le fruit de l'infection de la cellule par un virus, alors l'épitope en question sera reconnu par les cellules immunitaires comme viral et entraînera l'activation d'une réaction immunitaire amenant à la lyse de la cellule par les lymphocytes T8 dit lymphocytes cytotoxiques.Si la protéine est une protéine du « soi », alors l'épitope correspondant sera reconnu comme tel et empêchera l'activation d'une réaction immunitaire contre cette cellule.L'épitope reconnu étant issu de l'activité intracellulaire, il représente les protéines de la cellule et est la clé de l'immunité à médiation cellulaire.Dans d'autres cas les polypeptides formant l'épitope ne sont pas de type endogène, c’est-à-dire que les protéines ne sont pas issues d'une traduction par la cellule, comme précédemment, mais sont d'origine exogène.
En effet certaines cellules, les cellules présentatrices d'antigène ou CPA (les cellules dendritiques, les lymphocytes B et les macrophages) présentent à leur surface un autre type de molécule CMH (dit de classe II) spécialisées dans la présentation de polypeptides issus de protéines exogènes, apportées par un organisme étranger, entrées dans le milieu intracellulaire par endocytose et découpées en polypeptides (de 11 à 25 acides aminés) dans les endosomes.
Ces cellules peuvent donc présenter un antigène dit « natif » au TCR (pour T cell receptor) des lymphocytes T4 qui se différencieront d'une part :
L'année 2011 est une année commune qui commence un samedi.
C'est la 2011e année de notre ère, la 11e année du IIIe millénaire et du XXIe siècle et la 2e année de la décennie 2010-2019.L'année 2011 du calendrier grégorien correspond aux dates suivantes :Les lauréats du Prix Nobel en 2011 sont :
Le western blot (également appelé transfert de protéines ou buvardage de western ou encore technique des immuno-empreintes), est une méthode de biologie moléculaire permettant la détection et l'identification de protéines spécifiques dans un échantillon biologique (sérum ou autre extrait ou homogénat tissulaire) à l'aide d'anticorps dirigés contre ces protéines que l'on souhaite détecter.
Le western blot permet ainsi de visualiser des protéines particulières dans un mélange complexe.
C'est l'une des techniques analytiques de transfert sur membrane utilisées en biochimie et en biologie moléculaire.Elle est parfois utilisée comme un outil de diagnostic complémentaire pour mettre en évidence une protéine particulière (protéine virale, par exemple) dans le sérum d'un patient.Cette technique, née des progrès de la protéomique, de la biologie moléculaire et de l'Immunofluorescence, utilise l'électrophorèse sur gel de polyacrylamide pour séparer des protéines, préalablement dénaturées, selon leur taille.
Ces protéines sont ensuite transférées depuis le gel sur une membrane (typiquement en nitrocellulose), où elles sont exposées à un anticorps spécifique de la protéine d'intérêt.
Il est possible grâce à cette technique de détecter la présence d'une protéine dans un tissu, d'évaluer sa taille, sa concentration, les variations de cette concentration, effectuer des comparaisons de concentrations entre différents groupes, etc. D'autres techniques utilisant les anticorps permettent la détection de la protéine dans les cellules après fixation (immunocytochimie) et dans les tissus (immunohistochimie).La méthode fut mise au point dans le laboratoire de George Stark à Stanford.
Le nom du western blot, donné à la technique par W. Neal Burnette, est un jeu de mot à partir de la technique du Southern blot ou transfert de Southern, technique de détection d'ADN nommée d'après son inventeur, Edwin Southern et non d'après le point cardinal.
La détection d'ARN est appelée northern blot ou transfert de northern.
Toutes ces techniques dérivent leur nom de l'étape de transfert sur membrane, comparée à une empreinte sur buvard (blot = « tache » en anglais).Les échantillons (d'un tissu ou d'une culture cellulaire) sont rapidement refroidis, voire réfrigérés (en dessous de 0 °C).
Ils sont homogénéisés par sonication (utilisation d'ultra-sons pour rompre les membranes), contrainte mécanique ou simplement lysés par utilisation de tampons à haute concentration en sels.
Il en résulte un homogénat de tous les compartiments cellulaires, pouvant être utilisé tel quel ou être soumis à plusieurs étapes de centrifugation différentielle afin d'isoler les fractions cytosolique, nucléaire et membranaire.
L'échantillon est ensuite traité de façon à recueillir un taux constant de protéines à partir de chaque échantillon différent.
Cela implique un dosage des protéines par la méthode du Biuret ou du bleu de Coomassie (Méthode de Bradford).Les échantillons sont ensuite bouillis de 1 à 5 minutes dans une solution tampon d'électrophorèse (par exemple le tampon de Laemmli), contenant une substance tampon, généralement du Tris, un colorant, un composant sulfhydryl (typiquement du  beta-mercaptoéthanol ou du dithiothréitol ou plus simplement DTT), un détergent anionique lipophile (sodium dodécyl sulfate ou SDS) et du glycérol pour diminuer la poussée d'Archimède.
La poussée d'Archimède entraine, un corps plongé dans un fluide, verticalement vers le haut.
L'ébullition dénature les protéines en brisant les faibles liaisons intramoléculaires, ce qui a pour conséquence de les dérouler complètement.
Le SDS leur procure alors un environnement riche en charges négatives afin de les solvater et prévenir la précipitation, et le composant sulfhydryl empêche la regénération des ponts disulfure.
Le glycérol augmente la densité de l'échantillon par rapport au tampon dans la partie supérieure du réservoir du gel, facilitant la mise en place des échantillons qui descendront plus facilement au fond des compartiments du gel.Les protéines de l'échantillon sont séparées selon leur taille par électrophorèse sur gel, dont la composition varie en fonction du laboratoire, du poids moléculaire des protéines d'intérêt et des tampons disponibles.
Les gels de polyacrylamide sont les plus fréquents.
Les protéines ne traversant le gel que dans une dimension (du haut vers le bas), les échantillons sont chargés l'un à côté de l'autre dans des puits formés dans le gel.
Les protéines sont séparées par masse en « bandes » dans chaque « couloir » formé sous les puits.
Un couloir est réservé à un « marqueur » ou « échelle standard », une mixture de protéines possédant des poids moléculaires définis disponibles dans le commerce.Il est également possible d'employer un gel 2D qui, à partir d'un seul échantillon, permet de faire migrer les protéines dans deux dimensions.
Les protéines sont alors séparées par leur point isoélectrique (c'est-à-dire le pH auquel leur charge nette est neutre) dans la première dimension, et selon leur poids dans la seconde.La composition d'un tampon d'électrophorèse (running buffer) pour western blot est d'un volume de tampon TGS (Tris-glycine-SDS) dilué 10 fois dans 9 volumes d'eau distillée.Afin de rendre les protéines accessibles à la détection par anticorps, elles sont transférées depuis le gel sur une membrane de nitrocellulose ou de PVDF.
La membrane est placée face-à-face avec le gel, et un courant électrique est appliqué aux grandes plaques sur l'un des deux côtés.
Les protéines chargées migrent depuis le gel vers la membrane en conservant l'organisation relative qu'elles avaient dans le gel.
Il résulte de ce transfert que les protéines sont exposées sur une surface mince, ce qui facilite les étapes de détection ultérieures.
Tant les membranes de nitrocellulose que de PVDF sont « collantes », liant des protéines de manière non spécifique (c'est-à-dire qu'elles lient toutes les protéines présentes dans l'échantillon de la même façon).
La fixation des protéines à la membrane se fait grâce à des interactions hydrophobes et ioniques entre la membrane et les protéines.
Bien que les membranes de nitrocellulose soient moins chères que celles en PVDF, elles sont moins solides et ne peuvent être employées plusieurs fois.
À la différence de celles en nitrocellulose, les membranes de PVDF doivent être imbibées de méthanol ou d'isopropanol à 100 % avant leur utilisationLa composition pour un litre d'un tampon de transfert type est de :Cette étape visualise la protéine totale qui a été transférée avec succès à la membrane.
La coloration des protéines permet à l'utilisateur de vérifier l'uniformité du transfert de protéines et d'effectuer une normalisation ultérieure de la protéine cible avec la quantité réelle de protéines par voie.
La normalisation avec le soi-disant "contrôle interne" a été basée sur l'immunocoloration des protéines constitutifs ou des protéines de structure (comme l'actine ou la tubuline) dans la procédure classique, mais se dirige vers la coloration des protéines totales récemment, en raison des avantages multiples.
Au moins sept approches différentes pour la coloration des protéines totales ont été décrites pour la normalisation des Western blot: Ponceau S, stain-free technique, Sypro Ruby, Epicocconone, Coomassie R-350, Amido Black et Cy5.
Afin d'éviter le bruit du signal, la coloration des protéines doit être effectuée avant le blocage de la membrane.
Néanmoins, des colorations post-anticorps ont également été décrites.La membrane ayant été choisie pour ses propriétés de liaison non spécifique, comme tant la protéine-cible que les anticorps sont des protéines, des précautions doivent être prises pour minimiser les interactions entre membrane et anticorps.
Le blocage des sites d'interactions non spécifiques entre la membrane et les anticorps est réalisé en plongeant la membrane dans une solution diluée de protéines - le plus souvent de l'albumine de sérum bovin ou ASB (BSA en anglais) ou du lait sans matières grasses (lait dilué à 5 % - 5 g pour 100 ml) - en présence de détergent, typiquement du Tween 20), pendant une heure à température ambiante.
Les protéines dans la solution diluée se lient à la membrane dans tous les sites non occupés par la protéine-cible.
De la sorte, lorsque les anticorps sont appliqués lors de l'étape suivante, ils ne peuvent (idéalement) plus s'attacher à la membrane que sur les sites de liaison de la protéine-cible, ce qui réduit le « bruit de fond » dans le produit final du transfert de western, donne des résultats plus clairs et élimine les faux positifs.Au cours de la détection, la membrane est « sondée » pour la protéine d'intérêt avec des anticorps, liés ensuite à une enzyme émettant un signal photométrique ou colorimétrique, ou bien des photons.
Pour plusieurs raisons, ceci se produit classiquement en deux étapes, bien que des méthodes en une étape soient disponibles pour certaines applications.Les anticorps sont générés par inoculation à l'animal (généralement un lapin ou une chèvre) ou exposition d'une culture de cellules immunitaires à la protéine d'intérêt dans son intégralité ou seulement sur l'une de ses fractions (épitope).
Toutefois, les protéines ayant été dénaturées lors de l'électrophorèse sur gel, il faut utiliser des anticorps qui reconnaissent spécifiquement la protéine dénaturée, et non la protéine native.La réponse immunitaire normale est dans ce cas exploitée afin de générer des anticorps qui sont récoltés et utilisés comme outils de détection possédant à la fois une bonne sensibilité et une bonne spécificité, se liant directement à la protéine - d'où leur appellation d'anticorps « primaire ».
Quelques anticorps monoclonaux, beaucoup plus difficiles à réaliser et dont l'affinité est beaucoup plus élevée peuvent également être utilisés en transfert de western.Après le blocage, une solution diluée d'anticorps primaire (généralement comprise entre 0,5 et 5 micros grammes/ml) est incubée avec la membrane sous agitation modérée.
La solution se compose typiquement d'un tampon salin proche du pH neutre (généralement, une faible quantité de chlorure de sodium), d'un petit pourcentage de détergent, et parfois de protéines (ASB ou lait 5 %) diluées.
La solution d'anticorps et la membrane peuvent être scellées dans un sachet en plastique et incubées ensemble pour une durée allant de 30 minutes à une nuit.
Elle peut aussi être incubée à différentes températures, les températures plus élevées étant associées  à plus de liaisons plus spécifiques.Après rinçage de la membrane afin d'enlever les anticorps primaires non liés, celle-ci est exposée à un autre anticorps, dirigé contre une portion espèce-spécifique de l'anticorps primaire.
Cet anticorps est connu comme anticorps « secondaire », et tend à être référé, du fait de ses propriétés de ciblage, comme « anti-souris », « anti-chèvre », « anti-lapin », etc.
Les anticorps sont de source animale (mais généralement, d'espèces différentes de l'espèce de l'anticorps primaire), ou de cultures d'hybridomes d'origine animale ; un anticorps anti-souris se liera à pratiquement tout anticorps primaire d'origine murine, ce qui permet de réaliser des économies en laissant le laboratoire partager une seule source d'anticorps secondaire, et permet des résultats plus reproductibles.
L'anticorps secondaire est généralement lié à la biotine ou à une enzyme qui permet l'identification visuelle de la protéine étudiée sur la membrane, comme une phosphatase alcaline ou la peroxydase de raifort.
Cette étape confère un avantage, en ce que plusieurs anticorps secondaires se lieront à un anticorps primaire, permettant d'améliorer le signal.Le plus communément, un anticorps secondaire lié à la peroxydase de raifort (horseradish peroxidase) est utilisé en conjonction avec un agent luminescent, et le produit de la réaction émet une luminescence proportionnelle à la concentration en protéine.
Un film photographique sensible est placé contre la membrane et, sous l'exposition de la lumière due à la réaction, crée une image des anticorps liés à la membrane.
Plus souvent maintenant, une caméra à CCD est utilisée en place des films photographiques.
Comme pour les procédures d'ELISPOT et ELISA, l'enzyme peut être fournie avec une molécule-substrat qui sera converti par l'enzyme pour émettre un produit de réaction coloré, visible sur la membrane.
Une troisième possibilité consiste à utiliser un marqueur radioactif plutôt qu'une enzyme couplée à l'anticorps secondaire, par exemple en marquant une protéine liant les anticorps, telle que la protéine A du staphylocoque avec un isotope radioactif de l'iode.
Cependant, les autres méthodes étant plus sûres, plus rapides et moins chères, cette méthode est plus ou moins tombée en désuétude, mais demeure parfois utilisée dans certaines circonstances.Lorsque la technique est apparue, le processus de détection était réalisé en deux étapes, du fait de la relative facilité de production des anticorps primaires et secondaires en deux procédés distincts.
Cela permet aux chercheurs et fournisseurs une certaine souplesse à l'emploi, et ajoute une étape d'amplification du signal au processus de détection.
Toutefois, depuis l'arrivée d'analyses de protéines à haut rendement et à marge de détection plus basse, c'est-à-dire détectant des protéines à très faible concentration, il est devenu intéressant de développer des systèmes de sondage en une étape unique qui permettront un gain de temps et une économie de matière première.
Ces systèmes nécessitent un anticorps de détection pouvant à la fois détecter la protéine d'intérêt et émettre un signal détectable, lesquelles sont souvent disponibles pour des marqueurs de protéine connus.
La sonde primaire est incubée avec la membrane à la manière de l'anticorps primaire dans le procédé en deux temps, et est ensuite prête pour la détection directe après une série d'étapes de rinçages.Après rinçage des anticorps secondaires non liés, le western blot est prêt pour la détection des sondes marquées et liées à la protéine d'intérêt.
En pratique, tous les transferts de western ne révèlent pas la protéine sur une bande donnée de la membrane, les gels n'étant pas complètement exempts de protéines après avoir été épongés.
Une approximation sur la taille est réalisée en comparant les bandes marquées à celles des marqueurs de la gamme étalon chargé durant l'électrophorèse dans un puits à part.
Le processus est répété pour une protéine de structure, comme l'actine ou la tubuline, dont la concentration ne devrait pas varier entre les échantillons (contrôle interne).
La concentration de la protéine-cible est indexée à celle de la protéine servant de contrôle interne, afin de normaliser les expériences.
Cette pratique permet la correction par rapport au taux de protéines total sur la membrane, en cas d'erreur ou de transfert incomplet.
Cette méthode est tributaire, lors de l'incubation du transfert de western, de la présence d'un substrat qui réagit au déclencheur présent sur l'anticorps secondaire (comme la phosphatase alcaline).
Cela convertit un colorant soluble en une forme insoluble, de couleur différente, qui précipite à côté de l'enzyme, teintant donc la membrane de nitrocellulose.
Le développement du transfert de western  est alors arrêté par rinçage du colorant soluble.
La concentration de protéine est évaluée par densitométrie, évaluation de l'intensité de la bande ou par spectrophotométrie.Cette méthode nécessite, lors de l'incubation du transfert de western, la présence d'un substrat qui émet de la lumière après exposition au déclencheur présent sur l'anticorps secondaire.
La lumière émise sert à impressionner un film photographique, ou plus récemment, par des caméras CCD qui restituent une image numérique du transfert de western.
L'image est analysée par densitométrie, qui évalue le taux relatif de marquage de la protéine, et quantifie les résultats en ce qui concerne la densité optique.
Des logiciels permettent une analyse plus poussée des données, comme l'analyse du poids moléculaire si les standards appropriés sont utilisés.
Cette méthode appelée détection améliorée de la chimiluminescence (enhanced chemiluminescent, ECL) est considérée comme l'une des méthodes de détection les plus sensibles pour l'analyse des western blots.Le marquage radioactif ne nécessite pas de substrat enzymatique, mais permet l'utilisation de films utilisés en médecine pour l'imagerie à rayons X.
Le film est directement placé sur la membrane, qui se développe lors de son exposition au marqueur et crée des régions sombres, lesquelles correspondent aux bandes de la protéine d'intérêt (cf.
L'importance des méthodes de détection par radioactivité est en déclin, du fait de son coût et de techniques plus sûres comme l'ECL.La sonde couplée à l'anticorps est excitée par un rayon monochromatique et l'émission qui en résulte est alors détectée par un photosenseur, par exemple une caméra CCD équipée des filtres en transmission appropriés, qui restitue une image numérique du transfert de western et permet une analyse plus fine telle que l'analyse du poids moléculaire ou quantitative du transfert de western.
La fluorescence est considérée comme d'un niveau à peu près équivalent à la chimiluminescence pour l'analyse des transferts de western.
Elle nécessite un outillage plus coûteux toutefois.Bien que de mécanisme photophysique similaire, chimiluminescence et fluorescence ne sont pas la même chose :L'une des plus grandes différences entre les membranes en nitrocellulose et celles en PVDF est liée à leur capacité de supporter l'« arrachage » (stripping) d'anticorps et la réutilisation des membranes pour des sondages par d'autres anticorps.
Bien qu'il existe des protocoles bien établis pour la réutilisation des membranes de nitrocellulose, le PVDF, plus épais, permet de réaliser ces manœuvres en toute sécurité et facilité, et davantage d'utilisations ultérieures avant d'être, tel un palimpseste, recouvert de signaux parasites.
Une autre différence importance est que le PVDF, contrairement à la nitrocellulose, doit être trempé dans de l'éthanol à 95 % ou de l'isopropanol avant usage.
Les membranes en PVDF tendent aussi à être plus épaisses et plus résistantes aux dommages physiques liés à leur utilisation normale.
Le génie génétique est l'ensemble des outils permettant de modifier la constitution génétique d'un organisme en supprimant, en introduisant ou en remplaçant de l'ADN.Celui-ci peut être introduit directement dans les cellules de l'organisme hôte ou dans des cellules cultivées ex vivo puis réintroduites dans l'organisme.
Un prérequis au développement du génie génétique a été la mise au point de techniques recombinantes d'acide nucléique pour former de nouvelles combinaisons de matériel génétique héritable suivies de l'incorporation de ce matériel soit indirectement à travers un système vecteur ou directement par micro-injection, macro-injection ou micro-encapsulation.Il a souvent pour but la modification des génotypes, et donc des phénotypes.Le génie génétique est un champ très actif de la recherche car les applications possibles sont multiples, notamment en santé humaine (correction d’un gène porteur d’une mutation délétère, production de protéines thérapeutiques, élimination de séquences virales persistantes, etc.), en agriculture biotechnologique (mise au point de nouvelles générations de plantes génétiquement modifiées, etc.) ou encore pour la mise au point d’outils destinés à la recherche (par exemple pour explorer la fonction d’un gène).À la suite du développement exponentiel du génie génétique, une nouvelle discipline est apparue dans les années 1960, la bioéthique, qui vise à sensibiliser les chercheurs, mais aussi les politiciens et le grand public, à la nécessité d'introduire systématiquement une dimension éthique dès la phase de recherches (principe de précaution).Au début du XXe, la redécouverte des travaux de Mendel (1822-1888) et les travaux de Morgan (1866-1945) sur la mouche drosophile permettent de comprendre que l'hérédité est due à la transmission de particules appelés gènes, disposés de manière linéaire sur les chromosomes.
Dans les années 1950, est mise en évidence la nature chimique des gènes, ainsi que la structure moléculaire de l'ADN.
En 1965, découverte des enzymes de restriction confirmée en 1973 par Paul Berg et ses collaborateurs.
Ces protéines capables de découper et recoller précisément l’ADN, donnent aux chercheurs les outils qui leur manquaient pour établir une cartographie du génome.
Elle ouvre aussi la voie à la transgénèse, qui permet d'intervenir in vitro sur des portions d'ADN et donc des gènes.
La technologie de l'ADN recombinant permet l'insertion d'une portion d'ADN (un ou plusieurs gènes) dans un autre ADN.Chez certains organismes, les technologies mises au point pour introduire un gène dans la cellule vivante restent cependant limitées par le caractère aléatoire de l’insertion de la nouvelle séquence dans le génome.
Positionné aléatoirement, le nouveau gène peut inactiver ou perturber le fonctionnement de gènes tiers, ou même être à l’origine d’effets indésirables graves comme le déclenchement d’un processus de cancérisation.
Les technologies d'insertion non ciblées ne permettent pas d’obtenir de reproductibilité de l’expérience : il n’y a pas de garantie que la nouvelle séquence soit insérée toujours au même endroit.Depuis la fin des années 1990, une nouvelle génération de technologies, capitalise sur des connaissances et des technologies plus récentes, comme les nucléases programmables (ZNFs, TALENs et CRISPR).
Elles permettent d’intervenir sur une zone spécifique de l’ADN afin d’accroître la précision de la correction ou de l’insertion pratiquée, de prévenir ainsi les toxicités cellulaires et d’offrir une reproductibilité fiable de l'intervention.Ces nouvelles technologies d'ingénierie génomique, avec la génomique synthétique (conception de génomes artificiels), figurent actuellement parmi les technologies les plus prometteuses en termes de recherche biologique appliquée et d’innovation industrielle.La production d’OGM permet d’introduire dans le génome d’un être vivant de nouveaux gènes, par insertion de portions d’ADN, ou de supprimer ou modifier certains gènes présents.
Ces modifications font appel à divers outils du génie génétique, notamment la transgénèse et plus récemment des nucléases programmables (plus particulièrement l'outil CRISPR).Le génie génétique constitue l'une des principales avancées scientifiques du XXe siècle.
Il présente en effet un fort potentiel de développement.
Toutefois, les possibilités d'application qu'il offre dans la recherche biomédicale suscitent autant de craintes que d'espoirs.
Raison pour laquelle une nouvelle discipline est apparue dans les années 1960, la bioéthique, qui vise à sensibiliser les chercheurs, mais aussi les politiciens et le grand public, à la nécessité d'introduire systématiquement une dimension éthique dès la phase des recherches.En 2015, l'Académie nationale de médecine des États-Unis a organisé un sommet international pour attirer l'attention sur les risques du génie génétique comme, plus important pour les organisateurs, l'eugénisme.
Un autre risque est l'incertitude des effets du génie génétique: compte tenu de la complexité du génome humain et l'interdépendance entre tous les gènes différents, la modification d'un gène singulier influencerait aussi des autres parties du génome.
Cependant pour la première fois des bébés dit OGM ont vu le jour en Chine, en effet grâce à la technologie CRISPR-Cas9 qui est une nouvelle innovation médicale mis au point en 2012 par la française Emmanuelle Charpentier et l'Américaine Jennifer Doudna.
Le chercheur Chinois He Jiankui l’a utilisé afin d'éviter que les jumelles Lulu et Nana ne soient pas porteuses du VIH.
La nouvelle technologie Cas9 permet de sectionner certains gènes cependant cela n’avait encore jamais été tenté sur des embryons destinés à rester en vie.Biologiste québécois, Jean-François Gariépy, avertit que le génie génétique pourrait mener au remplacement des mécanismes actuels de la reproduction humaine.
Dans la monographie Le phénotype révolutionnaire (The revolutionary phenotype), Gariépy base cette théorie sur l'hypothèse du monde à ARN où l'ARN a été remplacé par l'ADN comme réplicateur dominant dans le monde.
Si l'humanité choisissait ce chemin, la conséquence, en longue terme, serait la transformation radicale de toute société humaine conforme aux intérêts des forces manipulant le processus du génie génétique,La transgénèse consiste à introduire un ADN exogène dans le génome d'un organisme soit au moyen d'un virus ou d'une bactérie soit par introduction de l'ADN par des méthodes physico-chimiques (électroporation, transfection ou micro-injection).
La première souris transgénique a été créée par le biologiste Rudolf Jaenisch en 1974.
Les premières plantes transgéniques sont créées en 1984 en utilisant Agrobacterium tumefaciens comme vecteur d'ADN exogène,.
Une limitation importante des approches de transgenèse est que le matériel génétique exogène est inséré de façon aléatoire.
L'insertion, lorsqu'elle a lieu à proximité d'un gène endogène peut entraîner un défaut d'expression de ce dernier.À la différence de la transgenèse, les approches de recombinaison homologue permettent d'introduire, d'enlever ou de remplacer du matériel génétique, et ce de façon très précise.
Ces approches reposent sur un mécanisme naturellement présent au sein des cellules permettant de réparer un ADN endommagé en utilisant comme modèle une séquence homologue située sur un autre brin.Il est possible d’induire des recombinaisons homologues entre l’ADN naturel d’une cellule et d'un ADN exogène introduit par les chercheurs, en utilisant comme vecteur le génome modifié d’un rétrovirus par exemple.
Le phénomène de recombinaison est suffisamment souple pour qu’il soit possible d'introduire un certain niveau de changement (ajout, suppression ou modification d’une portion d’ADN) au niveau de la zone d’homologie visée.Dès les années 1980, Mario R. Capecchi et Oliver Smithies ont travaillé sur la recombinaison homologue de l'ADN comme outil de « ciblage de gène », c’est-à-dire comme instrument d’inactivation ou de modification de gènes précis.
Avec la collaboration de Martin J. Evans, ils ont mis au point un procédé permettant de modifier le génome de souris en modifiant l’ADN de cellules souches embryonnaires murines en culture, et en injectant ces cellules souches modifiées dans des embryons de souris.
Les souris génétiquement modifiées ainsi générées permettent d’étudier des maladies humaines en laboratoire.
C’est aujourd'hui un outil couramment utilisé en recherche médicale.
Les travaux des trois chercheurs leur ont valu le Prix Nobel de physiologie ou médecine en 2007.Une limitation importante de l'approche de modification génétique par recombinaison homologue est sa très faible activité spontanée, hormis chez la levure et dans les cellules souches embryonnaires de souris qui font figure d'exception.
Ceci a fortement limité son application à d'autre organismes.
Or au milieu des années 1990, les équipes de Maria Jasin et Jean-François Nicolas démontrent qu'une cassure double-brin de l'ADN de cellules mammifères stimule très fortement la recombinaison homologue (qui est utilisée par la cellule afin de réparer la cassure),.
En outre, l'analyse des séquences d'ADN après réparation met en évidence l'action d'une seconde voie de réparation d'ADN, appelée jonction d'extrémités non homologues, qui conduit à la délétion ou à l'insertion de petites séquences d'ADN (typiquement de 1 à 20 nucléotides de long).
Ces observations ont donc conduit les chercheurs à développer des nucléases (enzymes coupant l'ADN) dont la séquence d'ADN cible peut être programmée.Les enzymes de restriction couramment utilisées en biologie moléculaire pour couper l’ADN interagissent avec des séquences constituées de 1 à 10 nucléotides.
Ces séquences, très courtes et souvent palindromiques, sont généralement présentes à plusieurs endroits du génome (le génome humain comprend 6,4 milliards de bases).
Les enzymes de restriction sont donc susceptibles de couper la molécule d’ADN à de multiples reprises.Pour pratiquer une chirurgie des génomes précise et sûre, les scientifiques se sont donc tournés vers des outils plus précis.
L’ingénierie ciblée des génomes est rendue possible par l’utilisation d’enzymes capables de reconnaître et d’interagir avec des séquences d’ADN suffisamment longues pour n’exister, en toute probabilité, qu’en un exemplaire unique dans un génome donné.
L’intervention sur l’ADN se produit alors précisément au niveau de la séquence ciblée.
Avec des sites de reconnaissance de plus de 12 paires de bases, les méganucléases, les nucléases à doigts de zinc, les TALENs et les systèmes CRISPR répondent à ces critères de spécificité.Une fois la coupure de l’ADN effectuée, les mécanismes naturels de réparation de l’ADN et la recombinaison homologue permettent d’incorporer une séquence modifiée ou un gène nouveau.Le succès de ces différentes étapes (reconnaissance, coupure, recombinaison) dépend de divers facteurs, parmi lesquels l’efficacité du vecteur qui introduit l’enzyme dans la cellule, l’activité enzymatique de coupure, les capacités cellulaires de recombinaison homologue et probablement l’état de la chromatine au locus considéré.Découvertes à la fin des années 1980, les méganucléases sont des enzymes de la famille des endonucléases qui présentent la caractéristique de reconnaître des séquences d’ADN de grande taille, de 12 à 40 paires de bases.
Parmi ces méganucléases, les protéines du groupe LAGLIDADG, qui doivent leur nom à une séquence d’acides aminés conservée, sont les plus nombreuses et les mieux connues.Ces enzymes ont été identifiées dès les années 1990 comme des outils prometteurs pour l’ingénierie des génomes.
Néanmoins, malgré leur diversité dans la nature, et même si chacune d’elles peut présenter de petites variations de son site de reconnaissance de l’ADN, il existe trop peu de chances de trouver la méganucléase adaptée à l’intervention sur une séquence d’ADN bien déterminée.
Chaque nouvelle cible d’ingénierie génomique nécessite ainsi une première phase d’ingénierie protéique afin de produire une méganucléase sur mesure.Les nucléases à doigt de zinc sont des enzymes de restrictions synthétiques créées en fusionnant des domaines à doigt de zinc avec des domaines de coupure de l'ADN.La combinaison de 6 à 8 doigts de zinc dont les domaines de reconnaissance ont été caractérisés, il est possible d’obtenir des protéines spécifiques de séquences d’une vingtaine de paires de bases.
On peut ainsi contrôler l’expression d’un gène spécifique.
Il a été montré que cette stratégie permet de promouvoir un processus d’angiogenèse chez l’animal.
Il est également possible de fusionner la protéine ainsi construite avec le domaine catalytique d’une endonucléase afin de provoquer une cassure ciblée de l’ADN et d’utiliser ces protéines comme outils d’ingénierie des génomes.Les nucléases à doigts de zinc sont des outils de recherche et développement qui ont déjà été utilisés pour modifier des génomes variés, notamment par les laboratoires fédérés dans le Zinc Finger Consortium.
L’entreprise américaine Sangamo Biosciences utilise les nucléases à doigts de zinc pour des travaux sur l’ingénierie génétique des cellules souches et la modification de cellules immunitaires à des fins thérapeutiques,.
Des lymphocytes T modifiés font actuellement l’objet d’essais cliniques de phase I, portant sur le traitement d’un cancer du cerveau (le glioblastome) et la lutte contre le SIDA.Les TALENs sont des enzymes de restriction artificielles générées par fusion d'un domaine de liaison à l'ADN appelé TALE et d'un domaine ayant la capacité de cliver l'ADN.Le domaine TALE de liaison à l'ADN est constitué de répétitions de 33 ou 34 acides aminés identiques à l'exception des acides aminés 12 et 13.
Ces deux derniers résidus confèrent à un module la capacité de reconnaître une base de l'ADN selon un code très simple,.
En assemblant ces modules dans l'ordre souhaité, il est très aisé de générer une protéine qui reconnaîtra une séquence spécifique du génome.
La fusion de ce domaine TALE avec un domaine de clivage de l'ADN permet d'induire très facilement des cassures double brin sur un gène souhaité.La rapidité pour la construction de telles enzymes et leur bas coût en font des outils excellents pour réaliser de l'ingénierie des génomes.Afin de légiférer sur ces nouvelles méthodes, les différents gouvernements ont créé la commission de génie génétique dissoute le 8 décembre 2008 et le Haut Conseil des biotechnologies créé en juin 2008.Selon l’article 18 du chapitre 5 de la convention pour la protection des droits de l'homme et de la biomédecine, lorsque la recherche sur les embryons in vitro est admise par la loi, celle-ci assure une protection adéquate de l'embryon.
La constitution d'embryons humains aux fins de recherche est interdite.Les modifications effectuées par le chercheur He jiankui sont donc illégales selon la convention d’oviedo de 1997 .En novembre 2018, deux jumelles chinoises chez lesquelles une mutation censée les préserver du VIH a été introduite grâce à la technique d’édition des génomes dite CRISPR-Cas9 ont vu le jour.
Cet évènement a mis en évidence l’absence de consensus international et les divergences de pratiques des États quant à l’utilisation de la technique CRISPR sur l’homme, l’encadrement de la recherche ayant un caractère essentiellement national.CRISPR-Cas9, ou plus simplement CRISPR, est une technique d’ingénierie de l’ADN qui permet d’ajouter, de modifier ou de supprimer une séquence spécifique du génome d’un être vivant, bactérie, plante ou animal.
Contrairement aux techniques précédentes complexes à mettre en œuvre, CRISPR-Cas9 est facile à utiliser.
Elle est aussi plus précise, plus fiable et moins coûteuse.Chez l’humain, la technique CRISPR peut être utilisée tant pour modifier les cellules de l’embryon que celles d’un individu adulte.
L’intervention peut porter sur ce que l’on appelle les cellules-souches, sources de toutes les autres.
D’abord, les cellules souches germinales, reproductrices, que l’on appelle aussi gamètes (spermatozoïdes et ovules), ainsi que les cellules présentes chez le zygote (embryon aux premiers stade de développement).
Puis, les cellules souches somatiques, soit les autres cellules du corps.
Toute modification des gamètes sera transmise à la descendance, alors que la modification d’un gène sur une cellule somatique ne concernera que le seul humain soumis au traitement.
La commutation isotypique (ou commutation de classe, ou « class switching ») est un processus qui, lors de la maturation d'un lymphocyte B, permet de changer l'isotype (classe) des immunoglobulines produites.
C'est un changement de la chaine lourde des anticorps.
Cela permet à la réponse humorale d’être plus efficace et de s’adapter au type de pathogène.
Une glycoprotéine est une protéine portant un ou plusieurs groupements oligosides.
C'est un hétéroside (composé de plusieurs oses différents) dont le premier motif glucidique est fixé de façon covalente à la chaine polypeptidique.Une glycoprotéine est synthétisée par la glycosylation d’une protéine, qui peut être de trois types (N-glycosylation, C-glycosylation et O-glycosylation) selon l’acide aminé utilisé, asparagine (NH2), tryptophane (en C2), sérine ou thréonine (OH).
Les glycophorines sont, parmi bien d'autres, un exemple de glycoprotéines.Les glycoprotéines ne renferment pas d'acide uronique, ni des esters sulfates dans leur structure.La fraction glucidique peut représenter 5 à 40 % de la molécule.Glycoprotéine composée de 2 sous-unités protéiques reliées par une paire de ponts disulfure à leur extrémité C-terminale.
Elle est par conséquent dimérique.Elle possède différents motifs de liaison : Glycoprotéine de la membrane basale, molécule flexible de 3 chaînes comportant plusieurs domaines :Elle constitue un support de liaison de plusieurs composants de la matrice, les organise en réseau et régule l'adhérence cellule-matrice.Glycoprotéine complexe utilisée par le système immunitaire adaptatif pour détecter et neutraliser les agents pathogènes et sécrétés par les plasmocytes.Les sélectines sont des glycoprotéines qui se trouvent dans l’espace transmembranaire des leucocytes et des cellules endothéliales.
Leur interaction retient les leucocytes sur un court temps pour permettre l’action des intégrines par la suite.
Les intégrines, également localisées sur les leucocytes et les cellules endothéliales, permettent l’adhésion cellulaire et l’enclenchement de la diapédèse.
La diapédèse est l’événement qui permet le déplacement des leucocytes du sang jusqu’au site de l’inflammation.Les glycoprotéines sont importantes dans la fécondation, car elles permettent la liaison du spermatozoïde à l’ovocyte.La glycoprotéine ZP3, située sur la zone pellucide de l’ovocyte, est un récepteur qui lie le spermatozoïde.
Cette interaction enclenche la réaction acrosomale et la libération d’enzymes qui permettent au spermatozoïde de traverser la zone pellucide.PH-30 est une protéine glycosylée, localisée sur la membrane plasmique de l’ovocyte, qui lie également le spermatozoïde.
Leur interaction amène à l’introduction du spermatozoïde à l’intérieur de l’ovocyte.Sans ces deux glycoprotéines, le spermatozoïde ne peut pas fertiliser l’ovocyte.Il existe plusieurs maladies qui sont causées par des défauts dans la production des glycoprotéines.Il existe des cellules cancéreuses qui possèdent plusieurs types de glycoprotéines sur leur membrane.
Il est connu que certaines de ces glycoprotéines sont directement impliquées dans la production de métastase.Cette maladie est représentée par l’absence de glycoprotéines fucosylés, qui sont des protéines ayant subi une fucosylation (type de glycosylation).
Les sélectines, qui lient normalement ces glycoprotéines, ne peuvent pas interagir avec leur ligand.
Elles ne peuvent donc pas permettre le déplacement des leucocytes à l’extérieur des vaisseaux sanguins, puis au site de l’inflammation.Dans cette maladie, il y a deux glycoprotéines mutées qui sont impliquées; le DAF et le CD59.
Ces deux protéines, en temps normal, ont une action inhibitrice sur le système du complément.
Ainsi, sans l’action des deux glycoprotéines, le système du complément peut agir sur les globules rouges et causer leur hémolyse.La maladie arthrite rhumatoïde est représentée par de l’inflammation chronique au niveau des articulations.
Cette inflammation est causée par la liaison anormale et abondante de la protéine de liaison du mannose (MBP) au immunoglobuline G (IgG).
Dans ce cas-ci, le processus de glycosylation des immunoglobuline G (IgG) est anormal, ce qui provoque leur liaison aux MBP.
Les cellules tueuses naturelles, ou lymphocytes  NK, pour Natural Killer, sont des cellules du système immunitaire inné cytotoxique qui n'éliminent pas directement les agents infectieux notamment en raison de leurs récepteurs invariants.Les cellules NK représentent environ 5 à 16 % des lymphocytes humainsCe sont des cellules provenant de la lignée lymphocytaire proche des cellules des lymphocytes T, mais ne possédant pas de récepteur membranaire aux antigènes comme les lymphocytes.
Ce sont de grands lymphocytes granuleux (par opposition aux « petits lymphocytes »), non T (CD3-) non B (CD19-), caractérisés chez l'humain par les marqueurs CD56, CD16 et NK.Les récepteurs du lymphocyte NK sont synthétisés au cours du développement et de la maturation de la cellule puis ceux-ci ne subiront plus de changement.Les cellules NK utilisent des récepteurs inhibiteurs (récepteur tueur d'immunoglobuline et Ly49) pour se développer, mûrir et reconnaître le « soi » du « non-soi ».Les cellules tueuses naturelles éliminent les cellules dont la fonction est altérée, comme les cellules tumorales ou les cellules infectées par un virus.
Par exemple, les cellules tueuses naturelles peuvent reconnaître les cellules n'exprimant plus le CMH de classe I.
Cette situation est observée durant une infection virale, certains virus pouvant induire la diminution du CMH de classe I pour éviter la reconnaissance par d'autres cellules immunitaires comme les lymphocytes T CD8.Découvertes dans les années 1960, ces cellules tirent leur nom du fait qu'elles n'ont pas besoin de l'activation d'un lymphocyte CD4+ pour avoir une action cytotoxique,.L'existence de lymphocytes cytotoxiques naturels ou lymphocytes NK  (sigle de l'anglais Natural Killer, signifiant « tueur naturel ») aussi appelés cellules tueuses naturelles ayant des propriétés anti-tumorales intrinsèques et innées a été découverte lors d'expérience avec des lymphocytes T.L'activité des cellules NK a d'abord été observée dans les cellules mononucléaires du sang  périphérique humain,; cependant, ces gros lymphocytes granuleux résident dans plusieurs tissus lymphoïdes et non lymphoïdes, notamment la moelle osseuse, les ganglions lymphatiques, la peau, l'intestin, les amygdales, le foie et les poumons.En matière de cytotoxicité, la différence fondamentale entre les lymphocytes T CD8+ et les lymphocytes NK est que la cellule T CD8+ nécessite une activation par le T CD4+ auxiliaire pour exprimer sa cytotoxicité entraînant une synthèse de récepteurs spécifiques d'une espèce microbienne par recombinaison somatique.
Comme leur nom l'indique, les cellules NK sont constitutivement cytotoxiques et, contrairement aux cellules T cytotoxiques, ne nécessitent pas d'exposition préalable  à l'antigène pour médier leurs effets anti-tumoraux,.Les lymphocytes NK ont été découverts dans les années 1960, et, en 10 ans, les chercheurs ont commencé à explorer une population de lymphocytes innés auparavant inconnue, et désignées aujourd'hui sous le nom de cellules tueuses naturelles (NK),,,.On pensait initialement que les cellules NK se développaient exclusivement dans la moelle osseuse.
Cependant, des preuves récentes chez l'homme et la souris suggèrent qu'elles peuvent également se développer et mûrir dans les tissus lymphoïdes secondaires y compris les amygdales, la rate et les ganglions lymphatiques.
Les progéniteurs cellulaires et les populations intermédiaires qui donnent naissance aux cellules NK sont définis par l'expression différentielle de marqueurs de surface spécifiques à la lignée.
Les cellules tueuses naturelles représentent 5 à 20% des lymphocytes circulants chez l'homme.Chez l'homme, des sous-ensembles de cellules NK expriment le récepteur Fc activateur, CD16 et la plupart expriment CD56 ,.Les cellules souches hématopoïétiques multipotentes donnent naissance à tous les leucocytes et globules rouges dont une branche constitue le progéniteur lymphoïde commun.
Les progéniteurs lymphoïdes communs donnent naissance à des cellules lymphoïdes innées Pro-B, Pre-T, et des lignées Pre-NKP.
Des travaux récents ont permis de délimiter un total de six étapes du développement des cellules NK humaines en fonction de leur développement à la fois moelle osseuse et ganglion lymphatique, :On distingue deux types de cellules NK chez l'être humain, regroupées selon la densité des marqueurs membranaires CD56 et CD16 :La plupart des cellules population immature de NK se transforment en une population CD56bright mineure (~5 %) qui se transforme en population CD56dim majeure (> 90 %).
La régulation négative du CD56 pendant la maturation des cellules NK humaines est fortement associée à l'acquisition d'une cytotoxicité anti-tumorale car les cellules N56 CD56bright sont de puissants producteurs de cytokines inflammatoires, tandis que la fonction cytolytique des cellules NK humaines réside principalement dans la population CD56 dim,,.Les cytokines sont des médiateurs inflammatoires essentiels qui contrôlent de multiples aspects de la biologie des cellules NK.
Les cellules NK expriment les récepteurs des cytokines au début de leur développement et nécessitent une signalisation à travers la chaîne gamma commune (γc) pour leur développement, leur homéostasie et leur fonction.
La chaîne γc (CD132) est une glycoprotéine transmembranaire qui sert de sous-unité de signalisation pour IL-2, IL-4, IL-7, IL-9, IL-15 et IL-21.
Bien que ces cytokines présentent une certaine redondance fonctionnelle, leurs fonctions spécifiques aux cellules au cours d'une réponse immunitaire sont déterminées par l'expression de récepteurs distincts,L'interleukine-2 et l'IL-15 sont des membres fonctionnellement apparentés de la famille γc des cytokines en ce qui concerne leurs interactions avec les récepteurs.
L'IL-2Rα (CD25) est exprimée sur les cellules NK activées et augmente considérablement leur affinité pour l'IL-2 qui stimule leur prolifération et la production de molécules lytiques telles que la perforine et le granzyme B. Étant donné que les cellules NK se trouvent près des zones de cellules T dans les tissus lymphoïdes secondaires, l'IL-2 dérivée des cellules T peut faciliter un échange efficace vital entre les lymphocytes innés et adaptatifs pendant une infection.l'IL-15 est unique à cet égard.
L'IL-15 interagit avec les cellules T Pour que cela se produise, l'IL-15 soluble se lie à l'IL-15Rα sur la surface des cellules qui présentent ce complexe aux cellules NK exprimant les hétérodimères IL2-Rβ / γc.
L'IL-15 peut être présentée par les cellules dendritiques et les macrophages ainsi que par les cellules non hématopoïétiques, y compris les cellules stromales et les cellules épithéliales.
IL-21 synergise avec IL-2 pour augmenter l'expression de NKG2A, CD25, CD86, CD69, Perforin et Granzyme B et ainsi augmenter la cytotoxicité.
Ces cytokines qui utilisent les récepteurs à base de γc sont le lien obligatoire entre les cellules NK et les cellules qui les produisent.
Par exemple, les cellules T auxiliaires qui produisent de l'IL-21 peuvent réguler les niveaux d'expression des récepteurs d'activation ou du contenu cytolytique dans les cellules NK.
De même, les CD qui produisent IL-15 jouent un rôle essentiel dans la prolifération et l'amorçage des cellules NKLa forte cytotoxicité anti-tumorale est le résultat de sécrétion de quantité importante de cytokines pro-inflammatoires.
La cellule NK possède multiples récepteurs d'activation des cellules NK codés par la lignée germinale tels que NKG2D, NCR1, NCR2, NCR3, NKG2C, CD244, Ly49D et Ly49H.
L'expression de plus d'un récepteurs d'activation qui reconnaissent les ligands du non soi ou pathogènes confère aux cellules NK des capacités innées de médiation des fonctions effectrices.
En raison de l'expression de multiples récepteurs d'activation, les cellules NK doivent suivre un programme de développement distinct pour éviter une mauvaise reconnaissance de «soi» conduisant à des réponses auto-immunes.
La nature variée des récepteurs d'activation et l'absence de domaines de signalisation dans leurs parties cytoplasmiques nécessitent l'association et le recrutement de co récepteurs pour la transduction du signal.
Les molécules coréceptrices qui propagent la signalisation des récepteurs NK comprennent FcεRIγ, CD3ζ et le DAP12 qui signalent via des motifs d'activation à base de tyrosine (ITAM) contenus dans leurs domaines cytoplasmiques.
Les récepteurs d'activation qui utilisent ces corécepteurs incluent CD16, NCR1, Ly49D, Ly49H et NKG2D,,, .
Cependant, Ly49H et NKG2D peuvent également signaler via le motif YINM présent dans le corécepteur, DAP10,, L'activation des cellules NK à travers ces corécepteurs se produit en interagissant avec des ligands cellulaires et étrangers distincts présents sur les cellules malades et forme la base de la réponse immunitaire médiée par les cellules NK dans de multiples contextes.Les cellules tueuses naturelles médient leurs effets grâce à deux fonctions effectrices essentielles.
Premièrement, les cellules NK sont des lymphocytes cytotoxiques qui peuvent directement lyser des cellules qui ont subi une transformation maligne ou qui ont été infectées par un virus ou un autre pathogène intracellulaire.
La fonction cytolytique des cellules NK peut s'initier à travers une variété de processus, y compris la dégranulation et la stimulation des récepteurs de la mort, et est essentielle pour l'élimination des cellules malades et dysfonctionnelles,.
Deuxièmement, les cellules NK peuvent produire une variété de cytokines inflammatoires en réponse à la stimulation des récepteurs et l'activation induite par les cytokines inflammatoires,.
Ces fonctions effectrices des cellules NK sont des composantes essentielles de la réponse immunitaire et sont les principaux mécanismes par lesquels les cellules NK assurent l'immunité .Il existe sur la membrane cellulaire des NK des récepteurs activateurs (portant des séquences « ITAM ») : immunoreceptor tyrosine-based activation motif) ou inhibiteurs (portant des séquences « ITIM » : immunoreceptor tyrosine-based inhibition motif).
Lorsqu'un NK rencontre une autre cellule, la lyse de cette cellule ne se produira que si les signaux d'activation surpassent les signaux d'inhibition.
Le principal signal inhibiteur est produit par les récepteurs KIR (acronyme de l'anglais « killer cell Ig-like receptor »), portés par le NK, qui reconnaissent les molécules du CMH de classe I.
L'activation d'un seul type de récepteur KIR suffit à empêcher l'activation du NK alors qu'il faut toujours plusieurs signaux activateurs différents pour provoquer la dégranulation du NK et la mort de la cellule non reconnue.
Les signaux d'activation sont variés, et comportent notamment des protéines produites par des cellules stressées, par exemple lors d'une infection.
Ce système d'équilibre dynamique activation / inhibition permet en pratique aux cellules NK de lyser toutes cellules dépourvues des molécules du CMH de classe I (dont théoriquement tous parasites extracellulaires) ou cellules infectées par des virus ou des bactéries tout en épargnant les cellules saines.
La lyse des cellules cibles se fait principalement par les voies perforine / granzyme et l'interféron gamma.L'ADCC ou antibody-dependent cell-mediated cytotoxicity, est permise par l'expression du marqueur CD16 à la surface des cellules NK.
Le CD16, nommé aussi FcγRIII, est un récepteur de fragment constant d'immunoglobulines telles que l'IgG1 et l'IgG3.
Il semblerait que les cellules CD56bright, qui expriment peu de CD16, soient moins efficaces dans les mécanismes d'ADCC que les cellules CD56dim.Une autre voie par laquelle les cellules NK reconnaissent les cellules cibles potentielles dépend du fait que des cellules tumorales et des cellules infectées par certains virus exposent des antigènes contre lesquels le système immunitaire a développé une réponse anticorps, de telle façon que des anticorps antitumoraux ou antiviraux soient liés à leur surface.
Étant donné que les cellules NK expriment le CD16, qui est un récepteur membranaire pour l'extrémité carboxy-terminale de la molécule d'IgG, appelée Fc (cf.
anticorps), elles peuvent fixer à ces anticorps et, par la suite, lyser les cellules ainsi marquées.
Ceci est un exemple d'un processus connu sous le nom de cytotoxicité cellulaire dépendante des anticorps (ADCC, antibody-dependent cell-mediated cytotoxicity).Les cellules tueuses naturelles sont de puissants producteurs de cytokines pro-inflammatoires et immunosuppressives.
Cependant, la libération de cytokines inflammatoires est distincte de la sécrétion de granules cytotoxiques et les cellules NK utilisent des voies de signalisation induits par activation pour réguler ces deux fonctions .
Bien que les cellules NK puissent produire une large gamme de cytokines en fonction de l'environnement inflammatoire , les cellules NK produisent principalement des cytokines de type produit par le Th1 lorsqu'elles répondent aux ligands tumoraux et aux agents pathogènes intracellulaires, Il s'agit notamment de l'IFN-γ, du TNF et du facteur de stimulation des colonies de granulocytes / monocytes (GM-CSF) qui facilitent l'activation des cellules T les cellules dendritiques, les macrophages et les neutrophiles,.
Les cellules NK produisent également des cytokines chimiotactiques (chimiokines), notamment CCL3 (MIP-1α), CCl4 (MIP-1β), CCL5 (RANTES), XCL1 (lymphotoxine) et CXCL8 (IL-8) qui peuvent attirer les lymphocytes effecteurs et les cellules myéloïdes vers un site d'inflammation.L'activation des voies de transcription des molécules cytolytiques et des cytokines inflammatoires est un processus hautement régulé médié par une variété de régulateurs dans les cellules NK.
Beaucoup de ces facteurs de transcription, tels que le T-bet, définissent la lignée et s'activent tôt dans le développement des cellules NK.
L'activation induite par les cytokines de facteurs de transcription, tels que les transducteurs de signal et les voies de transcription (STAT) 4 et 5, se produit en réponse à la signalisation IL-12 et IL-2 + IL-15, respectivement.
Les récepteurs de la cellule NK lancent également des voies de transcription inflammatoire lors de l'activation.
Ceux-ci comprennent l'hétérodimère c-Fos et c-Jun, AP-1, le facteur nucléaire kappa-amplificateur de chaîne légère des cellules B activées (NF-κB) et le facteur nucléaire des cellules T activées, qui se lient aux régions promotrices et favorisent la transcription du gène de la cytokine inflammatoire,Les cellules NK sécréteraient également des protéines FasR afin d'induire la mort de cellules tumorales.Il a été montré que les cellules NK pouvaient être activées par une interaction directe entre les peptides viraux (présents en surface du virus) et des récepteurs membranaires retrouvés sur la cellule NK.
Pour exemple, le récepteur NKp46 avec l’hémagglutinine du virus influenza (virus de la grippe) ou l’hémagglutinine-neuramidase du virus Sendai.
De la même manière, l’interaction du récepteur NKp44 avec la glycoprotéine E du DENV pourrait activer les cellules NK.Bien avant les cellules T CD8, les cellules NK sont activées dans la réponse immune antivirale.
Dans les quelques heures suivant l'infection virale, un pic de cytokines telles que l'IL-12 et les interférons de type I est retrouvé dans la sérologie.
En effet, la présence d'interférons est spécifique d'une infection virale : ce sont des cytokines antivirales synthétisables par divers types cellulaires dans l'organisme.
Les IFN I induisent l'activation de voies de signalisation permettant en amont la synthèse de protéines antivirales.
De plus, les IFN I ont un rôle important dans l'activation des cellules NK (notamment en stimulant leur synthèse de protéines cytotoxiques) et leur prolifération.Les cellules NK sont aussi activées par l’IL-12 et le TNF-α produits par les macrophages au début de nombreuses infections et qui induisent une production d'autres cytokines, majoritairement l’IFN-γ.
Cette activation des cellules NK durant le début de l’infection virale permet de bloquer ou tout au moins de contenir l'infection, pendant qu'une réponse immune adaptative, plus spécifique au type de virus, se met en place.Les cellules dendritiques sont aussi connues pour activer les cellules NK dans certains cas.
Elles sécrètent l'IL-12, l'IL-18 et l'IFN-I qui activent les fonctions des cellules NK.Une fois activée, la cellule NK agit en trois phases majeures que l'on peut découper de la manière qui suit :1. la production de cytokines ;2. le relargage de granules cytotoxiques (granzymes et perforines, essentiellement) ;3. la lyse de la cellule cible.La biologie des cellules NK est d'un intérêt particulier dans la lymphohistiocytose hémophagocytaire primaire (pHLH pour les anglophones) car tous les défauts génétiques associés à ce trouble entraînent une diminution de la capacité cytotoxique des cellules NK et des lymphocytes T ; des tests de destruction des cellules NK sont utilisés cliniquement pour le diagnostic de HLH.L'importance des altérations de la fonction des cellules NK semble liée à la pathogenèse de la lymphohistiocytose hémophagocytaire.Les lymphocytes NK CAR sont des lymphocytes NK génétiquement modifiés pour cibler des antigènes spécifiques situés à la surface des cellules cancéreuses.
C'est un axe de recherche en immunothérapie.
Cette approche semble présenter moins d'effets secondaires indésirables que le traitement par lymphocytes T CAR,,.Certaines maladies comportent une diminution du nombre global de ces cellules.
D'autres ont une déficience de leur fonction tout en conservant un nombre normal.
Toutes entraînent un déficit immunitaire.La mutation du gène MCM4 entraîne un syndrome dont l'un des éléments est un déficit en cellules NK.
Celle des gènes GATA2 et RTEL1 comporte également une lymphopénie concernant ces cellules.
D'autres mutations, par exemple concernant le CD16 ou l'IRF8 , sont responsables d'un déficit fonctionnel.Une étude japonaise démontre que de brefs séjours en forêt permettent d'augmenter très sensiblement le nombre de lymphocytes NK.
Le myélome multiple (MM ou  myélome multiple des os ou maladie de Kahler, de maladie de Kahler-Bozzolo) est un cancer hématologique (signifiant qu'il se développe à partir des cellules de l'hématopoïèse, celles-là même qui sont à l'origine des cellules du sang, formées dans la moelle osseuse).C'est une lymphopathie B maligne (prolifération maligne d'un clone plasmocytaire ; les cellules touchées seront toutes des plasmocytes (qui sont des lymphocytes B activés en différenciation terminale), cellules du système immunitaire produisant les anticorps (immunoglobulines) pour combattre les infections et maladies.
Ce myélome est caractérisé par le développement dans le squelette de multiples tumeurs ostéolytiques à plasmocytes (plasmocytomes) sécrétant dans la plupart des cas soit une immunoglobuline monoclonale de type G (52 % des cas), soit de type A (21 % des cas), soit une chaîne légère Kappa ou Lambda (12 %).Le myélome multiple représente le plus répandu des cancers hémopathiques (10 % du total), le premier après le lymphome non-hodgkinien ; il compte pour 1 % de tous les cancers et 2 % de tous les décès par cancer.Il affecte plus d'hommes que de femmes (sex ratio : 3/2).
Et il est plus fréquent chez les afro-américains et plus rare en Chine ; est 2 à 3 fois plus fréquent chez les Noirs que chez les Blancs.Le taux d'incidence annuel du MM est environ de 4 cas pour 100 000 individus ; Cette incidence est en hausse depuis plusieurs décennies, en grande partie probablement en raison d'une amélioration du diagnostic et du vieillissement de la population générale.Au début des années 2000 en France, l'incidence est de 4 000 cas par an et aux États-Unis, 45 000 personnes vivent avec le myélome avec environ près de 20 000 nouveaux cas par an.
Au Canada, chaque année, environ 2 000 personnes reçoivent un diagnostic de myélome multiple.Les gammapathies de signification indéterminée (ou MGUS pour Monoclonal Gammopathy of Unknown Significance) sont les premiers précurseurs, souvent trouvées par hasard lors de tests demandés pour d'autres problèmes de santé.
Elles sont plus fréquentes avec l'âge : 1 % des gens en développent à 50 ans, et 5 % à 80 ans.15 à 20% des MGUS évoluent ensuite en myélome multiple selon Kyle (2018), mais la plupart des porteurs de MGUS peuvent vivre de nombreuses années sans développer de myélome ; la plupart des MGUS ne progresseront jamais.Un myélome peut « couver » durant des années sans symptômes ; le myélome couvant a été décrit en 1980, chez six patients ayant assez de protéines monoclonales dans leur sang et assez de cellules plasmatiques anormales dans leur moelle osseuse pour suggérer un myélome, bien que n'en présentant toujours aucun symptômes, même après 5 ans de suivi.
Comme le MGUS, le myélome « couvant » est asymptomatique mais les patients dans ces états précurseurs ont des niveaux plus élevés de protéines monoclonales que celles atteintes de MGUS, plus de cellules plasmatiques anormales dans leur moelle osseuse (au moins 10%) ou les deux.L'âge moyen de diagnostic tend à diminuer, après avoir été de 65 à 70 ans (65 ans vers 2015) et son incidence augmente avec l'âge : « 7 pour 100 000 à 50 ans, 20 pour 100 000 à 80 ans ».
Cette maladie est rare chez les jeunes ; selon Bladé et Kyle (1998) chez les moins de 40 ans elle comptait alors pour seulement 2% de tous les myélomes, et chez les moins de 30 ans ce taux tombe à 0.3% .Vers 2010, après le diagnostic, la survie sans incident est estimée à 5 mois, la survie totale à 56 mois.En cas de MGUS (Monoclonal Gammopathy of Unknown Significance) on observe uniquement une sécrétion anormalement élevée d'immunoglobuline (Ig) monoclonale, par des clones plasmocytaires qui  ont échappé au contrôle de l'organisme.Les MGUS, souvent bénins et sans signes cliniques, peuvent avoir plusieurs origines : des stimulations antigéniques longues ou répétées telles que des infections chroniques bactériennes ou virales (hépatite par exemple), un cancer profond distant, ou plus simplement elles sont une causés par le vieillissement du système immunitaire.Certains MGUS évoluent en myélome.
Alors, en plus de l'immunoglobuline monoclonale, le plasmocyte (ou le stroma conjonctif l'entourant) sécrètent de nombreuses autres molécules, dont des OAF (Osteoclast Activating Factors) ; principalement : IL-6, TNFα, IL-1, voie Rank- Rank-L qui tous stimulent la résorption osseuse ostéoclastique.
L'os se déminéralise alors, ce qui suscite des lacunes osseuses, des douleurs osseuses, et une hypercalcémie.
Dans un second temps la formation ostéoblastique est en outre inhibée par une sécrétion de DKK1 et de sclérostine.Parallèlement le plasmocyte pathologique (myélomateux) sécrète également des molécules inhibant l'érythropoïèse (d'où l'anémie).
Et plusieurs autres cytokines peuvent affecter les lymphocytes B et inhiber le rétrocontrôle de la prolifération plasmocytaire.
Ces substances peuvent aussi réduire la production normale des immunoglobulines (par les plasmocytes non myélomateux), ce qui diminuera l'immunité face aux infections différentes.La recherche s'attache à mieux comprendre les conditions prédéterminantes de la maladie (gammapathie monoclonale, myélome multiple « couvant »...) pour aider à déterminer chez qui ce cancer risque le plus de progresser et qui pourrait bénéficier d'un traitement précoce, lequel invite à envisager une politique de dépistage pour traiter la maladie avant même qu'elle ne se développe, avec alors bien moins de risques pour le patient.On a récemment compris que le myélome multiple ne correspond pas une maladie unique, mais plutôt un large éventail de situations pathologiques, dont la progression est liée à plusieurs facteurs génétiques, très différents.
Il pourrait en ressortir à l'avenir des façons innovantes de personnaliser les traitements.Elles sont mal comprises mais outre l'âge, des facteurs environnementaux semblent en cause au moins dans un certain nombre de cas :Le diagnostic est souvent fortuit, lors d'un examen sanguin de routine, parfois même à l'occasion d'un examen de fonds d'œil.Les symptômes les plus fréquents sont :La principale conséquence du myélome est la présence d'une très grande quantité d'immunoglobulines dans le sang.
Ces immunoglobulines sont des protéines, qui se manifestent par :L'hypercalcémie, fréquente, est liée aux destructions osseuses.On retrouve aussi un excès de protéines dans les urines ; cette protéinurie est constituée de chaînes légères des immunoglobulines monoclonales, aussi appelées protéine de Bence-Jones.
L'immunoélectrophorèse ou l'immunofixation des protéines urinaires détermine le type de chaîne, kappa ou lambda.
Ce pic est décelé dans les bêtaglobulines.Une gammapathie monoclonale bénigne ne comporte ni anémie, ni lésion osseuse, ni complication viscérale.
Comme son nom l'indique, elle n'a pas du tout le même caractère de gravité que le myélome et ne requiert qu'une simple surveillance.Le myélogramme étudie les cellules de la moelle osseuse, prélevées par ponction, à la recherche d'un excès de plasmocytes.
Dans le myélome, la moelle est infiltrée par des plasmocytes, qui présentent d'habitude de nombreuses anomalies morphologiques et sont fréquemment en mitose.La radiographie du squelette montre très fréquemment des lésions osseuses de type ostéolyse.La tomodensitométrie à faible dose de tous le corps est plus sensible que la radiographie conventionnelle pour décrire les aspects ostéolytiques ; elle est recommandée depuis 2015 en Europe comme nouvelle norme pour détecter les lésions lytiques du grade 1A du myélome.Le myélome est une maladie grave.
Il en existe cependant des formes atténuées (faible masse tumorale) pouvant rester asymptomatiques (sans signe apparent) pendant des années.Le myélome peut se compliquer : La stratification de la maladie peut être faite suivant différents critères.
Celle de Durie et Salmon a été employée jusqu'en 2005.
Elle a été remplacée alors par une classification internationale.Le traitement classique du myélome a longtemps été une chimiothérapie pénible, pour les cas de maladie active, combinant le plus souvent (depuis les années 1960) du melphalan et des corticoïdes.Aujourd'hui de nouvelles thérapies, dites « ciblées » sont adaptées à l'âge, au stade de la maladie, à l'état des reins du patient, etc.
Elles ont totalement modifié la prise en charge du myélome multiple (bortézomib ou Velcade, la thalidomide, doxorubicine liposomale pegylée ou Caelyx et la lénalidomide ou Revlimid).
La thalidomide est donnée en première intention en association avec le melphalan et la prednisone.Le lénalidomide est donné en seconde intention en association avec la dexaméthasone pour les formes réfractaires ou en cas de rechute après au moins une ligne thérapeutique ayant comporté des alkylants et lorsqu'aucune alternative n'existe.
La lénalidomide est reconnue à l'échelle mondiale comme étant l'un des médicaments les plus efficaces en association pour le traitement du myélome multiple.
C'est aussi un traitement qui prolonge la vie des patients et qui, dans bien des cas, leur permet de conserver pleinement une vie active,.
Le bortezomib est potentiellement utilisé à plusieurs stades de la maladie, notamment en première ligne associé à la thalidomide et au melphalan.Jusqu'à la fin du XXe siècle, on s'abstenait de traitement si le myélome était dormant ou à un stade très peu avancé, car « les traitements contre le myélome étaient si exigeants et toxiques - chimiothérapie à haute dose suivie d'une perfusion des propres cellules souches de la personne, par exemple - qu'ils étaient difficiles à justifier chez les personnes n'ayant pas de symptômes et pouvant ne jamais développer le cancer ».
Depuis le début des années 2000, des inhibiteurs du protéasome (bortézomib, imides immunomodulateurs comme le lénalidomide) ont changé les règles car ils sont mieux tolérés et plus efficaces (permettant souvent une rémission temporaire du myélome actif).
En 2020, on se demande s'il ne serait pas utile de traiter plus tôt, même si (comme pour le GMUS) un myélome latent peut ne jamais évoluer vers la maladie active, alors que quelques autres se transformeront en cancer quelques années après le diagnostic ; la question est encore en suspens car les traitements, bien que plus doux qu'autrefois, ont néanmoins encore des effets secondaires, notamment un risque d'induction de certains autres cancers, et ils sont extrêmement coûteux.
Les doses ne peuvent être diminuées (sinon on élimine les cellules myélomateuses les moins agressives, au profit des plus agressives qui prennent alors le dessus).Il faut aussi lutter contre les douleurs osseuses, l'hypercalcémie, et traiter les complications s'il y a lieu.
Les bisphosphonates sont utilisés contre la lyse osseuse et auraient une action propre contre le myélome.Depuis la fin des années 1990, on privilégie les techniques dites d'autogreffe de cellules souches, consistant à prélever des cellules souches qu'on « nettoie » des cellules porteuses de la maladie et qu'on congèle, puis à mettre le malade en aplasie (destruction totale des plasmocytes).
On réinjecte alors les cellules souches, qui vont régénérer des plasmocytes « sains ».
Cette technique peut être répétée, surtout en cas de réponse incomplète de la première autogreffe, la survie moyenne dépassant alors les sept ans.En 2014 on a élargi la définition du myélome actif pour y inclure les patients asymptomatiques mais dont les analyses révèlent des biomarqueurs associés à un risque de 80% de développer des symptômes dans les deux ans.
Le nombre de patients ayant un statut de maladie active est alors passé de 10 à 15% des patients diagnostiqués pour myélome couvant.
On leur recommande alors un traitement immédiat.En 2015 le réseau European Myeloma Network a émis les remarques et recommandations suivantes : Virothérapies ?
Selon Brian Owens (Nature, novembre 2020), « les thérapies qui utilisent des virus pour attaquer les cellules tumorales sont à nouveau prometteuses après des déceptions précoces », Immunothérapies?
Cette voie, qui a connu un grand succès contre de nombreuses autres formes de cancer, fait aussi des progrès contre cette maladie.Dans les années 2000-2010, l'immunothérapie cellulaire cible une protéine dite "antigène de maturation des cellules B"  (ou "BCMA").
Cependant chaque cellules cancéreuses n'expriment pas cette protéine, ce qui explique que chez certains patients ce traitement ne fonctionne pas ou autorise des rechutes.En 2019, on a trouvé un récepteur (dit GPRC5D) anormalement exprimé par les cellules de la moelle osseuse dans le myélome multiple.
Il semble pouvoir être une cible presque idéale pour un immunothérapie (dite thérapie par cellules T de récepteur d'antigène chimérique ou thérapie CAR-T).
On ne le connait en effet pas dans les cellules d'autres tissus (hormis dans le follicule pileux).
On a donc conçu des cellules immunitaires ciblant uniquement les cellules tumorales porteuses de GPRC5D.
Elles se sont montrées efficaces chez la souris de laboratoire modifiée pour exprimer des cellules de myélome multiple humain.
Des malades au stade avancés pourraient aussi bénéficier d'un tel traitement encore à tester chez l'être humain.Jusqu'en 2010 environ, ce pronostic était médiocre.Ce cancer reste assez fréquent (second cancer du sang le plus courant après la leucémie) - mais entre 2010 et 2020, de nouveaux traitements en ont amélioré le pronostic.Le système international de pronostic (« International Staging System ») peut aider à prédire la durée de survie qui dépend de la phase de la maladie.La survie médiane est de 62 mois pour la phase 1 de la maladie, de 45 mois pour la phase 2 de la maladie, et 29 mois pour la phase 3 de la maladie.Les anomalies cytogénétiques de type 6p21 et 11q13 sont associées à un meilleur pronostic.Les calculs de durée de survie sont toujours effectués par analyses rétrospectives, et il est probable que de nouveaux développements de traitement permettent déjà d'améliorer les perspectives de ceux qui avaient traditionnellement « de faibles chances de survie ».En France :En Europe :Au Canada : Dans le reste du monde :
Le clonage désigne principalement deux processus.
C'est d'une part la multiplication naturelle ou artificielle à l'identique d'un être vivant, c'est-à-dire avec conservation exacte du même génome pour tous les descendants (les clones).
C'est donc un synonyme de certaines formes de multiplication asexuée telles que le bouturage.
C'est d'autre part la multiplication provoquée d'un fragment d'ADN par l'intermédiaire d'un micro-organisme.
Ainsi, en biologie, le mot clonage désigne plusieurs choses :Au sens scientifique, le clonage est l'obtention d'un être vivant génétiquement identique à l'original qui a fourni son génome.Des vrais jumeaux, monozygotes, chez les animaux et chez l'Homme sont des clones naturels.
Ils démontrent à la fois les ressemblances et les différences que l'on peut attendre chez des clones artificiels, en raison du contexte différent où ils peuvent être placés (alimentation, traitement différents par l'éleveur ou les parents, etc.).Le terme clone est utilisé pour la première fois en 1903 par le botaniste H.
J. Webber en désignant des plantes reproduites par multiplication asexuée.
Ce mot sera ensuite réutilisé par J.
B. S. Haldane.Dans la nature, le clonage n'est rien de plus qu'un mode de reproduction parmi tous ceux à la disposition des êtres vivants.
C'est même le plus répandu puisqu'il concerne toutes les cellules procaryotes (division), presque tous les eucaryotes unicellulaires (mitose) à l'exception de ceux qui pratiquent la reproduction sexuée (faisant intervenir la méiose), mais également de nombreux végétaux et animaux multicellulaires.Le clonage peut être naturel chez les plantes (fraisier, ail, etc.); il est dans ce cas le plus souvent appelé multiplication végétative.
Il a lieu par émission de rejets, par marcottage naturel, par division naturelle de rhizomes ou de stolons, par création d'organes spécialisés bulbilles, etc.Certaines espèces végétales émettent des rejets, comme l'olivier.
Lorsque l'ortet initial vieillit, il émet des rejets sur le pourtour de sa souche.
Ces ramets deviennent ensuite autonomes et se séparent entre eux lors de la disparition de la souche initiale avec le temps.
D'autres, comme les fraisiers, produisent des stolons, rameaux dont le bourgeon terminal s'enracine au contact d'un substrat favorable et reproduit ainsi, par marcottage naturel, une plante identique à la plante mère.
Par bouturage naturel des morceaux de plante peuvent repousser s'ils se retrouvent placés dans de bonnes conditions, et redonner une plante adulte complète.En horticulture et en culture, les techniques de reproduction des plantes par clonage peuvent être pratiquées en laboratoire, sous serres ou sur le terrain.
Elles sont applicables chez beaucoup de dicotylédones produisant des méristèmes en abondance et sur quelques monocotylédones également (le bananier peut se multiplier par rejets, la canne à sucre par bouturage).
On peut citer le greffage, le bouturage et d'autres techniques cette fois inspirées de la multiplication végétative naturelle : (le marcottage, le démariage de rejets ou la division de rhizomes et de stolons, etc.).En laboratoire, on pratique la culture in vitro de méristèmes (ou d'autres parties de la plante) produisant des embryons puis des plantules complètes (voir embryogenèse somatique et embryogenèse zygotique).
Les techniques in vitro sont les seules qui peuvent être employées pour des monocotylédones comme le palmier dattier, le palmier à huile.
Les producteurs parlent de « vitroplants ».Le comportement et la forme des clones peuvent différer selon la partie de la plante d'où sont extraites les cellules destinées à les produire.
Par exemple, chez les fraisiers des bourgeons adventifs stipulaires ou donnent des fraisiers à feuilles plus claires et plus rondes.
Ils présentent un métabolisme différent, un nombre plus élevé de stolons, un réceptacle floral plus court, des étamines aux anthères plus grosses, alors que le clone axillaire est, lui, moins bien pollinisé et produit pour cette raison des fruits plus souvent difformes, notamment en l'absence d'agents pollinisateurs.Le clonage végétal a déjà permis de réinsérer des espèces disparues.
Comme la Cylindrocline lorencei qui a pu être réimplantée par le conservatoire botanique national de Brest en 2007, à partir de vieilles semences.Dans le domaine animal, un pas est franchi au XXe siècle grâce au clonage à partir de noyaux de cellules différenciées, réimplantés dans des ovocytes préalablement énucléés.
Cette technique au taux de réussite encore faible et qui n'a abouti que chez quelques espèces en est à ses balbutiements.
Des problèmes de vieillissement accéléré semblent pouvoir être reliés à l'état des télomères.La technique du clonage par implantation d'un noyau dans un ovocyte énucléé est mise au point en 1952 par Briggs & King.
Ils introduisent un noyau provenant de la blastula d'une grenouille dans un ovocyte dont le noyau a été éliminé.
Le stade blastula étant issu du développement embryonnaire précoce des vertébrés, il a fallu attendre 10 ans de plus pour voir l'avènement du premier organisme cloné à partir d'un noyau de cellule différenciée.
En effet, en 1962, Gurdon introduit le noyau d'une cellule intestinale de têtard dans un ovocyte énucléé de Xénope et obtient des amphibiens viables et fertiles.Au début des années 1960, l'embryologiste chinois Tong Dizhou, fut le premier à cloner un poisson à partir du noyau d'une cellule d'embryon.
Il publia ses recherches dans un magazine scientifique chinois qui ne semble pas avoir été traduit à l'époque.
C'était 33 ans avant la brebis Dolly, mais Dolly, elle, fut clonée à partir d'une cellule provenant d'un individu adulte.Cette technique a permis de cloner les animaux suivants :Toutes ces expériences ont montré que le clonage des mâles est en général plus délicat que celui des femelles.
De plus, pour des raisons encore inconnues, seuls 5 à 10 % des œufs fabriqués et réimplantés produisent des clones viables ou en bonne santé apparente.
On ne comprend pas non plus pourquoi certaines cellules d'un organisme se clonent mieux que d'autres.Un second pas est franchi avant le nouveau millénaire par le clonage de seconde génération (obtention d'organismes clonés à partir d'autres organismes clonés) sur des souris, puis un taureau.En 2007, il existe près d'un millier de cochons clonés et près de 3 000 bovins.Seul le matériel génétique du noyau est transféré lors d'un clonage.
L'ADN mitochondrial reste celui de la cellule réceptrice tout comme la machinerie nécessaire à la transcription de l'ADN pendant les premières phases du développement embryonnaire.
Une autre source de variation est la régulation épigénétique.
L'épigénétique conserve une même séquence ADN mais en modifiant l'expression de certains gènes en régulant la condensation de l'ADN (modifiant la production de protéines entre autres effets), ceci permet par exemple aux différentes cellules humaines de devenir des cellules différenciées sans modifications de leur séquence ADN.
De même, des facteurs environnementaux peuvent modifier le devenir des embryons.
En pratique les animaux clonés diffèrent sur plusieurs paramètres et sont moins ressemblants que de vrais jumeaux monozygotes (ayant le même patrimoine génétique).
Cela est particulièrement visible en cas d'animaux tachetés, les taches du clone n'ayant pas de raison particulière de se trouver à la même place, marquant de façon visible que les deux animaux sont différents.Lorsque l'on parle de clonage moléculaire cela fait référence à une technique de biologie moléculaire qui consiste a l'insertion d'un fragment d'ADN dans un vecteur.
Le plus souvent le vecteur est de nature plasmidique.
Un plasmide est un fragment d'ADN double brins et circulaire qui possède sa propre origine de réplication.
Dans le domaine de la recherche biologique, les plasmides sont utilisés afin d'insérer des fragments d'ADN que l'on appel gènes dans le but d'étudier leurs fonctions.
Le clonage moléculaire est notamment utilisé pour restaurer la fonction d'un gène préalablement supprimé, muté ou rendu inactif.
L'insert d'un gène peut également permettre la production de la protéine codée par celui-ci.
Idéalement, cette production est contrôlée via des séquences dites d'induction telles que celles de l'opéron lactose.
Différentes souches de Escherichia coli sont classiquement utilisées selon les étapes et les besoins.
La méthode la plus ancienne pour cloner des fragments d’intérêt appelé insert dans un vecteur plasmidique est l'utilisation des enzymes de restrictions.
Ces enzymes sont purifiées à partir des organismes procaryotes.
Initialement se sont des enzymes qui servent a cliver l'ADN considéré comme étranger (par exemple l'ADN de virus infectant les bactéries, les bactériophages).
Ce système de reconnaissance de l'ADN étranger chez les procaryotes a été détourné par les scientifiques pour en faire des outils de biologie moléculaire.
Les enzymes de restrictions reconnaissent des courte séquence d'ADN qui correspondent à leur domaine de fixation à l'ADN.
Une fois fixées elles sont capables de couper l'ADN double brins de deux manières : i) coupure à bout franc, cela correspond a une coupure que l'on peut se représenter comme vertical du double brin d'ADN, l'extrémité 5' est positionné au même niveau que l'extrémité 3', ii) coupure a bout cohésive, l'ADN double brin est coupé en forme d'escalier.
Cela  correspond à un brin 5' plus long que le brin 3'.
La technique de clonage mise au point consiste dans un premier temps à l'amplification en PCR "Polymerase chain reaction" autrement appelé réaction de polymérisation en chaine du gène d’intérêt.
Les amorces utilisées pour amplifier l'insert permettent d'ajouter aux extrémités de l'amplicon des sites de fixation des enzymes qui ont été préalablement choisit.
Le choix des enzyme dépend de plusieurs facteurs.
Il faut impérativement que les enzymes de restrictions ne soit pas présente dans l'insert, ou sinon l'insert sera clivé.
En revanche elle doivent être présent dans le plasmide vecteur, mais ne doivent couper qu'une fois dans une zone dédié a l'ouverture du plasmide, on parle de linéarisation du plasmide.
La plupart du temps il existe des MCS "Multiple cloning sites" dans les vecteurs.
Cela correspond à une zone ou il y a beaucoup de site d'enzyme de restriction unique pour le clonage.
Après avoir purifié l'insert coupé avec les enzymes de restriction, ainsi que le plasmide linéarisé a l'aide des même enzymes de restriction on peut cloné l'insert dans le vecteur en effectuant une ligation grâce à une enzyme appelé ligase.
Le vecteur doit être préalablement déphosphorylé pour éviter une recircularisation du vecteur.
En revanche l'insert doit être phosphorylé en 5' pour pouvoir être assemblé avec le résidu OH en 3' du vecteur.La technique de clonage par Gibson assembly  a été mise au point pour pallier les limites du clonage par restriction ligature.
En effet la dépendance aux sites de restriction qui peuvent être naturellement présents dans les fragments à cloner peut rendre la tâche difficile.
C'est pourquoi, cette technique de clonage est fondé sur le rajout de séquences complémentaires aux extrémités des amorces sur chaque fragments amplifié.
Ces séquences sont ajoutées lors de la PCR et sont appelé "overlap".
Le vecteur est linéarisé en PCR (ou en restriction) et on y ajoute entre 10 et 20 pb qui sont complémentaire du ou des fragments a cloner.
On fait de même pour le ou les fragments à cloner.
Chaque fragment d'ADN est ainsi orienté par sa complémentarité avec les autres fragments d'ADN en amont et en aval, cette complémentarité est unique ce qui permet d'assembler de nombreux fragments simultanément, de manière polarisé.
Le clonage s’effectue in vitro, avec un mix d'enzyme : i) une exonucléase qui possèdent une activité 5', ii) Une polymérase qui a une activité en 3' et iii) Une ADN ligase.
Avec cette technique on peut donc assembler de nombreux fragments dans un vecteur, de manière indépendante des enzymes de restriction.Plus récemment les scientifiques ont été capables de cloner le génome complet de certain virus, comme le SARS-Cov-2.
Cette technique particulière de clonage est appelé clonage TAR pour "Transformation-associated recombination".
Elle permet d'amplifier en PCR  une multitude de fragments qui correspondent à la totalité du génome du virus.
Chaque fragment amplifié est complémentaire de manière exclusive du fragment situé en amont et en aval, comme dans le principe du clonage par Gibson.
Ce qui permet de polariser chaque fragment.
Ce type de clonage repose sur la capacité des levures à reconstruire le génome sous la forme d'un très gros plasmide, appelé YAC "Yeast artificial chromosome".
L'assemblage des fragments complémentaires les uns des autres est donc effectué par la levure elle-même.
Le chromosome artificiel de levure est ensuite extrait de la levure sous la forme d'un très grand ADN circulaire correspondant a l'intégralité du génome viral.Le clonage, in vitro notamment permet – à faibles coûts – la création délocalisée de grands nombres d'individus.
Il permet de recréer des plantes en voie de disparition, mais recherchées par les collectionneurs ou amateurs (ex : orchidées qu'il n'est alors plus nécessaire de prélever dans la nature pour les vendre par exemple).
Plus important : il assure à la recherche que l'on va travailler sur des spécimens identiques, éliminant un facteur de bruit dans les mesures.Par contre, l'utilisation croissante de clones dans l'agriculture et la sylviculture est source d'une importante perte de biodiversité, et par là de fragilisation d'espèces qui sont des ressources agricoles et pour l'élevage.
Les plans issus de clones ou de greffes sont souvent à terme plus fragiles et sensibles aux épidémies de pathogènes, c'est un fait déjà noté, il y a presque 200 ans, par un fonctionnaire français François-Joseph Grille, qui, sans employer le vocabulaire des écologues modernes, protestait déjà contre l'appauvrissement génétique des populations d'ormes trop volontiers clonés et/ou greffés au détriment de la richesse adaptative que permet le semis :— François-Joseph Grille, Description du département du NordCette homogénéisation génétique a effectivement peut-être contribué à la rapide explosion de la graphiose de l'Orme.Des sylviculteurs tels que Akira Miyawaki ou l'école de sylviculture Prosilva ont développé des techniques visant au contraire à utiliser la biodiversité pour augmenter la résilience forestière, ce qu'encourage aussi l'écolabel forestier FSC.Plusieurs rapports provenant d’agences de sécurité et en particulier de l’AFSSA, de l’AESA (Agence Européenne de Sécurité Alimentaire) et la FDA tentent d’établir des règles permettant de déterminer si les produits issus des clones sont sains ou non pour les consommateurs.
Selon ces rapports, après six mois, un clone ne se distingue presque en rien qui soit mesurable des animaux contrôlés.
Un vétérinaire appliquant les règles classiques permettant de déterminer si la carcasse d’un animal peut être introduite dans les circuits de consommation, donnerait apparemment sans hésiter son autorisation pour la consommation des carcasses des clones de plus de six mois.
Cependant certains vétérinaires et scientifiques suggèrent que les clones ont une sensibilité un peu augmentée vis-à-vis de certaines maladies infectieuses, mais surtout qu’ils ne doivent pas être totalement sains étant donné leurs débuts souvent difficiles dans la vie.
Jean-Louis Peyraud, chercheur à l'Institut national de recherche agronomique a déclaré : «Des cas de veaux à trois pattes ou d'animaux à deux têtes ont été rapportés».
Toutes ces observations ont conduit la FDA et l’AESA à publier, en 2008, chacune un rapport sur les risques alimentaires de la consommation des produits issus des clones, après avoir pris en compte les avis des représentants de la société civile.
Les deux organisations ont alors conclu que rien ne pouvait faire supposer que la consommation de produits issus du clonage comporte un risque alimentaire, mais que cependant cette observation ne reposait pas sur assez de données et qu'il serait souhaitable d'augmenter les études sur le clonage.En 2020, la viande issue d'animaux ayant été clonés est de plus en plus fréquente, elle est légale dans certains pays comme les États-Unis, où la Food and Drug Administration (l'Agence américaine du médicament et de l'alimentation) a déclaré que la consommation de lait et viande produites par des animaux clonés était sans risque.
Le Brésil et le Canada autorisent également la consommation de ce genre de produits.
En Europe, certes aucune demande d'autorisation de vente de viande ou lait de clones n'a été faite, mais il n'est pas impossible que quelques-uns de leur descendants y aient été mangés car jusqu'en 2015 les clones ne faisaient pas l'objet d'une législation, et la viande a pu aussi être importée d'Amérique.
L'Agence européenne de sécurité des aliments n'a cependant pas d'inquiétudes, en 2017, pour la santé humaine.
Rien n’interdit non plus l’importation directe de viande ou de lait issus des enfants de ces clones, nés à l’étranger.Le Groupe européen d'éthique a conclu dans son avis : « Étant donné le niveau actuel de maladies et de problèmes de santé des mères porteuses et des animaux clonés, le groupe doute que le clonage d'animaux à des fins alimentaires soit justifié d'un point de vue éthique.
La question de savoir si cela s'applique également à la progéniture demande une recherche scientifique plus poussée.
À l'heure actuelle, le GEE ne voit pas d'arguments convaincants pouvant justifier la production d'aliments à partir d'animaux clonés et de leur progéniture ».
Ce groupe a aussi listé des mesures à prendre en cas d'introduction d'aliments issus d'animaux clonés dans l'UE.
Les eurodéputés ont donc adopté une législation le mardi 8 septembre 2015, interdisant le clonage d'animaux à des fins d'élevage et d'alimentation dans l'Union européenne, mais aussi l'importation de descendants et de produits issus d'animaux clonés (viande, lait, matériel reproducteur, etc.).
Les autres pays devront quant à eux, garantir que les produits qu'ils exportent en Europe ne sont pas issus de clones; par un système de certificats.Les promoteurs du clonage d'animaux d'élevage estiment qu'il répond à des enjeux de recherche agronomique (accélérer la sélection animale, sauver des races en voie de disparition) et scientifique (mieux comprendre les mécanismes de la régulation épigénétique des premières phases du développement embryonnaire).
La sécurité des aliments issus d'animaux clonés reste discutée, malgré la publication d'un avis favorable de la Food and Drug Administration (organisme fédéral américain chargé de contrôler la qualité des produits alimentaires mis en vente sur le marché américain) estimant que « la viande et le lait issus de bovins, de porcs et de chèvres clonés, ainsi que de la progéniture de clones d'espèces traditionnellement consommées sous forme d'aliments, ne présentent pas plus de dangers que ceux issus d'animaux élevés selon les méthodes classiques  L'agence n'exige pas l'étiquetage, ni aucune autre mesure supplémentaire, pour les aliments issus de clones de bovins, porcs ou chèvres clonés, ou de leur progéniture, car les aliments issus de ces sources ne diffèrent aucunement de ceux issus de bêtes élevées selon des méthodes classiques  Étant donné que les clones seraient utilisés pour l'élevage, leur introduction dans la chaîne alimentaire ne se ferait pas en nombres importants.
Au contraire, leur progéniture issue de la reproduction sexuelle serait utilisée pour la production de viande et de lait destinés à la commercialisation.
À l'heure actuelle, l'agence continue de recommander que les aliments issus d'espèces clonées autres que les bovins, porcs et chèvres (ex.
les ovins) ne soient pas introduits dans la chaîne alimentaire ».Début 2008, l'EFSA (Agence européenne de la sécurité alimentaire) prépare un nouvel avis sur ces questions.
D'après un rapport de la FDA publié en 2006, et d'un rapport de l'EFSA publié en 2008, il n'existe pas de différence ni de danger en matière de sécurité sanitaire entre les produits alimentaires dérivés d'animaux clonés et ceux traditionnels.
Selon ce rapport, compte tenu du manque d'études à l'époque il y avait des incertitudes dans l'évaluation des risques,.En 2008, 58 % des sondés par la Commission européenne se prononcent en défaveur du clonage animal, en raison de la considération du bien-être animal.Le clonage, par copie d'un génome, ne permet pas la diversification et recombinaison du gène caractéristique de la reproduction sexuée.
Or cette dernière est selon la théorie de l'évolution le moyen de l'adaptation du Vivant et de la biosphère aux changements environnementaux, et le gage de coévolution des organismes à reproduction sexuée avec celle de leurs prédateurs, pathogènes et parasites.Au-delà des questions techniques relevant du clonage animal en général, le clonage de l'humain pose des problèmes philosophiques nouveaux, débouchant sur la question d'une législation spécifique.
Quelques chercheurs travaillent actuellement sur le clonage humain reproductif.
Sans nier l'exploit technologique que constituerait une telle réalisation, la tendance internationale semble pencher vers l'interdiction, pour l'instant, des recherches sur le domaine.
Ceci étant, un sondage CNN montre un intérêt toujours grandissant du public pour la technique.
Arnold Schwarzenegger, ex-gouverneur de la Californie a milité en faveur du clonage humain.
Les opposants au clonage semblent d'autant plus pressés d'arriver à un consensus international.
Les États-Unis, avec plus de cinquante autres pays, ont signé un appel à une interdiction totale du clonage humain.
Un autre texte interdisant seulement le clonage reproductif a été rédigé par la Belgique et soutenu par plus de vingt pays, dont la Russie, le Japon, le Royaume-Uni, la Corée du Sud et le Danemark.
La recherche en faveur du clonage humain reproductif exprime une quête encore fantasmatique, de l'homme, pour son immortalité.Fin 2002, la firme Clonaid, associée au mouvement raélien, a affirmé par voie médiatique avoir réalisé le clonage d'êtres humains mais aucune preuve scientifique de leur existence ne fut apportée.
Le tout est tombé dans l'oubli depuis.Il est admis scientifiquement que l'identité de l'être ne se résume pas à son génotype, ce qui signifie qu'il est impossible de produire deux êtres identiques simplement en dupliquant un génome.
Le cas de vrais jumeaux (dits monozygotes), qui peut être techniquement apparenté au clone, ne peut être considéré comme un exemple de clonage humain, au sens où le principe de reproduction sexué entre deux parents est assuré naturellement, sans intervention technologique, et après brassage génétique.Mais tout ceci pose des questions éthiques, philosophiques, et religieuses importantes en ce début de XXIe siècle conduisant à de nombreux débats.
Devons nous considérer le clone, comme un Homme à part entière ou comme une pâle reproduction, une sorte de sous-homme ?
Devons nous les considérer comme notre égal ?
Faut-il créer une législation nouvelle pour les clones ?
Tant de questions qui sont à débattre.Cette nouvelle forme de génération présente par exemple des difficultés juridiques concernant le statut légal du clone.
Notamment lorsque l'on parle de clonage « thérapeutique », qui implique que le clone soit mis au service d'autrui par sa destruction partielle, voire totale.En mai 2005, des chercheurs de Corée du Sud ont annoncé les premiers clonages d’embryons humains à des fins de recherches thérapeutiques.
Après une controverse scientifique qui amène la publication dans Science à être retirée, il s'avère qu'il s'agit d'une reproduction par parthénogenèse et non par clonage.En 2008, des chercheurs américains, des entreprises Stemagen et Reproductive Science Center, ont annoncé avoir obtenu trois embryons clonés à partir de cellules adultes (cellules de peau) et d'ovocytes énucléés.
C'est la première fois que des embryons sont obtenus à partir de cellules qui ne sont pas des cellules souches.Après l'intervention des scientifiques Ian Wilmut et Keith Campbell en relation avec le mouton Dolly, l'Académie pontificale pour la vie a publié un document intitulé ' «Réflexions sur le clonage».
Ce document condamne fermement toute expérimentation avec des humains ou leurs cellules à des fins de clonage humain.
Les plasmocytes (parfois appelés à tort cellules plasmatiques - un calque du terme anglais plasma cells) sont des lymphocytes B pleinement différenciés, sécréteurs d'anticorps.
Ils sont uniquement présents dans les tissus.
On en trouve aussi beaucoup au niveau des muqueuses où ils produisent notamment des IgA dimériques qui deviendront des IgA secrétoires.
On ne les trouve ni dans le sang, ni dans la lymphe à l'état normal.
Dans les organes lymphoïdes périphériques, ils sont notamment présents au niveau des zones B des ganglions lymphoïdes.
Ce sont des cellules basophiles, hormis à proximité de leur noyau, région qui est nommée archoplasme.
Cette basophilie est due à la présence d'un abondant réticulum endoplasmique, riche en ARN, servant à la production massive d'immunoglobulines ou anticorps.Ces cellules produisent des anticorps et représentent le stade final de différenciation des lymphocytes B. À ce titre, elles participent à l'immunité à médiation humorale.À la différence des lymphocytes B, qui présentent leurs anticorps à leur surface (ancrés dans la membrane), les plasmocytes produisent des anticorps circulants.
De plus, ces cellules se caractérisent par une incapacité à se multiplier (contrairement aux autres stades d'activation des lymphocytes).
Le marqueur les caractérisant est une molécule nommée CD138 ou syndecan-1, un récepteur de molécules faisant partie de la matrice extracellulaire.Les lymphocytes B matures, une fois activés par leur rencontre avec l’antigène, se différencient en plasmocytes responsables de la production des anticorps et en lymphocytes B mémoire.L'archoplasme, du grec archos (« chef, guide ») et de plasmos (« chose »), est la partie juxtanucléaire du plasmocyte.
Seule région non basophile, il n'est donc pas coloré par les colorants usuels en microscopie optique et il apparaît translucide.
En microscopie électronique, on peut y voir l'appareil de Golgi.Certaines maladies cancéreuses impliquent un dérèglement lié aux plasmocytes, notamment les deux suivantes :
La recherche scientifique est, en premier lieu, l’ensemble des actions entreprises en vue de produire et de développer les connaissances scientifiques.
Par extension métonymique, on utilise également ce terme dans le cadre social, économique, institutionnel et juridique de ces actions.On peut cependant relever l'existence de quelques embryons d'une telle organisation, avec les lycées antiques, les écoles philosophiques, les universités médiévales, les monastères, ou le système du mécénat.C'est à Paris, au cœur de la vie universitaire européenne, que sont prises les premières tentatives d'encouragement des sciences de l'époque moderne, à travers les tentatives d'émancipation des arts libéraux.
Ainsi, Guillaume Budé profite-t-il de sa position auprès du roi François Ier pour suggérer la création du collège royal, futur collège de France.
Une institution qui a pour but d'encourager et de protéger financièrement ceux qui se dédient à l'étude de l'éloquence, et plus généralement à l'avancement des arts libéraux.C’est au XVIe siècle, en particulier avec Francis Bacon (1561-1626), qu’est précisée l’idée que la science peut et doit s'organiser en vue d'une maîtrise de la nature et du développement des nations.
En affirmant ainsi l’intérêt économique et politique du progrès scientifique, et la nécessité pour les gouvernants de ne pas mésestimer la valeur de leurs savants, Bacon pose les bases d'une recherche scientifique institutionnalisée, encadrée par une politique scientifique participant à l’organisation des travaux des savants pour mieux servir le progrès économique et militaire de la nation.
Dans son utopie de la Nouvelle Atlantide, Bacon imagine en particulier une « Maison de Salomon », institution préfigurant nos modernes établissements scientifiques, où sont rassemblés tous les moyens d'une exploration scientifique du monde.
Cette Maison de Salomon inspirera la création de la Royal Society, en 1660.Mais si Bacon peut symboliser un moment important de l'institutionnalisation de la recherche, il n'en est pas pour autant l'unique fondateur.
Ses textes traduisent une idée qui se cristallise à son époque, et qui commence à se manifester au travers de l'Europe.C'est au cours des XVIIe et XVIIIe siècles que se développent les Académies, qui sont la première véritable manifestation de l'institutionnalisation de la recherche, jusque-là organisée au gré des mécènes.Il faut cependant attendre le XIXe siècle pour que la recherche se professionnalise réellement, avec l'apparition des premiers chercheurs.La Seconde Guerre mondiale a été le déclencheur de la conception de nombre des systèmes d'intégration de la recherche dans la stratégie de développement économique et de défense des États modernes.
Vannevar Bush, aux États-Unis, est considéré comme un pionnier de cette organisation, qui a fait pression sur le monde politique pour la création de différentes instances, dont la National Science Foundation.La recherche scientifique recouvre des réalités très hétérogènes.Le manuel de Frascati, pour satisfaire des besoins statistiques, définit plusieurs types de recherche :Il faut également bien sûr prendre soin de distinguer les différents secteurs disciplinaires : la recherche en philosophie est évidemment très différente de celle en biologie moléculaire ou en archéologie.On peut également distinguer, à la suite des travaux de Terry Shinn, différents régimes de recherche : régime utilitaire, académique et technico-instrumental.Selon les différentes formes de recherche rencontrées, différentes sortes de normes et de règles encadrent les pratiques scientifiques.Ces normes et ces règles ne sont pas toujours d'ordre juridique.
La sociologie des sciences rapporte ainsi l'existence de normes propres au champ scientifique.Les différentes formes de recherche se distinguent également par les différentes normes « techniques » qui y guident l'activité intellectuelle.
C'est l'objet des épistémologies régionales d'analyser et comprendre ces impératifs épistémiques locaux.
De même, la « méthode scientifique » n'est pas la même selon les différents régimes de recherche.Les différentes formes de recherche se distinguent par le système normatif qui les encadre, mais aussi de manière plus concrète par les lieux, les métiers, les modes de financement et d'évaluation, etc.La recherche scientifique est généralement inscrite dans des lieux particuliers, qui offrent aux chercheurs les moyens d'exercer leur activité.
Ces lieux peuvent être des laboratoires, mais ce n'est pas systématiquement le cas.Les laboratoires, qui peuvent aussi bien être publics que privés, sont les lieux privilégiés où se déroule l'activité de recherche.
S'y trouvent rassemblés des chercheurs, des techniciens et des administratifs qui, dans l'idéal, collaborent autour d'un ou de plusieurs projets ou sujets de recherche.
Ces chercheurs y partagent les ressources et les moyens rassemblés dans le laboratoire.Il existe des laboratoires tant pour les sciences exactes que pour les sciences humaines et sociales.La taille, le type et la structure des laboratoires peuvent considérablement varier en fonction des moyens et des besoins.
Certains peuvent rassembler une poignée d'individus autour d'un unique instrument situé dans une modeste pièce ou un campement provisoire, d'autres peuvent associer des milliers de collaborateurs, physiquement éparpillés sur toute la planète en différents lieux (qui eux-mêmes peuvent constituer une « annexe », un « laboratoire » ou une « antenne » du laboratoire principal).Il est courant de constater une séparation entre les lieux d'expérimentation et d'analyse, ne serait-ce que par la nature du sujet étudié.Pour de nombreuses disciplines, en particulier celles des sciences humaines et sociales, l'activité de recherche peut se dérouler hors des murs du laboratoire.
C'est évident pour le philosophe, mais ce peut être également le cas du mathématicien, du sociologue, de l'historien.Outre ces situations particulières où l'activité de recherche peut accompagner le chercheur où qu'il soit, certaines disciplines se distinguent par leurs propres lieux de recherche : les centres d'archives pour l'historien, le chantier de fouille pour l'archéologue, le « terrain » pour le sociologue ou l'anthropologue, l'observatoire pour l'astronome...La recherche vise évidemment à produire des connaissances scientifiques.
Mais ces connaissances peuvent prendre des formes diverses : il peut s'agir de publications, de rapports, de brevets, de communications orales, etc.
Enfin, ces connaissances peuvent être incorporées dans de nouvelles machines, de nouveaux instruments ou dispositifs.
Ce sont tous ces produits qui, en étant diffusés au sein de la communauté scientifique, permettent au chercheur d'être reconnu par ses pairs, et de recevoir en retour les moyens nécessaires à la poursuite de son travail.Les chercheurs scientifiques publient leurs travaux dans diverses catégories de publications:Le terme de « publication scientifique » ne recouvre normalement que les trois premiers cas, c’est-à-dire des publications techniques évaluées par un comité scientifique, dirigées vers un public de spécialistes uniquement (chercheurs du domaine et de domaines proches, et plus rarement ingénieurs en butte à un problème d'ordre fondamental).
Les scientifiques peuvent en revanche être sollicités par des médias visant le grand public à des fins de vulgarisation scientifique, par exemple dans des magazines de vulgarisation scientifique (Pour la Science, Science et Vie, etc.), mais aussi dans le cadre d'émissions audiovisuelles ou dans des livres de science.La communication en vue des publications scientifiques peut se faire par les biais d'appels à papier, pour la rédaction d'ouvrage, de journaux ou bien de conférences.Les brevets ont commencé à se multiplier dans le monde de la recherche au cours des années 1980.
Naturellement, ils restent un produit plus caractéristique de la recherche privée que de la recherche publique.
Le monde académique développe cependant cette forme de publication de ses travaux.La recherche technico-instrumentale est un type de recherche particulier.La recherche scientifique regroupe différents corps de métier : chercheurs bien sûr, mais également ingénieurs, techniciens, administratifs...Un chercheur n'a pas nécessairement de statut qui reconnaisse la spécificité de son métier.
Est chercheur celui dont la fonction professionnelle consiste à contribuer de manière originale à la production de connaissances scientifiques.
Il peut ne pas avoir le titre de chercheur, mais être considéré comme tel par la communauté scientifique.
Il peut aussi bien être membre bénévole d'une association ou d'une ONG, ingénieur dans une entreprise de haute technologie que membre d'un laboratoire de recherche.
Une part essentielle de la recherche scientifique moderne, et pratiquement la totalité de la recherche fondamentale, est cependant faite soit au sein de laboratoires de recherche, soit en collaboration étroite avec ceux-ci.La recherche n'est pas nécessairement la seule activité du chercheur.
D'autres missions peuvent lui être confiées.
Des missions d'expertise dans le cadre d'une entreprise.
Des missions d'enseignement dans le cadre d'une université.
Le couplage enseignement recherche est de loin le plus courant, les universités occupant généralement une place centrale dans les systèmes nationaux de recherche.Les ingénieurs et techniciens impliqués dans la recherche scientifique font partie de ce qu'il est commun d’appeler « personnel de support de la recherche ».
Ils sont généralement chargés de la mise en application des expérimentations et de la conception des outils qui permettent de conduire ces expérimentations.Il n'est pas rare que des ingénieurs aient une véritable activité de recherche, publient des articles et développent des travaux originaux.
L'un des ingénieurs dont les recherches sont les plus connues est Claude Shannon et sa théorie mathématique de la communication.La distinction entre personnel de support et chercheur renvoie presque toujours à une différence statutaire.
En France par exemple, au sein des laboratoires universitaires les ingénieurs et techniciens appartiennent à un corps - les IATOS - différent de celui des chercheurs et enseignants chercheurs.
En Amérique du Nord, les établissements de recherche font une différence entre les corps des assistants et associés de recherche et celui des chercheurs.La plus grande partie de la recherche est aujourd'hui financée sur fonds privés.
l'État joue cependant un rôle toujours important et central dans le financement de la recherche, que cela soit en France ou dans les autres pays développés.Ces financements peuvent être attribués directement à des chercheurs, mais également à des équipes de recherche, des laboratoires, des institutions, des groupements d'institutions, des collectivités territoriales, etc.Le financement public est l'opération qui consiste à obtenir des ressources monétaires nécessaires à la réalisation d'un projet public venant de l'État.À un moment où la relance de l’innovation dans les entreprises est prioritaire, les PME françaises n’exploitent pas suffisamment l’opportunité que sont les aides européennes à l’innovation.
Ainsi elles représentent plus de 10 milliards d’euros pour la France sur la période 2007-2013.
Elles englobent de nombreux dispositifs destinés à soutenir des projets de maturité différente, qui vont de la recherche fondamentale à la mise sur le marché.
Ces aides concernent, en règle générale, des projets collaboratifs regroupant PME, laboratoires et grandes entreprises (PCRDT, PIC), et parfois des projets individuels (FEDER).Les financements peuvent représenter jusqu’à 75 % des projets.
L’effet de levier de ces aides est d’autant plus important qu’elles ont aussi des effets positifs indirects sur le développement des entreprises.
Elles leur permettent de poser les bases d’une stratégie d’internationalisation grâce au réseau développé avec de potentiels clients, fournisseurs, ou partenaires industriels.
La Commission européenne souhaite mettre en place un cadre stratégique commun pour le financement de la recherche et de l’innovation en Europe.Lorsque l'activité de recherche est jugée « Hors de l’intérêt national » ou s'effectuant en dehors des structures sous l'égide de l'état (CNRS, IFREMER, universités, etc.) celle-ci s'appuie intrinsèquement sur fonds privés.Par fonds privés s'entendent tous moyens techniques et financiers ne découlant pas d'une aide de l'état.Ce peut ainsi être des Dons effectués par des particuliers, des Bourses attribuées en partenariat avec une entreprise, un Emprunt contracté auprès d'un organisme...Dans la majorité des cas, il s'agit des biens personnels des chercheurs ou donations de leur entourage.Ces financements sont composés des salaires du personnel, lorsqu'ils sont en CDI ou ont le statut de fonctionnaire.
Ces financements récurrents sont également constitués des dotations des laboratoires ainsi que des moyens d'équipements (instruments scientifiques, ordinateurs, bureaux, locaux).Pour parvenir à des objectifs de politique scientifique, les organismes de financement de la recherche peuvent aussi lancer des appels d'offres sur des thèmes prédéfinis.
Les groupes de chercheurs intéressés par la proposition vont ensuite postuler pour que le projet leur soit attribué.
Dans ce type de procédure, l'autonomie de la science peut cependant être mise à mal par la formulation de projets où la réponse souhaitée par le financeur apparaît implicitement.Alternativement, l'initiative peut venir d'une organisation extérieure à la recherche : par exemple, une entreprise rencontrant un problème spécifique, mais aussi une association ou tout acteur de la société civile.
Ceux-ci peuvent susciter des appels d'offres financés, ou tenter de contacter les chercheurs et de les intéresser au problème de façon qu'ils relaient l'initiative.On désigne par le terme de financements par contrat tout accord contractuel entre un laboratoire scientifique et une organisation publique ou privée, conduisant à la rémunération d'une activité de recherche.
En France, la plupart des laboratoires universitaires ont désormais recours à ce type de financement pour accroître leur capacité de recherche.
Il n'est pas rare que dans les bilans de laboratoires les plus actifs, les deux tiers de leur budget de fonctionnement soient obtenus par ce biais.Les organisations publiques les plus connues pour leur activité de financement par contrat sont les agences officielles d'état.
Des projets scientifiques sont présentés par des consortiums composés de plusieurs laboratoires et entreprises qui travaillent en commun sur leur réalisation.
Avant d'accorder un financement, des experts indépendants examinent et valident le dossier puis contrôlent, pendant la durée du projet, son état d'avancement et sa conformité.
En France, l'Agence nationale de la recherche a pour finalité de financer des projets de recherche.
Elle fonctionne selon un mode opératoire très proche de celui de la Commission Européenne, qui elle aussi, finance de nombreux contrats de recherche par le biais de programmes spécifiques (programme-cadre pour la recherche et le développement technologique, dit aussi FP, ou encore e.content).Dans la plupart des pays, les administrations militaires proposent également des contrats de recherche : c'est le cas aux États-Unis avec la DARPA, ou encore en France avec la DGA.
Ces contrats prennent souvent la forme d'un financement de thèse de doctorat d'une durée de trois ans plus rarement celle d'une dotation pour un laboratoire ayant une spécialité intéressant l'armée.Les financements par contrat privés sont le fait d'entreprises souhaitant introduire dans leurs catalogues de produits des innovations technologiques.
Le laboratoire du physicien prix Nobel Albert Fert, par exemple, est financé en partie par la société Thales.
Des équipes de recherche peuvent également être composées en partie par des doctorants en thèse CIFRE.
Le thésard est un salarié de l'entreprise, il passe une partie de son temps au sein du laboratoire public.
En contrepartie, l'entreprise employeur perçoit une aide financière de la part de l'ANRT.
Une convention doit être conclue entre l'entreprise et le laboratoire afin notamment de préciser le régime de propriété et d'exploitation des fruits de la recherche.Le financement par contrat, en constante augmentation, accroît considérablement le nombre de salariés contractuels dans les laboratoires.
De nombreux ingénieurs, techniciens et administratifs sont ainsi recrutés chaque année pour des périodes variant de quelques semaines à 2 ou 3 ans.
Cette précarisation du métier de la recherche est parfois contestée dans le milieu universitaire français, bien qu'elle corresponde a une tendance dans toute l'Europe et qu'elle soit la règle en Amérique du Nord.Les partisans de ce mode de fonctionnement objectent que la contractualisation, donne une autonomie de moyen aux laboratoires, mais aussi aux chercheurs.
Par ce biais, ces derniers sont en effet en mesure de trouver eux-mêmes des sources de financements, et ainsi d'être moins dépendants de l'administration pour mener leurs recherches, ou recruter des collaborateurs (doctorants ou techniciens).Les laboratoires peuvent déposer des brevets sur des procédés mis au point dans le cadre de leur recherche.
Dans ce cas, la cession de licences peut permettre de percevoir des dividendes qui contribueront aux budget du laboratoire ou de l'université détentrice de ce brevet.
La plupart des universités française se dotent désormais de services de valorisation de la recherche, composés de juristes et de négociateurs, pour développer ce mode de financement.
Dans le reste du monde, ce mode de financement est en vigueur depuis de nombreuses années.Les formes d'évaluation de la recherche diffèrent très sensiblement selon les secteurs.
Elles peuvent porter sur plusieurs niveaux : les chercheurs eux-mêmes, leurs laboratoires et les institutions accueillant ces laboratoires.
De surcroît, les systèmes nationaux de recherche sont eux-mêmes évalués et comparés (benchmarking), en sorte d'améliorer et d'adapter les politiques de recherche.Les chercheurs sont doublement évalués :Naturellement, ces deux formes d'évaluation sont liées, la première reposant en grande partie sur la seconde, qui est la pierre angulaire du fonctionnement de la science.Dans les sociétés modernes, où l'effort de recherche est financé par l'État ou des entreprises privées, un fort besoin d'évaluer l'efficacité des efforts de recherche est apparu.
Dans le cas de la recherche fondamentale cependant, il est difficile, à court terme au moins, de déterminer la portée des résultats obtenus.
L'évaluation se base donc sur des indicateurs concernant la communication de résultats par les chercheurs, la continuité des recherches fondées sur ces résultats, la reconnaissance des avancées réalisées par le reste de la communauté scientifique, et, dans les cas où cela est pertinent, la valorisation commerciale ou sociale des résultats.Cette évaluation peut être effectuée sur une base individuelle ou collective.
Selon les critères employés et les choix qui découlent de l'évaluation, des effets pervers peuvent apparaître, les chercheurs infléchissant leurs choix pour améliorer leur évaluation plutôt que la qualité scientifique réelle de leur production.L'évaluation se fait en amont et en aval.Dans le contexte académique, l'initiative d'un projet peut être le fait d'un chercheur, ou d'un groupe de chercheurs, ayant une expérience suffisante pour discerner une direction intéressante de recherche, fondée sur les travaux précédents de la communauté scientifique.
Une fois la problématique posée, les chercheurs peuvent définir une démarche qui soit susceptible de lui apporter des éléments de réponse, ce qui définit un projet.Les besoins en moyens humains et matériels peuvent alors être évalués.
Parfois, ceux-ci peuvent être déjà entièrement couverts par des moyens à la disposition des chercheurs, si ces derniers disposent d'un statut leur assurant une période d'emploi et une autonomie de décision suffisante.
La plupart du temps cependant, il est nécessaire ou souhaitable de disposer de moyens supplémentaires, par exemple pour des frais de déplacement (réunions entre chercheurs travaillant dans des lieux différents, congrès), d'embauche de personnel contractuel (chercheur post-doctoral) ou de moyens expérimentaux, d'enquête, etc.
Une demande de financement doit donc être déposée auprès d'un organisme de financement de la recherche.
Le succès de cette demande dépendra des choix de politique scientifique de l'organisme.Plusieurs niveaux d'organisation de la recherche peuvent être distingués : le niveau des institutions, des nations et des entités supranationales, mais aussi celle des entités infranationales (commune, région, département, plus généralement organisation locales).Les laboratoires de recherche sont généralement groupés au sein d'institutions plus larges : entreprises, groupements professionnels, hôpitaux, universités, centres de recherche.
C'est d'abord au niveau de ces institutions qu'est organisée la recherche scientifique.
En plus de référents extérieurs (comités, normes...), ce sont ces institutions qui définissent les dispositifs d'évaluation, obtiennent des budgets, organisent la répartition des moyens, structurent les équipes, etc.Ces institutions ont généralement l'autonomie nécessaire pour définir l'organisation et les objectifs de leurs recherches.
Cela peut dépendre de leur propre situation (une entreprise rachetée par un grand groupe peut perdre cette autonomie, qui passe alors au niveau du groupe) ou du cadre national.
En France, les grandes lignes de l'organisation de la recherche publique sont définies évidemment au niveau national, tandis que les objectifs sont définis à plusieurs niveaux : équipe, laboratoire, établissement, agences gouvernementales, Commission européenne, partenaires contractuels.Pour sa part officielle, la recherche est menée dans des universités ou d'autres établissements d'enseignement supérieur, dans des organismes de recherche privés ou publics (EPST et EPIC en France), et dans les divisions de recherche des entreprises.
Elle dispose de moyens importants mais peu de marge de manœuvre car liée sous contrat de résultat.Pour sa part officieuse, la recherche est menée dans des lycées techniques, des associations à but scientifique, des apprentis...
Tout lieu utile déniché par les membres de l'équipe de recherche.
Elle dispose de faibles moyens et donc de temps limité, mais d'une complète autonomie de décision.Certaines activités font l'objet de concours et de rassemblements à but récréatif et sportif.
Les entreprises et organismes y ont parfois recours pour trouver de nouveaux talents ou de nouvelles idées.La recherche officielle est la « Voie d'or » pour un chercheur, lui donnant accès à une reconnaissance de son travail, la possibilité de publier ses résultats, de signer des contrats, d'obtenir financement et titres de brevet...À l'inverse, la recherche officieuse est généralement dénigrée ou reléguée aux activités sportives et récréatives du fait même des théories abordées (nouvelles ou controversées, souvent dépassées comme les recherches en alchimie ou en astrologie), d'une méthodologie empirique ou d'une approche inhabituelle, voire de la présence d'une personnalité à la mauvaise réputation.
Sa seule voie de réussite est la Nécessité publique ou la création d'une entreprise.
Se posent en effet les problèmes de reconnaissance du résultat et du coût des brevets potentiels.Les régions jouent un rôle de plus en plus important dans l'organisation de la recherche, avec le développement de structures rassemblant divers acteurs institutionnels (université, entreprise, organismes...).
Ces structures peuvent être des parcs scientifiques, des technopôles ou des pépinières d'entreprises.
Les différentes subdivisions administratives du territoire national (régions, länder, état, etc.) sont souvent fortement impliquées dans ces structures, qui intéressent directement le tissu économique local.Mais indépendamment même de ces strates administratives, la recherche peut spontanément s'organiser au niveau local, pour donner parfois des résultats particulièrement impressionnants.
C'est par exemple le cas de la célèbre Silicon Valley, qui a vu se former une division du travail particulièrement efficace entre un tissu serré de petites entreprises de haute technologie, quelques très grandes entreprises et des centres de recherche (en particulier l'université de Stanford), parfois en relation avec le complexe militaro-industriel américain.Au niveau national, les États définissent des politiques de recherche qui déterminent non seulement le financement public de la recherche, mais aussi une grande partie du contexte institutionnel et juridique de la recherche.
Se posent en particulier des questions sur le pilotage de la recherche et sur les grandes orientations stratégiques.Enfin, la recherche peut s'organiser au niveau international.
Il s'agit en particulier de la recherche communautaire, qui est aujourd'hui la forme la plus intégrée de différents systèmes nationaux de recherche.Mais d'autres formes de collaborations internationales en matière de recherche se développent également, généralement sur des questions précises ou sur des projets particuliers.
C'est par exemple le cas de nombreux programmes d'exploration spatiales, dont les coûts imposent d'organiser les phases de recherche au niveau international.Les retombées issues des progrès scientifiques sont de plusieurs ordres, bénéficiant à différents acteurs :Ces retombées rendent la recherche scientifique désirable, dans la mesure où elle n'enfreint pas les principes d'éthique et de précaution.
Le jeu des intérêts des bénéficiaires potentiels conduit donc les décideurs politiques et économiques à organiser et à financer la recherche.
Cependant, ces décideurs ne peuvent maîtriser le processus qui mène à la découverte scientifique, celle-ci n'étant pas toujours concevable au moment où les recherches sont entreprises : le pilotage de la recherche n'est donc possible que de façon limitée.Le rôle d'expertise dévolu aux chercheurs suppose aussi que ceux-ci sont indépendants d'intérêts commerciaux et de dogmatismes, qui pourraient biaiser leur réponse.
L'organisation et le financement de la recherche doivent donc permettre l'autonomie de la science.Afin de tenter de concilier ces différentes contraintes sur le fonctionnement de la recherche scientifique, un système complexe s'est peu à peu mis en place depuis 1945, avec un équilibre sans cesse modifié entre pilotage extérieur et autonomie des chercheurs, entre évaluation administrative et par les pairs, et où interviennent des capitaux publics et privés, le tout dans un cadre fixé par la législation.Enfin, une nouvelle approche dans l'intégration de la recherche dans la société civile émerge actuellement, où des associations peuvent lancer des appels d'offres de recherche qui sont ensuite subventionnés.Les sociétés modernes sont en butte à l'introduction de technologies toujours plus avancées, dont la réglementation nécessite une évaluation des risques et des bénéfices.
Ainsi, l'énergie nucléaire a l'avantage d'être de production peu coûteuse, mais le devenir des déchets radioactifs fortement toxiques est problématique.
Afin de prendre une décision, il est nécessaire d'avoir une expertise des différentes options pour la gestion de ces déchets, qui évalue, en se basant sur les connaissances disponibles, les probabilités des risques associés.
Une décision politique, fondée sur une appréciation de l'acceptabilité de ces risques, peut ensuite être prise.Pour cela, il est crucial que les chercheurs ne soient pas influencés dans leur travail par des intérêts politiques ou commerciaux (voir ci-dessous le paragraphe concernant la : « Question de l'autonomie et du pilotage de la recherche »), ou par une pression médiatique.Une autre cause de biais parfois dénoncée est l'intérêt personnel du chercheur, qui peut souhaiter qu'un équipement comme ITER soit bâti parce que sa recherche en bénéficiera, et ainsi tendre à accepter plus facilement les risques associés.
Plus généralement, les chercheurs sont susceptibles de survaloriser le progrès scientifique pour lui-même.
Cependant, l'appréciation elle-même des risques n'est pas du ressort de l'expert, et il appartient donc au politique et non au chercheur de décider de leur acceptabilité.Les scientifiques de différents domaines (médecine, science forensique, etc.) peuvent également être experts pour une décision de justice, là encore, leur indépendance est nécessaire, et leur rapport ne doit pas être confondu avec la décision de justice elle-même.Un scientifique peut être amené, dans le cadre de ses activités professionnelles, à trancher des questions ayant un contenu moral ou éthique.
Cela peut concerner :En 1955, le manifeste Russell-Einstein donna naissance au mouvement Pugwash, dont les conférences ont voulu être la conscience morale des scientifiques.Les activités biomédicales sont particulièrement concernées par les problèmes éthiques ; citons ainsi, notamment, la controverse autour des techniques de clonage et de leur hypothétique application à la personne humaine.
En 1994, l'unité de bioéthique de l'UNESCO recensait plus de deux cents comités d'éthique nationaux.Aujourd'hui les grands thèmes de réflexion éthique sont :La bioéthique est un débat actuel et regroupe les oppositions existantes par exemple sur la possibilité d'utiliser des embryons pour des expériences scientifiques.Pour Jacques Testart les interactions entre science et société incitent à soumettre la recherche scientifique, dès l’amont, à un contrôle démocratique afin de prendre en considération les critères éthiques et sociétaux.L'État doit en théorie assurer l'indépendance de la recherche publique en garantissant que les chercheurs ne seront pas influencés dans leur travaux par des circonstances extérieures.
Il est par exemple évident qu'un chercheur ne doit pas être influencé par des intérêts commerciaux.
Il ne doit pas non plus être influencé par des dogmes, qu'ils soient idéologiques ou religieux.
Enfin, il ne doit pas être influencé par un changement de gouvernement ou un état étranger.Outre la relative liberté d'expression, cette autonomie nécessite la stabilité de l'emploi du chercheur et des mécanismes sains d'évaluation et de financement de la recherche.Cependant, la société au sein de laquelle la recherche publique est menée est en butte à des problèmes qu'elle souhaite voir abordés de façon prioritaire par les chercheurs — leur autonomie a donc certaines limites.
Les décideurs introduisent pour cela des modes de pilotage de la recherche, sélectionnant et recrutant du personnel diplômé pour travailler sur ces axes.
Un compromis est donc indispensable entre liberté et pilotage de la recherche.Ces trois catégories sont parfois mêlées de manières indistinctes.
Il s'agit pourtant de phénomènes totalement différents, et qui ne relèvent pas toujours du pathologique.La recherche scientifique ne consiste pas en l'application d'une méthode d'une parfaite infaillibilité.
Elle se nourrit des erreurs prospectives et des errements consubstantiels au métier de chercheur, dont la démarche peut être fondamentalement incertaine.
Bien que les grandes découvertes soient souvent le fruit d'un programme préétabli, elles apparaissent occasionnellement de manière inattendue.
Cette particularité de la recherche scientifique porte un nom : c'est la sérendipité.L'histoire montre que les plus grands savants ne sont pas à l'abri d'erreurs.
Galilée a par exemple soutenu une théorie sur les marées en contradiction avec des observations connues de lui, qu'il attribuait à des causes secondaires indéterminées (lire l'article en anglais).
Il ne faut cependant pas adopter une lecture contemporaine de ces erreurs, et il importe de bien garder à l'esprit que ces erreurs, dans le contexte scientifique d'une époque particulière, n'avaient souvent rien d'évident.Enfin, la recherche scientifique est collective.
Si l'erreur peut être un problème pour le chercheur comme individu, elle est essentielle à la marche en avant du processus collectif de production des connaissances scientifiques.La fraude est très différente de l'erreur.
Mais là encore, il faut se garder d'une vision unilatérale et anachronique de la fraude.
Les normes encadrant l'administration de la preuve ne sont pas aujourd'hui ce qu'elles étaient hier.
On pouvait tolérer hier de retoucher quelques données, ce n'est plus le cas aujourd'hui.Des analyses statistiques ont montré que Gregor Mendel, le père de la génétique moderne, a probablement arrangé des résultats, sans doute en omettant des données jugées trop éloignées du résultat attendu, et également en se focalisant sur un cas particulier bien choisi (lire l'article en anglais).La fraude scientifique peut prendre de multiples formes :D’autres comportements, sans prendre le caractère d’une fraude, s’en rapprochent : ainsi, la présentation d’un résultat scientifique pour ce qu’il n’est pas, la présentation du même résultat dans plusieurs publications, etc.Son but est le plus souvent de permettre la construction d’une notoriété scientifique, mais d’autres raisons peuvent apparaître (justification de financements, etc.).La principale cause de la fraude scientifique est le fait que la carrière des chercheurs dépend de leurs résultats : recrutements, promotions, etc., se font le plus souvent au vu de la production scientifique, c’est-à-dire essentiellement des publications scientifiques.
Il peut donc être tentant d’augmenter artificiellement ce nombre.
Les équipes et laboratoires sont en concurrence, et chacun essaye d'apparaître comme le meilleur.Les publications scientifiques sont évaluées par d’autres scientifiques, lesquels ne peuvent le plus souvent pas reproduire les expériences des candidats à la publication.
L'évaluateur peut ainsi se trouver dans la position inconfortable deIl est rare qu’une fraude soit détectée au moment de l’évaluation.
Par ailleurs, dans la plupart des cas, les erreurs dans les publications scientifiques sont commises de bonne foi, parfois par manque de rigueur (voir ci-dessus), parfois simplement parce que la vérité est hors de la portée de l'étude.La justice intervient rarement dans des affaires de fraude scientifique ; cela arrive cependant parfois, notamment dans des affaires médiatisées où l’un des participants accuse l’autre de diffamation.
Cependant, les organismes de recherche ou les universités peuvent être pourvus d’instances disciplinaires pouvant sanctionner professionnellement un manquement grave à la probité scientifique.
Ces dernières années, un certain nombre de fraudes ont défrayé la chronique.Quelques exemples de fraudes célèbres :Mais l'accusation de fraude scientifique pose problème.
La Société Géologique de France a d'ailleurs réhabilité en 1991 un scientifique condamné pour fraude en 1919 : Jacques Deprat.
C'est le seul cas connu de réhabilitation, à titre posthume.La controverse, qu'elle soit de nature scientifique, sociale ou de débat public, est un élément très important de la dynamique de la science.
La recombinaison V(D)J est un mécanisme de recombinaison de l’ADN qui se produit uniquement au cours des premiers stades de la maturation des lymphocytes B et les lymphocytes T.C’est une recombinaison site-spécifique sur le chromosome support de la protéine, qui retient de manière presque aléatoire l'un des nombreux allèles homologues utilisables dans le domaine « variable », pour ses différents segments « variable » (V), de « jonction » (J) au domaine constant, et pour certaines protéines, de « diversité » (D).
Le processus utilise en particulier plusieurs éléments d'un mécanisme plus général de réparation de l'ADN, appelé réparation par jonction d'extrémités non homologues.Cette recombinaison assigne à chacun de ces lymphocytes une combinaison unique d'allèles, et donc une configuration unique de la protéine qui sera potentiellement traduite.
Elle est à l'origine de la grande diversité de récepteurs des cellules T et d’immunoglobulines nécessaires à la reconnaissance spécifique de l’immense variété des antigènes étrangers.
Il en résulte un répertoire très diversifié d'anticorps / immunoglobulines et de récepteur des cellules T (TCR), chaque récepteur n'étant porté que par une fraction infime des lymphocytes.Ce processus est la caractéristique clef du système immunitaire adaptatif, qui permet la reconnaissance des antigènes de presque tous les agents pathogènes, y compris les bactéries, les virus, les parasites et les vers, ainsi que les "cellules du soi altérées" comme on en trouve dans le cancer.
Quand elle est défaillante, la « reconnaissance » peut également conduire à des réactions de nature allergique (par exemple au pollen ou à d'autres allergènes), ou être dirigée contre les tissus de l'hôte et conduire à une maladie auto-immune.La recombinaison V(D)J est présente chez les humains et d’autres vertébrés.Chez les mammifères, elle se produit dans les organes lymphoïdes primaires (moelle osseuse pour les lymphocytes B, et thymus pour les lymphocytes T).En 1987, Susumu Tonegawa a reçu le prix Nobel de physiologie ou médecine « pour sa découverte du principe génétique de la génération de la diversité des anticorps ».Les récepteurs des antigènes (immunoglobulines, récepteur des lymphocytes B et récepteur des cellules T) appartiennent à la superfamille des immunoglobulines.
Ils sont formés de chaînes de protéines, elles-mêmes formées de plusieurs domaines, en partie « constants » (C), et dont l'un au moins est « variable » (V) :Dans les trois cas, les domaines « constants » assurent les fonctions structurelles invariantes de la molécule, et les domaines « variables », en extrémité, réalisent la reconnaissance des antigènes suivant leur conformation.Sur le chromosome qui porte le codage de la chaîne polypeptidique, les régions « variables » (V) sont codées par des gènes à travers trois types de segments à assembler, chaque segment pouvant être réalisé par de nombreux allèles.Par exemple, dans le génome humain, le locus de la chaîne lourde des immunoglobuline contient initialement 50 gènes différents pour le segment « Variable » (V), 30 versions de gènes pour le segment de « Diversité » (D) et 6 pour le segment de « Jonction » (J), outre 9 gènes C (Constant) pour la partie « constante ».
Les gènes codant les chaînes légères possèdent de même de nombreux segments V et J (mais n'ont pas de segment D).
La chaîne légère kappa, de son côté, contient près de 40 gènes V et 5 gènes J.
La chaîne lambda contient 52 versions de V et sept assemblages J-C.Lors de la maturation du lymphocyte, un seul gène de chaque type sera conservé.
La recombinaison entre les fragments VDJ permet donc de générer V x D x J = 50 x 30 x 6 = 9000 possibilités différentes pour la chaîne lourde, 200 possibilités pour la chaîne kappa, et 364 pour la chaîne lambda, ce qui permet donc d'exprimer un « vocabulaire » de plus de 5 millions de configurations différentes à partir de l'assemblage des deux.Ce nombre est évidemment approximatif (en raison du polymorphisme, le nombre de gènes V, D et J fonctionnels diffère selon les individus) mais il permet d'apprécier l'économie de moyen réalisée par la recombinaison VDJ : partant de quelques dizaines de duplications pour chaque segment, la recombinaison ici de cinq parties variables permet l'expression de millions de configurations différentes.
Si toutes ces combinaisons avaient dû être codées directement sur le chromosome, la longueur du codage aurait été des dizaines de milliers de fois plus longue.Les loci des gènes V, D, J sont flanqués par des recombination signal sequences (RSSs) qui sont reconnues par un groupe d’enzyme connues collectivement comme VDJ recombinases.
RSS sont constitués par un heptamère (constitué  de  sept nucléotides) palindromique conservé, suivi d’une séquence intercalante de 12 ou 23 nucléotides, puis un nonamère (constitué de neuf nucléotides) conservé.
Ainsi, dans le cas d'un réarrangement des gènes V et J, les séquences RSS situées en 3’ (aval) du segment V et en 5’(amont) du segment J sont reconnues par la recombinase.
Seules des associations de RSS dissemblables sont efficacement recombinés, c’est-à-dire un RSS avec une séquence intercalante de 12 nucléotides sera recombinée avec un RSS ayant un intercalant de 23 nucléotides.
Ceci est connu comme la règle 12-23.Les recombinases VDJ sont une collection d’enzymes dont certaines sont spécifiques des lymphocytes, et d’autres sont exprimées dans de nombreux types cellulaires.
Les premières étapes de la recombinaison VDJ sont pris en charge par des enzymes spécifiques des lymphocytes, appelées RAG1 et RAG2.
Ces enzymes s’associent entre elles pour reconnaître les séquences RSS et induire le clivage de l’ADN aux sites RSS.
Cette coupure ne concerne qu’un seul brin d’ADN, ce qui conduit la formation d’une épingle à cheveux.D’autres enzymes VDJ recombinase sont exprimées dans de multiples types cellulaires et sont impliquées dans la réparation de l’ADN suivant l’action des protéines RAG1 et RAG2.Chaque lymphocyte n’exprime individuellement qu’un seul type de récepteur, qui est sélectionné lors de son développement dans la moelle osseuse.Dans les lymphocytes B en développement, la première recombinaison à avoir lieu se fait entre un segment D et un segment J d’un locus de chaîne lourde.
Toute la chaîne d’ADN située entre ces deux segments est éliminée.Cette recombinaison D-J est suivie par la jonction d’un segment V venant d’un locus en amont du gène DJ nouvellement formé.
Cette fois encore, tout le locus situé auparavant entre le segment V et le DJ est éliminé du génome.Lors de la transcription du gène, l’ARN messager contient la région VDJ recombinee de la chaine lourde, ainsi que les segments constants mu et delta (Cμ et Cδ).
Ce premier transcrit subit des modifications post-transcriptionelles classiques (polyadénylation, epissage des introns) et un épissage alternatif conduisant des gènes codant les segments constants.La traduction de cet ARNm produit la chaîne lourde Ig μ.Le récepteur sélectionné lors du développement de la cellule est a priori capable de reconnaître toutes sortes de peptides, qu’il soit du soi ou du non-soi, et présentés par n’importe quelle molécule du complexe majeur d’histocompatibilité (CMH), qu’elle soit du soi ou du non-soi.
Il est donc important de ne retenir que les lymphocytes capables de reconnaître correctement le CMH.
Des cellules spécialisées (cellules stromales pour les B, cellules épithéliales pour les T) présentent aux lymphocytes immatures les molécules du CMH, et sélectionnent suivant sa réaction :Outre cette sélection en fonction de l'affinité au CMH, les lymphocytes doivent subir une autre sélection, en fonction de leur nature :
Les anticorps catalytiques (aussi appelés abzymes) sont des anticorps capables de catalyser une réaction chimique.
Par rapport à une enzyme normale, ils possèdent une meilleure spécificité par rapport au substrat.
Un autre avantage est qu´ils peuvent être produits pour catalyser toute sorte de réactions, comme la réaction de Diels-Alder.
Le nom abzyme a été construit à partir des mots antibody (anticorps en anglais) et enzyme.
Comme toutes les enzymes, ils fonctionnent en stabilisant l´état de transition de la réaction.
En pratique, ils sont développés et sélectionnés à l´aide d´une molécule ressemblant à cet état.
Actuellement, des recherches sont menées dans l´espoir de pouvoir utiliser des abzymes à des fins thérapeutiques.Les anticorps catalytiques furent décrits pour la première fois en 1986 par les équipes de Peter G. Schultz et Richard Lerner.
La biologie médicale (France, Québec, Afrique du Nord et de l'Ouest), biologie clinique (Belgique, Pays-Bas, Autriche, Luxembourg), médecine de laboratoire (Allemagne, Suisse, Roumanie, Pologne, Europe de l'Est), pathologie clinique (Pays anglophones, Italie et Portugal) ou encore analyses cliniques (Espagne) est une spécialité médicale et pharmaceutique qui consiste en l'exécution d'analyses sur les liquides biologiques (ou des extraits/broyats de tissus) et en l'interprétation médicale des résultats dans le but de caractériser l'origine physiopathologique d'une maladie.
C'est une des deux branches de la pathologie avec l'anatomo-pathologie.
Dans certains pays francophones (Canada, Belgique), le terme de biologie médicale se réfère plutôt à la filière universitaire des sciences biomédicales.La biologie médicale contribue à 70 % des diagnostics médicaux à la suite d'examens complémentaires.
Son cœur de métier et donc la diagnostic et le suivie de pathologies.
Les domaines d'investigation sont les suivants :Le constat : la biologie médicale est devenu un élément centrale dans le parcours de soin du patient et la nécessité d'apporter des garantis de qualité des examens médicaux,.Cette réforme s'articule sur trois mesures phares :Chaque état européen conserve une souveraineté étendue dans le domaine médical.
Ainsi, plusieurs modèles de biologie médicale coexistent en Europe.Ce sont ces professionnels ayant suivi une formation post-universitaire appelée résidence ou internat qui ont les fonctions médicales interprétatives au sein des laboratoires médicaux dans la fonction publique ou dans le secteur privé.
Dans les laboratoires privés, ils occupent généralement les fonctions de directeur, ou directeur adjoint.La formation en biologie médicale est très différente d'un pays à l'autre en Europe, notamment pour les non-médecins.
C'est à partir de ce constat que l’European Confederation of Clinical Chemistry and Laboratory Medecine ou EC-4 a été fondée dans le but de créer à terme une plateforme de reconnaissance des diplômes au sein des pays de l'UE.En effet, si la spécialité de « médecine de laboratoire » est relativement homogène d'un pays à l'autre en Europe pour les médecins ce qui permet des équivalences automatiques entre les pays, il n'en est pas de même pour les autres professionnels, pharmaciens et scientifiques,.Certains pays n'ont pas de scientifiques pour la biologie médicale (France, Portugal), d'autres ont des scientifiques mais pas de pharmaciens (Italie, Allemagne), d'autres les deux (Espagne, Belgique).Les scientifiques diplômés en biologie médicale dans l'Union européenne, théoriquement, ne peuvent donc pas exercer la « biologie médicale » en France, contrairement aux pharmaciens de l'UE spécialisés dans la discipline.Cependant, en France, depuis le 31 mai 2008, les professionnels européens non titulaires des diplômes permettant l'exercice de la biologie médicale en France, ont la possibilité d'y exercer la biologie médicale après examen et validation de leur dossier (vérification des diplômes, compétences et expériences) par la Commission nationale permanente de biologie médicale (CNPBM) ce que confirme l'ordonnance portant réforme de la biologie médicale du 15 janvier 2010.Les pays autorisant aux scientifiques l'exercice de la biologie médicale le font en grande majorité dans la discipline de la biochimie clinique.On peut distinguer trois grandes catégories de pays suivant l'importance des différentes spécialités dans la formation "post-grade" des biologistes médicaux :L'EC-4 a rédigé récemment un syllabus pour la formation « post-grade » en Europe qui reprend les objectifs pédagogiques à atteindre pour tout biologiste médical.En avril 2011, le nom de laboratory medicine specialist a été adopté par les principales organisations européennes de biologie médicale pour définir le biologiste médical européen.Microscopes, automates d'analyses médicales, centrifugeuses, etc.Différents types de liquides biologiques peuvent être prélevés.
En fonction de l'examen souhaité, il existe différents types de matériels (aiguilles, flacons, tubes…) à utiliser pour prélever et récupérer le liquide en question afin de l'analyser correctement.L'examen visuel du liquide prélevé est une première indication primordiale.
Il peut donner une première indication sur l'origine du trouble au biologiste ou au clinicien.
L'aspect du liquide conditionne par ailleurs la prise en charge analytique qui suit et la validité des résultats finaux.L'analyse microscopique est une activité importante du biologiste et du laborantin.
Ils ont pour cela recours à de nombreuses colorations différentes (Gram, MGG, Grocott, Ziehl-Neelsen…).L'immunofluorescence, la cytochimie, l'immunocytochimie et la FISH sont également utilisées afin d'approfondir le diagnostic.Cette étape permet d'affirmer le caractère « normal », tumoral, inflammatoire voire infectieux du liquide.
En effet, l'examen microscopique permet souvent d'identifier un agent infectieux causal, le plus souvent une bactérie, un champignon, une levure, ou encore un parasite, plus rarement un virus.Les automates d'analyses médicales, par l'association de la robotique et de la spectrophotométrie, ont permis ces dernières décennies une meilleure reproductibilité des résultats des dosages, notamment en biochimie médicale et en hématologie.Les entreprises du diagnostic in vitro essayent dorénavant de vendre des chaînes d'automates, c'est-à-dire un système permettant le transfert automatique des tubes vers les différents types d'automates de la même marque.
Ces systèmes peuvent inclure la gestion automatisée d'une sérothèque.Ces automates doivent subir des contrôles quotidiens pour garantir un résultat le plus juste possible, on parle de contrôle qualité.
Ces automates doivent également subir des maintenances quotidiennes, hebdomadaires et mensuelles.Une part importante des examens de biologie médicale, essentiellement en microbiologie médicale, utilisent des milieux de culture.Ceux-ci permettent, par exemple, la mise en évidence d'un ou de plusieurs agent(s) infectieux responsable(s) des signes cliniques.Les valeurs de références sont parfois encore appelées "valeurs normales".
Cette dernière appellation est abusive car elle laisse sous-entendre une distribution de la population étudiée selon une loi Normale.
Telle n'est pas la réalité de toutes les valeurs de références.
La grippe aviaire, également connue sous le nom d'influenza aviaire ou anciennement de peste aviaire, provoquée par des souches A du virus grippal, est une maladie infectieuse affectant les oiseaux.
L’infection peut causer toutes sortes de symptômes chez les oiseaux, depuis une maladie bénigne, qui passe souvent inaperçue, jusqu’à une maladie rapidement mortelle qui peut provoquer de graves épidémies.Le terme désigne différentes formes de la maladie causée par le virus de la grippe infectant les oiseaux sauvages et les oiseaux domestiques.
En 2004, une souche H5N1 du virus est mise en avant en raison de son danger et de sa transmissibilité à l'homme.Cette affection est transmissible entre volailles et plus rarement à des mammifères (dont le porc, à la fois réceptif aux virus grippaux aviaires et aux virus grippaux humains), mais elle est habituellement difficilement transmissible et inoffensive à l'homme.
Certaines espèces d'oiseaux, et en particulier certains canards en sont souvent porteurs asymptomatiques.Ce virus a également été dépisté chez un petit nombre d'espèces mammifères, dont les humains, les rats et les souris, les belettes et les furets, les porcs, les chats et les chiens.
Selon les plus récentes données scientifiques, le risque de transmission de l'influenza aviaire d'un mammifère domestique à un humain est très faible, cependant, le gouvernement canadien encourage les propriétaires à prendre des mesures de précaution afin de se protéger et de protéger leurs animaux de compagnie.Les données scientifiques et historiques sont rares avant la fin du XIXe siècle (1880).
Certaines épidémies ont décimé de vastes populations d'oiseaux domestiques, de pigeons ou de volailles.
Dans 3 cas au moins, les chroniqueurs ont noté une mortalité conjointe humaine et animale dès 1200 av.
On ne connaît pas d'importantes pandémies grippales humaines qui auraient touché tous les continents avant celle de 1918.Les descriptions antiques ou médiévales ne permettent donc pas d’identifier la peste aviaire avec certitude.
Les chroniqueurs ont cependant gardé la trace d’épizooties parfois impressionnantes dont l’étude rétrospective peut être utile à la compréhension de l’éco-épidémiologie de la grippe à virus Influenza A, B ou C.Peu d’indices permettent de quantifier le nombre d’oiseaux d’élevage ou sauvages morts ou malades, mais des textes évoquent des hécatombes d’oiseaux sauvages, la disparition des chants des coqs, le silence qui remplaçait les chants des oiseaux, et surtout la puanteur des cadavres.
Ces indices rapportés à quelques reprises, surtout en Europe au XVIIe siècle et plus encore au XVIIIe siècle laissent penser que des quantités très importantes d’oiseaux ont été touchées par ces épizooties.Les chroniqueurs de l'Antiquité en ont conservé la mémoire, pour quelques épisodes marquants de mortalité conjointe humaine, du bétail, et d’oiseaux sur le continent européen : De nombreux chroniqueurs du Moyen Âge, et dès le VIIe siècle, ont rapporté des épisodes de mortalité aviaire massive chez les volailles (ou pigeons, probablement souvent domestiqués ou semi-domestiqués).Concernant les mortalités d’oiseaux sauvages, faute de connaître les modes d'action et de transmission des virus, et peut-être au vu des symptômes hémorragiques ou des œdèmes, les auteurs contemporains de ces mortalités aviaires les ont souvent attribuées à des guerres opposant des oiseaux d’espèces différentes ou d’une même espèce.
Les dates de toutes ces « batailles » ont été relevées par Fleming.Dans ces derniers cas, l’influenza aviaire hautement pathogène peut être suspectée au vu des symptômes et de certaines caractéristiques écoépidémiologiques, en particulier avec des épizooties commençant chez les oies ou les canards dont on sait aujourd’hui qu’ils sont très susceptibles au virus.
Le cygne ne semble pas évoqué, ou peu, mais peut-être ses populations étaient elles déjà décimées par la chasse.
Dans deux cas, les chroniqueurs eux-mêmes notent une concomitance entre épizootie aviaire et épidémie humaine :Dès 2003, certains ont volontiers incriminé les migrations aviaires comme vecteur principal de diffusion de la maladie, mais ceci n'était et ne reste qu'une hypothèse.
En 2003, la FAO écrivait : « Aucune évidence jusqu'ici n'indique que les oiseaux sauvages sont la source des présentes éruptions épizootiques du virus hautement pathogène de la grippe aviaire H5N1.
Les oiseaux sauvages ne doivent pas être éliminés ».
Les faits récents, dont l'épizootie roumaine de début juin 2006 montre l'importance de l'élevage industriel comme facteur de risque quand les mesures de biosécurité ne sont pas respectées.En 2004, une souche H5N1 du virus est mise en avant en raison de son danger et de sa transmissibilité à l'homme.À l'heure actuelle, on n'a observé que des reproductions d'oiseau à homme qui restent rares.
Toutefois l'OMS craint que le virus ne mute, créant ainsi une pandémie hautement mortelle.
Entre 2003 et 2012, 573 cas d'infections humaines par le virus H5N1 ont été relevés, dont près de 60% ont été mortels.
Cependant, une estimation du nombre réel de personnes infectées est délicat et le taux de mortalité fait l'objet de recherches.
Début 2009, ce virus reste actif chez les oiseaux, essentiellement en Asie du Sud-Est, et le risque d'une pandémie est toujours présent.En 2020, 46 départements français présentent un risque « élevé » et doivent prendre des mesures pour protéger les élevages de volailles.
En janvier 2021 en France, malgré une conséquente modernisation des élevages et la mise en place de protocoles sanitaires sévères, à la suite notamment d'une crise similaire ayant eu lieu en 2016 aux graves conséquences économiques, le Sud-Ouest et ses élevages de canards sont une nouvelles fois gravement touchés par une souche de type H5N8 d'une virulence rarement observée, et la maladie se répand à nouveau rapidement malgré l'abattage de centaines de milliers de canards.
Les autorités craignent de devoir recourir à un abattage massif comme 4 ans auparavant, quand 25 millions de canards avaient été abattus, occasionnant 350 millions d'euros de dédommagements.
La Chine a immédiatement cessé les importations de foie gras en provenance de France et le Japon celles en provenance des Landes, où cette nouvelle épidémie s'est d'abord concentrée.
On y dénombrait le 11 janvier 119 foyers de grippe parmi les 127 recensés, soit déjà 2 fois plus qu'une semaine auparavant,.
Les autorités décident de tuer préventivement 2,5 millions de volailles en janvier 2022.Fin octobre 2022, le député du Maine-et-Loire Philippe Bolo (MoDem) est nommé co-rapporteur de la mission d’information sur « la grippe aviaire et son impact sur les élevages ».En novembre 2022 trente-six foyers de la maladie sont recensés  dans des sites d'élevage industriel de volailles français, comme dans la Sarthe ou l'Indre ; des milliers d'animaux sont euthanasiés,.En Angleterre, le confinement des oiseaux domestiques et des volailles est rendu obligatoire à partir du 7 novembre pour lutter contre la propagation du virus.Deux salariés agricoles sont atteints par la maladie en Espagne dans un élevage de volailles en 2022.
Le virus grippal Influenza est classé en fonction du type de deux de ses protéines de surfaces, en 144 combinaisons possibles (16 hémagglutinines × 9 neuraminidases).
Ces 144 sous-types semblent tous pouvoir infecter toutes les espèces d'oiseaux, et actuellement six d'entre eux (H1Nx, H2Nx ou H3Nx, ou HxN1 ou HxN2) ont des caractéristiques leur permettant d'infecter plus facilement l'homme, situation qui peut évoluer si le virus mute.
Chaque sous-type peut se décliner en de nombreux variants, plus ou moins pathogènes.Les symptômes sont peu spécifiques et par exemple proches de ceux de la maladie de Newcastle.
Si l'infection n'est pas totalement asymptomatique, dans le cas d'une influenza « faiblement pathogène », avec des variantes selon la souche virale et le degré de résistance immunitaire des oiseaux infectés, les symptômes sont chez la volaille des comportements généraux modifiés (« frilosité, tassement des oiseaux, dépression, sous-consommation d’aliment et d’eau de boisson, plumage ébouriffé »), des troubles respiratoires (larmoiement, écoulement nasal, sinus infra-orbitaires gonflés, toux, râles plus ou moins sévères, pouvant parfois conduire à une suffocation mortelle).
Les pondeuses voient leur productivité chuter brutalement (de 5-20 % pour les poules, 30- 80 % pour les dindes, et le nombre d’œufs malformés ou décolorés augmente).Les souches FP (faiblement pathogènes) tuent de 2 à 3 % des volailles infectées ; 2 à 3 % des poulets industriels, mais en cas de co-infections bactériennes ou virales jusqu'à plus de 40 % chez les jeunes dindonneaux (de moins de 35 jours) et jusqu’à 20 % chez les dindes reproductrices.Les souches HP (hautement pathogènes) induisent les mêmes symptômes mais beaucoup plus sévères, avec éventuellement pétéchies et hémorragies généralisées à tous les organes, œdèmes de la tête et du cou (visibles) et des poumons (moins visibles).
Si la souche est très contagieuse, ou que les conditions se prêtent à la contagion, jusqu'à 100 % (en 48 à 72 h) d'un cheptel peut alors mourir.
La mort peut aussi être brutale et sans signe clinique l'annonçant.Plus que chez la dinde, on observe parfois aussi chez la pintade des signes neurologiques (torsion du cou, torticolis, paralysie de membres…).
Une forme respiratoire d'influenza correspond à l'infection des ratites.La pathogénicité varie selon les sous-type viraux, les époques et les animaux ou personnes concernées.Au début du XXIe siècle, selon le bilan de l'OMS (au 27 février 2014), les deux grippes aviaires les plus pathogènes et létales pour l'être humain ont été induites par :L'Organisation des Nations unies pour l'alimentation et l'agriculture a publié, en août 2006, une étude présentant les modalités supposées de contamination de la faune sauvage par la grippe aviaire avant la migration des oiseaux :Pour devenir pandémique, le virus est supposé passer (en mutant) par un hôte intermédiaire plus proche de l'homme (cochon par exemple).
Le chat pourrait être un des intermédiaires possibles.
Il semble que dans de rares cas un virus aviaire (autre que H5N1) puisse aussi directement infecter l'homme.Le cas de l'homme contaminé par l'animal est réputé le plus fréquent, tout en restant rare.
Il est apparu par exemple que l'épizootie due au virus H5N1 a, de 2004 à 2007, durement frappé les oiseaux, et surtout des volailles, mais seulement quelques centaines d'humains.
Ces humains avaient dans la plupart des cas été en contact étroit ou prolongé avec des volailles touchées par une épizootie qui évolue en panzootie (fin juillet 2006, 58 pays ou territoires ont notifié des infections d'oiseaux sauvages ou d'élevage par le virus H5N1 sur trois continents).La transmission de la grippe entre animaux est supposée la plus commune entre volailles, oiseaux d’agrément et oiseaux sauvages, et possible dans les deux sens.
Le passage de l’oiseau à d’autres espèces est mal connu, mais on en connaît quelques exemples.Les facteurs de risque immédiat ont été largement surestimés par les pays riches.
Ils pouvaient être liés à la stratégie de détection et de lutte contre une pandémie / manque de vaccin, à une faible réactivité, à une préparation insuffisante, à un manque d'antiviraux et/ou une monothérapie (un seul médicament, pour un virus qui a la réputation de muter facilement) et des facteurs contextuels et de long et moyen terme.L'émergence de la maladie peut être due à des facteurs écologiques, agro-pastoraux, agro-industriels et zootechniques, des facteurs démographiques, des impasses, du phénomène de résurgence de virus anciens, des délais de détection d'un nouveau sous-type de virus de grippe A et de la qualité et pertinence du suivi épidémiologique.L'Organisation mondiale de la santé (OMS) craignait que la grippe aviaire, si elle concernait les humains, puisse d'une panzootie évoluer en pandémie susceptible de tuer jusqu'à 100 millions de personnes parmi plusieurs milliards de malades.
D'autres évaluations envisageaient de 7,4 à 320 millions de morts en un à deux voire trois ans, selon que la morbidité du virus serait semblable à celle des pandémies de 1957 ou 1968 (très faible mortalité), ou comparable à celle de 1918.
(Ces données sont obtenues en multipliant les évaluations de la mortalité due à la grippe espagnole par le facteur correspondant à l'augmentation de la population depuis 88 ans).Pour limiter le problème du manque de vaccin en cas de pandémie, en mai 2007, il a été annoncé que six pays (Brésil, Inde, Indonésie, Mexique, Thaïlande et Viêt Nam), recevraient jusqu'à 2,5 millions de dollars du Japon et des États-Unis (financement immédiat) pour lancer l'industrie de production locale de vaccins.Entre 2005 et 2014, le virus H5N1 a fait l'objet de nombreuses mesures de lutte.
Il n'a finalement pas muté pour s'adapter aux tissus humains ou acquérir une forte contagiosité interhumaine.
Le risque pandémique ne s'est pas exprimé : au 31 décembre 2008, on ne comptait « que » 248 morts, mais en 2014, le virus H5N1 circule encore et fait donc l'objet d'une veille sanitaire, tout comme d'autres virus de l'Influenza A aviaire qui pourraient par recombinaison génétique devenir Hautement pathogène pour l'Homme (ou des animaux d'élevage).Il n'existe que deux types de masques protégeant du virus de la grippe aviaire.
Il s'agit des modèles "filtering face-piece particules" FFP2 et FFP3.
Un masque de protection n'offre une protection efficace que s'il est bien utilisé, notamment au niveau de l'étanchéité par rapport au visage.Normalement, la grippe aviaire ne touche pas l’homme.
Mais il est arrivé que des souches hautement pathogènes provoquent une maladie respiratoire grave chez l’être humain.
Dans la plupart des cas, les personnes contaminées avaient eu des contacts rapprochés avec des volailles infectées ou avec des objets contaminés par leurs déjections.Malgré les recherches et quelques promesses, en 2022, aucun vaccin contre la grippe aviaire pour l’homme n'a été mis au point et commercialisé.
Le vaccin ordinaire contre la grippe saisonnière hivernale ne serait d'aucune efficacité contre le H5N1 directement, mais éviterait les recombinaisons dans le cadre d'une grippe classique opportuniste, ce qui en augmenterait le facteur aggravant, tout en augmentant sa contagiosité.Un vaccin a été mis en place contre l'influenza aviaire H5N1 mais il n'est pas accepté par la population qui l'accuse de donner la maladie.
Dans ces conditions, les seules mesures barrières disponibles sont, dans l'attente d'une nouvelle campagne de prévention, les masques et les médicaments anti-viraux (Tamiflu ou Relenza) qui ne pourraient pas guérir la maladie elle-même, mais pourraient réduire la gravité des symptômes et ralentir la propagation du virus.Habituellement les oiseaux ne sont pas vaccinés,  le respect des recommandations officielles suffisant à contenir la propagation de ce type de virus, dans les élevages, notamment.
Pourtant depuis 2003 des vaccins pour les oiseaux ont été mis au point.
En 2004, une commission d'experts vétérinaires  recommande la vaccination des volailles d'élevage dans les zones concernées par les épidémies, avec "des vaccins inactivés homologues ou hétérologues exclusivement".
En décembre 2005  l'Union européenne approuve "la vaccination des volailles comme mesure de prévention à court terme, voire à long terme", pour l' Italie, la France et les Pays Bas.Avec l'industrialisation, la mondialisation économique des filières et le développement de la chaîne du froid, ces coûts augmentent.
La majorité des cas cliniques concernent des oiseaux d'élevage et surtout la dinde, puis la poule et moindrement d'autres espèces (caille/perdreau, canards, oies, autruche).
Ce sont donc ces filières qui subissent le contrecoup économique, mais également les filières d’abattage, de transports ou de production et fourniture d’aliments des volailles.Trois principaux scénarios sont évoqués pour une mutation permettant une pandémie :À ce jour, aucun de ces scénarios n'a eu lieu.
Ni pandémie ni épidémie comparable à la grippe de 1957 ou celle de 1968 n'ont existé.Si la question de la grippe aviaire a rapidement mobilisé tant d'experts et d'organismes internationaux, dont l'ONU, l'Organisation mondiale de la santé et la FAO, c'est en raison d'une possible « humanisation » du virus H5N1, qui par ailleurs semble aussi dangereux que celui de la grippe de 1918, qui est aujourd'hui le seul auquel on puisse le comparer en termes de virulence.
Il ne lui manque que la capacité d'infecter facilement l'homme.En novembre 2004, Shigeru Omi, directeur régional de l'OMS estimait que les évaluations les plus prudentes font état de sept à dix millions de morts, mais le maximum pourrait être de cinquante millions ou même, dans le pire des scénarios, cent millions.Fin décembre 2004, Klaus Stöhr et un autre expert de l'OMS déclarent En quelques mois, près de 30 millions de personnes auraient besoin d'être hospitalisées, un quart d'entre elles mourraient.Le professeur Didier Houssin, délégué interministériel chargé de la lutte contre cette maladie, déclare le 17 octobre 2005 qu'une pandémie grippale est inéluctable sans pouvoir en prévoir la date.
Un éventuel virus humanisé de la grippe aviaire devra en tout cas être circonscrit en deux à quatre semaines, a rappelé un expert de l'OMS, sinon il serait ensuite impossible à contenir.Le 17 janvier 2006, l'Institut de veille sanitaire  publie dans son bulletin hebdomadaire  qu'une pandémie grippale résultant d'une mutation d'un virus aviaire (H5N1 ou autre) pourrait atteindre entre 15 % et 35 % de la population française et serait responsable d'environ près 600 000 hospitalisations et 118 500 décès sont attendus en l'absence de traitement ou de vaccin.Selon la Banque mondiale, il faudrait mettre en œuvre un budget d'un milliard et demi d'USD comme moyen de contrer la pandémie.
De plus, si une pandémie devait se déclarer dans un pays mal préparé, le risque de réactions violentes est important, motivées par la panique, de la part de la population, notamment en ce qui concerne la distribution des masques et des antiviraux.À titre d'exemple, le Québec a prévu que 1/3 des Québécois soient malades, que 2,6 millions de personnes soient infectées, que 1,4 million de malades nécessitent un médecin avec 34 000 hospitalisations et 8500 morts au maximum.L'Organisation mondiale de la santé, l'FAO et l'OIE recommandent une vaccination des volailles et d'animaux de zoos et de faire suffisamment de stocks d'antiviraux pour pouvoir traiter au moins 25 % de leur population, afin de limiter la propagation du virus de la grippe aviaire au cas où une pandémie se déclencherait.En février 2006, l'UE qui s'est notamment prononcée pour la mise en place d'un périmètre de quarantaine et de surveillance de 10 km autour des foyers suspects ou confirmés de la maladie chez des oiseaux sauvages ou de basse-cour, dans ce dernier cas, les volailles sont tuées dans un rayon de 3 km autour du foyer.
Les vétérinaires européens ont estimé que des « zones-tampons » de la taille d'un département français ou d'une région devront être créées pour enrayer l'épizootie, comme cela a été fait avec succès pour des épizooties précédentes.Le risque d'une persistance du virus et de foyers d'infections est plus grand dans les zones de l’UE où des populations importantes de canards et d'oies domestiques vivent.
C'est le cas dans le delta du Danube où quatre millions de canards et quatre millions d'oies domestiques sont élevées en Roumanie avec des densités comparables à celles de zones asiatiques où le H5N1 est devenu endémique.
Le pourtour de la mer Noire est une zone à risque ainsi 20 millions environ de canards sont élevés rien qu'en Ukraine.Pour la saison 2021-2022, près de 46 millions d’animaux ont été tués dans l'Union européenne pour faire face à la grippe aviaire.Pour faire face à une éventuelle pandémie, la France a prévu le dispositif suivant, financé par la Sécurité sociale :Une population déterminée d'animaux peut également être abattue pour endiguer une épidémie.
Le collectif "Sauve qui poule" est créé en 2017 "par des consommateurs et des éleveurs soucieux de défendre l’élevage de volailles plein-air et le bien-être de leurs animaux", "constitué suite à l'obligation de confiner les volailles".Entre l'automne 2021 et le printemps 2022, plus de 20 millions de volailles sont abattues "dans les élevages infectés ou de manière préventive pour stopper la progression du virus".
Les régions d'élevage, Pays de la Loire et Bretagne, épargnées jusqu'alors, sont particulièrement touchées.En mars 2022, le ministère de l'Agriculture déclare avoir supervisé l'abattage de plus de 10 millions de volailles pour tenter de stopper l'épidémie de grippe aviaire alors localisée dans les Pays-de-la-Loire.
C'est l'épisode le plus sévère qu'a jamais connu le pays.
Les petits élevages en agriculture biologique, généralement épargnés par l'épidémie, dénoncent cet abattage massif obligatoire réalisé sans véritable préparation.
Ils  organisent des manifestations soutenues par la Confédération Paysanne et déplorent que les arrêtés depuis novembre dernier les obligent à élever leurs animaux comme dans les élevages industriels, ce qui à leur yeux est une tromperie  vis à vis des consommateurs.En novembre 2022, alors que depuis l'été plus de 770.000 animaux ont été abattus, le niveau de risque passe de « modéré » à « élevé », impliquant "le confinement automatique des bêtes dans tout le pays".La Confédération paysanne déplore que "la gestion sanitaire se limite une nouvelle fois à la claustration obligatoire généralisée et aux abattages préventifs massifs pour protéger les couvoirs et élevages de reproducteurs" et ne tienne pas compte de la spécificité et de la "résilience face à l’épidémie" de l'élevage en plein air.Le 12 novembre 2016, la Suisse est touchée par la grippe aviaire, en majorité chez les oiseaux.
Le soir même, le journal de 19 h 30 de la (RTS) a interviewé le vétérinaire cantonal du canton de Vaud Giovanni Peduto.
En 2022 la Suisse est à nouveau touchée.
La superfamille des immunoglobulines (IgSF) est une super-famille de protéines ayant en commun une structure tertiaire caractéristique des immunoglobulines.
La structure de ces protéines contient un ou plusieurs domaines dits "de type immunoglobuline" (domaines Ig).
Ces protéines sont impliquées dans les phénomènes d'interaction cellule-cellule et cellule-matrice extracellulaire.Cette famille contient, outre les immunoglobulines, les molécules du complexe majeur d'histocompatibilité, des molécules d'adhésion cellulaire appartenant à la famille des Ig-CAM (en) (telles que les VCAM-1 (en), ICAM-1 ou NCAM (en)), des corécepteurs (telles que les molécules CD4 et CD8 intervenant dans l'activation des lymphocytes T), et certains récepteurs de cytokines.Certaines de ces molécules ont un rôle crucial dans les interactions entre les cellules impliquées dans la réponse immunitaire.
Le complexe majeur d'histocompatibilité de type I et de type II et les anticorps font en effet partie de cette superfamille.
Certains membres de cette famille sont la porte d'entrée de virus tels que le virus du SIDA (récepteur de la molécule CD4) ou celui de la rage.La plupart des membres de cette superfamille ne sont cependant pas des effecteurs du système immunitaire, car ils n'ont pas de partie variable et ne lient pas d'antigène.Les protéines membres de la superfamille des immunoglobines sont des glycoprotéines très souvent membranaires, mais parfois solubles trouvées en solution dans les liquides ou mucus du corps.
Autour de 500 protéines exprimées par le génome humain ont été identifiées.
Une analyse du génome humain a également suggéré que 2% de l'ensemble des gènes coderaient pour des protéines IgSF.Un domaine de type immunoglobuline est constitué d'un repliement de la chaîne polypeptidique d'environ 100 acides aminés de long en 2 couches de feuillets beta antiparallèles qui se font face et qui forment une structure "sandwich-like".
Ce repliement est stabilisé par la présence d'un pont disulfure entre 2 résidus cystéine de la chaîne peptidique espacés de 50 à 70 acide aminés.
Le domaine est généralement représenté sur les schémas de structure de ces protéines par une boucle fermée par le pont disulfure.
Claude Ropartz, né le 29 mai 1929 à Paris et mort le 31 janvier 2000 à Équemauville, est un médecin, qui a été de nombreuses années directeur du Centre départemental de transfusion sanguine de Rouen.Dans ce centre il a travaillé avec son équipe sur la structure, l'allotypie, l'isotypie et l'idiotypie des immunoglobulines.
Appliquant la technique de Grubb et Laurell (découvreurs du système Gm en 1956), il a découvert en 1961 le système Inv, maintenant appelé Km, porté par les chaînes légères Kappa.Il a créé et dirigé un laboratoire de l'INSERM orienté vers la génétique et l'immunologie, ainsi qu'un laboratoire de référence de l'OMS pour les immunoglobulines.
Ont également été étudiés dans ce Centre les allotypes de l'albumine, de l'α1-antitrypsine ou système Pi.À la suite de ses travaux, et de ses nombreuses publications, il fut nommé Professeur de génétique et d'immunologie à l'Université de Rouen.Il a contribué au développement de la transfusion sanguine française, et a créé l’Association pour le Développement de la Transfusion Sanguine (ADTS).
Il a également cosigné un article remarquable avec Salmon, Huguenard e.a., avertissant le monde médical sur certains dangers de la transfusion de sang total.
Dans Le Concours médical n° 14 du 1er avril 1972 (p. 2597-2605) il déclare  que « Chaque transfusion est, sur le plan immunitaire, une greffe rejetée  et même une bombe à retardement dans certains cas ».
En fait, en 1972, cela concernait probablement le problème immunologique des multitransfusés (apparition d'anticorps divers, anti-érythrocytaires, anti-HLA, anti-HPA, anti-allotypes d'immunoglobulines, anti-..., dont on craignait les possibles implications à terme, en cas de transfusion ou greffe) et non pas un problème de transmission virale (voir Affaire du sang contaminé des années 1980).
La phagocytose, en biologie, est le processus cellulaire par lequel certaines cellules regroupées sous la dénomination générale de phagocyte peuvent ingérer des particules étrangères solides d'échelle micrométrique.
On considère habituellement que la phagocytose est une forme particulière d'endocytose.
Elle se distingue d'autres processus d'internalisation cellulaire (endocytose, pinocytose) par au moins deux critères généraux :Élément essentiel de l'immunité, elle a été découverte à la fin du XIXe siècle par Élie Metchnikov (1845-1916), récompensé par le Prix Nobel de physiologie ou médecine en 1908, conjointement avec Paul Ehrlich.
Chez les amibes, elle joue un rôle nutritionnel, en leur permettant de capturer et d'ingérer des bactéries.Bien que la phagocytose ait été observée expérimentalement dans plusieurs types cellulaires, elle est généralement fortement associée avec certaines catégories de leucocytes, tels les macrophages, les cellules dendritiques ou les neutrophiles.
Les conséquences de l'activité phagocytaire sont multiples et importantes.
On peut citer notamment l'élimination des pathogènes, la présentation des antigènes aux lymphocytes, l'élimination des débris cellulaires pro-inflammatoires.
La phagocytose peut également être exploitée en biomédecine, par exemple pour la livraison ciblée de molécules pharmaceutiques ou pour l'immunothérapie antitumorale.On appelle phagocytes toutes cellules étant capables de phagocytose.
Les observations in vitro ont mis en évidence que de nombreux types cellulaires pouvaient, dans certaines conditions, se comporter en phagocytes.
C'est par exemple le cas des fibroblastes, des cellules épithéliales ou des cellules endothéliales.
Toutefois, la phagocytose est principalement le fait de phagocytes dit « professionnels ».
Ce qualificatif leur vient de leur taux de phagocytose nettement plus élevé ainsi que de l'adaptation de leur machinerie moléculaire interne à ce processus d'internalisation.
Ces phagocytes « professionnels » appartiennent à la catégorie des leucocytes.
On distingue en particulier les macrophages, les neutrophiles et les cellules dendritiques.
Les études des bases moléculaires et mécaniques de la phagocytoses concernent principalement les deux premiers.La phagocytose est habituellement représentée dans la littérature comme la formation d'une protrusion membranaire en forme de calice, la coupe phagocytaire, qui se forme au niveau du contact entre phagocyte et cible phagocytaire.
Cependant, les déformations membranaires menant à la phagocytose présentent des morphologies très variées, en fonction de la cible et de la nature des ligands et récepteurs phagocytaires impliqués :Les causes physico-chimiques ainsi que les conséquences fonctionnelles (efficacité, rapidité, etc.) de cette diversité sont encore peu connues.La phagocytose se distingue d'autres modes d'ingestion cellulaire par la nécessité d'un contact entre le phagocyte et sa cible.
Certains cas de phagocytose passive ont été décrits.
Dans ce cas, les propriétés physico-chimique du couple cible/phagocyte (charges électriques, hydrophobie) suffisent à ce que la cible soit passivement englobée.
La plupart des cas concernent en revanche une phagocytose active, où le processus n'est enclenché qu'en aval de l'appariement d'un ou plusieurs récepteurs phagocytaires (portés par le phagocyte) et d'un ou plusieurs ligands (portés par la cible).
Cette phagocytose active a pour conséquence d'introduire la notion de spécificité de la phagocytose.
Parmi les cas de phagocytose active, on distingue ceux où la cible présente déjà les ligands et ceux où les ligands sont fixés sur la cible à la suite de réactions chimiques extérieures, ce qu'on appelle l'opsonisation.
L'exemple d'opsonisation le plus connu est le rôle des anticorps IgG : ce n'est que lorsque les IgG se fixent sur leur cible que les récepteurs FcR à la surface des phagocytes peuvent s'y fixer et initier le processus de phagocytose.Il est habituellement découpé en trois phases : adhésion, ingestion, et digestion - cette dernière étape n'étant pas systématique.La première fonction décrite des macrophages est leur capacité de phagocytose, c'est-à-dire que les cellules phagocytaires sont capables de lier, par l’intermédiaire de molécules ayant une surface particulière, certains composants reconnus à la surface de micro-organismes, de parasites ou de cellules.On sait maintenant que la particule phagocytée est entourée par les pseudopodes de la cellule, formant une nouvelle vacuole intracellulaire, le « phagosome ».
Dépendant du type cellulaire et des conditions de phagocytose, des sources autres que la membrane plasmique peuvent fournir la membrane du phagosome.
Il s'agit des endosomes de recyclage et du réticulum endoplasmique.Les principaux récepteurs macrophagiques impliqués dans les processus de phagocytose sont les récepteurs aux opsonines (récepteurs au complément, à la portion Fc des immunoglobulines), le CD14 et le récepteur mannose-fucose.La liaison d’un micro-organisme ou de toute autre particule à une molécule de surface macrophagique entraîne une cascade signalétique, régulée principalement par des processus de phosphorylation.
Cette signalisation résulte en de profonds remaniements du cytosquelette cellulaire, avec accumulation de F-actine sous la membrane plasmique.Longtemps on a cru que la phagocytose était la seule fonction des phagocytes et que ces cellules avaient une seule mission, celle de servir d'éboueurs des éléments étrangers à notre organisme.
Aujourd'hui, il est devenu clair que les polymorphonucléaires comme les phagocytes sont capables d'exercer bien d'autres fonctions que celle de la phagocytose qui les définit.Ainsi, ces cellules sont capables de synthétiser, de sécréter des métabolites agissant sur d'autres types de cellules, de détruire sans les englober des cellules tumorales, certains parasites, et des cellules normales ou tumorales sensibilisées par des anticorps.C'est l'étape au cours de laquelle la membrane de la cellule phagocytaire adhère à la particule qu'elle va ingérer.
Cette étape se fait grâce aux lectines (glucoses complexes) qui se trouvent à la surface du corps étranger.
Des liaisons se forment entre les glycoprotéines membranaires des cellules immunitaires et les oses du corps étranger.
L'adhésion est aussi facilitée par l'opsonisation des corps étrangers.On a cru longtemps que la phagocytose se produit par invagination (repli) de la membrane autour de la particule et une formation secondaire d'une vacuole de phagocytose ou phagosome.
On sait maintenant que la particule phagocytée est entourée par les pseudopodes de la cellule entre ces pseudopodes, se forme une nouvelle vacuole intracellulaire, le phagosome.
Dépendant du type cellulaire et des conditions de phagocytose, des sources autres que la membrane plasmique peuvent fournir la membrane du phagosome.
Il s'agit des endosomes de recyclage et du réticulum endoplasmique.À l'intérieur de ce phagosome, le devenir de la particule peut être de trois types :La phagocytose s’accompagne le plus souvent d’une brutale élévation de la consommation cellulaire en oxygène.
En effet, la liaison d’une particule exogène à son récepteur membranaire entraîne une activation de la NADPH oxydase, qui transfère des électrons du NADPH à l'oxygène moléculaire.
Les formes actives de l'oxygène formées (H2O2, radicaux OH• et O2) se retrouvent en forte concentration dans le phagosome, où elles exercent des effets toxiques sur les micro-organismes phagocytés.
De plus, certains macrophages sont capables après induction d’une NO synthase de produire des dérivés nitrés, notamment le monoxyde d'azote, par oxydation des noyaux azotés de la L-arginine.
Le monoxyde d’azote, qui est libéré lors de l'infection de macrophages par des bactéries, des levures, des parasites ou des champignons, contribue à l'élimination de ces organismes.Pendant l’étape de digestion, il y a l’activation de lysosomes, constituant ainsi un phagolysosome.
Les divers enzymes vont se déverser et, selon leur spécificité, s'attaquer aux divers constituants de la particule ou du micro-organisme pour la digestion totale.La fonction de phagocytose est partagée par les cellules dendritiques et deux variétés de cellules appartenant à la famille des leucocytes (ou globules blancs) :Les neutrophiles sont les premiers à se rendre sur le lieu de l'inflammation.
Dans les heures qui suivent, ce sont les monocytes qui parviennent au sein du foyer inflammatoire.Ils y subissent une différenciation en macrophages, et vont persister pendant un laps de temps variable selon le site de l'inflammation, mais dans l'ensemble, beaucoup plus longtemps que les neutrophiles.
Contrairement à ces derniers, les monocytes peuvent survivre après l'acte de phagocytose.Dans les cas de persistances par des micro-organismes (bactéries ou virus), il existe la digestion partielle avec présentation des peptides antigéniques par les molécules de classe II du CMH.La multiplication du micro-organisme :Dans tous les cas, le macrophage doit être activé : c'est le rôle de la cellule Th1 qui, par la sécrétion d'interférons, activera le macrophage « embarrassé ».
César Milstein (8 octobre 1927 - 24 mars 2002) est un biochimiste argentin qui passe la plus grande part de sa vie en Grande-Bretagne.
Son champ majeur de recherche concerne les anticorps, il reçoit le prix Nobel de physiologie ou médecine en 1984.Milstein naît à Bahía Blanca en Argentine.
Il obtient sa licence à l'université de Buenos Aires et obtient son doctorat à l'école de médecine avec une thèse sur la cinématique d'une enzyme, l'aldéhyde dehydrogénase.
En 1958 le British Council lui procure les fonds pour pouvoir rejoindre le département de biochimie de l'université de Cambridge pour travailler sur le mécanisme d'activation de la phosphoglucomutase.
Durant ce travail il collabore avec Frederick Sanger dont il rejoint l'équipe.Milstein tourne son attention de l'enzymologie à l'immunologie et commence des recherches sur les anticorps, leurs structures et les mécanismes qui leur permettent d'être très diversifiés.
En 1975, avec Georges Köhler, il développe la technique des hybridomes pour la production d'anticorps monoclonaux qui lui vaut le prix Nobel de physiologie ou médecine en 1984.
Cette découverte permet une extension de l'exploitation des anticorps en science et en médecine.Il fait plusieurs contributions majeures en technologie des anticorps, se focalisant sur l'utilisation des anticorps monoclonaux pour fournir des marqueurs permettant de distinguer différentes types de cellules.
Il prévoit aussi le potentiel de l'abondance des ligands réactifs qui peuvent résulter de l'application de la technologie de l'ADN recombinant aux anticorps monoclonaux et inspire ainsi le développement de l'ingénierie des anticorps.En dehors de son prix Nobel, Milstein reçoit de nombreuses récompenses, entre autres, le prix Wolf en 1980, le prix Gairdner en 1981 la médaille royale en 1982, le Prix Albert-Lasker pour la recherche médicale fondamentale en 1984, la médaille Copley en 1989 etc.Milstein meurt le 24 mars 2002 à Cambridge à l'âge de 74 ans de la suite de problèmes cardiaques.
Un poulet est une jeune volaille, mâle ou femelle, de la sous-espèce Gallus gallus domesticus, élevée pour sa chair.
S'il s'agit du même animal, les conditions de production des poulets de chair diffèrent de celles des poules pondeuses qui sont élevées pour leurs œufs.
Par exemple le rythme de croissance des poules pondeuses est bien moins important que celui des poulets de chair.En France l'élevage de poulets est majoritairement intensif, c'est-à-dire que les animaux sont élevés en grand nombre dans des bâtiments fermés pendant 35 jours en moyenne.La sélection des reproducteurs et le développement de nouveaux types d'alimentation permettent d'accélérer la croissance des oiseaux afin de produire beaucoup de muscles, ce qui n'est pas sans risque pour la santé des animaux.Un poulet mâle est un coquelet, un poulet femelle est une poulette.
Un jeune coq châtré pour que sa chair soit plus tendre est un chapon, une poulette à qui on a donné une nourriture riche pour retarder la ponte pour le même motif est une poularde.Les parties suivantes sont distinguées dans la découpe du poulet :Le poulet se cuisine de multiples façons :La viande de poulet contient, en pourcentage de masse, deux à trois fois plus de graisses polyinsaturées que la plupart des viandes rouges.La viande de poulet contient en général peu de graisses (excepté la viande de chapon).
La graisse est essentiellement concentrée dans la peau du poulet.
Une portion de 100 g de poulet cuit contient :En comparaison, une même portion de bifteck de bœuf contient 10 g de gras et 27 g de protéines.Les poulets sont de tous les animaux terrestres les plus nombreux à être élevés pour la consommation alimentaire.
En 2016, ont été élevés et abattus : 66 milliards de poulets dans le monde, 7,4 milliards de poulets au sein de l’Union européenne, 800 millions de poulets en France.
23 milliards de poulets vivent à tout moment sur Terre, soit 10 fois plus que n'importe quelle autre espèce d'oiseaux et 40 fois plus que le nombre de moineaux.
La chercheuse Carys Bennett indique que « la masse totale des poulets domestiques est trois fois supérieure à celle de toutes les espèces d'oiseaux sauvages réunies ».En France, l'élevage de poulets est majoritairement intensif puisqu'en 2020, 64% des poulets de chair sont élevés d'après ce mode de production.
Aucun label n'est donc assigné à ce produit (Certifié, Label Rouge, bio...).Dans ce type d'élevage, les oiseaux sont détenus à 22 par mètre carré en moyenne dans de grands bâtiments fermés.
Contrairement à certains élevages de poules pondeuses, en France, les poulets de chair ne sont pas élevés en cage.
La grande promiscuité entre les animaux est une grande source d'inconfort et de stress pour les oiseaux.
Les densités élevées tout comme la présence de litière souvent sale et humide (cette dernière est rarement changée entre l'arrivée des poussins dans l'élevage et leur départ à l'abattoir un mois plus tard) sont favorables à la propagation des maladies.
L'élevage intensif est ainsi l'un des responsables de la survenue d'épidémies de type grippe aviaire.Les poulets d'élevage intensifs sont issus de souches à croissance rapide, souches sélectionnés génétiquement pour donner des individus qui grandissent et grossissent rapidement.
Cette croissance est de plus en plus rapide au fil des siècles puisque les oiseaux atteignent en 2014 leur poids d’abattage en 35 jours, soit 4 fois plus rapidement qu’en 1950.
Cette croissance rapide est susceptible d'entrainer des problèmes locomoteurs et respiratoires chez les oiseaux.Plus de 30 % des poulets meurent en élevage du fait de ces conditions de production.
Afin de limiter le taux de mortalité et d'augmenter la productivité des oiseaux, des antibiotiques sont souvent distribués en permanence dans la nourriture des poulets.L'élevage des poulets est réglementé au niveau européen par la Directive européenne de protection des poulets de chair.
Entré en vigueur en 2010, ce texte est régulièrement décrié par les associations de protection animale comme insuffisamment protecteur pour assurer aux animaux des conditions d'élevage sans souffrances.En 2020, en France, la répartition de la production de poulets de chair selon leur type d'élevage est : Cependant, la proportion des types d'élevage change au fil des années.Dans les élevages Label Rouge et "bio", les poulets ont accès à un parcours extérieur une partie de leur vie.
Les animaux sont issus de souches à croissance médium ou lente.
Ils sont envoyés à l'abattoir à l'âge de 81 jours en moyenne.À noter qu'après une période d'engraissement à l'extérieur, les oiseaux élevés sous le cahier des charges poulets de Bresse sont « finis » en épinettes, c'est-à-dire qu'ils sont enfermés dans des cages individuelles et nourris aux céréales pendant 10 jours minimum avant de partir à l'abattoir.Afin d'être amenés à l'abattoir, les poulets sont ramassés à la main ou à la machine, le plus souvent par des sociétés spécialisées.
Cette étape  est souvent une source de stress et de souffrance importante pour les animaux déjà fragilisés par leurs conditions d'élevage et la sélection génétique.Le temps de transport des animaux est réglementé par le règlement Européen CE 1/2005 qui autorise les trajets de 12 heures consécutives sans accès à l'eau (et ne limite pas la durée de transport si les oiseaux ont de l'eau et de la nourriture dans les caisses).
Le cahier des charges Label rouge est l'un des rares à imposer une durée maximum de transport de deux heures entre l'élevage et l'abattoir.La méthode d'abattage la plus répandue en France est l'électronarcose.
Les oiseaux sont sortis des caisses de transport et accrochés conscients par les pattes sur un rail métallique.
La tête à l'envers, ils sont alors plongés dans un bain d'eau électrique, étape visant à les rendre inconscients avant la saignée.
L'autorité européenne de sécurité des aliments (EFSA) déconseille fortement cette méthode d'abattage du fait des souffrances importantes qu'elles occasionne pour les poulets.
L’INRA avait déjà pointé du doigt en 2009 les souffrances liées à cette méthode (fractures, luxations, hémorragies) qui demeure pourtant majoritaire en France.En France, la consommation de poulet a augmenté de près de 40 % entre 2005 et 2015, pour atteindre 18,8 kg par an et par habitant en 2017.
Il s'agit d'une des rares consommation de viande qui ne diminue pas.L'élevage intensif de poulets a des impacts sur la santé humaine.
Ainsi, la présence importante d'antibiotiques en élevage standard de poulets est accusée de favoriser le phénomène d'antibiorésistance.
L'impact environnemental est également important : pour produire 1 kg de poulet, 6 000 litres d'eau sont nécessaires.Selon certains chercheurs, les fossiles de poulets de batterie pourraient permettre d'aider à dater l'Anthropocène.
Bertrand Bed'hom, spécialiste de la génétique du poulet et chercheur à l'Institut National de Recherche Agronomique, estime quant à lui que le plastique, la pollution ou le réchauffement climatique sont de meilleurs marqueurs.
Un domaine protéique est une partie d'une protéine capable d'adopter une structure de manière autonome ou partiellement autonome du reste de la molécule.
C'est un élément modulaire de la structure des protéines qui peuvent ainsi être composées de l'assemblage de plusieurs de ces domaines.
On parle alors de protéine multidomaines.Les domaines protéiques forment en général une structure compacte et stable, et peuvent parfois être produits de manière indépendante (par génie génétique, coupure protéolytique...).
Ils peuvent être porteurs de certaines fonctions spécifiques de la protéine complète : liaison de ligands, interaction avec d'autres macromolécules, site catalytique...
Un domaine protéique donné est en général caractérisé par sa structure tridimensionnelle et par un certain nombre d'acides aminés conservés dans sa structure primaire.
Un même domaine protéique peut être présent dans différentes protéines (voir figure) de fonctions variées.
Cette organisation modulaire des protéines en domaines est un des leviers de l'évolution moléculaire qui permet de les utiliser de manière combinée comme briques de base pour construire une grande variété de protéines.La définition d'un domaine protéique s'articule ainsi autour de trois concepts : unité de base de structure, unité de base de fonction, unité de base de repliement.La taille typique d'un domaine protéique varie entre 30 et 500 acides aminés, avec une moyenne autour d'une centaine d'acides aminés.L'existence d'intermédiaires dans le repliement de chacun des monomères de protéines a été démontrée par Michel Goldberg en 1969, qui a désigné sous le nom de « globules » ces régions de chaînes polypeptidiques se repliant de façon autonome, autour de centres de nucléations indépendants, avant l'élaboration de la structure tertiaire complète de la protéine.
En 1973, un modèle similaire fut proposé par Donald B. Wetlaufer sous le nom de « domaine », terme qui fut finalement retenu.Il existe une grande diversité de domaines protéiques, mais néanmoins plus limitée que celle des protéines entières.
Certaines estimations avancent le chiffre de quelques milliers seulement de structures possibles pour un domaine globulaire.
On peut reconnaitre des éléments récurrents dans l'architecture de ces domaines, ce qui a permis d'en faire une classification.Certains domaines sont très fréquents et présents dans de très nombreuses protéines.
Le motif de reconnaissance de l'ARN ou domaine RRM a ainsi été trouvé dans les séquences de pas moins de 928 protéines codées dans le génome humain.
Un complexe immun (ou complexe antigène-anticorps) résulte de la combinaison d'un épitope (ou déterminant antigénique) immunogène avec un anticorps dirigé spécifiquement contre cet épitope.
Cette réaction est la première étape de l'immunité humorale.
Après cette réaction, le complexe peut être ingéré par des phagocytes ou transformé par des protéases.Il existe des cas pathologiques où les complexes immuns peuvent causer des maladies par eux-mêmes, lorsqu'ils se déposent dans des organes, par exemple dans certaines formes de vascularites.
Il s'agit d'une forme d'hypersensibilité de type III dans la classification de Gell et Coombs.Lors de l'intrusion d'un agent infectieux dans l'organisme, des cellules immunitaires, les plasmocytes formés par les lymphocyte B, sécrètent des anticorps en réponse à l'infection.
Les différents anticorps se diffusent alors dans l’organisme à la recherche de l'agent infectieux.
Lorsqu'un anticorps spécifique à l'antigène rencontre celui-ci, il se fixe sur ses récepteurs membranaires.
Une fois cette fixation effectuée, le complexe immun est formé.Le complexe immun est un des mécanismes de défense du système immunitaire.
On le qualifie de mécanisme inné : il fait partie de la réponse immunitaire primaire.
En effet, lors d’une infection, il y a d’abord une réponse immunitaire primaire que l’on qualifie d'innée.
Cette première barrière est assurée par les monocytes et phagocytes.
Le complexe immun, quant à lui, facilite ces mécanismes par sa spécificité à un seul antigène.
Une fois que l’antigène a été reconnu par son anticorps grâce à ses chaînes légères spécifique, il va y avoir mise en marche du complexe immun : l’association anticorps-antigène va se fixer à un phagocyte.
Ce phagocyte aura alors la capacité de digérer le couple anticorps-antigène et de l’éliminer.
Ce processus s’appelle la phagocytose et s’effectue en quatre grandes étapes : Il faut savoir que lorsque ce mécanisme n’arrive pas à éliminer la totalité des agents infectieux, la deuxième barrière se met en marche, que l’on qualifie de spécifique.
Cette dernière est plus longue la réponse innée.
Elle est effectuée par les Lymphocytes B, les Lymphocytes T et les Lymphocytes T cytotoxiques.Les complexes immuns peuvent causer des maladies par eux-mêmes, en particulier les complexes immuns que l’on qualifie de circulant.
Naturellement on constate l'apparition de complexes immuns circulants due à des réactions immunitaires.
Ce n'est que l'amplification de ce phénomène normal qui aboutit à certaines pathologies.
En effet, physiologiquement les complexes immuns circulants interceptent les compléments qui correspondent à des variétés d'enzymes qui participent aux mécanismes immunitaires de l'organisme contre les antigènes.
Dès cet instant le complexe antigène anticorps c'est-à-dire l'agrégation des deux, après avoir circulé à l'intérieur du sang, est éliminé grâce à l'intervention des composants contenus dans les organes lymphoïdes (système réticulohistiocytaire) c'est-à-dire les cellules possédant la capacité d'éliminer les déchets dans le sang.
Cependant en réalité le phénomène est un peu différent et le complexe immun peut se retrouver dans trois situations différentes c'est-à-dire évoluer de manière différente dans l’organisme ce qui peut avoir des conséquences variables.
Voici les trois cas possibles : Cette destruction se fait soit par précipitation (solidification et neutralisation) soit par phagocytose (absorption puis digestion par une variété particulière de globules blancs, le phagocyte).
Il faut savoir que les complexes immuns peuvent également être liés à un processus auto-immun, c'est-à-dire que le patient induit des réactions immunitaires contre ses propres tissus.
Les maladies auto-immunes liées à l'apparition de complexes immuns circulant font appel avant tout à la plasmaphérèse (épuration plasmatique).
L'idiotype, du grec « particulier, forme », est une caractéristique retrouvée chez de rares individus d'une même espèce.Cette notion a été développée, par Jacques Oudin (biologiste) en particulier, lors de l'étude des spécificités antigéniques des immunoglobulines.Un idiotype est une conformation caractéristique de la partie variable de l'immunoglobuline, partie variable dite Fab (fragment antigen binding) permettant la reconnaissance spécifique d'un antigène.L'idiotype est donc caractéristique de l'immunoglobuline produite par le clone cellulaire de plasmocytes développé à la suite d'une stimulation antigénique.
« Souris » est un nom du vocabulaire courant qui peut désigner toutes sortes de mammifères rongeurs ayant généralement une petite taille, un museau pointu, des oreilles rondes, un pelage gris-brun et une queue relativement longue.
Autrement dit, ce terme ne correspond pas à un niveau précis de la classification scientifique des espèces.
Il s'agit d'un nom vernaculaire dont le sens est ambigu en biologie, car il est applicable seulement à une partie des espèces classées dans l'ordre des Rodentia.
Toutefois, en disant « souris » les francophones font le plus souvent référence à la souris grise (Mus musculus), une espèce commune des maisons, élevée également comme animal de compagnie ou de laboratoire.
La souris chicote, elle, émet un cri ressemblant à un petit crissement.
Par analogie, le terme « souris » est souvent repris pour désigner d'autres petits rongeurs, principalement des Muridés, famille qui comprend aussi les campagnols et mulots, et de nombreux rats.
En revanche, mis à part de vagues similitudes d’apparence, les chauves-souris forment un groupe de mammifères bien différent : l'ordre des Chiroptères.Souris vient du français médiéval : souriz (1175) puis souri (1200).À partir du XVIe siècle sont distinguées les « souris terrestres » (1562), des sortes de musaraignes, les « blanches souris » (1576), la « souris de terre » (1753-67) ou « petit mulot », la « souris de montagne » (1768) ou « lemming », les « souris d'eau » (1812), ainsi que divers autres animaux parfois très éloignés de la souris commune.Le mot souris est mentionné dès la première édition du Dictionnaire de l'Académie française (1694), qui n'évoque apparemment que la souris commune et en donne comme définition : « Petit animal à quatre pieds, qui se retire dans les trous des maisons, et qui ronge… »Pourtant, dans la seconde moitié du XVIIIe siècle, L'Encyclopédie ou Dictionnaire raisonné des sciences, des arts et des métiers de Diderot et d’Alembert définit le « rat » comme étant l'espèce Mus domesticus, c'est-à-dire l'actuelle souris domestique.Le Dictionnaire de la langue française d'Émile Littré, publié à partir de 1863, en donne une définition analogue.
À partir de l'édition de 1832, la définition donnée par le Dictionnaire de L'Académie française évolue, indique en plus qu'il s'agit d'un représentant de la famille des rongeurs et précise qu'il s'agit d'un animal « plus petit » que le rat.Le Trésor de la Langue Française (1971-1994) en donne une définition beaucoup plus étendue, mentionnant les Muridés et plus spécialement la souris domestique (Mus musculus) et sa variante albinos, la souris blanche.
Ce dictionnaire indique aussi que le terme s'étend à des espèces voisines de la souris domestique, présentes sur les cinq continents, mais également à certains marsupiaux ou à quelques chauve-souris.Une jeune souris est appelée un souriceau.
Un piège à souris, est appelé une souricière.Les souris proprement dites appartiennent au genre Mus.
Dans le langage courant, le terme désigne plus particulièrement la Souris domestique (Mus musculus).
L'espèce de souris la plus récemment découverte l'a été en 2004 à Chypre.
Son origine daterait d'environ 0,5–1 Ma, résultant d'une « colonisation ancienne de l'île ou d'un transport accidentel par les premiers arrivants épipaléolithiques.
Dans ce dernier cas, la nouvelle espèce devrait aussi exister quelque part en Asie Mineure ».Par extension ou confusion, on appelle aussi communément « souris » un certain nombre d'espèces de rongeurs de la sous-famille des Murinés (souris, rats et mulots de l'« ancien monde ») et, plus largement, de la famille des Muridés, laquelle comprend aussi les campagnols, les lemmings, les rats, les rats musqués, les hamsters, les gerbilles, etc., voire du sous-ordre des Myomorphes — souris sauteuses, souris à poche, et quelques autres espèces comme la souris du désert (Selevinia betpakdalaensis),.Les caractéristiques générales des souris sont celles des petits mammifères rongeurs, avec des nuances pour chaque espèce : voir les articles détaillés pour plus d'informations sur leur comportement ou leur physiologie respective.Les souris jouent un rôle important dans les écosystèmes :La plupart des rongeurs sont susceptibles d'être réservoir et/ou vecteurs de nombreux pathogènes et parasites (externes ou internes), dont certains peuvent être transmis à l'Homme (ex.
: maladie de Lyme, transmise par des tiques, mais dont le réservoir principal semble être, en Amérique du Nord, la souris à pattes blanches).Certaines espèces de souris sont commensales de l'homme ou pénètrent occasionnellement dans les habitations, entrepôts, poulaillers, etc.
Elles peuvent transmettre diverses maladies par leur urine et leurs excréments, par morsure, par des fomites ou encore via les tiques, puces ou poux qu'elles véhiculent.Dans la nature, ce sont les prédateurs carnivores qui sont leurs régulateurs, ou occasionnellement des épidémies, des incendies de forêts, des inondations, etc.Dans l'environnement humain (maisons, villes, entrepôts), elles font l'objet d'une lutte par les chats, pièges, poison souricide, entreprise de dératisation, mais les souris sont aussi utilisées comme animal de laboratoire (parfois génétiquement modifiées depuis quelques années en biothérapie).Le tableau triable suivant présente une synthèse non exhaustive des noms vernaculaires attestés en français et des noms scientifiques correspondants.
Il faut noter que certaines espèces ont plusieurs noms possibles.
En gras est indiquée l'espèce la plus connue des francophones.
Les classifications évoluant encore, certains noms scientifiques peuvent avoir un autre synonyme valide :Et aussi :Le genre Akodon, regroupe un certain nombre d'espèces de « souris » d'Amérique du Sud parfois appelées souris champêtres que les anglo-saxons nomment souvent : grass mice (souris d'herbe) ou South American field mice (souris des champs).Au Canada, on appelle communément « souris » treize espèces de rongeurs présents sur le territoire canadien et appartenant au sous-ordre des Myomorphes.Les deux plus petites espèces sont la souris des moissons occidentale et la souris à abajoues flavescente (maximum 13 cm avec la queue).
La plus grande espèce est la souris sauteuse de l'Ouest qui peut atteindre 25 cm avec sa queue.
À la différence de la majorité des souris qui se nourrissent de graines, la souris à sauterelles se nourrit d'insectes.La souris commune a été introduite dans le Nouveau Monde par les premiers colons.Source : Petits mammifères terrestres (Soricidés et Muridés) du Complexe d’Aires Protégées de Gamba, Gabon : composition taxinomique et comparaison de méthodes d’échantillonnage.Carrie O’Brien, William McShea, Sylvain Guimondou, Patrick Barriere et Michael Carleton.Remarque : certaines de ces « souris » peuvent avoir d'autres noms vernaculaires dans d'autres régions d'Afrique.La souris est utilisée par l'homme comme animal de laboratoire, animal de compagnie ou comme nourriture pour d'autres animaux de compagnie et dans les zoos.
Il s'agit dans ce cas le plus souvent de la Souris domestique (Mus musculus) et de sa variété d'élevage, la « souris blanche ».En Égypte ancienne, la graisse de souris était utilisée en médecine et le rongeur lui-même pouvait être ingéré dans le cadre d'un rituel magique, par l'enfant et éventuellement sa mère ou nourrice, afin de le guérir d'une affection de la bouche.
La finalité de ce rituel s'est perdue au cours du temps et l'ingestion de la souris a été interprétée par Dioscoride comme un médicament destiné à empêcher le nourrisson de trop baver.
Les réminiscences de cette pratique se rencontraient au début du XXe siècle en Angleterre et au pays de Galles.Les souris ont certainement été utilisées par l'homme comme source de protéines depuis la nuit des temps.
Au XXIe siècle l'habitude de consommer des souris subsiste encore chez certaines peuplades.
Par exemple chez les peuples des provinces rurales de l'est de la Zambie.
Pour eux, les souris sont un plat recherché et elles sont traditionnellement chassées par les enfants.
Capturer les souris leur permet à la fois de limiter les dégâts qu'elles causent aux récoltes et d'obtenir une viande bon marché dans une région où l'élevage est rare et la viande chère à cause des ravages causés par la mouche tsé-tsé.
Les Tumbuka consomment 14 sortes de « souris » après les avoir vidées, bouillies, salées puis séchées.
Elles sont réservées aux invités, aux ancêtres ou aux fêtes familiales.
Cependant la colonisation par les Européens et les influences modernes tendent à ravaler progressivement cette nourriture au rang de plat méprisé.Les souris, au sens large, et plus particulièrement la souris grise de maisons (Mus musculus), jouent un grand rôle dans l’imaginaire populaire ou enfantin et dans le domaine culturel : croyances, proverbes et citations, poèmes et chansons, livres de toutes natures, bandes dessinées, films, dessins animés en très grand nombre mais aussi dans les arts plastiques.La souris est parfois source de musophobie (phobie des souris et des rats), probablement en raison du souvenir historique du rôle néfaste des Murinae propagateurs des maladies épidémiques.
Une maladie auto-immune est consécutive à une anomalie du système immunitaire conduisant ce dernier à s'attaquer aux composants normaux de l'organisme (le « soi », d'où la racine auto- pour parler de ce trouble de l'immunité).Parmi ces maladies peuvent être citées la sclérose en plaques, le diabète de type 1 — jadis appelé « diabète juvénile » ou « diabète insulino-dépendant » —, le lupus, les thyroïdites auto-immunes, la polyarthrite rhumatoïde, le syndrome de Goujerot-Sjögren, la maladie de Crohn, etc.
On distingue classiquement les maladies auto-immunes spécifiques d'organes, qui touchent un organe en particulier (comme par exemple les maladies auto-immunes de la thyroïde), et les maladies auto-immunes systémiques, telles que le lupus, qui peuvent toucher plusieurs organes.
Au début du XXIe siècle en Occident, les maladies auto-immunes sont devenues la 3e cause de mortalité/morbidité après le cancer puis les maladies cardiovasculaires et à peu près dans les mêmes proportions.Le système immunitaire est un ensemble de cellules et voies métaboliques conduisant à l'élimination d'une grande variété de pathogènes.
Ce système repose sur la notion très centrale du soi opposé au non-soi ainsi qu'au soi modifié.
Cette distinction s'effectue grâce à des marqueurs chimiques du soi (c'est-à-dire la reconnaissance de motifs antigéniques plus ou moins spécifiques) mais elle n'est pas véritablement innée : les cellules immunitaires naïves sont d'abord sensibilisées et sélectionnées en fonction de leur réactivité vis-à-vis de ces marqueurs du soi,.
Cela explique notamment le fait que les individus chimériques n'expriment pas forcément « plus » d'auto-immunité que des individus monozygotes.Il existe donc chez tous les vertébrés une auto-immunité latente, laquelle est en temps normal inhibée par les mécanismes de régulation de la maturation des cellules immunitaires.On connaît ou suspecte diverses causes possibles :Dans les pays industrialisés, les maladies auto-immunes touchent environ 8 % de la population, dont 78 % de femmes.
Une forte prévalence de maladies auto-immunes (lupus érythémateux disséminé (SLE pour les anglophones) est constatée, sclérose en plaques (SEP),, cirrhose biliaire primitive, polyarthrite rhumatoïde (PR), et thyroïdite de Hashimoto notamment) chez les femmes.
L'évolution de nombreuses maladies auto-immunes, leur gravité et leur pronostic varie aussi selon le sexe.
Ceci n'est pas encore clairement expliqué, bien qu'il ait été prouvé que les taux d'hormones sont liés à la gravité de certaines maladies auto-immunes dont la sclérose en plaques.Chez les humains, et dans le modèle animal, le système hormonal semble avoir une importance majeure dans plusieurs phénomènes liés à ces maladies ; par exemple, les maladies auto-immunes sont plus fréquentes chez les personnes ayant une dysthyroïdie que dans la population générale, ce qui peut laisser supposer des mécanismes physiopathologiques communs et « justifie une surveillance des patients ayant une dysthyroïdie auto-immune et la réalisation d'un bilan initial et d'un suivi thyroïdien régulier chez les patients ayant une maladie auto-immune »,.En laboratoire chez le modèle murin, les femelles sont également plus touchées que les mâles par des maladies telles que le lupus érythémateux disséminé spontané (souris de souches (NZB×NZW)F1 et NZM.2328), l'encéphalomyélite allergique expérimentale (EAE, pour Experimental autoimmune encephalomyelitis) chez la souris SJL, la thyroïdite, le syndrome de Sjögren chez les souris de souche MRL/Mp-lpr/lpr, et pour le diabète chez les souris NOD.
Les hormones sexuelles et/ou le patrimoine génétique hérité lié au sexe semblent donc être responsables de la sensibilité accrue des femmes à ces maladies auto-immunes.Chez l’animal, certains œstrogènes, la progestérone et les androgènes préviennent ou atténuent les signes cliniques des maladies auto-immunes alors que la castration chez le mâle les aggrave.Du fait de leurs propriétés immunologiques, promyélinisantes, neurotrophiques et neuroprotectrices des œstrogènes, progestatifs et androgènes, une régulation hormonale pourrait peut-être moduler l'évolution de maladies telles que la sclérose en plaques (qui est plus rare et plus tardive chez l'homme que chez la femme, mais plus grave).
Chez les femmes, le rythme des poussées de cette maladie diminue en fin de grossesse, puis progresse après l'accouchement, alors que les sécrétions hormonales chutent.
D'autres maladies auto-immunes semblent pouvoir répondre à une médication de type hormonal.
L'influence de perturbateurs endocriniens pourrait possiblement être l'un des facteurs explicatifs de la récurrence croissante de certaines maladies auto-immunes.D'autre part — de manière générale — les femmes ont une réponse immunitaire différente que celle des hommes,, ; elles répondent notamment à l'infection, à une vaccination ou à des traumatismes avec une production plus importante d'anticorps et une production accrue de lymphocytes T auxiliaires Th2 (réponse immunitaire humorale prédominante), alors qu'une réponse par les lymphocytes T auxiliaires Th1 et l'inflammation sont généralement plus sévères chez les hommes.
Cette différence d'intensité et de qualité de réponse immunitaire semble au moins en partie responsable de la plus grande vulnérabilité des femmes à un nombre important de maladies auto-immunes.
À l'importance du sexe sur la réponse immunitaire s'ajoutent parfois les additionnels de l'importance du sexe sur les organes cibles de ces maladies auto-immunes, telles que le CNS dans la MS (Cerghet et al.
2007).Chez les deux sexes, les maladies auto-immunes commencent par une phase aiguë associée à une réponse immunitaire inflammatoire pour évoluer vers une phase chronique associée à la fibrose, mais des différences marquées existent selon le sexe :Le sexe du sujet est donc un facteur à considérer comme particulièrement important dans les études sur l'auto-immunité, concernant les processus physiopathologiques du système immunitaire et des organes-cibles concernés.Les auto-anticorps sont des anticorps (Ac) dirigés contre des éléments de l'organisme qui les a fabriqués ; leur nombre est élevé.Certains de ces auto-anticorps sont plus fréquemment retrouvés dans certaines maladies appelées maladie auto-immune.Ces maladies sont :Les maladies suspectées d'être des maladies auto-immunes sont :À ce jour, il n'existe pas de traitement curatif.
Il existe plusieurs traitements « suspensifs », qui limitent l'expression des symptômes mais qui ont leurs limites en raison de leur toxicité pour le système immunitaire et certaines cellules.De nouveaux traitements sont envisagés pour bloquer l'effecteur même.
Ce sont souvent les mêmes médicaments que ceux utilisés pour éviter les rejets de greffe d'organes.Les principales molécules utilisées visent à supprimer l'activation de cellules à problème et/ou à les tuer ; ce sont ;La recherche vise à utiliser des anticorps ciblant mieux leurs cibles (lymphocytes T et/ou B), ce qui permettrait de traiter certaines maladies auto-immunes avec moins de toxicité pour le patient.Les effets iatrogènes (secondaires) liés à la toxicité des médicaments sont un problème majeur du traitement des maladies auto-immunes, car ils sont par exemple source d'hypertension, de risque de cancer (si traitement au long-cours) ; l'immunosuppression facilite les infections virales, moindre production de cellules sanguines, neurotoxicité.4 approches se dessinent au début du XXIe siècle :
La dénomination commune internationale (DCI) d'une substance active pharmacologique est un nom non commercial (c'est-à-dire distinct de tout nom de produit commercial) défini par l'Organisation mondiale de la santé, conçu pour être utilisable sans ambiguïté dans un grand nombre de langues.
Le système des DCI existe depuis 1953 (il avait été précédé par une première tentative réunissant les États-Unis, le Royaume-uni, les pays nordiques et la France en 1945).Par rapport à la nomenclature de l'Union internationale de chimie pure et appliquée (UICPA), ces dénominations présentent l'avantage d'être plus courtes et plus simples à mémoriser, des segments clés (affixes) permettant de grouper les substances par familles thérapeutiques (de différentes classes pharmacologiques).
Les emballages de médicaments portent souvent le nom de la substance active sous forme de DCI en dessous du nom commercial.
Cependant, il peut arriver que le nom de substance inscrit ne soit pas la DCI mais une dénomination commune (DC) nationale (British Approved Name (BAN) ou United States Adopted Name (USAN)), laquelle varie d'un pays à l'autre.
Les DC, comme les DCI, diffèrent des noms exacts donnés en chimie.La directive 92/27/CEE recommande  l’usage des DCI pour l’ensemble des pays de l’Union européenne.
Depuis le 5 juin 2002, les médecins généralistes sont tenus de rédiger 25 % des lignes de leurs prescriptions en dénomination commune internationale (DCI) .Il est obligatoire depuis le 1er janvier 2015 pour les logiciels de prescription médicale et lors de toute prescription d'une spécialité pharmaceutique pour tout prescripteur de mentionner ses principes actifs désignés par leur dénomination commune internationale (DCI) recommandée par l'Organisation mondiale de la santé ou, à défaut, leur dénomination dans la pharmacopée.
La cytométrie en flux (CMF) est une technique de caractérisation individuelle, quantitative et qualitative, de particules en suspension dans un liquide.
Un appareil fait défiler des particules, molécules ou cellules, à grande vitesse dans le faisceau d'un laser.
La lumière issue, par diffusion ou fluorescence, du cytomètre permet de compter et de classer la population étudiée suivant plusieurs critères.
Il s'agit d'analyser les signaux optiques ou physiques émis par une particule coupant le faisceau lumineux d’un laser ou d’une lampe à arc.
Les signaux mesurés sont essentiellement relatifs :Ces signaux séparés par des filtres optiques sont collectés par des photomultiplicateurs (PMT), amplifiés, numérisés, traités et stockés par un ordinateur par l'intermédiaire d'une composante informatique et optique (miroir dichroïque et filtre optique).Ce procédé d’analyse individuelle (cellule par cellule) est multiparamétrique et peut s’effectuer à la vitesse de plusieurs milliers d’événements par seconde.
L’ordinateur calcule les données statistiques associées aux distributions des paramètres mesurés et les représente sous la forme d’histogrammes (un paramètre) ou de cytogrammes (deux paramètres) sur une ou plusieurs populations dont les propriétés cellulaires sont ainsi évaluées.La fonction tri des cytomètres en flux les plus évolués permet de trier physiquement une ou deux populations cellulaires définies par leurs propriétés optiques.Les premiers cytomètres en flux ont été inventés dans les années 1950.C'est un des domaines d'intérêt de l'analyse biologique et plus largement de l'évaluation environnementale.On espère pouvoir un jour assurer ainsi un monitoring automatisé de la qualité de l'eau, et de ses variations par le suivi de bioindicateurs.Les signaux optiques recueillis ont une intensité corrélée avec les propriétés particulaires.La lumière diffusée renseigne sur la morphologie et la structure de la particule.
Si la diffusion de la lumière est mesurée dans l’axe du rayon incident, l’intensité du signal peut être corrélée avec la taille et la viabilité cellulaire.Sous un angle de 90°, la mesure correspond à la structure intracellulaire de la cellule (réfringence du cytoplasme, granulosité, morphologie, rapport nucléo-cytoplasmique).L’utilisation simultanée de ces deux paramètres permet de distinguer, dans un sang périphérique par exemple, les plaquettes, les lymphocytes, les monocytes et les polynucléaires.Cette mesure évolue proportionnellement au diamètre de la cellule (supposée sphérique) et à l’indice d’absorption des constituants cellulaires.Cette fluorescence peut être spontanée, mais le plus souvent, elle est apportée à la cellule par un fluorochrome.
Le fluorochrome absorbe l’énergie du laser et réémet l’énergie absorbée sous forme de photons d’une longueur d’onde plus élevée :L'hématologie a été l’une des premières disciplines médicales à bénéficier des applications cliniques de la cytométrie en flux.
Certaines de ces applications sont maintenant utilisées régulièrement pour le diagnostic ou le suivi thérapeutique de différentes affections, notamment les hémopathies malignes.
Ces applications concernent aussi bien l’étude fonctionnelle de cellules saines que la mise en évidence du caractère pathologique des cellules analysées.
Bien que l'étude porte généralement sur les leucocytes, certaines affections plaquettaires (thrombopathies) ou encore des globules rouges ont un diagnostic pouvant être précisé par l'usage de la cytométrie en flux.En cancérologie, la détection de la cellule pathologique est l’application la plus développée.
Cette détection repose essentiellement sur la mesure d’un contenu anormal d’ADN dans le noyau de la cellule tumorale.L'immunologie utilise la CMF pour la détection ou l'identification des sous-types des cellules impliquées dans l'immunité.
Le cycle cellulaire représente l’intégralité de la période de division, c’est-à-dire l’ensemble des événements biochimiques et morphologiques qui sont responsables de la prolifération cellulaire.La CMF offre une méthodologie rapide et simple à mettre en œuvre pour l’analyse du cycle cellulaire.
Elle permet de suivre la distribution des cellules dans les différentes phases du cycle en fonction de divers stimulus ou de l’ajout de certaines drogues.
Elle permet aussi de voir la présence de cellules avec des contenus anormaux d’ADN.De nombreuses études en pharmacologie font aussi appel à des techniques de CMF : mise au point ou étude de drogues antimitotiques, immunothérapie.En océanologie, la cytométrie en flux est devenue une méthode de routine pour compter les différentes populations du picoplancton photosynthétique sur la base de la fluorescence des pigments tel que la chlorophylle.
Après marquage des échantillons avec des marqueurs de l'ADN tels que le SYBR-Green, on peut aussi énumérer bactéries et virus.D'autres recherches font appel à la CMF : l’analyse des chromosomes, la physiologie végétale (ploïdie, contenu en ADN, pour la sélection des plantes les plus résistantes), etc.
Le système immunitaire adaptatif comprend les lymphocytes T, qui contribuent à l'immunité à médiation cellulaire, et les lymphocytes B, qui sont responsables de l'immunité à médiation humorale.
Ces deux populations cellulaires ont des propriétés et des fonctions distinctes des cellules du système immunitaire inné.Il existe deux caractéristiques majeures propres à l'immunité adaptative :Le système immunitaire adaptatif permet de construire au cours de la vie une immunité acquise qui, avec le système immunitaire inné, constitue le phénotype immunitaire des individus.Apparu chez les poissons cartilagineux il y a 500 millions d'années, le système immunitaire adaptatif n’existe que chez les agnathes (vertébrés dépourvus de mâchoires) et les gnathostomes (vertébrés à mâchoires).L'immunité adaptative est activée à la suite de la reconnaissance d'agents infectieux par le système immunitaire inné.
Bien que l'immunité innée permette de reconnaître des familles de pathogènes grâce à des récepteurs spécifiques dont il existe plusieurs types correspondant à plusieurs classes de pathogènes, elle ne peut pas reconnaître une espèce particulière : par exemple, elle peut reconnaître les bactéries Gram négatives, mais elle ne peut pas distinguer quelle espèce de Gram négative provoque l'infection.L'immunité adaptative est spécifique pour une espèce donnée et a un mécanisme de mémoire.
Le système immunitaire adaptatif permet d'amplifier la réponse immunitaire et confère à la fois une réponse spécifique à l'antigène, et donc particulièrement adaptée à l'agent infectieux, et une réponse mémoire permettant une élimination plus efficace du même agent infectieux si l'organisme y est de nouveau confronté.
Les cellules de l'immunité adaptative constituent ainsi un complément essentiel de la réponse immunitaire innée.Spécificité et mémoire sont les deux caractéristiques principales du système immunitaire adaptatif.Une autre caractéristique importante de l'immunité adaptative est la nécessité de mettre en jeu un nombre important de cellules spécifiques pour combattre un agent pathogène spécifique.
Cette multiplication spécifique est l'expansion clonale.
Elle nécessite plusieurs jours, ce qui explique que les effets de l’immunité adaptative n'apparaissent qu'au bout d'environ sept jours.Au début du XXe siècle, les biologistes pensaient que, au vu du nombre très important de pathogènes possibles, il n'était pas possible pour l'organisme de produire, à l'avance, des récepteurs pour tous les antigènes pathogènes.
Les biologistes pensaient que la pénétration d'un microbe entraînait une production par l'organisme de récepteurs capables de reconnaître le microbe, puis que dans un second temps ces récepteurs nouvellement synthétisés signalaient la présence d'un microbe aux lymphocytes qui produisaient enfin des anticorps.
Cette théorie était nommée la théorie interventionniste.
Cette théorie est fausse.L'organisme produit à l'avance des récepteurs pour tous les microbes présents et à venir.
Si cette production dépendait du génome présent dans les lymphocytes, la taille du génome lymphocytaire contenant moins de 25 000 gènes serait insuffisante.
Il faudrait des millions de gènes pour stocker autant d'information.L'organisme peut fabriquer des milliards de récepteurs grâce à un mécanisme nommé la recombinaison somatique qui se produit dans l'ADN des lymphocytes B et T se trouvant dans les ganglions.
La production des récepteurs des lymphocytes B et T s’accompagne de modifications de l'ADN de ces lymphocytes.Le répertoire immunitaire est l'ensemble formé par les lymphocytes B et T ayant un récepteur membranaire spécifique pour un pathogène.
Seule une partie du répertoire des lymphocytes peut reconnaître un antigène donné, par conséquent seule une partie du répertoire des lymphocytes est activée par un antigène donné dans un contexte infectieux.Les immunoglobulines sont des structures protéiques dont il existe deux formes : les immunoglobulines membranaires au niveau des lymphocytes B naïfs qui vont recevoir l’antigène du pathogène et les immunoglobulines solubles qui sont sécrétées dans le plasma par les plasmocytes (cellules dérivant des lymphocytes B).
Les immunoglobulines solubles sont nommées anticorps et vont se fixer sur le pathogène.L'immunoglobuline est formée de deux chaînes protéiques : la chaîne lourde et la chaîne légère.
Il existe cinq classes, parfois nommées isotypes, d'immunoglobulines désignées par une lettre de l'alphabet (cette lettre de l’alphabet est en fait la première lettre du nom de la lettre grecque donnée par les biologistes à chaque chaîne lourde) : immunoglobuline A, immunoglobuline D, immunoglobuline E, immunoglobuline G, immunoglobuline M.Les immunoglobulines membranaires se fixent au niveau des lymphocytes B naïfs par une petite zone : la zone d'ancrage membranaire (B Cell Receptor).
La portion verticale d'une immunoglobuline, constituée uniquement de chaîne lourde, est nommée domaine Fc.
Le domaine Fc détermine la fonction de l'immunoglobuline : c'est par exemple sur cette partie que se fixent les protéines du système de complément et les cellules ayant une action phagocytaire comme les récepteurs Fc d'un macrophage (Fc Receptor).
C'est sur l’extrémité des portions variables que sont reconnus les antigènes du pathogène.L’immunoglobuline se divise en deux régions : la région constante (en violet sur le schéma) identique pour toutes les immunoglobulines de la même classe et une région variable (en vert sur le schéma).
La synthèse (formation) de la partie variable est un processus complexe car elle comporte une région hypervariable (à l’extrémité de la région variable) nommée CDR (Complementary Determining Regions) où se fixe l’antigène.Un antigène est toute molécule reconnue par les lymphocytes B ou T par l'intermédiaire des immunoglobulines sécrétoires et/ou membranaires.
Les parties de l'antigène qui sont reconnues par un anticorps sont appelées épitopes et la partie de l'anticorps reconnaissant l'épitope est appelée paratope.
La plupart des antigènes comportent plusieurs épitopes.La plupart des molécules, protéines, glycoprotéines, polysaccharides, lipoprotéine, lipopolysacharide, acides nucléique peuvent être des antigènes.
C'est même le cas pour des substances chimiques comme les métaux lourds ou les narcotiques.Les auto antigènes sont des antigènes qui font partie de son propre corps : ce sont les antigènes du soi.Les antigènes qui n'appartiennent pas à son propre corps sont les antigènes du non soi dont il existe deux catégories :L'immunogénicité est la capacité d'un antigène à produire une réponse par le système adaptatif.
Certains antigènes ne produisent pas de réponse immunitaire.
On nomme haptène un antigène de faible masse moléculaire qui a besoin d'un porteur pour provoquer une réponse immunitaire du système adaptatif.Pour que la réponse immunitaire adaptative reconnaisse, élimine, et se « rappelle » les multiples antigènes exprimés par les multiples agents infectieux rencontrés au cours de l'existence, le système immunitaire doit pouvoir reconnaître un très grand nombre d'antigènes différents.
Un être humain est à priori capable de produire près de mille milliards d'anticorps différents.La multitude des récepteurs antigéniques est produite par un processus appelé sélection clonale.
Selon la théorie de la sélection clonale, à la naissance, un animal génère de façon aléatoire une immense diversité de lymphocytes dont chacun exprime un récepteur antigénique unique à partir d'un nombre limité de gènes.
Afin de générer des récepteurs antigéniques uniques, ces gènes sont soumis au processus de recombinaison somatique, durant lequel chaque segment de gène se recombine avec l'autre pour former un gène unique.
Le produit de ce gène donne ainsi un récepteur antigénique ou un anticorps unique pour chaque lymphocyte, avant même que l'organisme soit confronté à un agent infectieux, et prépare l'organisme à reconnaître un nombre quasiment illimité d'antigènes différents.Il existe cinq classes ou isotypes d'immunoglobulines.
Cette classification dépend de la zone constante de l'immunoglobuline (violet).L'immunoglobuline D n’existe que sous forme membranaire.
Il n’existe pas d'immunoglobulines D solubles (dans le sang).L'immunoglobuline M présente une forme sécrétée différente de la forme membranaire.
L'immunoglobuline M soluble est formée de cinq immunoglobulines M, ou pentamères.
Chaque pentamère a donc dix sites de reconnaissance antigénique, ce qui rend cette immunoglobuline particulièrement efficace pour la reconnaissance des antigènes pathogènes.Les immunoglobulines D et les immunoglobulines M sont les immunoglobulines retrouvées à la surface des lymphocytes B naïfs.L'immunoglobuline A dans sa forme soluble est un dimère.
La liaison reliant les deux immunoglobulines se nomme la chaîne J.
C'est l'anticorps le plus présent dans les muqueuses respiratoires, digestives et génitales.Les immunoglobulines E et G sont sécrétées sous forme de monomères.L'avidité des anticorps est une notion très importante.
L’avidité est la capacité (force de liaison) d'un anticorps à se fixer sur un antigène.L’avidité de l'anticorps dépend de deux facteurs :L'avidité des immunoglobulines G est très utilisée pour déterminer la datation d'une infection virale (rubéole, varicelle, etc.) ou parasitaire (toxoplasmose) chez la femme enceinte.
Une avidité forte signale une infection ancienne.
On élimine ainsi l'hypothèse d'une infection en début de grossesse en situant l'infection avant la grossesse.
L'apparition d'une avidité forte des immunoglobulines varie en fonction de l'infection.
Par exemple, pour les anticorps toxoplasmiques, l'avidité devient forte 4 mois après l'infection.
Une avidité forte des anticorps toxoplasmiques chez une femme enceinte de 10 semaines (2,5 mois) suspectée d'infection toxoplasmique en début de grossesse indique que cette infection a eu lieu avant la grossesse.Rappelons que les lymphocytes B sont responsables de l'immunité humorale par production d'anticorps.
Cette immunité s'attaque surtout au microbe extracellulaire ou avant que celui-ci pénètre dans la cellule comme les virus.Le BCR est le récepteur situé à la surface des lymphocytes B naïfs (avant toute stimulation par un microbe).
Le site de fixation de l’antigène est une immunoglobuline membranaire fixée par une petite zone : la zone d'ancrage membranaire (B Cell Receptor).
Cette zone ne pénètre pas dans la cellule.
Le BCR est incapable à lui seul de signaler à la cellule qu'un microbe s'est fixé sur lui.
Les immunoglobulines des BCR des lymphocytes B naïfs sont des immunoglobulines M et D.L'immunoglobuline membranaire a besoin d'un corécepteur pour signaler la présence d'un microbe : le CD79.
Il est formé de deux chaînes : alpha et bêta.
À l'intérieur de la cellule, le CD79 possède une zone nommée ITAM (motif d'activation des récepteurs immuns basé sur la tyrosine ou (Immunoreceptor Tyrosine-based Activation Motif) qui permet de signaler la présence d'un microbe par phosphorisation,,.Rappelons que les lymphocytes T sont responsables de l'immunité cellulaire.
Cette immunité s'attaque surtout au microbe intracellulaire.Le TCR est composé de deux parties :Une organisation particulière des gènes au niveau des chromosomes et un processus particulier nommé recombinaison somatique permettent la formation d'un répertoire immense de récepteurs.
La recombinaison somatique est un processus qui permet de joindre différents gènes localisés sur un chromosome.
Cette recombinaison est sous le contrôle de deux enzymes : les recombinases RAG1 et RAG2.La question de l'immunologie adaptative est de savoir comment les immunoglobulines et les lymphocytes T n'attaquent par les antigènes de la personne qui les produit.
Les mécanismes éliminant les cellules pouvant attaquer la personne qui les fabrique se font au cours de la maturation.La maturation des cellules B se produit dans la moelle osseuse.
La cellule souche donne un lymphocyte B selon des étapes bien définies :Ce processus de formation du répertoire des lymphocytes B par élimination est appelé sélection négative.La formation des récepteurs nécessite aussi un contrôle allélique, c'est-à-dire que les gènes impliqués dans la formation des chaînes lourdes et légères soient toujours d'origine maternelle ou paternelle.La maturation des cellules T se produit dans le thymus.
Elle obéit aux mêmes règles que celles du lymphocyte B pour la formation du récepteur des lymphocytes T.
La seule exception est que dans cette maturation, à côté de la sélection négative, il existe une sélection positive.
Cette sélection consiste à faire reconnaître par l'organisme les lymphocytes T réagissant à la présentation d'un peptide présenté par un MHCLe récepteur TCR se doit de reconnaître à la fois le peptide présenté par le MHC et le type de MHC : le type I pour les MHC que possèdent toutes les cellules de l'organisme et le type II qui existe seulement dans les macrophages, les lymphocytes B et les cellules dendritiques.
Cette reconnaissance du type de MHC se fait grâce à des corécepteurs présents à la surface des lymphocytes T, le corécepteur CD4 pour les MHC de type II, le corécepteur CD8 pour les MHC de type I.
La maturation des cellules T au niveau du thymus est régie par l'expression des corécepteurs CD4 et CD8 au niveau des lymphocytes T : les cellules n'exprimant ni CD4 ni CD8 sont nommées doubles négatives CD4− CD8−.
Les cellules exprimant CD4 et CD8 sont nommées doubles positives CD4 CD8 :Le processus de sélection aboutit à des lymphocytes T matures.La sélection négative détruit les cellules réagissant aux cellules du moi.La sélection positive assure que le lymphocyte T reconnaît un peptide présenté par une cellule dendritique :Il faut souligner que cette sélection se fait avec les peptides du soi, c'est pourquoi la sélection se fait sur la faible attractivité.Les organes lymphoïdes se divisent en organes lymphoïdes primaires et secondaires.Les organes lymphoïdes primaires comprennent la partie rouge de la moelle osseuse et le thymus.
La moelle osseuse est le siège de l'hématopoïèse chez l'adulte et de la génération des lymphocytes B. Les lymphocytes se multiplient, se différencient et maturent dans le thymus.
Dans la partie rouge de la moelle osseuse se trouvent les cellules souches hématopoïétiques ainsi que les souches des lymphocytes B et T.Les cellules souches se différencient en lymphocytes B, se multiplient, produisent le récepteur BCR, subissent la sélection négative et rejoignent la circulation sanguine.
Les cellules souches produisent aussi des progéniteurs des lymphocytes T qui vont se diriger immédiatement dans la circulation sanguine pour rejoindre le thymus où la maturation va se poursuivre.Le thymus comprend deux zones : la zone corticale et la zone médullaire.
Les progéniteurs des lymphocytes T prennent le nom de thymocytes quand ils pénètrent dans le thymus.
Dans la zone corticale, le thymocyte est d'abord doublement négatif, ne produisant ni le CD4 ni le CD8, puis le TCR est produit par réarrangement successif de gène TCRTK et du gène TCR alpha et le thymocyte devient CD4 positif et CD8 négatif.
La sélection positive TCR arrive ensuite, sélectionnant les thymocytes capables de reconnaître un MHC du soi.
Les thymocytes qui reconnaissent avec une faible affinité les MHC classe I deviennent positifs TCD8.
Les thymocytes qui reconnaissent avec une faible affinité les MHC classe II deviennent positifs TCD4.
Ce processus s'accompagne d'un nombre très important de déchets correspondant aux thymocytes pour lesquels le TCR est incapable de reconnaître un MHC du soi : ceux-ci meurent par négligence en l'absence d'un signal de survie.
Les thymocytes qui reconnaissent trop fortement un peptide sont également éliminés : c'est la sélection négative.A la fin du processus de maturation, les thymocytes sont libérés dans la circulation sanguine et deviennent des lymphocytes T.Les organes lymphoïdes secondaires sont les ganglions lymphatiques, la rate et les tissus lymphoïdes associés aux muqueuses.Le ganglion lymphatique comporte trois zones : la zone corticale pour les lymphocytes B, la zone paracorticale pour les lymphocytes T et les cellules dendritiques et la zone médullaire où se trouvent les plasmocytes secrétant les immunoglobulines.Le ganglion lymphatique bénéficie d'une double irrigation, une irrigation sanguine et une irrigation lymphatique par les vaisseaux lymphatiques.
Cette irrigation lymphatique permet aux cellules dendritiques de voyager du lieu de l'infection vers le ganglion pour présenter l’antigène.
Les lymphocytes B et T sont apportés par le sang.
Ils migrent dans le stroma lymphatique au niveau des veinules à endothélium épais (High Epithelium Venules ou HEV) qui se trouvent principalement dans la zone corticale.Les lymphocytes T et les cellules se trouvant dans la zone corticale, la présentation de l’antigène peut commencer.C'est la pulpe blanche de la rate qui est l’organe lymphoïde secondaire.
La pulpe blanche entoure les artérioles terminales de l'artère splénique formant l'enveloppe lymphoïde péri artériolaire (Peri Arterial Lymphatique Sheaths) où se trouvent des lymphocytes B.Comment le système immunitaire peut-il reconnaître un agent pathogène alors que le répertoire des lymphocytes comporte des milliards de cellules B et T porteuses d'un récepteur antigénique adéquat capable de reconnaître un antigène pathogène venant de pénétrer dans l'organisme ?
La réponse est que le système immunitaire a développé un mécanisme permettant de capter et de présenter l’antigène aux lymphocytes.La cellule dendritique est la cellule du système immunitaire spécialisée dans la présentation d’antigène,.
Elle prépare l’antigène et le présente aux récepteurs d’antigène des lymphocytes T et B. Il existe plusieurs types cellulaires pouvant présenter l’antigène mais les cellules dendritiques sont les seules à pouvoir initier la réponse des lymphocytes T.
Les cellules dendritiques sont présentes dans la peau, les muqueuses bronchiques, intestinales et de l'appareil urogénital.
Elles sont aussi présentes dans les ganglions lymphatiques pour les pathogènes ayant réussi à échapper aux cellules dendritiques périphériques et dans la rate pour les pathogènes pénétrant directement dans le sang,.La cellule dendritique existe sous deux formes : la forme immature et la forme mature.La forme immature réside dans les tissus périphériques et la rate.
Ces celules ont une capacité élevée de captation d'un antigène.
Elles portent plusieurs récepteurs à leur surface :La cellule dendritique devient mature lorsqu'elle capture l’antigène et migre dans le ganglion lymphatique.
Elle a une capacité élevée à présenter l’antigène et à activer des lymphocytes T mais elle perd sa capacité de captation de pathogènes (perte des FcR pour capter les immunoglobulines et des récepteurs du complément).
Ses récepteurs de surface changent :La cellule dendritique, en plus de la fonction de présentation de l'antigène, a une fonction costimulatrice par les récepteurs de pattern.Les cellules B et les cellules T ne reconnaissent pas les antigènes (microbes) de la même façon :Il existe deux modes de reconnaissance de l’antigène par les cellules B : le mode TD ou thymus-dépendant ou le mode TI ou thymus-indépendant.
Le mode TD nécessite une cellule T porteuse du corécepteur CD4 (lymphocyte T helper; ou T CD4+).
Le mode TI ne nécessite pas de T CD4+.Le mode TD est l'activation de la cellule B par une cellule CD4+ ayant été activée par le même antigène : la plupart des antigènes activant le mode TD sont des protéines.Le T CD4+ doit donc être stimulé par une cellule dendritique qui aura transmis un épitope (partie de l'antigène) de l'antigène au récepteur de la cellule T CD4+.L’antigène entier se fixe sur le récepteur de la cellule B, déclenchant un premier signal.Le T CD4+ va déclencher un deuxième signal en présentant l'épitope fixé sur son récepteur au CMH de type II du lymphocyte B. Cette présentation nécessite l'interaction du ligand CD40 du T CD4+ avec le CD40 de la cellule B,Le mode thymo-dépendant permet une réponse spécifique avec la production d'immunoglobulines G, A et E et la mémorisation de l'infection par le système immunitaire.Le mode TI est un mode qui ne nécessite pas de CD4+ et aboutit à la production d'immunoglobuline M durant quelques jours.
Ce mode est un mode peu spécifique contre un pathogène et sans mémorisation.
C'est un processus primitif de lutte contre l'infection.Ce mode nécessite la stimulation simultanée des récepteurs de la cellule B  et des récepteurs de pattern présent sur les cellules B.Ce mode nécessite uniquement la stimulation simultanée des récepteurs de la cellule B. Les antigènes sont dans des grosses molécules présentant des épitopes répétés.Le T CD4+ reconnaît des polypeptides de 10 à 30 acides aminés présentés par le MCH de classe II de la cellule dendritique.
Le T CD8+ reconnaît des polypeptides de 8 à 10 acides aminés présentés par le MCH de classe I présent sur toutes les cellules du corps humain à l'exception des cellules anuclées (hématie, plaquette).
Les peptides présentés par la cellule dendritique sont le résultat de la destruction du pathogène par la cellule dendritique.Le mode de reconnaissance de l’antigène diffère selon qu'il s'agit d'une reconnaissance par une cellule T naïve ou par une cellule T à mémoire.En immunologie, les cellules présentatrices de l’antigène (Antigen Processing Cell ou APC) sont les macrophages, la cellule dendritique et la cellule B. Ces trois cellules sont nommées APC professionnelles.
Mais la cellule dendritique est la seule capable d'activer in vivo les cellules T naïves.La cellule T naïve nécessite la présentation d'un peptide par la cellule dendritique sur le MHC de type II et un cosignalisateur CD80/86 sur la cellule dendritique reconnu par un corécepteur CD28 de la cellule T.Si la cellule présente le peptide à la cellule T sans activation par le corécepteur CD80/86, cela conduit à une inactivation de la cellule T appelée anergie.
C'est une forme de tolérance car l'absence du corécepteur signale l'absence de danger.
Cette tolérance est appelée tolérance périphérique si elle se situe dans les tissus périphériques ou tolérance centrale si elle se situe dans la moëlle osseuse ou le thymus.La cellule T mémoire nécessite uniquement la présentation d'un peptide par la cellule dendritique sur le MHC de type II sans cosignalisateur.La présentation de l'antigène se fait en deux étapes : la préparation de l’antigène et sa présentation.Le MHC est la molécule principale de présentation de l'antigène, mais il existe d’autres molécules pouvant présenter des antigènes, notamment la molécule CD1, qui ne présente que des antigènes lipidiques et des glycolipides.
Les cellules se fixant sur les CD1 sont certains TCD8, les lymphocytes NK et les lymphocytes T ayant des récepteurs gamma delta.La préparation de l'antigène est le clivage de l’antigène en plusieurs peptides.La présentation de l’antigène est la synthèse des molécules MHC par la cellule infectée, la capture des peptides viraux par le MHC et la migration du MHC à la surface de la cellule infectée ou de la cellule présentatrice d’antigène.La MHC de classe I est formé d'une chaîne alpha et d'une microglobuline.
La MHC de classe II est formé de deux chaînes alpha.La synthèse des MHC est sous la dépendance d'un locus 6p21,31 présent sur le chromosome 6 d’environ quatre millions de bases nommé locus HLA (Human Leucocyte Antigen).
Il existe plus de 220 gènes identifiés sur ce locus dont 40 pour la synthèse des MHC.Le locus HLA est divisé en 3 parties : les classes I, II et III.
La partie HLA I code la chaîne alpha des MHC de classe I.
La partie HLA II code les chaînes alpha et beta des MHC de classe II.
La synthèse des MHC est codominante, c'est-à-dire que les deux allèles des gènes participent à la formation des MHC : l’allèle maternel et l'allèle paternel.Les molécules MHC sont polymorphiques, contrairement aux autres protéines du corps humains.
Ce polymorphisme explique pourquoi certains individus résistent mieux aux infections en ayant des MHC plus performants pour présenter des peptides viraux : ainsi les individus porteurs du locus HLA B 2757 résisteront mieux au virus du SIDA car ils ont une meilleure capacité à présenter les antigènes de ce virus.Il existe trois voies de présentation de l'antigène :Les cellules du système immunitaire adaptatif sont les lymphocytes, dont les deux principaux types sont les lymphocytes T et les lymphocytes B. Le corps humain contient près de mille milliards de lymphocytes (10¹²) qui sont présents majoritairement dans le sang mais également dans la lymphe, les organes lymphoïdes et les tissus.Chez l'adulte, les organes lymphoïdes secondaires contiennent des lymphocytes T et des lymphocytes B pouvant être dans au moins trois stades de différenciation :Les cellules T sont au cœur de la réponse immunitaire adaptative.
Les cellules T assurent trois fonctions dans la lutte contre les infections :Les lymphocytes T auxiliaires, ou lymphocytes T CD4, jouent un rôle important dans l'établissement et le maintien de la réponse immunitaire adaptative.
Ces cellules n'ont ni capacité cytotoxique ni capacité de phagocytose et ne peuvent pas directement tuer des cellules cibles ou éliminer des agents infectieux, mais elles jouent un rôle essentiel dans l'orchestration de la réponse immunitaire.
Les lymphocytes T auxiliaires possèdent un récepteur antigénique qui reconnaît des peptides présentés par le CMH de classe II exprimé par les cellules présentatrices d'antigène professionnelles.
Les lymphocytes T auxiliaires activés relarguent des cytokines qui influencent l'activité de nombreux types cellulaires, y compris les cellules présentatrices d'antigène.
Les lymphocytes T auxiliaires peuvent activer d'autres cellules comme les lymphocytes T cytotoxiques ou les lymphocytes B.L'activation du lymphocyte T se fait par la formation de la synapse immunologique entraînant l'activation avec une phase de prolifération nommée expansion clonale par l'action de l'interleukine 2.
La prolifération s'accompagne d'une différenciation en lymphocytes cytotoxiques T CD8 et en cellules T à mémoire.L'activation des cellules T nécessite deux évènements : la reconnaissance de l’antigène par le récepteur de la cellule T (TCR) et une costimulation.
Le contact initial entre la cellule dendritique et la cellule T se produit avec des molécules d'adhésion cellulaire.
Après la reconnaissance du peptide montré par le MHC de classe II par le récepteur du lymphocyte T, un corécepteur va se former.
La synapse immunologique comprend :Un superantigène est une protéine virale qui se fixe simultanément sur le récepteur du lymphocyte T et sur le récepteur MHC, entraînant une libération brutale et massive de cytokines et une expansion clonale de cellules T incompétentes.Il existe deux classes de molécules costimulatrices :En l'absence de costimulation, la cellule T n'a pas d'expansion clonale.
La cellule T est incapable de lutter contre l'infection.
La costimulation est un mécanisme qui assure que la cellule T ne s'active que pour des pathogènes.Les molécules d'adhésion permettent à la cellule dendritique de rester suffisamment longtemps pour transmettre les signaux de reconnaissance de peptide et de danger au lymphocyte T.
Les molécules d'adhésion se trouvent sur les cellules T avec les ligands sur la cellule dendritique.Les molécules d'adhésion appartiennent à la famille des protéines hétérodimériques nommée intégrine, par exemple la protéine LFA-1 (Leucocyte Function Associated Antigen 1) qui se fixe avec une protéine ICAM 1 (Intracellular Adhesion Molecule 1) de la cellule dendritique.L'activation du T CD8 par une infection peut se faire de deux façons : soit la cellule dendritique est elle-même infectée (par un virus par exemple) ; dans ce cas la cellule dendritique va stimuler directement le T CD8 en lui présentant les peptides viraux via les MHC de type II aux récepteurs des cellules T CD8 naïves, ceux-ci se transformant en lymphocyte killer.
Donc, une activation des T CD8 en lymphocyte killer est possible sans intervention des T CD4Soit la cellule dendritique va phagocyter une cellule quelconque infectée par le virus, présenter le peptide viral aux cellules T CD4 et aussi aux cellules T CD8.
L'activation du T CD8 va nécessiter l'augmentation de l'activité des costimulateurs CD40/CD40L et la libération de cytokines.Le récepteur CD40 est présent dans les cellules B, les macrophages et les cellules dendritiques.Le complexe MHC-peptide/ TCR et les corécepteurs CD4/CD8 vont déclencher la voie de signalisation aussi nommée voie de transduction.
En biologie cellulaire, on appelle ainsi les cascades de protéines déclenchées par un récepteur de surface qui vont modifier le propriétés de la cellule le plus souvent à travers l'expression des gènes :Les cellules T sont au repos dans le thymus.
L'activation par la cellule dendritique va réveiller la cellule T qui va se multiplier en produisant un ensemble de cellules rigoureusement identiques et spécifiques pour attaquer le pathogène incriminé.
La molécule responsable de l'activation et de la prolifération des cellules T est la cytokine interleukine-2.
L' interleukine-2 va agir par voie autocrine (sur la cellule qui la produit)  ou par voie paracrine (sur les cellules proches d 'elle).
Les traitements immunosuppresseurs utilisés dans les greffes d'organes agissent en perturbant le fonctionnement de l'interleukine-2.
L'amplitude de la réponse diffère selon le type de cellule T.
Le nombre de cellules T CD8 va être multiplié par 100 000, le nombre de cellules T CD4 va être multiplié par un facteur compris entre 100 et 1000.
La division lymphocytaire est un processus long: la division d'une cellule lymphocytaire dure 6 heures environ.
Enfin, un clone cellulaire est spécifique pour un petit nombre de peptides immunodominants de l'agent infectieux.La réponse Th1 est caractérisée par la production d'interféron γ qui active l'activité bactéricide des macrophages et induit la production d'immunoglobulines IgG par les lymphocytes B. La réponse Th1 permet notamment une réponse efficace contre les bactéries intracellulaires et les virus.La réponse Th2 est caractérisée par la production d'interleukine 4, qui induit la production d'immunoglobulines IgE par les lymphocytes B.La réponse Th17 est caractérisée par la production d'interleukine-17 qui induit le recrutement de neutrophiles.
La réponse Th17 permet notamment une réponse efficace contre les bactéries extracellulaires et les levures comme Candida albicans.Il existe d'autres sous-populations de lymphocytes T effecteurs, comme les lymphocytes Th9 caractérisés par la production d'interleukine 9 ou les lymphocytes Th22 caractérisés par la production d'interleukine-22 ou les lymphocytes T folliculaires.
Les lymphocytes T régulateurs peuvent être préprogrammés ou être inductibles en périphérie comme les populations décrites ci-dessus et jouent un rôle important dans la régulation des réponses immunitaires.Comme pour les lymphocytes T cytotoxiques, une partie des lymphocytes T auxiliaires sont conservés après l'élimination d'un agent infectieux et constituent une population de lymphocytes T mémoire.Le virus de l'immunodéficience humaine infecte et élimine progressivement les lymphocytes T auxiliaires, ce qui a pour effet de compromettre l'efficacité de la réponse immunitaire contre les virus mais également contre d'autres classes de microorganismes et conduit au syndrome d'immunodéficience acquise.À côté de la fonction d'activation de la cellule T CD8 en T Killer et de la fonction de stimulation de la cellule B indispensable pour la sécrétion d’antigène, la cellule B CD4 peut se différencier en cellule directement active en exprimant des molécules de surface et des cytokines différentes.
Un des récepteurs de la cellule B activée est le ligand CL40L, Ce ligand CD40 L peut se fixer sur les macrophages au récepteur CD40.
Le système immunitaire répond de façon différente à des pathogènes différents comme les virus, les parasites, les bactéries, les helminthes ou les champignons.Par exemple, comme les helminthes sont trop gros pour être phagocytés, la réponse immunitaire à une infection par helminthes est dominée par la sécrétion d'immunoglobulines de type E et l'activation des éosinophiles.
Pour un microbe intracellulaire comme celui de la tuberculose, qui résiste à la destruction intracellulaire, le système adaptatif consiste à activer les phagocytes par les T CD4 pour tuer les cellules infectées.Cette réponse fait appel aux T CD4.
En créant des T CD4 spécialisés, le système immunitaire peut répondre à différents type d'infection.
Cette spécialisation est nommée la polarisation des cellules T.Les groupes les mieux étudiés sont les groupes spécialisés pour les infections intracellulaires (virus, mycobactérie, listéria) de type Th 1 et le groupe pour les infections des vers parasites.Tableau des cytokines impliquées dans le développement des CD4 Th1 et CD4.Cette différenciation se fait principalement par le type de cytokine produite.Les cellules Th1 produisent l'interféron gamma et l'interleukine-12 qui permet après activation du facteur de transcription T-Bet de :La réponse Th2 permet notamment une réponse efficace contre les parasites; Les réactions allergiques sont des réactions de type Th2Les cellules Th2 produisent l'interleukine-4, l'interleukine-5, l'interleukine-13 qui stimule, après activation du facteur de transcription GATA-3:Certaines populations de lymphocytes T auxiliaires ont une fonction prédéterminée, comme les lymphocytes T régulateurs qui se développent dans le thymus, alors que d'autres populations ont des fonctions inductibles.
Au cours d'une infection, les cellules présentatrices d'antigène professionnelles détectent des signaux microbiens caractéristiques de l'agent infectieux.
En fonction de ces signaux, les cellules présentatrices d'antigène peuvent produire différentes cytokines et exprimer différentes protéines à leur surface.
Lorsque ces cellules interagissent avec les lymphocytes T auxiliaires naïfs dans les ganglions lymphatiques, différents programmes de différenciation sont induits en fonction des cytokines produites.
Ainsi, des lymphocytes T ayant une spécificité donnée peuvent exercer des effets différents en fonction des signaux perçus par les cellules présentatrices d'antigène.Les cellules effectrices augmentent l'expression des molécules d’adhésion à leur surface afin de favoriser et d'étendre le contact avec les cellules présentatrices d'antigènes pour les CD4 et avec les cellules cibles dans le cas des lymphocytes cytotoxiques CD8+.
Les cellules effectrices modifient les récepteurs aux chimiokines nommés aussi récepteurs d’adressage qui permettent aux cellules T de quitter les ganglions lymphatiques et de migrer vers les sites d'infection (récepteur CCR5 et CXCR3).
Le récepteur CCR5 est utilisé par le virus VIH pour pénétrer dans les lymphocytes.
Une autre caractéristique des cellules T effectrices est la production de cytokines (IL-4) et d'enzymes (perforine et granzyme).En résumé, une cellule T effectrice produira des cytokines, des récepteurs de chimiokines, des protéines d'adhésion et des molécules spécifiques pouvant agir sur les cellules cibles.L'activation du macrophage nécessite l'action des lymphocytes T CD4+ Th1 par la production d'interférons gamma et l’interaction CD40:CD40L.
Le macrophage va présenter les peptides, grâce à son MHC, aux récepteurs du T CD4+ qui vont reconnaître ce peptide comme étant le même peptide présenté par la cellule dendritique alors que le T CD4 était naïf.
Le macrophage va produire des réactifs oxygénés et nitrogénés, des enzymes lysosomales qui rendent le macrophage beaucoup plus agressif.
La réaction du macrophage est proinflammatoire avec risque d'endommager les tissus cellulaires.
Le macrophage va à son tour libérer du TNF, de l' IL-1 et IL-12 et chemokines.
L'IL-12 va par un rétrocontrôle positif stimuler le Th1.Les actions des cellules Th2 se font grâce à la sécrétion des interleukines 4 et des interleukines 5.Les cellules Treg sont des cellules qui expriment le récepteur Foxp3.
Elles sont générées soit dans le tissu, soit dans les organes lymphoïdes secondaires.Elles participent à la tolérance périphérique en inhibant les réponses des cellules T par inhibition de l'interleukine 12.Les lymphocytes T cytotoxiques sont un sous-groupe de lymphocytes T qui sont capables d'induire la mort par apoptose des cellules infectées par des virus (ou par d'autres agents infectieux) ou des cellules cancéreuses.Les lymphocytes T cytotoxiques naïfs sont activés lorsque leur récepteur antigénique reconnaît un complexe peptide-CMH de classe I présenté à la surface d'une cellule cible.
L'interaction de haute affinité permet au lymphocyte T cytotoxique de rester en contact avec la cellule cible.
Une fois activés, les lymphocytes T cytotoxiques prolifèrent.
Ce processus, appelé expansion clonale, aboutit à un clone de cellules ayant une même affinité ce qui amplifie la réponse immunitaire spécifique de l'antigène reconnu.
Les lymphocytes T cytotoxiques activés recirculent ensuite dans l'organisme afin de contrôler les cellules présentant le même antigène que celui pour lequel ils sont spécifiques.Lorsqu'ils reconnaissent une cellule infectée ou une cellule cancéreuse, les lymphocytes T cytotoxiques relarguent des perforines qui induisent la formation de pores dans la membrane plasmique des cellules cibles, ce qui conduit à l'entrée d'ions et d'eau dans les cellules cibles et conduit à leur lyse.
Les lymphocytes T cytotoxiques relarguent également des granzymes qui entrent dans les cellules à travers les pores et induisent la mort des cellules par apoptose.
Afin d'éviter une dégradation tissulaire trop importante, l'activation des lymphocytes T cytotoxiques nécessite à la fois une interaction forte entre le récepteur antigénique et le complexe CMH-antigène de la cellule cible et l'interaction avec des lymphocytes T auxiliaires.Une fois que l'infection est endiguée, la plupart des lymphocytes T cytotoxiques meurent par apoptose et sont éliminés par les phagocytes mais un petit nombre de lymphocytes deviennent des lymphocytes T cytotoxiques mémoire.
Au cours d'une infection ultérieure par un même agent infectieux, ces lymphocytes T cytotoxiques mémoire prolifèrent plus rapidement et permettent donc une réponse immunitaire plus efficace.La réponse des lymphocytes B est la réponse humorale, c'est-à-dire la réponse du système immunitaire permettant à l'organisme de se défendre contre des microbes qui sont à l'extérieur des cellules et aussi contre les toxines sécrétées par ces microbes.
Les cellules B reconnaissent les microbes par leur récepteur (BCR) qui sont des immunoglobulines fixées sur la membrane des cellules B ou immunoglobulines membranaires.
La stimulation des immunoglobulines membranaires par un antigène microbien va entraîner une modification de la cellule B en plasmocyte et ces plasmocytes vont sécréter les immunoglobulines dans le sang: ces immunoglobulines sont appelées immunoglobulines solubles ou anticorps.
Les plasmocytes peuvent sécréter entre 500 et 1 000 anticorps par seconde qui sont capables d'agir à distance.Les cellules B sont formées dans la partie rouge de la moëlle osseuse et une sélection négative élimine les cellules B réagissant aux protéines de l'organisme, c'est-à-dire possédant des immunoglobulines membranaires M autoréactives.Les cellules B sont alors secrétées dans le sang par lequel elles rejoignent les ganglions lymphatiques ou la rate.
Ce sont des cellules B naïves car elles n'ont jamais été en contact avec un antigène.
Les cellules B naïves ne possèdent que des immunoglobulines membranaires de type M ou D.
La formation des immunoglobulines D membranaires se fait par épissage.Dans le ganglion lymphatique, les cellules B rejoignent les follicules ganglionnaires ou la rate.L'activation des cellules B nécessite deux signaux comme pour les cellules T :Il existe plusieurs types de cellules B :La réponse B aux antigènes T-indépendante est la réponse des cellules B qui ne nécessitent pas l'intervention d'un lymphocyte T CD4+ (lymphocyte auxiliaire).
Les cellules B de la zone marginale et les cellules B-1 présentes dans les muqueuses contribuent aux réponses cellule T-indépendante.
La réponse est une sécrétion d'immunoglobuline M non spécifique, de courte durée et ne produisant pas de cellule mémoire.Antigène qui engage le récepteur cellulaire B pour le premier signal et un récepteur de pattern pour le second signal.Antigène qui engage uniquement le récepteur cellulaire B pour le premier signal et pour le second signal.
Cette réponse B thymus-indépendante est la source continue d'anticorps naturels produits par le corps humain en réponse aux antigènes de la flore intestinale.Les lymphocytes B sont les cellules produisant les anticorps, qui circulent dans le sang et la lymphe, et sont donc responsables de l'immunité à médiation humorale.
Les anticorps, ou immunoglobulines (Ig), sont des protéines permettant la reconnaissance et la neutralisation de corps étrangers comme les agents infectieux ou les toxines.
Chez les mammifères, il existe différents isotypes d'immunoglobulines : les IgA, IgG, IgE, IgD et IgM, dont les propriétés sont différentes.Comme les lymphocytes T, les lymphocytes B ont un récepteur antigénique à leur surface.
Toutefois la nature de ce récepteur est différente de celui des lymphocytes T puisqu'il s'agit d'un anticorps fixé à la surface de la cellule et non d'un récepteur pouvant reconnaître un complexe peptide-CMH.
L'une des différences entre les lymphocytes T et les lymphocytes B est que les lymphocytes T reconnaissent un antigène présenté par le CMH à la surface d'une cellule alors que les lymphocytes B reconnaissent un antigène dans sa forme native.
Lorsqu'un lymphocyte B reconnaît un antigène spécifique et qu'il est activé par un lymphocyte T auxiliaire, il se différencie en plasmocyte.
Les plasmocytes sont des cellules dont la durée de vie est de quelques jours et qui sécrètent des anticorps.
Ces anticorps peuvent se fixer aux microorganismes, et fournissent ainsi des repères aux cellules phagocytes et au système du complément.
Près de 10 % des plasmocytes survivent à l'issue d'une infection et deviennent des lymphocytes B mémoire à longue durée de vie.
Au cours d'une infection ultérieure par un même microorganisme, ces cellules produisent des anticorps plus rapidement et leur efficacité est plus importante.Les cellules B reconnaissent directement l'antigène par le complexe du récepteur des cellules B (BCR) dans l'organe lymphoïde secondaire (rate ou ganglion).
Ces antigènes sont:La reconnaissance de l’antigène par le BCR assure deux fonctions :Le BCR est formé d'une immunoglobuline membranaire de type D ou M et d'un co récepteur (CD79) qui est hétérodimére de deux polypeptides (Ig alpha et Ig beta).
Ce sont des corécepteurs transmembranaires de type 1 de la super famille des immunoglobulines qui possèdent des motifs ITAM.L'activation de la cellule B nécessite deux signaux.Le premier signal nécessite la reconnaissance du microbe par le complexe BCR et les corécepteurs activateurs CD21/CD2 qui fixent le complément C3d lui même fixé sur le microbe.
Le complément C3d appartient au système immunitaire inné.
Cet ensemble permet l'activation par des mécanismes de transcription dont il existe trois voies principales nommées par une des enzymes participant à la transcription (la voie NfkappaB, la voie NF-AT, la voie MAP kinase).La reconnaissance de microbe par le complexe BCR va entraîner :Le deuxième signal implique le lymphocyte T auxiliaire CD4+ qui aura avant était sensibilisé aux mêmes épitopes présentés par une cellule dendritique.
Le deuxième signal va être déclenché par la formation de la synapse immunologique décrit précédemment puis la libération de cytokine.Les conséquences de l'activation de la cellule B lymphocytaire sont :Trois évènements majeurs se déroulent dans le centre germinatif :L'hypermutation somatique ou mutation d'affinité est le changement de quelques acides aminés dans la partie variable de l'immunoglobuline membranaire du complexe récepteur.
Ce changement intéresse autant la chaîne lourde que la chaîne légère.
Comme une division de lymphocyte dure 6 heures, au bout d'une semaine, une cellule B produit environ 5000 lymphocytes B. Ce processus est encore mal connu, mais dépend de l'enzyme désaminase activation dépendante.
Le but de ce processus est de produire des immunoglobulines de plus en plus efficaces contre un microbe.
Durant ce processus interviennet des mécanismes de sélection positive pour empêcher l'apparition d'anticorps attaquant l'organisme.La recombinaison de commutation de classe (class switch recombination, CSR) permet aux cellules B de changer leur isotype d'immunoglobuline M en d'autres isotypes sans pour autant modifier leur spécificité de fixation d'antigène.
La CSR est une réaction de recombinaison-délétion au niveau de l'ADN.
La commutation de classe est régulée par des cytokines qui ouvrent la chromatine des deux régions participantes.
Les cytokines induisent les anticorps les mieux adaptés pour combattre l'infection.À l'issue d'un épisode infectieux, une partie des lymphocytes B et T qui ont été activés deviennent des lymphocytes mémoire.
Lors d'une infection par le même agent infectieux, ces cellules agissent plus rapidement et plus efficacement que lors de la première infection par cet agent infectieux.
C'est l'une des raisons pour lesquelles on parle d'immunité « adaptative », en cela que l'organisme s'adapte à son environnement en se préparant à des infections répétées par un même microorganisme.
La mémoire immunitaire peut s'acquérir de façon passive ou de façon active.La mémoire immunitaire acquise passivement peut durer entre plusieurs jours et plusieurs mois.
Les nouveau-nés n'ayant pas été confrontés à des agents infectieux, et n'ayant donc pas eu l'occasion de se constituer un pool de cellules mémoire, sont particulièrement vulnérables aux infections.
Plusieurs mécanismes de mémoire immunitaire passive leur sont transmis par la mère durant la vie fœtale.
Les IgG maternelles sont transportées à travers le placenta et permettent ainsi aux nouveau-nés d'avoir un répertoire d'IgG circulantes dont la spécificité et l'efficacité correspondent à une réponse mémoire de la mère.Le lait maternel contient également des anticorps permettant de protéger les nouveau-nés contre les infections intestinales.La mémoire immunitaire peut s'acquérir naturellement au cours d'une infection ou artificiellement par la vaccination.Les maladies infectieuses ont toujours été, et sont toujours, une cause majeure de mortalité dans la population humaine.
Durant les derniers siècles, deux principes essentiels ont permis de réduire la mortalité liée aux infections : l'hygiène et la vaccination.
La vaccination est l'induction délibérée d'une réponse immunitaire et représente le moyen le plus efficace de prévenir une infection en agissant sur les mécanismes naturels de mise en place d'une réponse immunitaire mémoire.
Le principe sous-jacent à la vaccination est d'administrer dans l'organisme un agent infectieux dont le potentiel pathogène est au préalable atténué pour éviter l'infection, mais suffisant pour induire l'immunisation et la mise en place d'une réponse mémoire.
La vaccination peut également s'effectuer par administration d'antigènes dérivés d'organismes infectieux, et s'accompagne généralement de l'injection d'adjuvants permettant d'induire une réponse immunitaire suffisamment forte.
La rate est un organe profond, situé dans l'hypocondre gauche en regard de la 10e côte (côte splénique), accolé à la face latérale de l'estomac, la grande courbure.
Elle est donc en position thoraco-abdominale.
Elle joue un rôle dans l'immunité et dans le renouvellement des cellules sanguines.Malgré sa topographie anatomique dans la cavité abdominale, recouverte de péritoine viscérale, la rate ne fait nullement partie de l'appareil digestif : elle n'a ni fonction endocrine, ni exocrine, uniquement des fonctions hématologiques et immunitaires.De couleur rouge ou pourpre foncé, la rate mesure chez l'être humain en moyenne 12 × 7 × 4 cm pour une masse moyenne de 200 g, c'est l'organe lymphoïde le plus volumineux.
La rate comprend classiquement trois faces et une base :Le bord antérieur est crénelé dû à sa proximité avec les dernières côtes gauches, c'est celui-ci que l'on perçoit à la palpation lors d'une splénomégalie.La rate est capable de se contracter ou de se dilater en fonction des besoins de l'organisme, la splénocontraction entraînant un retour de sang dans la circulation générale.La rate est entourée d'une capsule conjonctive très souple, riche en réticuline et en élastine, envoyant des cloisons conjonctives dans le parenchyme splénique.
Ces cloisons partagent la rate en lobules spléniques qui sont les unités fonctionnelles de la rate.Elle est constituée de deux sortes de tissus :La vascularisation artérielle de la rate se fait principalement par l'artère splénique (artère liénale).
Celle-ci étant l'une des 3 branches du tronc cœliaque qui naît de l'aorte au niveau de la 12e vertèbre thoracique.
Après un trajet très sinueux sur le bord supérieur du pancréas, elle pénètre dans le parenchyme par le hile en se divisant en deux branches supérieure et inférieure ; ceci explique l'existence de la splénectomie partielle.
Ensuite ces branches se divisent en artères trabéculaires qui cheminent dans les travées conjonctives.
Elles-mêmes donnent les artères centrales en sortant de la travée, qui s'entourent d'un manchon de pulpe blanche (surtout lymphocytes T).
L'artère centrale se poursuit et sort de la pulpe blanche pour donner des plus petites branches : les « artères pénicillées ».
Celles-ci se finissent par des capillaires avec des sortes de bouchons qui entourent leur terminaison: ce sont les capillaires à housse.
Ces capillaires terminaux sont obturés et il va y avoir des passages entre les cellules endothéliales terminales, et le sang va sortir des vaisseaux et traverser le parenchyme splénique pour rejoindre les sinus veineux.On a donc une circulation fermée et une circulation ouverte.La vascularisation veineuse se fait quant à elle par la veine splénique (veine liénale), qui rentre dans la constitution du tronc porte avec les veines mésentériques supérieure et inférieure.Les vaisseaux lymphatiques sont situés près des vaisseaux sanguins.
Seuls des vaisseaux lymphatiques efférents existent à la rate.Des canaux lymphatiques extérieurs relient la rate à l'estomac (épiploon gastro-splénique), au pancréas (épiploon pancréas-splénique).
Ces canaux jouent peut-être un rôle dans l'équilibre sodium / potassium du corps.Les nerfs suivent les vaisseaux et principalement les artères.
Ils expliqueraient partiellement les points de côté (par ischémie de la rate) et les coupures de souffle lors de chocs dans l'hypochondre gauche.
Lors d'un traumatisme de la rate, on peut observer parfois une douleur projetée dans l'épaule gauche due à l'afférence sensitive commune au niveau de la moelle épinière.Les rates surnuméraires, dites accessoires, sont fréquentes, retrouvées dans plus de 10 % des cas des scanners abdominaux.
Elles ne causent habituellement pas de problème mais des cas de torsion, se manifestant par une douleur abdominale aiguë, ont été décrits.
Dans ce cas, on retrouve une rate principale et des secondaires.On peut également avoir des polysplénies, on retrouve alors plusieurs rate de taille équivalente, sans une dominante.
Dans ce cas, on a souvent d'autres malformations : situs invertus, mauvaise disposition des vaisseaux abdominaux…La rate, au lieu d'être lisse, peut être polylobée.
Rarement elle peut être ectopique, voire, fusionnée avec une gonade.La rate a trois rôles essentiels :La rate n'est pas indispensable à la vie.
Pour cette raison la splénectomie, ou ablation de la rate, peut être indiquée dans différentes situations :En dehors des éventuelles complications opératoires, les principales complications de la splénectomie sont infectieuses, en raison de l'asplénie induite, avec un risque d'infections bactériennes très sévères.
Les germes en cause sont les pneumocoques, les méningocoques et l'Haemophilus influenzae.Les Anciens (Hippocrate) disaient qu'en automne il fallait « faire rire la rate », en mangeant des racines (panais, radis noir, pissenlit, etc.).
Ce qui permettait de mieux supporter le froid et d'être de meilleure humeur.
La rate, selon la théorie des humeurs, servait surtout à réguler les humeurs.
Si on mangeait assez de racines, on évitait les dépressions liées à l'hiver.Les Anciens attribuaient à la rate de nombreuses propriétés dont celle de provoquer les points de côté et de nuire par conséquent à la course.
On croyait ainsi que les Anciens desséchaient la rate des coureurs et de leurs chevaux pour en améliorer les performances.
Le paratope d'un anticorps en est la partie qui assure la fonction de reconnaissance de l'antigène.
Chaque paratope reconnaît de façon spécifique une partie de l'antigène, partie appelée épitope.
C'est le site de reconnaissance de l'anticorps.Le paratope se trouve aux extrémités des chaînes lourdes (heavy) et légères (light) d'un anticorps, dans sa partie variable.
La sélection clonale est une théorie scientifique en immunologie qui explique les fonctions des cellules du système immunitaire (lymphocytes) en réponse à des antigènes envahissant le corps.Elle rend compte du mécanisme de sélection des acteurs capables de s'attaquer spécifiquement à l'antigène correspondant à un épitope particulier.
Par exemple, les lymphocytes T.Les acteurs ainsi sélectionnés subissent ensuite une phase de prolifération durant laquelle ils se répliquent à l'identique, menant à la formation d'une population cellulaire dirigée contre l'antigène initialement repéré.En 1900, Paul Ehrlich proposa la "théorie des chaînes latérales" de la production d'anticorps.
Selon cette théorie, certaines cellules présentent à leur surface différents "chaîne latérales" (c'est-à-dire des anticorps liés à la membrane) capables de réagir avec différents antigènes.
Lorsqu'un antigène est présent, il se lie à une chaîne latérale correspondante.
Ensuite, la cellule arrête de produire toutes les autres chaînes latérales et commence une synthèse et une sécrétion intensives de la chaîne latérale de liaison à l'antigène en tant qu'anticorps soluble.Bien que distincte de la sélection clonale, l'idée d'Ehrlich était une théorie de la sélection beaucoup plus précise que les théories instructives qui ont dominé l'immunologie au cours des décennies suivantes.En 1955, l'immunologiste danois Niels Jerne émis l'hypothèse qu'il existe déjà une vaste gamme d'anticorps solubles dans le sérum avant toute infection.
L'entrée d'un antigène dans le corps entraîne la sélection d'un seul type d'anticorps correspondant.
Cela se serait produit par certaines cellules phagocytose du complexe immunitaire, répliquant d'une manière ou d'une autre la structure de l'anticorps pour en produire davantage.En 1957, David W. Talmage émis l'hypothèse que les antigènes se lient aux anticorps à la surface des cellules productrices d'anticorps et « seules les cellules sont sélectionnées pour la multiplication dont le produit synthétisé a une affinité pour l'antigène ».
La principale différence avec la théorie d'Ehrlich était que chaque cellule était supposée synthétiser une seule sorte d'anticorps.
Après la liaison à l'antigène, la cellule prolifère, formant des clones avec des anticorps identiques.Le concept de sélection clonale a été introduit par le médecin australien Frank Macfarlane Burnet en 1957, pour tenter d'expliquer la grande diversité des anticorps formés lors de l'initiation de la réponse immunitaire,.Dans son article, Burnet développa les idées de Talmage, nommant la théorie résultante « théorie de la sélection clonale ».
Il formalisa ensuite cette théorie dans son livre de 1959, « The Clonal Selection Theory of Acquired Immunity ».La première preuve expérimentale en a été donnée en 1958, lorsque Gustav Nossal et Joshua Lederberg ont montré qu'une cellule B ne produit qu'un anticorps unique.Cette théorie est à présent largement acceptée comme modèle de la façon dont le système immunitaire humain répond à infection et comment certains types de B et lymphocytes T sont sélectionnés pour la destruction de antigènes .Burnet proposa d'expliquer la mémoire immunologique comme étant la conséquence du clonage de deux types de lymphocytes.
L'un des clone agit immédiatement pour combattre l'infection, tandis que l'autre dure plus longtemps, restant longtemps dans le système immunitaire et provoquant une immunité contre cet antigène.Selon l'hypothèse de Burnet, parmi les différents anticorps susceptibles d'être produits se trouvent des molécules qui peuvent probablement correspondre avec des degrés de précision variables à tous, ou pratiquement tous, les déterminants antigéniques qui se produisent dans le matériel biologique autre que ceux caractéristiques du corps lui-même.
Chaque type de motif est un produit spécifique d'un clone de lymphocytes.Au cœur de la théorie est l'hypothèse que chaque cellule dispose automatiquement à sa surface de sites réactifs représentatifs équivalents à ceux de la globuline qu'elle produit.Lorsqu'un antigène pénètre dans le sang ou les fluides tissulaires, on suppose qu'il se fixe à la surface de tout lymphocyte portant des sites réactifs qui correspondent à l'un de ses déterminants antigéniques.La théorie proposée est que dans un groupe préexistant de lymphocytes (en particulier les cellules B), un antigène spécifique active (c'est-à-dire sélectionne) uniquement sa cellule contre-spécifique, qui induit alors cette cellule particulière à se multiplier, produisant un clone pour la production d'anticorps.
Cette activation se produit dans les organes lymphoïdes secondaires tels que la rate et les ganglion lymphatiques.De cette manière est initiée une prolifération préférentielle de tous ces clones dont les sites réactifs correspondent aux déterminants antigéniques sur les antigènes présents dans le corps.
Les descendants sont capables de libérer activement des anticorps solubles et des lymphocytes, les mêmes fonctions que les formes parentales,.En bref, la théorie est une explication du mécanisme de génération de la diversité de la spécificité des anticorps.La théorie de la sélection clonale peut être résumée par les quatre principes suivants :Burnet et Peter Medawar ont travaillé ensemble pour comprendre la tolérance immunologique, un phénomène également expliqué par la sélection clonale.
Il s'agit de la capacité de l'organisme à tolérer l'introduction de cellules avant le développement d'une réponse immunitaire tant qu'elle se produit tôt dans le développement de l'organisme.
Il existe un grand nombre de lymphocytes présents dans le système immunitaire, allant des cellules qui tolèrent les tissus du soi aux cellules qui ne le font pas.
Cependant, seules les cellules tolérantes au tissu propre survivent au stade embryonnaire.
Si du tissu non-soi est introduit, les lymphocytes qui se développent sont ceux qui incluent les tissus non-soi en tant que tissu propre.En 1959, Burnet a proposé que dans certaines circonstances, des tissus puissent être transplantés avec succès chez des receveurs étrangers.
Ces travaux ont conduit à une bien meilleure compréhension du système immunitaire et également à de grandes avancées dans la transplantation de tissus.
Burnet et Medawar ont partagé le Prix Nobel de physiologie ou médecine en 1960.En 1974, Niels Kaj Jerne a proposé que le système immunitaire fonctionne comme un réseau régulé via des interactions entre les parties variables des lymphocytes et leurs molécules sécrétées.
La théorie des réseaux immunitaires est fermement basée sur le concept de sélection clonale.
Jerne a remporté le prix Nobel de physiologie ou médecine en 1984, en grande partie pour ses contributions à la théorie des réseaux immunitaires.L'idée s'est avérée être le fondement de l'immunologie moléculaire, en particulier dans l'immunité adaptative.
En médecine, le diagnostic est la démarche par laquelle le vétérinaire, médecin, généraliste ou spécialiste, le kinésithérapeute, la sage-femme ou le chirurgien-dentiste, ou encore le psychologue au Canada, détermine l'affection dont souffre le patient, et qui permet de proposer un traitement.
Il repose sur la recherche des causes (étiologie) et des effets (symptômes) de l'affection ; on parle aussi de « tableau clinique ».
(voir la page diagnostic  pour l'étymologie et des généralités sur ce mot)Typiquement, le diagnostic se déroule en deux parties :Il peut se compléter d'examens complémentaires, certains pouvant être faits directement lors de la consultation, d'autres nécessitant des intervenants différents (analyse de sang, d'urine, imagerie médicale…).Le diagnostic différentiel d'un état morbide est l'ensemble des pathologies présentant éventuellement des symptômes et signes proches.L'évaluation d'un patient ne concerne pas que le médecin, le chirurgien dentiste ou le maïeuticien.
Il existe aussi un diagnostic infirmier, un diagnostic kinésithérapique, un diagnostic psychologique et un diagnostic orthophonique.Au Canada, les psychologues sont également habilités à poser un diagnostic.
Il s'agit alors principalement de définir les troubles psychiques dont souffre le patient et leur implications dans la maladie, mais aussi de déterminer la manière la plus adaptée de réaliser l'ordonnance médicale, ou de choisir la technique et son intensité en fonction de l'état et des capacités du patient.Il existe deux principaux types de diagnostics médicaux :Raisonnement analogique ou reconnaissance de formes.Le raisonnement bayésien construit, à partir d'éléments de l'entretien et de l'observation, une probabilité de la cause du symptôme ou de l'épisode, qui s'affinera de plus en plus.
Ainsi le diagnostic indique-t-il qu'une maladie ou une causalité est plus qu'une autre est probablement à l'origine des symptômes du patient; des examens renforcent ou infirment l'hypothèse.Il semblerait qu'à l'issue de ce type de raisonnement, la plupart des médecins ont tendance à surestimer la probabilité que le patient soit effectivement malade, tant avant qu'après un test diagnostic.
La biologie moléculaire (parfois abrégée bio.
est une discipline scientifique de la vie au croisement de la génétique, de la biochimie métabolique et de la physique, dont l'objet est la compréhension des mécanismes de fonctionnement de la cellule au niveau moléculaire.
Le terme « biologie moléculaire », utilisé la première fois en 1938 par Warren Weaver, désigne également l'ensemble des techniques de manipulation d'acides nucléiques (ADN, ARN), appelées aussi techniques de génie génétique.La biologie moléculaire est apparue au XXe siècle, à la suite de l'élaboration des lois de la génomique, transcriptomique, protéomique, métabolomique) de la biologie moléculaire pour étudier plus spécifiquement les cellules des micro-organismes.La biologie moléculaire est apparue dans les années 1930, le terme n'ayant cependant été inventé qu'en 1938 par Warren Weaver.
Warren Weaver était à l'époque directeur des Sciences Naturelles pour la Fondation Rockefeller et pensait que la biologie était sur le point de vivre une période de changements significatifs étant donné les avancées récentes dans les domaines tels que la diffractométrie de rayons X.
Il a donc investi des sommes importantes provenant de l'Institut Rockefeller dans les domaines biologiques.
Après la découverte de la structure en double hélice de l'ADN en 1953 par James Watson (1928-), Francis Crick (1916-2004), Maurice Wilkins (1916-2004) et Rosalind Franklin (1920-1958), la biologie moléculaire a connu d'importants développements pour devenir un outil incontournable de la biologie moderne à partir des années 1970.Les chercheurs en biologie moléculaire utilisent des techniques spécifiques pour la biologie moléculaire (voir plus loin Techniques de biologie moléculaire), mais les combinent de plus en plus avec les techniques et les idées provenant de la génétique et de la biochimie.
Il n'y a pas de frontière bien définie entre ces disciplines, bien qu'il y en ait eu à une certaine époque.
La figure ci-contre illustre une vue possible de la relation entre les domaines :L'essentiel du travail en biologie moléculaire est quantitatif, et récemment beaucoup de travaux ont été faits à l'intersection de la biologie moléculaire et de l'informatique, dans la bio-informatique et dans la biologie calculatoire.
Depuis les années 2000, l'étude de la structure et de la fonction des gènes, la génétique moléculaire, fait partie des sous-domaines les plus saillants de la biologie moléculaire.
De plus en plus d'autres domaines de la biologie se concentrent sur les molécules, soit directement, en étudiant leurs interactions propres comme en biologie cellulaire et en biologie du développement, soit indirectement, quand les techniques de la biologie moléculaire sont utilisées pour déduire les attributs historiques des populations ou des espèces, comme dans les domaines de la biologie de l'évolution telles que la génétique des populations et la phylogénie.
Il y a également une longue tradition d'étude des biomolécules « à partir du bas » en biophysique.Depuis la fin des années 1950 et le début des années 1960, les biologistes moléculaires ont appris à caractériser, isoler et manipuler les composants moléculaires des cellules et des organismes.
Ces composants incluent l'ADN, support de l'information génétique, l'ARN, proche de l'ADN dont les fonctions vont de la copie provisoire d'ADN jusqu'aux réelles fonctions structurelles et enzymatiques et qui est une partie fonctionnelle et structurelle de l'appareil traductionnel, et les protéines, molécules structurelles et enzymatiques les plus importantes des cellules.Une des techniques les plus élémentaires en biologie moléculaire pour étudier le rôle des protéines est le clonage d'expressions.
Dans cette technique, l'ADN codant la protéine qui nous intéresse est cloné en utilisant la réaction en chaîne par polymérase (PCR en anglais pour Polymerase Chain Reaction) et/ou des enzymes de restriction dans un plasmide (qu'on appelle vecteur d'expression).
Ce plasmide peut avoir des éléments de séquences promotrices spéciales pour diriger la production de la protéine en question et peut aussi avoir des marqueurs de résistance antibiotique pour aider à suivre le plasmide.Ce plasmide peut être inséré dans des cellules, soit de bactérie, soit d'animal.
Introduire de l'ADN dans des cellules bactériennes est appelé transformation, et cela peut être complété de plusieurs manières : électroporation, micro-injection, consommation passive et conjugaison.
Introduire de l'ADN dans des cellules d'eucaryotes, telles que des cellules animales, est appelé transfection.
Plusieurs techniques différentes de transfection sont disponibles : transfection calcium phosphate, transfection de liposomes ou lipofection, électroporation ou encore par réactifs de transfection propriétaires tels que le Fugene ou le Genecellin.
L'ADN peut alors être introduit dans les cellules en utilisant des virus ou des bactéries pathogènes comme transporteurs.
Dans de tels cas, la technique est appelée transduction virale/bactérienne, et les cellules sont dites transduites.Dans les deux cas, le codage ADN pour la protéine qui nous intéresse est maintenant à l'intérieur d'une cellule, et la protéine peut maintenant s'exprimer.
Une variété de systèmes, tels que des promoteurs inductibles et des facteurs spécifiques signalant les cellules, sont disponibles pour aider la protéine qui nous intéresse à s'exprimer à haut niveau.
De grandes quantités de protéines peuvent alors être extraites de la cellule bactérienne ou eucaryote.
La protéine peut être testée pour connaître son activité enzymatique dans une variété de situations, elle peut être cristallisée pour qu'on puisse étudier sa structure tertiaire, ou, dans l'industrie pharmaceutique, on peut étudier l'activité de nouveaux médicaments sur la protéine en question.La réaction en chaîne par polymérase (PCR en anglais, pour Polymerase Chain Reaction) est une technique extrêmement flexible de copie d'ADN.
En gros, la PCR permet à une simple séquence d'ADN d'être copiée des millions de fois, ou d'être altérée par des moyens prédéterminés.
Par exemple, la PCR peut être utilisée pour introduire des sites d'enzymes de restriction, ou pour muter (changer) des bases particulières de l'ADN.
La PCR peut aussi être utilisée pour déterminer si un fragment particulier d'ADN se trouve dans une bibliothèque d'ADN complémentaires.
La PCR a de nombreuses variations, comme la PCR à transcription inversée (RT-PCR en anglais pour Reverse Transcription Polymerase Chain Reaction) pour l'amplification de l'ARN, et, plus récemment, la PCR temps réel (qPCR) qui permet des mesures quantitatives de molécules d'ADN et d'ARN.L'électrophorèse est un des principaux outils de biologie moléculaire.
Le principe de base est que l'ADN, l'ARN et les protéines peuvent être séparées par des champs électriques.
Dans l'électrophorèse en gel d'agarose, l'ADN et l'ARN peuvent être séparés en fonction de leur taille en faisant circuler l'ADN à travers un gel d'agarose.
Les protéines peuvent être séparées en fonction de leur poids en utilisant un gel SDS-PAGE.
Les protéines peuvent aussi être séparées par leur charge électrique, en utilisant ce qu'on appelle un gel isoélectrique.Nommé ainsi d'après le nom de son inventeur, le biologiste Edwin Southern, le Southern blot est une méthode pour sonder la présence d'une séquence précise d'ADN à l'intérieur d'un échantillon d'ADN.
Des échantillons d'ADN avant ou après digestion par une enzyme de restriction sont séparés par électrophorèse et transférés sur une membrane par marquage via action capillaire.
La membrane peut alors être testée en utilisant une sonde ADN marquée avec un complément de la séquence en question.
À l'origine, la plupart des protocoles utilisaient des marqueurs radioactifs ; cependant, maintenant, il existe des possibilités de marquages non radioactifs.
Le Southern blot est utilisé moins souvent dans les laboratoires, du fait que la PCR permet déjà de détecter des séquences ADN spécifiques à partir d'échantillons d'ADN.
Cependant, ces marquages sont encore utilisés pour certaines applications, telles que la mesure du nombre de copies transgéniques dans les souris transgéniques, ou dans l'ingénierie de lignes de cellules souches embryonnaires à gènes invalidés.Le northern blot est utilisé pour étudier les modèles d'expression d'un type spécifique de molécule d'ARN en comparaison relative avec un ensemble de différents échantillons d'ARN.
C'est essentiellement une combinaison d'une dénaturation d'électrophorèse d'ARN, et d'un blot.
Dans ce processus, l'ARN est séparé en fonction de la taille, puis est transféré sur une membrane qui est alors sondée avec un complément marqué pour la séquence intéressante.
Les résultats peuvent être visualisés d'une variété de façons selon le marquage utilisé ; cependant, la plupart conduisent à une révélation de bandes représentant la taille de l'ARN détecté dans l'échantillon.
L'intensité de ces bandes est liée à la quantité d'ARN ciblé dans les échantillons analysés.
Le procédé est utilisé généralement pour étudier quand et combien d'expressions de gènes se produisent en mesurant la quantité de cet ARN présent dans les différents échantillons.
C'est un des outils les plus fondamentaux pour déterminer quand certains gènes s'expriment dans les tissus vivants.Séparation des protéines par électrophorèse SDS-PAGE uniquement en fonction de leur poids (le SDS, ou sodium dodécylsulfate, dénature les structures tertiaire et quaternaire des protéines et les charge toutes négativement), puis transfert des protéines séparées sur membrane pour les rendre accessibles à divers marquages immunologiques ou autres.Les anticorps pour la plupart des protéines peuvent être créés par injection de petites quantités de protéine cible dans les animaux tels que la souris, le lapin, le mouton ou l'âne (anticorps polyclonaux) ou produits dans une culture de cellules (anticorps monoclonaux).
Ces anticorps peuvent être utilisés dans une variété de techniques analytiques et préparatives.Dans le western blot (immunobuvardage), les protéines sont d'abord séparées en fonction de leur poids, dans un gel fin pris entre deux plaques de verre par une technique qu'on appelle SDS-PAGE (pour Sodium Dodecyl Sulphate Poly-Acrylamide Gel Electrophoresis).
Les protéines dans le gel sont alors transférées sur un PVDF, nitrocellulose, nylon ou autre membrane de support.
Cette membrane peut alors être sondée avec des solutions d'anticorps.
Les anticorps qui s'attachent spécifiquement à la protéine en question peuvent alors être visualisés selon une variété de techniques, dont la colorimétrie, la chimiluminescence ou l'autoradiographie.
Des méthodes analogues de western blot peuvent aussi être utilisées pour marquer directement des protéines spécifiques dans des cellules et des sections de tissus.
Cependant, ces méthodes de marquages immunologiques sont plutôt associées à la biologie cellulaire qu'à la biologie moléculaire.Les termes western et northern sont des jeux de mots : les premiers blots étaient sur l'ADN, et comme ils ont été faits par Edwin Southern, ils ont pris le nom de Southern (southern veut dire « du sud » en anglais ; tandis que western signifie « de l'ouest » et northern, « du nord »).
Il est peu probable que Patricia Thomas, inventrice du blot ARN, qui est devenu le northern blot, utilise vraiment ce terme.
Pour pousser la plaisanterie plus loin, on peut trouver, dans la littérature , des références vers des south-westerns (« du sud-ouest ») (interactions protéine-ADN) et des far-westerns (du « far-ouest ») (interactions protéine-protéine).Une puce à ADN, aussi appelée microarray, est une collection de milliers de puits microscopiques sur un support solide tel qu'une lame de microscope; chaque puits contient un grand nombre de fragments d'ADN identiques qui permet de mesurer l'expression d'un gène particulier par complémentarité de séquence avec ARN correspondant.
Les puces permettent ainsi de connaître le transcriptome, c'est-à-dire l'ensemble des gènes transcrit à un moment donné dans un groupe de cellules données.Il y a plusieurs manières différentes de fabriquer des puces à ADN ; les plus courantes sont les puces à silicium, lames de microscope dont les taches ont 100 microns de diamètre, les puces qu'on peut adapter à ses besoins, et celles avec des taches plus grosses sur des membranes poreuses (macropuces).
Les puces peuvent aussi être fabriquées pour des molécules autres que l'ADN.
Par exemple, une puce à anticorps peut être utilisée pour déterminer quelle protéine ou bactérie est présente dans un échantillon de sang.Les puces à ADN sont ensuite lues à l'aide d'un scanner de micraorrays qui permettent d'acquérir le niveau de fluorescence de chaque spot présent sur la lame afin d'en analyser les données.Au fur et à mesure que de nouvelles procédures et de nouvelles technologies sont devenues disponibles, les anciennes sont rapidement abandonnées.
Des exemples typiques sont les méthodes pour déterminer la taille des molécules d'ADN.
Avant l'électrophorèse, avec agarose et polyacrylamide, on calculait la taille de l'ADN par sédimentation dans des gradients sucrés, une technologie lente et laborieuse nécessitant une instrumentation coûteuse ; et avant les gradients sucrés, on utilisait la viscométrie.
La vaccination est l'administration d'un agent antigénique, le vaccin, dans le but de stimuler le système immunitaire d'un organisme vivant afin d'y développer une immunité adaptative contre un agent infectieux.
La substance active d’un vaccin est un antigène dont la pathogénicité du porteur est atténuée afin de stimuler les défenses naturelles de l'organisme (son système immunitaire).
La réaction immunitaire primaire permet en parallèle une mise en mémoire de l'antigène présenté pour qu'à l'avenir, lors d'une vraie contamination, l'immunité acquise puisse s'activer de façon plus rapide et plus forte.La vaccination s'effectue sur un individu sain soit par injection sous-cutanée ou intramusculaire soit par voie orale, selon des pratiques le plus souvent réglementées.
En général, chaque acte de vaccination est documenté (exemple : dans un carnet de vaccination).L'Organisation mondiale de la santé estime que la vaccination est l’une des interventions sanitaires les plus efficaces et les plus économiques.
Elle a permis d’éradiquer la variole, de réduire de 99 % à ce jour l’incidence mondiale de la poliomyélite, et de faire baisser de façon spectaculaire la morbidité, les incapacités et la mortalité dues à la diphtérie, au tétanos, à la coqueluche, à la tuberculose, et à la rougeole.
Pour la seule année 2003, les autorités sanitaires estiment que la vaccination a évité plus de deux millions de décès.Des méthodes empiriques de variolisation sont apparues très tôt dans l'histoire de l'humanité, grâce à l'observation du fait qu'une personne qui survit à la maladie est épargnée lors des épidémies suivantes.
L'idée de prévenir le mal par le mal se concrétise dans des pratiques populaires sur les continents asiatique et africain,,.
La pratique de l'inoculation était en tout cas connue en Afrique depuis plusieurs siècles et c'est de son esclave Onesimus que l'apprit le pasteur américain Cotton Mather.
La première mention indiscutable de la variolisation apparaît en Chine au XVIe siècle.
Il s'agissait d’inoculer une forme qu’on espérait peu virulente de la variole en mettant en contact la personne à immuniser avec le contenu de la substance qui suppure des vésicules d'un malade (le pus).
Le risque n'était cependant pas négligeable : le taux de mortalité pouvait atteindre 1 ou 2 %.
La pratique s’est progressivement diffusée le long de la route de la soie.
Elle a été importée depuis Constantinople en Occident au début du XVIIIe siècle grâce à lady Mary Wortley Montagu.
Voltaire lui consacre en 1734 sa XIe lettre philosophique, « Sur la petite vérole », où il la nomme inoculation, lui attribuant une origine circassienne et précisant qu'elle se pratique aussi en Angleterre : En 1760, Daniel Bernoulli démontra que, malgré les risques, la généralisation de cette pratique permettrait de gagner un peu plus de trois ans d’espérance de vie à la naissance.
La pratique de l'inoculation de la variole a suscité de nombreux débats en France et ailleurs.Pour la première fois, des années 1770 jusqu'en 1791, au moins six personnes ont testé, chacune de façon indépendante, la possibilité d'immuniser les humains de la variole en leur inoculant la variole des vaches, qui était présente sur les pis de la vache.
Parmi les personnes qui ont fait les premiers essais, figurent en 1774 un fermier anglais nommé Benjamin Jesty et, en 1791, un maître d'école allemand nommé Peter Plett.
En 1796, le médecin anglais Edward Jenner fera la même découverte et se battra afin que l'on reconnaisse officiellement le bon résultat de l'immunisation.
Le 14 mai 1796, il inocula au jeune James Phipps, âgé de 8 ans, du pus prélevé sur la main de Sarah Nelmes, une fermière infectée par la vaccine, ou variole des vaches.
Trois mois plus tard, il inocula la variole à l'enfant, qui s'est révélé immunisé.
Cette pratique s'est répandue progressivement dans toute l'Europe.
Le mot vaccination vient du nom de la « variole des vaches », la vaccine, elle-même dérivée du latin : vacca qui signifie « vache ».
Un auteur récent – reprenant en cela un débat ancien qui avait commencé dès Jenner – fait remarquer que la pratique aurait pu s'appeler « équination » vu l'origine équine de la vaccine.
Il est par ailleurs attesté qu'en de multiples occasions des lymphes vaccinales ont été produites à partir de chevaux (l'un de ses premiers biographes rapporte même que Jenner a inoculé son fils aîné, en 1789, avec des matières extraites d'un porc malade du swinepox,).Le principe de la vaccination a été expliqué par Louis Pasteur et ses collaborateurs Roux et Duclaux, à la suite des travaux de Robert Koch mettant en relation les microbes et les maladies.
Cette découverte lui permit de développer des techniques d'atténuation des germes.
Sa première vaccination fut la vaccination d'un troupeau de moutons contre le charbon le 5 mai 1881.
La première vaccination humaine (hormis la vaccination au sens originel de Jenner) fut celle d'un enfant contre la rage le 6 juillet 1885.
Contrairement à la plupart des vaccinations, cette dernière fut effectuée après l'exposition au risque — ici, la morsure du jeune Joseph Meister par un chien enragé et non avant (le virus de la rage ne progressant que lentement dans le système nerveux).Le terme vaccinologie a été créé en 1976 par Jonas Salk (1914-1995), pour désigner une branche de médecine de santé publique consacrée aux vaccins (statut de médicament) et à la vaccination (action d'immunisation préventive).
La vaccinologie est pluri-disciplinaire avec un double aspect biomédical et politique (de santé publique).La vaccinologie fait appel aux disciplines suivantes :La dimension économique de la vaccinologie est celle de l'activité industrielle liée aux vaccins : le coût recherche-développement d'un vaccin est comparé au coût de la maladie infectieuse évitable, certes dans le cadre général d'une économie libérale (recherche de profits) mais aussi de gestion budgétaire (limitation ou contrôle des dépenses d'un système de santé).Les dimensions sociologiques et éthiques sont représentées par les problèmes posés par l'obligation vaccinale et les droits individuels (information, liberté de choix…), les résistances et les oppositions aux vaccinations, les problèmes de communication et de gestion de crise face à des rumeurs ou des évènements médiatisés.Un vaccin est une préparation d'un ou plusieurs antigènes microbiens utilisés pour induire une immunité protectrice et durable de l'organisme, en faisant appel à l'immunité adaptative, par opposition à l'immunité innée.
Le but principal des vaccins est d'obtenir, par l'organisme lui-même, la production d'anticorps et l'activation de cellules T (lymphocyte B ou lymphocyte T à mémoire) spécifiques à l'antigène.
Une immunisation réussie doit donc procurer une protection contre une future infection d'éléments pathogènes identifiés.
Un vaccin est donc spécifique à une maladie mais pas à une autre.La vaccination est une technique d'immunisation active, par opposition à l'immunisation passive par transfert d'anticorps (par exemple, la sérothérapie).Le schéma vaccinal définit le nombre et l'intervalle des injections nécessaires à l'obtention d'une immunité protectrice suffisante.
La primo-vaccination est celle qui induit cette protection, et les rappels de vaccination sont celles qui l'entretiennent.À l'échelle nationale, le calendrier vaccinal est l'ensemble des schémas vaccinaux, réactualisés chaque année, par et pour un pays donné.
Ces schémas peuvent être recommandés ou obligatoires, selon l'âge ou la profession, en population générale ou particulière.La couverture vaccinale correspond au taux de personnes ayant reçu un nombre donné d'injections vaccinales à une date donnée.Deux grandes familles : vaccins issus d'agents infectieux et ceux sans agent infectieux.La première famille (vaccins classiques) se détaille en deux grandes catégories :Avec les vaccins vivants atténués, on injecte au patient une version modifiée du pathogène contre lequel on veut qu’il soit protégé.
Cette modification de l’agent infectieux sert à réduire son efficacité sans le tuer.
Notre corps va se défendre comme s’il combattait le virus ou la bactérie non-modifiée et produire des cellules mémoires pour le combattre plus efficacement la prochaine fois qu’il sera en contact avec ce même pathogène.
Ce type de vaccination est efficace sur le long terme.
Cependant, comme il s’agit d’inoculer la forme vivante du pathogène, même atténuée, il existe un faible risque infectieux qui constitue une contre-indication pour les personnes immunodéprimées.Les vaccins inactivés contiennent l’agent infectieux mort, ou alors fragmenté.
Cette méthode de vaccination est moins efficace sur le long terme et nécessitera des rappels.La deuxième grande famille est produite sans agent infectieux.
Parmi ceux-ci, les vaccins à ARN d'utilisation récente (même si le principe est connu depuis plus d'une dizaine d'années) se révèlent très prometteurs et très adaptables face aux mutations des virus.Les vaccins multivalents ou combinés, associent des combinaisons d'antigènes, permettant de cibler plusieurs maladies différentes en un seul vaccin (par exemple Rougeole-Oreillons-Rubéole ou Diphtérie-Tétanos-Poliomyélite-Coqueluche-Hib-Hépatite B).
Ces vaccins permettent de diminuer le nombre d'injections et d'augmenter la couverture vaccinale.La vaccination est un acte médical qui engage la responsabilité du vaccinateur, elle doit être expliquée et consentie.
Le sujet à vacciner a le droit de recevoir une information personnalisée, adaptée à son niveau de compréhension.En principe, l'acte vaccinal comporte des règles à respecter.
Il est effectué par un médecin ou un(e) infirmièr(e), ou selon des cas règlementés par une sage-femme ou un pharmacien.
En France, 90 % des vaccinations sont effectuées en médecine libérale, dans d'autres pays (comme les pays scandinaves) les vaccinations sont faites dans un cadre collectif (médecine scolaire, ou d'autres services publics).Elle doit être précédée d'un interrogatoire à la recherche d'éventuelles contre-indications (antécédents d'allergie, déficience immunitaire, grossesse ou projet en cours de grossesse…) ; de la vérification du vaccin (conditions de conservation du vaccin, date de péremption) et de ses conditions d'utilisation (selon la présentation du vaccin, le calendrier vaccinal, l'âge du sujet…).Chez le nourrisson et le petit enfant, l'utilisation de patch anesthésique ou d'une solution sucrée avec tétine est possible pour diminuer la douleur ou la peur.Le vaccinateur doit être en mesure de prendre en charge un malaise vagal ou une réaction allergique dans les minutes qui suivent une injection.La plupart des vaccins sont injectés par voie sous-cutanée ou intramusculaire, dans les conditions habituelles d'hygiène et d'asepsie.
Les principaux sites d'injection se font dans la région du deltoïde, du sus-épineux chez l'enfant et l'adulte, et la face antéro-latérale de la cuisse chez le nourrisson.
L'injection dans la fesse n'est pas recommandée, outre la proximité du nerf sciatique, l'épaisseur du tissu graisseux peut réduire l'efficacité vaccinale.La voie intradermique (injection superficielle et tangentielle à la peau) est pratiquement réservée au BCG, au niveau de la face externe du bras.
Elle est de réalisation plus délicate.Quelques vaccins sont administrés par voie orale, comme le vaccin oral contre la poliomyélite, ou les vaccins contre le rotavirus.
Des vaccins par spray nasal sont en cours d'essai (ex.
: vaccin antigrippal NasVax en Israël), voire déjà utilisés (vaccins contre la grippe saisonnière ou contre la grippe pandémique aux États-Unis).Les vaccinations sont notées et documentées (date, lot, fabricant, vaccinateur…) dans un carnet de vaccination et dans le dossier médical du patient.L'administration de paracétamol pour limiter des symptômes généraux (fièvre, douleur…) est à l'appréciation du prescripteur.Par abus de langage, le terme de vaccination s'applique parfois à diverses inoculations et injections sans vaccin.
Ainsi l'immunocastration des porcs est souvent présentée comme un vaccin (contre l'odeur de verrat).
En 1837, Gabriel Victor Lafargue parla de « vaccination morphinique » pour ce qui n'était qu'une injection sous-épidermique.
Dans cette catégorie se place également le vaccin de Coley (qui génère une hyperthermie destinée à détruire des tumeurs).La vaccination préventive est une forme de vaccination visant à stimuler les défenses naturelles de façon à prévenir l'apparition d'une maladie.
Elle ne cesse de voir son domaine s'élargir et peut prévenir les maladies suivantes :Au Québec, depuis le 1er janvier 2006, un vaccin contre la varicelle est offert à tous les enfants à partir de l'âge de un an.
De plus, il est maintenant combiné avec le vaccin contre la rubéole-rougeole-oreillons.La vaccination à large échelle permet de réduire de façon importante l'incidence de la maladie chez la population vaccinée, mais aussi (si la transmission de celle-ci est uniquement inter-humaine) chez celle qui ne l'est pas, le réservoir humain du germe devenant très réduit.
L'éradication de la poliomyélite de type 2 en 1999 est la conséquence des campagnes de vaccinations.
De même, pour l'éradication de la variole qui est effective depuis 1980, l'OMS avait mis en place une stratégie de vaccination de masse, alliée à une approche reposant sur la surveillance et l’endiguement (dépistage des cas, isolement des malades et vaccination des sujets contact).Aussi appelée « immunothérapie active » (ou, plus anciennement (?
), « thérapie vaccinale », « vaccinothérapie »), cette technique consiste à stimuler le système immunitaire de l'organisme pour favoriser la production d'anticorps.
Il ne s'agit donc plus de prévenir l'apparition d'une maladie mais d'aider l'organisme des personnes déjà infectées à lutter contre la maladie en restaurant ses défenses immunitaires.On a pu créditer Auzias-Turenne d'être à l'origine de la vaccination thérapeutique avec sa méthode de syphilisation, Pasteur prenant le relais avec son vaccin contre la rage.
Contrairement à une idée reçue cependant, la vaccination contre la rage n'est pas thérapeutique.
En fait, en pré-exposition (chez les personnes susceptibles d'être atteintes du fait de leur activité professionnelle par exemple) il s'agit d'une vaccination habituelle (injection de l'antigène qui va stimuler la fabrication de défenses spécifiques).
En post-exposition, c'est-à-dire après une morsure par un animal susceptible d'être enragé, il s'agit d'une immunisation passive et active.
Passive parce qu'il y a injection d'immunoglobulines (anticorps) spécifiques contre la rage et, au même moment, injection du vaccin antirabique.
Contrairement au SIDA ou au cancer, la vaccination antirabique n'est largement plus au stade expérimental.En août 1890, Robert Koch annonça avoir découvert une substance capable de guérir la tuberculose ; ce traitement à la tuberculine ne devait pas tenir ses promesses.
Un article d'Almroth Wright, publié en 1902 et intitulé Généralités sur le traitement des infections bactériennes localisées par inoculation de vaccins à base de bactéries, expliqua pour la première fois sans ambiguïté la théorie de la thérapie vaccinale.L'Organisation mondiale de la santé estime que la vaccination est l’une des interventions sanitaires les plus efficaces et les plus économiques.
Elle a permis d’éradiquer la variole, de réduire de 99 % à ce jour l’incidence mondiale de la poliomyélite, et de faire baisser de façon spectaculaire la morbidité, les incapacités et la mortalité dues à la diphtérie, au tétanos, à la coqueluche et à la rougeole.
Pour la seule année 2003, on estime que la vaccination a évité plus de deux millions de décès.Le tableau suivant montre la diminution de la mortalité en France entre avant 1950 et après 1990.
Il s'agit d'un taux de mortalité, c'est-à-dire du nombre de morts pour un million de personnes.Un plan de reconstruction au Japon ainsi qu'un plan de vaccination sont mis en place après la Seconde Guerre mondiale.
La coqueluche ravage un pays qui sort d'une guerre dévastatrice, on compte à la même année 152 072 personnes infectées par cette maladie et 17 001 morts.
À partir de 1951, le nombre de cas par an baisse tout comme le nombre de morts à la suite de la loi de vaccination préventive promulguée en 1948 et les exigences relatives au vaccin contre la coqueluche mises en place en 1949.
En 25 ans, le nombre de personnes infectées passe à moins de 400 cas par an et le nombre de morts à moins de 5 grâce à cette politique de santé.Pourtant, en décembre 1974 et janvier 1975, le gouvernement est notifié que deux enfants sont victimes d'accidents de vaccination.
Le rapport signale que l'un a contracté une encéphalopathie et que l'autre a fait un choc allergique qui lui est fatal.
À la suite de la pression de l'opinion publique, le gouvernement gèle temporairement l'obligation de vaccination pour la population japonaise.
Les effets de l'arrêt de la vaccination ne sont pas directement visibles à court terme.Néanmoins, dès 1979, le gouvernement japonais était mis au courant de 13 092 nouveaux cas.
Il s'agit ainsi d'une augmentation constante du nombre de personnes infectées par la coqueluche qui ne s'était jamais produite avant le gel du plan de vaccination, prouvant son efficacité.
Peu de temps après cet épisode épidémique, le taux de vaccination dans le pays retourne progressivement à 80 % et le nombre de nouveaux cas et le nombre de morts par an baisse à nouveau.Les effets indésirables de la vaccination dépendent d'abord de l'agent infectieux combattu, du type de vaccin (agent atténué, inactivé, sous-unités d'agent, etc), du mode d'administration (injection intramusculaire, injection intradermique, prise orale, vaporisateur intranasal, etc.) ainsi que de la nature du solvant, de la présence éventuelle d'adjuvants destinés à renforcer l'efficacité thérapeutique du vaccin et de conservateurs chimiques antibactériens.Il n'existe donc pas d'effet secondaire commun à tous les modes de vaccination.
Néanmoins, suivant les vaccins, certains effets indésirables, en général bénins, se retrouvent de manière plus ou moins fréquente.
L'une des manifestations les plus courantes est la fièvre et une inflammation locale qui traduisent le déclenchement de la réponse immunitaire recherchée par la vaccination.
Dans de très rares cas, la vaccination peut entraîner des effets indésirables sérieux et, exceptionnellement, fatals.
Un choc anaphylactique, extrêmement rare, peut par exemple s'observer chez des personnes susceptibles avec certains vaccins (incidence de 0,65 par million, voire 10 par million, pour le vaccin rougeole-rubéole-oreillons (RRO)).En France, la loi prévoit le remboursement des dommages et intérêts par l'Office national d'indemnisation des accidents médicaux lorsqu'il s'agit de vaccins obligatoires.La variole est considérée comme éradiquée depuis 1977.
La vaccination n'est donc plus du tout pratiquée même si des stocks de vaccins sont conservés en cas de résurgence.
Les complications suivantes ressortissent donc plutôt à l'histoire de la médecine :Les effets indésirables pouvant avoir lieu dans de rares cas sont surtout dus au vaccin anti-coqueluche (Per), :La première campagne de vaccination de masse anti-poliomyélite, dans les années 1950, a été marquée par la fourniture par les Laboratoires Cutter d'un important lot défectueux (virus vivant non atténué) aboutissant à près de 220 000 contaminations dont 70 000 malades, 164 paralysies sévères et 10 décès.Avant que la cause génétique de l'autisme ne soit établie, une publication a affirmé un lien entre ce vaccin et l'autisme.
Quelques années plus tard, cette étude a été récusée, son auteur Andrew Wakefield ayant reconnu la fraude sur fond de conflits d'intérêts.
Une étude de 2015 confirme qu'il n'y a aucun lien de cause à effet entre ce vaccin et l'autisme.Les effets indésirables de la vaccination contre l'hépatite B peuvent être, :Les réactions suivantes ont été observées :Cette vaccination est recommandée aussi bien chez les jeunes filles que chez les garçons.Au niveau international, l'OMS élabore des recommandations de vaccination.
Ces recommandations, non contraignantes, sont des indications de base en vue d'aider les pays membres à dresser leur propre calendrier national de vaccination, en fonction de leur situation, besoins et priorités.Ces recommandations sont explicitées par des notes de synthèse sur chaque vaccination, régulièrement actualisées.Le Plan d’action mondial pour les vaccins de 2011 à 2020 par l'Organisation Mondiale de la Santé fixe comme recommandation un taux national de 90 % de vaccination DTCoq chez les enfants.
L'Organisation des Nations unies indique que 139 des 194 États membres de l’OMS ont atteint, voire dépassé ce taux.
Malgré un progrès notable de la vaccination dans le monde, avec généralement moins d’inégalités au sein même d'un pays qu’il y a dix ans, en 2016, 10 millions d’enfants répartis dans 64 pays auraient besoin d’être vaccinés pour atteindre une couverture de 90 %.
L'ONU estime que 7,3 millions de ces enfants vivent dans un environnement précaire, de crise humanitaire ou dans un pays touché par des conflits.
C'est le cas de 4 millions d'enfants vivent en Afghanistan, au Nigeria et au Pakistan.Parmi les États membres de l’OMS, huit pays n'atteignent pas une couverture vaccinale DTCoq de 50 % : la Guinée équatoriale, le Nigeria, la République centrafricaine, le Somalie, le Soudan du sud, la Syrie, le Tchad et l'Ukraine.
Selon l'OMS et l'UNICEF, depuis 2010, le nombre d’enfants ayant une vaccination complète stagne.Au début du XXIe siècle, le plan de vaccination du pays comprend la coqueluche, la rougeole, la diphtérie, la tuberculose, le tétanos, l'hépatite B et la poliomyélite.En France, la vaccination est encadrée par différentes autorités qui ont chacune un rôle précis.
Ainsi, le ministère de la Santé élabore la politique vaccinale.
Ensuite, le Haut Conseil de la santé publique (HCSP), avec le comité technique des vaccinations, donnent des avis et des recommandations sur les vaccinations en se basant sur les connaissances scientifiques les plus récentes.
L'institut de Veille sanitaire assure la surveillance des maladies pour lesquelles il existe des vaccins.
L’agence nationale de sécurité du médicament et des produits de santé (ANSM) contrôle la qualité des vaccins et surveille le rapport bénéfice/risque des vaccins en collectant tous les effets indésirables déclarés.
Elle travaille en collaboration avec l’Agence européenne des médicaments (AEM).
La HAS, haute Autorité de santé évalue le service rendu des vaccins autorisés si le laboratoire qui les produit souhaite qu’ils soient remboursés par l’Assurance maladie.
Santé publique France (SPF), ex-INPES, placée sous la tutelle du ministère de la Santé, informe le public et les professionnels de santé sur les vaccinations nouvelles, existantes et obligatoires.En France, c'est le comité technique des vaccinations, une composante du Haut Conseil de la santé publique, qui est chargé de donner un avis sur le « calendrier vaccinal » mis à jour chaque année.
Ce dernier est établi par le ministère de la Santé et publié dans un des bulletins épidémiologiques hebdomadaires (BEH)de l'Institut de veille sanitaire (InVS) accessibles en intégralité.Plusieurs vaccins sont ainsi recommandés ou obligatoires, pour la population en fonction du lieu d'habitation, du sexe, de l'âge, des pathologies et d'autres facteurs de risque tels que la profession.
Ainsi, pour la population française, saine et non exposée à des facteurs de risque particuliers, le tableau suivant mentionne la situation en 2018, hors situation de rattrapage.Certains vaccins sont recommandés en fonction de la situation géographique, c'est le cas du BCG et du vaccin contre la fièvre jaune.
Concernant le BCG, le vaccin contre la tuberculose, une dose est conseillée pour les enfants résidant en Guyane ou à Mayotte, entre la naissance et 14 ans.
Concernant le vaccin contre la fièvre jaune, une dose est recommandée pour les enfants résidant en Guyane, à l'âge de 12 mois en lieu et place de la vaccination contre l'infection à méningocoque qui est déplacée à 16-18 mois ; par la suite, une dose de vaccin contre la fièvre jaune doit être administrée tous les 10 ans.Le calendrier vaccinal ayant fait l'objet de remaniements en 2013 et 2018, les situations de transition ou rattrapages sont prises en compte dans le document.
C'est en particulier le cas pour les vaccins les plus récemment introduits.
Ainsi, celui contre le papillomavirus humain (3 doses) peut être administré chez la fille jusqu'à 19 ans, et celui contre les infections à méningocoque (1 dose) peut être administré jusqu'à 24 ans.Pour rétablir la confiance des Français envers les vaccins, Marisol Touraine, alors ministre des affaires sociales, de la santé et des droits des femmes, a mis en place un plan d'action en septembre 2016.
Les objectifs principaux de son action sont d'informer la population des objectifs de la vaccination, de coordonner les actions pour améliorer la couverture vaccinale et d'éviter les conflits concernant l'approvisionnement des vaccins ainsi que les pénuries de ces derniers.
Le but ultime est de rendre le sujet de la vaccination important au sein des discussions citoyennes.Le calendrier est adapté à la situation chronique de pénurie de vaccins en France, toujours en 2019.Des tableaux synoptiques reprennent ce cadre et des résumés,.La Semaine européenne de la vaccination est mise en place sous l'initiative de l’Organisation mondiale de la santé en Europe depuis 2005.
Elle est un temps fort de mobilisation et d'actions pour promouvoir la vaccination et augmenter la couverture vaccinale.En France, la Semaine de la vaccination est coordonnée par le ministère chargé de la Santé publique France, et pilotée en région par les agences régionales de santé (ARS).
À cette occasion, des actions très diverses sont organisées à des endroits clés tels que les établissements scolaire et les Halles : expositions, séances d’information du public, conférences, jeux, animations, séances de vaccination gratuites, portes ouvertes, formations de professionnels… La Semaine de la vaccination est l'occasion de faire connaître le calendrier des vaccinations et pour chacun de s’informer sur ses vaccinations qui auront des bénéfices personnels et collectifs pour se protéger contre certaines maladies infectieuses.Au cours du XXIe siècle, des dizaines d'agents de santé ont été tués par des militants antivaccination ; les visites à domicile en vue d'une vaccination se font depuis sous escorte policière.À la fin des années 1980, les autorités sanitaires du Bangladesh ont décidé d'un plan de communication en faveur de la vaccination contre la polio porté par les chefs religieux du pays, appelé « mosquées porte-voix ».
Des publicités télévisées mettant en scène des célébrités bangladaises incitent la population à se vacciner.Le réseau électrique du pays n'est pas fiable et le climat est chaud, provoquant un risque de rupture de la chaîne du froid : pour pallier cela, tous les centres de santé sont équipés de panneaux solaires.
Le relais dans les espaces reculés se fait par cyclistes ou mariniers lorsque les rivières sont en crue.À noter que certaines professions (égoutiers, professions médicales, etc.) doivent avoir des vaccins supplémentaires par rapport au reste de la population.En 2010, sur 30 pays incluant les 27 pays de l'Union Européenne plus l'Islande, la Norvège et la Suisse, pour les enfants de moins de 13 ans, 16 pays n'ont aucune vaccination obligatoire : ce sont l'Allemagne, l'Autriche, Chypre, le Danemark, l'Espagne, l'Estonie, la Finlande, l'Irlande, l'Islande, la Lituanie, le Luxembourg, la Norvège, les Pays-Bas, le Royaume-Uni, la Suède et la Suisse.
Les 14 autres ont au moins une vaccination obligatoire.
Ce sont la Belgique (1 vaccin obligatoire), Bulgarie (9), France (11), Grèce (4), Hongrie (8), Italie (4), Lettonie (12), Malte (3), Pologne (8), Portugal (2), Roumanie (8), Slovaquie (9), Slovénie (7), République Tchèque (7).La vaccination contre la polio est obligatoire pour les enfants et les adultes dans 12 pays, contre la diphtérie et le tétanos (11 pays), contre l'hépatite B (10), l'hépatite A (2), HPV (1), pneumocoque (4), ROR (8), coqueluche (8), rotavirus (1), BCG (7), varicelle (1).
L'obligation vaccinale est considérée comme un moyen d'améliorer les programmes de vaccinations.
Toutefois, de nombreux pays atteignent les objectifs requis uniquement par recommandations.
Ainsi, il n’y a pas de différence significative de couverture vaccinale (taux de vaccinés) entre les pays qui recommandent et ceux qui obligent.Dès lors, le label « obligatoire » n'est pas le seul facteur permettant d'atteindre une forte couverture vaccinale en Europe.
D'autres facteurs peuvent entrer en jeu, comme l'utilisation de vaccins multivalents, le coût financier pour le pays destinataire, le type d'offre (gratuité ou remboursement, par médecin personnel ou de collectivité), les campagnes d'information et de promotion.
La diversité des politiques vaccinales en Europe tient plus à des facteurs historiques et culturels, qu'à des raisons scientifiques de santé publique.De meilleures informations sur la diversité de l'offre vaccinale au niveau européen pourraient aider les pays à adapter leurs stratégies vaccinales, en se basant sur l'expérience des autres pays.
Toutefois, cette adaptation devrait se faire aussi en tenant compte du contexte national local.En 2017, la France envisage de porter à 11 le nombre de vaccins obligatoires pour les enfants, tandis que l'Italie les porte à 12.L'arrêté du 28 février 1952 « fixant les obligations des médecins chargés des vaccinations antidiphtérique, antitétanique et antityphoparathyphoïdique et des examens médicaux préalables » — qui prolongeait l'arrêté ministériel du 20 août 1941 (JO du 10 septembre 1941) — avait instauré en France l'examen systématique des urines avant toute vaccination.
Ces dispositions, après avoir été étendues à la vaccination antipoliomyélitique par l'arrêté du 19 mars 1965 tel que paru au JO du 23 mars, ont été abrogées par la circulaire no 503 du ministère des Affaires Sociales et de la Solidarité du 3 octobre 1984.La loi du 9 août 2004 relative à la politique de santé publique, qui a créé le Haut Conseil de la santé publique (HCSP), précise que « la politique de vaccination est élaborée par le ministre chargé de la santé qui fixe les conditions d’immunisation, énonce les recommandations nécessaires et rend public le calendrier des vaccinations après avis du HCSP ».Les vaccins obligatoires sont remboursés par la sécurité sociale.
Les autorités sanitaires assurent que le rapport bénéfice/risque est suffisamment significatif.
L'inobservation des prescriptions vaccinales expose à des sanctions pénales ou administratives, notamment au retrait de l'autorité parentale, à la déscolarisation, au renvoi d'une administration, à une amende ou à une peine privative de liberté.
L'obligation de vaccination a entraîné la création de groupements de personnes opposées à son aspect systématique, par exemple la Ligue nationale pour la liberté des vaccinations qui invoque la Charte des droits fondamentaux de l'Union européenne qui instaure une clause de conscience.Depuis janvier 2018, huit vaccinations, auparavant recommandées, sont devenues obligatoires : les vaccinations contre coqueluche, Haemophilus influenzae de type b, hépatite B, pneumocoque, méningocoque de sérogroupe C, rougeole, oreillons et rubéole (les vaccinations contre diphtérie, tétanos et poliomyélite étant antérieurement seules obligatoires).
Ces 11 injections sont pratiquées, sauf contre-indication médicale reconnue, dans les 18 premiers mois, selon le calendrier vaccinal et sont exigibles pour l’entrée ou le maintien en collectivité à partir du 1er juin 2018 pour tout enfant né à partir du 1er janvier 2018.Le seul vaccin « DTP » n'est plus commercialisé par son fabricant depuis 2008, à la suite d'une recrudescence d'allergies dont il serait responsable.Les vaccins à 2, 4 et 11 mois sont en général injectés en même temps au sein d'un vaccin dit « hexavalent ».Le plan de vaccination suisse est élaboré par des experts indépendants (Commission fédérale pour les vaccinations, CFV), en collaboration avec l’Office fédéral de la santé publique (OFSP), il s'agit de recommandations qui ne sont pas obligatoires.En Suisse, la vaccination est libre ; si un vaccin est obligatoire dans un canton, pour un enfant seulement, les parents doivent justifier par écrit un refus.Depuis 2016, l'Australie prive d'une partie des allocations familiales les parents qui refusent de faire vacciner leur enfant.À la suite de l'éradication totale de la variole dans le cadre d'un programme mondial de l'OMS, le vaccin contre cette maladie n'est plus requis.
Deux souches sont cependant conservées dans des laboratoires américain et russe dans un but de recherche.La vaccination par le BCG (Vaccin bilié de Calmette et Guérin : tuberculose) n'est plus obligatoire depuis 2007.La prévalence de la tuberculose a fortement diminué en Europe entre le XIXe et le XXe siècle,.
Ce recul de la maladie serait largement dû à des facteurs autres (éloignement des malades en sanatorium, sélection naturelle des souches, amélioration des conditions de vie et d'alimentation, etc.),,.
Des études épidémiologiques d'efficacité vaccinale n'ont pas montré de recul de la maladie après des campagnes de vaccinations en Inde du sud,.
De même, on observe que la régression de la tuberculose est antérieure à la mise en place des campagnes de vaccination.Les études rétrospectives montrèrent que ces campagnes de vaccinations ne furent pas aussi systématiques que programmées.
Il est aujourd'hui admis que le vaccin BCG offre une immunisation variable, en particulier chez les jeunes adultes dans les régions tropicales.
Selon l'OMS, les études disponibles montrent que la vaccination par le BCG donne un degré élevé de protection contre les formes graves de la maladie (tuberculose méningée et miliaire).Selon les recommandations 2018 de l'OMS, dans les pays d'incidence élevée de tuberculose ou de lèpre, une dose unique de vaccin BCG doit être administrée à tous les nouveau-nés en bonne santé à la naissance.
Les pays à faible incidence de tuberculose ou de lèpre peuvent choisir de vacciner sélectivement les nouveau-nés au sein de groupes à risque.
Les pays dans lesquels les taux de tuberculose diminuent sont encouragés à passer d’une vaccination universelle à une vaccination sélective des groupes à risques.
Lors de ce passage, il est recommandé de mettre en place un système efficace de surveillance.En ce qui concerne d'autres pathologies infectieuses (comme la diphtérie, le tétanos, la poliomyélite, les oreillons, la rubéole ou la rougeole) le bénéfice de la vaccination ne fait aucun doute et les recommandations internationales maintiennent la vaccination systématique.Chercheurs à l'INED, Jacques Vallin et France Meslé précisent le bénéfice de la vaccination sur ces maladies :En 2005, les décès par pneumonie sont estimés à 2 millions d'enfants selon l'OMS.
Cela représente 18 % de la mortalité infantile totale annuelle.
L'OMS accueille favorablement le développement de vaccins efficaces pour prévenir les pneumococcies dont l'un des principaux agents sont les bactéries pneumocoques.
Selon une étude, un vaccin antipneumococcique conjugué peut réduire la mortalité et les hospitalisations pour pneumonie.Les deux principales maladies qui pourraient bénéficier d'une vaste campagne de vaccination sont la rougeole et l'hépatite virale B (chaque année, 112 000 décès pour la rougeole, 600 000 décès pour l'hépatite B).La mortalité liée à la grippe a fortement chuté depuis l'arrivée d'un vaccin plus efficace mélangeant diverse souches virales au début des années 1970 : en France, on comptait environ 1 000 morts en 2005, contre 10 000 à 20 000 (voire le double avec les complications) dans les années 1970.
En France, l'Assurance maladie prend en charge à 100 % le vaccin contre la grippe chez les personnes de plus de 65 ans (90 % des cas mortels) depuis 2003 (75 ans en 1985, date du début de la gratuité du vaccin pour cette partie de la population).Les résistances et l'opposition à la vaccination débutent dès le tournant des XVIIIe et XIXe siècles contre le vaccin d'Edward Jenner (1749-1823).
D'abord d'ordre religieux, l'opposition devient politique (défense de la liberté individuelle) lors de l'extension de l'obligation du vaccin anti-variolique au cours du XIXe siècle.
À partir de la fin du XIXe siècle, des raisons « naturelles » (de médecines alternatives) s'opposent au « pasteurisme » et à la multiplication de nouveaux vaccins (le vaccin comme inutile ou anti-naturel).Avec le consumérisme et la mondialisation des réseaux d'information, l'opposition vaccinale se manifeste entre autres, par la dénonciation de l'industrie pharmaceutique, la crainte et la polémique des effets indésirables, ainsi que par une tendance au complotisme (associant la vaccination à des volontés de profits ou de malfaisance).
Cependant, les grands arguments de fond de l'opposition ou de la résistance aux vaccins n'ont guère changé depuis le XIXe siècle ; ces arguments se perpétuent sous une forme plus moderne selon les progrès technologiques.En France, la défiance vaccinale est devenue la première au monde (45 % des Français interrogés estiment que les vaccins ne sont pas sûrs), elle est suivie par la Bosnie-Herzégovine, le Japon et la Russie « pays dont on ne voit pas immédiatement les points communs », alors que les Anglais et les Allemands ne sont que 10 %.
Cette proportion est de 13 % pour 65 000 citoyens interrogés de 67 pays.De même 20 % des Français interrogés estiment que les vaccins ne sont pas efficaces, ce qui les classe parmi les plus sceptiques avec les Italiens, les Grecs et les Russes, alors que les Anglais, les Allemands et les Américains du nord représentent 8 à 10 %, selon une vaste étude anglaise parue en 2016.La proportion de personnes opposée aux vaccinations tend à croître aux États-Unis mais reste marginale (moins de 3 % des parents aux États-Unis en 2004, avec une grande disparité régionale, cette proportion pouvant atteindre près de 20 % dans certains endroits).
Les croyances et les représentations individuelles jouent un rôle important dans la décision de se faire vacciner.
Il semble que la conviction des professionnels de santé sur l'importance de la vaccination joue un rôle important sur la perception du public à ce sujet.Les sites de vulgarisation médicale sont souvent visés via leurs forums (doctissimo, etc.).
Les activistes anti-vaccinalistes profitent de discussions pour aiguiller certaines personnes vers leurs sites web (nombreux liens hypertextes utilisés dans les signatures et se répétant sur tous leurs messages).
Un petit nombre d'activistes intervient alors dans les sections « vaccinations » de différents sites web d'informations anti-vaccinalistes, faisant alors penser aux utilisateurs que leurs références sont nombreuses et légitimes.Les réseaux sociaux sont aussi largement utilisés, ils permettent un accès large et un recrutement facile de profils.Les sites de partage en ligne sont également largement inondés de vidéo anti-vaccinalistes.
Cette technique permet de submerger les décideurs (les parents) d'informations négatives sur la vaccination, faisant passer les informations médicales validées au second rang.
Ainsi, la mise en avant des effets secondaires négatifs par les médias n'incitent pas les consommateurs à se faire vacciner.Ces discours anti-vaccinalistes sont de plusieurs types, correspondant à des niveaux différents de débats.
Le discours politique met en avant la liberté vaccinale (refus des obligations vaccinales), la corruption financière, et l'inutilité des vaccins mis en opposition avec les autres moyens de santé publique.
Ce discours rejoint des thèmes naturalistes de dénigrement de la science et de la médecine, de négation des progrès de santé attribuables à la vaccination, en matière de santé des dernières décennies, ou sur le caractère bénin des maladies infantiles d'où il découle qu'il est plus sûr, ou plus naturel, de les contracter que de faire vacciner.Un discours pseudo-scientifique liste des ingrédients potentiellement toxiques (en dénigrant/niant les études de sécurité réalisées) ; ou détourne les résultats des études scientifiques par un biais de confirmation (cherry picking) par exemple en mettant en exergue un article qui alerte sur un risque potentiel en niant les dizaines d'autres qui le démentent par la suite.Depuis la fin du XIXe siècle, les méthodes utilisées par l'antivaccinalisme sont le témoignage, les arguments basés sur photographies ou vidéo, sur l'émotion, le simplisme et le « bon sens » (coïncidence confondue avec la causalité).
Sur le net, une nouvelle forme de discours tactique est apparue qui consiste à se soustraire de l'étiquette « antivaccin » en se présentant comme un partisan de vaccins plus sûrs, seulement soucieux de questions légitimes, comme le fait que les vaccinations ne seraient pas suffisamment étudiées.Il y aurait ainsi des « antivax » radicaux (qui condamnent la vaccination) et des antivax « opportunistes » ou de circonstance qui refusent les recommandations vaccinales, à propos de tel ou tel vaccin, ou telle modalité, en arguant de leur liberté personnelle de choisir leurs risques.
Cette attitude individualiste s'oppose au principe de responsabilité collective.L'antivaccinisme se présente alors comme un discours irréfutable, inexpugnable dans sa logique interne.
Il révèle toutefois d'importantes problématiques sociales contemporaines comme les rapports individu/société, nature/culture, résistance/soumission au biopouvoir, les places respectives public/privé, les rapports à l'information…« Reste à savoir où et comment se règleront les questions d'autorité et de légitimité  Reste à trouver une gouvernance acceptable et efficace pour la vaccination du XXIe siècle ».
« Phagocyte » (aussi appelé « cellule phagocytaire ») signifie « cellule mangeuse ».
On les appelle parfois éboueurs de l'organisme.
Les phagocytes ou « cellules phagocytaires », sont en effet des cellules pouvant ingérer et détruire des particules de taille variable (de l'échelle nanométrique à micrométrique), qui sont par exemple des microbes, des cellules altérées, des tissus sanguins ou des particules étrangères à l'organisme.Les phagocytes jouent un rôle essentiel contre les infections, essentiellement bactériennes, mais ils participent aussi à l'élimination des micro et nanoparticules étrangères qui pénètrent l'organisme.
Ils participent aux processus inflammatoires.Le terme « phagocyte » est habituellement utilisé pour les organismes animaux, dont celui de l'être humain, mais des processus comparables à la phagocytose existent chez d'autres organismes vivants.Ces cellules peuvent se déformer et émettre des prolongements (pseudopodes), qui emprisonnent la particule de manière à permettre son ingestion par inclusion progressive dans le phagocyte où elle est enfermée à l'intérieur de leur cytoplasme, dans une sorte de poche (« la vacuole de phagocytose ») où des organes spécialisés de la cellule, les lysosomes, vont sécréter des enzymes lytiques capables de dégrader la matière vivante pour détruire la particule ou cellule ingérée.
L'ensemble de ce processus s'appelle la phagocytose.
Le plus souvent, les macrophages éliminent totalement les microbes présents au niveau d'une plaie ou d'un site infecté.
Parfois, les microbes résistent à la phagocytose ; l'infection peut alors progresser.Si les microbes détruisent les neutrophiles ou que ces derniers sont très nombreux et en fin de vie, il y a formation de pus (abcès ou production externe).Les phagocytes sont :70 % d'entre eux sont des granulocytes, 5 % d'entre eux des macrophages issus de la différenciation de monocytes, et le reste est composé de cellules dendritiques.
La microscopie en fluorescence (ou en épifluorescence) est une technique utilisant un microscope optique en tirant profit du phénomène de fluorescence et de phosphorescence, au lieu de, ou en plus de l'observation classique par réflexion ou absorption de la lumière visible naturelle ou artificielle,.On peut ainsi observer divers objets, substances (organiques ou inorganiques) ou échantillons d'organismes morts ou vivants.Elle fait désormais partie des méthodes de recherche classiques et de la biologie et continue à se développer avec l'imagerie moléculaire.La fluorescence est la propriété que possèdent certains corps d'émettre de la lumière après avoir absorbé des photons de plus haute énergie.
La microscopie en fluorescence repose sur la formation d'une image par détection de cette lumière émise.Le déplacement de Stokes décrit la différence entre la longueur d'onde absorbée par l'objet (émise par la source lumineuse du microscope) et émise par l'objet.
Plus la différence entre les deux longueurs d'onde est grande plus il est facile d'observer la fluorescence.En fluorescence on distingue deux types d'objets : En microscopie de fluorescence, on peut donc visualiser directement des substances fluorescentes.
Pour des substances, des cellules, des molécules non fluorescentes, il est nécessaire de les marquer par des substances appelées fluorochromes, comme le DAPI qui marque l'ADN et fluoresce en bleu.Certains marqueurs génétiques comme la protéine fluorescente verte, (en anglais Green Fluorescent Protein ou GFP) sont aussi très utilisés en biologie dans des organismes génétiquement modifiés pour en produire de manière endogène.Dans ce cas, le fluorochrome est une protéine produite directement par la cellule elle-même et ne nécessite pas l'ajout de substrat.
La fluorescence peut alors être visualisée directement dans les cellules vivantes, c'est un des domaines développés par l'imagerie moléculaire.De nombreuses techniques de marquage peuvent être utilisées :On peut exciter les substances fluorescentes par une excitation monophotonique.
On utilise pour cela une lumière d'excitation dont la longueur d'onde excite directement le fluorophore.
Donc, la fluorescence émise peut provenir de toute l'épaisseur de l'échantillon traversée par le faisceau d'excitation.
L'élément clé de ce microscope confocal est alors représenté par une « fenêtre » (un sténopé ou un iris confocal) placée devant le détecteur qui élimine la fluorescence provenant des régions non focales.
L'observation de signaux de fluorescences repose sur cinq éléments :Cette excitation consiste en l'absorption quasi simultanée de plusieurs photons d'excitation d'une longueur d'onde proche d'un multiple de l'excitation optimale à un photon.
On utilise pour cela un laser pulsé dans des fréquences proches de l'infrarouge.
Dans ce cas, seul le point de focalisation du faisceau laser est excitateur (densité de photon suffisante pour coupler l'énergie d'excitation).
Bien souvent les applications sont limitées à la microscopie biphotonique (excitation du fluorophore par deux photons).Ce système est considéré comme une évolution technologique importante pour trois raisons majeures : En pratique, le rendement d'émission de fluorescence est moins bon qu'un confocal simple photon et le rapport signal/bruit est plus faible.
Ainsi, il ne montre que peu d'avantage pour l'observation de cellules en culture ou de coupes de tissu (50-70 µm d'épaisseur).Cette technique est naturellement utilisée pour l'excitation simultanée de plusieurs fluorophores à spectres d'émission différents.Une variante de cette technique est la « microscopie à fluorescence par excitation multiphotonique multifocale ».
Le principe est identique, mais le faisceau laser est divisé en plusieurs faisceaux ce qui permet de balayer simultanément plusieurs points.
Ceci permet de diminuer le temps d’acquisition des images.Les techniques de fluorescence peuvent être utilisées avec différents types de microscope :Ces appareils possèdent des pièces interchangeables en forme de cube disposées sur une tourelle rotative ou sur une tirette selon les fabricants.Ces « cubes » filtrent la lumière allant vers l'objectif et allant vers l'observateur ou le capteur, selon les fluorescences recherchées.Ils comportent deux filtres et un miroir particulier, « dichroïque » qui réfléchit certaines longueurs d'onde et qui est traversé par d'autres.Vers la source se trouve le filtre d'excitation.Côté observateur se trouve le filtre barrière.Les cubes sont répertoriés selon les lumières d'excitation: ultraviolet, violet, bleu, vert...On utilise cette technique, notamment pour observer des monocouches lipidiques auxquelles on a ajouté une sonde lipidique fluorescente.
On observe une fluorescence selon la phase dans laquelle se trouve le lipide principal.
En général, la sonde est soluble dans la phase liquide-expansé (LE) mais pas dans les phases gazeuse (G) ou solide (S).
Ceci permet d'observer les macrostructures formées par la monocouche.
Ci-contre, on observe une monocouche lipidique à l'équilibre par microscopie à épifluorescence.
La sonde fluorescente lipidique est soluble dans la phase LE mais pas dans la phase G. Le résultat est qu'on observe, à l'équilibre, des sortes de bulles (mais une « bulle » est un concept tridimensionnel) dont les parois sont constituées du lipide en phase LE et l'intérieur en phase G. Si l'on prend un exemple tridimensionnel, cela reviendrait à prendre de la mousse de savon et à en couper une très fine tranche.
Un pont disulfure (liaison S-S) est une liaison covalente qui se forme par oxydation dans les protéines, de manière post-traductionnelle ou par des agents oxydants mis en œuvre par l'homme.
Cette liaison se forme entre les atomes de soufre des fonctions thiol de deux cystéines dans une séquence peptidique (ou protéine) (voir la figure ci-dessous où les groupes R représentent le reste de l'acide aminé).
La molécule résultante de la liaison de deux cystéines est la cystine.Le pont disulfure est un élément des structures tertiaires (après le repliement de la protéine) ou quaternaire (lors d'association de sous-unités protéiques) de la protéine.
La formation d'un pont disulfure à partir de deux cystéines s'accomplit spontanément en conditions oxydantes, en particulier en présence de dioxygène.
Les ponts disulfures ne se forment en général pas dans le cytoplasme, qui est un environnement réducteur, mais lorsque les protéines sont sécrétées ou exposées à la surface cellulaire.En biochimie, la réduction d'un pont disulfure peut se faire en présence de réducteurs doux, tels le 2-mercaptoéthanol ou le dithiothréitol (DTT ou réactif de Cleland).C'est une liaison nécessaire à la stabilisation de la structure de certaines protéines : certaines petites protéines comme les toxines présentes dans le venin de reptiles ou de scorpions ne peuvent atteindre une conformation active que parce que des ponts disulfures verrouillent leur structure.Dans la ricine, le pont disulfure relie deux chaines A et B de fonctions complètement différentes.
La chaîne B permet à la toxine de se fixer à la paroi cellulaire et la chaîne A, responsable des propriétés toxiques, est capable d’inhiber la synthèse des protéines en attaquant l'ARN des ribosomes, entraînant la mort cellulaire.
La destruction du pont disulfure rend la toxine complètement inactive (elle ne peut plus pénétrer la cellule).Dans d'autres protéines, les ponts disulfures servent à maintenir la liaison entre les différentes chaînes peptidiques ou sous-unités.
C'est le cas pour les anticorps produits par les cellules du système immunitaire.
Ceux-ci sont composés de quatre chaînes, deux lourdes et deux légères, reliées par des ponts disulfures.
C'est également le cas de l'insuline qui est composée de deux chaînes comportant trois ponts disulfures, nécessaires à l'activité de cette hormone.Enfin, dans quelques cas spécifiques, on trouve un pont disulfure dans le site actif de certaines enzymes ou protéines impliquées dans des processus d'oxydoréduction ou de transport d'électron.
C'est le cas par exemple des thiorédoxines qui participent à l'homéostasie de l'état redox de la cellule.Certaines peptidases comme la kératinase ou la trypsine du pancréas s'attaquent spécifiquement à ce pont et permettent la digestion de substances protéiques comme la fibrine, la lysine, l'arginine ou le collagène.Dans les protéines contenant un grand nombre de cystéines, l'agencement correct des ponts disulfures nécessite parfois l'intervention d'une enzyme spécifique possédant une activité protéine disulfure isomérase (PDI).
Ce processus est effectué par les protéines du réticulum endoplasmique rugueux (RER) mais pas dans le cytosol.
Le cytosol des cellules est en effet un environnement très réducteur, et conséquemment les protéines cytoplasmiques contiennent donc peu ou pas de ponts disulfures.
On en trouve surtout dans les protéines exportées dans d'autres compartiments cellulaires ou hors de la cellule.
On en trouve également dans les domaines extracellulaires de protéines membranaires, ils interviennent en particulier dans l'oligomérisation des sous-unités de certains récepteurs comme le récepteur de l'insuline.Les bases fortes et les acides forts ont le pouvoir de détruire les ponts disulfures.Les ponts disulfure sont aussi sensibles aux réactions d'oxydo-réduction d'où les usages dans la coiffure.Les cheveux sont constitués à 90 % de kératine liée entre elle par des ponts disulfures, dont le nombre et l'emplacement donnent aux cheveux leur forme.
Une permanente consiste en deux réactions chimiques successives.
La première (une réduction) rompt un certain nombre de ponts disulfures.
La structure de la protéine est relâchée.
On enroule alors le cheveu selon la forme voulue.
Cette opération amène en face les unes des autres des cystéines qui, à l'origine, étaient éloignées.
La deuxième réaction (une oxydation) refait donc des ponts entre des cystéines qui ne se seraient jamais rencontrées naturellement : c'est le processus de la permanente.
La protéine prend la forme ondulée imposée par la coiffeuse ou le coiffeur.Les réactions employées pour friser un cheveu lisse peuvent évidemment être utilisées pour étirer un cheveu frisé.
Comme la destruction et la formation des ponts disulfures sont deux réactions faciles à faire ; comme d'autre part, le cheveu pousse selon sa forme naturelle, la frisure ne dure qu'un temps limité.
Ceci n'est qu'une explication simplifiée de la structure du cheveu.
En effet d'autres molécules sont associées à la kératine, en particulier des pigments.La formation des ponts disulfures est responsable de la coagulation des viandes et des œufs.
Le chauffage provoque la dénaturation thermique des protéines globulaires du lait ou des protéines fibreuses (chaînes de collagène) de la viande, ce qui expose les groupes portant les atomes de soufre et conduit à leur association par des liaisons disulfure.
Lors de la confection des pâtes de pâtisserie ou des pâtes à pain, le pétrissage fournit l'énergie mécanique qui permet aux protéines insolubles (gliadines et gluténines du blé) de se lier entre elles par un réarrangement des ponts disulfures intra- et inter-moléculaires.
Il se forme alors un réseau de gluten : la gélification des protéines est à l'origine d'un gel, réseau protéique tridimensionnel complexé avec les lipides de la farine et certains composés glucidiques, emprisonnant les grains d'amidon et les bulles d'air.
La structure tridimensionnelle de la matrice de gluten est stabilisée par des liaisons non covalentes (liaisons hydrogènes, interactions hydrophobes et liaisons ioniques) et essentiellement covalentes (ponts tyrosine-tyrosine et surtout liaisons disulfures formées suite à l'oxydation des groupements SH sous l’action des enzymes de la farine ainsi que de ses agents oxydants),.Les ponts disulfures sont aussi à la base d'un procédé chimique appelé vulcanisation permettant le durcissement des caoutchoucs.
Le caoutchouc naturel ou synthétique sans additif est une matière trop molle pour de nombreuses utilisations actuelles.
Le procédé de vulcanisation consiste à introduire divers additifs dont du soufre dans le caoutchouc avant une cuisson à haute température.
Lors de ce procédé, le soufre forme des ponts disulfure intra et inter moléculaire ce qui va lier entre eux les chaînes de polymère du caoutchouc, leur donnant ainsi des propriétés de dureté tout en conservant une certaine élasticité au matériau.
Les procédés exacts de cuisson et d'ajout du soufre sont tenus secrets par les transformateurs car c'est la concentration en soufre et la température de cuisson qui détermine, en grande partie, les propriétés physiques du caoutchouc vulcanisé.
Nature est une revue scientifique généraliste de référence, à comité de lecture et publiée de manière hebdomadaire.
C'est l'une des revues scientifiques les plus anciennes et les plus réputées au monde.
Elle a été lancée en 1869 par le Britannique Joseph Norman Lockyer avec une vocation d'excellence dans tous les domaines des sciences dites dures — physique, mathématiques, chimie, biologie, génétique — mais aussi dans de nombreuses sciences dites exactes comme la paléontologie, la géologie, les sciences de l'évolution, l'archéologie, voire dans certains aspects des sciences sociales.La visibilité de Nature se traduit par son facteur d'impact à deux ans qui, en 2016, est de 43,769.
En 2007, Nature est corécipiendaire, avec la revue américaine Science, du prix Princesse des Asturies de la communication, une première pour une revue scientifique.Elle est publiée par le groupe de presse britannique Nature Publishing Group (fusionné depuis 2015 avec Springer Science+Business Media) et l'actuel directeur de publication est Magdalena Skipper.La revue est fondée en 1869 par le scientifique et astronome britannique Joseph Norman Lockyer.
Écrivant des articles scientifiques dans la revue The Reader, lorsque cette dernière cesse de paraître, il a l'idée de créer un magazine scientifique en s'associant avec l'éditeur Alexander MacMillan (en).Le sous-titre du journal « A weekly illustrated Journal of Science » suggère que la publication s'adresse à un public de non spécialistes.
Son but est annoncé dans le premier numéro paru le 4 novembre 1869 : il est « de présenter au grand public les principaux résultats du travail scientifique et de la découverte scientifique ; et de favoriser la reconnaissance générale des valeurs de la Science dans l'Éducation et la Vie quotidienne ».La revue ne compte que de 100 à 200 abonnés au départ.Au XXIe siècle, le titre londonien constitue, avec son rival américain Science, la plus prestigieuse des revues scientifiques généralistes, mais elle soulève bien des critiques.
En 2013, la déclaration de San Francisco sur l'évaluation de la recherche milite contre les emplois abusifs du facteur d'impact qui mesure la renommée d'une revue, pas celle des articles et des chercheurs qu'elle publie.
Ainsi la publication dans Nature en 2001 de l'article historique décrivant le séquençage du génome humain, cité depuis plus de 10 000 fois, a valu et vaut toujours au titre de posséder le facteur d'impact le plus élevé.
La concurrence en termes de prestige et de publicité entre ces deux revues peut les conduire à privilégier les « hot papers » portant sur les domaines les plus controversés (cellules-souches, OGM, réchauffement climatique, etc.), ce qui leur assure d'être abondamment citées et une grande audience.
La politique éditoriale de Nature peut ainsi favoriser la course à la publication d'articles suscitant un fort intérêt (dilemme du « publier ou périr »), ce qui vaut à la revue d'être surnommée le « Voici du monde scientifique ».En octobre 2020, alors que Donald Trump et Joe Biden briguent tous deux le poste de président des États-Unis, la revue donne son soutien à Biden.
Elle a déjà exprimé auparavant sa préférence pour Barack Obama (2012) puis Hillary Clinton (2016), mais pas d'une façon aussi « incisive ».Cette section contient une liste de parutions remarquables de Nature :Nature, comme toute revue, a également publié des résultats polémiques et qui se sont rapidement révélés incorrects, comme la mémoire de l'eau.En plus du titre principal Nature, le Nature Publishing Group publie différents Nature spécialisés par branche de recherches, comme Nature Genetics ou Nature Physics (liste complète).
L'année 2015 est une année commune qui commence un jeudi.
C'est la 2015e année de notre ère, la 15e année du IIIe millénaire et du XXIe siècle et la 6e année de la décennie 2010-2019.L'année 2015 du calendrier grégorien correspond aux dates suivantes :2015 est la 3e année la plus chaude depuis le début des relevés (1850), a été confirmée comme marquée par une température moyenne de 1,1 °C de plus que  la période préindustrielle 1850-1900 à exequo avec 2017.L'année 2015 fut la plus chaude depuis 1880 selon la NOAA et la NASA, dépassant le record précédent de 2014 .
Le phénomène El Niño y fut si intense que les météorologues américains l’ont baptisé avec humour « Bruce Lee ».« Le trou de la couche d'ozone de 2015 a été l'un des plus graves jamais enregistrés en ce qui concerne la superficie maximale, et le déficit intégré et a été particulièrement durable, avec de nombreuses valeurs supérieures aux extrêmes précédents en octobre, novembre et décembre ».
Ceci a été ensuite (en 2019) attribué à des conditions très froides en altitude, et aux effets d'aérosols issus de l'éruption du volcan Calbuco (Chili) en avril 2015.Les lauréats du Prix Nobel en 2015 sont :
Le système Rhésus (parfois appelé groupe) est, avec le système ABO, un des principaux systèmes antigéniques érythrocytaires.
Il doit son nom à un singe d'Asie du Sud-Est, Macaque rhésus (Macaca mulatta), qui servit d'animal d'expérience à la fin des années 1930 dans les recherches sur le sang.
L'association du système antigénique érythrocytaire ABO et du système Rhésus définit les groupes sanguins.Le système antigénique érythrocytaire (Rh) est l'un des 36 systèmes antigéniques érythrocytaires humains connus.
C'est le deuxième système antigénique érythrocytaire le plus important, après le système antigénique  ABO.Les globules rouges présentent à leur surface des antigènes qui varient suivant les personnes.
Un antigène est une macromolécule naturelle ou synthétique qui, reconnue par des anticorps ou des cellules du système immunitaire d’un organisme, est capable de déclencher chez celui-ci une réponse immunitaire.Le système rhésus fait référence spécifique à un de ces antigènes.
Cet antigène est désigné par la lettre D,.
La présence de cet antigène correspond au rhésus positif et l'absence de cet antigène correspond au rhésus négatif.
Si du sang rhésus positif est injecté chez un individu rhésus négatif, celui-ci fabriquera des anticorps anti-rhésus, ceux-ci peuvent agglutiner du sang du macaque rhésus,, ainsi que des personnes Rh+.Le système antigénique Rh comprend en réalité 49 variétés connues de l'antigène, parmi lesquels les cinq antigènes D, C, c, E et e sont les plus importants (D est le plus important).
Le statut Rh(D) d'un individu est normalement décrit par un suffixe positif ou négatif après le type ABO (par exemple, une personne qui est A Positive possède l'antigène A et l'antigène Rh(D), alors qu'une personne qui est A Négative n'a pas l'antigène Rh(D)).
Les termes facteur Rh, « Rh positif » et « Rh négatif » font uniquement référence à l'antigène Rh(D).Les transfusions sont possibles de Rh- vers Rh+ mais pas de Rh+ vers Rh-.
Autrement dit, les personnes ne possédant pas l'antigène et dont le sang est mis en contact avec celui-ci vont développer une réaction immunitaire contre les globules rouges possédant l'antigène et les détruire.Les anticorps anti-RHD sont des anticorps irréguliers de type IgG, acquis à l’occasion d’une transfusion ou d’une grossesse.
Lorsque les globules rouges n’ayant pas l’antigène D, des anticorps contre cet antigène peuvent être produits par l’individu dans le cas d’une exposition.Les anticorps aux antigènes Rh peuvent être impliqués dans des réactions transfusionnelles hémolytiques et les anticorps aux antigènes Rh(D) et Rh(c) confèrent un risque significatif de maladie hémolytique du fœtus et du nouveau-né.La présence du seul antigène e (donc Rh+) entraîne chez une personne transfusée Rh- la production d'anticorps qui vont détruire ses globules rouges.
C'est pour cela qu'il n'est possible de transfuser que des personnes ayant le même groupe ABO et le même rhésus que le receveur.Le nom Rhésus vient de l'extraction du premier sérum test obtenu à partir du sang de lapins traités avec des érythrocytes de singes rhésus (Macaca mulatta).
Les scientifiques ont donc découvert par hasard ce groupe sanguin en premier chez les singes rhésus.
Le terme « Rh » était à l'origine une abréviation de « facteur Rhésus ».
Il a été découvert en 1937 par Karl Landsteiner et Alexander S. Wiener, qui, à l'époque, pensaient qu'il s'agissait d'un antigène similaire présent dans les globules rouges du singe rhésus.
On a appris par la suite que le facteur humain n'est pas identique au facteur du singe rhésus, mais à cette époque, le « groupe Rhésus » et d'autres termes similaires étaient déjà largement utilisés dans le monde entier.
Ainsi, bien qu'il s'agisse d'une appellation erronée, le terme survit.Certaines formes de molécules Rhésus se retrouvent dans la plupart des formes de vie.
Le facteur Rhésus a une origine très ancienne.
Il pourrait descendre d'une molécule appelée protéine de transport de l'ammonium (Amt).
L'Amt se trouve dans tous les êtres vivants, y compris l'Archaea, qui est probablement la plus ancienne forme de vie sur Terre,.
85 % des Suisses ont l'antigène RHD et sont donc rhésus positif.
Les chiffres sont similaires dans la population française, 85 % des personnes sont rhésus positif contre 15 % rhésus négatif.Il existe deux systèmes antigéniques érythrocytaires rhésus : le système antigénique + et -.
L'existence de l'antigène rhésus, suspectée en 1939 par Philip Levine et Rufus E. Stetson, a été découverte par Karl Landsteiner et Alexander Solomon Wiener en 1940.
Leur idée initiale était de mettre en évidence une communauté antigénique entre le singe et l'homme, par immunisation d'un animal afin d'obtenir un sérum test comme cela avait été fait antérieurement pour les antigènes M, N et P1 en 1927.L'expérience a consisté à immuniser un cobaye lapin avec des érythrocytes de singes, et à tester le sérum de ce cobaye ainsi obtenu vis-à-vis de globules rouges humains.Ils ont alors constaté que les globules rouges humains s'agglutinent ou non en présence du sérum de ce cobaye immunisé par des globules rouges de singe rhésus.
Ce sérum contient des anticorps dit anti-rhésus.
Ce même sérum donne une réaction d'agglutination avec les érythrocytes de 85 % environ des sujets testés dans la population caucasoïde.
On dit alors que le sang de ces sujets est rhésus positif (Rh +) ou rhésus négatif (Rh -) dans le cas contraire.Dans la réalité, on s'est rendu compte plus tard que ce sérum test ne reconnaissait pas exactement le même épitope que l'anticorps rencontré chez les sujets rh négatif immunisés décrits par Levine en 1939, et était en fait un anti-LW.
Cette protéine fut nommée, sur proposition de Levine, LW (également ICAM4), faisant partie du complexe membranaire RH avec RHD, RHCE, Rh50 (RHAG), CD47, GPB (glycophorine B, système MNS) à la surface de l'érythrocyte, du nom des auteurs de cette expérience initiale, Landsteiner et Wiener.
Cependant le nom d'origine, rhésus, qui avait déjà donné lieu à de nombreuses publications, a été conservé, et ne s'applique en fait plus à l'épitope initialement découvert, mais à l'épitope Rhésus D ou RH1 dans la nomenclature internationale.En ce qui concerne les nomenclatures RH, il en existe trois, dont deux historiques, mais toujours utilisées.La première, dite nomenclature Wiener, utilise Rh pour les Rhésus positif standard D et rh pour les rhésus négatifs.
R et r représentent les gènes (écrits en italique ou soulignés), Rh et rh les phénotypes (antigènes en caractères romains).
Wiener pensait que ce système ne comportait qu'un gène, à un seul locus, avec plusieurs allèles.La seconde, dite nomenclature de Fisher et Race, est apparue lors de la découverte des autres antigènes du système C, c, E et e. D correspond à l'antigène Rh.
Fisher (statisticien) et Race (immuno-hématologiste) raisonnaient sur trois gènes, à trois locus étroitement liés, avec 2 allèles chacun (D/d, C/c, E/e).Il existait donc la correspondance suivante entre les haplotypes des deux nomenclatures, avec leur fréquence génique constatée en France : et la correspondance suivante des phénotypes : pour le génotype Wiener R1/r, le génotype Fisher Race DCe/dce et les phénotypes correspondants Rh1rh = DCcee.
Inversement on remarquera qu'à un phénotype peuvent correspondre plusieurs génotypes possibles.
Ainsi un sujet DCcEe peut avoir pour génotypes : DCe/DcE = R1/R2 (le plus fréquent en France), DCE/Dce = Rz/R0, DCE/dce = Rz/r, DCe/dcE = R1/r", DcE/dCe = R2/r', Dce/dCE = R0/ry, alors qu'un sujet ddCcee ne peut être que de génotype dCe/dce = r'/r.La troisième nomenclature, actuelle (de R.E. Rosenfield et coll.
au départ), numérique :D = RH1, C = RH2, E = RH3, c=RH4, e = RH5, ... Cw = RH8...G = RH12 ...jusqu'à plus de 50.Cette nomenclature, contrairement aux précédentes, ne préjugeait pas de la génétique sous-jacente.
Il est maintenant connu qu'il y a deux locus avec le gène D ou d (gène d en fait inexistant) au premier locus RHD, et le gène CE synthétisant une protéine avec les deux épitopes (C-c, E-e) au second locus RHCE.
Ces deux gènes, d'orientation opposée, les exons 10 étant proches, sont situés sur le chromosome no 1, en 1 p36.2-p34.Ainsi, un sujet Rh1rh' (Wiener) sera DCCee (Fisher Race) et RH(1,2,-3,-4,5) maintenant.Ces trois nomenclatures sont toujours utilisées dans le milieu transfusionnel, selon les endroits et les us et coutumes locales.
Il est plus simple de demander un « R1 petit r » ou un « moins 3 » qu'un « Grand D, grand C, petit c, petit e, petit e » ou qu'un « RH 1, 2, moins 3, 4, 5 ».
Bref, on pense en Fisher Race, on parle en Wiener (génotype probable) ou en numérique abrégé, en n'indiquant que les antigènes absents, et on écrit en numérique.Les protéines RH sont codées par deux gènes, RHD et RHCE, étroitement liés, située sur le chromosome 1 en 1p36.13-p34.3 séparés de 30 kilobases contenant le gène SMP1 (small membrane protein 1), orientés tête-bèche selon la séquence : centromère-....-5'-Rh box-RHD-3'-Rhbox-gène SMP1-3'-3'-RHCE-5' en 1p34.3-p36.13.
Ces deux gènes, présentant 96 % d'homologie, sont composés de 10 exons chacun, les exons 1 à 7 codant 50 à 60 AA chacun, les exons 8 à 10 codant les 58 derniers AA C-terminaux.
Une délétion de RHD est responsable du phénotype RH:-1 (dd).
Un troisième gène homologue RHAG localisé sur le chromosome 6 en 6p11-p21.1 code la glycoprotéine associée au RH (Rh-associated glycoprotein) RHAG ou RH50, essentielle pour l'expression des antigènes Rhésus.
Ce gène a dix exons répartis sur 30 kilobases.
Quoique présentant une forte homologie, la glycoprotéine RHAG, dont la localisation du gène est différente, ne peut faire partie du système rhésus.
Du fait de la forte homologie entre les deux gènes RH, indépendamment des mutations ponctuelles, expliquant par exemple le polymorphisme C/c (Cys16Trp, Ile60Leu, Ser68Pro et Sr103Pro), E/e (Pro226Ala) ou Cw (Gln41Arg) de la protéine RHCE, de nombreuses translocations ont eu lieu, de telle sorte que diverses molécules hybrides ont été observées, un ou des exons de l'un étant échangés avec les exons homologues de l'autre.
Il existe ainsi, comme dans le système MNS, des gènes RH(D-CE-D), ou RH(CE-D-CE).
Ces gènes hybrides expliquent les nombreux variants rencontrés dans le système Rhésus, certaines molécules ayant perdu un ou des antigènes, et en en ayant acquis d'autres.
C'est ainsi que 54 antigènes différents sont homologués par la Société internationale de transfusion sanguine dans le système RH, du no 001 à 053, les nos 013 à 016, 024, 025 et 038 n'étant plus attribués à un antigène particulier.Les deux protéines RHD et RHCE, de 417 AA chacune, se situent dans la membrane de l’érythrocyte qu'elles traversent à douze reprises, les C et N terminaisons étant intracytoplasmiques.
Ces protéines ne sont pas glycosylées, mais portent 3 acides palmitiques intramembranaires.Dans la nomenclature Fisher-Race, l'allèle D est évidemment dominant par rapport à d, dont nous savons maintenant qu'il s'agit d'une délétion.
Les allèles C / c d'une part et E / e d'autre part sont codominants.
Ainsi deux parents d / d ne pourront pas avoir un enfant D, RH:1, mais deux parents D / d (Rhésus positif standard D, RH:1) pourront avoir un enfant d / d (Rhésus négatif) avec une probabilité de 25 %.
Deux parents C / c pourront avoir des enfants présentant l'un des trois génotypes possibles C / C, C / c ou c / c.
Le même raisonnement s'applique aux allèles E et e. Il est évidemment plus simple de raisonner sur les haplotypes.
Deux parents DCe / dce et DcE / dce pourront avoir des enfants DCe / DcE, DCe / dce, DcE / dce et dce / dce.Cependant, comme dans pratiquement tous les systèmes de groupes sanguins (ABO, MNs, FY, JK, DO…), il est possible de rencontrer d'apparentes exclusions de paternité ou de maternité.Il existe ainsi un rarissime haplotype RHnull dans le système Rhésus.
Cet haplotype, qui ne synthétise aucune des deux protéines RH, ni RHD, ni RHCE, est noté RH:---.
Supposons un père déterminé comme D+, C+, E-, c-, e+, c'est-à-dire possédant les antigènes D, C, et e, et ne possédant pas les antigènes c et E. Nous en déduisons le génotype vraisemblable de ce père comme étant DCe / DCe, ou DCe / dCe.
Or, ce père, uni à une femme de génotype dce / dce, pourra avoir un enfant D-, C-, E-, c+, e+, c'est-à-dire ne possédant pas l’antigène attendu C.
Cet enfant sera considéré à tort comme de génotype dce/dce.
Nous constatons alors une apparente exclusion de paternité, l'enfant étant supposé avoir reçu un haplotype dce qui n'existe pas chez son père.
Or ceci peut être parfaitement expliqué par le génotype DCe / --- de ce père, qui a transmis son haplotype « --- » à son enfant dont le génotype réel est dce / --- .En conclusion, une anomalie apparente de transmission d’un groupe sanguin ne permet en aucune façon à elle seule de conclure à une exclusion de paternité ou de maternité.
Une telle conclusion doit s’appuyer sur plusieurs systèmes, et maintenant sur la biologie moléculaire (analyse directe au niveau des chromosomes).Les gènes RHD et RHCE étant étroitement liés, nous devons considérer la fréquence des haplotypes dans une population plutôt que la fréquence des divers allèles de chaque gène.
Ces fréquences haplotypiques permettent de retrouver facilement les fréquences phénotypiques, selon le principe de Hardy-Weinberg visualisé par l'échiquier de Punnett, dans les populations concernées.Pour la France, les haplotypes DCe (0.42527) et DCwe (0.00264) ont été regroupés en DCe (0.4279)À l'origine, était considéré comme de phénotype Du un groupe Rhésus donnant de faibles réactions avec les réactifs habituellement utilisés pour déterminer le groupe sanguin RH1, D.
Cette recherche était faite par une technique à l'antiglobuline, voire par une technique de fixation-élution.
Compte tenu de l'amélioration des réactifs (anticorps monoclonaux, réactifs qui ont l'avantage d'être très puissants, mais l'inconvénient de ne concerner qu'un seul épitope par clone) et des techniques (filtration sur gel) le nombre de Du dépistés est maintenant très faible.
En cas de réelle nécessité, la biologie moléculaire (B.M.)
peut maintenant être utilisée, et montre très souvent qu'il s'agit en réalité d'un variant du gène RH1.On a considéré très longtemps, avant la biologie moléculaire, qu'il s'agissait d'un antigène normal, mais en quantité moindre, donc à considérer comme positif.
Cependant, non mis en évidence par une technique simple de groupage, le Du est souvent étiqueté comme négatif lors de la détermination du groupe rhésus de malades.
Ceci n'a pas de conséquences graves, à l'exception de consommer beaucoup d'unités de sang rh négatif en cas de transfusion, ou de faire une injection inutile d'immunoglobulines anti-D chez une accouchée, si elle est Du avec un enfant Rh+.Ne pas faire cette injection d'anti-D serait plus grave si la mère est rh négatif et l'enfant Du.
Cette recherche de Du, faite pendant de nombreuses années (jusqu'au début des années 2000) à la naissance chez la mère et l'enfant, pour poser l'indication d'une prévention de la maladie hémolytique du nouveau-né par injection d'anti-D, n'est plus faite aujourd'hui, sauf cas particuliers de discordance de détermination de groupe, du fait de l'amélioration de nos réactifs monoclonaux.Par contre, en tant que donneur de sang, il est absolument impératif de considérer le D faible comme Positif, car l'antigène Du est immunogène.
Ceci explique le fait que certaines personnes peuvent être déterminées comme RH1 Positif (D) en tant que donneur de sang et RH1 Négatif (dd) en tant que malade susceptible d'être transfusé.Chez un sujet D partiel la proteine est qualitativement anormale dû au manque d'epitopes mais son expression quantitatif reste normale.Par la suite, on s'est aperçu que certains sujets Rh positif, ou Du, pouvaient faire un anticorps anti-D.
On les considère alors comme des D partiels, que l'on doit transfuser en rh négatif.Depuis le début des années 2010, selon les réactions que l'on observe au laboratoire, le sujet concerné (peau blanche, noire…), les anticorps utilisés, et avec un peu d'expérience, le Du sera considéré soit comme Rh Positif, soit suspecté d'être un variant et donc un possible D partiel.
Il sera alors contrôlé en biologie moléculaire, où sera révélée la mutation concernée.
Si une réponse anticorps a déjà été observée chez de tels sujets transfusés avec des sangs Rh +, ce sujet sera considéré, en tant que malade, comme un rhésus négatif.
Un commentaire accompagnera le résultat, car cette personne peut très bien être retrouvée Rh Positif sans aucun problème dans un autre laboratoire, tout dépend de l'anticorps monoclonal employé et de l'épitope reconnu.
Ces sujets sont donc considérés comme receveurs Rh négatifs (RH:-1, dd) et donneurs positifs (RH:1, D) parfois seulement en dons de plasma ou plaquettes, le don de globules rouges risquant d'entraîner l'apparition d'un anticorps contre certains variants chez le receveur.Le Du, ou du moins le phénotype considéré comme tel, est de plus en plus rare.
En cas de discordance de résultats avec différents réactifs, un variant ou un « D partiel » susceptible de produire une réponse anti-D est le plus souvent suspecté, cas qui reste exceptionnel.
Enfin, les antigènes associés C ou E trouvés chez un RH D négatif, compte tenu de leur fréquente association à l'antigène D, sont des indicateurs à surveiller.Encore dénommé antigène Cw dans la nomenclature Fisher-Race, de fréquence phénotypique de 1 à 9 % selon les populations (2 % chez les personnes à peau blanche), il s'agit d'une particularité de la molécule RHCE C+ (RH:2) le plus souvent (exceptionnellement d'une molécule ce), due à une substitution Gln41Arg.
Cette particularité n'a aucune conséquence clinique, mais un anticorps anti-Cw naturel (c’est-à-dire apparaissant en dehors de toute immunisation par transfusion ou grossesse) et sans danger même en cas de transfusion, est souvent dépisté lors d'une recherche d'anticorps irréguliers (RAI).Cet épitope, nommé également rhG, est dû à la présence d'une sérine en position 103 tant sur la molécule RHD que sur la molécule RHCE de type C (RH:2), la molécule de type c (RH:4) ayant une proline en 103.
L'antigène G (RH:12) est donc un antigène commun aux molécules D (RH:1) et C+ (RH:2).
Rares sont les molécules D+ et G- ayant une proline en 103.
Ceci explique la survenue d'immunisations dites anti D+C qui sont en fait très souvent des anti D+G.Antigène rencontré dans la population africaine, de fréquence phénotypique 1 %, il s'agit d'une molécule hybride due à un gène RH(CE-D-CE) dans lequel l'exon 4 du gène RHCE est remplacé par l'exon 4 du gène RHD.
Cet antigène est également présent chez d'exceptionnels phénotypes D partiels de génotype RH(D-CE-D) où les exons -5 à 7 ou 5 à 9 de RHD sont remplacés par les exons homologues de RHCE.
Les sujets RH32 homozygotes (de génotype RN/RN selon la nomenclature Wiener) peuvent présenter un anticorps immun (apparaissant après grossesse ou transfusion) et très dangereux contre l'épitope RH46 qu'ils ne possèdent pas.
Or, cet épitope RH46 existe sur toutes les protéines RHCE qui ne sont pas RH32.
On dit des antigènes RH32 et RH46 (tout comme RH2 et RH4 ou RH3 et RH5) qu'ils sont antithétiques : si l'un est absent, l'autre est normalement présent.
Lorsqu'ils possèdent cet anticorps anti-RH46, les sujets RH:32,-46 ne peuvent plus être transfusés, sauf par des sangs de même phénotype.
En France, ces sujets ont donc une carte nationale de groupe rare, et leur sang est conservé congelé à la Banque nationale de sang de phénotype rare à Créteil.Cet antigène, encore dénommé antigène VS, est rencontré dans la population noire, avec une fréquence phénotypique de 26 à 40 %.
Il est dû à une substitution Leu245Val sur la molécule RHCE de type ce, ou sur la molécule hybride RHD-CE-D.
Cet anticorps peut être naturel, et n'entraîne que des réactions cliniques mineures.Certains haplotypes ne codent pas l'ensemble des antigènes attendus.
L'antigène absent est remplacé par le signe — dans la nomenclature Fisher Race.Les haplotypes RH en délétions pourraient faire croire à une exclusion de parenté, l'enfant ne possédant pas un haplotype attendu, ou paraissant posséder un haplotype non mis en évidence chez le parent lui ayant transmis l'un de ces haplotypes.
De même, un parent RHnull de type régulateur peut transmettre un haplotype normal à son enfant, le problème génétique étant évident dans ce dernier cas.Ces deux types de RHnull sont indiscernables sérologiquement.
On ne retrouve sur aucun l'antigène RH29, que l'on retrouve sur toutes les hématies qui ne sont pas RHnull.
Ce phénotype entraîne le syndrome RHnull, caractérisé par une fragilité des hématies, marquée par une sphérocytose et une fragilité osmotique.
D'où une anémie hémolytique chronique, souvent bien compensée (réticulocytose), mais dans certains cas pouvant nécessiter une splénectomie.
Le tableau est en fait proche de la sphérocytose héréditaire, ou maladie de Minkowski-Chauffard.
Mais la gravité de l'atteinte clinique, au sein d'une même famille, est très variable d'un sujet à l'autre.Ces personnes posent un rarissime mais énorme problème transfusionnel.
Elles peuvent être transfusées une fois, mais pas deux si elles produisent un anticorps.
Hors leur famille, il sera très difficile de trouver un donneur compatible.
Il est donc nécessaire, grâce à un protocole d'auto-transfusion, de conserver congelé le sang de ces personnes dans un centre national.
Ou de faire appel aux autres centres nationaux de transfusion sanguine qui pourraient avoir de tels sangs congelés en stocks.Il s'agit toujours d'anticorps irréguliers.
C’est-à-dire que l'absence de l'antigène n'entraîne pas la présence de l'anticorps correspondant (contrairement au système ABO où l'absence de l'antigène A ou B sur le globule rouge doit entraîner systématiquement la présence de l'anticorps dans le plasma).Il peut s'agir d'allo-anticorps, chez le sujet sain, ou d'auto-anticorps dans les maladies et anémies auto-immunes.Ces anticorps peuvent être naturels, c'est le cas le plus fréquent pour les anti-E et anti-Cw.
Les autres anticorps de système RH sont le plus souvent immuns, c’est-à-dire qu'ils résultent de transfusions ou de grossesses.
Il s'agit essentiellement des anti-D, anti-c, les plus fréquents et entraînant les conséquences les plus graves.
Mais tous les autres anticorps, moins fréquents, peuvent se voir.
Très souvent, associé à l'anti-D, nous trouvons un anticorps que nous identifions comme un anti-C.
En fait, l'anti-C pur est très rare, et il s'agit souvent non pas d'un anti-C, mais d'un anti-G (anti-RH12) qui est une spécificité commune à la molécule D et à la molécule RHCE C+.
L'anti-G reconnaît donc à la fois le D (RH1) et le C (RH2).
Ainsi, ce que nous appelons un anti-D+C peut très bien être un anti-G, un anti-D+G, un anti-C+G ou un anti-D+C+G.
Seules, des techniques de fixation-élutions permettraient de différencier ces divers anticorps, ce qui n'a aucun intérêt pratique dans ce cas.
Nous rencontrons aussi dans le système RH des anticorps vis-à-vis d'antigènes composés, c’est-à-dire reconnaissant l'association de deux épitopes sur la même protéine : anti-Ce (RH7), anti-cE (RH 27), anti-ce (RH6, f), anti-CE (RH22), mais ne reconnaissant pas chacun de ces épitopes isolés.
Ainsi, chez un sujet DCCee transfusé avec un sang DCcEe (de génotype DCe/DcE), nous pouvons avoir l'association de trois anticorps : anti-c + anti-E + anti-cE.Les auto-anticorps chauds (en règle actifs à 37 °C, de type IgG) rencontrés dans les maladies auto-immunes, ont souvent une spécificité RH.
La spécificité en est suspectée par les différences de sensibilité d'hématies normales.
Les hématies de phénotype RH : EE, dépourvue de l'antigène e, réagissant moins que les autres, ou ne réagissant pas dans certaines techniques, par exemple, nous pouvons alors en conclure qu'il s'agit, dans ce cas, d'un auto-anticorps à spécificité préférentielle anti-e.La preuve définitive pourrait en être apportée -ce qui ne présente aucun intérêt en pratique- par le fait que certaines hématies RH en délétion, de phénotype DC-, D--, ou --- (RHnull) ne réagissent pas du tout, et qu'elles ne possèdent donc pas l'épitope RH reconnu par ces auto-anticorps.
Mais ces hématies rarissimes ne sont utilisées que pour l'identification d'allo-anticorps susceptibles d'entraîner des accidents transfusionnels.La découverte du système Rhésus a permis de rendre plus sûre la transfusion sanguine, de comprendre et de prévenir les incompatibilités fœto-maternelles de groupe sanguin au cours de la grossesse.La règle est qu'on peut transfuser des produits sanguins Rh - (qui ne contiennent pas l'antigène D ou RH1) à un individu Rh +, mais pas le contraire.
L'individu Rh - fabriquerait des anticorps anti-RH1 (D) destructeurs des globules rouges Rh +, ce qui provoquerait un accident transfusionnel lors d'une nouvelle transfusion incompatible.Il existe un risque d'immunisation au cours de la grossesse d'une femme Rh - par un fœtus Rh + dans certaines circonstances :Dans ces cas, la mère doit recevoir rapidement, dans les 48 heures (ou 72 heures au plus tard, l’efficacité diminuant rapidement au-delà) des immunoglobulines anti D (RH1) qui préviennent sa possible immunisation afin de pouvoir mener sans encombre une grossesse ultérieure.
D’où le nom de prévention de la maladie hémolytique du nouveau-né donné à cette méthode.
Les immunoglobulines anti-D entraînent d’une part la disparition rapide des globules rouges fœtaux de la circulation maternelle, par hémolyse intra ou extra-vasculaire, disparition qui peut être mise en évidence par le test de Kleihauer, et bloquent d’autre part la réponse immunitaire primaire.
Ainsi, l'organisme de la mère ne garde pas la mémoire immunologique de son contact avec l’antigène RH1, D.Maintenant que cette prévention est faite systématiquement à la naissance, et est même recommandée à la 28e semaine de grossesse, nous observons beaucoup moins d'incompatibilités par anti-D.
Mais nous observons toujours des incompatibilités par anti-c (donc chez des femmes Rhésus + DCCee, accouchant d'un enfant hétérozygote DCcee) et anti Kell.
D'où la règle transfusionnelle de respecter la totalité des phénotypes Rhésus et Kell pour la transfusion chez une fille ou une jeune femme.En France, leur répartition est la suivante, par groupe sanguin :La région du monde qui compte la plus forte proportion de rhésus négatifs est le Pays basque.
Un virus est un agent infectieux nécessitant un hôte, souvent une cellule, dont les constituants et le métabolisme déclenchent la réplication.
Le nom virus a été emprunté au XVIe siècle par Ambroise Paré au latin vīrus, ī, n.
(« venin, poison, proprement suc des plantes »),,.
La science des virus est la virologie, et ses experts sont des virologues ou virologistes.
On considère de plus en plus les virus comme faisant partie des acaryotes.
Ils changent de forme durant leur cycle, passant par deux stades :Sous la forme intracellulaire (à l'intérieur de la cellule hôte), les virus sont des éléments génétiques qui peuvent s'intégrer à un chromosome du génome hôte (on parle alors de provirus ou de prophage) ou non (cas par exemple des usines à virions).Pour les humains, sur les environ 5 000 espèces décrites, seules 129 sont jugées pathogènes en 2018.Le débat sur la nature des virus (vivants ou pas) repose sur des notions complexes,, et reste aujourd'hui ouvert.
Selon de nombreuses définitions du vivant (entité matérielle réalisant les fonctions de relation, nutrition, reproduction), les virus ne sont pas des êtres vivants, mais d'autres définitions permettent de les considérer comme vivants.Les maladies virales comme la rage, la fièvre jaune ou la variole affectent l'Homme depuis des millénaires.
Des hiéroglyphes mettent en évidence la poliomyélite dans l'Égypte antique ; des écrits de l'Antiquité gréco-romaine et d'Extrême-Orient décrivent certaines maladies virales.Varron (116–27  av.
affirme "qu'il y a des créatures minuscules qui ne peuvent être vues par les yeux", qui flottent dans l'air et pénètrent dans le corps par la bouche et le nez et y provoquent des maladies graves.À la fin du XIXe siècle, se représenter des agents infectieux qui ne fussent ni des bactéries, ni des champignons, ni des parasites, et qu'on ne pouvait déceler au microscope optique, était encore difficilement concevable.
Le médecin testerin Jean Hameau avait fait un premier exposé sur les virus en 1837 devant la Société royale de médecine de Bordeaux, Réflexions sur les virus, puis devant l'Académie nationale de médecine en 1843.
Son Mémoire sur les virus est présenté en séance de l'Académie de médecine le dimanche 14 avril 1850.Les scientifiques isolaient alors les agents infectieux grâce aux filtres de porcelaine utilisés pour recueillir les bactéries.
Entre 1887 et 1892, le botaniste russe Dimitri Ivanovski, en étudiant la mosaïque du tabac, montre que la sève des plantes malades contenait un agent infectieux non retenu par les filtres Chamberland (conçus par le biologiste du même nom).
Ivanovski pensait à une toxine ou une très petite bactérie.
C'est le chimiste hollandais Martinus Willem Beijerinck qui approfondit ces travaux et, en 1898, écarta à la fois l'hypothèse bactérienne, et l'hypothèse toxinique : diluant la sève de plantes infectées, il l'inocula à des plantes qui développèrent la maladie ; réitérant la manipulation, il put transmettre la maladie de multiples fois, montrant ainsi que la sève de la dernière plante infectée était aussi virulente que la première, effet qu'une toxine, après tant de dilutions n'aurait pu produire.
Beijerinck appela l'agent Contagium vivum fluidum (« germe vivant soluble »).À la même époque, le premier virus identifié est celui de la fièvre aphteuse, par Friedrich Löffler et Paul Frosch.
Le premier virus pathogène de l'Homme identifié est celui de la fièvre jaune, entre 1900 et 1902.
Louis Pasteur les nomma « infrabactéries », d'autres les qualifièrent de « virus filtrants » ou « virus ultrafiltrants ».C’est pendant la Première Guerre mondiale que le Britannique Frederick Twort et le microbiologiste franco-canadien Félix d'Hérelle mettent en évidence le phénomène de « lyse transmissible » observable par la lyse des bactéries cultivées en milieu solide.
Ce phénomène est dû à un virus de bactéries que Félix d'Hérelle qualifia de bactériophage.
Les virus des plantes, des animaux, de l'Homme et des bactéries étaient ainsi découverts et leurs listes ne cessèrent de s'allonger au cours du XXe siècle.Vers 1925, un virus était défini comme un « agent responsable d'une maladie infectieuse, parasite, de nature particulaire et de taille comprise entre 0,01  et   0,3 micromètre ».L'apparition de la microscopie électronique dans les années 1930 permit l'observation des virus, mais on ne savait toujours pas à cette époque ce qu'ils étaient réellement.
Le biochimiste américain Wendell Stanley cristallisa le virus de la mosaïque du tabac sous forme de cristal protéique en 1935.
L'année suivante, des études complémentaires montrèrent que ce cristal contenait également de l'ARN.
Les études ultérieures montrèrent que, selon les virus étudiés, ceux-ci étaient composés soit de protéines et d'ARN, soit de protéines et d'ADN.
C'est en 1957 qu'André Lwoff proposa une définition claire et moderne des virus.
En 1959, les microbiologistes Lwoff, Anderson et Jacob proposèrent le terme de virion pour définir la particule virale infectieuseÀ partir des années 1960, les progrès des cultures cellulaires, de la microscopie électronique et de la biologie moléculaire permirent de progresser dans la compréhension des mécanismes de réplication des virus, dans la réalisation de diagnostics fiables et dans l'élaboration de vaccins.On sait, depuis la fin du XXe siècle, que l'océan mondial est un immense réservoir de virus, de la surface aux évents hydrothermaux en passant par l'Arctique et les sédiments marins.Dans l'eau de mer, la concentration en particules virales est de 106 à 108 particules par millilitre.
En surface et près des rivages, les concentrations en virus habituellement rencontrées sont de l'ordre de 107 virus par millilitre (soit dix mille virus par millimètre cube (un millième de millilitre)) ; la concentration décroissant avec la profondeur et la distance au rivage.
Des concentrations plus élevées (108 à 109 / cm3) se rencontrent dans les sédiments marins proches de la surface.Ces virus jouent dans l'océan un rôle majeur dans le contrôle des efflorescences algales, ainsi que dans les cycles biogéochimiques, en particulier dans le cycle du carbone océanique (quotidiennement environ 20 % des organismes constituant la biomasse microbienne océanique totale est tuée par des virus ; ces derniers s'attaquent massivement au phytoplancton et au zooplancton, mais aussi aux bactéries et cyanophycées).Grâce aux progrès de la cytométrie en flux et de l'analyse génétique (métagénomique notamment), en quelques décennies les chercheurs ont inventorié près de 200 000 types de populations virales en mer (en 2019, on en comptait 195 728 exactement, un chiffre douze fois plus élevé que celui de l'évaluation faite en 2016) ; 90 % des virus identifiés en mer entre 2016 et 2019 étaient jusqu'alors inconnus de la science.
Remarque : on ne parle pas ici d'espèces mais de populations, au sein desquelles il y a plus de flux de gènes dans un groupe qu'entre groupes de virus (si les virus séquencés partagent au moins 95 % de leur ADN, alors ils sont classés dans une même population distincte des autres).En 2007 on a estimé qu'il pourrait y avoir environ 1030 virus dans l'océan ; étirés et mis bout à bout, ils formeraient une ligne s'étendant au-delà des 60 galaxies les plus proches.
Et chaque seconde il y aurait environ 1023 infections virales dans l'océan, jouant un rôle majeur dans l'évolution et l'entretien de la biodiversité marine.
L'abondance virale semble liée à l'abondance et à la productivité en procaryotes, mais cette relation varie selon les environnements marins, notamment en fonction de la température.Le virome est la composante virale d'un microbiome.
Ainsi, le virome humain (en) est l'ensemble des communautés virales du microbiote de l'organisme humain.
La recherche actuelle estime que dans le corps humain il y a 100 fois plus de virus (1015) que de cellules humaines (1013).
Chaque individu en bonne santé porte en moyenne plus de 10 types de virus responsables d'infections virales systémiques chroniques et asymptomatiques.On caractérise un virus par son incapacité à se reproduire par mitose, par scissiparité ou par méiose.
Pour répliquer son acide nucléique, il dépend d'une cellule hôte qu'il doit infecter pour détourner et utiliser son métabolisme : un virus est nécessairement un parasite intracellulaire.
Il est composé d'une ou plusieurs molécules d'acide nucléique (ADN ou ARN, simple ou double brin), éventuellement incluse dans une coque protéique appelée capside, voire d'une enveloppe lipidique (ex : l'Ebolavirus est un virus enveloppé).
Parfois certaines capsides contiennent quelques enzymes (par exemple : transcriptase inverse du VIH) mais aucune pouvant produire de l'énergie.Historiquement, les virus ont d'abord été considérés comme des particules organiques dites non filtrables, puis de petite taille (inférieure à celle d'une bactérie), en règle générale moins de 250 nanomètres, possédant un acide nucléique double ou simple toujours d'un seul type (ADN ou ARN).
Les girus ont bousculé une première fois cette définition au moment de leur découverte.
Ces derniers appartiennent pourtant bien au règne des virus et leurs virions possèdent à la fois des molécules d'ADN et d'ARN, remettant en cause cette vision historique.
Il fallut repenser la définition des virus et la création de classes tels les « virus géants » comme mimivirus avec sa taille de 400 nm ou « girus » ou les NCLDV, voire les pandoravirus avec une taille allant jusqu'à 1 000 nm et leur « capside » qui n'en est pas vraiment une.
La découverte des virophages et des virus satellites a aussi modifié la vision qu'on avait des virus, révoquant l'idée qu'une virose cellulaire était la forme irréductible du parasitisme.Aujourd'hui les chercheurs s'accordent sur une remise en cause du paradigme capsidocentré, eu égard aux découvertes d'espèces virales montrant que certaines peuvent avoir plusieurs formes, y compris acapsidées, mais chaque fois infectieuses sans l'aide d'un virus assistant,.
Au-delà de ce paradigme, il semble que les origines des virus soient multiples.
Ainsi certains virus auraient évolué à partir de putatifs ancêtres cellulaires s'étant simplifiés.
Parallèlement, d'autres virus auraient évolué à partir de réplicons génétiques autonomes tels que les transposons, les plasmides et affiliés, finissant par acquérir d'abord une infectiosité propre puis une éventuelle capside.S'ils sont inclus dans la biologie et l'étude des maladies, les virus sont l'objet de débats depuis leur première découverte et celles qui ont suivi.Le débat sur le caractère vivant ou inerte des virus reste encore aujourd'hui ouvert,,.
Répondre à cette question exige de répondre au préalable à une autre : qu'est-ce que la vie ?
D'après Ali Saïb, « la notion du vivant est une notion dynamique, évoluant en fonction de nos connaissances.
En conséquence, la frontière entre la matière inerte et le vivant est tout aussi instable ».
L'existence ou non d'un métabolisme, c'est-à-dire d'un ensemble cohérent de processus chimiques (l'homéostasie et non la reproduction), constitue un discriminant possible, en tout cas commode, mais qui semble réducteur.Comme les cellules vivantes, les virus possèdent un acide nucléique (ADN ou ARN) et des protéines.
Cependant, selon la définition du biochimiste Wendell Stanley, les virus ne sont pas des êtres vivants mais de « simples » associations de molécules biologiques, le fruit d'une auto-organisation de molécules organiques.François Jacob insiste aussi sur cette caractéristique des virus : « Placés en suspension dans un milieu de culture, ils ne peuvent ni métaboliser, ni produire ou utiliser de l'énergie, ni croître, ni se multiplier, toutes fonctions communes aux êtres vivants.
» Les virus n'ont pas leur propre machinerie enzymatique, ne peuvent se multiplier qu'en utilisant celle d'une cellule qu'ils infectent.
Cependant ces caractéristiques sont en partie partagées avec les bactéries intracellulaire obligatoires.En revanche, Gustavo Caetano-Anollés et Arshan Nasir (du laboratoire de bio-informatique évolutionnaire à l'université de l'Illinois, États-Unis) défendent une tout autre thèse.
Ils avancent que, à côté des trois grandes « branches » du vivant (classiquement regroupées sous le nom de domaines) archées, bactéries (procaryotes) et eucaryotes, les virus en constitueraient une quatrième.
Ils seraient la résultante de cellules ayant précédé le dernier ancêtre commun universel (Last Universal Common Ancestor, acronyme LUCA) des trois autres domaines.
Pour avancer leur théorie les deux chercheurs se basent, non sur les séquences génétiques, mais sur les structures 3D des protéines qu'elles produisent.Depuis 1990, ils ont analysé 11 millions de protéines produites par 3 460 espèces de virus et 1 620 espèces de cellules appartenant aux trois domaines ; ils affirment ainsi pouvoir retracer l'histoire évolutive de ces structures ; les protéines ayant des structures proches seraient issues d'un même ancêtre hypothétique,.Si cette hypothèse est encore minoritaire, Patrick Forterre, biologiste spécialiste de l'évolution, considère qu'elle a le mérite de « favoriser le retour des virus dans la mire des évolutionnistes, alors qu'ils en étaient les grands absents ».En élargissant la définition des virus aux cellules virolées comme étant transformées en cellules virales, et les particules virales (en particulier le virion avant changement de paradigme) comme des éléments reproducteurs plutôt que le virus lui-même (à l'image de spores), alors il est acceptable selon ce point de vue d'envisager les virus comme vivants,.Au cours des dernières années, des entités intermédiaires ont été découvertes : le mimivirus, infectant une amibe, possède dans son génome 1 200 gènes (davantage que certaines bactéries).
Certains de ces gènes participeraient à la synthèse protéique et à des mécanismes de réparation de l'ADN.
Il existe chez le mimivirus une trentaine de gènes présents habituellement chez les organismes cellulaires mais absents chez les virus.Le virus ATV d'archées présente lui aussi des caractéristiques étonnantes : ce virus en forme de citron présente la particularité de se modifier en dehors du contexte cellulaire par un mécanisme actif.
Il est capable de s'allonger à chaque extrémité à une température de 80 °C, température à laquelle vit son hôte Acidianus à proximité des sources hydrothermales.
Néanmoins, organes et échanges cycliques, donc métabolisme, restent absents.Les virus jouent aussi un rôle dans l'évolution.
Patrick Forterre avance même l'hypothèse que les virus seraient les premiers organismes à ADN.
À l'origine de la vie, l'ARN dominait (hypothèse du monde à ARN) et assurait à la fois les fonctions de stockage et transmission de l'information génétique et de catalyse des réactions chimiques.
Seules existaient des cellules dont le génome était codé par de l'ARN et dont le métabolisme était assuré par des ARN-enzymes qui ont progressivement été remplacés par des protéines-enzymes.
Ces protéines, déjà complexes, auraient « inventé » l'ADN.
L'ADN a été sélectionné en raison de sa plus grande stabilité.
D'après Patrick Forterre, l'ADN confèrerait au virus le pouvoir de résister à des enzymes dégradant les génomes à ARN, arme de défense probable des protocellules.
On retrouve le même principe chez des virus actuels, qui altèrent leur ADN pour résister à des enzymes produites par des bactéries infectées.Virus et micro-organismes (ou microbes) ne sont donc pas des notions de même nature.
Elles s'opposent en ce que les microbes sont des organismes vivants, ce qui est contesté pour les virus.
Mais leur portée est différente, les micro-organismes (bactéries, archées, levures, protistes, etc.) n'étant regroupés que pour leur taille microscopique, sans que ce regroupement ait un sens en termes de classification des espèces, alors que les virus ont bien des caractéristiques phylogéniques communes, même si le concept d'espèce reste flou pour les acaryotes.Tout agent infectieux ressortissant au règne des virus est composé au minimum d'un acide nucléique.
Les formes incapables d'effectuer le cycle viral sans assistance sont qualifiées particules sub-virales (exemple : virusoïde, ADN satellite, etc.).
Les formes extracellulaires capables d'effectuer le cycle viral sans assistance sont appelées particules virales, allant d'une forme simplifiée à l'extrême et ne comportant que l'acide nucléique — lequel, lorsqu'il encode au minimum une protéine, est qualifié de virus et lorsqu'il n'encode aucune protéine est appelé viroïde — ou une forme transportant un à plusieurs acides nucléiques dans un conteneur protéique appelée virion.On le dit encapsidé car l'acide nucléique, généralement stabilisé par des nucléoprotéines basiques, est enfermé dans une coque protéique protectrice appelée capside.
La forme de la capside est à la base des différentes morphologies des virus.
Le virion a une forme microscopique variable : si la représentation « usuelle » lui donne l'image du VIH, les différentes espèces ont des formes allant de la sphère à des conformations d'apparence insectoïde.La taille des virus se situe entre 10  et   400 nanomètres.
Les génomes des virus ne comportent que de quelques gènes à 1 200 gènes.
L'un des plus petits virus connus est le virus delta, qui parasite lui-même celui de l'hépatite B. Il ne comporte qu'un seul gène.
L'un des plus gros virus connus est le mimivirus, avec un diamètre qui atteint 400 nanomètres et un génome qui comporte 1 200 gènes.Le filament d'acide nucléique peut être de l'ADN ou de l'ARN.
Il peut être circulaire ou linéaire, bicaténaire (double brin) ou monocaténaire (simple brin).
Le génome sous forme d'ADN est généralement bicaténaire.
Le génome sous forme d'ARN est généralement monocaténaire et peut être à polarité positive (dans le même sens qu'un ARN messager) ou à polarité négative (complémentaire d'un ARN messager).
Le peloton central d'acide nucléique est dénommé nucléoïde.La capside est une coque qui entoure et protège l'acide nucléique viral.
La capside est constituée par l'assemblage de sous-unités protéiques appelées capsomères.
L'ensemble formé par la capside et le génome est nommé nucléocapside.
La structure de la capside peut présenter plusieurs formes.
On distingue en général deux groupes principaux de virus : les virus à symétrie cubique (ou à capside icosaédrique) et les virus à symétrie hélicoïdale.De nombreux virus sont entourés d'une enveloppe (ou péplos) qui prend naissance au cours de la traversée des membranes cellulaires.
Sa constitution est complexe et présente un mélange d'éléments cellulaires et d'éléments d'origine virale.
On y trouve des protéines, des glucides et des lipides.
Les virus possédant une enveloppe sont les virus enveloppés.
Les virus ne possédant pas d'enveloppe sont les virus nus.
L'enveloppe permet un camouflage immunologique qui est un avantage évolutif, en revanche les virus enveloppés sont plus sensibles que les virus nus à la désinfection par des détergents doux.On distingue deux voies principales de réplication du génome viral :Les virus ne peuvent se répliquer qu'au sein de cellules vivantes.
C'est l'interaction du génome viral et de la cellule hôte qui aboutit à la production de nouvelles particules virales.
L'infection d'une cellule par un virus, puis la multiplication du virus, peuvent se résumer en différentes étapes.
Toutefois, après pénétration du virus dans la cellule, ces étapes peuvent différer selon la nature du virus en question et notamment selon qu'il s'agit d'un virus à ADN ou d'un virus à ARN, ou encore d'un girus.Certains virus induisent des structures où se concentrent l'activité réplicative :Afin de mieux connaître la biologie, la multiplication et le cycle des virus, et éventuellement de préparer des vaccins, il est nécessaire de cultiver les virus.
Ceux-ci peuvent se multiplier uniquement au sein de cellules vivantes.
Les virus infectant les cellules eucaryotes sont cultivés sur des cultures de cellules obtenues à partir de tissus animaux ou végétaux.
Les cellules sont cultivées dans un récipient en verre ou en plastique, puis sont infectées par le virus étudié.
Les virus animaux peuvent aussi être cultivés sur œufs embryonnés et parfois chez l'animal, lorsque la culture in vitro est impossible.
Les virus bactériens peuvent également être cultivés par inoculation d'une culture bactérienne sensible.
Les virus de végétaux peuvent aussi être cultivés sur des monocouches de tissus végétaux, des suspensions cellulaires ou sur des plantes entières.Les virus peuvent ensuite être quantifiés de différentes manières.
Ils peuvent être comptés directement grâce à la microscopie électronique.
Dans le cas des virus bactériens, la technique des plaques virales (ou plages) est très utilisée pour évaluer le nombre de virus dans une suspension.
Une dilution de suspension virale est ajoutée à une suspension bactérienne, puis l'ensemble est réparti dans des boîtes de Petri.
Après culture, des zones claires (plages) à la surface de la gélose sont la conséquence de la destruction d'une bactérie et des bactéries adjacentes par un virion.Les virus peuvent être purifiés grâce à diverses méthodes de biochimie (centrifugation différentielle, précipitation, dénaturation, digestion enzymatique).Tout être vivant peut être infecté par un virus.
Il existe des virus de bactéries (les bactériophages), des virus d'archées, des virus d'algues (Phycodnaviridae), des virus de plantes, des virus fongiques, des virus d'animaux, parmi lesquels on trouve de nombreux agents pathogènes, et même des virus de virus.Il existe plusieurs hypothèses concernant l'origine et l'évolution des virus.
Il est probable que tous les virus ne dérivent pas d'un ancêtre commun et les différents virus peuvent avoir des origines différentes.Des études en 2013 de divers girus tendent à favoriser l'hypothèse d'une simplification.
Cela impliquerait que les virus pourraient être un embranchement phylogénétique au même titre que les autres règnes (eucaryotes, bactéries, archées) du vivant.Il est possible que les virus soient très anciens, peut-être plus anciens que les bactéries les plus âgées.Au début des années 2000, dans des amibes du genre Acanthamoeba, des chercheurs ont découvert un virus géant (Megaviridae) : le Mimivirus.
Aussi grand et complexe que certaines bactéries, il a modifié la perception des virologistes quant aux limites supérieures de taille (sa longueur totale dépasse 0,7 micromètre) et du nombre de gènes du monde viral (il possède plus de 1 000 gènes).Dix ans plus tard, des chercheurs français publiaient (2013) la description de deux virus encore plus grands, et dont le génome est environ deux fois plus gros (en nombre de gènes) que les précédents virus géants découverts.
Ces deux nouveaux virus géants ont été classés dans une catégorie créée pour eux (Pandoravirus) car ils ne sont pas apparentés aux virus connus et présentent même des caractéristiques inattendues :Le premier (Pandoravirus salinus) a été trouvé dans des sédiments marins prélevés au large du Chili et le second (Pandoravirus dulcis) dans une mare d'eau douce près de Melbourne (en Australie).Bien que présentant les caractères essentiels d'un virus (pas de ribosome, pas de division ni de production d'énergie), ils semblent d'un type tout à fait nouveau.
Leur génome dépasse en taille celui de certains petits eucaryotes (cellules à noyau) parasites.Les Pandoravirus utilisent donc directement le code génétique de leur hôte.
Ces organismes ne sont pourtant ni des eucaryotes, ni des eubactéries ni des archébactéries.
Cette découverte remet en question le dogme établi par la virologie dans les années 1950 voulant qu'il n'y ait pas de continuité entre virus et bactéries.
La vie cellulaire aurait donc pu émerger à partir de formes de vie pré-cellulaires plus variées que ce qu'on pensait.D'autre part, les virus jouent un rôle important de vecteur naturel dans les transferts de gène dits horizontaux (par opposition aux transferts dits verticaux de parent à descendant) entre différents individus et même différentes espèces, permettant un accroissement de diversité génétique, et la dissémination d'innovations génétiques au-delà de la descendance d'individu porteur d'une mutation génétique donnée.
En particulier la transduction et l'endogénisation sont typiquement des évolutions génétiques qui ne peuvent s'effectuer qu'à l'aide des virus.En abiotique (les prémisses du vivant), une des hypothèses stipule que les virus auraient joué des rôles clefs très tôt dans l'histoire évolutive du vivant, probablement avant la divergence entre bactéries, archées et eucaryotes, à l'époque du dernier ancêtre commun universel.
Ils restent l'un des plus grands réservoirs de diversité génétique inexplorés sur la planète.Les virus jouent également un rôle important dans les corps des humains.
Selon le chercheur Clément Gilbert, « le corps d'un homme adulte sain abrite plus de trois mille milliards de virus, pour la plupart des bactériophages infectant les bactéries présentes dans le tractus intestinal et sur les muqueuses.
L'impact de ces virus n'est pas encore complètement compris, mais on peut déjà parier qu'ils jouent un rôle important dans la régulation de la composition des communautés bactériennes vivant en symbiose avec l’homme ».
Il souligne également que « plus de 8 % du génome humain dérivent de rétrovirus », ce qui permet de dire que « nous sommes d’une certaine manière apparentés aux virus ».Les virus possèdent différents mécanismes leur octroyant diverses possibilités stratégiques d'infection, dont l'incidence provoque éventuellement des maladies.
Le virion pénètre une cellule hôte plus ou moins spécifique où il se désagrège, libérant son contenu qui en s'activant prend le pas sur les fonctions cellulaires normales.
À ce niveau, les effets cytopathogènes des virus peuvent entraîner divers effets néfastes.
Les capacités de synthèse protéique de la cellule infectée peuvent être détournées ou inhibées, tandis que la chromatine est fragmentée par des enzymes virales.
Des particules virales s'accumulent dans le cytoplasme avant de s'assembler en virions.
La surcharge virale endo-cellulaire provoque enfin la mort de la cellule hôte par lyse, libérant les virions qui vont ensuite disséminer.Lorsque le virus pénètre dans une cellule non permissive, il ne peut pas se multiplier.
Son génome peut cependant subsister sous la forme d'un épisome libre ou intégré au génome cellulaire.
Il y a transformation cellulaire virale lorsque le génome du virus entre en interaction avec l'ADN du génome cellulaire.
On appelle ces virus des virus oncogènes.
Parmi ceux-ci, les rétrovirus, en s'intégrant dans le génome cellulaire, peuvent devenir tumorigènes et éventuellement entraîner des cancers.La capacité d'un virus d'entraîner une maladie est décrite en termes de pouvoir pathogène tandis que son intensité est exprimée en termes de virulence.La classification des principaux groupes de virus, et leurs correspondances en pathologie, se trouvent dans l'encyclopédie médicale Vulgaris.
Cette classification est notamment basée sur le type de molécules d'acide nucléique (ARN ou ADN) dont est constitué le virion.En 2018, on recense 129 espèces de virus impliqués dans des maladies humaines,.Le rhume, la grippe, la varicelle, la rougeole, la mononucléose infectieuse sont des exemples de maladies humaines relativement courantes d'origine virale.
On connaît d'autres exemples plus nocifs comme le SIDA, certains coronavirus (SRAS, maladie à coronavirus 2019), la grippe aviaire, la variole, ou la maladie à virus Ebola, fièvre hémorragique causée par le virus Ebola.Quelques exemples de virus pathogènes pour Homo sapiens :Dangerosité d'un virus : selon le professeur Arnaud Fontanet, épidémiologiste, qui dirige l'unité d'épidémiologie des maladies émergentes à l'institut Pasteur de Paris, les caractéristiques d'un virus dangereux :Étant donné que les virus utilisent la machinerie cellulaire de l'hôte pour se reproduire à l'intérieur même de la cellule, il est difficile de les éliminer sans tuer la cellule hôte.
Des médicaments antiviraux permettent cependant de perturber la réplication du virus.Une autre approche est la vaccination qui permet de résister à l'infection.Divers médicaments permettent de traiter les symptômes liés à l'infection, mais pas les antibiotiques, qui sont sans effet sur les virus.
Les antibiotiques interfèrent en effet avec des constituants ou le métabolisme des bactéries et permettent donc de traiter seulement les maladies d'origine bactérienne et non les maladies d'origine virale.Diverses méthodes de désinfection in vitro permettent d'inactiver les virus (hypochlorite de sodium à 1 %, éthanol à 70 %, glutaraldéhyde à 2 %, formaldéhyde, eau oxygénée à 2 %, acide peracétique).Les virus présentant en général un matériel génétique simpliste, ce sont d'excellents outils dans l'étude de la biologie moléculaire et la biologie cellulaire.
Ils permettent la manipulation de fonctions cellulaires, ce qui permet d'en approfondir notre compréhension et d'élucider certains mécanismes moléculaires de la génétique comme la réplication de l'ADN, la transcription, les modifications post-transcriptionnelles de l'ARN, la traduction, le transport des protéines et l'immunologie.Les virus peuvent être utilisés (virothérapie) comme vecteur de gène au sein de cellules cibles.
Outil utilisé par exemple pour faire acquérir à une cellule la capacité de produire une protéine d'intérêt ou pour étudier l'effet de l'introduction du nouveau gène dans le génome.Certains virus sont utilisés en thérapie génique pour soigner diverses maladies génétiques, par exemple pour remplacer un gène défectueux provoquant des troubles fonctionnels ou mécaniques.Les virus sont également utilisés dans la lutte contre le cancer.
Certains virus peuvent être en quelque sorte programmés pour détruire spécifiquement des cellules cancéreuses.Les virus sont classés selon leur stratégie de réplication, c'est-à-dire selon la nature de l'acide nucléique de leur génome (ADN ou ARN), la structure de l'acide nucléique (monocaténaire ou bicaténaire) et la forme de l'acide nucléique (linéaire, circulaire, segmenté ou non) : c'est la classification de Baltimore.
Les données morphologiques peuvent également être prises en compte (présence ou absence d'enveloppe, symétrie de la capside).
Souvent, le sérogroupage est encore utilisé pour raffiner la définition des différences entre virus très proches.Un pas vers une classification phylogénétique est franchi en octobre 2018 avec la reconnaissance par l'ICTV (Comité international de taxonomie des virus) du regroupement des virus à ARN simple brin à polarité négative en un embranchement, deux sous-embranchements et six classes,.Il existe deux catégories de virus de procaryotes selon le type d'hôte qu'ils parasitent.
La première catégorie regroupe ceux qui infectent les bactéries et sont appelés bactériophages.
La deuxième catégorie regroupe ceux qui infectent les archées.Il existe quatre grands groupes morphologiques de virus de procaryotes.Les bactériophages possèdent un rôle dans les écosystèmes.
Par exemple, dans les écosystèmes aquatiques, ils participent au contrôle de l'abondance et de la diversité bactérienne.En principe spécifiques d'une espèce ou d'un groupe de phylums génétiquement proches, les virus ont tendance à infecter un type cellulaire ou tissulaire principal ou exclusif.
Cependant, il existe de nombreux virus, comme la rage, qui sont moins spécifiques à un hôte par comparaison avec d'autres virus comme la maladie de Carré, le virus de l'immunodéficience féline ou la variole.
Les virions se propagent principalement par contact direct entre individus, mais peuvent aussi diffuser dans l'air sous forme d'aérosols (éternuements), être charriés par des excrétions diverses (vomis, urines, selles, larmes…), ou encore transportés par d'éventuels arthropodes parasites (moustiques, tiques, puces…).Les arbovirus sont des virus ayant pour vecteurs des arthropodes hématophages.Les baculovirus sont des virus d'insectes très étudiés.
La larve de l'insecte s'infecte en ingérant de la nourriture.
À partir du tube digestif, l'infection peut se transmettre aux autres tissus.
L'utilisation de virus pathogènes d'invertébrés dans la lutte contre les insectes ravageurs des cultures et des forêts pourrait être l'un des moyens pour limiter ou remplacer les insecticides chimiques.Les baculovirus sont aussi utilisés en biologie moléculaire pour exprimer un gène étranger (protéine recombinante) dans des cultures de cellules d'insectes.Par ailleurs, certains virus de végétaux sont transmis par des invertébrés mais ne se multiplient pas chez ces vecteurs.La structure des virus des plantes ou phytovirus, est similaire à celle des virus bactériens et animaux.
Beaucoup de virus végétaux se présentent sous la forme de minces et longues hélices.
La majorité a un génome composé d'ARN.
Les virus de végétaux peuvent être disséminés par le vent ou par des vecteurs comme les insectes et les nématodes, parfois par les graines et le pollen.
Les virus peuvent aussi contaminer la plante par l'intermédiaire d'une blessure ou d'une greffe.Différents types de symptômes peuvent apparaître sur la plante infectée.
Les virus peuvent provoquer des taches ou des flétrissements sur les feuilles et les fleurs.
Des tumeurs peuvent survenir sur les tiges ou les feuilles.Le virus de la mosaïque du tabac (TMV ou tobamovirus) est un exemple très étudié de virus de végétaux.Les virus des champignons, ou mycovirus, sont particuliers car ils se propagent lors de la fusion cellulaire.
Il n'y a pas de virions extracellulaires.
Chez les levures comme Saccharomyces, les virus sont transmis au moment du brassage cytoplasmique lors de la fusion cellulaire.
Les champignons filamenteux comme Penicillium ou le champignon de Paris Agaricus bisporus peuvent également être infectés par des virus, ce qui peut entraîner des problèmes lors de production.
Il a été imaginé d'utiliser ces virus dans le cadre d'une lutte biologique contre des champignons pathogènes.Découvert en 2008, Sputnik est un cas à part capable d'infecter un autre virus (Mamavirus) appartenant à la classe des virus géants (génome de plus de 300 000 pb et taille supérieure à 0,2 μm).On connaît aussi d'autres virophages comme Mavirus associé au CroV (en) (un virus géant infectant l'hôte eucaryote Cafeteria roenbergensis, organisme unicellulaire).
La variabilité jonctionnelle contribue à la création de la diversité des immunoglobulines produites par les lymphocytes B. Comme la recombinaison VDJ, ce phénomène a lieu dans la moelle.Cette variabilité est une des composantes de la biodiversité, au sein des individus, des populations et des espèces.
C'est aussi un des éléments de la coévolution des organismes avec leurs parasites et pathogènes.La recombinaison VDJ rend des éléments physiquement éloignés dans le génome contigus, il y a donc nécessité de couper la double hélice d'ADN puis de la refermer.
La coupure se fait par les endonucléases RAG1 et 2, la réparation par une kinase dépendant de l'ADN (DNA-PK).Mais ce mécanisme de recombinaison commet des erreurs, notamment au cours de la coupure (hypermutation somatique) : l'endonucléase enlève quelques nucléotides ou au contraire en laisse un peu trop.
La séquence est donc légèrement modifiée et aboutira à la synthèse d'un anticorps différent.
Le terme bactérie est un nom vernaculaire qui désigne certains organismes vivants microscopiques et procaryotes présents dans tous les milieux.
Le plus souvent unicellulaires, elles sont parfois pluricellulaires (généralement filamenteuses), la plupart des espèces bactériennes ne vivant pas individuellement en suspension, mais en communautés complexes adhérant à des surfaces au sein d'un gel muqueux (biofilm).Les bactéries les plus grosses, dites bactéries géantes, sont visibles à l'œil nu.
Jusqu'au début du XXIe siècle, les spécialistes considéraient que les plus petites mesuraient 0,2 μm, mais il existe des ultramicrobactéries,,.Les bactéries présentent de nombreuses formes : sphériques (coques), allongées ou en bâtonnets (bacilles) et des formes plus ou moins spiralées.
L’étude des bactéries est la bactériologie, soit une des nombreuses branches de la microbiologie.Il existe environ 10 000 espèces connues à ce jour,, mais la diversité réelle du groupe est probablement supérieure.
L'estimation du nombre des espèces oscillerait entre 5 et 10 millions,.Les bactéries sont ubiquitaires et sont présentes dans tous les types de biotopes rencontrés sur Terre.
Elles peuvent être isolées du sol, des eaux douces, marines ou saumâtres, de l’air, des profondeurs océaniques, des déchets radioactifs, de la croûte terrestre, sur la peau et dans l’intestin des animaux ou des humains.
Les bactéries ont une importance considérable dans les cycles biogéochimiques comme le cycle du carbone et la fixation de l’azote de l’atmosphère.Un nombre important de bactéries vit dans le corps humain, d'ordre comparable à la quantité des cellules qui le constituent, mais la masse de ces dernières est plus importante.
La plupart de ces bactéries sont inoffensives ou bénéfiques pour l'organisme.
Il existe cependant de nombreuses espèces pathogènes à l'origine de beaucoup de maladies infectieuses.Les bactéries peuvent être très utiles à l’humain lors des processus de traitement des eaux usées, dans le secteur agroalimentaire lors de la fabrication des yaourts ou du fromage et dans la production industrielle de nombreux composés chimiques.Les bactéries étant microscopiques, elles ne sont donc visibles qu'avec un microscope.
Antoine van Leeuwenhoek fut le premier à observer des bactéries, grâce à un microscope de sa fabrication, en 1676.
Il les appela « animalcules » et publia ses observations dans une série de lettres qu'il envoya à la Royal Society,,.Au XIXe siècle, les travaux de Louis Pasteur ont révolutionné la bactériologie.
Il démontra en 1859 que les processus de fermentation sont causés par des microorganismes et que leur croissance n’était pas due à la génération spontanée.
Il démontra aussi le rôle des microorganismes comme agents infectieux.
Pasteur conçut également des milieux de culture, des procédés de destruction des microorganismes comme l’autoclave et la pasteurisation.Le médecin allemand Robert Koch et ses collaborateurs mirent au point les techniques de culture des bactéries sur milieu solide.
Robert Koch est un des pionniers de la microbiologie médicale, il a travaillé sur le choléra, la maladie du charbon (anthrax) et la tuberculose.
Il démontra de façon claire qu’une bactérie pouvait être l’agent responsable d’une maladie infectieuse et il proposa une série de postulats (les postulats de Koch, toujours utilisés aujourd'hui) confirmant le rôle étiologique d’un microorganisme dans une maladie.
Il obtient le prix Nobel de physiologie ou médecine en 1905.Si les bactéries étaient connues au XIXe siècle, il n’existait pas encore de traitement antibactérien.
En 1909, Paul Ehrlich mit au point un traitement contre la syphilis avant l’utilisation de la pénicilline en thérapeutique suggérée par Ernest Duchesne en 1897 et étudiée par Alexander Fleming en 1929.
Ehrlich reçut le prix Nobel pour ses travaux sur l'immunologie en 1908, et fut un pionnier de l'usage de colorants pour détecter et identifier les bactéries, son travail étant la base de la coloration de Gram et de la coloration de Ziehl-Neelsen.Les microbiologistes Martinus Beijerinck et Sergei Winogradsky initièrent les premiers travaux de microbiologie de l’environnement et d’écologie microbienne en étudiant les relations entre ces microorganismes au sein de communautés microbiennes du sol et de l’eau.Le mot « bactérie » apparaît pour la première fois avec le naturaliste et zoologiste allemand Christian Gottfried Ehrenberg en 1838.
Ce mot dérive du grec βακτηριον, qui signifie « bâtonnet ».
Parallèlement Haeckel inventa en 1866 l'embranchement Monera pour regrouper au sein de son règne Protista tous les microorganismes sans structure interne (bien qu'excluant les cyanobactéries, alors classées parmi les plantes).
Ferdinand Cohn utilisa à son tour le terme Bacteria comme taxon en 1870 et tenta le premier de les classer rigoureusement selon leur morphologie.
Pour Cohn, les bactéries étaient des plantes primitives non chlorophylliennes.
À la suite des travaux de Cohn, Haeckel révisa la circonscription de ses « monères » pour y inclure les cyanobactéries.
Les termes de « monère » et de « bactérie » devinrent alors synonymes.En 1938 Herbert Copeland éleva les monères au rang de règne, à un niveau désormais égal aux animaux, plantes et protistes.
Ce n'est qu'en 1957 qu'André Lwoff distingua avec clarté les concepts de bactérie et de virus grâce à des arguments biochimiques et structuraux.
Enfin, Roger Stanier et Cornelis van Niel définirent pour la première fois rigoureusement en 1962 le concept de bactérie par l’absence d’organite membrané (et en particulier de véritable noyau, donc de mitose).Liste alphabétique de noms vulgaires ou de noms vernaculaires attestés en français.En 1977, Carl Woese grâce à ses travaux de phylogénie moléculaire divisa les procaryotes en deux domaines : les Eubacteria et les Archaebacteria ; il les renomma respectivement Bacteria et Archaea lors de la révision de sa nomenclature en 1990.
Le mot « bactérie » faisant référence à l'ensemble des procaryotes avant 1990, ce renommage a provoqué une certaine ambiguïté dans l'utilisation de ce terme et n'a donc pas été accepté par tous les biologistes,,,,.Certains biologistes, pensent que cette tentative de renommage tient davantage de la propagande (de la part de Carl Woese, afin d'accréditer ses idées) que de la science :Et plus loin dans le même article :Dans un cadre kuhnien la théorie des trois domaines qui sous-tend ce changement de nomenclature est parfois analysé comme un paradigme de la bactériologie moderne,,, ce qui expliquerait les résistances (principalement de nature sociologiques) contre sa remise en cause.Les bactéries présentent une grande diversité de tailles et de formes.
Les cellules bactériennes typiques ont une taille comprise entre 0,5 et 5 µm de longueur, cependant, quelques espèces comme Thiomargarita namibiensis et Epulopiscium fishelsoni peuvent mesurer jusqu’à 750 µm (0,75 mm) de long et être visibles à l’œil nu, (voir bactérie géante).
Thiomargarita magnifica, découverte en 2019, peut même mesurer jusqu'à 2 cm.
Parmi les plus petites bactéries, les mycoplasmes mesurent 0,3 µm, soit une taille comparable à certains gros virus.La plupart des bactéries sont soit sphériques soit en forme de bâtonnets.
Dans le premier cas elles sont appelées coques (du grec kókkos, grain) et dans le second bacilles (du latin baculus, bâton).
Il existe aussi des formes intermédiaires : les coccobacilles.
Quelques bactéries en forme de bâtonnets sont légèrement incurvées comme les Vibrio.
Ce sont des spirilles si la forme est invariable et rigide, des spirochètes si l’organisme est flexible et peut changer de forme.
La grande diversité de formes est déterminée par la paroi cellulaire et le cytosquelette.
Les différentes formes de bactéries peuvent influencer leur capacité d’acquérir des nutriments, de s’attacher aux surfaces, de nager dans un liquide et d’échapper à la prédation.Beaucoup d’espèces bactériennes peuvent être observées sous forme unicellulaire isolée alors que d’autres espèces sont associées en paires comme les Neisseria ou en chaînette, caractéristique des Streptocoques.
Dans ces cas, les coques se divisent selon un axe unique et les cellules restent liées après la division.
Certains coques se divisent selon un axe perpendiculaire et s’agencent de façon régulière pour former des feuillets.
D’autres se divisent de façon désordonnée et forment des amas comme les membres du genre Staphylococcus qui présentent un regroupement caractéristique en grappe de raisins.
D'autres bactéries peuvent s’élonger et former des filaments composés de plusieurs cellules comme les actinobactéries.En dépit de leur apparente simplicité, elles peuvent former des associations complexes.
Des capteurs leur permettent de détecter d'autres bactéries ou une surface (ce qui induit souvent chez elle un changement de comportement ; ainsi Pseudomonas aeruginosa ne devient virulente et active ses gènes de résistance que quand son « sens du toucher » l'informe qu'elle entre en contact avec une surface ; muqueuse pulmonaire par exemple).Les cyanobactéries forment des chaînes appelées trichomes où les cellules sont en relation étroite, grâce à des échanges physiologiques.
Certaines bactéries forment des colonies pouvant solidement s’attacher aux surfaces.
Ces « biofilms » sont un arrangement complexe de cellules et de composants extracellulaires, formant des structures secondaires comme des microcolonies, au sein desquelles se forme un réseau de canaux facilitant la diffusion des nutriments.Une caractéristique importante des bactéries est la paroi cellulaire.
La paroi donne à la bactérie sa forme et la protège contre l’éclatement sous l’effet de la très forte pression osmotique du cytosol.
Les bactéries peuvent être structuralement divisées en deux groupes : les bactéries à paroi unimembranée (ne contenant qu'une seule membrane, la membrane plasmique, voir Unimembrana) et les bactéries à paroi bimembranée (constituée de deux membranes superposées, la membrane interne et la membrane externe, voir Negibacteria).
La coloration de Gram est un critère empirique, quoique imparfait, permettant de déterminer la structure de la paroi bactérienne.Certains organites extracellulaires comme les flagelles ou les poils peuvent être enchâssés dans la paroi cellulaire.
Quelques bactéries peuvent fabriquer de fines couches externes à la paroi cellulaire, généralement essentiellement constituées de polysaccharides (des sucres).
D'autres bactéries peuvent s’envelopper d’une couche protéique appelée la couche S.En tant que procaryote (organisme sans noyau), les bactéries sont des cellules relativement simples, caractérisées par une absence de noyau et d’organites comme les mitochondries et les chloroplastes, elles n'ont pas non plus de réticulum endoplasmique ou d'appareil de Golgi.Le métabolisme d’une cellule est l’ensemble des réactions chimiques qui se produisent au niveau de cette cellule.
Pour réaliser ce processus, les bactéries, comme toutes les autres cellules, ont besoin d’énergie.
L’ATP est la source d’énergie biochimique universelle, commune à toutes les formes de vie, mais les réactions d’oxydo-réduction impliquées dans sa synthèse sont très variées selon les organismes et notamment chez les bactéries.Les bactéries vivent dans pratiquement toutes les niches environnementales de la biosphère.
Elles peuvent ainsi utiliser une très large variété de source de carbone et/ou d’énergie.Les bactéries peuvent être classées selon leur type de métabolisme, en fonction des sources de carbone et d’énergie utilisés pour la croissance, les donneurs d’électrons et les accepteurs d’électrons.L’énergie cellulaire des chimiotrophes est d’origine chimique alors que celle des phototrophes est d’origine lumineuse.
La source de carbone des autotrophes est le dyoxyde de carbone, tandis que des substrats organiques sont la source de carbone des hétérotrophes.
Il est aussi possible de distinguer deux sources possibles de protons (H+) et d'électrons (e-) : les bactéries réduisant des composés minéraux sont des lithotrophes alors que celles réduisant des substances organiques sont des organotrophes.Tout organisme vivant réalise en permanence de nombreuses réactions chimiques destinées à construire les biomolécules indispensables à la vie, et particulièrement lipides, protéines, acides nucléiques et saccharides.
Ces réactions ne sont possibles que grâce à l'énergie accumulée à la suite d’autres réactions chimiques.
Le métabolisme d'une bactérie est l'ensemble des réactions chimiques qui se produisent au niveau de la cellule bactérienne.
Les besoins énergétiques de la bactérie peuvent être satisfaits par deux mécanismes :Les bactéries possèdent un chromosome généralement unique et circulaire (mais il y a des exceptions) qui porte la majorité des gènes.
Certains gènes ayant des fonctions particulières (résistance à un antibiotique, un prédateur, adaptation physiologique au milieu, etc.) sont cependant localisés sur des petites sections d'ADN circulaire libres appelées plasmides.Il existe une grande diversité de métabolismes par rapport aux eucaryotes.
D'ailleurs la phototrophie et l'autotrophie chez les eucaryotes sont toujours le résultat d'une symbiose avec des bactéries (certains lichens par exemple) et/ou d'une symbiogenèse impliquant une cyanobactérie (chloroplaste).Source de matière : hétérotrophie vs autotrophieSource d'énergie : phototrophie vs chimiotrophieLes bactéries, avec les autres micro-organismes, participent pour une très large part à l’équilibre biologique existant à la surface de la Terre.
Elles colonisent en effet tous les écosystèmes et sont à l’origine de transformations chimiques fondamentales lors des processus biogéochimiques responsables du cycle des éléments sur la planète.Une population de bactéries peut avoir un comportement coordonné grâce à une messagerie moléculaire, le quorum sensing.Au sein des biofilms des relations s'établissent entre bactéries, conduisant à une réponse cellulaire intégrée.
Les molécules de la communication cellulaire ou « lang » sont soit des homosérines lactones pour les bactéries à Gram négatif, soit des peptides courts pour les bactéries à Gram positif.
De plus au sein de biofilms établis, les caractéristiques physico-chimiques (pH, oxygénation, métabolites) peuvent être néfastes au bon développement bactérien et constituer donc des conditions stressantes.
Les bactéries mettent en place des réponses de stress qui sont autant d'adaptation à ces conditions défavorables.
En général les réponses de stress rendent les bactéries plus résistantes à toute forme de destruction par des agents mécaniques ou des molécules biocides.L'étude des canaux ioniques bactériens a permis à une équipe de chercheurs de mettre en évidence, en 2015, une synchronisation du métabolisme de certaines bactéries au sein des communautés de biofilms bactériens par des vagues d'ions potassium.
Celles-ci résultent d'une boucle de rétroaction positive, dans laquelle un déclencheur métabolique induit la libération d'ions potassium intracellulaire, qui à son tour dépolarise les bactéries voisines.
Cette vague de dépolarisation coordonne les états métaboliques entre les bactéries à l'intérieur et à la périphérie du biofilm.
La suppression ou le blocage de l'activité des canaux potassium supprime cette réponse.Les eaux naturelles comme les eaux marines (océans) ou les eaux douces (lacs, mares, étangs, rivières, etc.) sont des habitats microbiens très importants.
Les matières organiques en solution et les minéraux dissous permettent le développement des bactéries.
Les bactéries participent dans ces milieux à l’autoépuration des eaux.
Elles sont aussi la proie des protozoaires.
Les bactéries composant le plancton des milieux aquatiques sont appelées le bactérioplancton.Il y a environ quarante millions de cellules bactériennes dans un gramme de sol et un million de cellules bactériennes dans un millilitre d’eau douce.
On estime qu'il y aurait (à un instant donné) quatre à six quintillions (4  × 1030 à 6 × 1030), soit entre quatre et six mille milliards de milliards de milliards de bactéries dans le monde, représentant une grande partie de la biomasse du monde.
Cependant, un grand nombre de ces bactéries ne sont pas encore caractérisées car non cultivables en laboratoire.Le sol est composé de matière minérale provenant de l’érosion des roches et de matière organique (l’humus) provenant de la décomposition partielle des végétaux.
La flore microbienne y est très variée.
Elle comprend des bactéries, des champignons, des protozoaires, des algues, des virus, mais les bactéries sont les représentants les plus importants quantitativement.
On peut y retrouver tous les types de bactéries, des autotrophes, des hétérotrophes, des aérobies, des anaérobies, des mésophiles, des psychrophiles, des thermophiles.
Tout comme les champignons, certaines bactéries sont capables de dégrader des substances insolubles d’origine végétale comme la cellulose, la lignine, de réduire les sulfates, d’oxyder le soufre, de fixer l’azote atmosphérique et de produire des nitrates.
Les bactéries jouent un rôle dans le cycle des nutriments des sols, et sont notamment capables de fixer l’azote.
Elles ont donc un rôle dans la fertilité des sols pour l’agriculture.
Les bactéries abondent au niveau des racines des végétaux avec lesquels elles vivent en mutualisme.À la différence des milieux aquatiques, l’eau n’est pas toujours disponible dans les sols.
Les bactéries ont mis en place des stratégies pour s’adapter aux périodes sèches.
Les Azotobacter produisent des cystes, les Clostridium et les Bacillus des endospores ou d’autres types de spores chez les Actinomycètes.Dans le sous-sol, dans l'eau ou dans les cavités humides, des bactéries colonisent inévitablement les galeries minières, puits de mines et leurs abords faillés ou évidés, y compris dans les centres de stockage souterrains ; elles sont parfois trouvée à grande profondeur dans le sous-sol, y compris dans les remontées de forages d'eau ou de pétrole.
Elles peuvent là aussi modifier leur environnement, être source de CO2 ou de méthane, d'acidification, de corrosion, de méthylation, de putréfaction et/ou interagir avec les nappes, certains métaux ou des matériaux de confinement (Rizlan Bernier-Latmani mène sur ce sujet une campagne expérimentale d'étude à des centaines de mètres de profondeur, au sein du laboratoire du Mont Terri, près de Saint-Ursanne dans le Jura, où est étudiée la pertinence de la roche argileuse pour le stockage géologique des déchets nucléaires).Les bactéries peuvent aussi être rencontrées dans des environnements plus extrêmes.
Des bactéries halophiles sont rencontrées dans des lacs salés, des bactéries psychrophiles sont isolées d’environnements froids comme des océans Arctique et Antarctique, des banquises.
Des bactéries thermophiles sont isolées des sources chaudes ou des cheminées hydrothermales.En 2007, des forages dans le pergélisol du nord-est de la Sibérie, du nord-ouest du Canada et de l'Antarctique ont permis à des scientifiques de l'université de Californie dirigée par le professeur Eske Willerslev (en) (Université de Copenhague) de mettre au jour des bactéries toujours vivantes vieilles d'environ 500 000 ans.
Les chercheurs ont montré chez ces bactéries des signes de réparation de leur ADN combiné à un état de dormance inférieure à l'activité métabolique nécessaire à la réparation de l'ADN maintenue à un bas niveau.En 2000, une équipe scientifique a annoncé avoir découvert une bactérie demeurée endormie dans un cristal de sel pendant 250 millions d'années.
De nombreux scientifiques sont très réservés vis-à-vis de ce résultat, qui serait plutôt dû à une colonisation récente du cristal.Dans l'espace, les bactéries deviendraient presque trois fois plus virulentes.
C'est du moins le cas de Salmonella typhimurium, une bactérie responsable d'intoxication alimentaire.
Celles-ci ont fait un voyage à bord de la navette Atlantis en 2006.
À leur retour, les bactéries qui avaient été conservées dans un récipient étanche, ont été transmises à des souris.
Il n'a fallu que le tiers de la dose habituelle pour tuer la moitié du groupe de souris qui avait été infecté,.On cherche actuellement à savoir s'il a existé une vie bactérienne sur la planète Mars.
Certains éléments d'analyse du sol martien semblent s'orienter en ce sens, et la présence abondante d'eau sur Mars jadis a peut-être pu constituer un terrain extrêmement favorable au développement de la vie bactérienne, si elle est apparue.
Si la chose venait à être confirmée, ce serait un élément important en faveur de l'hypothèse de panspermie.
Des chercheurs écossais ont mis en évidence en juin 2017 que le sol de mars éliminait la moindre bactérie.
C’est l’interaction entre le rayonnement ultraviolet, les substances oxydantes du sol de Mars, et surtout les perchlorates qui confère à la surface de la Planète rouge sa capacité à éliminer toute bactérie.
D'autres recherches s'intéressent aussi aux glaces de la lune jovienne Europe qui abritent de l'eau liquide sous leur surface.En dépit de leur apparente simplicité, les bactéries peuvent entretenir des associations complexes avec d’autres organismes.
Ces associations peuvent être répertoriées en parasitisme, mutualisme et commensalisme.
En raison de leurs petites tailles, les bactéries commensales sont ubiquitaires et sont rencontrées à la surface et à l’intérieur des plantes et des animaux.Dans le sol, les bactéries de la rhizosphère (couche de sol fixée aux racines des plantes) fixent l’azote et produisent des composés azotés utilisés par les plantes (exemple de la bactérie Azotobacter ou Frankia).
En échange, la plante excrète au niveau des racines des sucres, des acides aminés et des vitamines qui stimulent la croissance des bactéries.
D’autres bactéries comme Rhizobium sont associées aux plantes légumineuses au niveau de nodosités sur les racines.Il existe de nombreuses relations symbiotiques ou mutualistes de bactéries avec des invertébrés.
Par exemple, les animaux qui se développent à proximité des cheminées hydrothermales des fonds océaniques comme les vers tubicoles Riftia pachyptila, les moules Bathymodiolus ou la crevette Rimicaris exoculata vivent en symbiose avec des bactéries chimiolitho-autotrophes.Buchnera est une bactérie endosymbiote des aphides (puceron).
Elle vit à l'intérieur des cellules de l'insecte et lui fournit des acides aminés essentiels.
La bactérie Wolbachia est hébergée dans les testicules ou les ovaires de certains insectes.
Cette bactérie peut contrôler les capacités de reproduction de son hôte.Des bactéries sont associées aux termites et leur apportent des sources d'azote et de carbone.Des bactéries colonisant la panse des herbivores permettent la digestion de la cellulose par ces animaux.
La présence de bactéries dans l’intestin de l’Homme contribue à la digestion des aliments mais les bactéries fabriquent également des vitamines comme l’acide folique, la vitamine K et la biotine.Des bactéries colonisent le jabot d'un oiseau folivore (consommateur de feuilles), le Hoazin (Opisthocomus hoazin).
Ces bactéries permettent la digestion de la cellulose des feuilles, de la même manière que dans le rumen des ruminants.Des bactéries bioluminescentes comme Photobacterium sont souvent associées à des poissons ou des invertébrés marins.
Ces bactéries sont hébergées dans des organes spécifiques chez leurs hôtes et émettent une luminescence grâce à une protéine particulière : la luciférase.
Cette luminescence est utilisée par l'animal lors de divers comportements comme la reproduction, l'attraction de proies ou la dissuasion de prédateurs.Un nombre important de bactéries vit dans le corps humain, environ autant, voire plus, que de cellules le constituant, toutefois leur masse reste infime en comparaison.Les calculs donnent des résultats variés quant à leur nombre.
D'après certaines estimations, 1012 bactéries colonisent la peau, 1010 bactéries colonisent la bouche et 1014 bactéries habitent dans l'intestin.
D'autres calculs, réalisés par des chercheurs de l'institut Weizmann, indiquent qu'il y a plus de cellules bactériennes (~40 × 1012) que de cellules humaines (~30 × 1012) dans le corps humain,.La plupart de ces bactéries sont inoffensives ou bénéfiques pour l’organisme.
Il existe cependant de nombreuses espèces pathogènes à l'origine de beaucoup de maladies infectieuses comme le choléra, la syphilis, la peste, l’anthrax, la tuberculose.Le plus souvent, les maladies bactériennes mortelles sont les infections respiratoires : la tuberculose à elle seule tue environ deux millions de personnes par an, principalement en Afrique subsaharienne.
Des bactéries peuvent entraîner des troubles respiratoires ou intestinaux alors que d’autres peuvent être responsables de l’infection d'une blessure.
Les infections bactériennes peuvent être traitées grâce aux antibiotiques, qui le plus souvent inhibent une de leurs fonctions vitales (par exemple, la pénicilline bloque la synthèse de la paroi cellulaire).Les bactéries pathogènes sont responsables de maladies humaines et causent des infections.
Les organismes infectieux peuvent être distingués en trois types : les pathogènes obligatoires, accidentels ou opportunistes.Un pathogène obligatoire ne peut survivre en dehors de son hôte.
Parmi les bactéries pathogènes obligatoires, Corynebacterium diphtheriae entraîne la diphtérie, Treponema pallidum est l’agent de la syphilis, Mycobacterium tuberculosis provoque la tuberculose, Mycobacterium leprae la lèpre, Neisseria gonorrhoeae la gonorrhée.
Les Rickettsia à l’origine du typhus sont des bactéries parasites intracellulaires.Un pathogène accidentel présent dans la nature peut infecter l’Homme dans certaines conditions.
Par exemple, Clostridium tetani provoque le tétanos en pénétrant dans une plaie.
Vibrio cholerae entraîne le choléra à la suite de la consommation d’une eau contaminée.Un pathogène opportuniste infecte des individus affaiblis ou atteints par une autre maladie.
Des bactéries comme Pseudomonas aeruginosa, des espèces de la flore normale, comme des Staphylococcus de la flore cutanée, peuvent devenir des pathogènes opportunistes dans certaines conditions.
On rencontre surtout ce type d’infection en milieu hospitalier.La capacité d’une bactérie à provoquer une maladie est son pouvoir pathogène.
L’intensité du pouvoir pathogène est la virulence.
L’aboutissement de la relation bactérie-hôte et l’évolution de la maladie dépendent du nombre de bactéries pathogènes présentes dans l’hôte, de la virulence de cette bactérie, des défenses de l’hôte et de son degré de résistance.Pour déclencher une maladie, les bactéries infectieuses doivent d’abord pénétrer dans l’organisme et adhérer à un tissu.
Des facteurs d’adhésion permettent la fixation des bactéries à une cellule.
Le pouvoir invasif est la capacité de la bactérie à se répandre et à se multiplier dans les tissus de l’hôte, soit par un processus d'endocytose permettant leur pénétration intracellulaire, soit pour certaines bactéries en passant entre les cellules des muqueuses afin de coloniser la lamina propria sous-jacente.
Les bactéries peuvent produire des substances lytiques leur permettant de se disséminer dans les tissus.
Certaines bactéries présentent aussi un pouvoir toxinogène qui est la capacité de produire des toxines, substances chimiques portant préjudice à l’hôte.
On peut distinguer les exotoxines libérées lors de la multiplication des bactéries et les endotoxines fixées dans la membrane des bactéries.Les bactéries pathogènes tentant d’envahir un hôte rencontrent toutefois de nombreux mécanismes de défense assurant à l’organisme une protection aux infections.
Une bonne alimentation et une hygiène de vie correcte constituent une première protection.
La peau, les muqueuses forment une première ligne de défense contre la pénétration d’organismes pathogènes.
Les bactéries de la flore normale constituent aussi une barrière de protection.
Lorsqu’un micro-organisme a pénétré ces premières lignes de défense, il rencontre des cellules spécialisées qui se mobilisent contre l’envahissement : ce sont les phagocytes.
L’inflammation est une réaction défensive non spécifique.
Un second système de défense très efficace est le système immunitaire spécifique, capable de reconnaître des antigènes portés ou sécrétés par les bactéries, et d’élaborer des anticorps et des cellules immunitaires spécifiques de ces antigènes.En milieu hospitalier, le personnel soignant doit suivre des protocoles de protection (port de la blouse, gants, lunettes en chirurgie...).
En cas de contact avec un élément à risque (sang, liquide...), le personnel soignant doit impérativement et au plus tôt se laver les mains avec un produit désinfectant et aseptisant.Les bactéries pathogènes pour les plantes sont connues du grand public pour leur responsabilité dans la dévastation de cultures agricoles.
En 2001, les vergers du midi de la France étaient victimes d'une vague d'infection par une bactérie du genre Xanthomonas.En biotechnologie végétale, la bactérie du sol, Agrobacterium tumefaciens, est utilisée pour sa capacité à transmettre un fragment d'ADN à la plante cible lors de son cycle infectieux.Les Procaryotes sont d'importants outils dans le domaine de la biorestauration : on se sert d'organismes pour éliminer des polluants du sol, de l'eau et de l'air.
Exemple : Les archées décomposent la matière organique contenue dans les eaux usées pour la transformer en substance qui peut servir d'engrais.
Dans l'industrie minière, les Procaryotes aident à retirer les métaux contenus dans le minéral.
L'utilité des Procaryotes provient en grande partie de la diversité de leurs formes de nutrition et de métabolisme.L’origine de la microbiologie industrielle date de l’époque préhistorique.
Les premières civilisations ont utilisé sans le savoir des micro-organismes pour produire des boissons alcoolisées, du pain et du fromage.Les bactéries comme Lactobacillus, Lactococcus ou Streptococcus, combinées aux levures et moisissures interviennent dans l’élaboration d’aliments fermentés comme les fromages, les yaourts, la bière, le vin, la sauce de soja, le vinaigre, la choucroute.Les bactéries acétiques (Acetobacter, Gluconobacter) peuvent produire de l'acide acétique à partir de l'éthanol.
Elles se rencontrent dans les jus alcoolisés et sont utilisées dans la production du vinaigre.
Elles sont également exploitées pour la production d'acide ascorbique (vitamine C) à partir du sorbitol transformée en sorbose.La capacité des bactéries hétérotrophes à dégrader une large variété de composés organiques est exploitée dans des processus de traitement des déchets comme la bioremédiation ou le traitement des eaux usées.
Des bactéries sont également utilisées dans les fosses septiques pour en assurer l'épuration.
Des bactéries, capables de dégrader des hydrocarbures du pétrole, peuvent être utilisées lors du nettoyage d'une marée noire.
Le processus de nettoyage de milieux pollués par des micro-organismes est la bioremédiation.Des bactéries peuvent être utilisées pour récupérer des métaux d'intérêts économiques à partir de minerais.
L'activité de bactéries est ainsi exploitée pour la récupération du cuivre.Des bactéries peuvent être utilisées à la place de pesticides en lutte biologique pour combattre des parasites des plantes.
Par exemple, Bacillus thuringiensis produit une protéine Bt qui est toxique pour certains insectes.
Cette toxine est utilisée en agriculture pour combattre des insectes qui se nourrissent de plantes.En raison de leur capacité à se multiplier rapidement et de leur relative facilité à être manipulées, certaines bactéries comme Escherichia coli sont des outils très utilisés en biologie moléculaire, génétique et biochimie.
Les scientifiques peuvent déterminer la fonction de gènes, d’enzymes ou identifier des voies métaboliques nécessaires à la compréhension fondamentale du vivant et permettant également de mettre en œuvre de nouvelles applications en biotechnologie.De nombreuses enzymes utilisées dans divers processus industriels ont été isolées de micro-organismes.
Les enzymes des détergents sont des protéases de certaines souches de Bacillus.
Des amylases capables d’hydrolyser l’amidon sont très utilisées dans l’industrie alimentaire.
La Taq polymérase utilisée dans les réactions de polymérisation en chaîne (PCR) pour l’amplification de l’ADN provient d’une bactérie thermophile Thermus aquaticus.Les bactéries génétiquement modifiées sont très utilisées pour la production de produits pharmaceutiques.
C’est le cas par exemple de l’insuline, l’hormone de croissance, certains vaccins, des interférons… Certaines bactéries comme Streptomyces sont très employées pour la production d’antibiotiques.Certaines bactéries peuvent provoquer une dégradation d'installation (biocorrosion), en particulier les bactéries sulfato-réductrices.Il existe des bactéries tumoricides, ou bactéries carcinolytiques qui d'un côté sont des pathogènes connus (à part pour Bifidobacterium), mais qui ciblent particulièrement les cellules cancéreuses, et font conséquemment partie de traitements effectifs ou expérimentaux contre le cancer.
Ce sont un groupe de bactéries anaérobies facultatives ou obligatoires (capables de produire de l'adénosine triphosphate lorsque l'oxygène est absent et meurt à des niveaux d'oxygène normaux) pouvant cibler les cellules cancéreuses dans le corps, supprimer la croissance tumorale et survivre dans le corps pendant un certain temps, longtemps même après l'infection.
Lorsque des bactéries de ce type sont administrées dans le corps, elles migrent vers les tissus cancéreux et commencent à se développer, puis déploient leurs mécanismes respectifs pour détruire les tumeurs solides.Chaque espèce de bactérie utilise un processus différent pour éliminer la tumeur.
Les bactéries tumoricides courantes comprennent notamment Salmonella, Clostridium, Bifidobacterium, Listeria et Streptococcus.
Les premières recherches sur ce type de bactéries ont été mises en évidence en 1813 lorsque les scientifiques ont observé que les patients atteints de gangrène gazeuse, une infection causée par la bactérie Clostridium, pouvaient engendrer des régressions tumorales.Les bactéries les plus étudiées pour le traitement du cancer sont Salmonella, Listeria et Clostridium.
Une souche génétiquement modifiée de Salmonella (TAPET-CD) a terminé les essais cliniques de phase 1 pour les patients atteints d'un cancer métastatique de stade 4.
Des vaccins anticancéreux à base de Listeria sont actuellement produits et font l'objet de nombreux essais cliniques.
Des essais de phase I de la souche Clostridium appelée Clostridium novyi (C. novyi -NT) pour les patients atteints de tumeurs réfractaires au traitement ou de tumeurs qui ne répondent pas au traitement sont actuellement en cours.Les bactéries expriment des substances utilisés en médecine, comme l'éthanol.Alteromonas infernus produit le polysaccharide GY785 qui peut réparer une lésion de tissu humain (dont os et cartilage), en complément de l'injection de cellules souches du patient.
La pièce de théâtre Bílá nemoc (La Maladie blanche) de l'écrivain tchécoslovaque Karel Čapek, publiée en 1937, décrit une épidémie de morbus chengi, une maladie proche de la lèpre qui ne s'attaque qu'aux personnes âgées de plus de 45 ans, qu'elle tue en 3 à 5 mois.
Face au danger pour la population, le gouvernement dictatorial ne pense qu'à tirer profit de la maladie à des fins politiques.Le roman de science-fiction La Variété Andromède de l'écrivain américain Michael Crichton, paru en 1969, imagine l'arrivée sur Terre d'une bactérie extra-terrestre apportée par un astéroïde et qui déclenche des réactions mortelles chez les êtres humains.
Le mulet et la mule sont des hybrides statistiquement stériles de la famille des équidés, engendrés par un âne (Equus asinus) et une jument (Equus caballus).
Le nom de mulet vient du mot latin mulus, de même sens.
Aucune étymologie satisfaisante n'a abouti pour ce nom.
On appelle « mulet » l'hybride mâle et « mule » l'hybride femelle.Le mulet présente les caractéristiques de ses deux parents.
D'une taille intermédiaire entre l'âne et la jument, il possède d'un côté la force du cheval et de l'autre la robustesse et la rusticité de l'âne.
Il est réputé résistant, le pied sûr, endurant, courageux et intelligent.
Il présente un nombre de chromosomes exactement intermédiaire entre celui de ses deux espèces parentales, soit 63 chromosomes.Les caractéristiques physiques du mulet les plus notables sont :Le mulet et la mule tirent comme avantages :Les mulets sont le plus souvent stériles.
En cinq siècles, la société muletière britannique n'a enregistré que 60 naissances naturelles dues à des croisements spontanés entre mulets, ce qui montre la marginalité du phénomène et la quasi impossibilité en pratique de créer une nouvelle espèce commercialement viable pour les éleveurs.
On sait depuis 1999 que ce sont les différences de structures chromosomiques chez les deux espèces parentales qui sont responsables du problème d'appariement des chromosomes au cours de la méiose, plutôt que le nombre impair de chromosomes des mulets.Le mulet et la mule présentent dans 10 % des cas une anémie hémolytique grave liée aux anticorps de la mère contenus dans le colostrum lors des premiers jours de l'allaitement.
La cause a été identifiée depuis le milieu des années 1940 et résolue depuis par le biais d'un titrage des anticorps, d'un retard de l'allaitement, et de la transfusion de globules de la mère.Les croisements ânes et chevaux remontent à l'antiquité et se sont largement répandus depuis le Ve siècle jusqu'à nos jours.En France, au XIXe siècle, l'industrie mulassière est des plus florissantes.
Très réputé à l'étranger, le mulet s'exporte en Suisse, en Allemagne, en Italie, en Espagne, au Portugal, dans les pays nordiques et également en Amérique.
Le développement de l'élevage français se fait sur plusieurs zones géographiques : le Poitou, où les mules poitevines sont puissantes et de grandes tailles, le Dauphiné, le Massif central et les Pyrénées, où la mule des Pyrénées est plutôt utilisée pour les travaux légers et pour un usage de luxe.
Son déclin s'amorce au début du XXe siècle avec l'arrivée de la motorisation.On distingue le mulet de bât, utilisé en montagne, le mulet de trait, qui rend les mêmes services que rendrait un cheval dans d'autres régions, et le mulet de selle, surtout aux États-Unis, qui est utilisé avec succès dans toutes les disciplines équestres.En France, l’importance du commerce des muletiers du Velay est connue dès le XVIe siècle car les routes du Velay ou du Vivarais étaient peu praticables,.Dans l'armée française, le train muletier faisait partie des moyens de transports militaires en terrains montagneux dès la création des troupes alpines en Europe entre 1870 et 1890.
L'animal est apprécié pour sa robustesse.
En argot militaire français les mulets étaient appelés « brèles »,.
La mauvaise réputation du mulet — animal de bât très utile mais réputé pour son caractère agressif et la dangerosité de ses ruades, — a fait que le mot brêle est resté en argot pour désigner un bon à rien, En 1975, les derniers mulets disparaissaient des effectifs de l’armée française à l’exception d'un animal retraité des troupes de montagne allemandes qui deviendra la mascotte par le 110e régiment d’infanterie dissout en 2014.
Toutefois en 2021, le 7e bataillon de chasseurs alpins a réintroduit deux mulets en « auxiliaires logistiques ».
Les Alpini, troupes de montagne italiennes, ont également employé des mulets, depuis la fondation de leur corps en 1872, jusqu'en 1993.L'Armée de terre indienne, en 2019, dispose de 6 000 mules.
L'armée de pakistanaise en a également.Le bardot, parfois confondu avec les mules et les mulets, est issu du croisement entre une ânesse et un cheval.
On a pu croire autrefois à l'existence du joumart, produit du croisement entre un cheval ou un âne et une vache, ou entre un taureau et une ânesse ou une jument.Ce nom désigne, par extension, tout animal de sang mêlé, issu du croisement de deux espèces voisines.Il existe aussi le cerf mulet, qui n'a de rapport que par le nom, et qui est désigné ainsi à cause de ses oreilles similaires à celles d'un mulet.
Selon l'historien Thierry Murcia, qui cite diverses sources antiques, on appelait autrefois mule de Libye (ou parfois « âne de Libye »), le fruit du croisement entre un onagre et une jument.Compagnon utilitaire de l'homme, le mulet a longtemps été utilisé dans la langue française où de nombreuses expressions et proverbes y font référence.
Les expressions « être chargé comme une mule » ou « être têtu comme une mule » sont rentrées dans le langage courant et renvoient directement aux qualités et défauts de l'animal,.
Le mulet est également présent en littérature, et ce dès l'antiquité, comme dans les Fables d'Ésope ainsi que chez Phèdre.
Jean de La Fontaine l'utilise également dans ses Fables et Alphonse Daudet lui dédie l'une des nouvelles du recueil des Lettres de mon moulin, La Mule du pape.
(notamment pour sa place dans le calendrier républicain / révolutionnaire français chaque 5 messidor).
Un test de grossesse permet de savoir si une femme est enceinte ou non.
Il est réalisable de différentes façons.Il est possible de se procurer en pharmacie, en grande surface ou sur des sites internet dédiés, un test qui détecte le taux de hCG (l'hormone chorio-gonadotrophique humaine) contenue dans l'urine.
Le test ne fonctionne correctement que deux semaines approximativement après la fécondation.
En France, son achat est possible sans ordonnance mais n'est pas remboursé par la Sécurité sociale.
Depuis le décret no 2011-969 du 16 août 2011, les tests de grossesse et d'ovulation sont autorisés en libre accès dans les pharmacies d'officine.Le taux de hCG peut également être détecté par une prise de sang.L'échographie obstétrique permet aussi de détecter une grossesse.Il semble que dans l'Égypte antique les femmes urinaient sur différentes céréales et observaient leur germination afin de savoir si elles étaient enceintes.
Si les céréales poussaient, alors la femme était considérée comme étant enceinte.
Le sexe du bébé attendu se déterminait en fonction de la vitesse de germination des céréales.
Si le blé grandissait plus vite que l'épeautre, il s'agissait d'un garçon ; si en revanche l'épeautre grandissait plus rapidement, il s'agissait d'une fille.
Les céréales citées ne font pas l'unanimité parmi les chercheurs.
Les différents papyrus sur lesquelles ces remarques sont basées datent d'il y a trois mille ans, ils sont toutefois connus grâce à des recopies grecs d'il y a mille cinq cents ans.Des tests ont été réalisés à la fin du XIXe siècle avec des tritons ou des grenouilles, l'urine féminine déclenchant la ponte.
À partir des années 1930, les femelles des espèces de Xenopus laevis ont été choisies pour leur capacité à pondre toute l'année.
Ce genre de test est devenu commun dans les années 1940-1950 sous le nom de test de Hogben, du nom de Lancelot Hogben.Le test de la lapine ou test de Friedman est aussi un procédé qui permet de savoir avec une lapine si une femme est enceinte.
En effet, il suffit d'injecter de l'urine de la patiente dans l'ovaire de la lapine, ce qui provoque l'ovulation de l'animal.La plupart des tests de grossesse vendus à l'heure actuelle repose sur le principe de l'immunochromatographie et sont apparus au milieu des années 1970 (grâce à la découverte des anticorps monoclonaux).
L'hormone hCG présente dans l'urine va se lier à un anticorps de détection coloré, puis migrer le long de la bande.
Les anticorps fixés sur les bandes capturent les complexes anticorps-hCG (positif) et le détecteur seul (contrôle négatif).
Un hybridome est une cellule provenant de l'hybridation artificielle de cellules lymphoïdes normales de mammifères et de cellules myélomateuses de tumeurs malignes du système immunitaire.L' hybridome cumule les propriétés des deux cellules de départ : production spécifique d'anticorps pour le lymphocyte et immortalité pour la cellule cancéreuse.Les hybridomes donnent des lignées immortalisées stables productrices d'anticorps monoclonaux.
Ils servent à produire en grande quantité des anticorps monoclonaux utilisés comme réactifs dans la recherche, pour l'établissement de diagnostics, ou utilisés pour produire certains médicaments à base d'anticorps monoclonaux, notamment utilisés en cancérologie (ex : trastuzumab dans le cancer du sein) mais également dans d'autres pathologies (infliximab contre la polyarthrite rhumatoïde et la maladie de Crohn) .Pour diverses applications, de grandes quantités d'anticorps spécifiques et purs sont nécessaires.
Or, en produisant des anticorps par injection d'un antigène, plusieurs lymphocyte B sont sollicités ce qui donne lieu à une hétérogénéité d'anticorps.
En 1975, Cesar Milstein et Georges Köhler, du Medical Research Counsil de Cambridge, en Angleterre ont cherché un moyen de produire un seul type d'anticorps.
Ils ont contourné le problème d'hétérogénéité des anticorps, en isolant les cellules capables de produire l'anticorps souhaité et en cherchant à les cultiver.
Malheureusement, les cellules capables de produire les anticorps, les plasmocytes, ne pouvaient alors pas se développer en culture.
Ils ont pensé à utiliser des cellules malignes de myélomes car ce sont les cellules les plus proches des cellules voulues et qui se développent rapidement, éternellement et produisent de grandes quantités d'anticorps.
Mais celles-ci ne répondent pas à un antigène particulier ; elles produisent l'anticorps du lymphocyte B normal avant que celui-ci ne devienne malin.L'équipe de Milstein et Köhler a combiné les propriétés de ces deux cellules pour obtenir les cellules hybrides appelées hybridomes.La production d'hybridomes passe les étapes suivantes :remarque : Les hybridomes peuvent être congelés pour la conservation.Les hybridomes produisent des anticorps monoclonaux qui peuvent servir comme sondes très spécifiques.
Cette particularité est très utile pour le diagnostic médical.
Les anticorps permettent de mesurer la concentration de protéines spécifiques dans le sang ou l'urine, par exemple un test de grossesse qui décèle la présence d'une protéine.
Les anticorps monoclonaux peuvent aussi être utilisés pour la purification des protéines.
La méthode des hybridomes est très utile comme agent thérapeutique dans le traitement des maladies humaines.
L'opsonisation est un processus biochimique par lequel une molécule (alors qualifiée d'opsonine) recouvre la membrane d'une cellule cible (une bactérie ou une cellule du corps infectée par un agent pathogène) pour favoriser sa phagocytose par une cellule dotée de récepteurs pour les opsonines.On distingue deux types d'opsonines qui agissent de façon synergique :Ce processus fait partie de l'immunité innée et est réalisé principalement par les cellules présentatrices d'antigènes (cellule dendritique, macrophage et lymphocyte B).
La sérologie est l'étude des sérums et des variations ou modifications de leurs propriétés au cours des maladies.Depuis les progrès de la biologie, elle consiste surtout, via ce qu'on appelle communément une analyse de sang, à mettre en évidence des indices de présence d'agents pathogènes dans l'organisme, au moyen de différents tests.
Elle permet une approche quantitative et qualitative, avec par exemple le dosage d'anticorps spécifiques.
Elle est donc liée à l'étude des immunoglobulines du sérum sanguin ou d'autres liquides organiques.
Elle est utilisée comme outil diagnostic, comme outil de dépistage (SIDA, hépatite, etc.), comme outil épidémiologique et de plus en plus écoépidémiologique.
En raison de réactions croisées, du développement à bas bruit de certains pathogènes, ou du délai nécessaire à l'apparition détectable d'anticorps, ce n'est pas un outil de diagnostic fiable à 100 %.Une « sérologie positive » pour un micro-organisme X (ou séropositivité) signifie simplement que l'organisme a, dans un passé plus ou moins récent, combattu le micro-organisme X et synthétisé des anticorps dirigés contre celui-ci.
Ce micro-organisme peut ne plus être présent, mais si plusieurs sérologies successives montrent une augmentation du taux d'anticorps, c'est qu'il y a infection (ou réinfection) en cours.La sérologie s’effectue sur un prélèvement sanguin veineux (en général au pli du coude).
Il n'est pas indispensable d'être à jeun.
Pour établir un diagnostic, deux prélèvements espacés de deux à quatre semaines sont souvent utiles pour montrer une ascension marquant une infection récente.
Les dépistages nécessitent en général un seul prélèvement.Généralement, la sérologie consiste à évaluer l'immunité contre une maladie en mesurant la quantité d'anticorps spécifiques de celle-ci.
Elle peut être utilisée également pour s'assurer de l'efficacité d'une vaccination (c'est le cas par exemple pour l'hépatite B).
Elle peut enfin servir au diagnostic d'une maladie auto-immune.Le taux d'anticorps augmente après un contact avec un agent pathogène, si celui-ci est détecté par le système immunitaire.
Les premiers anticorps produits, après un temps de latence, appartiennent à la classe des IgM (immunoglobulines M).
Celle-ci laisse progressivement place à une autre classe, les IgG (immunoglobulines G), qui seront plus durablement produites par l'organisme.
En cas de réinfection par un même agent pathogène, le taux d'IgG réaugmente brutalement par un phénomène mémoire du système immunitaire vis-à-vis du pathogène.
Le temps de latence et l’effet mémoire diffèrent selon les maladies, et selon le patient et l'état de son système immunitaire.
certains microbes (virus de la grippe par exemple) peuvent, au moins provisoirement, mais à plusieurs reprises successives, déjouer le système immunitaire en changeant par mutation leurs protéines de surface, ou en utilisant une sorte de déguisement constitué de protéines directement prélevées à l'hôte.
Leur détection par le système immunitaire et par la sérologie peut alors être plus tardive.La sérologie n’est pas appliquée à toutes les infections.
Une liste non exhaustive est proposée ci-après :etc.etc.Il existe de nombreuses techniques de détection des anticorps :La sensibilité et la spécificité varient d’une technique à une autre, donc influent sur le choix de la technique retenue.
Pour un dépistage on cherche à avoir très peu de faux négatifs, c’est pourquoi une technique plus sensible sera valorisée.
Inversement pour une confirmation, on cherche à avoir très peu de faux positifs, ainsi une technique plus spécifique conviendra mieux.La réponse immunitaire à une infection fait parfois intervenir la création d'anticorps.La présence d'anticorps spécifiques à une maladie indique que la personne, à un moment donné dans le passé, a été infectée par la maladie ou est simplement entrée en contact avec l'agent pathogène.
On dit que la personne a une sérologie positive, ou bien est séropositive.
Inversement, l'absence d'anticorps indique habituellement que la personne n'a pas été contaminée, la personne est dite séronégative.Il s'agit d'une méthode indirecte puisqu'elle ne cherche pas la présence de l'agent pathogène mais la réponse du système immunitaire contre cet agent pathogène.Depuis la découverte du VIH par l'opinion publique au milieu des années 1980, le terme « séropositif » désigne dans le langage courant une personne qui a obtenu un résultat positif à un test de détection d'anticorps dirigés contre des protéines apparentées au VIH (ELISA ou Western Blot).
Un test positif confirmé par Western blot signifie que le sujet a été contaminé par le virus VIH, ou, plus exactement, qu'à la suite d'un contact avec ce virus, son système immunitaire a fabriqué des anticorps.
En effet, ce test n'explore que la présence d'anticorps et non pas directement celle du virus.Dans l'absolu, le terme n'est pas spécifique au VIH.
Lorsqu'on dit par exemple d'une femme enceinte qu'elle est séropositive pour la toxoplasmose, cela signifie qu'elle a déjà été en contact avec la toxoplasmose et qu'il n'y a plus de risque qu'elle l'ait de nouveau au cours de cette grossesse.De même pour les maladies auto-immunes, la présence d'un anticorps auto-immun sera indiquée par le terme de séropositivité, et son absence par le terme de séronégativité.
Les polyarthrites rhumatoïdes sont ainsi dites séropositives lorsque la recherche d'anticorps appelé facteur rhumatoïde est présent.La séroconversion est le passage d'une séronégativité à une séropositivité.
Ce terme est souvent utilisé en obstétrique ou en médecine fœtale pour désigner la date de survenue d'une infection, par exemple la toxoplasmose.
Ainsi les conséquences d'une séroconversion sur le fœtus dépendent du terme de la grossesse ou de l'âge gestationnel du fœtus.
Le rituximab (commercialisé par les laboratoires Hoffmann-La Roche et sa filiale Genentech sous les noms Rituxan et MabThera) est un anticorps monoclonal chimérique dirigé contre la molécule de surface CD20 (présente sur la plupart des cellules B).
Il permet de diminuer de façon substantielle le nombre de lymphocytes B par un effet toxique direct sur ces cellules.
Deux spécialités biosimilaires sont disponibles  en France : la spécialité Rixathon commercialisée par le groupe Sandoz (filiale de Novartis) et la spécialité Truxima commercialisée par le groupe Celltrion Healthcare Hungary Kft représenté en France par Biogaran.C'est un médicament utilisé dans le traitement de certains lymphomes, exprimant la molécule de surface CD20, c'est-à-dire la plupart des lymphomes B et la leucémie lymphoïde chronique.
Ses principales indications sont les lymphomes diffus à grandes cellules B, les lymphomes folliculaires, les lymphomes du manteau et la leucémie lymphoïde chronique.
Il est également actif dans la leucémie aiguë lymphoblastique dans les formes CD20.Il est également utilisé aujourd'hui pour traiter les formes sévères de certaines affections auto-immunes, en particulier les anémies hémolytiques, les purpuras thrombopéniques, le lupus, et aussi la polyarthrite rhumatoïde.Après une greffe de moelle ou d'organe il permet de traiter les lymphomes induits par le virus EBV.Enfin, il est également utilisé dans des formes particulières de rejet de greffes d'organes (rejet aigu vasculaire de mécanisme humoral).Il est de plus en plus utilisé dans le traitement en seconde ligne de la myasthénie réfractaire ou résistante aux cortico-dépendante, après qu'une étude rétrospective a montré son efficacité.Ce médicament est en cours de test pour le traitement de la sclérose en plaques et a des résultats prometteurs lors d'une leucémie lymphoïde chronique.Son efficacité s'avère être décevante dans le lupus érythémateux disséminé,.Dans les vascularites avec anticorps antineutrophiles cytoplasmatiques (ANCA), le rituximab pourrait être une alternative au cyclophosphamide,.
Il pourrait avoir un intérêt dans le syndrome de Gougerot-Sjögren.Il est administré sous forme de perfusion par voie IV lente ; le rythme dépend du type de pathologie à traiter.Une urticaire, une fièvre, des frissons, peuvent se voir dans près de la moitié des cas après une injection de rituximab.
Ces effets indésirables sont le plus souvent bénins mais parfois sévères (maladie sérique), dans 10 % des cas environ.
Ils tendent à s'estomper si on poursuit le traitement.
Ils sont d'origine allergique et une désensibilisation peut en améliorer la tolérance.Rarement, une pneumopathie interstitielle peut survenir, d'évolution parfois fatale.
Une perforation intestinale a été décrite en cas de localisation digestive du lymphome.
Des cas de leucoencéphalopathies multifocales progressives ont été décrits.Du fait de son mécanisme d'action, il entraîne un certain degré d'immunodéficience ayant pour conséquence une plus grande sensibilité aux infections.
Cette immunodéficience est relative puisque la fonction des lymphocytes T est préservée.
Des cas de neutropénies retardées ont été décrits.Le Truxima du laboratoire Biogaran est passé en avril 2017 à la commission de transparence de la HAS en France avec un avis favorable .L'ofatumumab, le tositumomab, l'obinutuzumab et l'ocrelizumab sont d'autres anticorps monoclonaux se fixant sur une autre zone de la molécule CD20.Le rituximab serait la cinquième molécule médicamenteuse vendue, en termes de valeur, en 2012, avec un chiffre projeté de 7,1 milliards de dollars.
Une pandémie Écouter (du grec ancien πᾶν / pãn « tous », et δῆμος / dễmos « peuple ») est une épidémie présente sur une large zone géographique internationale.
Dans le sens courant, elle touche une partie particulièrement importante de la population mondiale.Les pandémies surviennent lors de déséquilibres majeurs liés à des modifications sociales et environnementales au cours de l'histoire (révolution agricole, guerres et commerce, voyages et grandes découvertes, révolution industrielle et empires coloniaux, mondialisation…).Les conséquences d'une pandémie non maîtrisée peuvent être très importantes, comme cela a été le cas de la peste noire en Europe et en Asie, où elle a tué en quelques années des dizaines de millions de personnes et a eu un fort impact sur la démographie, ou, plus récemment, avec l'infection par le virus de l'immunodéficience humaine (VIH) qui touche sévèrement l'Afrique subsaharienne.Au XXIe siècle, la surveillance et le contrôle d'une pandémie reposent en premier lieu sur une coopération internationale.Le terme pandémie apparait en français en 1752 sous le modèle de épidémie (epi « sur » et demos « peuple »).
Une « pan-démie » est étymologiquement (sous-entendu) un mal qui s'étend sur l'ensemble (pan-) de la population (demos).Dans son sens général, une pandémie désigne une épidémie qui se développe à l'échelle mondiale, ou sur de vastes zones internationales traversant des frontières, et touchant le plus souvent un grand nombre de personnes,.
Mais, selon le journaliste spécialisé Marc Gozlan, "il n’existe pas de définition claire et unanimement acceptée du terme pandémie".Une description pertinente d'une « pandémie » est en littérature celle de Jean de La Fontaine, dans « Les Animaux malades de la peste » : « Ils ne mouroient pas tous, mais tous eſtoient frappez ».La notion de pandémie, et les concepts et modèles permettant d'y réagir, porte en premier lieu sur l'émergence de maladies infectieuses fortement contagieuses, et les modalités d'action permettant d'en atténuer la propagation, et les effets sanitaires ou sociaux.
La question centrale est alors celle de sa propagation.La transformation d'une épidémie en pandémie est d'autant plus facilitée dans un monde de plus en plus globalisé.Le terme de « pandémie » est parfois employé pour des maladies non infectieuses.
En 1997, après une consultation tenue à Genève (3-5 juin), l'OMS a parlé d'une « épidémie globale » de l'obésité dans le monde.
Le terme pandémie peut alors s'appliquer aux addictions, aux maladies cardiovasculaires, à celles liées au grand âge, etc. voire à tout phénomène ou comportement émergent devenant très répandu ou mondialisé.
Dans cette acception, la notion de « propagation » est au mieux secondaire (et probablement limitée à une question de structure sociale ou de comportement culturel) ; une pandémie renvoie simplement à la politique permettant de lutter à long terme contre son incidence, ou d'en atténuer les effets sanitaires ou sociaux.Il faut attendre 2011 "pour que le mot pandemic entre dans le thesaurus des mots clés (MeSH) de la base de données biomédicales PubMed de la National Library of Medicine (Bethesda, Maryland, États-Unis)".Les épidémies mondiales de grippe saisonnière sont des « pandémies » au sens ordinaire : l'Organisation mondiale de la santé (OMS) suit mondialement la grippe saisonnière pour la composition des vaccins antigrippaux.
Cependant, les termes de pandémie grippale ou de grippe pandémique sont utilisés pour désigner plus particulièrement l'apparition d'un nouveau virus grippal qui se propage mondialement.Pour l'OMS, « Une pandémie est une épidémie mondiale d'une maladie.
Une pandémie de grippe peut survenir lorsqu'un nouveau virus grippal apparaît contre lequel la population humaine n'est pas immunisée.
Cette définition élimine la référence précédemment retenue à un « nombre élevé de morts et de maladie ».En effet, selon Patrick Zylberman, professeur émérite d’histoire de la santé :Dans ses plans de préparation (1999, 2005, 2009) contre une grippe pandémique, l'OMS a proposé des niveaux d'alerte organisés d'abord en six, puis en neuf phases,.
Les modifications actualisées de 2009 ont fait l'objet de critiques de la part de ceux qui y voient une influence de l'industrie pharmaceutique.En 2017, l'OMS propose quatre phases pandémiques grippales : phase interpandémique, phase d'alerte (identification d'un nouveau sous-type de virus chez l'humain) phase pandémique (propagation mondiale), phase de transition (mesures de relèvement en fin d'épidémie).
Ces phases mondiales ne doivent pas être confondues avec deux autres processus relevant, en dernier ressort, de la responsabilité du directeur général de l'OMS :Les actions nationales sont à dissocier des phases mondiales dans la mesure où l’évaluation mondiale du risque, par définition, n’est pas révélatrice de la situation dans chacun des États Membres.Le facteur premier dans la propagation d'une épidémie est d'influer sur le nombre de reproduction de base, ou R0, c'est-à-dire le nombre de personnes qui sont en moyenne infectées par contagion par une personne malade, pendant la durée de sa maladie.
Ce nombre est fondamental :Sur un territoire donné, la lutte contre une pandémie abordera trois aspects.Il existe quatre niveaux de causes différentes et spécifiques menant à une pandémie :Dans le cas de retour d'une maladie infectieuse déjà connue, seuls les niveaux trois et quatre sont concernés.Le niveau 1 est surtout biologique.
Il dépend des caractéristiques de l'agent, et de la capacité à le détecter.
L'émergence est rendue visible par l'utilisation de nouvelles techniques (biologie moléculaire, bio-informatique).
Par exemple, l'agent du sida n'a pu être conceptualisé que par la connaissance des virus ARN, de nouveaux coronavirus par l'utilisation de la bio-informatique.Le niveau 2 est biomédical, mettant en œuvre des systèmes de surveillance épidémiologique de maladies ou de syndromes (découverte du sida par les CDC).Les niveaux 3 et 4 sont, pour l'essentiel, d'ordre environnemental et social.
Les facteurs en jeu sont nombreux, :Il s'avère de plus en plus que les rapports entre les germes microbiens et les populations humaines devraient dépasser les métaphores militaires qui les opposent de façon radicale.
Il faudrait interpréter les pandémies (ou épidémies dans un « village mondial ») comme une coévolution darwinienne liée à des déséquilibres écologiques (démographie humaine et perturbations de l'environnement).En 2015, l'OMS publie une liste de 8 pathogènes émergents à surveiller en priorité (affectation de nouveaux moyens) :Cette liste est susceptible de révision annuelle en fonction de la situation mondiale, elle devrait varier entre 5 et 10 maladies prioritaires.
Trois autres sont candidats prioritaires : maladie à virus Zika, Chikungunya, et syndrome de fièvre sévère avec thrombocytopénie.En 2015, le virus Zika, transmis par moustique, provoque des épidémies (maladie à virus Zika) dans près de 70 pays, dont de graves atteintes chez les femmes enceintes au Brésil (nouveau-nés atteints de microcéphalie).D'autres maladies présentent un risque potentiel important, mais elles ne sont pas incluses dans la liste, car il existe déjà des moyens de contrôle ou d'importants secteurs de recherches consacrés à ces maladies : sida, tuberculose, paludisme, grippe aviaire et dengue.En règle générale, le choix des maladies prioritaires se basent sur neuf critères :De façon plus détaillée, d'autres facteurs sont pris en compte, par exemple les facteurs par rapport au système immunitaire :Un autre exemple, les facteurs liés au contexte :Les moyens de contrôle d'une pandémie reposent en premier lieu sur une coopération internationale, concrétisée par un règlement sanitaire international, instrument juridique de droit international.La surveillance épidémiologique est à la fois nationale, régionale (à l'échelle d'un continent) et mondiale.
Elle porte à la fois sur la population humaine et la santé animale domestique ou sauvage.
Au niveau régional ou mondial, il existe une surveillance par imagerie satellitaire (épidémiologie intégrée dans une écologie du paysage).L'expertise des agents pathogènes, notamment des virus, est le fait des méthodes de biologie moléculaire.
Celles-ci sont menées dans des réseaux de laboratoires spécialisés, et pour les agents pathogènes les plus dangereux, dans des laboratoires de haute sécurité.Sur le plan international, l'OMS peut formuler des recommandations et des conseils aux voyageurs.
Une épidémie peut être déclarée par l'OMS d'abord comme une urgence de santé publique de portée internationale, puis comme une pandémie.
En situation pandémique, l'OMS propose des recommandations sanitaires stratégiques et de gestion de crise, comme des mesures de confinement ou de limitation de déplacement.Les mesures générales de santé publique sont adaptées à chaque situation particulière.
Une mesure essentielle est l'information du public, en situation de crise.
Pour être efficace, cette information doit s'appuyer sur une confiance réciproque entre ceux qui savent (experts), ceux qui peuvent (autorités politiques, équipes médicales ou de santé publique) et ceux qui sont affectés (communautés citoyennes).
Au XXIe siècle, écouter et comprendre les croyances, les préoccupations et les perceptions du grand public est aussi important que d'apporter des informations exactes ou des recommandations appropriées.
Exposer franchement ce qui est connu et ce qui reste incertain est essentiel dans l'établissement de la confiance.Les épidémies deviennent possibles à partir de la révolution néolithique (vers 6000 av.
en Europe), dès que des groupes humains atteignent une taille suffisante, avec des contacts fréquents entre ces différents groupes, d'où l'importance de la sédentarisation et de l'urbanisation liées à l'agriculture et au commerce.Les grandes épidémies sont d'abord rares, puis plus fréquentes avec les liaisons commerciales ou conflits militaires impliquant un réseau de cités de plus en plus peuplées et connectées à de longues distances.
La première « pandémie » décrite est la peste d'Athènes en 428 av.
Pandémie de typhus probable, elle serait venue d'Éthiopie, frappant l'Égypte, la Perse, et la Grèce.De nombreuses épidémies sont signalées dans la première moitié de l'histoire romaine, notamment par Tite-Live mais elles s'étendent rarement au-delà des villes voisines.
J.-C., la conquête romaine entraîne la construction d'un réseau routier en direction du Proche-Orient.
De nouvelles épidémies apparaissent en Italie, dont la lèpre.
J.-C., Tacite rapporte une autre maladie - qu'il ne décrit pas - qui, en trois mois, fait 30 000 morts dans la ville de Rome, et s'étend en Gaule et en Germanie.De grandes épidémies à l'échelle européenne surviennent jusqu'à la fin de l'Empire romain.
Les plus connues sont la peste antonine (167-172 ap.
ou peste galénique (décrite par Galien) qui serait une variole probable ; la peste de Saint Cyprien (251-256), décrite par Cyprien de Carthage, de nature indéterminée.Plusieurs épidémies de « pustules » (maladie indéterminée, variole ou charbon selon les auteurs) surviennent au cours du IVe siècle, notamment celle décrite par Ammien Marcellin, lors de guerres perso-romaines.Vers le Ve siècle, le commerce diminue avec comme corollaire l'absence d'épidémies notables, mais quelques « pestes » peuvent accompagner les grandes invasions.
Du VIe au VIIIe siècle deux grandes pandémies frappent l'Europe, l'une de variole, l'autre de peste bubonique ou peste de Justinien (541-767) considérée comme la première pandémie de peste.La lèpre devenue endémique dans l'Antiquité tardive recule au haut Moyen Âge, après l'an 800, les épidémies de variole s'espacent et la peste disparaît.
Trois autres grandes épidémies frappent alors l'Europe : l'ergotisme, une intoxication venue d'Asie centrale, et qui atteint son apogée au XIIe siècle.
À partir du Xe siècle de grandes épidémies (interprétées comme des grippes pandémiques) surviennent une ou deux fois par siècle ; le paludisme jusqu'alors confiné en Méditerranée, tend à s'installer dans les zones marécageuses de l'Europe du Nord.À partir du Moyen Âge central, les nouveaux contacts avec le Proche-Orient relancent la lèpre.
De grandes épidémies surviennent en Europe,.
Selon la chronique du moine Matthieu Paris, près de 19 000 léproseries existent en Europe au XIIIe siècle, les historiens estiment que l'Europe en 1300 comptait environ 600 000 lépreux sur une population totale de 75 à 80 millions d'habitants.La peste bubonique réapparaît avec la peste noire qui fait environ 25 millions de morts en Europe entre 1346 et 1350 et probablement autant en Asie.
C'est le début explosif de la deuxième pandémie de peste.En Occident, de grandes maladies du Moyen Âge persistent après la Renaissance, comme la peste et la variole.
La deuxième pandémie de peste se poursuit par plusieurs grandes épidémies qui se terminent à la fin du XVIIIe siècle.
La variole tue près de 400 000 Européens chaque année à l'approche du XVIIIe siècle.D'autres fléaux prennent de l'importance, comme le typhus lié aux camps militaires, le paludisme qui se répand à partir de l'Italie, et la tuberculose sous la forme des écrouelles.Le développement des échanges humains et commerciaux, les grandes découvertes et les guerres favorisent l'extension des infections.
Plusieurs maladies épidémiques sont distinguées ou redécouvertes comme la coqueluche, la diphtérie, les oreillons, la grippe, la rougeole ou la scarlatine.Avec la découverte de l'Amérique par les Européens,  l'Eurasie se trouve en contact avec le Nouveau Monde.
Deux maladies en sont importées : la suette anglaise et la syphilis.
Dans l'autre sens l'Europe exporte la variole, la lèpre, la rougeole, la tuberculose et le paludisme.La variole et la rougeole déciment les civilisations amérindiennes au Mexique, en Amérique centrale, et même les Incas.
Les envahisseurs décident de recourir à l'esclavage pour exploiter les colonies américaines.
Avec le commerce triangulaire, l'Afrique noire rejoint le circuit pandémique entre les Amériques et l'Eurasie.
Elle en reçoit les maladies et elle en exporte d'autres comme la fièvre jaune et le paludisme.À partir du XVIIIe siècle, les règlements communaux ou régionaux de santé publique sont traités au niveau gouvernemental.
Les politiques sanitaires et la lutte contre les épidémies deviennent l'affaire des états-nations, et d'accords internationaux au XIXe siècle (Conseil sanitaire international fondé à Constantinople en 1838, Conférence internationale de Paris en 1851, pour lutter contre la peste et le choléra).La collaboration internationale se développe en même temps que la puissance des pandémies.
Celle-ci est multipliée par les mutations sociales de la révolution industrielle et les transports modernes utilisant la machine à vapeur.La deuxième pandémie de peste se termine au Proche-Orient à partir de 1841 dans l'Empire Ottoman qui adopte et applique sévèrement les règlements européens.
La peste épidémique est éliminée en quelques années, ne subsistant que sous la forme de cas locaux épisodiques.
Une troisième pandémie de peste réapparait en Chine dans la deuxième moitié du XIXe siècle.
Elle fait d'abord plusieurs millions de victimes en Chine et en Inde et elle se répand dans le monde entier, mais elle est bloquée au niveau des ports des autres continents ne faisant que quelques milliers de victimes.Sept pandémies de choléra asiatique, venant de l'Inde, se succèdent au XIXe siècle.
Les plus violentes frappant l'Europe et l'Amérique du Nord, sont les deuxième (1829-1837) et troisième (1840-1860) pandémies.
Par exemple, le choléra de 1832 tue plus de 500 000 personnes en Angleterre et 100 000 en France.
Le paludisme ou malaria (principalement par Plasmodium vivax) décline en Europe, mais il atteint son expansion maximale en Amérique du Nord, où il est lié aux modifications de l'habitat et de l'activité agricole.
Plasmodium falciparum devient une véritable menace pour les colonisateurs et indigènes lorsqu'elle atteint pour la première fois le continent américain lors d'échanges d'esclaves.
La malaria fait des ravages dans la colonie de Jamestown, ainsi que dans le Sud et le Midwest.
En 1830, elle atteint le Pacific Northwest.
Pendant la guerre de Sécession, plus de 1,2 million de cas de malaria sont recensés chez les soldats des deux camps.
Le Sud des États-Unis continue à souffrir de la malaria dans les années 1930.La fièvre jaune est à l'origine de plusieurs pandémies dévastatrices.
Des villes américaines telles que New York, Philadelphie et Boston, ont été touchées par cette pandémie.
En 1793, l'une des plus grandes pandémies américaines de fièvre jaune tue plus de 5 000 personnes à Philadelphie — près de 10 % de la population.
Près de la moitié des habitants ont fui la ville, y compris le Président George Washington.
À l'époque coloniale, l'Afrique de l'Ouest était connue sous le nom de « la tombe de l'Homme blanc » à cause de la malaria et de la fièvre jaune qui y régnaient.Au XIXe siècle, la tuberculose aurait tué plus d'un quart de la population adulte en Europe.
Elle est liée à la révolution industrielle et à l'habitat (pauvreté en milieu urbain).
En 1918, un décès sur six en France est causé par la tuberculose.
Au XXe siècle, la maladie a tué approximativement 100 millions de personnes.
Elle est l'une des complications sanitaires les plus importantes en expansion dans le monde.D'autres pandémies liées à la misère sont le typhus exanthématique et la fièvre récurrente.
Celles liées à l'hygiène de l'eau (transmission hydrique) et des aliments sont des infections gastro-intestinales, par exemple le choléra, déjà cité, et la fièvre typhoïde.Des maladies épidémiques frappent surtout les enfants, elles ne peuvent être vraiment combattues qu'après identification de l'agent causal et immunisation passive (sérothérapie) ou active (vaccins).
Ces épidémies reviennent régulièrement et sont de gravité variable.
Les plus importantes, en fréquence comme en gravité, furent ou sont la diphtérie, la poliomyélite, la scarlatine, et la rougeole.Il y avait 3 à 4 millions de cas de rougeole aux États-Unis chaque année avant qu'un vaccin ne soit introduit en 1963.
La rougeole a tué près de 200 millions de personnes dans le monde en 150 ans.Comme aux siècles précédents, de grandes épidémies de grippe sévissent au XIXe siècle, dont celle de 1847-1848, la grippe russe de 1889-1890 est considérée comme la première grippe pandémique bien documentée.La grippe espagnole, de 1918 à 1920, a été l'une des pandémies les plus mortelles de l'histoire de l'Humanité, avec de 20 à 40 millions de morts (80 à 100 millions d'après des réévaluations récentes).Les grippes pandémiques suivantes furent plus modérées : la grippe asiatique en 1957 (2 millions de morts), la grippe de Hong-Kong en 1968 (4 millions de morts), la grippe russe de 1977, et la grippe A(H1N1) de 2009.La variole persiste au XIXe siècle, y compris dans les pays industrialisés, sous la forme d'épidémies de brève durée, mais parfois très meurtrières (France, hiver 1870-1871).
Au XXe siècle, la maladie aurait tué près de 300 à 500 millions de personnes.
Au début des années 1950, 50 millions de cas de variole sont recensés chaque année.
À la suite de campagnes de vaccination ciblées à succès pendant les XIXe et XXe siècles, l'OMS déclare la variole éradiquée en décembre 1979.
La variole est la seule infection humaine à avoir été éradiquée et l'un des deux virus mortels ayant été éradiqués.En 1971, Abdel R. Omran propose le concept de transition épidémiologique (en), inspiré de celui de transition démographique, pour distinguer trois âges dans l'histoire de l'humanité, :Si le concept de transition épidémiologique reste utilisé (ou modifié en transition sanitaire intégrant des facteurs sociaux), le modèle initial d'Omran a été invalidé (dans son âge 3) par le rebond inattendu, dans le dernier quart du XXe siècle, des maladies infectieuses, anciennes ou nouvelles.
Parmi les anciennes, selon les pays, la tuberculose, la syphilis, la diphtérie, la dengue.Depuis 1970, plus de 1500 nouveaux agents infectieux pathogènes ont été découverts, dont 70% ont été démontrés comme d'origine animale.
Beaucoup n'ont guère d'importance en santé publique, mais plusieurs ont des conséquences considérables.
Parmi les maladies émergentes ou nouvelles maladies identifiées à la fin du XXe siècle, c'est le cas notamment de la maladie de Lyme, de la légionellose, d'Ebola… L'exemple le plus notoire étant le VIH / Sida qui provient du continent africain, puis s'étend aux États-Unis depuis Haïti entre 1966 et 1972.La troisième pandémie de peste est en phase dormante, mais une épidémie majeure a eu lieu à Madagascar en 2017, avec 2 417 cas confirmés ou suspects, dont 209 décès par peste pneumonique.
Neuf pays en relation avec Madagascar ont dû se placer en alerte de peste.
Cet exemple montre que les maladies anciennes disparaissent très rarement de façon définitive.
D'autres exemples sont la fièvre jaune ou le choléra.
40 épidémies de choléra sont signalées chaque année à l'OMS, la plus importante étant l'épidémie de choléra en Haïti de 2010.Le syndrome d'immunodéficience acquise (sida) est une pandémie actuelle, qui touche plus de 25 % de la population sud et est-africaine.
En 2006, la prévalence du VIH chez les femmes enceintes en Afrique du Sud est de 29,1 %.
L'enseignement des relations sexuelles en toute sécurité aide à ralentir la pandémie dans de nombreux pays africains grâce au système éducatif scolaire.
Les infections se répandent continuellement en Asie et dans les continents américains.
Le nombre de décès liés au SIDA en Afrique pourrait, selon les estimations, atteindre 90 à 100 millions en 2025.En 2009, l'épidémie de Grippe A (H1N1), qui se déclare au Mexique, évolue par la suite en pandémie.
C'est la première grippe pandémique du XXIe siècle, moins sévère que prévu.La même année, le nouveau rapport de la CIA estime que « l'apparition d'une nouvelle maladie respiratoire humaine virulente, extrêmement contagieuse, pour laquelle il n'existe pas de traitement adéquat, pourrait déclencher une pandémie mondiale ».
Il considère que cette apparition pourrait être liée à des « souches hautement pathogènes de la grippe aviaire telles que le H5N1 », ainsi qu'à « d'autres agents pathogènes, comme le coronavirus du SRAS et diverses souches de la grippe », et qu'elle pourrait intervenir « sans doute dans une zone à forte densité de population, de grande proximité entre humains et animaux, comme il en existe en Chine et dans le Sud-Est asiatique où les populations vivent au contact du bétail »,.Fin 2019, le coronavirus SRAS-CoV-2 apparaît en Chine, déclenchant une urgence de santé publique de portée internationale le 30 janvier 2020.
Cependant, l'Organisation mondiale de la santé ne parle à ses débuts que d'un risque important de pandémie.Le 11 mars 2020, l'Organisation mondiale de la santé annonce officiellement que l'épidémie de Covid-19 est devenue pandémique,.
Ceci intervient deux jours après la décision du gouvernement italien de placer tout le pays en quarantaine.On dénombre plus de 528 millions de contaminations et plus de 6,3 millions de morts officiellement recensés à travers le monde à la date du 24 mai 2022.
Cependant, en tenant compte des morts non reportés dans les statistiques officielles, plusieurs sources estiment des quantités bien plus importantes : entre 12 et 22 millions de morts selon une étude publiée par la revue Nature.
Entre 13,3 et 16,6 millions de morts selon l'OMS.En 2009, le risque d'une pandémie mondiale, une “nouvelle maladie respiratoire humaine virulente, extrêmement contagieuse” est établi par des analystes de la CIA et publié,La Plateforme intergouvernementale scientifique et politique sur la biodiversité et les services écosystémiques (Ipbes) publie en octobre 2020 un rapport qui met en garde contre les risques d'une « ère des pandémies », concluant : « À moins que l'approche globale de la lutte contre les maladies infectieuses ne soit modifiée, des pandémies futures vont apparaître plus souvent, se propageront plus rapidement, causeront plus de dommages à l'économie mondiale et tueront plus de personnes que le COVID-19 ».
Ce rapport, citant près de 700 articles de recherche, conclut que les activités humaines à l'origine du changement climatique (agriculture intensive, artificialisation des sols, mondialisation des échanges commerciaux…) favorisent la diffusion des agents pathogènes pour l'homme : « on estime à 1,7 million le nombre de virus non découverts actuellement présents dans les mammifères et les oiseaux, dont 827.000 pourraient avoir la capacité d'infecter les êtres humains ».Une traduction citoyenne en français du résumé exécutif du rapport est disponible ici.
L'année 2016 est une année bissextile commençant un vendredi.
C'est la 2016e année de notre ère, la 16e année du IIIe millénaire et du XXIe siècle et la 7e année de la décennie 2010-2019.L'année 2016 du calendrier grégorien correspond aux dates suivantes :2016 est l'année la plus chaude dans le monde depuis le début des relevés (1850), a été confirmée comme marquée par une température moyenne de 1,2 °C de plus que la période préindustrielle 1850-1900, devant 2019, 2017, 2015, 2018 et 2014.Pour la seule année 2016, il y a eu 327 catastrophes, dont 191 dues à la nature et 136 dues à l'homme ; l'Asie est la région du monde la plus touchée.
Ces catastrophes dans le monde ont coûté 175 milliards de dollars.L’ouragan Matthew a été la catastrophe la plus meurtrière : 700 personnes y ont trouvé la mort, principalement à Haïti.
Le séisme qui a frappé l’île japonaise de Kyushu en avril 2016 a occasionné les dommages économiques les plus lourds de cette année-là, estimés entre 25 et 30 milliards de dollars (23 et 27,6 milliards d’euros).Les lauréats du Prix Nobel en 2016 sont :
En médecine, un traitement, appelé aussi traitement médical, traitement thérapeutique, thérapie ou plus généralement thérapeutique, est un ensemble de mesures appliquées par un professionnel de la santé à une personne vis-à-vis d'une maladie, afin de l'aider à en guérir, de soulager ses symptômes, ou encore d'en prévenir l'apparition.
Lorsque ce professionnel décide de ne pas médicaliser une situation qu'il juge ne pas relever de traitement, il s'agit d'abstention thérapeutique (non-initiation d'un traitement ou interruption du traitement appelée retrait ou congé thérapeutique).
L'observance thérapeutique désigne la capacité d'un patient à suivre correctement le traitement qui lui a été prescrit.Concernant la santé animale, il s'agit des mesures appliquées par un vétérinaire.Le traitement peut être théoriquement classé selon le but global poursuivi pour l'individu :En outre, on peut théoriquement classer un traitement selon son mode d'action principal par rapport à une maladie :On peut classer un traitement, selon le type d'acte dispensé, en traitement médical, chirurgical ou médicotechnique.Le traitement médical fait intervenir un pharmacien, un médecin ou un infirmier, le plus souvent à l'aide de mesures hygiénodiététiques (conseil sur le mode de vie et l'alimentation, éducation thérapeutique) et de médicaments par voie injectable ou non.D'autres procédés font partie du traitement médical.
La rééducation fait intervenir un kinésithérapeute, un orthophoniste ou un ergothérapeute.
La psychothérapie fait intervenir un psychiatrie ou un psychologue.
Le pansement fait intervenir un infirmier.
Le massage et la physiothérapie font intervenir un kinésithérapeute.
Il existe également l'hydrothérapie en rhumatologie, l'électroconvulsivothérapie et la luminothérapie en psychiatrie, et l'asticothérapie en dermatologie.
Dans le cadre de soins d'urgence ou de réanimation, le traitement médical peut également concerner la pratique d'acte technique "simple" tel que le sondage des voies naturelles (urinaire, digestive, respiratoire) ou le massage cardiaque.Il faut également citer ici le traitement non conventionnel qui regroupe différentes pratiques ayant en commun le fait de ne pas avoir de base scientifique théorique ni de preuve scientifique d'efficacité.Le traitement chirurgical fait intervenir un chirurgien qui va pratiquer une incision.Plusieurs traitements sont à la frontière de la chirurgie.
Le traitement radio-interventionnel fait intervenir un radiologue.
Le traitement endoscopique fait intervenir un médecin endoscopiste.
La radiothérapie fait intervenir un radiothérapeute.
La photothérapie fait intervenir un médecin spécialiste.On peut classer le traitement selon la méthode employée :De nombreuses autres méthodes sont utilisées en médecine non conventionnelle.Parfois, la surveillance, qui peut être clinique (exemple : pression artérielle), biologique (exemple : protéine C réactive) ou radiologique (exemple : radiographie du thorax), est considérée comme partie intégrante du traitement, en particulier pour la surveillance clinique.En orthopédie, on différencie le traitement chirurgical (mise en place de matériel rigide dans le corps) ; le traitement orthopédique (mise en place d'un plâtre) et le traitement fonctionnel (mise en place d'une immobilisation relative non plâtrée : attelle ou bandage).En psychologie, la psychothérapie se décline en différents types.
On retrouve par exemple les thérapies cognitivo-comportementales, psychanalytiques ou familiales.
La biologie (du grec bios « la vie » et logos, « discours ») est la science du vivant.
Elle recouvre une partie des sciences de la nature et de l'histoire naturelle des êtres vivants.La vie se présentant sous de nombreuses formes et à des échelles très différentes, la biologie s'étend du niveau moléculaire, à celui de la cellule, puis de l'organisme, jusqu'au niveau de la population et de l'écosystème.Le terme biologie est formé par la composition des deux mots grecs bios (βιος), en français « vie », et logos (λογος), qui signifie « discours, parole »,.Ce néologisme est créé à la fin du XVIIIe siècle et au début du XIXe siècle et de façon indépendante :Chez Lamarck on trouve, pour la première fois, une conception de l'être vivant qui reconnaît son originalité, comparativement aux objets inanimés sans pour autant la faire déroger aux lois de la physique, contrairement à ce qu'avaient tendance à faire les vitalistes et les fixistes.Le même Lamarck, bien avant de donner des cours de biologie en 1819, sépare dans son ouvrage Hydrogéologie, paru également en 1802, la physique terrestre en trois parties : Les savants allemands, à l'appel de Treviranus, lancent les méticuleux inventaires de la flore et de la faune, réalisés par ceux qui, respectivement, se nommeront botanistes et zoologistes.
Vers le milieu du XIXe siècle, un intérêt pour les fonctions du vivant oriente la recherche biologique vers la physiologie.L'objet de la biologie est l'être vivant et la vie, dans son ensemble et son fonctionnement.
Mais qu'est-ce qu'un être vivant ?
En quoi se différencie-t-il des objets inanimés et des machines ?
Et qu'est-ce que la vie ?
À ces questions, les biologistes n'ont actuellement pas de réponse précise, qui fasse l'unanimité dans la communauté scientifique.
Certains d'entre eux pensent même que ces questions sont sans objet.Ainsi en 1878 Claude Bernard, dans la première des Leçons sur les phénomènes de la vie communs aux animaux et aux végétaux, déclare explicitement « on peut caractériser la vie, mai non la définir », car la biologie doit être une science expérimentale ; ce serait là une définition a priori et « la méthode qui consiste à définir et à tout déduire d'une définition peut convenir aux sciences de l'esprit, mais elle est contraire à l'esprit même des sciences expérimentales ».
En conséquence, « il suffit que l'on s'entende sur le mot vie pour l'employer » et « il est illusoire et chimérique, contraire à l'esprit même de la science, d'en chercher une définition absolue ».La biologie semble être restée fidèle à cette conception, puisqu'elle continue à ne pas précisément définir la notion de vie pour se limiter à l'analyse de « choses naturelles » ou parfois en partie créées par l'humain (via la sélection puis le génie génétique) que le sens commun lui désigne comme vivants.
Cette analyse permet de mettre en évidence un certain nombre de caractères communs à ces objets d'étude, et ainsi d'appliquer ce qualificatif de vivant à d'autres objets présentant les mêmes caractères.
Cette méthode, exclusivement analytique et expérimentale, a considérablement renforcé l'efficacité et la scientificité du travail du biologiste, comparativement aux conceptions souvent spéculatives d'avant Claude Bernard.
Elle a cependant amené une « physicalisation » telle que l'on a parfois l'impression que, pour rendre scientifique la biologie, il a fallu nier toute spécificité à son objet.De fait, certains biologistes en viennent à déclarer que « la vie n'existe pas !
», ou plus exactement qu'elle serait un processus physico-chimique parmi d'autres.Le premier d’entre eux est probablement Albert Szent-Györgyi, prix Nobel de médecine en 1937, qui a déclaré : Le plus connu est François Jacob :Plus récemment, c'est aussi la position d'Henri Atlan :Cette dernière citation illustre la confusion entre l'étude de la vie et celle de la matière des êtres vivants, où transparaît la tentation de réduire la biologie à la seule biologie moléculaire en niant au vivant, grâce au nivellement que permet la chimie, toute spécificité qui ne soit pas une simple différence physico-chimique.
Autrement dit, il est tentant, en réduisant la biologie à la biologie moléculaire, de ne différencier le vivant de l'inanimé que par les critères par lesquels la biologie moléculaire se différencie du reste de la chimie.André Pichot affirme que « Cette négation de la spécificité du vivant pourrait venir d'une conception où l'on n'admet aucune discontinuité entre vivant et inanimé pour conserver un univers cohérent et unifié ».
On peut y admettre une gradation progressive entre l'inanimé et le vivant, tant dans les formes actuelles (les virus, censés être à la limite du vivant et de l'inanimé) que dans l'apparition de la vie sur Terre (cette apparition y est comprise comme une phase prébiotique progressive sans discontinuité marquée).Cette « négation de la spécificité du vivant », qui se veut matérialiste, semble confondre simplement le matérialisme épistémologique (l'étude critique des sciences) et les sciences de la matière proprement dites.En biologie, tenter d'expliquer la notion de vie et la spécificité de l'être vivant, peut conduire aux notions de vitalisme ou même d'animisme, car en s'écartant un peu de la physico-chimie on peut sortir du matérialisme épistémologique.
Si bien qu'aujourd'hui « on a l'impression que ce que vise la biologie n'est pas tant l'étude de la vie (ou de l'être vivant dans ce qu'il a de spécifique relativement à l'objet inanimé) que sa pure et simple négation, le nivellement et l'unification de l'univers par la physico-chimie.
Comme si, pour unifier, il valait mieux nier les solutions de continuité que les comprendre ».Une autre approche est plus systémique ainsi résumée en 1970 François Jacob : « Tout objet que considère la Biologie représente un système de systèmes; lui - même élément d'un système d'ordre supérieur, il obéit parfois à des règles qui ne peuvent être déduites de sa propre analyse » ; c'est une des bases de l'écologie scientifique et de son « approche écosystémique ».Le problème de la spécificité de l'être vivant n'est donc pas encore réglé par la biologie moderne qui ainsi n'a donc aucune définition claire et explicite de son objet.
Ce problème est seulement occulté de diverses manières, qui toutes tendent à ramener, faute de mieux, la conception de Descartes de l'être vivant comme plus ou moins semblable à une machine très complexe.Rares sont les biologistes qui s'inscrivent en faux contre cette approximation en avançant une conception du vivant plus précise, visant à se rapprocher de la réalité,.
Un certain nombre de travaux en biologie théorique tentent en effet de dépasser les limitations auxquelles on s'est heurtées jusqu'à présent, tels que ceux de Francisco Varela, Robert Rosen ou Stuart Kauffman.
L'enjeu est alors souvent de tenter d'appréhender les différences entre biologie et physique.La première théorie de l'évolution du vivant a été avancée par Jean-Baptiste Lamarck dans son ouvrage Philosophie Zoologique en 1809.
Comme son titre l'indique, elle se présente sous la forme d'un système philosophique, bien qu'elle pose les bases essentielles pour la compréhension des êtres vivants et de leur évolution.
Cinquante ans plus tard, en 1859, avec la parution de L'Origine des espèces, Charles Darwin propose une explication scientifique de l'évolution, sous la forme d'un mécanisme simple, avec le principe de sélection naturelle.
Avec le temps, la théorie originelle de Darwin a été affinée avec les résultats des expériences et observations que les biologistes ont effectuées.
La théorie faisant actuellement consensus est celle de la théorie synthétique de l'évolution, appelée aussi néodarwinisme.Le caractère évolutionniste de la vie a pendant très longtemps été discuté et est même encore mis en doute par certaines personnes en dehors de la communauté scientifique, mais aucune de ces objections à la théorie de l'évolution n'est scientifiquement fondée.
La communauté scientifique a depuis très largement admis l'évolutionnisme de la vie comme un fait démontré par l'expérience et l'observation à maintes reprises notamment par :Si la biologie est si vaste, c'est en raison de l'extrême diversité du vivant qui se présente sous tellement de formes que l'on peut avoir du mal à discerner des points communs.
Une hiérarchisation du vivant a tout de même été réalisée, qui est le domaine de la systématique et de la taxinomie.
Tous les êtres vivants sont classés en trois domaines :Bien qu'étant différentes, toutes les formes de vie partagent des caractères communs.
Ce qui porte à croire que la vie sur Terre a pour origine une seule et même forme de vie, désignée sous l'acronyme de LUCA (pour l'anglais : Last universal common ancestor), qui serait apparue sur Terre il y a au moins 2,5 milliards d'années.Les principaux caractères universels du vivant sont :En raison du caractère extrêmement vaste du sujet, l'étude de la biologie nécessite un morcellement en domaines d'études.
Une approche un peu « réductrice » mais ayant l'avantage de clarifier les thèmes consiste à définir des niveaux d'organisation.
Dans un souci de parvenir à une compréhension plus globale de la biologie, des ponts se sont naturellement créés entre les différentes disciplines.
Permet l'exploration de différents sujets originaux comme la biologie moléculaire, la biotechnologie, la toxicologie, la science biomédicale, etc.Les domaines étudiant la structure du vivant sont à l'échelle de l'atome pour la biologie moléculaire et de la cellule pour la biologie cellulaire.Le domaine de la biologie moléculaire étudie les composés de bases du vivant, comme l'ADN et les protéines.
Pendant longtemps, on a cru que les lois de la chimie régissant le vivant étaient différentes de celles pour la matière inanimée.
Mais depuis la synthèse de nombreux composés organiques, il est clairement admis que les lois chimiques sont les mêmes que pour la matière inorganique.
Aucune force vitale n'insuffle la vie à la matière comme on le pensait avant avec la théorie vitaliste.La mise au point du microscope avec lequel Robert Hooke a découvert les cellules en 1665 a marqué la naissance de la biologie cellulaire et celle d'un monde alors insoupçonné.
Cette découverte et les nombreuses qui ont suivi ont permis d'expliquer certains phénomènes comme ce que l'on qualifiait à l'époque de génération spontanée.
C'est à cette échelle que l'on rencontre les premiers organismes vivants.Prise au sens structurelle et fonctionnelle, la biologie recouvre également l'ensemble des disciplines, classiques et modernes, qui étudient des structures comme les tissus avec l'histologie ou les organes avec l'anatomie.
La physiologie quant à elle étudie les principes mécaniques, physiques et biochimiques des organismes vivants et est séparée en deux branches : la physiologie végétale et la physiologie animale.L'extrême diversité du vivant n'empêche en rien le groupement en entités ou taxons (Taxinomie), leurs relations les uns par rapport aux autres et leur classement (systématique).Les interactions des êtres vivants entre eux et les liens les unissant avec leur environnement est le domaine de l'écologie.
L'éthologie quant à elle étudie le comportement animal dans le milieu naturel.Les Sciences de la Vie comprennent de nombreuses disciplines et sous-disciplines plus ou moins reliées entre elles et parfois imbriquées.
Ces disciplines sont organisées soit par niveau d'observation, soit par approche méthodologique, soit par type d'organisme étudié.Les applications des découvertes en biologie sont nombreuses et très présentes dans le quotidien de l'être humain.
Les avancées importantes de ces dernières décennies en médecine ont principalement pour origine les découvertes sur le fonctionnement du corps humain.
Le domaine pharmaceutique profite également des avancées en chimie organique.Plus récemment, la découverte de la structure de l'ADN et une meilleure compréhension de l'hérédité ont permis de modifier finement les êtres vivants, par notamment les techniques de génie génétique, et trouvent des applications dans les domaines agricole et agro-alimentaire.La biologie peut également avoir des applications en criminologie.
Dans la Revue française de criminologie et de droit pénal, Laurent Lemasson présente trois corrélations entre biologie et criminalité mises en évidence par différents chercheurs: la présence des gènes MAOA et HTR2B chez une part importante de criminels ; un fonctionnement anormal des régions frontales et temporales du cerveau ; enfin un état de sous-excitation physiologique chez les criminels multirécidivistes.Depuis le développement de la biologie moléculaire et de la physiologie cellulaire dans la seconde partie du XXe siècle, les progrès de la biologie sont devenus quotidiens et ont un impact énorme sur la société : compréhension des mécanismes moléculaires de plusieurs centaines de maladies, amélioration des traitements contre le cancer, compréhension des mécanismes neurologiques, amélioration des traitements des maladies mentales et dépistage de tares génétiques in utero.
Une meilleure compréhension de l'évolution moléculaire, substrat physique à l'évolution des espèces, permet de transposer aux humains les découvertes faites sur les animaux, y compris des vers comme C. elegans ou la mouche drosophile, dont on a montré que les mécanismes moléculaires de segmentation du corps au cours de l'embryogenèse sont identiques à ceux de l'humain, et, de manière générale, à tout le vivant métazoaire.Toutefois, les progrès très rapides de la biologie suscitent parfois des interrogations philosophiques, de vives inquiétudes, voire une forte opposition de certaines associations ou organisations non gouvernementales (ONG).
On peut citer notamment : le clonage, les organismes génétiquement modifiés (OGM), le séquençage, et les problèmes de propriété intellectuelle qui en découlent.
CricetinaeLes hamsters (Cricetinae) sont de petits rongeurs de la famille des Cricetidae qui forment la sous-famille des Cricetinae.
Il en existe plusieurs espèces, réparties dans différents genres.
Quelques espèces sont élevées en captivité comme animal de compagnie, pour l'expérimentation animale ou pour leur fourrure.
Le premier fut le hamster doré qui existe à présent en de multiples variétés colorées et, plus récemment, des espèces naines comme le hamster de Roborovski, le hamster russe, le hamster de Campbell et le hamster de Chine.On ne doit pas les confondre avec les hamsters-taupes qui appartiennent à la sous-famille des Myospalacinae, ni avec le Hamster d'Imhause, ou Rat à crête, qui appartient quant à lui à la sous-famille des Lophiomyinae.Le terme « hamster » est un emprunt à l'allemand Hamster, en vieux haut-allemand hamustro (le verbe allemand hamstern « faire des réserves », est dérivé du nom et non l'inverse).
Le nom allemand est lui-même emprunté au slave, cf.
Le russe khomiak (« hamster »), ancien khoměkǔ, semble être une forme abrégée de khoměstorǔ.
On a proposé d'expliquer le slave khoměstorǔ comme un emprunt à l'avestique hamaēstar (« ennemi qui jette à terre ») (pour le sens, comparer chor yrlak « hamster », yr- « être ennemi de » ; en effet, le hamster plie les tiges des céréales pour en manger les grains).
Le lituanien staras « spermophile (lt) » est inséparable du mot slave, mais la relation est incertaine (il pourrait en être une autre forme courte, ou alors contredire l'étymologie iranienne).Auparavant le contenu de la famille des Cricetidae était placé avec d'autres sous la famille des Muridés (Muridae), mais les études récentes tendent à distinguer six familles, dont Cricetidae, au sein d'une super-famille de Rongeurs, les Muroidea.Certaines bases comme ITIS continuent toutefois à diviser les Muridés seulement en sous-familles.Cette sous-famille se répartit en 7 genres selon les classifications classiques :Selon ITIS (31 oct.
2010), Animal Diversity Web (14 mai 2011) et Mammal Species of the World (version 3, 2005)  (14 mai 2011) :Le classement des genres Allocricetulus et  Tscherskia n'est pas encore définitif.Autrefois, avant les recherches phylogénétiques, on classait aussi par erreur dans cette sous-famille les genres sigmodontinae (Miller and Gidley 1918), nesomyinae (Miller and Gidley 1918, Ellerman 1941), calomyscidae (Ellerman 1941), mystromyinae (Vorontsov 1966), et myospalacinea (Michaux et al.
2001).Chaque espèce de hamster a des caractéristiques particulières.
Elles présentent chacune des différences physiques, de taille, de comportement, d'habitat naturel, etc.
Voir les articles détaillés pour en savoir plus.Les cricétidés sont différenciés physiquement par une queue très épaisse et courte (moins de 45 % de la longueur du corps), un corps compact, des pattes courtes et larges, des oreilles petites et velues, un estomac comportant deux compartiments, des particularités dentaires avec une formule dentaire 1/1, 0/0, 0/0, 3/3 = 16, des spécificités génétiques, etc. Leur taille est très variable selon les espèces avec un corps de 5 à 34 cm et une queue de 0,7 à 10,6 cm.Les hamsters ont surtout la particularité de posséder des poches extensibles  à l'intérieur des joues, appelées abajoues.
Ces poches servent essentiellement à transporter la nourriture.
Certaines espèces sont connues pour cacher leurs petits dans leurs abajoues quand elles ont peur d'un danger, afin de les transporter ailleurs.
Quelques espèces de hamsters peuvent aussi nager parfaitement en remplissant ces poches avec de l'air pour mieux flotter.Ils occupent une distribution géographique naturelle en Afrique du Nord, dans certaines parties d'Europe, au Moyen-Orient, à l'est de la Sibérie jusqu'en Chine.Tous les hamsters ont en commun de vivre dans la nature dans des zones terrestres dégagées et sur des terrains secs : déserts, steppes, champs, zones rocheuses, etc..Les cricétidés sont avant tout des granivores, mais ils varient volontiers leur alimentation par des compléments végétaux comme des fruits, légumes, tiges, feuilles ou racines.
Certaines espèces sont cependant omnivores et dévorent des insectes ou de petits vertébrés, par exemple des grenouilles.
Ils remplissent alors leurs abajoues pour rapporter la nourriture dans leur terrier.
On a découvert des terriers contenant près de 90 kg de réserves alimentaires.Les femelles pratiquent occasionnellement le cannibalisme en dévorant les petits trop faibles à la naissance.
À moins qu'elle n'ait été effrayée durant la mise-bas, cela permet dans une situation ordinaire de redonner des forces à la mère tout en privilégiant l'allaitement des rejetons les plus robustes.Les hamsters ne connaissent pas de véritable hibernation, mais plutôt de longs moments de torpeur pouvant durer plusieurs semaines en hiver.Les hamsters sont polygames, c'est-à-dire que les mâles et les femelles n'ont pas de partenaire précis.
À la saison des amours les mâles hamsters vont d'un terrier à l'autre à la recherche de femelles réceptives.
Un opercule empêche la fécondation des œufs par les mâles suivants et la femelle chasse alors le plus souvent les prétendants de son territoire.
La saison de reproduction se situe entre février et novembre.
Les femelles auront deux à trois portées par an après une courte gestation de 15 à 22 jours.
Le nombre de petits par portée est très variable, pouvant aller jusqu'à 13, avec une moyenne de 5 à 7 petits.
Les petits sont allaités 3 semaines environ et deviennent adultes à 6 ou 8 semaines.Le record de longévité connu pour un hamster sauvage est de 10 ans, mais la plupart des hamsters, sauvages ou en captivité, ne dépassent pas 2 ou 3 ans.
Dans la nature leurs principaux ennemis sont les prédateurs : rapaces, serpents, mammifères carnivores et même des hérons ou des corbeaux qui capturent les plus jeunes.
Ils craignent également les hivers trop froids, les maladies et les machines agricoles qui détruisent leur terrier.Ils creusent en effet des terriers complexes à entrées multiples, avec tout un jeu de chambres, de greniers et de latrines reliés par un réseau de tunnels qui peuvent plonger à plus de 2 m sous la surface du sol en hiver.
Le terrier s'agrandit au cours de la vie de l'animal.
Ce n'est pas un animal grégaire, il y vit seul et en sortira généralement au crépuscule ou à la nuit tombée, bien que certaines espèces soient également diurnes.Certaines espèces sont particulièrement agressives vis-à-vis de leurs congénères, et des règles hiérarchiques strictes règlent ces rencontres.
Les cricétinés se défendent âprement avec leurs incisives quand ils sont attaqués.
Ils attaquent aussi quand ils se font capturer malgré leur fourrure propice au camouflage.
Celle-ci est généralement dans des tons gris, noir, brun et roux, avec souvent des flancs plus clairs ou une rayure dorsale.Les hamsters bénéficient d'une bonne vue pour trouver leurs proies, mais leur ouïe et leur odorat sont également bien développés.
Pour communiquer entre eux les mâles surtout utilisent un marquage olfactif du territoire.
Plus l'animal est dominant, plus ses glandes sébacées seront développées.Les hamsters consomment des plantes et des graines, et ils sont à leur tour une source de nourriture pour de nombreux animaux carnivores.Leur habitude d'emporter les graines dans leur terrier sous terre joue certainement un rôle dans la dispersion des semences.Pour les humains les hamsters sont souvent considérés comme nuisibles lorsqu'ils ravagent les cultures de haricots, de maïs ou de lentilles.
On les chasse aussi parfois pour leur fourrure.
Certaines espèces de hamsters, élevées en captivité, sont appréciées comme animal de compagnie ou dans les laboratoires pour les recherches comportementales ou physiologiques.Les Hamsters sont susceptibles  au SARS-CoV2 et donc de transmettre la maladie covid19 à l'homme  .Dans les pays où l'équilibre écologique est fragile, par exemple dans l'État du Queensland en Australie, les hamsters sont interdits, même en tant qu'animaux de compagnie afin de préserver la faune et la végétation locale.Pourchassés et piégés par les agriculteurs, parfois jusqu'à l'éradication totale sur certains territoires, certaines populations de hamsters bénéficient à l'inverse d'un statut de protection juridique.
C'est le cas par exemple du hamster d'Europe en Alsace ou du Hamster doré en Syrie.Note : certaines espèces ont plusieurs noms.Seules quelques espèces de hamsters sont élevées en captivité.
D'abord animaux de laboratoire ils ont été adoptés par la suite comme animaux de compagnie.
Il s’agit du Hamster doré, du Hamster russe, du Hamster de Roborovski, du Hamster de Campbell et du Hamster chinois.Le Hamster doré est l'espèce la plus répandue dans les élevages, il est aujourd'hui considéré comme domestique au regard de la législation de nombreux pays, notamment en France.D'autres espèces ont été adaptées, plus récemment, à la captivité.
Ces animaux remportent un grand succès dans le commerce grâce à leur petite taille.
Plus vifs, ils sont en général plus difficiles à manipuler et apprivoiser.
On voit aujourd'hui apparaître, notamment en Europe, des élevages de ces espèces naines qui proposent des animaux avec des standards, couleurs et caractères spécifiques.
Les animaux ainsi obtenus se révèlent parfaitement adaptés à la vie en captivité et tout aussi manipulables que les hamsters dorés.Les éleveurs sont aussi parvenus à créer des hybrides en croisant des hamsters russes avec des hamsters de Campbell, seules espèces capables de se reproduire entre elles et de donner naissance à quelques individus, difficilement viables et fertiles.En captivité, les hamsters ont des besoins spécifiques qui sont méconnus et donc très rarement appliqués.
En France les dimensions minimales des cages sont de 80 cm de longueur × 50 cm (soit 4 000 cm²) pour un hamster nain et 100 cm de longueur x 50cm (soit 5 000cm² pour un hamster doré.
En Allemagne on conseille un minimum de 5 000 cm² pour tous les hamsters (100x50cm de superficie de base).
Une étude scientifique de l'université de Berne (Vetsuisse-Fakultät der Universität Bern) montre que le hamster a besoin d'une surface minimale de 1 m² pour ne pas développer des troubles du comportement comme le mordillement des barreaux,.Dans la nature, le hamster vit dans les galeries qu'il a construites lui-même ou qu’il a trouvées inoccupées.
En captivité, il est important que le hamster dispose d'une couche de minimum 15 à 20 cm de litière (par exemple : chanvre ou lin, mais surtout pas de copeaux de bois), idéalement plus de 50 cm.Il est également important de disposer d'une roue d'un diamètre adapté.
Cependant, la roue ne remplace pas une grande cage diversifiée.
Pour le hamster nain, on conseille un diamètre minimum de 25cm, idéalement 28cm et, pour le hamster syrien, un diamètre d'au moins 28cm, idéalement 30 cm.
Le hamster doit avoir le dos droit lorsqu'il court à l'intérieur de sa cage : il ne doit pas avoir besoin de relever la tête.
La surface de course doit être pleine, les roues à barreaux/trous étant dangereuses pour les hamsters.Un habitat trop petit peut avoir des conséquences sur le comportement du hamster.
Ce dernier pourra vivre dans un espace retreint, mais certains problèmes pourraient survenir si l'espace utilisé est trop petit pour deux hamsters.
En effet, ils sont territoriaux par nature.
Aussi, ils pourraient s'attaquer entre eux.
Une cage trop petite exacerbera ce trait de caractère chez le hamster jusqu'à le rendre agressif et mordeur.La couleur et les motifs de la fourrure des hamsters varient selon les espèces.
Plusieurs espèces possèdent une raie (exemple : les hamsters russes ont une ligne très visible dans la plupart des cas) sur le dos mais peuvent être différenciées d'après la taille de l'animal, la forme de la tête et du corps ainsi que d'après les autres motifs et couleurs apparaissant sur le reste du corps.Il existe plusieurs couleurs pour chacun des types de hamsters d'élevage.
Quand on parle d'agoutis, on dit qu'il y a plus d'une couleur sur le corps (par exemple, Écaille de Tortue).
Par contre, un coloris uni signifie qu'il n'y a qu'une seule et même couleur (par exemple, Noir).
Certaines robes sont particulièrement appréciées, comme la Panda dont le corps est noir-gris avec une bande blanche au tiers du tronc.Les hamsters doivent leur nom à la couleur fauve qu'ils ont à l'état sauvage, les hamsters dorés se déclinent grâce à l'élevage sélectif en de multiples teintes et types de poil.La couleur de la robe peut-être de deux sortes: unie ou agouti.Un hamster uni a un poil de couleur uni et sans marquage.
Les hamsters unis peuvent être crème, blancs, ivoire, noirs, sable, vison, chocolat ou gris.Un hamster agouti peut posséder une robe de différentes couleurs.
Les animaux portent deux bandes contrastées sur les côtés de la face et de la tête.
Le poil d'un hamster agouti présente souvent deux tonalités.
Par exemple, un animal cannelle a une robe d'une riche couleur orangée, mais la racine des poils est grise.
Les variétés agouti peuvent être de couleurs dorée, cannelle, gris foncé, gris argent, fauve et miel.Comme les hamsters unis, les hamsters agouti peuvent donner naissance à des petits aux robes originales.À l'état sauvage le poil est court.Il existe des hamsters à poils longs.
La longueur du poil dépend du sexe du hamster.
Si c'est un mâle, le poil sera très long.
Si c'est une femelle, il le sera un peu moins.
Au niveau de la tête, le poil est plus court.Il y a aussi le rex, dont les poils et les moustaches sont frisés.
Leur poil est fin et a un aspect brillant.
Il ne faut jamais accoupler deux hamsters satin ensemble sous risque de se retrouver avec des petits aux poils si fins qu'ils paraissent nus.
Pour finir, le hamster nu, qui n'a aucun poil.Dans les pays occidentaux et au Japon, le hamster est l'un des animaux de compagnie bien connus des enfants et des adolescents.
L'image du hamster courant dans sa roue, comme celle des abajoues remplies de graines, y est familière.
Ces animaux sont souvent les héros involontaires de nombreux jeux et gags sur Internet.Films :Épisodes de séries :Jeux vidéo :Jeux de société :Jeux virtuels :Jouets :Pendant les guerres et en périodes de restriction on donnait dans les pays germaniques le surnom de hamsters aux thésauriseurs d’aliments.
On lit dans L’Alsace pendant la guerre de Charles Spindler à la date du 6 janvier 1918 : « ...
Il n'existe aujourd'hui que deux espèces d'animaux ; les hamsters et les ânes.
Dans cette dernière catégorie se rangent tous ceux qui ne sont pas des hamsters », me disait ce matin mon ami S., venu à Boersch pour essayer de se procurer sous main quelques vivres.
« Dire qu'on en est réduit à mendier de ci de-là, et en payant des prix féroces, de quoi ne pas mourir de faim!
Les granulocytes neutrophiles ou polynucléaires neutrophiles (PNN) (ou simplement « les neutrophiles ») sont des cellules sanguines appartenant à la lignée blanche.
Ce sont des globules blancs (leucocytes) qui ont un rôle majeur dans le système immunitaire.
Les neutrophiles font partie des cellules granulocytes ou « cellules polynucléaires ».
On les appelle polynucléaires en raison d'une erreur historique : de par le caractère plurilobé de leur noyau (de deux à cinq lobes en général), on a longtemps cru que ces cellules possédaient plusieurs noyaux.
Les autres granulocytes sont les granulocytes éosinophiles et basophiles.
Le qualificatif de « neutrophile » vient aussi d'une caractéristique visible en microscopie optique : après ajout des colorants vitaux usuels (May-Grünwald Giemsa ou MGG), ces cellules restent neutres (elles fixent mal les colorants acides et basiques).Les neutrophiles représentent à eux seuls environ 65 % de l'ensemble des leucocytes du sang, et 99 % des granulocytes.Les granules présents dans le cytoplasme des neutrophiles contiennent des substances toxiques permettant l'élimination des microorganismes extracellulaires comme les bactéries ou les champignons.
Comme pour les macrophages, l'activation de l'explosion oxydative (oxidative burst) par les neutrophiles conduit à la production de radicaux libres de l'oxygène et la sécrétion de peroxyde d'hydrogène et d'hypochlorite.
Les neutrophiles sont les phagocytes les plus nombreux, constituant 50 % à 60 % de l'ensemble des leucocytes circulants, et sont parmi les premières cellules recrutées au site d'infection.
La moelle osseuse d'un individu sain adulte produit environ 100 milliards de neutrophiles par jour, et environ 10 fois plus au cours d'une infection aigüe.Le passage des polynucléaires neutrophiles dans le sang est rapide et bref car ils jouent leur rôle essentiellement dans les tissus, où ils sont le principal agent cellulaire anti-bactérien.
La durée de vie du polynucléaire neutrophile est très courte car il est entièrement consommé par sa fonction, ce qui contribue à faire de lui une cellule anti-infectieuse, absolument non spécifique ; il peut en effet combattre une très grande variété de menaces différentes.Le polynucléaire neutrophile est une cellule sphérique, possédant un noyau segmenté en plusieurs lobes qui réfléchit la lumière (à cause des nombreuses granulations).
Il se déplace de manière adhérente sur la paroi d'autres cellules en projetant des extensions nommées lamellipodes.Ce mode de déplacement est appelé amœboïde.Les neutrophiles proviennent de la moelle osseuse qui en produit 100 milliards par jour.
Le granulocyte neutrophile provient de la maturation d'un myéloblaste, un processus qui dure 3 jours.Les myéloblastes proviennent des hémocytoblastes eux-mêmes provenant d'une cellule souche hématopoïétique.La lignée granulocytaire se subdivise en trois types d'éléments, les neutrophiles, les éosinophiles et les basophiles.
Les neutrophiles sont issus des CFU-GM (progéniteur des granulocytes et des monocytes).
Lorsque la cellule souche se différencie en granulocyte, il devient un myéloblaste et mature en suivant les divers stades suivants, qui correspondent aux précurseurs :Leur durée de vie est de 24 heures.C'est la première cellule mobilisée par le système immunitaire en présence d'un agent pathogène.Les neutrophiles ont un rôle primordial de phagocytose lorsqu'ils rencontrent une cellule étrangère ou infectée.
La phagocytose se déroule juste après la stimulation du neutrophile par un antigène porté par la cellule cible (cet antigène étant le plus souvent un fragment de membrane bactérienne ou un fragment de virus, reconnu comme étranger) avec l'émission de pseudopodes (longs prolongements cytoplasmiques) qui vont entourer la cellule cible, et finir par l'inclure dans le corps cellulaire du neutrophile.
Là, des vacuoles contenues dans les neutrophiles fusionnent avec la vacuole de phagocytose : leur contenu (lysozyme et granulations sécrétoires) détruit la cellule cible par un mécanisme toxique.Ce processus entraîne la mort du neutrophile, car elle épuise toutes ses réserves en glucose.La phagocytose est favorisée par la mobilité de ces cellules : elles sont capables de se déplacer dans le sang puis dans les tissus vers les foyers d'infection, où elles sont attirées par chimiotactisme (lors d'une infection, les cellules endothéliales, mastocytes et macrophages à proximité libèrent des substances chimiques appelées cytokines, qui attirent les polynucléaires).Les neutrophiles sont bien plus nombreux que d'autres cellules douées de phagocytose (les macrophages), mais survivent dans le sang bien moins longtemps.
Certains spécialistes  du système immunitaire pensent que cette courte durée de vie (qui se termine dès la première phagocytose) est une adaptation évolutive qui permet d'éviter la propagation de pathogènes capables de parasiter les phagocytes.
La durée de vie des neutrophiles a été mesurée au moyen de globules blancs marqués par des isotopes radioactifs.
Dans la circulation, les neutrophiles ne vivent guère plus de 10 à 12 heures.
Dans les tissus, cette durée de vie semble être plus longue (2 à 3 jours).
Lorsqu'un neutrophile sort de la circulation, p. ex.
pour se rendre vers un foyer inflammatoire, il n'y retourne plus jamais.
Lorsqu'un neutrophile meurt, ses fragments sont repris par phagocytose dans le S.R.E.Après de nouvelles recherches, il semblerait que les neutrophiles possèdent une fonction inédite dans le contrôle immunitaire.
En effet, ils auraient la capacité d'expulser leur propre matériel génétique, en direction de l'agent pathogène afin de les neutraliser et de les dégrader plus facilement .
Les propriétés de l'ADN sont bien connues, molécule très longue (quand elle se condense) et surtout très collante, son action sur les parasites pourrait fonctionner en effet.
Lors de l'action des neutrophiles ceux-ci expulsent en direction des bactéries (surtout) une substance très visqueuse et très collante, leur ADN.
Les bactéries sont ainsi engluées et elles ne peuvent plus bouger, leur destruction est plus facile.Une baisse de la valeur absolue des neutrophiles est appelée « neutropénie ».
Celle-ci peut être congénitale, ou bien plus souvent liée à des facteurs acquis (infection sévère, chimiothérapie, etc.).Les anomalies fonctionnelles sont le plus souvent héréditaires : les neutrophiles peuvent être incapables de phagocytose.Le déficit congénital en alpha-1-antitrypsine entraîne un défaut d'inactivation de l'élastase, une des enzymes contenues dans les neutrophiles.
L'élastase est une enzyme capable de détruire certains tissus, et cette maladie entraîne des dégâts tissulaires, en particulier dans le poumon (emphysème pulmonaire).Une intoxication tabagique entraîne une inhibition de l'alpha-1-antitrypsine qui a pour rôle de moduler l'action des élastases des neutrophiles.
Ceci entraîne une destruction accrue des fibres élastiques du poumon ce qui augmente sa compliance, provoquant un emphysème qui gêne la mécanique ventilatoire.Le neutrophile peut être sujet à diverses autres anomalies, ces anomalies peuvent être transitoires comme les granulations toxiques, la présence de vacuole dans le cytoplasme ou la présence de corps de Döhle souvent signe d'un état infectieux ou plus sérieuse comme la présence de neutrophile hypersegmenté (le noyau contient 5 lobes ou plus).1) Mobilisation des granulocytes marginaux et séquestrésC'est ce qu'on constate, par exemple après injection d'adrénaline ou à la suite d'un exercice musculaire.2) Largage des réserves de la moelle osseuseHyperleucocytose transitoire.3) Hyperproduction de neutrophiles par la moelle osseuseDans ce cas, l'hyperleucocytose se maintient de manière soutenue ; la proportion des neutrophiles dépasse souvent 80 % ; il y a toujours apparition de formes jeunes (monolobées).
La médecine (du latin : medicina, qui signifie « art de guérir, remède, potion »), au sens de pratique (art), est la science témoignant de l'organisation du corps (anatomie), son fonctionnement normal (physiologie), et cherchant à préserver la santé (physique comme mentale) par la prévention (prophylaxie) et le traitement (thérapie) des maladies.
La médecine humaine est complémentaire et en synergie avec la médecine vétérinaire.La médecine contemporaine utilise l'examen clinique, les soins de santé, la recherche et les technologies biomédicales pour diagnostiquer et traiter les blessures et les maladies, habituellement à travers la prescription de médicaments, la chirurgie ou d'autres formes de thérapies.Il n'existe pas suffisamment de données fiables pour déterminer le début de l'usage des plantes à des fins médicinales (phytothérapie).
Les données médicales contenues dans le Papyrus Edwin Smith peuvent être datées du XXXe siècle av.
Les premiers exemples connus d’interventions chirurgicales ont été réalisés en Égypte aux alentours du XXVIIIe siècle av.
Imhotep sous la troisième dynastie est parfois considéré comme le fondateur de la médecine en Égypte antique et comme l'auteur originel du papyrus d’Edwin Smith qui énumère des médicaments, des maladies et des observations anatomiques.
Le papyrus gynécologique Kahun traite des maladies des femmes et des problèmes de conception.
Nous sont parvenues trente-quatre observations détaillées avec le diagnostic et le traitement, certains d'entre eux étant fragmentaires.
J.-C., il s’agit du plus ancien texte médical, toutes catégories confondues.
On sait que des établissements médicaux, désignés par l’expression Maisons de vie ont été fondés dans l’Égypte antique dès la première dynastie.Les plus anciens textes babyloniens sur la médecine remontent à l’époque de l’ancien empire babylonien dans la première moitié du IIe millénaire av.
Cependant, le texte babylonien le plus complet dans le domaine de la médecine est le Manuel de diagnostic écrit par Esagil-kin-apli le médecin de Borsippa, sous le règne du roi babylonien Adad-ALPA-iddina (1069-1046 av.
).Hippocrate, est considéré comme le père fondateur de la médecine moderne et rationnelle,, et ses disciples ont été les premiers à décrire de nombreuses maladies.
On lui attribue la première description des doigts en baguette de tambour, un signe important pour le diagnostic de la bronchopathie chronique obstructive, du cancer du poumon et des cardiopathies cyanogènes congénitales.
Pour cette raison, le symptôme des doigts en baguette de tambour est parfois appelé hippocratisme digital .
Hippocrate a également été le premier médecin à décrire la face hippocratique.
Shakespeare fait une allusion célèbre à cette description dans sa relation de la mort de Falstaff dans Henry V, acte II, scène III,.
Le Corpus hippocratique popularise la théorie des humeurs.
La médecine rationnelle grecque et latine coexiste cependant pendant toute l'Antiquité avec les cultes des Dieux guérisseurs.Agnodice (Hagnodice) ou Hagnodikè (en grec ancien : Ἁγνοδίκη) fut, selon une légende grecque rapportée par Hygin (Caius Julius Hyginus) dans la 274e de ses Fabulae, l'une des premières femmes médecin et gynécologue.
Issue de la haute société athénienne, elle se déguisa en homme pour suivre les cours de médecine du célèbre médecin Hérophile.
J.-C., elle passa l'examen et devient gynécologue, mais sans révéler qu'elle était une femme.La médecine pratiquée et enseignée en occident a ses racines dans les connaissances acquises et protocolées de l'Antiquité au Ier millénaire av.
de l'Orient à l'Empire romain.Elles proviennent de la Torah, étonnement rationnelle en la matière, car tenant compte des conditions climatiques.
En effet, les cinq livres de Moïse qui la constituent, contiennent diverses « lois » ayant des conséquences directes sur la santé à travers différents rituels, tels que l'isolement des personnes infectées (Lévitique 13:45-46), le lavage des mains après avoir manipulé un cadavre (Livre des Nombres 19:11-19) et l’enfouissement des excréments à l’extérieur du campement (Deutéronome 23:12-13).La traduction dans les années 830-870 de 129 œuvres du médecin grec Galien (1er siècle av J.C.)
en arabe par Hunayn ibn Ishaq et ses élèves sert de modèle à la médecine des civilisations islamiques et se propage rapidement à travers l’Empire arabe, reprenant en particulier, l'insistance de Galien sur une approche rationnelle et systématique de la médecine.
Qusta ibn Luqa joua aussi un rôle important dans la traduction et la transmission des textes grecs.
Les médecins musulmans ont mis en place certains des premiers hôpitaux, institution qui importée en Europe à la suite des croisades.En Europe occidentale, l'effondrement de l'autorité de l’empire romain a conduit à l’interruption de toute pratique médicale organisée.
La médecine était exercée localement, alors que le rôle de la médecine traditionnelle augmentait, avec ce qui restait des connaissances médicales de l'antiquité.
Les connaissances médicales ont été préservées et mises en pratique dans de nombreuses institutions monastiques qui s’étaient souvent adjoint un hôpital et disposaient de carrés d'herbes médicinales.
Une médecine professionnelle organisée est réapparue, avec la fondation de l’école de médecine de Salerne en Italie au XIe siècle qui, en coopération avec le monastère du Mont Cassin, a traduit de nombreux ouvrages byzantins et arabes.À partir du XIe siècle, l'Église veut dissocier la vocation de moine de la profession de médecin.
La volonté d'encadrer le savoir aboutit à la formation d'universités aux mains des ecclésiastiques.
Les médecins de l'université de médecine de Montpellier, dépositaires des doctrines des médecins juifs et arabes, privilégient les plantes, ceux de l'Ancienne université de Paris privilégient la purge et la saignée.Au XIXe siècle, Karl August Wunderlich publie Das Verhalten der Eigenwärme in Krankheiten, qui établit que la fièvre est seulement un symptôme et met fin au credo d'une maladie infectieuse jusqu'alors nommée « fièvre intermittente ».
En 1881 Theodor Billroth réalise la première gastrectomie, il révolutionne la chirurgie du pharynx et de l'estomac.
En utilisant l'analyse statistique, le médecin Pierre-Charles Alexandre Louis (1787-1872) montre que l'utilisation des saignées chez les malades atteints de pneumonie n'est pas bénéfique mais néfaste.
Ceci esquisse la notion d'étude randomisée en double aveugle.Madeleine Brès (1842-1921) est la première femme de nationalité française à accéder aux études de médecine en 1868, mais sans avoir le droit d'accéder aux concours.
Elle obtient son doctorat en médecine, en 1875 et devient gynécologue et pédiatre.
Elle démontre dans sa thèse que le lait du nourrisson se modifie au cours de l'allaitement et crée une des premières crèches parisiennes.
Elizabeth Garrett Anderson, britannique la devance de cinq ans en France dans l'obtention de son doctorat.En 1854, Florence Nightingale est la première à utiliser les statistiques pour réorganiser les soins aux blessés de la guerre de Crimée et faire baisser la mortalité des soldats,,.Le 25 novembre 1901, Aloïs Alzheimer décrit le tableau clinique de la maladie qui porte son nom, dont il n'existe toujours aucun traitement connu à ce jour.
Les traitements médicaux font des progrès spectaculaires avec l'invention de nouvelles classes de médicaments.
Felix Hoffmann dépose le brevet de l'aspirine le 6 mars 1899.
En 1909, le Nobel de médecine Paul Ehrlich invente la première chimiothérapie en créant un traitement à base d'arsenic contre la syphilis.
En 1921 Frederick Banting de l'université de Toronto isole l'insuline et invente un traitement du diabète sucré.
Le premier antibiotique date de 1928 avec la découverte de la pénicilline par Alexander Fleming.Selon la psychanalyste argentine Raquel Capurro, la médecine a été le premier domaine influencé par le positivisme d'Auguste Comte, à partir du milieu du XIXe siècle, à travers des personnalités telles que le docteur Robinet parmi d'autres.La délimitation de ce qui est médecine et de ce qui ne l'est pas est source de débat.La plus grande partie de cet article traite de la médecine telle qu'elle s'est développée à partir de l'époque moderne, et pratiquée à partir du XIXe siècle.
Les innovations majeures apportées par la médecine occidentale à partir du XIXe siècle (anesthésie et asepsie puis vaccination et antibiotiques au XXe siècle), ses succès, ainsi que sa diffusion à travers le monde par le biais notamment de la colonisation par l'Occident vont inciter à poser, dès la fin du XIXe siècle, la médecine scientifique occidentale comme modèle de médecine faisant autorité, lequel s'est diffusé au niveau mondial à travers son industrialisation au XXe siècle.Certains chercheurs réhabilitent de même certains aspects de la médecine médiévale occidentale.
Ainsi l'historien de la médecine Roger Dachez qui met en valeur l'aspect préventif et la vision globale qu'avait de la médecine le Moyen Âge.De même, toujours à la fin du XXe siècle, notamment sous l'effet de la mondialisation, les médecines traditionnelles ou non occidentales ont vu leur place reconnue au sein de la médecine mondiale : en 2002, l'organisation mondiale de la santé a ainsi mis en place sa première stratégie globale en matière de médecine traditionnelle.On identifie ainsi, à côté de la médecine occidentale, d'autres types de médecines, dites « alternatives » incluant : médecine chinoise, médecine tibétaine traditionnelle, médecine ayurvédique, médecine traditionnelle, et médecine non conventionnelle.En Occident, l'usage de médecines alternatives et complémentaires est constaté dans certaines conditions où les traitements de biomédecine semblent inefficaces, notamment dans le cas de maladies chroniques.Les étapes de l'acte médical sont formées de :En travaillant ensemble comme une équipe interdisciplinaire, de nombreux professionnels de la santé hautement qualifiés sont impliqués dans la prestation des soins de santé modernes.
Voici quelques exemples : les infirmiers, les techniciens médicaux d'urgence et les ambulanciers, les scientifiques de laboratoire, pharmaciens, podologues, physiothérapeutes, inhalothérapeutes, psychologues, orthophonistes, ergothérapeutes, radiologues, des diététiciens, des bioingénieurs, des chirurgiens et des vétérinaires.Un patient admis à l'hôpital est habituellement sous les soins d'une équipe spécifique en fonction de leur problème de présentation principale, par exemple, l'équipe de cardiologie, qui peut ensuite interagir avec d'autres spécialités, par exemple, la chirurgie, la radiologie, pour aider à diagnostiquer ou traiter le problème principal ou des complications ultérieures.
Les médecins ont de nombreuses spécialisations et sous-spécialisations dans certaines branches de la médecine, qui sont énumérés ci-dessous.
Il existe des variations d'un pays à l'autre en ce qui concerne les spécialités et les sous-spécialités.Les principales branches de la médecine sont :Une profession de la santé est une profession dans laquelle une personne exerce ses compétences ou son jugement ou fournit un service lié au maintien ou l'amélioration de la santé des individus, ou au traitement ou soins des individus blessés, malades, souffrant d'un handicap ou d'une infirmité.
Des exemples de profession peuvent notamment inclure : médecin, pharmacien, chirurgien-dentiste, sage-femme, masseur-kinésithérapeute, physiothérapeute, ergothérapeute, psychomotricien, infirmier, podologue, aide-soignant, ambulancier, et attaché de recherche clinique.Chaque profession possède son propre cursus de formation.
En plus des études permettant d'exercer la profession de médecin dont l'organisation varie selon les pays, on trouve donc notamment les études en soins infirmiers, et les études de pharmacie.L'étudiant en médecine s'appelle carabin.Les apports de la médecine, particulièrement de la médecine occidentale depuis le XIXe siècle, se mesure notamment par l'allongement de la durée de la vie, l'espérance de vie en bonne santé, la réduction de la mortalité infantile, et l'éradication ou la capacité technique d'éradication de très anciennes épidémies (tuberculose, peste, lèpre, etc.).
Ces progrès se poursuivent comme avec les succès de nouvelles thérapies (ou actes chirurgicaux) sur des pathologies considérées encore incurables il y a une quinzaine d'années (comme certains cancers et maladies auto-immunes).La médecine n'est pas une science exacte, et l'acte médical peut parfois affecter la personne humaine de manière négative, par exemple via :De nombreux progrès sont annoncés ou espérés dans les années à venir, en matière de santé-environnement, d'épidémiologie, d'allongement de la durée de vie, si ce n'est de la durée de vie en bonne santé.
La médecine prédictive, le clonage, les cellules-souches posent des questions nouvelles en termes de bioéthique.Des défauts d'anticipation font que, par exemple en France, en 2025, alors que la population aura augmenté (et la population âgée plus encore), le nombre de médecins aura diminué de 10 % et la densité médicale de 15 %, à la suite du non-remplacement des médecins baby-boomers induit par les quotas d’accès aux études de médecine dans les années 1970 à 1990.
La médecine libérale devrait perdre 17 % de ses effectifs, et le secteur salarié 8 %, sauf en milieu hospitalier où le ministère envisage une hausse de 4 % ; 13 % des généralistes auront disparu, contre 7 % pour les spécialistes (ophtalmologistes, oto-rhino-laryngologistes et psychiatres surtout).
La faible « densité médicale » augmentera aussi le coût des soins, l’impact des déplacements en termes de pollution (et secondairement de santé) et pourrait diminuer l'efficience médicale (une moindre densité médicale augmente la mortalité), d'autant plus que les patients sont plus pauvres.
L'épigénétique (mot-valise de épigenèse et génétique) est la discipline de la biologie qui étudie la nature des mécanismes modifiant de manière réversible, transmissible (lors des divisions cellulaires) et adaptative l'expression des gènes sans en changer la séquence nucléotidique (ADN).Dans l'histoire de ce sujet d'étude, l'épigénétique est d'abord mise en évidence par la différenciation cellulaire puisque toutes les cellules d'un organisme multicellulaire ont le même patrimoine génétique, mais l'expriment de façon très différente selon le tissu auquel elles appartiennent.
Puis ce sont les possibilités d'évolution d'un même œuf en mâle ou femelle chez les tortues, en reine ou ouvrière chez les abeilles, qui prouvent que des mécanismes peuvent lier des facteurs environnementaux et l'expression du patrimoine génétique.En matière d'évolution, l'épigénétique permet d'expliquer comment des traits peuvent être acquis, éventuellement transmis d'une génération à l'autre ou encore perdus après avoir été hérités.
La mise en lumière récente de ces moyens épigénétiques d'adaptation d'une espèce à son environnement est, selon Joël de Rosnay en 2011, « la grande révolution de la biologie de ces cinq dernières années » car elle montre que dans certains cas, notre comportement agit sur l'expression de nos gènes.
Elle explique aussi le polyphénisme, par exemple les changements de couleur en fonction des saisons (tel le renard polaire qui devient blanc en hiver).L'épigénétique a des applications possibles en médecine, avec des perspectives thérapeutiques nouvelles notamment à l'aide d'« épi-médicaments », mais aussi en biologie du développement, agronomie ou nutrition.Par exemple, une même larve d'abeille deviendra une reine ou une ouvrière en fonction de la façon dont elle est nourrie, et un même œuf de tortue peut éclore en mâle ou femelle en fonction de la température.
Il s'agit bien de l’expression du même code génétique global, mais des facteurs environnementaux ont sélectionné une expression plutôt qu'une autre, chacune étant disponible dans la « base de données » génétique.Autrement dit, l'épigénétique concerne l'ensemble des mécanismes qui gouvernent la façon dont le génotype est utilisé pour créer un phénotype.Par analogie, on peut rapprocher le couple génétique - épigénétique à l'écriture et à la lecture d'un livre.S'il existe une « base de données génétique », sa lecture s'effectue de façon éminemment diverse en fonction des modifications épigénétiques qui sont apportées au génome et à la chromatine.
La transmission de l'héritage génétique s'accompagne également de celle d'un héritage épigénétique.Cette interrogation de Thomas Morgan qui se rapporte aux organismes pluricellulaires impose le constat de différences possibles dans l'expression d'un même génome car les cellules d'un même organisme — ou cellules somatiques — sont génétiquement identiques, clones les unes des autres.
Sauf cas exceptionnel de mutation spontanée ou lors du développement des lymphocytes T, les cellules issues d'une seule cellule œuf et dupliquées par mitose partagent exactement le même patrimoine génétique.
Pourtant un neurone, un globule blanc, ou encore une cellule épithéliale sont très différentes les unes des autres.
« Cadre classique de l'épigénétique », cette différenciation cellulaire sur la base d'un même code génétique est un objet d'étude de la biologie du développement.L'existence de phénomènes épigénétiques se trouve également illustrée par les différences physiques et biologiques constatées chez des animaux de laboratoire clonés, ou chez les clones naturels que sont les vrais jumeaux (monozygotes) chez qui les empreintes épigénétiques sont beaucoup plus semblables à 3 ans qu'à 50 ans.
Une vaste étude est toujours en cours pour caractériser les différences entre jumeaux monozygotes.Si ces mises en évidence concernent principalement des êtres pluricellulaires Eucaryotes, des phénomènes épigénétiques ont aussi été mis en évidence chez des êtres unicellulaires aussi bien eucaryotes (par exemple la levure) que procaryotes.L'histoire de l'épigénétique peut se rapporter aux théories qui se demandent si la totalité des caractéristiques d'un individu est contenue dans l'œuf dont il est issu, aux théories de l'influence du contexte sur la génétique, ou encore à la mise en évidence moléculaire de ces mécanismes et de la réversibilité sur quelques générations d'un caractère, en particulier s'il est créé par l'environnement.Par ailleurs, le terme ou des formes dérivées, telle que « épigénisation », sont également utilisés dans d'autres disciplines, par exemple la géologie.Le mot épigenèse remonte à Aristote qui nommait ainsi le développement d'un œuf informe de façon graduelle aboutissant à un organisme aux tissus différenciés.
Cette théorie s'opposa au préformationnisme dont les tenants qui se réclamaient d'Hippocrate postulaient que l'être vivant préexistait en miniature dans le germe.
La théorie de l'épigenèse fut soutenue par l'embryologiste William Harvey qui postulait en 1651 dans son ouvrage intitulé Exercitationes de generatione animalium que « tout ce qui vit vient initialement d'un œuf».
À la même époque, la théorie préformationniste (ou préformiste) avait l'appui de Marcello Malpighi tandis que Nicolas Hartsoeker n’était pas préformiste, mais disséminationniste (hypothèse selon laquelle les germes des animaux sont incréés et dispersés à travers le monde).Le débat entre épigénisme et préformationnisme fut une controverse majeure de la biologie au cours des siècles suivants, à travers notamment l'ovisme et l'animalculisme.
Elle prendra fin au milieu du XIXe siècle avec le développement de la théorie cellulaire et du rôle de la cellule, déjà envisagée par Buffon dans son Histoire naturelle générale et particulière, dont la publication en volumes s'étend de 1749 à 1804.Bénédict Morel propose, en 1857, une théorie de la dégénérescence  expliquant que le « crétin des Alpes » était le dernier rejeton d’une longue lignée d'individus de plus en plus dégénérés, rejetant l'hypothèse d'un manque d'iode, pourtant confirmée depuis.L'hypothèse de changements épigénétiques affectant l'expression des chromosomes a été émise par le biologiste russe Nikolaï Koltsov.
On attribue la paternité de l'épigénétique dans son sens moderne au biologiste et embryologiste Conrad Hal Waddington qui la définit en 1942 comme une branche de la biologie étudiant les implications entre les systèmes gènes + environnement et leurs produits donnant naissance au phénotype d'un individu.
Cette idée venait combler des lacunes du modèle génétique postulant une équivalence unique entre phénotype et génotype qui ne pouvait expliquer tous les phénomènes liés à la différenciation cellulaire.
Il fut alors élaboré une théorie dans laquelle chaque cellule indifférenciée passait par un état critique qui serait responsable de son développement futur non uniquement lié à ses gènes, et pour cette raison qualifié d'épigénétique.Dans les années 1960 et 1970, les expérimentations en biologie moléculaire fleurissent et donnent lieu à des Prix Nobel.
En 1965, pour François Jacob, Jacques Monod et André Lwoff, qui mettent en évidence le rôle de l'ARN dans le contrôle génétique des synthèses enzymatiques et virales ; en 1975, pour David Baltimore et Howard Temin, qui mettent en évidence le phénomène de transcription inverse, la synthèse d'un brin d'ADN à partir d'une matrice ARN.
Ces mécanismes annexes à la génétique sont fondamentaux dans la compréhension et l'émergence de l'épigénétique, mais ils ne remettent pas en cause le modèle standard de compréhension de l'évolution, la théorie synthétique de l'évolution, où seuls le hasard des mutations génétiques et la sélection naturelle sont en cause.Cette certitude scientifique reste inébranlable jusque dans les années 1990 pendant lesquelles cette théorie synthétique est confrontée au séquençage complet de plusieurs génomes ce qui suggère qu'elle doit être complétée, car la communauté scientifique n'y découvre pas la totalité des effets phénotypiques dont elle espérait l'explication.
Cette difficulté inattendue remet au goût du jour la recherche de facteurs externes au génome.
L'épigénétique ainsi redéfinie revendique alors sa place comme prolongement et complément de la génétique classique, notamment dans le domaine de la nutrition, de la reproduction, et comme « aspect de la post-génomique » accompagnant la recherche dans son passage de l'étude du génome à celui de l'épigénome.Dans les années 1980, Robin Holliday nomme « hérédité épigénétique » l'hérédité mise en évidence chez les mammifères en 1999 par Emma Whitelaw (en).
L'étape suivante qui se développe depuis les années 2000 est le travail sur le rôle de facteurs environnementaux sur l'expression génétique, comme en 2007 avec l'exposition au bisphénol A qui perturbe la méthylation de l'ADN de souris.
On étudie alors la possibilité de transmission des caractères acquis et le rôle des gamètes pour savoir s'ils peuvent conserver certains des marqueurs épigénétiques.Souvent polémique parce que non prévue par la théorie synthétique de l'évolution (bien que son principe ait été suggéré par Lamarck hors de toute connaissance génétique, et que Darwin lui-même laisse ouverte explicitement dans L'Origine des espèces la possibilité chez les chiens pointers d'effets cumulatifs du dressage), mais surtout parce que prises à tort par le grand public pour une réfutation de l'existant plutôt qu'un complément, ces études accordent volontiers à l'épigénétique un rôle davantage marginal pour expliquer quelques mécanismes d'adaptation et d'évolution des formes vivantes.D'autres dimensions du rôle de l'épigénétique sont aussi explorées comme son incidence sur les neurones pour stabiliser leurs connexions synaptiques, ce qui aurait un rôle sur la mémoire à long terme ; ou l'effet d'un stress infantile sur la sensibilité au stress à l'âge adulte par son effet sur la méthylation de l'ADN des récepteurs au glucocorticoïde.L'épigénétique propose des explications au sujet de la transmission des caractères acquis.La sélection naturelle combinée à la génétique et au hasard des mutations étaient les seuls facteurs reconnus de l'évolution depuis August Weismann, et jusqu'à l'apparition de l'épigénétique dans les années 1990.
Pourtant l'idée de la possibilité de transmettre des caractères acquis est abordée entre autres par Aristote, Jean-Baptiste de Lamarck, Charles Darwin, ou encore Ivan Mitchourine et Lyssenko.Les caractères épigénétiques ne s'opposent pas aux théories génétiques associées à la sélection naturelle, mais les complètent.
Ainsi, l'hérédité épigénétique « présente une plus grande sensibilité à l'environnement et une stabilité inférieure à celle des modifications de la séquence de l'ADN ».Selon Jean-Claude Ameisen qui vulgarise le sujet, les expérimentations scientifiques dans le domaine se sont multipliées dans les années 2000 et 2010.
Par exemple sur la transmission de caractères provoqués par le contexte, comme la présence d'une odeur, ou un vécu traumatique.
Chez la souris par exemple, un trauma précoce semble avoir des répercussions comportementales et métaboliques sur les générations suivantes, y compris si les descendants n'ont jamais été mis en contact avec les parents (fécondation in vitro et « mère porteuse »).
Globalement l'étude de ce qui est transmis par les cellules séminales paternelles est utilisée afin d'isoler des caractères exclusivement innés,.On a récemment montré (2017) chez le rat de laboratoire que l'exposition d'une mère à de l'atrazine (désherbant) au moment de la formation des gonades de ses embryons faisait que cette molécule (ou le stress induit in utero par cette molécule) pouvait reprogrammer durablement des cellules souches gonadique et être source de problèmes épigénétiques dans les générations suivantes (susceptibilité aux maladies induites par l'atrazine, chez les mâles et les femelles).De même, une chimiothérapie subie par un adolescent semble induire des effets épigénétiques (transmis donc à la descendance) via une modification qualitative du sperme (anomalies de l'ADN).
C'est la 1re démonstration du fait qu'une exposition chimique précoce peut reprogrammer durablement l'épigénome des cellules souches spermatogènes.
Les épimutations de la lignée germinale (cellules du sperme) identifiées suggèrent que la chimiothérapie peut changer l'hérédité épigénétique à la génération suivante.Le problème de la différenciation cellulaire (des cellules différentes ayant toutes le même génome) a trouvé son expression moléculaire lorsqu'il est apparu que les mêmes gènes n'étaient pas exprimés d'un type cellulaire à l'autre.
Ainsi, la combinaison de gènes nécessaires et suffisants à spécifier un type cellulaire donné est en général exprimée exclusivement dans ce type cellulaire.
Dans de nombreux cas, ces gènes restent exprimés tout au long de la vie du lignage cellulaire (l'ensemble des divisions au sein d'un même type cellulaire).
Il est donc important de comprendre comment se mettent en place ces spécificités cellulaires (comment les gènes deviennent activés ou réprimés au cours du développement) mais également, comment cette expression est par la suite propagée au cours des divisions cellulaires (par exemple pour maintenir l'expression de gènes spécifiques de l'identité musculaire dans des cellules de muscle).
Une grande partie des recherches en épigénétique se concentre justement sur les mécanismes de propagation temporelle de l'expression des gènes, plus particulièrement sur la transcription qui constitue le premier niveau de régulation de l'expression des gènes.
En effet, même si l'expression des gènes peut être régulée à plusieurs niveaux (transcription, épissage, export nucléaire des ARNs, traduction, etc.) la transcription semble être le principal niveau de contrôle.
L'état « épigénétique » d'une cellule semble dépendre principalement de deux variables: 1- les régulateurs transcriptionnels présents (par exemple, les facteurs de transcription) et 2- l'état de compaction de l'ADN, qui va déterminer la capacité des régulateurs transcriptionnels à moduler l'expression des gènes.
En résumé, la question posée en épigénétique consiste à comprendre comment, à partir d'un même génome, peuvent se mettre en place et se propager au cours de divisions cellulaires des états transcriptionnels (exprimé versus non exprimé) distincts.La transcription est la copie du code génétique de l'ADN en ARN.
La double hélice de l'ADN est ouverte et une chaîne d'ARN complémentaire de l'ADN matrice est formée par le complexe de l'ARN polymérase II.
Dans le cas des gènes dits « codants » (c'est-à-dire qui codent des protéines), cet ARN messager sert de matrice à la synthèse de protéines lors de l'étape de traduction.
De nombreux gènes codent des protéines régulatrices appelées facteurs de transcription, dont la fonction est de moduler l'expression d'autres gènes.Certains facteurs de transcription comme HNF4 et MyoD sont susceptibles d'activer leur propre expression, engendrant ainsi une boucle dite d'autorégulation.
Ce mécanisme par autorégulation permet la persistance temporelle de l'expression des gènes après que le stimulus déclencheur ait cessé d'opérer.
Notamment, après la division cellulaire par méiose ou mitose, si le stimulus à l'origine de l'activation d'un gène est absent, les cellules filles peuvent hériter de cette activation (par exemple par la présence de ces facteurs de transcription).
Une telle régulation qui opère en trans, est retrouvée chez des procaryotes (exemple du phage Lambda) comme chez les eucaryotes.
Chez les eucaryotes multicellulaires, ce mécanisme « trans-épigénétique » par autorégulation concerne de nombreux facteurs de transcription impliqués dans la spécification de l'identité cellulaire, et est à ce titre un mécanisme épigénétique majeur.La chromatine des eucaryotes, association entre l'ADN et les protéines histones, autour desquelles l'ADN s'enroule en bobine, constitue une couche régulatrice supplémentaire au contrôle de l'expression des gènes.
Celle-ci peut être soit décondensée ou « ouverte » (euchromatine), permettant ainsi l'accès à la machinerie transcriptionnelle et à l'expression génique, soit condensée ou « fermée » (hétérochromatine), empêchant ainsi l'expression d'un gène.Certaines régions du génome sont constamment dans un état chromatinien fermé, on parle d'hétérochromatine constitutive.
C'est ainsi le cas des centromères et des télomères.L'état de la chromatine dépend de plusieurs facteurs qui régulent sa structure en modifiant chimiquement l'ADN ou l'état post-traductionnel des protéines d'histones ou l'action de remodeleurs de la chromatine et de protéines chaperons.Plusieurs mécanismes de propagation épigénétique de l'information utilisant des modifications de la chromatine se sont mis en place chez les eucaryotes.Les histones forment la « bobine » autour de laquelle vient s'enrouler l'ADN.
Chaque boucle d'ADN avec autour d'un complexe de 8 histones forme un nucléosome.
Ces protéines histones sont elles-mêmes sujettes à plusieurs modifications post-traductionnelles que l'on retrouve principalement sur leurs queues N-terminales qui dépassent de la structure du nucléosome :Les modifications d'histones sont régulées par des enzymes spécialisées qui peuvent soit catalyser leur déposition (activité dite d'écriture) ou leur effacement (activité dite d'effacement).
Les modifications post-traductionnelles des histones peuvent influencer la chromatine de différentes manières : modification de la charge des histones (comme dans le cas de l'acétylation), modification de la structure de la chromatine, ou signal permettant le recrutement de protéines régulatrices (appelées « lecteurs » de la chromatine).
De plus, il existe des régulations croisées très importantes entre les différentes modifications de la chromatine.
Par exemple, certaines modifications d'histones inhibent l'activité d'enzymes qui catalysent la déposition d'autres modifications.Les modifications d'histones sont souvent abusivement qualifiées d'épigénétiques.
En réalité la plupart des modifications d'histones sont directement contrôlées par la transcription et participent à la robustesse plutôt qu'à la propagation des états transcriptionnels des gènes.L'expression d'un gène peut également être régulée par une modification chimique de l'ADN : la méthylation ; précisément la méthylation de cytosine en 5-méthylcytosine des paires de base (ou dimères) C-G.Cette méthylation peut inhiber l'expression génétique d'un brin d'ADN : une faible méthylation se traduit le plus souvent par une forte expression du gène, alors qu'un haut niveau de méthylation inactive le gène.
Cependant, il existe des exemples où une forte méthylation n'a pas de répercussions sur le niveau d'expression.Chez l'être humain, la méthylation de l'ADN s'effectue au niveau des résidus cytosines des îlots CpG (en), site CpG qui se trouvent essentiellement dans les régions proximales des promoteurs de 60 % des gènes.
Dans les cellules normales, ces îlots sont non méthylés, une petite portion devient méthylée pendant le développement, rendant ainsi quelques gènes silencieux de manière stable.On a longtemps pensé que la présence d'un groupe méthyle N1 sur des bases adénine de l'ADN et de l'ARN était une forme de dommage de l'ADN, mais des travaux récents (2016) indiquent que cette méthylation survient aussi dans des sites spécifiques des ARN messagers, où il affecte l'expression des protéines.Lors de la division cellulaire (mitose), un gène peut être transmis avec état de méthylation de l'ADN qui le porte, comme on peut donner un livre avec des marque-pages, mais on considère généralement que pour la reproduction (méiose et fécondation), il y a un nettoyage de tout marquage épigénétique pour permettre le développement d'un nouvel individu.La méthylation de l'ADN est l'acteur majeur de la mise en place de l'empreinte parentale, mécanisme par lequel l'expression d'un gène va dépendre de l'origine parentale.
Par exemple, dans le cas d'un gène à expression maternelle, l'allèle paternel est méthylé et entièrement éteint alors que l'allèle maternel est non méthylé et entièrement exprimé.
L'empreinte parentale dépend également des modifications de la chromatine.
La méthylation de l'ADN est également souvent observée dans les gènes répétés et les rétrotransposons et pourrait être un mécanisme naturel pour l'inactivation des gènes inutiles et potentiellement délétères s'ils étaient exprimés.
Les méthylations de l'ADN peuvent soit être héritées, soit créées ou modifiées en réponse à un facteur environnemental.L'inactivation du chromosome X, est un processus à partir duquel un des deux chromosomes X de la femelle mammifère est inactivé, ce qui permet de compenser la double dose de gènes de ce chromosome par rapport aux mâles.
Le chromosome X inactif est fortement hétérochromatinisé et prend une forme compacte visible dans le noyau des cellules, connue sous le nom de corpuscule de Barr.
Par conséquent une majorité des gènes du chromosome X inactif n'est plus exprimée.
Le choix du chromosome X à inactiver se fait au hasard pendant le développement embryonnaire précoce.
L'état inactif du chromosome X est ensuite fidèlement transmis à la descendance des cellules dans lesquelles le choix a été effectué.
On est donc bien en présence d'un phénomène épigénétique puisque coexistent au sein d'une même cellule deux chromosomes dans des états différents et que ces états sont propagés au fil des divisions cellulaires.Il existe une interdépendance entre la méthylation de l'ADN et celle des histones : on a montré une interaction entre certaines protéines à activité de méthylation de l'ADN, et un système de méthylation des histones.
Nous sommes donc en présence d'un lien direct entre les activités enzymatiques responsables de deux mécanismes épigénétiques distincts.L'épigénétique est donc un système régulateur fondamental, au-delà de l'information contenue dans la séquence d'ADN.
Le gène défini par Mendel doit maintenant être considéré avec la chromatine qui l'entoure puisqu'elle joue un rôle primordial dans la régulation transcriptionnelle et que, de plus, elle est héréditaire tout comme les gènes mendéliens.La transmission structurelle est un mécanisme encore mystérieux.
Il implique la transmission entre cellules (voire entre cellules de générations différentes) de structures particulières (par exemple de protéines).
Ces structures modifiées semblent jouer le rôle de « patron » pour l'organisation structurelle de la génération suivante.
Ce mécanisme de transmission a été mis en évidence dans les organismes unicellulaires ciliés comme la tetrahymena ou la paramécie.
En effet, pour des cellules semblables au niveau génétique, on peut observer des différences dans l'organisation des cils de surface.
Cette organisation est transmissible à la génération suivante.
On soupçonne une telle transmission d'être également possible pour les organismes multicellulaires.L'épigénétique aurait un rôle dans des maladies complexes, mais étant un sujet d'étude récent, voire en plein boom, les études émettent majoritairement des conjectures sur des facteurs influant plus que des certitudes scientifiques sur d'éventuels rapports de cause à effet.Il est question de caractéristiques de santé héritées d'un vécu des parents, par exemple l'influence du stress sur la taille des nouveau-nés ou de la faim pendant la gestation, sur la santé de la descendance (par exemple lors de la famine aux Pays-Bas en 1947).
En 2002, deux études ont été publiées concernant les effets sur la descendance humaine de la nutrition.
L'une sur l'effet des privations alimentaires entre 1890 et 1920 sur la descendance.
L'autre sur une population dont étaient référencés tous les individus, ainsi que leur alimentation en fonction des récoltes, et qui a montré qu'une grand-mère ayant vécu une famine transmet cette information à sa descendance qui peut développer des maladies alors qu'elle n'a jamais connu de famine.
En 2010, Frances Champagne met en corrélation la malnutrition, le stress et l'exposition aux produits toxiques de la mère avec l'état de santé des enfants, voire des petits enfants.
De même, des études ont montré que les enfants de femmes enceintes durant les événements du 11 septembre 2001 possédaient un taux de cortisol plus élevé.
On peut lire dans la même veine que « la mémoire traumatique de l’Holocauste se transmettrait génétiquement » avec la précision « Il s’agit de la première démonstration de transmission d’un traumatisme parental à son enfant, associé à des changements épigénétiques ».Ces phénomènes impliqueraient que certaines maladies ne sont pas dues à une variation de la séquence d’ADN mais peut-être à des « épimutations ».
Par exemple, une anomalie épigénétique serait impliquée dans plus de la moitié des cas de syndrome de Silver-Russel.Depuis 2010, des études lient des états mentaux et comportementaux à l'épigénétique par différentes voies.À partir des années 2010, des auteurs pensent qu'on pourrait bientôt « identifier des mécanismes épigénétiques impliqués dans le développement des maladies psychiatriques », proposer des modifications épigénétiques contrecarrant celles induites par un stress passé (qui semblent pouvoir être réversibles), et/ou trouver de « nouvelles cibles thérapeutiques ».
Mais en 2012, d'autres auteurs rappellent que le statut de vérité scientifique du rôle de l'épigénétique dans les troubles mentaux est encore loin d'être atteint et donc des "épimédicaments" soignant les conséquences de traumatismes (et/ou améliorant la mémoire ?).
Selon Isabelle Mansuy, étant donné la complexité des altérations épigénétiques induites par le stress, un médicament unique semble illusoire.D'autres auteurs font le lien entre pauvreté ou guerres et santé mentale, par différents vecteurs, avant de conclure : « Par conséquent, la priorité devrait être donnée aux politiques et programmes qui réduisent le stress parental, augmentent le bien-être émotionnel des parents et leur assurent des ressources matérielles suffisantes ».Le cancer est une prolifération de cellules toutes issues d'un même clone qui a acquis certaines caractéristiques lui permettant une résistance accrue et une capacité à se diviser indéfiniment.
On peut donc l'envisager sous l'angle d'une maladie de l'expression des gènes.
En effet, les mutations spontanées des gènes sont plutôt rares, les cellules humaines en culture présentent un taux de mutations spontanées de 2 × 10−7 mutations par gène par division cellulaire et l'on considère ainsi que d'autres mécanismes sont en cause pour expliquer l'apparition des cancers.Plusieurs types de cancers sont associés à une réduction globale du taux de méthyl-cytosines dans le génome par rapport au tissu normal, alors qu'à l'inverse on observe parfois que certains gènes suppresseurs de tumeurs sont rendus silencieux par méthylation de novo de leur promoteur.Des tumeurs peuvent maintenir stablement une mutation sur un allèle de gène alors que l'autre est hyperméthylé, et ainsi inactivé.De plus, les gènes suppresseurs de tumeurs résident souvent au sein de régions caractérisées par des délétions fréquentes, aboutissant à une perte d’hétérozygotie (LOH).Enfin, dans certaines de ces régions sont observés des événements épigénétiques sans altérations génétiques.
Ces altérations épigénétiques (ex : méthylation de l'ADN et modifications des histones), semblent initier des processus qui résultent en une perte ou une activation de la transcription des gènes.
Même une mutation peut être initialement due à un mécanisme épigénétique puisque, par exemple, une 5-méthyl-cytosine peut se désaminer (perte de la fonction amine) spontanément en thymine (autre base de l'ADN).
Dans ce cas, la cause primaire est un phénomène épigénétique.
On espère donc un jour pouvoir traiter certains cancers par des médicaments ciblant les modifications épigénétiques (moins fixes que les modifications génétiques, et parfois réversibles).Les maladies infectieuses ne sont pas habituellement décrites comme des régulateurs épigénétiques, mais l'infection et la transmission verticale de virus fonctionnent de manière identique.
De plus, certains prions ont montré des effets bénéfiques et, comme ils décrivent la nature adaptative des protéines, ils ont été décrits comme des mécanismes de transmission épigénétique.Certaines bactéries pathogènes sont capables d'induire des changements épigénétiques dans les cellules qu'elles infectent.
Par exemple Listeria monocytogenes provoque des modifications d'histones par le biais de nucléomodulines tandis que l'infection par Helicobacter pylori entraîne une hyperméthylation du génome des cellules concernées.
Cette stratégie vise généralement à empêcher l'activation de gènes de la réponse immunitaire.La thérapie épigénétique (en) (appelée aussi épithérapie) agit sur l'expression des gènes, quand la thérapie génique consiste à changer les gènes.La thérapie épigénétique peut consister néanmoins à agir directement sur l'ADN, sur la nature de ses constituants.
C'est le cas d'une thérapie qui consiste à réactiver un gène silencieux en empêchant la méthylation de l'ADN en remplaçant un nucléotide normal (ici la cytosine), par un nucléotide qui ne peut être méthylé.
Les analogues nucléosides ne pouvant être méthylés comme la 5-azacytidine sont incorporés lors de la réplication de l'ADN, ce qui semble montrer une efficacité dans le traitement de cancer du poumon, et des essais cliniques sont en cours pour traiter les syndromes myélodysplasiques et certaines leucémies, sièges d'une hyperméthylation génique.Pour les cancers, les espoirs portent sur l'azacitidine, la décitabine, le panobinostat (en), la romidepsine, le belinostatle et le vorinostat…).Une intervention indirecte sur l'épigénome consiste à moduler la disponibilité des groupements méthyles.
Pour ce faire, il est possible :Il a été proposé que la vitamine B12, l'acide folique, l'ADH, ainsi que le stress oxydatif ont un rôle à jouer, via des modifications épigénétiques, dans les altérations de la neurogenèse observées chez les enfants prématurés.Certains médicaments et certaines drogues pourraient avoir des effets épigénétiques indésirés.
Selon des hypotèses de 2009 et 2013, ces effets seraient fréquents.
Par exemple, selon des modélisations informatiques, 5 % des médicaments connus pourraient agir avec l'histone désacétylase, qui n'est qu'un facteur de régulation épigénétique parmi d'autres.
Parmi les médicaments et drogues ayant des effets épigénétiques indésirables, on peut mentionner certains des plus connus : le célécoxib, un anti-inflammatoire non stéroïdien, les antidépresseurs de classe ISRS (le citalopram, la fluoxétine) et tricyclique (l'imipramine), la tamoxifène, un régulateur des récepteurs de l'œstrogène utilisé dans le traitement du cancer du sein, l'acide valproïque, un médicament indiqué dans de nombreuses pathologies neurologiques, et, parmi les drogues, la cocaïne et les opiacés.
Voir aussi : Effet épigénétique des antidépresseurs.Une étude suggère que les effets secondaires épigénétiques des médicaments peuvent être impliqués dans l'étiologie des maladies cardiaques, le cancer, les troubles neurologiques et cognitifs, l'obésité, le diabète, l'infertilité, et la dysfonction sexuelle.
Les effets secondaires épigénétiques causés par un médicament, peuvent persister une fois le traitement arrêté selon certains auteurs, tandis pour d'autres, l'intérêt des thérapies épigénétiques repose au contraire sur la réversibilité de ces effets.Le psychologue Erik Erikson développa une Théorie épigénétique du développement humain traitant des crises psycho-sociales vécues par l'individu, servant ainsi à décrire différentes étapes développementales entrecoupées par ces crises.
Selon lui, même si ces crises ont le plus souvent une origine génétique, la manière dont elles se vivent ne peut être expliquée par la génétique et donc, en écho à la théorie en biologie, sont qualifiées d'épigénétiques.
Jacques Oudin (1908-1985) est un chercheur français en immunologie ; médaille d'Or du CNRS et membre de l'Académie des Sciences, il marque l’immunologie contemporaine par trois avancées majeures : la création d'une nouvelle méthode d'analyse, la découverte de l'allotypie des protéines, la découverte de l'idiotypie des anticorps.Né à Dreux le 15 mai 1908, il meurt à Paris le 15 octobre 1985.Mobilisé en août 1939 comme médecin lieutenant, il est fait prisonnier en juin 1940, puis libéré en janvier 1941 avec le personnel des services sanitaires.Il épouse en 1944 Catherine Gautier (1919-2011) ; ils auront 5 enfants et 12 petits-enfants.Quand sa vie professionnelle lui en laissait le temps, il aimait s’adonner à la peinture, et à la navigation à voile avec sa famille.Interne à l’hôpital Pasteur en 1935, il entre comme boursier à l’Institut Pasteur en 1937, et il y reste pendant toute sa carrière scientifique.
Chef de laboratoire en 1944, il dirige à partir de 1959 le service d’immunochimie analytique spécialement créé pour lui.
Il est nommé en 1964 directeur de recherches au CNRS.Trois avancées scientifiques parmi les plus marquantes de l’immunologie contemporaine jalonnent sa carrière scientifique : l’invention d’une méthode d’analyse immunochimique en milieu gélifié, les découvertes de l’allotypie des protéines et de l’idiotypie des anticorps.Autre grand pastorien, François Jacob (prix Nobel de médecine 1965) écrit à propos de Jacques Oudin : « C’était un chercheur solitaire.
L’un des derniers dans un monde qui est devenu l’affaire des grandes équipes… Personnage tout d’une pièce, Jacques Oudin ne se prêtait ni au compromis, ni à la demi-mesure.
L’intrigue lui répugnait, tout autant que la flatterie.
Ce qu’il avait à dire, il le disait sans fard ni ménagement.
Ce qui ne lui valait pas que des amis.
Mais lui valait d’apparaître comme un symbole de l’honnêteté scientifique et intellectuelle… une des figures les plus marquantes et les plus pures de l’Institut Pasteur et de la recherche française dans ce siècle ».L’importance et l’originalité de ses travaux a conduit de nombreux scientifiques à le considérer comme un des « oubliés » du prix Nobel,,,.En 1936, il soutient sa thèse de doctorat en médecine (étude histologique des épithéliomas du testicule).
En 1946, il crée une méthode d'analyse immunochimique en milieu gélifié, qui lui vaut une notoriété internationale.
Il la présente dans sa thèse de doctorat ès sciences qu'il soutient en 1949.
Durant un quart de siècle, cette méthode sera la seule au monde pour dénombrer, identifier et finalement doser les antigènes.En 1956 il découvre l’allotypie des protéines.
On pensait auparavant que tous les individus d’une même espèce animale avaient la même spécificité antigénique (isotypie).
Il montre que les spécificités antigéniques varient en réalité d’un individu à l’autre (allotypie) et sont transmises héréditairement suivant les lois de Mendel,,.
C'est l’acte de naissance de l’immunogénétique.En 1963 il découvre l’idiotypie des anticorps, en observant que les anticorps possèdent des spécificités antigéniques autres que les spécificités allotypiques et apparemment liées à la fonction anticorps : le système immunitaire de l’individu qui produit des anticorps est capable de réagir, dans des conditions non pathologiques, contre ces spécificités, qu'il qualifiera d'idiotypiques, et de contribuer ainsi à la régulation de leur production,.Cette découverte rend possible la théorie du réseau idiotypique élaborée par Niels Jerne, qui vaut à celui-ci le prix Nobel en 1984.
Il déclarera peu après à propos de sa théorie : « Celle-ci est fondée surtout sur les travaux d'un chercheur de l'Institut Pasteur, Jacques Oudin.
M. Oudin a découvert cette chose curieuse que les anticorps, ces millions de molécules différentes, constituent elles-mêmes pour le corps des molécules étrangères.
Et que le système immunitaire produit des anticorps contre ces anticorps que l'on appelle anticorps anti-idiotypiques.
Mais ça ne s'arrête pas là.
Car ces anticorps contre les anticorps sont eux aussi des molécules étrangères.
Alors le système immunitaire fabrique des anticorps contre les anticorps des anticorps, et ainsi à l'infini ».
Jacques Oudin lui-même aimait à utiliser sur ce point la comparaison de deux miroirs qui se font face et qui n'en finissent pas de se renvoyer leur image.
Depuis lors, l'étude de la genèse des maladies auto-immunes repose bien souvent sur cette notion.C’est Jacques Oudin qui a forgé,, ces mots d’isotypie, allotypie et idiotypie (à partir du grec : ίσος semblable, άλλος autre, ίδίος propre, τυπος empreinte) qui ont été par la suite utilisés par la communauté scientifique tout entière,, et qui expriment l’infinie possibilité d’adaptation de notre système de défense immunitaire.Selon François Jacob : « Toute injustice le hérissait.
D’où son engagement, son combat pour de nombreuses causes comme le génocide arménien.
Membre actif de l’association Amnesty international, il était aussi l’un des membres les plus assidus du Comité de Défense des Hommes de Science (CODHOS), chargé par notre Académie des Sciences de veiller sur les libertés des scientifiques ».En janvier 1979, à l’occasion de son soixante-dixième anniversaire, un colloque international lui est consacré à l’Institut Pasteur avec le concours du C.N.R.S.
et de la Société Française d’ImmunologieLe 27 juin 1992, un médaillon à son effigie, frappé par l’atelier de gravure de la Monnaie, est inauguré à l’Institut Pasteur et prend place aux côtés d’autres pastoriens prestigieux.
En 2002, la Société Française d’Immunologie crée un « prix Jacques Oudin » de recherche en immunologie clinique, qui a pour objectif de récompenser un travail original de recherche en immunologie fondamentale, translationnelle, ou clinique, ayant des applications directes en thérapeutique dans les domaines des maladies auto-immunes et infectieuses, des déficits immunitaires ou le cancer.Une rue porte son nom à Dreux dans le quartier des Rochelles, à proximité de l’avenue Marceau.
Le système du complément est un groupe d'environ 50 protéines connues du sérum, faisant partie de l'immunité innée.
Douze (12) de ces protéines sont directement impliquées dans les mécanismes d'élimination des pathogènes, les autres régulent finement l'activité des premières afin d'éviter une réaction auto-immune (réaction contre le soi).
Il y a trois voies biochimiques qui activent le système du complément : la voie classique du complément, la voie alterne du complément et la voie des lectines liant les résidus mannose des membranes bactériennes.
Le complément peut s'activer en l'absence d'anticorps, dans les trois voies, raison pour laquelle il est considéré comme faisant partie de l'immunité innée.
Néanmoins, la voie dite classique d'activation, la première découverte, peut aussi débuter par la reconnaissance d'anticorps et fait à ce titre partie de l'immunité acquise (dite aussi adaptative).
L'enfant allaité reçoit les compléments C1 à C9 via le lait maternel,.De façon générale, le complément montre qu'immunité innée et immunité acquise doivent être considérées comme deux systèmes collaborant pour élaborer la réponse immunitaire et non comme deux systèmes indépendants.
Le complément stimule l’inflammation et l'opsonisation, lyse directement les cellules pathogènes par formation du complexe d'attaque membranaire, recrute les lymphocytes B (initiant ainsi la réponse adaptative) ainsi que les macrophages phagocytant les pathogènes.À la fin du XIXe siècle, on découvrit que le sérum du sang contenait un « facteur » ou un « principe » capable de tuer les bactéries.
En 1895, Jules Bordet, un jeune scientifique belge à l’Institut Pasteur de Paris, démontra que cet élément pouvait être décomposé en deux composants : un thermostable et un thermolabile.Il a été découvert que le composant thermostable conférait une immunité contre des microorganismes spécifiques, alors que le composant thermolabile était responsable d’une activité non spécifique, conféré par tous les sérums.
Ce composant thermolabile est ce que nous appelons maintenant « complément ».Le terme « complément » fut introduit par Paul Ehrlich à la fin des années 1890, dans une partie de sa grande théorie sur le système immunitaire.
D’après cette théorie, le système immunitaire est constitué de cellules qui possèdent des récepteurs spécifiques à leur surface afin de reconnaître des antigènes.
Après l’immunisation par un antigène, beaucoup de ces récepteurs sont formés, et ils empêchent ainsi ces cellules de circuler dans le sang.Ces récepteurs que l’on appelle maintenant « anticorps », étaient nommés par Ehrlich « Amboceptors », afin d’appuyer sur leur double capacité d’attache : Ils reconnaissent et fixent un antigène spécifique, mais ils peuvent aussi être reconnus et être fixé par le composant antimicrobien thermolabile du sérum.Ehrlich nomma « complément » ce composant thermolabile, parce que c’est un élément présent dans le sang qui « complète » les cellules du système immunitaire.Ehrlich croyait que chaque « amboceptor » spécifique à un antigène avait son propre complément, alors que Bordet croyait qu’il n’y avait qu’un seul type de complément.
Au début du XXe siècle, la controverse fut résolue lorsqu’on comprit que le complément peut agir en combinaison avec des anticorps spécifiques, ou peut aussi agir par sa propre voie non spécifique.Le système du complément est un ensemble de protéines circulantes ou membranaires du sang, principalement sécrétées par le foie.
Leur rôle initialement reconnu était de compléter l'action des immunoglobulines sériques, d'où leur nom.
En l'absence des protéines thermolabiles (qui perdent leur qualités à une température déterminée), les immunoglobulines thermostables spécifiques sont incapables d'entraîner la lyse de leur cible.
Il convient de signaler que le procédé visant à décomplémenter un sérum destiné à un usage en culture cellulaire se fait selon ce principe.
En effet, en portant le sérum à une température de l'ordre de 56 °C, on lui retire ses activités lytiques non spécifiques et spécifiques qui seraient néfastes pour son utilisation ultérieure.
Les protéines du complément représentent environ 5 % des globulines plasmatiques.
Les différentes protéines du complément sont des proenzymes inactives et qui sont activées en cascade par clivage.
Le clivage libère une fraction ayant une activité enzymatique de protéase, et un petit fragment qui possède souvent un rôle sur les cellules inflammatoires.
Le système du complément possède plusieurs fonctions importantes : la cytolyse d'une cellule ou d'un agent pathogène, l'activation du système immunitaire par les petits fragments de clivage proinflammatoires, l'opsonisation de certains agents permettant leur phagocytose, et le métabolisme des complexes immuns circulants grâce aux récepteurs des fragments du complément.
Les différentes voies activant le complément aboutissent à la formation d'une C3 Convertase, point de départ de la voie effectrice commune qui détruit la cible en formant un canal transmembranaire, permettant l'entrée de molécules d'eau dans la cellule.
Les principales protéines du complément sont notées de C1 à C9, elles migrent en électrophorèse dans la fraction des Beta Globulines et ont un poids moléculaire de 100 à 200 kDa.Il existe trois voies principales : la voie classique, la voie alterne, et la voie des lectines, C3 étant le pivot de chacune des voies.Les fragments C3a et C5a sont des molécules appelées « anaphylatoxines » : elles ont pour rôle de libérer l'histamine, de plus C5a a une activité chimiotaxique importante.
Lorsqu'elles sont produites en trop grand nombre, elles peuvent provoquer un choc anaphylactique.
C5a peut aussi activer la voie des lipoxygénases et augmenter l’adhésion leucocytaire.
Tandis que C3b et C3bi fonctionnent comme des opsonines.Les protéines de C5 à C9 en s'assemblant forment le « complexe d'attaque membranaire » (en anglais membrane attack complex, MAC), qui est en l'occurrence l'élément permettant la lyse des cellules pathogènes.La voie classique commence par l'activation du complexe C1, un détecteur de pathogènes qui interagit aussi bien directement avec des pathogènes (immunité innée) qu'avec des  antigène-anticorps (immunité adaptative).
C1 est un gros complexe, composé de trois sous-composants : C1q, le plus gros de ses éléments composé de 6 trimères se terminant chacun par une tête globulaire et dotés d'une queue de type collagène, et qui porte la fonction de reconnaissance du pathogène, C1r et C1s, deux sérine-protéases, qui sont inactives au début du processus.
Lorsque deux têtes globulaires ou plus de C1 se lient à un ligand (pathogène ou anticorps), C1 active C1r, qui devient protéolytique, et clive C1s pour désamorcer la cascade de protéolyse.
Chaque clivage libère un petit fragment : C4a, C2a et C3a qui agissent sur les cellules inflammatoires.Le C1s activé clive alors le C4 en C4a (qui va dans le sang) et C4b qui se fixe sur la membrane de la cellule à lyser et va recruter C2.
C2 sera également clivé par C1s mais aussi via C4b.
Le fragment C2 se divise en C2a et C2b et C2a reste fixé à C4b alors que C2b reste libre.
Le complexe C4bC2a ainsi formé s'appelle la C3-convertase dont le rôle est de scinder C3 en C3a (qui part dans le sang) et C3b.
Ce dernier se fixe sur la membrane de la cellule à lyser et forme le complexe C4bC2aC3b : c'est la C5 convertase.
En immunité innée, C3b se lie ensuite directement au pathogène pour l'opsoniser, selon les cas directement à ses éléments de surface, ou via la Protéine C réactive.
Ces liaisons restent cantonnées à la surface du pathogène.En immunité adaptative, le processus est le même qu'en immunité innée, à cette différence que C3b se lie aux régions Fc d'anticorps.
Seules les IgG1, IgG3, les IgM, et faiblement les IgG2 sont capables d'entraîner la cascade des évènements.
La fixation de deux ou plusieurs immunoglobulines d'IgG ou une molécule d'IgM pentamérique, à la surface d'un microorganisme, permet à leur région Fc de fixer le premier composant de la voie classique.
Ce sont bel et bien les têtes globulaires qui vont interagir avec les fragments Fc des immunoglobulines ayant lié l'antigène.Plusieurs mécanismes interviennent dans la régulation du système de complément :La voie alterne est la première défense mise en jeu lors d'une infection par un germe inconnu de l'organisme infecté avant une réponse immune spécifique.
Elle est activée quant à elle par les surfaces cellulaires des bactéries gram+ ou gram-, quelques cellules infectées par un virus, quelques levures, et parasites.
Également par les polysaccharides, comme le zymosan ou l'inuline, par les LPS (lipopolysaccharides) bactériens, et diverses substances, comme les fibres d'amiante, le gluten, l'hémoglobine, certains produits de contraste fortement iodés et quelques cellules tumorales.
À noter qu'une membrane cellulaire est d'autant plus activatrice de la voie alterne qu'elle est pauvre en acide sialique.
La voie alterne d'activation résulte de la fixation du C3b sur un site accepteur.
En permanence de faibles quantités de C3 sont clivées spontanément en C3a et C3b.
Ce dernier possède, pendant un très court instant, un site hautement réactif capable de se fixer sur des groupements chimiques présents sur virtuellement toutes les surfaces biologiques, principalement bactériennes.
En l'absence de ce site accepteur, le C3b réagit avec l'eau et donne le C3b soluble.Le C3b fixé à une surface peut alors lier le facteur B qui est clivé, en présence d'ions Mg2+, par le facteur D en Bb et Ba, formant la C3-convertase alterne, ou C3bBb.
Cette C3-convertase clive des molécules de C3 pour former un complexe C3bBbC3b, ou C5-convertase alterne.
Cette dernière va à son tour cliver le c5 rejoignant ainsi la voie classique.Elle s'effectue grâce à différentes protéines : Au niveau des membranes, la régulation de l'activation de la voie alterne se fait grâce à différentes protéines membranaires: le récepteur du C, CR1, le facteur d'accélération de dissociation (DAF), la protéine cofacteur de membrane (MCP) ou CD46.
Ces protéines agissent comme cofacteur du facteur I pour dégrader C3b et C4b ou comme accélérateur de la dissociation des C3/C5 convertase alterne ou classique (CR1 et DAF).Une protéine globulaire, la Mannose Binding Lectin (MBL) appartenant à la famille des collectines, peut interagir avec les résidus mannose ou N-acétylglucosamine (GlcNac) des microorganismes.
Sa structure est homologue au C1q.
Sa fixation sur des mannoses de bactéries active 2 sérine-protéases MASP1 et MASP2 ou MASP3 qui clivent et activent C4 et C2, rejoignant ainsi la voie classique.Dans les trois cas, les composants précoces activent localement C3, qui est le facteur pivot du complément, et dont le clivage conduit non seulement à l'assemblage du complexe qui attaque la membrane, mais aussi au recrutement des différents globules blancs.Le C3b, qui est le plus grand fragment de la lyse de C3 par la C3-convertase, se lie de façon covalente à la surface de la cellule.
Le plus petit fragment, C3a, agit quant à lui comme signal diffusible qui provoque une réponse inflammatoire, en stimulant la migration des globules blancs vers le site de l'infection.Le fragment C3b fixé à la membrane, produit à la fois par la voie classique et la voie alterne, et même la voie des lectines, amorce la cascade des réactions qui conduit à la formation du complexe d'attaque membranaire, à partir des composants tardifs du complément.
Il est donc fixé sur la membrane de façon covalente, et il clive le facteur C5 en C5a et C5b.
C5b reste faiblement lié à C3b et s'assemble rapidement à C6 et C7 pour former le complexe C5b67 qui va s'ancrer à la membrane via C7.
Ce complexe lie ensuite C8, pour former le complexe C5b678.
La liaison du facteur C9, qui expose une région hydrophobe après changement de conformation, entraîne son insertion dans la membrane plasmique de la cellule.
Il s'ensuit alors une réaction en chaîne où les C9 de nouvelle conformation vont lier des C9 de l'ancienne, entraînant le changement conformationnel qui leur permet de s'insérer dans la double couche lipidique.
C'est ainsi qu'il se forme un canal au travers de la membrane cellulaire (Complexe d'attaque membranaire (CAM)).
Dès lors, la perméabilité de la cellule est perturbée, les petites molécules pénètrent et sortent de la cellule au voisinage de ces pores, et à travers ceux-ci.
Les macromolécules ne peuvent cependant pas passer.
De ce fait, le mécanisme cellulaire contrôlant l'équilibre des échanges est bouleversé.
L'eau entre par osmose dans la cellule, faisant augmenter son volume jusqu'à la lyse.
On observe ce même phénomène de lyse avec des globules rouges en solution hypotonique.
Ce système est très efficace puisqu'il a été observé que la présence d'un seul de ces canaux permet la lyse d'un globule rouge.Les maladies liées à un déficit en complément sont rares :Les maladies accompagnées de dysfonctionnements du complément sont nombreuses.Bien que certains agents pathogènes soient capables d'inactiver le complément, la plus grande majorité ne le peut pas, et au contraire, active la voie alterne de la C3 convertase.
Ces agents pathogènes favorisent la production des molécules de la voie alterne d'activation, en particulier C3a, C3b, C5a et le complexe d'attaque membranaire C56789.
Celui-ci étant formé sur le site de la C3-convertase, son activité de dégradation s'exerce sur les pathogènes et non sur les cellules de l'hôte.
Les fragments solubles du complément C3a et C5a qui sont formés possèdent des propriétés pro-inflammatoires.
Par exemple, la liaison du C5a aux récepteurs des cellules endothéliales augmente la perméabilité vasculaire et l'infiltration des protéines plasmatiques dans les tissus inflammés.
L'acide désoxyribonucléique recombinant (ADN recombinant ou ADN recombiné) est une molécule d'acide désoxyribonucléique créée en laboratoire composée de séquences nucléotidiques provenant de plusieurs sources créant ainsi des séquences qui n'existent pas dans les organismes vivants.La technologie recombinante est maintenant largement utilisée dans des projets de recherches ou de développement.
On l'utilise principalement pour la production de protéines thérapeutiques (tels que l'EPO ou l'insuline), ou à des fins de recherche pour ajouter une étiquette à une protéine d'intérêt.
Ces étiquettes qui sont liées à la protéine vont pouvoir faciliter sa purification (tels que l'étiquette poly-histidine ou l'étiquette FLAG) ou sa solubilisation (comme la thiorédoxine).
D'autres sortes d'étiquettes peuvent aussi être utilisés à des fins de détection (étiquettes fluorescentes, telles que FLAsH ou REAsH).L'érythropoïétine (EPO) est produite maintenant par la technologie de l'ADN recombinant.Le facteur VIII anti-hémophilique et certains vaccins le sont également (vaccins contre l'hydatidose par exemple).De nombreuses autres protéines recombinantes telles que l'insuline, l'antithrombine III sont obtenues à l'aide de ce type d'ADN
Du grec « égale, forme », caractéristique retrouvée chez tous les individus d'une même espèce.
L'isotype d'une protéine indique la forme spécifique que peut prendre cette protéine au sein d'une même famille.Cette notion a été développée, par Jacques Oudin en particulier, lors de l'étude des spécificités antigéniques des immunoglobulines.
Il s'agit alors d'une caractéristique de classe d'immunoglobulines, IgG, IgM, IgA, IgD, IgE, ou de sous classe, IgG1, IgG2, IgG3, IgG4, IgA1 et IgA2, chacune de ces différentes classes représentant un isotype différent.
Par commutation isotypique, un lymphocyte B peut, lors de sa maturation et en fonction de sa localisation, changer la classe d'immunoglobuline qu'il exprime.Ces caractéristiques spécifiques d'espèces avaient permis à Robin Coombs, Mourant et Race de développer le test à l'antiglobuline.
Le principe de ce test consiste à immuniser  un animal, un lapin par exemple, par un sérum humain.
Ce sérum humain contient des immunoglubulines.
Pour l'animal, ces immunoglobulines sont antigéniques, et ce lapin synthétisera des anticorps de lapin anti-"immunoglobulines humaines".
Nous avons alors obtenu un sérum de lapin anti-"immunoglobuline-humaine", dit sérum A.G.H.
ou antiglobuline humaine.Ce test a permis, à l'origine par technique d'agglutination, de mettre en évidence la présence d'une immunoglobuline humaine fixée sur un érythrocyte.
Depuis, ce test s'est généralisé et permet de mettre en évidence une immunoglobuline humaine dans tout liquide ou fixée spécifiquement sur tout support portant ou ayant fixé l'épitope (érythrocytes, plaquettes, parasites, particules de latex, etc.).Cette antiglobuline, d'origine animale, se fixe spécifiquement aux épitopes isotypiques des immunoglobulines humaines.
Cette antiglobuline peut être marquée afin de déceler sa présence, c'est-à-dire sa fixation spécifique sur les immunoglobulines humaines.Marquée par un fluorochrome, elle permet par technique d'immunofluorescence la mise en évidence d'anticorps antiparasites, toxoplasme ou plasmodium en particulier.Marquée par une enzyme, il s'agit alors d'une technique d'immuno-enzymologie qui permet la mise en évidence d'anticorps antivirus, antihépatite, par exemple.Marquée à l'iode radioactif, elle entre dans le cadre de la radio-immunologie.
La chimiotaxie, l'un des types de taxies, est le phénomène par lequel des cellules corporelles, des spermatozoïdes, le tube pollinique, d'un grain de pollen, ou des bactéries, ou d'autres organismes uni-, ou pluricellulaires, se dirigent ou dirigent leurs mouvements en fonction de certaines espèces chimiques présentes dans l’environnement.Il peut s'agir d'attirance et d'évitement.
Trouver de la nourriture (par exemple du glucose) en se dirigeant vers sa concentration la plus élevée est très important pour les bactéries, aussi bien qu’éviter les agents nuisibles (tels que le phénol).Chez les êtres vivants pluricellulaires, la chimiotaxie joue un rôle insigne dans le développement et dans le fonctionnement physiologique de l’organisme.
Les mécanismes permettant la chimiotaxie chez les animaux peuvent être supprimés lors de la formation des métastases cancéreuses.Bien que la migration des cellules ait été découverte dès le début du développement du microscope (Leeuwenhoek), la première description érudite en a été faite par T. W. Engelmann (en 1881) et par W. F. Pfeffer (en 1884) chez les bactéries et par H.
S. Jennings (en 1906) chez les organismes ciliés.
E. Metchnikov, lauréat du prix Nobel, a également contribué à la recherche de ce domaine en étudiant ce processus comme première étape de la phagocytose.L’importance biologique (et parfois pathologique) de la chimiotaxie a été largement acceptée dans les années 1930.
La définition la plus fondamentale du phénomène a été également formulée à cette époque.
Les aspects primordiaux du contrôle de qualité d’un essai chimiotactique ont été décrits par H. Harris dans les années 1950.Les deux décennies suivantes, les progrès de la biologie cellulaire et de la biochimie ont permis le développement d'une large gamme de techniques nouvelles pour l’étude des cellules donnant de réponse migratoire et des fractions subcellulaires responsables pour le chimiotactisme.
Le travail pionnier de J. Adler a représenté un tournant au niveau de la compréhension du processus entier de la transmission intracellulaire des signaux chez les bactéries.Le 3 novembre 2006, le docteur Dennis Bray (Université de Cambridge) a été honoré par le prix « Microsoft European Science Award » pour ses recherches concernant la chimiotaxie de l’E.
coli,.La chimiotaxie est une des réponses physiologiques les plus fondamentales.
Le développement des systèmes de récepteurs permettant la détection des substances nuisibles ou favorables de l’environnement était essentiel pour les organismes unicellulaires dès les premières étapes de la phylogénie.L’analyse compréhensive du chimiotactisme du Tetrahymena pyriformis — eucaryote protozoaire — et celle des séquences consensus des acides aminés présents dans la soupe primitive suggère l’existence d’une forte corrélation entre le caractère chimiotactique de ces composés relativement simples et leur apparition sur la Terre.
Ainsi, on suppose que les premières molécules étaient fortement chimioattractantes (par exemple Gly, Glu, Pro), tandis que les acides aminés apparus plus tardivement pouvaient être des chimiorepellants forts (par exemple Tyr, Trp, Phe).Certaines bactéries, dont Escherichia coli, ont quelques flagelles (en général 4-10 par cellule).
Ces derniers peuvent tourner dans deux sens :Le sens de la rotation est toujours observé en dehors de la cellule, en regardant les flagelles en face de la cellule.Le mouvement résultant de la bactérie est donc dû à l’alternance des deux phases (« run » et « tumble »).
Si on observe le mouvement d’une bactérie dans un environnement homogène on trouve une trajectoire aléatoire due aux phases de natations rectilignes relativement courtes, interrompues par des phases de « tumble » aléatoires qui réorientent les bactéries.
Les bactéries telles qu'Escherichia coli sont incapables de choisir la direction dans laquelle elles nagent et ne sont pas capables de nager longtemps suivant une ligne droite à cause de la diffusion rotationnelle.
Autrement dit, les bactéries « oublient » la direction dans laquelle elles vont.
Compte tenu de ces contraintes, il est remarquable que les bactéries sont capables de diriger leur mouvement afin de trouver des lieux favorables de concentration élevée en attractants (en général en nourriture) ainsi que d’éviter les substances répellantes (en général les agents toxiques).À la présence d’un gradient chimique les bactéries vont répondre avec la chimiotaxie, elles vont diriger donc leur mouvement en fonction du gradient chimique.
Si la bactérie sent qu’elle bouge dans la bonne direction (c’est-à-dire elle va vers l’attractant ou bien elle s’éloigne du repellant) elle continue de nager tout droit pour plus longtemps avant la phase « tumbling ».
Dans le cas contraire, elle va arrêter de nager plus tôt et essayer une nouvelle direction choisie au hasard.
Autrement dit, les bactéries comme E. coli utilisent une perception temporelle pour décider si la vie commence à devenir meilleure ou pire.
De cette façon, elles trouvent assez bien les lieux où la concentration des attractants est la plus élevée (en général la source).
De plus, même en cas de concentrations très élevées, elles sont capables de distinguer des différences très faibles de concentration.
La détection des reppellants fonctionne avec la même efficacité.Il paraît remarquable que cette marche aléatoire soit le résultat d’un choix simple entre deux formes de mouvement aléatoire, notamment entre la natation et le « tumbling ».
En effet, les réponses chimiotactiques telles qu’oublier la direction et choisir le type du mouvement ressemblent à la capacité de prendre des décisions des êtres vivants plus évolués possédant un cerveau avec lequel elles sont capables de traiter les informations sensorielles.La structure hélicale du filament flagellaire unique est cruciale pour l'exécution de ces mouvements.
Par ailleurs, la protéine constituant le filament flagellaire, la flagelline, est assez similaire chez toutes les bactéries ayant des flagelles.
Les vertébrés semblent tirer un bénéfice de ce fait : ils possèdent un récepteur immunologique (TLR5) conçu pour la reconnaissance de cette protéine conservée.Comme c’est souvent le cas en biologie, certaines bactéries ne suivent pas la règle.
Beaucoup de bactéries, telle que Vibrio, n’ont qu’un seule flagelle polaire (ciliature monotriche).
Leur méthode de chimiotaxie est différente.
D’autres possèdent un flagelle qui se situe entièrement dans la paroi.
Quand ces bactéries bougent, la cellule entière, dont la forme ressemble à un tire-bouchon, est mise en rotation.Le gradient chimique est perçu à l’aide de plusieurs récepteurs transmembranaires, appelés « methyl accepting chemotaxis proteins (MCPs) » qui varient par rapport à la molécule détectée.
Ces récepteurs fixent des attractants ou des repellants, soit directement soit indirectement, via des interactions avec des protéines du périplasme.
Ces signaux sont ensuite transmis à des récepteurs — à travers la membrane plasmique — au cytosol où les protéines Che  deviennent activées.
Les protéines Che altèrent la fréquence de « tumbling » et les récepteurs.Les protéines CheA et CheW se fixent au récepteur.
L’activation du récepteur par un stimulus externe résulte l’auto-phosphorylation de l'histidine kinase CheA à un résidu unique de histidine fortement conservé.
Puis, CheA transfère un groupe phosphoryl aux résidus aspartates conservés des régulateurs de réponse, CheB et CheY.
Ce mécanisme de transmission de signal s’appelle un « système à deux composants » qui est une forme très répandue de la transmission des signaux chez les bactéries.
CheY, en interagissant avec la protéine commutateur flagellaire, la protéine FliM, induit le changement du sens de rotation des flagelles du sens inverse des aiguilles d’une montre au sens des aiguilles d'une montre et ainsi induit le « tumbling ».
La modification de l’état de rotation d’un seul flagelle peut perturber le faisceau entier et provoquer le « tumbling ».Une fois activée par CheA, CheB agit comme une méthyle estérase et enlève des groupes méthyles des résidus glutamates de la partie cytoplasmique du récepteur.
Elle a un effet antagoniste par rapport à la méthyle transférase CheR qui méthyle les mêmes résidus de glutamates.
Plus de groupes de méthyle sont rajoutés au récepteur, plus ce dernier est sensible.
Comme le signal à partir du récepteur entraîne la déméthylation de ce dernier par un mécanisme de boucle de feedback, le système est toujours ajusté au niveau des composés chimiques dans l’environnement.
Ainsi, il reste sensible aux changements faibles, mêmes pour les concentrations extrêmes.
Cette régulation permet à la bactérie de ‘se souvenir’ des concentrations récentes et les comparer avec les concentrations actuelles, donc de savoir si elle se déplace dans le sens du gradient ou au contraire, dans le sens inverse du gradient.
Pourtant, le système de méthylation seul n’explique pas le spectre large de sensibilité des bactéries aux différents gradients chimiques.
Des mécanismes régulatoires supplémentaires tels que le « clustering » des récepteurs et les interactions de type récepteur-récepteur modulent également la voie de signalisation.Bien que le mécanisme de la chimiotaxie des eucaryotes soit assez différent de celui des bactéries, la perception du gradient chimique reste une étape cruciale du processus.
À cause de leur taille, les procaryotes ne sont pas capables de détecter les gradients de concentration effectifs, donc ces cellules « scannent » et évaluent leur environnement en nageant continuellement.
(La natation étant la série des étapes consécutives de natation droite et de « tumbling ».)
Les dimensions des cellules eucaryotes, en revanche, permettent la détection du gradient.
Cela résulte d'une distribution dynamique et polarisée des récepteurs.
L’induction de ces derniers par des chimioattractants ou par des chimiorepellants provoque la migration vers la substance de l’activité chimiotactique ou au contraire dans la direction opposée.Les niveaux des récepteurs, les voies de signalisation et les mécansimes effecteurs représentent tous des divers componants de type eucaryotiques.
Chez les eucaryotes unicellulaires les effecteurs majeurs sont les pseudopodes, les cils ou les flagelles de type eucaryote (par exemple l’Amoeba ou le Tetrahymena).
Quelques cellules eucaryotes d’origine mammifère à l'évolution plus complexe, telles que celles du système immunitaire, sont également capables de se déplacer au lieu nécessaire.
À part des cellules immunocompétentes (granulocyte, monocyte, lymphocyte), un groupe nombreux des cellules considérées auparavant comme fixées sur des tissus est également mobile sous certaines conditions physiologiques (mastocyte, fibroblaste, cellules endothéliales) ou pathologiques (par exemple métastases).
La chimiotaxie joue un rôle important au début de l’embryogenèse car la formation des couches du germe est guidée par les gradients des molécules de signal.Contrairement à la motilité pendant le chimiotactisme des bactéries, le mécanisme permettant le déplacement physique des cellules eucaryotes est encore peu élucidé.
Il existe probablement un mécanisme par lequel un gradient chimiotactique extracellulaire est perçu et transformé en un gradient de phosphatidylinositol 1,4,5 tris phosphate (PIP3) intracellulaire.
Cela résulte un gradient de l’activation de la voie de signalisation qui mène à la polymérisation des filaments d’actine.
L’élongation de l’extrémité (+) des filaments d’actine assure une connexion avec la surface interne de la membrane cytoplasmique via différents ensembles de peptides.
Ainsi, elle résulte la formation des pseudopodes.
Les cils des cellules eucaryotes sont également capables de provoquer la chimiotactisme, mais dans ce cas il s’agit plutôt d’une induction Ca2+ dépendant du système micro-tubulaire du corps basal et du 9×2+2 microtubules (axonème) du cils.
Le battement orchestré des milliers de cils est synchronisé par un système submembranaire formé entre les corps basaux.
Les détails de la voie de signalisation ne sont pas encore complètement éclaircis.Bien que la chimiotaxie soit la forme de migration la plus fréquemment étudiée, il existe quelques autres types de locomotion au niveau cellulaire.Dans la majorité des cas, les cellules eucaryotes perçoivent la présence des stimuli chimiotactiques via des récepteurs de 7 domaines transmembranaires (récepteurs serpentines), couplés aux protéines G qui sont des hétèrotrimères.
Ces récepteurs se regroupent dans une famille très nombreuse représentant une proportion significative du génome.
Certains membres de cette superfamille de gènes interviennent pendant la vue (rhodopsins) ou bien lors de l’olfaction.
Les classes majeures des récepteurs professionnels responsables pour la chimiotaxie sont stimulées par les peptides formylés (formyl peptide receptors (FPR)), par les chimiokines (chemokine receptors (CCR ou CXCR)) et par les leucotriènes (leukotriene receptors (BLT)).
Pourtant, l’induction d’une large gamme de récepteurs membranaires (par exemple ceux des acides aminés, de l’insuline, des peptides vasoactifs) déclenche également la migration de la cellule.Certains récepteurs chimiotactiques sont exprimés sur la surface membranaire et ont des caractéristiques à long terme car ils sont déterminés génétiquement.
Cependant, il en existe d’autres ayant une dynamique à court terme, assemblés d’une façon ad hoc en présence du ligand.
La différence des caractéristiques des récepteurs chimiotactiques et de celles des ligands permet la sélection des cellules ayant une réponse chimiotactique par un simple essai chimiotactique (« chemotaxis assay »).
Par la sélection chimiotactique il est possible de déterminer si une molécule encore non caractérisée agit via les voies de récepteur long terme ou court terme.
L'expression « sélection chimiotactique » peut aussi désigner une technique permettant de séparer les cellules eucaryotes ou procaryotes en fonction de leur capacité de répondre au ligand de sélection par la chimotaxie.Le nombre de molécules capables de déclencher une réponse chimiotactique est relativement élevé.
De plus, nous pouvons distinguer des molécules chimiotactiques primaires et secondaires.
Les groupes majeurs des ligands primaires sont les suivants :L’étude de la structure 3D des chimiokines a prouvé qu’une composition caractéristique des motifs feuillet-β et une hélice-α assure l’expression de la séquence nécessaire pour l’interaction avec le récepteur de chimiokine.
La formation d’un dimère ainsi que l’activité biologique accrue ont été démontrées par la christallographie d’un certain nombre de chimiokines (p.ex.
IL-8)Les réponses chimiotactiques déclenchées par les interactions entre les ligands et les récepteurs sont en général distinguées à la base de la concentration effective optimale du ligand.
Or, la corrélation entre l’amplitude de la réponse et la proportion des cellules répondant est également une propriété caractéristique de la signalisation chimiotactique.
Les études des différentes familles de ligands (p. ex.
Acides aminés, oligopeptides) ont prouvé l’existence d’une correspondance (« fitting of ranges ») entre les gammes (amplitudes, nombre des cellules répondant) et le chimiotactisme.
Le pouvoir chimioattractant est accompagné par des gammes larges, tandis que le caractère chimioreppellant par des gammes étroites.Le changement éventuel du potentiel migratoire des cellules a une importance relativement élevée dans le développement de certains symptômes et syndromes cliniques.
Le chimiotactisme altéré des pathogènes extracellulaires (p. ex.
Escherichia coli) et intracellulaires (p. ex.
Listeria monocytogenes) représente en soi une cible clinique significative.
La modification de la capacité chimiotactique intrinsèque de ces micro-organismes par des agents pharmaceutiques peut diminuer voire inhiber le taux des infections ou la propagation des maladies contagieuses.
En plus des infections, il existe d’autres maladies dont l’origine est une chimiotaxie restreinte (endommagée) telles que le syndrome de Chediak-Higashi, lors duquel des vésicules intracellulaires géantes inhibent la migration normale des cellules.Une large gamme de techniques est disponible pour évaluer l’activité chimiotactique des cellules ainsi que le caractère chimioattractant ou chimioreppelant des ligandes.
Les exigences de base des mesurages sont les suivantes :Malgré le fait que l’essai chimiotactique idéal ne soit toujours pas disponible, il existe pourtant certains protocoles et pièces d’équipement offrant une correspondance acceptable avec les conditions énumérées ci-dessus.
Les plus utilisés sont :p. ex.
Chambre de Boyden, chambre de Zigmond, chambre de Dunn, chambre « Multi-well » Techniques capillairesp.
Technique de « T-maze » – technique d’opalescence – essai d’orientation(Vous trouvez un chapitre plus détaillé à « Chemotaxis assay »)Pour être capables de se mouvoir, les cellules ont besoin de plusieurs composants cellulaires (tels que les moteurs cellulaires, diverses enzymes, etc.).
De plus, elles doivent être capables de changer leur forme.
Dans un sens large le mouvement cellulaire a deux types…Hapoptatique (qui signifie un mouvement en réponse des stimuli physiques ou méchaniques).
Chimiotactique (qui est un mouvement en réponse d’un gradient chimique).
Les années 1970 couvrent la période du 1er janvier 1970 au 31 décembre 1979.Les années 1970 (« seventies », en franglais) sonnent la fin de la période des « Trente Glorieuses », avec la décision des États-Unis de suspendre la convertibilité du dollar (1971), le premier choc pétrolier consécutif à la guerre du Kippour (1973) et le second choc pétrolier consécutif à la révolution iranienne (1979).
La décennie est marquée par des mouvements politiques et sociaux importants (libération sexuelle des femmes), et par la prise de conscience de la gravité des problèmes sexuels des personnes stériles et le début d'une nouvelle crise économique.
Elles marquent également le retour en force des idées libérales (les « Chicago Boys » au Chili, Margaret Thatcher au Royaume-Uni) et islamistes (Khomeiny en Iran).
Au Canada, la société québécoise est marquée par la crise d'octobre 1970 qui engendra de nombreuses réformes politiques, économiques et sociales au Japon et en Corée du Nord.
À partir du milieu de la décennie, on assiste à une certaine recrudescence de la guerre froide en raison du déclin relatif des États-Unis qui se rapprochent de la Chine, tandis que l'influence soviétique gagne du terrain en Asie et en Afrique (Indochine, Angola, Éthiopie, Afghanistan).
En Europe, la CEE passe de six à neuf membres avec l'adhésion du Royaume-Uni, de l'Irlande et du Danemark, tandis que le Portugal, la Grèce et l'Espagne s'engagent sur la voie de la dictature royale.L’Éthiopie a connu en 1973-1974 dans le Wollo une grande famine (200 000 morts).Voir également Groupe de musique des années 1970Article détaillé : Histoire du jeu vidéo dans les années 1970.Encore confidentiel au début des années 1970, le secteur du jeu vidéo décolle à la suite des succès de Pong et de l'Odyssey.
Les 350 000 consoles Odyssey vendues, chiffre relativement faible, confortent tout de même de nombreux industriels dans l'idée que le jeu vidéo domestique sera le nouvel eldorado du jeu.
En 1974, plusieurs sociétés développent des consoles se branchant à une télévision et proposent plusieurs jeux de sport, la plupart du temps des jeux de raquettes.
Ces consoles sont un assemblage de composants électroniques et ne sont bien souvent disponibles qu'en magasin spécialisé ou en vente par correspondance.Déjà précurseur sur le marché de l'arcade, avec des dizaines de jeux commercialisés, Atari fait croître rapidement le marché des consoles lorsqu'elle complète son offre avec sa console de salon Home Pong.
Au lieu de proposer plusieurs jeux, Atari n'en propose qu'un, une réplique de sa populaire borne d'arcade, de meilleure qualité que les autres jeux de l'année 1974.
Le nombre de consoles différentes sorties monte jusqu'à plus de 744 références en 1977, avant de connaître un ralentissement avec la démocratisation des microprocesseurs, qui permet l'ajout de nouveaux jeux aux consoles existantes et ainsi des cycles de commercialisation plus longs.La mode voit de profonds changements par rapport à la décennie passée.
Alors que jusque-là Londres insufflait les tendances dans les années 1960, les États-Unis deviennent le centre de la mode.
Globalement, deux courants dominent le monde occidental : les vêtements fantaisie représentant une mode permissive, et les tenues faciles à porter, dans la lignée du prêt-à-porter.
Les vêtements unisexes se répandent avec, en premier lieu, le jeans.
Plusieurs styles marqués et anti-conformistes vont se succéder sur quelques années, tels ceux issus du mouvement hippie, du punk, du glam-rock ou du disco.
Des créateurs de mode sont au premier plan comme le français Yves Saint Laurent ou l'américain Halston.Les années 1970 marquent un tournant dans la prise de conscience en faveur de la protection de l'environnement aux États-Unis.
Dès 1970, l’Agence de protection de l'environnement des États-Unis est fondée et le jour de la Terre est institué.
En 1971, une publicité de la compagnie Keep America Beautiful Inc. expose sur d'immenses affiches le visage d'un Amérindien qui pleure, accompagné du slogan : Pollution : it's a crying shame (La pollution : c'est honteux à pleurer)..
En 1972, une équipe du Massachusetts Institute of Technology dirigée par Dennis H. Meadows remet au Club de Rome un rapport alarmant intitulé The Limits to Growth (titre en français : Les Limites à la croissance ou  « rapport Meadows »).
Ce rapport évoque la croissance zéro comme remède à l'épuisement des ressources naturelles.
En 1971, dans le contexte de Guerre du Viêt Nam, l'association Greenpeace est fondée, et dénonce les essais nucléaires, la guerre, la chasse aux baleines et aux phoques.
En 1979, Greenpeace devient une organisation internationale.En 2016, une étude du WWF (Fonds mondial pour la nature) indique que plus de la moitié des vertébrés ont disparu en 40 ans, de 1970 à 2012.
Les milieux d’eau douce sont les plus affectés, avec un effondrement de 81 % sur la période, devant les espèces terrestres (− 38 %) et celles marines (− 36 %).
Cette tendance est importante durant toute la décennie, en raison des pressions sur les habitats naturels (artificialisation, déforestation, pollution, réchauffement climatique, catastrophes naturelles), et des excès de prélèvements au milieu (braconnage, chasse, pêche).Pong   (référence)
L'École royale polytechnique (en suédois : Kungliga Tekniska högskolan, ou KTH) est une école d'ingénieurs de Stockholm en Suède.
Elle a été fondée en 1827 et est la plus grande université scandinave de technologie.L'histoire de KTH débute en 1827, quand le Teknologiska Institutet (institut de technologie) commence à donner des cours dans des domaines technologiques avec une forte approche pratique, dans le but d'accompagner la demande croissante en ingénieurs consécutive au processus d'industrialisation entamé en Suède.
L'école arrive toutefois à concilier les approches théorique et pratique.En 1877, l'école prend le nom de « Kungliga Tekniska högskolan », reconnaissant ainsi son attachement à la recherche.
Elle ne cessera alors d'étendre ses domaines de compétences.
En 1867 elle comprend quatre branches : mécanique, chimie, génie civil et exploitation minière.
Viendront ensuite l'architecture (1877), le génie électrique (1901), l'architecture navale (1912), l'arpentage et la physique (1932), l'informatique (1983) et l'économie industrielle (1990).En 1917, l'école déménage pour s'installer au nord du centre-ville de Stockholm dans un nouveau campus dessiné par l'architecte Erik Lallerstedt (de).Dans les années 1950 sont installés sur le campus les premiers réacteur nucléaire et émetteur de télévision suédois.
KTH offre maintenant dans ses enseignements une grande place aux technologies d'avenir, comme les biotechnologies et les télécommunications.L'école s'étend aujourd'hui sur cinq campus répartis dans Stockholm et ses environs, sur une surface totale de plus de 250 000 m2.
L'immunothérapie consiste à administrer des substances stimulant les défenses immunitaires du malade contre des infections, certains cancers hématologiques (autrement dit, du sang), des maladies dégénératives ou auto-immunes.
Ceci inclut les thérapies utilisant des protéines (anticorps) produites par les cellules du système immunitaire, en particulier les immunoglobulines, sans que l'objectif de cette thérapie ne soit nécessairement la stimulation de l'immunité.
On distingue l'immunothérapie locale (rare) et l'immunothérapie générale (beaucoup plus fréquente).Des ancêtres de l'immunothérapie contemporaine sont la « thérapie sérique » et l'immunothérapie allergénique mise au point par Leonard Noon et John Freeman en 1911.
Les essais modernes d'immunothérapie remontent aux années 1970, basés sur des anticorps polyclonaux.
Depuis, d'autres molécules sont arrivées sur le devant de la scène, telles les immunoglobulines monoclonales, et moindrement les interférons, les interleukines et les inhibiteurs de point de contrôle.Des ancêtres de l'immunothérapie contemporaine sont la thérapie sérique et l'immunothérapie allergénique mise au point par Leonard Noon et John Freeman en 1911.Avant la découverte des antibiotiques, l'administration passive d'anticorps s'est montrée pertinente pour traiter de nombreuses maladies infectieuses, bien avant les anticorps monoclonaux et l'utilisation récente des "biomédicaments".
Les thérapies sériques étaient déjà basées sur le transfert artificiel d'une immunité humorale d'un organisme à un autre (éventuellement d'une espèce animale à l'homme) ; on parle aussi de transfert artificiel d'immunité passive ou de TIP artificiel (TIP signifiant ici « transfert d'immunité passive »).
Parfois très efficace, il a néanmoins posé de graves problèmes (dits « maladie sérique ») mais reste encore utilisé de nos jours pour quelques cas où les alternatives n'existent pas.Puis, à partir des années 1940, la généralisation des antibiotiques et d'autres chimiothérapies antimicrobiennes a abouti à la suppression de la plupart des types de thérapies passives par anticorps (elles étaient plus dangereuse en termes d'effets secondaires difficiles à prévoir).
Dans les années 1990, la chimiothérapie antimicrobienne a perdu beaucoup de son efficacité en raison du développement de l'antibiorésistance et de maladies nosocomiales d'une part, et de la forte augmentation du nombre de patients immunodéprimés d'autre part (du fait de maladies telles que le VIH/SIDA, du nombre croissant de greffés et éventuellement de facteurs environnementaux tels que la pollution ou l'alimentation qui pourraient affecter les forces immunitaires).
Au début du XXe siècle, le nombre de maladies émergentes ou ré-émergentes a augmenté.
Une alternative aux antibiotiques a été de développer des anticorps monoclonaux et de générer des thérapies à base d'anticorps humains puis de développer des dizaines de biomédicaments (souvent des anticorps produits par les moyens du génie génétique, via un animal, une plante, un champignon ou une bactérie transgénique biotechnologiquement modifiés afin de produire des protéines complexes et de grande taille que l'industrie chimique ou pharmaceutique classique serait incapable de produire par chimie de synthèse).
Au XXIe siècle, alors que l'antibiorésistance continue à se développer et que le risque pandémique augmente, les anticorps et les thérapies sériques ont à nouveau suscité un certain intérêt.
Théoriquement, à chaque microbe pathogène correspond un anticorps qui freinera ou bloquera l'infection au profit de l'hôte.
Le génie génétique permet aujourd'hui de reproduire avec plus ou moins de fidélité ces anticorps.
Comparées à la chimiothérapie standard, les thérapies à base d'anticorps ont des avantages et des inconvénients importants.En 2020 l'usage à grande échelle de l'immunothérapie aux États-Unis est envisagée dans le cadre de la pandémie de maladie à coronavirus de 2019-2020.
Des essais cliniques ont été lancés en France, aux Etats-Unis et en Asie ,.Les thérapies sériques puis plus généralement l'immunothérapie peuvent : À noter que l'immunoscintigraphie est une application diagnostique reposant aussi sur l'utilisation d'anticorps comme sonde spécifique mais marqués par fluorescence ou radioactivité faible et visualisés in vivo par imagerie.
En immunothérapie, on utilise des anticorps modifiés pour être, seulement mais de façon plus critique, « humanisés » afin d'éviter les réactions de défense immunitaire parce que les quantités employées sont justement plus fortes.Après des décennies de déceptions dans le traitement du cancer, l'immunothérapie a atteint une maturité ayant permis un changement de paradigme dans le traitement de nombreux types de tumeurs et de cancers.
Avec une compréhension accrue du système immunitaire, la guérison est devenue une possibilité réelle pour de nombreux patients.L'immunothérapie désigne une gamme de traitements destinés à stimuler l'immunité chez un patient.
Ces traitements comprennent des vaccins, des inhibiteurs du contrôle immunitaire, des lymphocytes T avec des récepteurs de l'antigène chimérique (CAR), des immunothérapies à base de virus oncolytique.Utilisée dans le cas du cancer de la vessie pour limiter les récidives à la suite de l'ablation chirurgicale du cancer.
Le principe consiste à stimuler l'immunité locale par des irrigations locales de la vessie à l'aide d'une solution contenant du BCG.L'immunothérapie générale consiste à injecter par voie générale des immunoglobulines, des cytokines ou des interférons recombinants, produits par génie génétique.
Les interférons alpha et gamma, l'interleukine 2 sont les cytokines les plus souvent utilisées actuellement.
L'interleukine 2 est indiquée dans le traitement du cancer du rein métastatique et dans le mélanome métastatique ainsi qu'en traitement adjuvant des mélanomes de mauvais pronostic.L'utilisation d'anticorps monoclonaux vise à empêcher la prolifération cellulaire en bloquant l'activité de certains récepteurs codés par des oncogènes.
Des anticorps monoclonaux sont utilisés dans le traitement de certains cancers.Le rituximab est indiqué pour le traitement de patients atteints de lymphomes folliculaires de stade III-IV en cas de chimiorésistance ou à partir de la deuxième rechute après chimiothérapie.
Cet anticorps monoclonal se lie spécifiquement à l'antigène transmembranaire CD20, une protéine située sur les lymphocytes B et s'exprimant dans plus de 95 % des cellules B des lymphomes non hodgkiniens.Le trastuzumab est administré aux patients ayant un cancer du sein résistant au traitement habituel en raison de la surabondance d'un récepteur spécifique dans leurs cellules, appelé HER2.
La présence de ce récepteur en surnombre entraîne la production en excès d'une protéine qui à son tour induit une multiplication incontrôlée des cellules.En 2016, l'immunothérapie commence également à être utilisée dans le cadre du cancer du poumon métastatique parce qu'elle semble donner, avec le pembrolizumab, de meilleurs résultats que la chimiothérapie dans les stades avancés.Un grand nombre de patients (environ la moitié) ne réagissent pas à un traitement par immunothérapie.
Cela est dû entre autres à une réaction d'auto-défense des cellules tumorales et à l'action de cellules venant inhiber les cellules T intervenant dans le processus d'immunothérapie, en particulier celle de cellules myéloïdes infiltrantes tumorales (TIM).Dans un contexte hyper-hygiéniste, des personnes ont été non-exposées ou sous-exposées à des parasites intestinaux ayant co-évolué avec l'Homme.
Il a été montré qu'elles avaient — pour des raisons incomplètement comprises —, statistiquement plus de risques de développer des maladies auto-immunes, intestinales comme la maladie de Crohn, mais pas uniquement (sclérose en plaques, allergies également).Une immunothérapie basée sur l'ingestion d'œufs de trichocéphale (Trichuris suis) et l'ankylostome (Necator americanus) a été testée avec succès pour des maladies immunologiques mais aussi contre les allergies.
Cette thérapie helminthique a été étudiée contre la maladie de Crohn,,, contre la sclérose en plaques diverses allergies et l'asthme.Les helminthes, par des mécanismes encore mal compris, modulent ou régulent les cytokines Th1 pro-inflammatoires, l'interleukine-12 (IL-12), l'interféron-gamma (IFN-γ) et le facteur de nécrose tumorale-Alpha (TNF-ά), tout en favorisant la production de cytokines Th2 régulatrices telles que IL-10, IL-4, IL-5 et IL-13,.Selon le modèle murin, les mères infectées par des schistosomes transfèrent une protection contre l'inflammation allergique des voies respiratoires à leur progéniture mais uniquement si l'accouplement s'est produit lors des phases TH1 et régulatrices de la parasitose (pas dans la phase immunitaire TH2) ; on a relié ces effets à des profils d'expression des cytokines et des gènes spécifiques aux schistosomes, profils significativement modifiés dans l'interface fœto-maternelle.
Le transfert d'antigènes d'helminthes n'est pas responsable de ce bénéfice ; ce serait l'IFN-γ d'origine maternelle produit en phase aiguë d'infestation qui est essentiel pour le phénotype protégeant immunitairement la descendance.Remarque : on sait qu'inversement chez la souris, un souriceau né d'une mère allergique à un produit risque plus de l'être aussi.On suppose que notre co-évolution avec certains helminthes a façonné des interactions durables, peut-être traduites dans les gènes associés à l'expression de l'interleukine et impliqués dans les troubles immunologiques, tels que la maladie de Crohn, la colite ulcéreuse et la maladie cœliaque.
Sur ces bases, les helminthes pourraient peut-être devoir être reclassés comme hôte naturel de notre microbiote intestinal, hôtes mutualistes voire symbiotes de l'être humain, et être inclus dans l'« hypothèse d'hygiène étendue » comme l'a proposé une équipe scientifique en 2014.L'immunothérapie est également utilisée dans de nombreuses autres conditions pathologiques comme les maladies inflammatoires et neurodégénératives.
Les anticorps ciblent par exemple la cytokine TNF-alpha dans la polyarthrite rhumatoïde ou la protéine tau dans les tauopathies.Depuis 2012 environ, les immunothérapies, en dépit d'effets secondaires graves (mais comme il en existe pour la chimiothérapie), ont révolutionné le traitement de certains cancers tenaces ; cependant, selon deux études récentes,, chez un petit nombre de patients atteints d'un cancer avancé, certains médicaments de l'immunothérapie qui visaient à traiter ce cancer (inhibiteurs de la PD-1,) peuvent au contraire accélérer très fortement (en une à deux semaines parfois) sa progression, pour des raisons encore mal comprises.
Les auteurs appellent à une étude plus large et pluridisciplinaire de ce phénomène pour en comprendre les causes.
Les patients concernés par ce problème semblent porter une altération génétique rare (copies supplémentaires des gènes de lutte contre le cancer MDM2 ou MDM4).
Un même phénomène est observé chez certaines souris de laboratoire « dont les tumeurs progressent rapidement après un traitement avec une immunothérapie ».
Des chercheurs de l'Institut Gustave Roussy de Villejuif (France) ont lancé une étude systématique de la croissance tumorale chez leurs patients et conclu en novembre 2016 que sur 131 personnes ayant reçu des thérapies anti-PD-1, 9 % ont été victimes d'une « hyperprogression » de leur tumeur (plus souvent chez des plus de 65 ans).
Le 28 mars 2017, Kurzrock et ses collègues confirment le phénomène : chez 155 personnes traitées avec des inhibiteurs de la PD-1 et d'autres immunothérapie, six patients présentaient des copies supplémentaires de MDM2 ou MDM4 et 10 présentaient des mutations du gène EGFR (associé au cancer).
Il ne semblait pas dans ce cas y avoir de corrélation entre l'âge et une aggravation rapide de la maladie mais, chez quatre des patients ayant des gènes MDM2 ou MDM4 supplémentaires et chez deux des personnes atteintes de mutations EGFR, les tumeurs ont rapidement grossi lors du traitement.
Une hypothèse est que chez ces patients uniquement, le traitement libérerait des « facteurs de croissance » de tumeurs, pour des raisons qui restent alors à comprendre.Les médicaments d'immunothérapies augmentent (plus ou moins selon le type de molécule mais de manière statistiquement significative) certaines comorbidités, notamment dans le cas de la polyarthrite rhumatoïde ; ils accroissent le risque de dépression (laquelle peut aggraver la douleur générale, de mauvais pronostic, le refus du traitement et une dégradation plus rapide de la qualité de vie du patient) ; ils peuvent également accroître le risque d'anxiété voire d'idées suicidaires et ce, plus fortement voire de manière « alarmante » pour certains médicaments (ex : méthotrexate, léflunomide, hydroxychloroquine et des médicaments dits biologiques (biotechnologiques) dans la littérature médicale anglophone ou médicaments antirhumatismaux modificateurs de la maladie DMARDs (pour Disease-modifying antirheumatic drug).
Le léflunomide provoquerait le moins de troubles de santé mentale selon une étude de 2013.
Dans une étude de 2013 basée sur 105 patients traités pour maladies rhumatismales, ceux qui prenaient des antirhumatismaux « modificateurs de la maladie » présentaient les taux les plus élevés de dépression, d'anxiété et d'idées suicidaires parmi tous les patients étudiés.L'immunothérapie antimicrobienne, qui comprend la vaccination, implique l'activation du système immunitaire pour répondre à un agent infectieux.La suppression immunitaire vise à tempérer voire supprimer une réponse immunitaire anormale par exemple dans le cadre des maladies auto-immunes ou à réduire une réponse immunitaire normale pour empêcher le rejet d'organes ou de cellules transplantés.L'immunothérapie allergénique (ITA), ou hyposensibilisation, est le seul traitement qui permette de traiter les allergies respiratoires — allergies aux pollens, aux acariens, aux poils de chat, etc. — en s’attaquant à la cause même de la maladie.
En effet, l'ITA permet d'altérer le cours naturel de la maladie allergique et entraîne ainsi des rémissions de longue durée.
Enfin, il est possible que l'ITA évite l'apparition de nouvelles sensibilisations, voire d'un asthme.Le traitement se fait en augmentant graduellement les doses d'allergène (mithridatisation) pour permettre au système immunitaire de construire les anticorps correspondants (sous-classe IgG4).
La dose de départ est souvent d'un facteur 1:10 000.Selon l’Académie nationale de médecine, la désensibilisation précoce des patients allergiques permet de modifier l’histoire naturelle de la maladie en limitant l’acquisition de nouvelles sensibilisations ou en réduisant chez les enfants atteints de rhinite allergique le risque de développement ultérieur d’un asthme.
Deux formes d’administration du traitement existent : la voie injectable, la plus ancienne, sous-cutanée, faite en cabinet par un médecin toutes les 4 à 6 semaines ; et la voie sublinguale où l’on dispose, soi-même à domicile, quotidiennement, des gouttes sous la langue à jeun, selon la prescription de son allergologue.
Plus pratique et présentant un excellent rapport bénéfice/risque, la désensibilisation sublinguale est la voie majoritairement utilisée aujourd'hui, bien qu'ayant une efficacité inférieure à la voie sous-cutanée et un coût supérieur.
Depuis une quinzaine d’années, la voie sublinguale a connu un développement rapide, par la mise à disposition de traitements basés sur des extraits allergéniques administrés sous forme de gouttes et l'arrivée des premiers comprimés de désensibilisation au pollen de graminées avec AMM (autorisation de mise sur le marché).
La désensibilisation est aujourd'hui parfaitement reconnue et codifiée par un consensus international (ARIA ou « Allergic Rhinitis and its Impact on Asthma ») sous l'égide de l'OMS.
Ce consensus recommande, avec un niveau de preuve élevé, l'utilisation de la voie sublinguale, chez les patients atteints de rhinite allergique pour qui la désensibilisation est indiquée.
Découverte par Leonard Noon et John Freeman en 1911, l'immunothérapie allergénique représente le seul traitement étiologique des allergies respiratoires.
Il est le seul médicament connu pour traiter non seulement les symptômes mais aussi les causes de l’allergie respiratoire.
La reproductibilité d'une expérience scientifique est une des conditions qui permettent d'inclure les observations réalisées durant cette expérience dans le processus d'amélioration perpétuelle des connaissances scientifiques.Cette condition part du principe qu'on ne peut tirer de conclusions que d'un événement bien décrit, qui est apparu plusieurs fois, provoqué par des personnes différentes.Cette condition permet de s'affranchir d'effets aléatoires venant fausser les résultats ainsi que des erreurs de jugement ou des manipulations de la part des scientifiques.Le critère de reproductibilité est une des conditions sur lesquelles le philosophe Karl Popper distingue le caractère scientifique d'une étude.Pour toutes les sciences expérimentales, les probabilités fournissent un modèle mathématique décrivant la variabilité des résultats.Depuis les années 2000, les sciences traversent une crise de la reproductibilité.Un phénomène est observé.
Il est alors répertorié et classé dans une catégorie d'observable.La liste peut être longue de phénomènes prétendument « observés » qui ne se sont pas reproduits : on parle alors d'« apparitions ».
Mais la liste des phénomènes observés et de façon reproductible est infiniment plus longue et constitue la base des sciences.La science s'intéresse surtout aux phénomènes qui se reproduisent et l'idéal est de pouvoir à volonté les reproduire.
Un phénomène que l'on peut reproduire à volonté devient un phénomène « reproductible » au sens scientifique.Même si certains phénomènes (par exemple l'activité solaire) ne sont pas contrôlables, donc non reproductibles, leur suivi permet d'en tirer des règles d'évolution dans le temps.
La périodicité ou une évolution dans le temps est un phénomène reproductible au sens où on peut prévoir l'évolution dans le temps, il est prévisible au sens de l'évolution temporelle.La science fonctionne en tirant d'observations reproductibles des « lois » ou « principes » qui ont comme principale propriété d'être vrais tant qu'aucune observation n'a prouvé le contraire.
La reproductibilité d'une mesure est essentielle pour valider scientifiquement une expérience.
En effet, une mesure scientifique convenable doit rester la même lorsque l'expérience est menée par d'autres scientifiques, dans les mêmes conditions.
Une expérience répétée qui ne donne pas les mêmes résultats sera considéré n'ayant aucune valeur scientifique.
Par contre, il est important de comprendre qu'une expérience répétée plusieurs fois et qui donne toujours les mêmes résultats ne doit pas être considérée comme fiable à 100 %, puisque les conditions restent les mêmes, les erreurs restent les mêmes aussi.
Ainsi, la reproductibilité d'une mesure ne peut garantir la justesse ou l'exactitude de cette mesure, mais elle confirme que l'expérience a été faite dans les mêmes conditions et que les démarches de mesures sont strictes.Pour mettre un produit sur le marché européen, les industriels présentent leurs propres études à l'Autorité européenne de sécurité des aliments qui les examine et les garde secrètes.
Le fait que ces études ne soient pas rendues publiques empêche les chercheurs académiques (et toute autre personne) de contrôler les protocoles et les résultats afin de vérifier qu'ils soient valides et complets.
Selon la journaliste Stéphane Horel, cela rend « impossible de respecter le principe scientifique fondamental de la reproductibilité ».Le terme de reproductibilité prend en métrologie un sens analogue à celui utilisé en recherche scientifique, et qualifie la compatibilité de mesurages pouvant être réalisés en des lieux, par des opérateurs et en utilisant des systèmes de mesure (procédures, méthodes) différents.
Elle diffère en cela de la répétabilité, qui évalue la compatibilité de mesurages réalisés avec les mêmes personnes, le même système de mesure, en mêmes conditions, et dans un temps relativement court.
Le plasma sanguin est le composant liquide du sang, dans lequel les cellules sanguines sont en suspension.
Il constitue 55 % du volume total du sang.Il sert à transporter les cellules sanguines et les hormones à travers le corps.
Généralement, on retrouve environ 2 750 à 3 300 ml de plasma dans le corps d'un adulte.L'extraction du plasma sanguin est effectuée par simple centrifugation ; le liquide jaunâtre que l'on observe après cette opération est le plasma sanguin.La première utilisation du plasma sanguin a été faite pendant la Seconde Guerre mondiale.
Le programme du Blood for Britain supervisé par le docteur Charles R. Drew a été un succès dès les années 1940 et s'est poursuivi par une collecte dans les hôpitaux de New York pour exporter le plasma vers l'Angleterre.
Le docteur Drew a transformé des expérimentations, notamment sur lui-même, en des techniques de production de masse du « plasma sec » qui ont équipé l'armée américaine.À la suite de cette invention, le docteur Drew fut nommé directeur de la Croix-Rouge ; il s'opposa à la directive des forces armées américaines qui séparait le sang/plasma en fonction de la race du donneur en argumentant qu'il n'existait pas de différence raciale mais uniquement des groupes sanguins.Composé à 91 % d'eau, le plasma sanguin contient une grande variété de solutés.
Parmi ces solutés, on trouve :Les éléments figurés du sang (hématies, leucocytes et plaquettes) sont à distinguer du plasma.Le plasma contiendrait 300 protéines.Les protéines les plus représentées en proportion sont les suivantes :Cependant même des protéines faiblement représentées en quantité peuvent avoir des fonctions essentielles pour l'organisme, comme celui de la coagulation ou de l'immunité.
Un stimulus dans le domaine de la psychologie expérimentale, de la physiologie et de la biologie, est un événement de nature à déterminer une excitation détectable par une réaction chez un organisme vivant.La psychophysique explore la relation entre les grandeurs physiques mesurables et les perceptions humaines, à travers la réaction de sujets obéissant à une consigne dans des conditions contrôlées.
Les expériences répétées un nombre suffisant de fois et avec un nombre suffisant de sujets dégagent des règles de perception valables statistiquement pour l'ensemble de la population.Le béhaviorisme définit le conditionnement comme le mécanisme fondamental de l'apprentissage par lequel un stimulus (dit conditionné) devient associé à un autre stimulus (non conditionné) à la suite d'associations répétées entre la présentation de l'un puis de l'autre stimulus.
Cet apprentissage s'observe par le fait que le sujet réagit au stimulus conditionné par une réponse comportementale normalement associée au stimulus non conditionné, c'est le « schéma stimulus-réponse ».On distingue les stimulus par le sens qui les détecte :On étudie aussi la réaction à un événement exigeant une adaptation musculaire, avec les accélérations et la sensation de pesanteur.Les chocs électriques constituent des stimulus entièrement artificiels.
Le temps intervient comme paramètre pour tous les stimulus, et est parfois aussi l'objet de la recherche.Les études psychophysiques cherchent à quantifier et à définir les seuils de perception de stimulus élémentaires, qui évitent autant que possible l'association à une signification.Outre les stimulus élémentaires les recherches psychologiques peuvent désigner comme stimulus des événements complexes, comme des mots ou des images, qui évoquent des connaissances ou des sentiments.Un stimulus subliminal ou préconscient est un évènement capable de provoquer une réponse, mais que la personne auquel il est soumis n'identifie pas en tant qu'évènement.En physiologie, le stimulus peut être externe (ceux étudiés par la psychologie expérimentale) ou interne.
Il s'agit alors de l'élévation du taux d'une substance dans l'organe ou dans l'organisme.En pharmacologie, on étudie l'effet de substances actives sur les perceptions des stimulus.
C'est notamment le cas des études sur la douleur.
Le mot « rat » est un nom vernaculaire ambigu qui peut désigner, en français, des centaines d'espèces différentes dans le monde de mammifères rongeurs omnivores, dont la queue est nue, les dents tranchantes et le museau pointu.
Les rats sont le plus souvent de la famille des Muridés ou, de façon plus restrictive, du genre Rattus, lequel regroupe les espèces les plus communes : Rattus rattus, le rat noir, et Rattus norvegicus, le rat d'égout, qui a donné le rat domestique en élevage.
Néanmoins, par analogie, le terme désigne aussi quelques espèces de rongeurs qui ne font pas partie de la famille des Muridés, comme le Rat palmiste, le Rat-chinchilla, etc.L'homme étudie ces rongeurs, les utilise à son profit, les apprivoise ou bien, au contraire, les considère comme des nuisibles et cherche à les exterminer.
Les rats font ainsi partie intégrante de la symbolique, de la culture et de l’histoire humaine, et de nombreuses œuvres y font référence.L'étymologie du mot « rat » est incertaine.
Sa racine semble commune aux langues romanes (rata en espagnol, ratto en italien, ratazana en portugais) et aux langues germaniques (Ratte en allemand, rat en anglais et néerlandais).
Le mot date de la fin du XIIe siècle.
Auparavant, rats et souris sont désignés indistinctement sous le terme de mus.
Mais les origines en restent obscures ; il viendrait d'une onomatopée, née du bruit du rat qui grignote, ronge ou gratte.
Il pourrait venir de l’allemand ratt, ou encore du celte ract ou raz,.
La femelle du rat est appelée une rate, et son petit un raton.
Une ratière désigne un piège à rats et une raterie désigne un élevage de rats domestiques.Le langage courant confond longtemps rat et souris comme l'atteste par exemple la fable de La Fontaine intitulée Le Chat et un vieux rat, où l'auteur les regroupe finalement dans l'expression globale « la gent trote-menu » après avoir employé indifféremment l'un et l'autre termes.Le mot « rat » remonterait à 1170 en tant que « nom usuel de nombreux mammifères rongeurs ».En 1606, dans le Thresor de la langue françoyse tant ancienne que moderne, Jean Nicot  associe le rat à Mus mais avant que ce genre ne soit fixé par Linné en 1758.Dans la seconde moitié du XVIIIe siècle, L'Encyclopédie de Diderot et d’Alembert définit le « rat » comme étant de l'espèce Mus domesticus, ce qui en fait un synonyme de l'actuelle souris domestique, mais décrit un animal de 14 pouces (35,56 cm), queue comprise, capable de tenir tête à un chat et nomme la souris Mus minor.Dans sa 1re édition (1694) et les suivantes, le Dictionnaire de l'Académie française donne du « rat » une définition assez vague, précisant simplement que c'est un « animal à qui les chats donnent la chasse » et le décrivant physiquement comme « petit... au museau pointu... pieds courts... queue longue » et mentionne la différence entre « gros rat » et « petit rat ».
Il décrit aussi ses mœurs : « qui ronge & mange les grains, la paille, les meubles, les tapisseries ».
L'Académie précise seulement à partir de la 6e édition (1832-5) qu'il s'agit d'un « petit quadrupède de l'ordre des Rongeurs ».
Définition que reprendra presque mot pour mot Émile Littré au XIXe siècle dans son Dictionnaire de la Langue Française.Dès l'époque classique apparaissent pourtant des différenciations entre les divers « rats » : en 1606 Nicot cite le « rat d'eau », en 1668 La Fontaine distingue le « rat de ville » du « rat des champs » et en 1725 l'Académie des sciences parle du « rat musqué ».
Diderot et d'Alembert, quant à eux, en plus du « rat » (la souris commune), décrivent le Rat d'Amérique (mus americanus, syn.
de l'actuel rat brun), le rat des champs (mus agrestis minor, sans doute un campagnol du genre Microtus), le rat d'eau (mus aquaticus, sans doute un campagnol aquatique du genre Arvicola), le rat musqué et le rat musqué d'Amérique, le rat de Norvège (mus caudâ abruptâ, corpore fulvo, nigro, maculato), le rat oriental (mus orientalis), le rat blanc de Virginie, (mus agrestis virginianus albus) ainsi que d'autres espèces.Au début du XIXe siècle, le terme « rat », employé seul, est encore associé au genre Mus, qui comportait à l'époque de nombreux rongeurs à présent classés ailleurs, mais il désigne surtout Mus rattus, ancien synonyme du Rat noir (Rattus rattus).Au XXe siècle, le dictionnaire français Larousse définit toujours le terme « rat » de façon scientifiquement vague comme désignant « divers rongeurs Muridés et Cricétidés » mais précise qu'il s'applique plus particulièrement aux espèces du genre Rattus; tandis que le Trésor de la langue française informatisé (TLFi) en donne une définition un peu plus complète qui réduit la classification (« Mammifère rongeur de la famille des Muridés ») tout en indiquant que cela représente tout de même « des centaines d'espèces dans le monde » ayant les caractéristiques physiques suivantes : « longue queue écailleuse, museau pointu, deux incisives tranchantes à chaque mâchoire », des mœurs communes : « omnivore, prolifique, vorace, commensal de l'homme » et qui sont des espèces « porteuses de bactéries et de virus ».Dans les ouvrages modernes, le mot « rat » désigne le plus souvent le rat noir (Rattus rattus) et le rat brun (Rattus norvegicus).
Cette dernière espèce est également appelée surmulot et rat d'égout.
Le rat domestique est issu de l'élevage du rat brun.
Cette souche de rat brun est depuis longtemps maintenue en captivité où elle est d'abord devenue un animal de laboratoire puis un animal de compagnie, faisant partie de ce que l'on appelle les nouveaux animaux de compagnie (NAC).Le nom de « rats » peut également désigner de manière générale en zoologie le genre Rattus.
La plupart des espèces de ce genre portent en français le nom de « rat », suivi d’un qualificatif.
Par exemple le rat polynésien (Rattus exulans) qui est la troisième espèce de rat la plus répandue au monde après le rat brun et le rat noir.Néanmoins de manière assez courante, on appelle aussi « rats » d’autres rongeurs de la sous-famille des Murinae ou de la famille des Muridae qui n’appartiennent cependant pas au genre Rattus.
Bien que plus rarement, on appelle même « rats » des animaux qui ne sont même pas de la famille des Muridés, à commencer par certains Cricetidae dont la classification fait encore débat et qui ont longtemps été classés parmi les Muridés.Parmi les Rodentia :Les caractéristiques générales des rats sont celles des rongeurs, avec des nuances pour chaque espèce (voir les articles détaillés pour plus d'informations sur leur comportement ou leur physiologie respective).Le « rat » désigne donc un rongeur de dimensions variées, pouvant aller du minuscule rat des moissons (Micromys minutus) au rat de Gambie (Cricetomys gambianus ), un géant en comparaison.
Les caractéristiques physiques sont très diverses parmi les animaux appartenant à l'ordre des Rodentia mais ce nom vernaculaire est surtout employé pour désigner des rongeurs dotés d'oreilles rondes et d'une queue relativement longue, généralement annelée.
Il s'agit le plus souvent d'un rongeur plus gros que la souris, bien que ce critère ne soit pas déterminant, puisque le rat des moissons (Micromys minutus) est également appelé souris naine.Le tableau triable suivant présente une synthèse non exhaustive des noms vulgaires ou des noms vernaculaires attestés en français et des noms scientifiques correspondants.
Il faut noter que certaines espèces ont plusieurs noms possibles.
En gras, les espèces les plus connues des francophones.
Les classifications évoluant encore, certains noms scientifiques peuvent avoir un autre synonyme valide :Qu’il s’agisse de l’une ou l’autre des espèces, les rats sont pour les hommes des propagateurs de maladies, notamment parmi les plus graves.
Le rat intervient soit comme réservoir du microbe (bactérie ou virus ou parasite) qu'il héberge sans le transformer, soit comme hôte intermédiaire dans le cycle du parasite (qui va se transformer dans l'organisme du rat et y devenir infectieux pour l'homme).
Il est alors infectieux soit par sa morsure, soit par ses déjections, ou par son sang prélevé et transmis à l'homme via un vecteur (insecte, tique).
La maladie à laquelle on associe le plus le rat est, sans doute, la peste, qui est principalement propagée par le rat et transmise à l’homme par piqûres de puces d’animaux infectés.
Plus facilement véhiculée par le rat noir, elle s’est répandue dans le monde en de terribles épidémies au cours de l’Histoire, on pense surtout au très connu épisode de peste noire du milieu du XIVe siècle.
Néanmoins, la leptospirose, maladie bactérienne qui est parfois appelée la maladie du rat, est propagée par l'urine infectée du rat ou de la souris et semble presque toujours la source directe ou indirecte des infections humaines.
D'autres maladies peuvent également être transmises par le rat comme la fièvre par morsure de rat (streptobacillose) (ou fièvre de Haverhill), le Sodoku qui en est une variante.
Le rat est aussi le réservoir, unique ou non, de la méningite à éosinophiles, de la fièvre hémorragique d'Argentine, de la fièvre hémorragique vénézuélienne, de la douve de Chine, de la fièvre hémorragique coréenne, du typhus murin, et il est l'hôte intermédiaire de l'échinococcose alvéolaireMais en plus de ce point de vue sanitaire, les rats sont des opportunistes et ils s’attaquent aux réserves alimentaires qu’ils dévorent et souillent de leurs déjections.
Ils mettent en péril les récoltes dans certains pays tropicaux et peuvent causer des déséquilibres écologiques,.
Pour un grain dévoré par le rat brun, 10 à 15 grains sont souillés et rendus inconsommables.De même, du fait de l'introduction du rat brun, du rat noir et du rat polynésien, dans 82 % des archipels mondiaux et au vu de leur caractère invasif, ils occasionnent de nombreux bouleversements dans les écosystèmes insulaires et contribuent également à l'éradication de certaines espèces animales,,.
Ces trois espèces de rats (Rattus exulans, Rattus norvegicus et surtout Rattus rattus) sont reconnues comme invasives, elles font partie des 100 espèces les plus invasives d’après l’UICN.
Ils peuvent devenir une menace pour l’équilibre écologique et les espèces locales, surtout lorsqu’ils colonisent une île.Pour éviter tous les problèmes apportés par les rats à l'état sauvage, des campagnes de dératisation sont organisées par les autorités dans de nombreux pays.
Elles visent à réduire les populations de rats et ainsi à diminuer le risque sanitaire.
En France, en 2021, 7% de la population a du faire face à une infestation de rat à son domicile.
Ce chiffre a été multiplié par deux depuis 2016, en raison notamment de l'interdiction de l'appâtage permanent depuis 2019.Depuis longtemps, l'homme essaye d'empêcher le rat de proliférer.
Au fil du temps différentes méthodes ont été déployées.
Dans les habitations, le chat ou certains chiens sont utilisés depuis toujours pour empêcher la prolifération de ces rongeurs.
Dans l’Égypte ancienne, on se sert déjà des chats pour combattre les rats.
Les Vénitiens ramenèrent d’Égypte et de Syrie des galères pleines de chats ratiers afin d’éradiquer les rats dans la lagune et par là même de combattre la peste.Vers 1727, avec l’invasion massive du rat gris (surmulot ou rat d'égout), les chiens ratiers, comme le Affenpinscher, prennent la place des chats en Europe.
Alors qu'au Moyen Âge, les massacres de chats n’ont fait qu’accélérer la propagation des rats noirs dont les puces étaient porteuses de la peste bubonique, les fonctionnaires municipaux de Londres ont répété la même erreur environ 300 ans plus tard.
De nos jours, on emploie surtout la mort aux rats, le gaz ou encore les pièges (plus écologiques et rapides), pour éliminer les indésirables.
Cependant, les rats sont dotés d'un odorat très développé qui leur permet d'éviter les pièges mis en place par les humains.
Et ils communiquent avec des ultrasons, dont la fréquence est trop élevée pour être audible pour l'oreille humaine.
Dès qu'ils sentent un danger, ils préviennent les autres rats.En règle générale, le rat n'attaque pas l'être humain, il le fuit,,.
Il peut cependant être agressif s'il se sent acculé ou surpris.
Il peut arriver que les rats mordent l'homme pendant son sommeil, mais il s'agit d'un phénomène rare.Bien qu'ils n'étaient pas alors considérés comme utiles les rats étaient appréciés dans un jeu de sang.
Les parieurs organisaient des combats de rats contre chiens.
Ce type de combat connut un grand succès par exemple en Angleterre au XIXe siècle quand les combats de chiens furent interdits en 1835.
Ainsi un chien nommé Billy devint célèbre en tuant cent rats en cinq minutes et demie.
En France, ce type de combat, finalement jugé trop cruel, est interdit depuis 1987,.D'un point de vue utilitaire, les rats ont joué et jouent encore un rôle dans l'alimentation humaine.
Plusieurs espèces de rats sont mangées par les communautés rurales d'Asie du Sud-Est, d'Inde et d'Afrique,.
En Occident, le rat n'a souvent été mangé qu'en situation de guerre et de famine.
Ainsi l'on sait que des rats et plusieurs autres espèces animales ont nourri les hommes pendant le siège de Paris en 1870-1871.Les rats des villes (Rattus norvegicus) jouent un rôle important dans le traitement des déchets humains.
On estime généralement que sans eux, les égouts et canalisations des grandes villes seraient rapidement bouchés de manière irrémédiable.
À Paris, ils dévorent près de 800 tonnes d'ordures par jour.Le rat domestique (Rattus norvegicus d’élevage) est très utilisé par les laboratoires pour divers tests et études.
De même son intelligence y est fort appropriée pour faire des expériences sur le comportement.
Sa petite taille, sa résistance et sa prolificité en font notamment un organisme modèle.Ce rat apprivoisé a trouvé sa place parmi les nouveaux animaux de compagnie (NAC).
On trouve de plus en plus de matériel et d’aliments dédiés à cet animal.
Il est apprécié pour son caractère, son agilité mais aussi son intelligence,.En dehors du genre Rattus, les rats géants de Gambie, des muridés du genre Cricetomys, sont utilisés comme démineurs pour détecter les mines antipersonnel en Afrique, notamment au Mozambique.
Ils permettent de les détecter et ainsi de les éliminer de manière très efficace.
Les rats de Gambie ont un odorat puissant et sont curieux et agiles, ce qui explique l'intérêt qu'ils représentent pour cette tâche.
D'autant plus qu'ils sont intelligents et apprennent très vite et il faut dire qu'ils ont un odorat plus puissant que celui d'un chien, qu'ils sont plus résistants mais aussi qu'ils sont plus petits et reviennent beaucoup moins chers,.
Leur poids est un atout idéal puisque pesant moins de 1,5 kg, ils ne font pas exploser les mines,.Depuis peu ils sont également utilisés en Tanzanie et au Mozambique pour la détection de la tuberculose à partir d'expectorations (crachats), toujours en se servant de leur sensibilité olfactive et de leur capacité d'apprentissage : leur taux de détection (67 %) est supérieur à celui de laborantins étudiant des lames au microscope (48 %) et ils permettent d'éviter des examens en laboratoires longs (une semaine) et couteux.Depuis la Préhistoire, le « rat » a toujours accompagné l'Homme, et de ce fait, c'est un animal qui occupe une très forte symbolique et qui est fortement présent dans les domaines folkloriques et artistiques.
Cependant la symbolique n'est pas la même selon les époques et selon les différents continents.
En Orient et plus particulièrement en Asie, le rat est généralement le symbole de l'intelligence, de l'ambition et même de la chance,.
En Occident, et ce depuis le Moyen Âge, sa valeur symbolique est généralement négative, certainement du fait qu'il est destructeur de récoltes et propagateur d'épidémies.
Cependant la symbolique du rat est bien plus complexe, et il reste un animal lourd de symbole, indissociable de l'Homme.En Inde comme en Extrême-Orient, le rat est associé aux divinités.Dans l'hindouisme, le rat est associé à Ganesh puisqu'il en est la monture (le vahana).
Du fait que Ganesh est une des divinités les plus populaires de l'hindouisme, le rat est un animal qui n'est pas vu comme nuisible mais aimé pour son ingéniosité et sa curiosité.
En tant que monture de Ganesh, il est comparable au mantra récité et qui dévore les graines d'ignorance pour permettre d'accéder à la connaissance que représente la Divinité.
Globalement perçus comme des créatures inoffensives, on peut voir en Inde des rats se promener parmi les hommes, sans que cela pose problème à la population.Le temple de Karni Mata, en Inde dans l’État du Rajasthan, est l'un des exemples les plus parlants que l'on puisse trouver.
Selon la légende locale les rats sont les réincarnations de la sadhvi Karni Mata, de sa famille mais aussi de ses conteurs, bardes et poètes.
Les rats sont les premiers dévots privilégiés de Karni Mata.
Des milliers de rats vivant au sein du temple (20.000 selon certaines estimations), la tradition dit qu'il y a quatre ou cinq rats blancs, que l'on considère comme particulièrement saints.
Ils sont les manifestations de Karni Mata elle-même et de sa famille.
Les apercevoir est un privilège et les visiteurs ont le devoir de leur donner de la nourriture.En Extrême-Orient, le rat fait partie de l'astrologie chinoise, il est le premier animal d'un cycle de douze animaux.
Des légendes relatent comment les animaux furent choisis et comment le rat devint le premier animal du cycle zodiacal.
Il le fut par la ruse et il est de ce fait associé à la mesquinerie mais surtout à l'intelligence,.
Il est également lié à l'argent.
Au Japon, le rat est considéré comme le messager de Daikokuten, divinité de la richesse, du commerce et des échanges.En Occident et plus précisément dans la langue française, le rat est aussi lié à la richesse mais il se retrouve lié à l'avarice.
Ainsi, de nombreuses expressions métaphoriques se sont créées à partir du mot « rat ».
Leur signification a souvent une connotation péjorative reflétant l'image négative et peu reluisante qu'inspire le rat.
On dit par exemple d'une personne avare qu'elle est très rat, d'un homme « fort gueux » qu'il est gueux comme un rat ou encore lorsqu'un logement est étroit et sale on dit que c'est un nid à rats.
Pour décrire quelqu'un de fantaisiste ou faisant un caprice on dit alors qu'il a des rats dans la tête (etc).Indésirable et propagateur d’épidémies, le rat a souvent été perçu par le dégoût, la répugnance et par la crainte.
Il a ainsi alimenté l'imaginaire collectif et la croyance populaire, tels le culte de Saint-Gertrude de Nivelles qui aurait eu le pouvoir de repousser les rats et les souris,, la légende du joueur de flûte de Hamelin ou encore la créature folklorique du roi de rats.
Un roi de rats est en fait un regroupement de rats dont les queues sont entrelacées les unes aux autres, souvent prises dans une gangue composée de paille, d'excréments et de poils.
C'est un phénomène rare et contesté qui est accompagné d'un mythe populaire.En Europe, le rat est donc présent dans les contes, puisque les frères Grimm ont notamment transcrit la légende du joueur de flûte de Hamelin, mais il est aussi dans les fables.
De nombreuses fables de Jean de La Fontaine parlent du rat et lui prêtent des caractéristiques anthropomorphes.
On en compte pas moins de douze ayant le mot « rat » dans leur titre,.À la fin du XIXe siècle et au XXe siècle le rat est encore une fois intégré à la littérature mais c'est au genre de l'horreur qu'il est associé, comme on peut le voir avec la nouvelle Les Rats dans les murs de l'écrivain américain Howard Phillips Lovecraft dans laquelle les rats sont anthropophages ou encore avec la Tétralogie des Rats du romancier anglais James Herbert.
Dans les dernières décennies du XXe siècle et dans les années 2000, l'image du rat reste souvent la même.
Le roman d'horreur Garbage rampage de Julian C. Hellbroke (coll.
Trash) se déroule sur fond d'invasion de rats mutants à New York.
L'image du rat évolue tout de même, et devient parfois un peu plus positive, sans doute du au recours plus fréquent du rat brun en laboratoire et aux débuts du rat brun en tant qu'animal de compagnie dans les années 1980.
Durant cette période, on voit aussi apparaître le rat dans la bande-dessinée.
Et ce aussi bien dans la BD franco-belge que dans le comic et le manga et dans les adaptations télévisuelles et cinématographiques qui en découlent.Le rat est donc également présent à l'écran.
Il y garde souvent son côté de vermine terrifiante et propagatrice d'épidémies, comme dans Willard, film d'horreur américain sorti en 1971 sa réadaptation de 2003, Soudain... les monstres ou bien encore dans D'origine inconnue (voir Liste de films d'horreur avec des rats).
Dans les films d'animation américains les rats y jouent des rôles divers.
Dans Brisby et le secret de NIMH, l'héroïne est une souris aidée par des rats de laboratoire intelligents qui se sont évadés et qui se trouvent être selon les personnages amicaux ou violents.
Dans Basil, détective privé, le rat se voit cantonné au rôle du méchant, rival de la souris.
Enfin dans Ratatouille, un rat d'égout se voit devenir un « héros culinaire »,,.
Ce dernier film a d'ailleurs été édité en jeu vidéo.
On peut également noter le portrait très sombre que le jeu vidéo A Plague Tale : Innocence fait du rat, qui devient ici la matérialisation de la vermine et de la mort.
Dans le livre Demain les rats, Christopher Stork met en scène des rats scientifiquement modifiés qui prennent finalement possession du monde.
: document utilisé comme source pour la rédaction de cet article.
La séquence d'un acide nucléique — ADN ou ARN — est la succession des nucléotides qui le constituent.
Cette succession contient l'information génétique portée par ces polynucléotides, de sorte qu'on la qualifie également de séquence génétique ou parfois de séquence nucléotidique.
Elle peut être déterminée par des méthodes de séquençage de l'ADN.Les séquences nucléotidiques sont conventionnellement écrites dans le sens 5’ → 3’, qui est celui dans lequel sont lues et synthétisées ces biomolécules.
Les nucléotides sont représentés conventionnellement par des lettres symbolisant la base nucléique qui les caractérise ; l'IUPAC a défini une nomenclature précise pour écrire les séquences d'acides nucléiques selon l'information que l'on souhaite représenter :Dans la mesure où les acides nucléiques sont des molécules le plus souvent linéaires, leur séquence nucléotidique définit entièrement les liaisons chimiques qui les constituent, de sorte que leur séquence nucléotidique se confond avec leur structure primaire.
La cytotoxicité est la propriété d'un agent chimique ou biologique à être toxique pour les cellules, éventuellement jusqu'à les détruire.Le traitement des cellules par un composé cytotoxique peut entraîner une variété de conséquences.
Les cellules peuvent subir une nécrose, dans laquelle elles perdent leur intégrité membranaire et meurent rapidement à la suite d'une lyse cellulaire.
Les cellules peuvent s'arrêter activement de croître et de se diviser (diminution de la viabilité cellulaire), ou les cellules peuvent activer un programme génétique de mort cellulaire contrôlée (apoptose).Les cellules qui subissent une nécrose présentent généralement un gonflement rapide, perdent l'intégrité de la membrane, arrêtent le métabolisme et libèrent leur contenu dans l'environnement.
Les cellules qui subissent une nécrose rapide in vitro n'ont pas assez de temps ou d'énergie pour activer les machines apoptotiques et n'exprimeront pas de marqueurs apoptotiques.
L'apoptose est caractérisée par des événements cytologiques et moléculaires bien définis, y compris une modification de l'indice de réfraction de la cellule, un retrait cytoplasmique, une condensation nucléaire et un clivage de l'ADN en fragments de taille régulière.
Les cellules en culture qui subissent une apoptose finissent par subir une nécrose secondaire.
Elles stopperont le métabolisme, perdront l'intégrité de la membrane et la lyse.
Un sujet très important en cytotoxicité est la prédiction de la cytotoxicité de composés chimiques sur la base de mesures précédentes, c'est-à-dire de tests in-silico.
Pour cela, de nombreuses méthodes QSAR et de criblage virtuel ont été proposées.
Une comparaison indépendante de ces méthodes a été effectuée dans le cadre du projet "Toxicologie au XXIe siècle".La chimiothérapie dans le traitement du cancer repose souvent sur la capacité des agents cytotoxiques à tuer ou à endommager les cellules cancéreuses qui se reproduisent ; La chimiothérapie cible notamment les cellules cancéreuses en division rapide.La cytotoxicité à médiation cellulaire dépendant de l'anticorps (ADCC) décrit la capacité de certains lymphocytes à détruire les cellules, ce qui nécessite que la cellule cible soit marquée par un anticorps.
La cytotoxicité à médiation lymphocytaire, par contre, n'a pas besoin d'être médiée par des anticorps, pas plus que la cytotoxicité dépendante des compléments (CDC), qui est médiée par le système du complément.On distingue trois groupes de lymphocytes cytotoxiques :Les soignants (hospitaliers notamment) ainsi que les coursiers transportant les préparations de médicaments, sont discrètement mais parfois significativement exposés à des médicaments cytotoxiques (surtout utilisés contre le cancers), sachant qu'en outre ces médicaments sont par ailleurs généralement également génotoxiques, cancérogènes ou toxiques pour la reproduction.
L'exposition professionnelle est généralement révélée par dosage des cytotoxiques ou de leurs métabolites dans les urines, et/ou via des analyses de prélèvements de surface ou de filtres dans leur environnement de travail.
Les sources de contamination sont l'inhalation ou l'ingestion chronique ou accidentelle de faibles doses de produits à partir de surfaces contaminées ou d'aérosols.
Plusieurs études ont démontré des effets génotoxiques et pour la reproduction chez des agents de santé du secteur de l'oncologie (diminution de la fertilité féminine, risque accru d'avortement et de malformation fœtale).
Les femmes enceintes ou songeant à enfanter, et celles qui allaitent ne devraient pas être affectées à la reconstitution, l'administration et l'élimination de ces produits.
Les lymphocytes B, ou cellules B, sont des globules blancs particuliers faisant partie des lymphocytes.
Ce sont des cellules synthétisées dans la moelle osseuse, et qui circulent dans le sang et la lymphe pour participer aux défenses naturelles de l'organisme.Ils sont responsables de l'immunité humorale et fabriquent les immunoglobulines appelées anticorps.Chaque cellule B a plus de 100'000 anticorps membranaires (ou récepteurs antigéniques) identiques et spécifiques a un seul antigène.
Pour qu'un lymphocyte B soit actif, un de ces récepteurs doit entrer en contact direct avec l'antigène en question (soit soluble dans la lymphe ou le sang, soit apportée par une cellule présentatrice d'antigène) via l'épitope de ce dernier.
La cellule B ainsi activée se multiplie et donne naissance à deux types cellulaires : les plasmocytes et les lymphocyte B mémoire.
Les plasmocytes ont un réticulum endoplasmique et un appareil de Golgi extrêmement développés afin de produire et de sécréter une quantité massive d'anticorps qui, une fois sécrétés, vont pouvoir se lier à l'antigène qui a provoqué l'activation de la cellule B, et ainsi neutraliser l'agent pathogène possédant cet antigène en l'empêchant d'infecter d'autres cellules ou de se propager.
Le pathogène et les anticorps seront ensuite éliminés par les phagocytes du système immunitaire.
Les cellules mémoire, quant à elles, ont une longue durée de vie et vont être conservées dans le corps (sang, lymphe et organes lymphoïdes), prêtes à proliférer et se différencier en plasmocyte rapidement en cas d'une nouvelle infection du même pathogène.Les lymphocytes B sont des lymphocytes participant à la réponse immunitaire adaptative (propre aux vertébrés), c'est-à-dire qu'un lymphocyte B donné ne peut réagir que contre un antigène précis.
Cette spécificité est donnée par le récepteur des cellules B, complexe membranaire similaire au TCR des lymphocytes T.
Le récepteur des cellules B est également issu d'une recombinaison V(D)J.Les cellules B sont des lymphocytes qui jouent un grand rôle dans l'immunité humorale (par opposition à l'immunité cellulaire).« B » est l’abréviation de « bourse de Fabricius »,, un organe des oiseaux dans lequel les cellules B sont produites et arrivent à maturité, et non celle de la moelle osseuse (en anglais : bone marrow) dans laquelle les cellules B sont produites chez tous les autres vertébrés, notamment chez l'humain.Le corps humain produit des centaines de milliers de types différents de cellules B, et chaque type a sur sa membrane un récepteur des cellules B particulier, qui se liera à un antigène particulier ; à chaque instant des millions de cellules B circulent dans le sang et la lymphe, sans produire d'anticorps.Il y a plusieurs types de cellules B :L'immunité humorale (la création d'anticorps circulant dans le plasma et la lymphe) implique l'activation des cellules B. L'activation cellulaire peut être mesurée au moyen de la technique ELISPOT ou de cytométrie en flux (FACS) qui peut déterminer le pourcentage de cellules B sécrétant n'importe quel anticorps particulier.Les cellules B se caractérisent sur le plan immunohistochimique par la présence de CD79b, (chaine d'immunoglobine transmembranaire qui est un composant du récepteur des cellules B sur leur membrane plasmique).Susumu Tonegawa a obtenu le Prix Nobel de physiologie ou médecine en 1987 pour avoir démontré de quelle manière les cellules B créent une énorme diversité d'anticorps au départ d'un petit nombre de gènes.Les anticorps sont composés de chaînes de protéines lourdes et légères, chaque type contenant une partie constante (C) et une partie variable (V).
Les gènes codant ces chaînes légères ou lourdes se situent à différents endroits du génome.
NB : il y a donc deux allèles de chaque gène, puisque le génome humain est diploïde.Les régions V sont codées par des gènes qui comportent trois types de segments.
Par exemple, le locus de la chaîne lourde contient environ 50 gènes Variables (V), 30 gènes de Diversité (D) 6 gènes de Jonction (J) et 9 gènes C (Constant), ce qui donne V x D x J = 50 x 30 x 6 = 9000 possibilités.
Les gènes codant les chaînes légères possèdent également de nombreux segments V et J, mais aucun gène D.
La recombinaison entre les fragments VDJ permet de générer environ 2 x >106 combinaisons possibles : 9000 x 320 (120 possibilités pour la chaîne légère lambda (λ) + 200 pour la chaîne légère kappa (κ)).Dans les lymphocytes B en développement, la première recombinaison à avoir lieu se fait entre un segment D et un segment J d’un locus de chaîne lourde.
Toute la chaîne d’ADN située entre ces deux segments est éliminée.
Cette recombinaison D-J est suivie par la jonction d’un segment V venant d’un locus en amont du gène DJ nouvellement formé.
Cette fois encore, tout le locus situé auparavant entre le segment V et le DJ est éliminé du génome.
Lors de la transcription du gène, l’ARN messager contient la région VDJ recombinee de la chaine lourde, ainsi que les segments constants mu et delta (Cμ et Cδ).
Ce premier transcrit subit des modifications post-transcriptionelles classiques (polyadénylation, epissage des introns) et un épissage alternatif conduisant des gènes codant les segments constants.
La traduction de cet ARNm produit la chaîne lourde Ig μ.Les locus des gènes codant les chaînes légères kappa (κ) et lambda (λ) réarrangent d’une façon très similaire, à ceci près que les chaînes légères sont dépourvues de segment D.
En d’autres termes, la première étape de la recombinaison des chaînes légères concerne les segments V et J pour former un complexe VJ, avant l’addition du segment constant de la chaîne légère lors de la transcription.
La traduction de l’ARNm épissé des chaînes kappa ou lambda produit des chaînes légères Ig κ ou Ig λ.L’assemblage de deux chaînes lourdes Ig μ et de deux chaînes légères conduit à la formation de la forme membranaire de l’immunoglobuline IgM exprimée à la surface des lymphocytes B, le récepteur des cellules B. L’assemblage d’une chaîne légère avec une chaîne lourde forme un paratope unique.
Rongeurs, RodentiensLes rongeurs ou Rodentiens (Rodentia) sont un ordre de mammifères placentaires (le plus grand ordre de mammifères, regroupant plus de 2 000 espèces).
Ces animaux se caractérisent par leur unique paire d'incisives à croissance continue sur chacune de leurs mâchoires (ce qui les distingue des Lagomorphes), qui leur servent à ronger leur nourriture, à creuser des galeries ou à se défendre.
Le reste de leur morphologie est relativement variable, mais la majorité des espèces sont de petite taille, avec un corps trapu, des pattes courtes et une longue queue.
La plupart des rongeurs se nourrissent de graines ou d'autres matières végétales, mais d'autres ont des régimes alimentaires plus variés.
Ce sont souvent des animaux sociaux et beaucoup d'espèces vivent en communauté au sein desquelles les individus interagissent et communiquent entre eux de façon complexe.
Le mode de reproduction peut être monogame, polygyne ou avec promiscuité sexuelle.
De nombreuses espèces ont des portées de petits peu développés et dépendants, quand d'autres donnent directement naissance à des jeunes déjà relativement bien développés.Les rongeurs forment un groupe très diversifié, présent sur tous les continents à l'exception de l'Antarctique.
C'est le seul ordre de mammifères placentaires à avoir colonisé l'Australie sans l'intervention humaine.
Ils se sont adaptés à de très nombreux habitats terrestres, dont ceux anthropisés, et certaines espèces sont arboricoles, fouisseuses ou semi-aquatiques.
L'ordre des Rodentia représente près de quarante pour cent des espèces de mammifères, ce qui en fait le plus diversifié devant celui des chauves-souris (Chiroptera).
Parmi les espèces les plus connues de ce groupe sont les souris, les rats, les écureuils, les chiens de prairie, les porcs-épics, les castors, les cochons d'Inde et les hamsters.
D'autres animaux tels que les lapins, les lièvres et les pikas, qui peuvent être pris pour des rongeurs et qui ont été placés dans cet ordre par le passé, constituent désormais l'ordre des Lagomorpha.
Les données fossiles disponibles sur les rongeurs remontent jusqu'au Paléocène en Laurasia.
Ce groupe connaît une grande diversification au cours de l'Éocène et se disperse sur tous les continents, parfois même en traversant les océans et rejoignant ainsi l'Amérique du Sud et Madagascar depuis l'Afrique.Les rongeurs sont utilisés en tant que source de nourriture, pour la confection de vêtements, en tant qu'animaux de compagnie ou de laboratoire.
Certaines espèces, comme le Surmulot (Rattus norvegicus), le rat noir (Rattus rattus) ou la souris grise (Mus musculus) sont de sévères ravageurs, mangeant ou dégradant les stocks de nourriture humains, ou agissant comme vecteurs de parasites (poux, tiques…) et de maladies infectieuses, souvent zoonotiques (touchant à la fois l'homme et l'animal).
Les espèces de rongeurs introduites par accident deviennent souvent envahissantes, menaçant la survie d'espèces indigènes.
C'est notamment le cas de nombreux oiseaux insulaires, auparavant privés de prédateurs et dont les couvées peuvent être prédatées.Les rongeurs se caractérisent par l'existence d'une unique paire d'incisives, acérées et à croissance continue, sur chacune de leurs mâchoires.
Ces dents sont munies d'épaisses couches d'émail sur l'avant, mais le sont peu sur l'envers.
Leur croissance ne cessant jamais, c'est leur usure perpétuelle qui leur évite de ne trop croître, et ainsi d'atteindre ou même de percer le crâne.
Comme les incisives s'aiguisent les unes contre les autres, la dentine à l'arrière des dents s'use, ne laissant que l'émail, solide, taillé comme un ciseau.
La plupart des espèces ont jusqu'à 22 dents, sans canines ni prémolaires antérieures.
Il y a un écart, ou diastème, entre les incisives et les molaires chez la plupart des espèces.
Cela leur permet d'aspirer leurs joues ou leurs lèvres et protéger leur cavité buccale de copeaux de bois ou d'autres matières non comestibles, et de se débarrasser de ces déchets par les côtés de leur bouche.
Les chinchillas et les cobayes ont une alimentation riche en fibres, et leurs molaires n'ont pas de racines mais ont une croissance continue comme les incisives.Chez beaucoup de rongeurs les molaires sont relativement grosses, très structurées et avec des cuspides ou des sillons très marqués, bien que chez d'autres, comme les espèces du genre Pseudohydromys, elles sont plus petites et plus simples.
Les dents sont bien adaptées à broyer les aliments en petits morceaux.
La musculature de la mâchoire est forte.
La mandibule est poussée vers l'avant pour ronger, et tirée vers l'arrière lors de la mastication.
Les différents groupes de rongeurs diffèrent, à la fois des autres mammifères et entre eux, par l'arrangement des muscles de leur mâchoire et par les structures du crâne associées à cette musculature.
Les Sciuromorpha, qui comprennent les écureuils typiques, ont le faisceau profond de leur masséter particulièrement puissant, qui les rend efficaces pour mordre avec les incisives.
Les Myomorpha, qui comprennent les souris, ont un muscle temporal élargi, qui leur permet de mastiquer puissamment avec les molaires.
Le Hystricomorpha, comme les cochons d'Inde ou les porcs-épics, ont un faisceau superficiel de leur masséter plus grand et un faisceau profond plus petit que les souris ou les écureuils, les rendant peut-être moins efficaces à mordre avec les incisives, mais leur muscle ptérygoïdien intérieur plus puissant leur permet de bouger davantage leur mâchoire sur les côtés lors de la mastication.Le plus petit rongeur existant est la gerboise Salpingotulus michaelis, qui mesure en moyenne 4,4 cm de longueur (tête et corps), avec des femelles adultes ne pesant que 3,75 g. La plupart des espèces de rongeurs pèsent moins de 100 g, mais le plus grand rongeur actuel, le Capybara (Hydrochoerus hydrochaeris), peut peser jusqu'à 66 kg.
Du côté des taxons éteints, les ossements fossiles ont montré qu'il y a environ trois millions d'années vivait au sud de l'Amérique un rongeur bien plus grand (plus grand encore que Eumegamys paranensis ou que Phoberomys pattersoni, découvert au Venezuela et pouvant peser de 436 à 741 kg, précédents records en taille chez les rongeurs fossiles) : Josephoartigasia monesi était aussi haut qu'un bison et pesait jusqu'à une tonne environ.
C'est le plus grand des rongeurs connus ayant vécu sur la Terre.
Plusieurs indices laissent à penser que sa mâchoire était dotée d'une force exceptionnelle, (plus encore que celle du tigre ou du crocodile).
Ce rongeur géant pourrait avoir ressemblé au cochon d'Inde, mais de la taille d'un hippopotame.La diversité des caractéristiques des rongeurs est grande, parfois même entre des espèces étroitement apparentées.
Les caractéristiques de quelques espèces de rongeurs typiques sont données dans le tableau ci-dessous :De nombreuses espèces de rongeurs présentent un dimorphisme sexuel.
Chez certaines, les mâles sont plus gros que les femelles tandis que chez d'autres c'est l'inverse.
Les gros mâles sont typiques chez les écureuils terrestres, les rats kangourous, les rats-taupes solitaires et les gaufres à poche, et ce dimorphisme est probablement apparu par sélection sexuelle et par l'existence de combat entre mâles.
Les grosses femelles sont trouvées chez les tamias et les souris sauteuses.
On ne sait pas pourquoi ce phénomène se produit, mais chez le Tamia amène (Tamias amoenus) il se pourrait que les mâles choisissent les femelles plus grosses qui auraient un meilleur succès reproducteur.
Chez certains rongeurs, comme les campagnols, le dimorphisme sexuel peut varier d'une population à une autre.
Chez le Campagnol roussâtre (Myodes glareolus), les femelles sont généralement plus grosses que les mâles, mais c'est l'inverse qui se produit chez les populations alpines, peut-être en raison du manque de prédateurs et des compétitions plus marquées entre mâles.Les différents groupes de rongeurs ont des morphologies très variables, mais ont généralement des corps massifs, trapus avec des pattes courtes.
Les membres antérieurs ont généralement cinq doigts, dont un pouce opposable, tandis que les membres postérieurs ont trois à cinq doigts.
Le coude donne à l'avant-bras une grande flexibilité.
La majorité des espèces sont plantigrades, marchant sur la sole de leurs pattes, et ont des ongles semblables à des griffes.
Les ongles des espèces fouisseuses ont tendance à être longs et forts, tandis qu'ils sont plus courts et plus pointus chez les rongeurs arboricoles.
Les différentes espèces de rongeurs utilisent une grande variété de modes de locomotion, dont la marche quadrupède, la course, l'usage de galeries souterraines, la grimpe, le saut bipède (gerboises, rats-kangourous et souris sauteuses d'Australie), la natation ou même le vol plané.
Les espèces de la famille des Anomaluridae et celles de la sous-famille des Pteromyinae, toutes appelées « écureuils volants », peuvent en effet planer d'arbre en arbre en utilisant des membranes qui s'étendent entre les membres antérieurs et postérieurs.
Les agoutis (Dasyprocta) sont des animaux rapides, étant munis d'ongles semblables à des sabots qu'ils utilisent en course digitigrade.
La majorité des rongeurs sont munis de queues, qui peuvent être de formes et tailles variées.
Certaines sont préhensiles, comme celle du Rat des moissons (Micromys minutus), et leur fourrure peut être touffue ou au contraire très réduite.
Cet organe sert parfois à la communication, comme chez le castor qui claque sa queue sur la surface de l'eau ou la souris domestique qui l'ébranle pour signaler un danger.
D'autres espèces ont des queues rudimentaires, ou pas de queue du tout.
Chez certaines espèces enfin, la queue est capable de régénération si elle est en partie coupée.Les rongeurs ont généralement les sens de l'odorat, de l'ouïe et de la vision bien développés.
Les espèces nocturnes ont souvent de grands yeux et certaines sont sensibles à la lumière ultraviolette.
De nombreuses espèces ont de longues vibrisses, qui leur servent à balayer l'environnement lors de la locomotion (avec des mouvements d'avant en arrière, le whisking).
Certains rongeurs ont des abajoues, qui peuvent être doublées de fourrure.
Chez de nombreuses espèces, la langue ne peut pas aller plus loin que les incisives.
Le système digestif des rongeurs est efficace, absorbant près de 80 pour cent de l'énergie ingérée.
Lorsqu'un rongeur consomme de la cellulose, la nourriture est d'abord prédigérée dans l'estomac puis passe dans le cæcum, où des bactéries la réduisent en glucides.
Le rongeur pratique alors la coprophagie, consommant ses propres pelotes fécales, de sorte que les nutriments peuvent ensuite être absorbés par l'intestin.
Ils produisent donc souvent des crottes dures et sèches.
Chez de nombreuses espèces, le pénis contient un os, le baculum.
Les testicules peuvent être situés sur l'abdomen ou à l'aine.La plupart des rongeurs sont herbivores, se nourrissant exclusivement de graines, de tiges, de feuilles, de fleurs ou de racines.
D'autres sont omnivores, et quelques-uns sont prédateurs.
Le Campagnol agreste (Microtus agrestis) est un exemple typique d'espèce herbivore, se nourrissant d'herbe, de tubercules, de mousses et d'autres végétaux.
Il ronge de l'écorce au cours de l'hiver, et consomme occasionnellement des invertébrés comme des larves d'insectes.
Le Gaufre brun (Geomys bursarius) mange des végétaux trouvés sous terre lorsqu'il creuse des galeries, et collecte aussi de l'herbe, des racines et des tubercules dans ses abajoues et qu'il cache dans des chambres souterraines.
Le gaufre à poche Geomys personatus évite de sortir à la surface pour se nourrir, attrapant les racines de plantes avec ses mâchoires et les tirant vers le bas creusé dans son terrier.
Le Cricétome de forêt (Cricetomys emini) cherche sa nourriture à la surface, collectant tout ce qui est comestible dans ses grosses abajoues, et ramène le tout dans son terrier pour le consommer.Les agoutis (Dasyprocta sp.)
sont des rares animaux qui arrivent à ouvrir les fruits du Noyer d'Amazonie (Bertholletia excelsa).
Chaque fruit contenant de nombreuses noix, l'animal ne les consomme pas en une fois mais les transporte et les cache, aidant à la dispersion des graines qu'il ne retrouve pas.
D'autres arbres à noix produisent de très nombreux fruits en automne, qui sont stockés dans des trous ou des crevasses par les écureuils.
Dans certaines régions arides, les graines sont souvent disponibles pour de courtes périodes, et les rats-kangourous en collectent autant qu'ils peuvent pour les stocker dans des chambres souterraines.
Une autre stratégie pour tirer parti des abondances saisonnières sont les réserves de graisse.
Elle est par exemple utilisée par les marmottes (Marmotta sp.
), qui peuvent être de 50 % plus lourdes à l'automne qu'au printemps, utilisant leurs réserves durant leur longue hibernation.
Les castors se nourrissent de feuilles, de bourgeons et de l'écorce interne des arbres en croissance, ainsi que de plantes aquatiques.
Durant l'automne, ces rongeurs coupent de petits arbres et des branches feuillues, et les immergent dans leur étang en plantant une extrémité dans la boue pour les fixer.
L'hiver, ils peuvent accéder à ces réserves, même lorsque l'eau est gelée en surface.Bien que les rongeurs ont par le passé été considérés comme des herbivores, un certain nombre d'espèces se montrent opportunistes et consomment à l'occasion des insectes, du poisson ou de la viande, et d'autres plus spécialisées ont besoin de ces ressources dans leur régime alimentaire.
Une étude morphologique et fonctionnelle de la dentition des rongeurs suggère que les rongeurs primitifs étaient omnivores plutôt qu'herbivores.
D'autres études montrent que de nombreuses espèces des sous-ordres des Sciuromorpha et des Myomorpha, et quelques membres des Hystricomorpha, incorporent naturellement de la matière animale dans leur régime alimentaire ou la consomme volontiers si ces aliments leur sont donnés en captivité.
L'examen du contenu stomacal de Souris à pattes blanches (Peromyscus leucopus) en Amérique du Nord, espèce normalement considérée comme herbivore, a montré que la matière animale constituait 34 % de l'alimentation.
Parmi les rongeurs carnivores plus spécialisés, on compte les espèces du genre Rhynchomys aux Philippines, qui se nourrissent d'insectes et d'invertébrés mous, et le Rat d'eau australien (Hydromys chrysogaster), qui consomme des insectes aquatiques, des poissons, des crustacés, des moules, des escargots, des grenouilles, des œufs d'oiseaux et des oiseaux aquatiques,.
La Souris sauterelle (Onychomys leucogaster), qui peuple les régions sèches de l'Amérique du Nord, se nourrit d'insectes, de scorpions ou d'autres petites souris, et seulement un peu de matière végétale.
Son corps est trapu et ses pattes et queue courtes, mais elle est agile et peut facilement maîtriser des proies aussi grandes qu'elle.Les rongeurs présentent une multitude d'organisations sociales, allant du système de castes du Rat-taupe nu (Heterocephalus glaber), un des seuls cas connus d'eusocialité chez les mammifères, aux colonies denses des chiens de prairie partageant de grands réseaux de galeries (appelés « villes »), en passant par les groupes familiaux ou le mode de vie solitaire du Loir gris (Glis glis).
Si les loirs adultes peuvent avoir des zones d'alimentation se chevauchant, ils vivent dans des nids différents et se nourrissent séparément, les rencontres n'ayant lieu que pour la reproduction.
Les gaufres à poche (Geomyidae) mènent aussi une vie solitaire en dehors de la saison de reproduction, chaque individu creusant son propre réseau de galerie et défendant son territoire.Les gros rongeurs ont tendance à vivre en groupes familiaux au sein desquels les parents vivent avec leur progéniture jusqu'à ce que celle-ci se disperse.
Les castors vivent en familles élargies, comptant généralement avec un couple d'adultes, les jeunes de l'année, ceux de l'année précédente et parfois d'années antérieures.
Le Rat brun vit généralement en petites colonies, avec jusqu'à six femelles partageant un terrier et un mâle défendant un territoire autour de celui-ci.
Quand les densités de rats sont élevées, ce système est abandonné et les mâles utilisent un système hiérarchique de domination, avec des territoires qui se chevauchent.
La progéniture femelle reste dans la colonie tandis que les jeunes mâles se dispersent.
Le Campagnol des Prairies (Microtus ochrogaster) est monogame et forme un couple uni pour la vie.
En dehors de la saison de reproduction, il vit en proximité d'autres congénères en petites colonies.
Un mâle n'est pas agressif envers les autres mâles jusqu'à ce qu'il se soit accouplé, après quoi il défend un territoire, une femelle et un nid contre les autres mâles.
Les deux partenaires se blottissent l'un contre l'autre, se toilettent mutuellement, et participent ensemble à l'élevage des jeunes.Les écureuils terrestres, comme les marmottes, figurent parmi les rongeurs les plus sociaux.
Ils forment généralement des colonies de femelles apparentées, les mâles se dispersant après le sevrage pour mener une vie nomade.
Les animaux d'une colonie peuvent coopérer à différents niveaux, en s'avertissant par des cris d'alarme, en défendant un territoire commun, en partageant leur nourriture ou en protégeant les zones de mise bas et les jeunes.
Le Chien de prairie à queue noire (Cynomys ludovicianus) forme des « villes » pouvant couvrir plusieurs hectares.
Les galeries les composant ne sont pas interconnectées mais sont creusées et occupées par des familles territoriales appelées « coteries ».
Ces dernières sont généralement constituées d'un mâle adulte, de trois ou quatre femelles adultes, de plusieurs jeunes non-reproducteurs et des petits de l'année.
Les membres d'une coterie interagissent paisiblement entre eux mais se montrent hostiles aux membres externes.Les exemples de comportement colonial des plus extrêmes chez les rongeurs sont probablement ceux des rongeurs eusociaux que sont le Rat-taupe nu (Heterocephalus glaber) et le Rat-taupe de Damaraland (Cryptomys damarensis).
Le premier vit entièrement sous terre et peut former des colonies comptant jusqu'à 80 individus.
Seule une femelle et jusqu'à trois mâles s'y reproduisent, tandis que les autres membres de la colonie sont plus petits, stériles et ont la fonction d'ouvriers.
Certains individus sont de taille intermédiaire, et aident à l'élevage des jeunes et peuvent prendre la place des reproducteurs si l'un d'eux meurt.
Chez le Rat-taupe de Damaraland, il n'y a qu'un couple reproducteur.
Les autres individus ne sont pas complètement stériles, mais ne deviennent fertiles que s'ils forment leur propre colonie.Les rongeurs utilisent le marquage sensoriel dans divers contextes sociaux, comme la communication inter- et intra-spécifique, le marquage des passages et l'établissement de territoires.
Leur urine donne des informations génétiques aux autres individus de l'espèce, comme le sexe ou l'identité, et des informations métaboliques sur le statut de dominance, le statut de reproduction et la santé.
Des composés dérivés du complexe majeur d'histocompatibilité (CMH) sont liés à plusieurs protéines urinaires.
L'odeur d'une prédateur conduit à réduire ce comportement de marquage sensoriel.Les rongeurs sont capables de reconnaître des individus qui leur sont apparentés par l'odeur, et cela leur permet de se comporter plus favorablement envers leurs proches (« népotisme ») et d'éviter la consanguinité.
Les animaux reconnaissent ainsi leurs proches par des signaux olfactifs à partir de l'urine, des fèces et des sécrétions glandulaires.
Le principal facteur de détermination implique le CMH, puisque le degré de parenté entre deux individus est corrélé avec les gènes CMH qu'ils ont en commun.
Dans la communication entre animaux qui ne sont pas apparentés, des marqueurs olfactifs plus permanents sont nécessaires, comme au niveau des limites de territoire, avec des protéines urinaires majeures non volatiles, dont la fonction de transporteurs de phéromones peut également être utilisée.
Ces protéines urinaires majeures peuvent aussi indiquer l'identité de chaque individu, chaque mâle de Souris grise excrétant dans son urine une combinaison de 12 protéines spécifique à l'animal.Les Souris domestiques déposent leur urine, qui contient des phéromones, pour marquer leur territoire, reconnaître les individus et pour des raisons d'organisation sociale.
Cela peut prendre différentes formes :Des rongeurs territoriaux comme les castors ou les Écureuils roux (Sciurus vulgaris) analysent et s'habituent aux odeurs de leurs voisins et sont moins agressifs envers leurs intrusions qu'envers celles d'animaux errants ou étrangers,.Plusieurs espèces de rongeurs, particulièrement celles qui sont diurnes et sociales, ont une large gamme de cris d'alarme qui sont émis quand ils perçoivent des menaces.
Ces cris ont des bénéfices directs comme indirects.
Ainsi, un prédateur potentiel peut s'arrêter à l'écoute de ce cri, considérant qu'il est repéré, et l'alarme ainsi donnée peut conduire les congénères de l'animal le produisant à se cacher pour éviter le danger.
Plusieurs espèces, par exemple les chiens de prairies, ont un système de cris d'alerte complexe.
Ces espèces peuvent employer des cris différents suivant le prédateur (un cri pour les prédateurs terrestres et un pour les prédateurs aériens par exemple) et chacun donne des informations sur la nature exacte de la menace.
L'urgence de la menace peut également être indiquée par les propriétés acoustiques du cri.Les rongeurs sociaux ont une plus large gamme de vocalisations que les espèces solitaires.
Quinze différents cris d'alarme ont été reconnus chez l'adulte rat-taupe Fukomys micklemi et quatre chez les jeunes.
De la même manière, l'octodon, un autre rongeur social, qui creuse des terriers, a une vaste palette de moyens de communication et un répertoire vocal élaboré comprenant 15 différentes catégories de sons.
Les ultrasons jouent un rôle dans la communication des loirs et sont utilisés quand les individus sont hors de vue les uns des autres.Les Souris grises utilisent à la fois des cris audibles et des ultrasons suivant le contexte.
Les cris audibles peuvent généralement être entendus lors d'échanges agressifs, tandis que les ultrasons sont utilisés dans la communication sexuelle ainsi que par les jeunes quand ils tombent de leur nid.Les rats de laboratoires (qui sont des Rats bruns, Rattus norvegicus) émettent des courtes vocalisations ultrasoniques à de hautes fréquences durant des expériences supposées agréables pour l'animal comme lorsqu'on lui administre une dose de morphine, lors de l'accouplement ou lorsqu'il est chatouillé.
Le cri, décrit comme un « gazouillis » caractéristique, est comparé à un rire, et est interprété comme l'attente de quelque chose de bon.
Dans des études cliniques, le « gazouillis » est associé à des sentiments positifs, et les liens sociaux naissent avec les chatouilles, qui sont donc recherchées par les rats.
Toutefois au fur et à mesure que les rats vieillissent, ils sont de moins en moins enclins à « gazouiller ».
Comme la plupart des vocalisations des rats, le « gazouillis » se fait à des fréquences trop hautes pour que les humains les entendent sans équipement spécial, et un récepteur approprié est donc utilisé pour ce type d'études.Il a été démontré que le Rat brun pouvait utiliser les ultrasons pour faire de l'écholocation.
La gamme de fréquences écoutée par les rongeurs diffère entre les espèces.
Le tableau ci-dessous montre la gamme entendue par différentes espèces.Les rongeurs, comme les autres mammifères placentaires à l'exception des primates, ont deux types de cônes pour capter la lumière au niveau de leur rétine, des cônes S sensibles aux courtes longueurs d'onde qui permettent de percevoir la couleur bleue et des cônes M qui possèdent un photopigment sensible aux moyennes longueurs d'onde et permettent de capter la couleur verte.
Ce sont donc des animaux dichromates.
Toutefois, ils sont sensibles au spectre ultraviolet, et c'est pourquoi ils peuvent voir des choses que l'Homme ne voit pas.
Le rôle de cette sensibilité aux ultraviolets n'est pas toujours clairement connu.
Chez les octodons, par exemple, le ventre reflète plus de lumière ultraviolette que le dos.
C'est pourquoi, quand un octodon se dresse sur ses pattes arrière, ce qu'il fait en cas d'alerte, il expose son ventre aux autres octodons et la vision ultraviolette pourrait servir à communiquer l'alarme.
Quand il se tient à quatre pattes, sa faible réflectance des rayons ultraviolets pourrait le rendre moins visible pour les prédateurs.
La lumière ultraviolette est abondante durant la journée mais pas la nuit.
Il y a une forte augmentation du taux de rayons ultraviolets par rapport à la lumière visible à l'aube et au crépuscule.
Certains rongeurs sont particulièrement actifs à ces heures de la journée, et la sensibilité aux ultraviolets leur donne alors un avantage.L'urine de plusieurs rongeurs (par exemple les campagnols, les octodons, les rats et les souris) reflète fortement la lumière ultraviolette et cela pourrait être un moyen de communication laissant un marquage à la fois visuel et olfactif.
Toutefois, la quantité d'ultraviolets reflétée diminue avec le temps, ce qui dans certaines circonstances peut constituer un désavantage pour les animaux ; le Faucon crécerelle (Falco tinnunculus) peut faire la différence entre un passage récent de rongeur et un passage plus ancien, ce qui lui donne un avantage lorsqu'il chasse.Les vibrations émises par certaines espèces sur le sol peuvent informer leurs congénères sur certains de leurs comportements.
Le rat-taupe Nannospalax ehrenbergi est le premier mammifère pour lequel la communication par vibrations a été observée.
Ce rongeur fouisseur cogne sa tête contre les parois de ses tunnels.
Ce comportement, que l'on pensait tout d'abord faire partie du processus de construction du tunnel, génère des signaux utiles pour la communication avec d'autres rats-taupes sur de longues distances.Certains rongeurs frappent le sol avec leurs pattes pour alerter de la présence d'un prédateur ou pour se défendre.
Ce comportement est principalement utilisé par des rongeurs fouisseurs ou semi-fouisseurs.
Dipodomys spectabilis émet de cette manière différents types de bruits en frappant le sol avec ses pattes, l'un d'eux servant par exemple en cas de rencontre avec un serpent.
Ce bruit peut alerter les congénères et la progéniture de celui qui donne l'alerte, mais repousse de lui-même le prédateur, qui comprend qu'il est repéré,.
Plusieurs études ont montré l'utilisation délibérée des vibrations du sol comme moyen de communication durant la parade nuptiale chez le Rat-taupe du Cap (Georychus capensis).Certaines espèces de rongeurs sont monogames, un mâle et une femelle formant un couple qui dure dans le temps.
La monogamie peut être obligatoire ou facultative.
Dans le premier cas, les deux parents s’occupent de la progéniture, et jouent un rôle important de la survie des jeunes.
C’est par exemple le cas chez la Souris de Californie, la Souris de plage, le Rat sauteur géant de Madagascar et les castors.
Dans ces espèces, les mâles se reproduisent généralement exclusivement avec leurs partenaires.
En plus de permettre une attention plus importante apportée aux jeunes, ce type de monogamie profite aux mâles en leur évitant de rester trop longtemps sans trouver de partenaire, ou de se reproduire avec une femelle infertile.
Dans le cas de la monogamie facultative, les mâles ne s’occupent pas directement des jeunes mais ils restent avec la même femelle car ils n’ont pas accès aux autres du fait d’une grande dispersion des animaux.
Les Campagnols des prairies constituent un exemple caractéristique de ce type de monogamie, les mâles défendant et gardant les femelles situées à proximité d’eux.Chez les espèces polygames, les mâles essaient de monopoliser et de s’accoupler avec plusieurs femelles.
Comme pour la monogamie, on en observe deux formes, une incluant la défense d’un territoire et des femelles l’occupant et l’autre non.
Dans le premier cas, les mâles occupent des territoires qui contiennent des ressources susceptibles d’attirer les femelles.
C’est le cas notamment chez les espèces de la tribu des Marmotini comme la Marmotte à ventre jaune, le Spermophile de Californie, le Spermophile du Columbia et le Spermophile de Richardson.
Dans le cas des marmottes, les mâles qui détiennent un territoire le perdent rarement, et remportent leurs combats contre ceux qui tentent de s’en emparer.
Certaines espèces défendent directement les femelles présentes sur leur territoire, et les combats qui s’ensuivent peuvent causer d’importantes blessures.
Chez les espèces polygames qui ne défendent pas de territoire, les mâles ne sont pas territoriaux et errent à la recherche de femelles.
Ces mâles établissent des hiérarchies entre eux, le mâle le plus dominant ayant accès au plus grand nombre de femelles.
C’est le cas chez des espèces comme le Spermophile de Belding et certains écureuils arboricoles.Enfin, chez d’autres espèces, mâles et femelles ont des partenaires multiples.
Chez des espèces comme la Souris à pattes blanches, les femelles donnent naissance à des portées d’animaux ayant différents pères.
Ce type de comportement conduit à une plus grande compétition spermatique et les mâles tendent à avoir de plus grands testicules.
Chez l'Écureuil de terre du Cap, les testicules du mâle peuvent représenter 20 % de la longueur de son corps (queue exclue).
Plusieurs espèces de rongeurs ont des systèmes de reproduction qui peuvent varier entre les différents types de comportements cités auparavant : monogamie, polygamie et promiscuité.Les femelles rongeurs jouent un rôle actif dans le choix de leur partenaire.
Leur préférence se fait suivant différents critères, qui peuvent comprendre la taille, la dominance et la taille du territoire du mâle.
Chez les Rats-taupes nus, une seule femelle s'accouple avec au moins trois mâles.Pour la plupart des espèces de rongeurs, comme les Rats bruns et les Souris communes, l’ovulation a lieu à cycles réguliers, tandis que pour d’autres, comme les campagnols, elle est induite par la copulation.
Durant l'accouplement, les mâles de certaines espèces de rongeurs déposent un bouchon spermatique dans les voies génitales de la femelle, à la fois pour éviter la fuite de sperme et pour prévenir le fait que d’autres mâles pourraient ensuite inséminer la femelle.
Les femelles peuvent retirer ce bouchon, mais doivent pour cela le faire immédiatement ou après quelques heures.Les rongeurs peuvent naître nidicoles (aveugles, sans poils et relativement peu développés) ou nidifuges (en partie munis de fourrure, les yeux ouverts et assez bien développés) selon l’espèce.
Le stade nidicole est caractéristique des écureuils et des souris, tandis que les cochons d’Inde et les porcs-épics sont nidifuges.
Les femelles qui ont des jeunes nidicoles construisent généralement des nids bien aménagés avant de donner naissance à leur progéniture, et les maintiennent jusqu’au sevrage de celle-ci.
La femelle donne naissance à ses petits en position assise ou couchée, et les nouveau-nés naissent dans la direction vers laquelle elle regarde.
Les nouveau-nés sortent pour la première fois du nid quelques jours après avoir ouvert leurs yeux et dans un premier temps ils y retournent très régulièrement.
Au fur et à mesure qu’ils grandissent, ils rentrent de moins en moins souvent au nid, avant de le quitter définitivement au moment du sevrage.Chez les espèces nidifuges, les femelles ne construisent qu’un nid sommaire, voire pas de nid du tout.
La femelle donne naissance à ses petits en se tenant debout, et ceux-ci naissent derrière elle.
Elle garde contact avec ses petits qui sont déjà très mobiles par de petits cris caractéristiques.
Bien que relativement indépendants et pouvant être sevrés au bout de quelques jours, les jeunes peuvent continuer à être soignés et nourris par leur mère un peu plus longtemps.
La taille des portées chez les rongeurs varient beaucoup, et de façon générale les femelles avec de petites portées passent plus de temps dans le nid que celles qui ont de grandes portées.Les femelles rongeurs s’occupent de leurs petits directement en les allaitant, les soignant et les récupérant quand ils sortent du nid, et indirectement en attrapant de la nourriture, bâtissant le nid et les protégeant.
Chez plusieurs espèces sociales, les jeunes peuvent être élevés par des animaux autres que leurs parents, une pratique connue sous le nom de reproduction communautaire.
C’est notamment le cas chez le Chien de prairie à queue noire et le Spermophile de Belding, où les femelles ont des nids communs et ne font pas la différence entre leurs petits et les autres.
On ne sait pas réellement si les femelles peuvent distinguer leur propre progéniture dans ce cas.
Dans le cas du Mara, les jeunes sont aussi placés dans des garennes communes, mais les femelles n’allaitent pas les petits qui ne sont pas issus de leur portée.Les infanticides existent chez diverses espèces de rongeurs et peuvent être causés par des congénères adultes des deux sexes.
Plusieurs raisons peuvent expliquer ce comportement, parmi lesquelles un stress nutritionnel, la compétition pour les ressources et, dans les cas des mâles, permettre à la femelle de devenir réceptive sexuellement plus rapidement.
Cette dernière raison, si elle est largement reconnue chez les primates et les lions, ne fait pas l’unanimité pour les rongeurs.
Les infanticides sont très fréquents chez les Chiens de prairie à queue noire, et sont notamment le fait de mâles envahissant le territoire, ou de femelles s’y installant, mais peuvent aussi prendre la forme d’un cannibalisme de leur propre progéniture.
Pour se prémunir des infanticides par les autres adultes, les femelles rongeurs peuvent éviter ou attaquer directement les adultes potentiellement dangereux pour leur portée, s’accoupler avec différents mâles ou défendre leur territoire.
Des fœticides peuvent également avoir lieu chez les rongeurs ; chez la Marmotte des Alpes, les femelles dominantes ont tendance à empêcher le bon déroulement du cycle de reproduction de leurs subordonnées en les agressant alors qu’elles sont en gestation.
Le stress qui en résulte cause parfois l’avortement du fœtus.Les rongeurs sont l'un des groupes de mammifères les plus répandus, étant présents sur tous les continents à l'exception de l'Antarctique.
Ils sont les seuls mammifères placentaires terrestres qui aient colonisé l'Australie et la Nouvelle-Guinée sans l'intervention humaine.
L'humain a cependant introduit des espèces, comme le Rat polynésien (Rattus exulans), sur de nombreuses îles océaniques isolées.
Les rongeurs se sont adaptés à presque tous les habitats terrestres, de la toundra froide (où ils peuvent vivre sous la neige) aux déserts chauds.
Certaines espèces comme les écureuils et les porcs-épics du Nouveau Monde sont arboricoles, tandis que d'autres, tels que les gaufres à poche et les rats-taupes, mènent une vie presque entièrement souterraine, où ils construisent des réseaux de galeries complexes.
D'autres vivent sur la surface, mais ont un terrier dans lequel ils peuvent se retirer.
Les castors et les rats musqués sont semi-aquatiques, mais le rongeur le plus adapté à la vie aquatique est probablement le rat Crossomys moncktoni de Nouvelle-Guinée.
Les rongeurs prospèrent également dans certains environnements créés par l'homme, tels que les zones cultivées et urbaines.Bien que certaines espèces soient des nuisibles pour l'humain, les rongeurs jouent aussi un rôle écologique important, et certains rongeurs sont considérés comme des espèces clé de voûte ou ingénieures de leurs habitats respectifs.
Dans les Grandes Plaines d'Amérique du Nord, les terriers des chiens de prairie jouent un rôle important dans l'aération du sol et dans la redistribution des éléments nutritifs, augmentant la teneur en matière organique du sol ainsi que l'absorption d'eau.
Ils maintiennent ces prairies, et quelques grands herbivores comme le Bison d'Amérique du Nord (Bison bison) et l'Antilope d'Amérique (Antilocapra americana) préfèrent paître près des colonies de chiens de prairie en raison de la qualité nutritionnelle accrue des pâturages.
Les chiens de prairie peuvent toutefois également contribuer à la perte de la biodiversité locale et régionale, par leur déprédation des semences et la création et la propagation d'arbustes envahissants.
Les terriers des rongeurs peuvent manger les sporophores de champignons et propager leurs spores dans leurs excréments, ce qui permet aux champignons de se disperser et de former des relations symbiotiques avec les racines des plantes (qui, généralement, ne peuvent pas prospérer sans eux).
Ainsi, ces rongeurs peuvent jouer un rôle dans le maintien de forêts saines.
Dans de nombreuses régions tempérées, les castors jouent un rôle essentiel pour l'hydrologie, leurs constructions de barrages et huttes modifiant le cours des ruisseaux et rivières, et en générant de grandes zones humides.
Une étude a estimé que l'action des castors augmentait d'un tiers le nombre d'espèces de plantes herbacées à proximité des rivières, une autre que la présence des castors augmentait les effectifs de populations de saumons sauvages.D'après Carleton (1984), il existe plus de 2000 espèces vivantes classées en 30 familles, mais aujourd'hui au XXIe siècle, il n'y en a plus qu'un peu plus de 1700.Liste de sous-ordres et familles selon Mammal Species of the World (version 3, 2005)  (8 octobre 2012) :Selon Paleobiology Database (20 mars 2015), l'ordre contient les groupes fossiles suivants :Les rongeurs ne sont pas l'ordre de mammifères le plus menacé, néanmoins 168 espèces appartenant à 126 genres sont dans une situation préoccupante sans que cela n'attire l'attention du grand public.
Comme 76 % des genres de rongeurs ne comprennent qu'une seule espèce, une large diversité phylogénétique peut disparaitre avec l'extinction de seulement quelques espèces.
En l'absence de connaissances très précises sur les espèces menacées, les efforts de sauvegarde portent sur des taxa supérieurs (sur les familles plutôt que sur les espèces par exemple) et sur des zones géographiques à risque.
Plusieurs espèces d'Oryzomys ont disparu depuis le XIXe siècle, probablement du fait de la perte de leur habitat, et de l'introduction d'espèces invasives.
En Colombie, Sphiggurus vestitus n'a été observé que dans deux zones montagneuses dans les années 1920, tandis que Santamartamys rufodorsalis est connu uniquement aux abords de sa localité type sur la côte des Caraïbes, ces espèces sont donc particulièrement vulnérables.
La Species Survival Commission de l'UICN a écrit « Nous pouvons conclure avec certitude que plusieurs rongeurs sud-américains étaient sérieusement menacés, principalement du fait de perturbations environnementales et de la chasse intensive ».Trois espèces de rongeurs commensales de l'Homme se sont dispersées au travers du monde en suivant les déplacements humains, notamment dans les bateaux au moment de la période des Grandes découvertes, causant divers dommages aux espèces locales.
Ce sont le Rat brun, le Rat noir et la Souris commune, et on peut également ajouter à cette liste le Rat polynésien (Rattus exulans) dans le Pacifique.
Par exemple, après que le Rat noir arrive sur l'Île Lord Howe en 1918, plus de 40 % des espèces d'oiseaux terrestres de l'île, dont la sous-espèce de Rhipidure à collier endémique de l'île Rhipidura fuliginosa cervina, vont disparaître dans les 10 années suivantes.
Des extinctions d'espèces similaires ont été observés sur les Îles Midway (1943) et la Grande île du cap Sud (1962).
Les programmes de sauvegarde de nombreuses espèces insulaires passent par l'éradication de ces rongeurs nuisibles, notamment en utilisant des rodenticides anticoagulants comme le brodifacoum.
Cette méthode a été fructueuse sur l'île de Lundy au Royaume-Uni, où l'éradication d'environ 40 000 Rats bruns a permis aux populations de Puffin des Anglais et de Macareux moine d'augmenter à nouveau,.Les Hommes utilisent depuis très longtemps les peaux d'animaux pour se vêtir, car le cuir est solide et la fourrure forme une couverture externe isolante.
Les peuples indigènes d'Amérique du Nord utilisent à cette fin les peaux de castors, les tannant et les cousant ensemble pour faire des robes.
Les Européens apprécient particulièrement la qualité de ces dernières, et le commerce nord-américain de la fourrure se développe et prend une importance majeure pour les premiers colons.
En Europe, la douce couche de poils de jarre connue comme « laine de castor » était considérée comme idéale pour fourrer les vêtements, et permettait également de faire des chapeaux,.
Plus tard, le ragondin devient une source de fourrure meilleur marché et est élevé en grand nombre en Amérique et en Europe.
Le changement des modes et l'arrivée de nouveaux matériaux a conduit cette branche de l'industrie de la fourrure animale à régresser depuis.
Le chinchilla a une fourrure douce et soyeuse et la demande pour celle-ci est devenue tellement importante qu'il a failli totalement disparaître à l'état sauvage avant que son élevage ne se développe et devienne la principale source de peaux.Au moins 89 espèces de rongeurs, la plupart appartenant aux Hystricomorpha comme le cochon d'Inde, les agoutis et les capybaras, sont consommés par l'Homme.
En 1985, il y avait au moins 42 sociétés différentes dans lesquelles on mangeait les rats.
Les cochons d'Inde sont élevés pour la consommation humaine depuis très longtemps.
J.-C., ils constituent la principale source de viande de l'empire Inca.
Les loirs étaient élevés par les Romains dans des pots spéciaux appelés « gliraria », ou dans de grands enclos extérieurs, où ils étaient engraissés avec des noix et des glands.
Les loirs étaient également capturés à l'état sauvage à l'automne, quand ils étaient le plus gras, et étaient rôtis et plongés dans le miel ou cuits farcis avec un mélange de porc, de pignons de pin et de divers aromates.
Des recherches ont montré qu'en Amazonie, dans les zones où les grands mammifères étaient rares, les pacas et agoutis représentaient environ 40 % de l'ensemble du gibier pris annuellement par les indigènes, mais dans les régions forestières où le grand gibier était prépondérant ils ne représentaient plus que 3 % des prises.Les cochons d'Inde sont utilisés dans la cuisine à Cuzco, au Pérou, dans des plats comme le cuy al horno,.
Le traditionnel four andin, connu sous le nom de qoncha ou fogón, est fait de boue et d'argile et renforcé avec de la paille et des poils d'animaux comme les cochons d'Inde.
Au Pérou, on compte 20 millions de cochons d'Inde domestiques et 64 millions de carcasses sont produites chaque année pour la consommation humaine.
Cet animal est une excellente source de nourriture, la chair étant constituée de 19 % de protéines.
Aux États-Unis, les écureuils, mais aussi les rats musqués, les porcs-épics et les marmottes sont consommés par l'Homme.
Les Navajos mangent les chiens de prairie cuisinés dans la boue, tandis que les Paiutes consomment les géomys, les écureuils et les rats.Les rongeurs, dont les Cochons d'Inde, les souris, les rats, les hamsters, les gerbilles, les chinchillas, les octodons et les tamias, peuvent constituer des animaux de compagnie faciles à conserver dans de petits espaces, chaque espèce ayant ses atouts et ses contraintes.
La plupart sont gardés dans des cages de taille adaptée, et ils ont des exigences en termes d'espace et d'interactions sociales diverses suivant les espèces.
S'ils sont domestiqués très jeunes, ils sont généralement dociles et ne mordent pas.
Les Cochons d'Inde ont une grande longévité et ont besoin d'une grande cage.
Les rats ont aussi besoin de beaucoup d'espace et peuvent devenir très dociles, apprendre des tours et sembler apprécier la compagnie de l'Homme.
Les souris ont une durée de vie courte mais ont besoin de très peu d'espace.
Les hamsters sont solitaires mais ont tendance à être plutôt actifs de nuit.
Ils ont des comportements intéressants, mais s'ils ne sont pas manipulés fréquemment ils peuvent être agressifs.
Les gerbilles ne sont généralement pas agressives, mordent rarement et sont des animaux sociables qui aiment la compagnie de l'Homme et de leurs congénères.Les rongeurs sont régulièrement utilisés comme modèle lors de test sur les animaux en laboratoire,.
Les rats albinos sont pour la première fois utilisés dans des expériences en 1828, et deviennent par la suite le premier animal domestiqué pour des raisons purement scientifiques.
De nos jours, la Souris commune est le rongeur le plus fréquemment utilisé en laboratoire, et en 1979 on estime que 50 millions de ces animaux sont utilisés annuellement à travers le monde.
Elles sont préférées du fait de leur petite taille, de leur fertilité, de leur courte durée de gestation et de la facilité avec laquelle on peut les manipuler.
Par ailleurs elles sont intéressantes car elles sont sensibles aux infections qui affectent l'Homme.
Elles sont utilisées dans des recherches concernant la génétique, la biologie du développement, la biologie cellulaire, l'oncologie et l'immunologie.
Les Cochons d'Inde étaient également largement utilisés dans les laboratoires jusqu'à la fin du XXe siècle ; environ 2,5 millions de Cochons d'Inde sont ainsi utilisés dans les laboratoires des États-Unis dans les années 1960, mais ce nombre décroit pour ne plus représenter que 375 000 animaux au milieu des années 1990.
En 2007, ils constituent 2 % de tous les animaux de laboratoire.
Les Cochons d'Inde ont joué un rôle majeur dans l'établissement de la théorie microbienne à la fin du XIXe siècle, à travers les expériences de Louis Pasteur, d'Émile Roux et de Robert Koch.
Ils ont été lancés en orbite dans l'espace plusieurs fois — la première fois par l'URSS dans le satellite Spoutnik 9 le 9 mars 1961, avec un retour fructueux.
Le Rat-taupe nu est le seul mammifère connu à être poïkilotherme ; il est utilisé pour des études sur la thermorégulation.
Il se caractérise aussi par l'absence de production du neuro-transmetteur substance P, un fait qui intéresse les chercheurs travaillant sur la douleur.Les rongeurs ont un odorat très développé, qui est utilisé par l'Homme pour détecter des odeurs ou des molécules chimiques.
Le Cricétome des savanes est ainsi capable de détecter le bacille de la tuberculose avec une sensibilité atteignant 86,6 %, et une spécificité (détectant l'absence de bacille) de plus de 93 % ; cette même espèce peut être entraînée pour détecter les mines,.
Les rats peuvent être utilisés dans des situations périlleuses comme dans les zones de désastres.
Ils peuvent être entraînés à répondre à des ordres, qui peuvent être donnés à distance, et même être persuadés de s'aventurer dans des zones très éclairées, que les rats évitent normalement,,.De par leurs préférences alimentaires et leurs modes de vie (souvent fouisseurs), les rongeurs sont en concurrence avec l'Homme pour une partie de ses activités (culture, sylviculture).
Certaines espèces introduites hors de leur milieu sont devenues invasives et sources de dégâts (rat musqué, ragondin, écureuil gris par exemple, quand ils ont été introduits en Europe).
Les gros rongeurs ne sont pas sources de pullulations, mais en raison de leur taille font des dégâts parfois spectaculaires.
Les petits rongeurs qui se reproduisent très rapidement peuvent périodiquement pulluler et alors causer des dommages importants dans les champs, forêts, entrepôts alimentaires,.
Par exemple, en 2003, les quantités de riz perdues car consommées par des souris et des rats en Asie représentaient selon des estimations la quantité nécessaire pour nourrir 200 millions de personnes.
La plupart des dégâts causés à travers le monde sont le fait d'un petit nombre d'espèces, principalement des rats et des souris.
En Indonésie et en Tanzanie, les rongeurs réduisent les rendements des cultures d'environ 15 %, tandis que dans certains cas extrêmes en Amérique du Sud elles sont amputées de 90 %.
En Afrique, des rongeurs comme les Mastomys et Arvicanthis font des dégâts dans les céréales, les noix de terre, les légumes et le cacao.
En Asie, les rats, les souris et certaines autres espèces comme Microtus brandti, Meriones unguiculatus et Eospalax baileyi détruisent une partie des récoltes de riz, sorgho, tubercules, légumes et noix.
En Europe, en plus des rats et des souris, les espèces des genres Apodemus et Microtus ainsi qu'Arvicola terrestris causent de manière épisodique des dégâts dans les vergers, les légumes et les pâtures, aussi bien que dans les céréales.
En Amérique du Sud, une gamme plus importante d'espèces de rongeurs est impliquée, parmi lesquelles Holochilus, Akodon, Calomys, Oligoryzomys, Phyllotis, Sigmodon et Zygodontomys, causant des dommages dans les cultures comme la canne à sucre, les fruits, les légumes et les tubercules.Les rongeurs sont également d'importants vecteurs de maladies.
Le Rat noir, avec la puce qu'il porte, joue un rôle majeur dans la dissémination de la bactérie Yersinia pestis responsable de la peste bubonique et est également un vecteur des organismes responsables du typhus, de la leptospirose, de la toxoplasmose et de la trichinose.
De nombreux rongeurs portent des orthohantavirus, comme ceux de Puumala, de Dobrava ou de Saaremaa, qui peuvent infecter l'homme.
Les rongeurs participent également à transmettre des maladies comme la babésiose, la leishmaniose cutanée, l'anaplasmose humaine, la maladie de Lyme, la fièvre hémorragique d'Omsk, l'encéphalomyélite de Powassan, la rickettsialpox, la fièvre récurrente mondiale, la fièvre pourprée des montagnes Rocheuses et la fièvre du Nil occidental.Étant donné que les rongeurs sont une nuisance et qu'ils mettent en danger la santé publique, les sociétés humaines tentent souvent d'en contrôler la prolifération.
Cela passe généralement par l'empoisonnement et le piégeage de ces animaux, des méthodes qui ne sont pas toujours sûres ou efficaces.
Plus récemment, la lutte intégrée tente d'améliorer le contrôle des populations de rongeurs par une combinaison d'études visant à déterminer la taille et la répartition de la population de nuisibles, l'établissement de seuils de tolérance (niveau d'activité des animaux au-delà duquel il est nécessaire d'intervenir), d'interventions et d'évaluation de l'efficacité de ces interventions à partir d'études régulières.
L'intervention peut comprendre l'éducation des populations, l'application d'une législation adaptée, la modification de l'habitat de ces animaux, la modification des pratiques agricoles et la lutte biologique en utilisant des pathogènes ou des prédateurs, ainsi que l'empoisonnement et le piégeage.
L'utilisation de pathogènes comme Salmonella a le défaut de pouvoir infecter l'Homme et les animaux domestiques, et les rongeurs deviennent souvent résistants.
L'utilisation de prédateurs comme les furets, mangoustes et les varans se montre souvent insatisfaisante.
Les chats domestiques et sauvages peuvent contrôler les populations de rongeurs efficacement, si la population de rongeurs n'est pas trop importante.
La pose d'affûts, de perchoirs et de nichoirs à rapaces est également une méthode de lutte contre la pullulation de nuisibles.
L'antiglobuline est un anticorps dirigé contre une immunoglobuline.
Utilisé en laboratoire comme réactif, il permet de mettre un anticorps en évidence.
L'analyse permettant cette mise en évidence nommée à l'origine « réaction de Coombs » est maintenant appelée « test à l'antiglobuline ».Ce test a été développé par Robin Coombs, Arthur Mourant et Rob Race.L'antiglobuline est obtenue par immunisation d'un animal, un lapin par exemple, par un sérum humain.
Ce sérum humain contient des immunoglobulines.
Pour l'animal, ces immunoglobulines sont antigéniques, et ce lapin synthétisera des anticorps de lapin anti-« immunoglobulines humaines », ce qui permet d'obtenir un sérum de lapin anti-« immunoglobuline-humaine », dit sérum A.G.H.
Cette antiglobuline, d'origine animale, se fixe donc spécifiquement aux épitopes isotypiques des immunoglobulines humaines.Ce test a permis, à l'origine par technique d'agglutination, de mettre en évidence la présence d'immunoglobulines humaines fixées sur les érythrocytes.
Cette technique est utilisée pour reconnaître spécifiquement une classe d'immunoglobulines, IgG, IgA, IgM (il s'agit dans ce cas d'une antiglobuline), ou des fractions du Complément, C4, C3b, C3c et C3d en particulier (il ne s'agit plus alors d'une antiglobuline stricto sensu, mais d'anti-compléments), susceptibles d'être fixées sur les érythrocytes.
On utilise alors soit une A.G.H dite polyspécifique (anti-IgG + C3d) -pour un dépistage d'anticorps, soit des antiglobulines spécifiques (anti-IgG, anti-IgA, anti-IgM), associées à des anti-compléments (C3c et C3d) -pour un diagnostic d'anémie hémolytique, par exemple.Le test direct à l'antiglobuline (en France T.D.A.
ou réaction de Coombs directe -R.C.D., en Belgique : Coombs direct) anciennement appelé réaction de Coombs directe (RCD), qui permet de mettre en évidence la présence d'anticorps fixés sur les érythrocytes.
Ce test est utilisé pour le diagnostic de la maladie hémolytique du nouveau-né, et dans le diagnostic des anémies hémolytiques auto-immunes, ou des incompatibilités transfusionnelles.Dans ces cas, les érythrocytes sont déjà recouverts par des anticorps humains qui sont insuffisants pour provoquer à eux seuls l'agglutination.
Ces érythrocytes sont appelés globules rouges sensibilisés (en France G.R.S.).
Ces globules rouges doivent être "lavés", c'est-à-dire débarrassés du plasma les entourant, et remis en suspension dans une solution saline ne contenant plus d'anticorps non fixés qui neutraliseraient l'antiglobuline (cette étape de lavage peut être maintenant évitée par une technique de filtration sur gel).
L'ajout de l'antiglobuline à ces globules rouges sensibilisés et "lavés" provoque alors l'agglutination.
Ce test sert également à vérifier s'il y a eu fixation in vivo (dans l'organisme) du complément, ce qui cause l'hémolyse du globule rouge, ou à déterminer les classes (ou sous-classes si besoin) des molécules d'immunoglobulines fixées sur les globules rouges étudiés.
Ce test doit souvent être complété par une technique d'élution, parfois plus sensible, qui permet également de mettre en évidence un anticorps fixé sur les hématies, en particulier pour la mise en évidence d'une incompatibilité fœto-maternelle ABO, ou d'une incompatibilité transfusionnelle récente.Le test indirect à l'antiglobuline (en France T.I.A.
anciennement appelé « réaction de Coombs indirecte », -R.C.I., en Belgique Coombs indirect) qui permet de mettre en évidence un anticorps irrégulier non agglutinant dans un sérum ou un antigène de groupe sanguin sur des érythrocytes.Dans le premier cas il s'agit d'une recherche d'agglutinine irrégulière (en France R.A.I.).
La mise en présence d'un sérum ou d'un plasma inconnu et d'érythrocytes portant des antigènes connus permet la fixation des anticorps recherchés sur ces érythrocytes et de les sensibiliser.
Dans un second temps, l'action de l'antiglobuline permettra la mise en évidence de cette éventuelle sensibilisation.
Si la réaction est positive, c'est que des anticorps ont été fixés sur ces érythrocytes, et étaient donc présents dans le sérum ou plasma objet de la recherche d'agglutinine irrégulière.Ce même test est également utilisé pour réaliser l'épreuve de compatibilité (cross matching, en anglais), qui consiste à tester le sérum ou plasma du malade avec un échantillon des érythrocytes du concentré érythrocytaire que l'on envisage de transfuser.
Si la réaction est positive, c'est qu'il existe un anticorps vis a vis des globules du donneur, et que la transfusion envisagée est incompatible, sans que l'on sache quel système de groupe sanguin est en cause.
Une autre unité de sang devra donc être choisie, et, bien sûr, testée.Dans le second cas, la mise en présence d'un anticorps connu, il s'agit alors d'un sérum test, avec des érythrocytes inconnus permet la mise en évidence de l'antigène correspondant sur ces érythrocytes.
Il s'agit de la détermination d'un phénotype de groupe sanguin.Depuis ce test s'est généralisé et permet de mettre en évidence une immunoglobuline humaine dans tout liquide ou fixée spécifiquement sur tout support.
Soit par des techniques utilisant des globules rouges sensibilisés comme révélateur, techniques d'inhibition ou de consommation d'antiglobuline utilisée pour la détermination des groupes Gm, Km, ISf, Am, soit par une antiglobuline marquée, ce qui permet de déceler sa présence, c’est-à-dire sa fixation spécifique sur les immunoglobulines humaines.Les anticorps anti-D humains (l'anticorps doit être d'origine humaine, doit être incomplet, relativement fréquent pour pouvoir obtenir le maximum d'épitopes possible sur les diverses sous-classes d'IgG, donner une réaction positive nette, liée au nombre de sites RH concernés, avec l'antiglobuline) d'un sujet de groupe Gm:1,17,21 sont fixés sur des globules rouges Rh+, D.
Nous avons alors des globules rouges sensibilisés, GRS, mais qui ne sont pas agglutinés, l'anti-D étant un anticorps incomplet.
Nous faisons agir sur ces GRS une anti-globuline anti Gm1 (antiglobuline d'origine humaine).
Nous provoquons alors une agglutination.Mélangeons un sérum X à cet anti Gm1 avant de le faire agir sur nos GRS.
Si ce sérum X contient une immunoglobuline de groupe Gm1, l'anti Gm1 va former un complexe antigène-anticorps, et sera consommé, et donc neutralisé.
Il ne pourra agir sur notre GRS, et la réaction sera négative.
Nous en conclurons que notre sérum X est de groupe Gm1, car notre réaction d'agglutination a été inhibée.Si notre sérum X est Gm-1, il ne neutralisera pas notre anti-globuline qui pourra alors se lier à l'anti-D fixé sur nos GRS, et en provoquer l'agglutination.
Voir anticorps irréguliers et potentiel zêta.Cette technique d'inhibition d'agglutination est une technique très sensible, un sérum dilué au 1/100, voire plus, peut inhiber la réaction et permettait, avant la biologie moléculaire, de mettre en évidence l'origine humaine (ou simiesque, nous sommes cousins) d'une tache de sang.Idem pour les anti-Gm2, Gm17, Gm4, Gm... ou anti-Km1... qui permettent de déterminer les groupes sériques d'immunoglobulinesLe principe est le même pour le système Am avec des immunoglobulines de classe A (IgA) soit spécifiques d'un antigène érythrocytaire, soit fixées passivement sur le globule.Ainsi, le test de Coombs plaquettaire, ou test de Dixon, permet grâce à une antiglobuline marquée, de mettre en évidence la sensibilisation des plaquettes par un anticorps, qu'il s'agisse du purpura thrombopénique idiopathique, P.T.I.
ou de la Thrombopénie néonatale par incompatibilité fœto-maternelle.L'antiglobuline peut être marquée par un fluorochrome, elle permet alors par technique d'immunofluorescence la mise en évidence d'anticorps anti-parasites, toxoplasme ou plasmodium en particulier.
Marquée par une enzyme, il s'agit alors d'une technique d'immuno-enzymologie qui permet la mise en évidence d'anticorps anti-virus dont les antigènes spécifiques sont fixés sur un support en plastique (billes ou cupules), anti-hépatite, par exemple.
Marquée à l'iode radioactif, elle entre dans le cadre de la radio-immunologie.
Georges Jean Franz Köhler fréquemment appelé Georges J.F.
Köhler (né le  17 avril 1946 à Munich et mort le 1er mars 1995) à  Fribourg-en-Brisgau) est un immunologiste allemand.Il a reçu, avec César Milstein et Niels Jerne, la même année le Prix Lasker et le prix Nobel de médecine en 1984 pour ses travaux sur le système immunitaire et sur la production d'anticorps monoclonaux.Il devient le directeur l'Institut Max Planck de Fribourg, poste qu'il occupera jusqu'à sa mort.L'astéroïde (11775) Köhler a été nommé en son honneur.
L'hypermutation somatique est un phénomène retrouvé dans la génération de la diversité des immunoglobulines produites par les lymphocytes B. Contrairement à la recombinaison somatique (ou recombinaison VDJ) qui a lieu dans la moelle, le processus d'hypermutation somatique a lieu dans les organes lymphoïdes secondaires.Le lymphocyte B sort de la moelle osseuse sans avoir jamais vu l'épitope que reconnaît son anticorps de membrane (le BCR : B Cell Receptor) : la spécificité et l'affinité du BCR, et par suite de l'anticorps circulant produit, sont donc déterminés avant la rencontre.Pour ajuster ces paramètres à l'antigène initiant une réaction immunitaire à médiation humorale, le clone de lymphocytes B activé va engager un phénomène d'hypermutations somatiques : la recombinaison génétique à l'origine de l'immunoglobuline produite va subir des mutations dans sa séquence qui vont ajuster les régions hypervariables à l'épitope.Les mutations ont lieu sur les segments variables des chaînes légères et lourdes.Ce phénomène participe majoritairement à la modulation de l'affinité de l'anticorps pour son épitope : le lymphocyte B dont l'immunoglobuline de membrane a une faible affinité pour un antigène pourra, sans recruter un autre lymphocyte B, augmenter l'affinité de l'anticorps pour l'antigène.Le processus d’hypermutation somatique dépend de l’activité de l’enzyme AID (activation induced cytidine deaminase)
Le mot lapin (/lapε̃/) est un terme très général qui désigne en français certains animaux lagomorphes à longues oreilles.
On les différencie des lièvres par une silhouette moins élancée et par les petits qui naissent aveugles et nus, cachés dans un nid creusé au sol.
Ces animaux ne correspondent donc pas à un niveau précis de classification scientifique.« Lapin » est en fait un nom vernaculaire ambigu, désignant une partie seulement des différentes espèces de mammifères classées dans la famille des Léporidés, une famille qui regroupe à la fois les lièvres et les lapins.
Longtemps classés dans l'ordre des rongeurs, ils sont maintenant regroupés dans un ordre à part : les Lagomorphes.En employant le terme « lapin », on fait toutefois référence le plus souvent au lapin domestique issu du Lapin de garenne (Oryctolagus cuniculus), l'espèce sauvage d'origine européenne qui s'est répandue un peu partout, puisqu'elle est à la base des multiples races de lapins élevées à présent dans le monde entier, y compris des lapins nains.
Cependant, les lapins ne se limitent pas à cette seule espèce européenne : il existe en effet plus d'une vingtaine d'espèces de lapins sauvages dans le monde, réparties dans neuf genres biologiques, mais dont plusieurs sont menacées d'extinction et protégées au XXIe siècle.Le lapin est un gibier traditionnel, classé en cuisine avec les volailles et il est un mets apprécié dans de nombreux pays .
C'est aussi un animal très présent dans de nombreux domaines culturels.
L'« animal aux longues oreilles » est évoqué dans l'art et la littérature tout autant que dans la culture populaire, la mythologie et la symbolique de plusieurs continents.
De nombreux personnages de fiction célèbres sont des lapins, notamment dans l'univers enfantin.
Le mot « lapin » est par ailleurs utilisé aussi bien comme patronyme que comme marque commerciale.Le substantif masculin,, lapin (prononcé ) est dérivé de lapereau, par changement de suffixe.
Il est attesté au XVe siècle,.Les lapins sont présents un peu partout sur la planète et se répartissent en neuf genres, tous classés dans la famille des léporidés, avec leurs proches parents les lièvres.
Ce ne sont donc pas des rongeurs mais des lagomorphes, une branche cousine qui comprend les lièvres, les lapins et les pikas.Remarque : Les lapins domestiques sont tous issus de l'espèce Oryctolagus cuniculus, qui est à l'origine de toutes les races de lapin sélectionnées en élevage : voir la Liste des races de lapins.Les lapins sont répartis dans les genres suivants de la famille des Leporidae : Brachylagus, Bunolagus, Caprolagus, Nesolagus, Oryctolagus (lapin commun), Pentalagus, Poelagus marjorita, Pronolagus, Romerolagus et Sylvilagus (ou lapins d'Amérique).
C'est-à-dire que les Léporidés sont presque tous des lapins, à l'exclusion du genre Lepus qui rassemble les lièvres.
Sept de ces genres ne comprennent qu'une seule espèce de lapin, on dit que ce sont des genres monospécifiques.
Le genre Nesolagus regroupe deux espèces, le genre Pronolagus en compte trois et le genre  Sylvilagus rassemble quinze espèces, soit au moins 27 espèces différentes de lapins en tout.Les lapins sont des mammifères herbivores.
Leurs caractéristiques générales sont celles des Léporidés, avec des nuances pour chaque espèce : voir les articles détaillés pour plus d'informations sur leur comportement ou leur physiologie respective.Ces mammifères sont des proies plus grosses que la plupart des rongeurs, donc très recherchées par de nombreux carnivores.
Ils tentent en permanence d'échapper à quantité de prédateurs, dont l'homme, grâce à une excellente vue à 360°, leurs grandes oreilles à l'ouïe fine et une morphologie particulièrement adaptée à la course.
Leurs longues et puissantes pattes arrière repliées sous le corps leur permettent en outre de bondir ou de se tenir assis pour observer leur environnement.Le dimorphisme sexuel est peu apparent entre le mâle et la femelle, même si la femelle est de constitution plus fine avec un bassin plus large.
Seul un examen des parties génitales permet de différencier les jeunes individus entre eux.
Toutefois, un fanon - sorte de double menton qui sert de réserve de graisse - est parfois bien visible chez la femelle adulte tandis qu'il est quasi inexistant chez le mâle, à moins d'être atteint d'obésité.Le poids et la taille des lapins adultes varient grandement selon l'espèce biologique : un Lapin pygmée (Brachylagus idahoensis) fait en moyenne 25 cm de long (de 23,5 à 29,5 cm) et pèse 400 g environ (entre 246 et 462 g), tandis qu'un Lapin de garenne (Oryctolagus cuniculus) peut mesurer jusqu'à 50 cm (de 38 à 50 cm) pour un poids maximal de 2,5 kg (de 1,5 à 2,5 kg).
La différence est encore plus considérable si on considère les races d'élevage de lapins domestiques puisqu'une race comme le géant des Flandres peut faire plus de 10 kg à l'âge adulte et même certains individus dépasser les 20 kg pour plus d'un mètre de long.Contrairement aux lièvres, tous les lapins vivent en groupe et creusent des terriers qui peuvent être complexes quand le terrain, ou garenne, est favorable.
Ils se distinguent aussi de leurs cousins lièvres par le fait que les lapereaux naissent nus et aveugles.
Les petits doivent rester cachés dans un nid tapissé du poil ventral de leur mère, creusé à même le sol ou au fond d'un terrier.
Ils sont soignés et allaités par la lapine durant plusieurs semaines, en début et en fin de journée, avant d'être capables de se débrouiller seuls.
Vers deux semaines, ils commencent à grignoter des végétaux puis, vers quatre à cinq semaines, ils suivent leur mère avant de prendre leur indépendance.
Une femelle peut avoir de trois à cinq portées par an, après une durée de gestation qui dure environ un mois.
Le nombre ou le poids à la naissance des lapereaux est très variable en fonction de la taille de la portée et selon les espèces ou les races.Strictement herbivores, les lapins se nourrissent à la belle saison surtout d'herbes diverses et de plantes fourragères.
En hiver, les lapins n'hibernent pas, ils grignotent en revanche un peu tout ce qu'ils peuvent trouver comme végétation comestible.
Le Lapin de Nuttall est même capable de grimper sur des troncs d'arbres inclinés pour trouver un peu de verdure en zone désertique.
Comme tous les léporidés, ils pratiquent la cæcotrophie qui consiste à ingérer certaines de leurs déjections partiellement digérées pour en récupérer les derniers nutriments et micro-organismes.
Les autres crottes forment des groupes de boulettes très sèches, abandonnées sur leurs lieux de pâturage.
Une autre pratique d'hygiène commune avec les lièvres consiste à prendre des bains de poussière dans une dépression du sol, sec et gratté.La stratégie de survie des lapins consiste à rester toujours en vue d'un refuge possible.
De son côté, la hase ne rejoint le nid qu'à l'aube ou au crépuscule, restant loin des lapereaux le reste du temps afin de ne pas signaler ses petits aux prédateurs.
Si l'un des membres de la colonie repère un danger, il ne crie pas mais tape rapidement le sol du pied pour alerter ses congénères, mais quand il est capturé et craint pour sa vie, il pousse un glapissement, sorte de puissant cri aigu.
En cas d'alerte, les lapins sont capables de rester très longtemps immobiles pour passer inaperçus, ne prenant la fuite qu'au dernier moment, en zigzaguant pour dérouter le poursuivant.Ces animaux sont surtout actifs à l'aube et au crépuscule.
Durant le jour, ils se cachent par exemple dans les buissons, sous les souches ou les tas de bois ou encore les vieux bâtiments agricoles.
Ils n'hibernent pas et par grand froid cherchent refuge dans un terrier qu'ils creusent eux-mêmes ou abandonné par un autre animal.Malgré toutes ces précautions, un lapin vit rarement très vieux dans la nature.
Quand ils ne meurent pas en bas âge, dévorés par des serpents et des petits carnivores comme les Mustélidés, les chats, etc. ou bien broyés dans leur nid par les engins agricoles, les adultes sont capturés bien avant d'atteindre un âge avancé par des prédateurs plus costauds (rapaces nocturnes ou diurnes, Canidés, Félins, , etc.).
Les hivers trop rigoureux ou au contraire sans neige suffisante pour s'enterrer leur sont fatals, à moins qu'ils ne soient décimés par les zoonoses.
Les lapins sont également chassés par l'homme ou écrasés le long des routes, si bien que leur espérance de vie moyenne est d'une année dans la nature, même s'ils peuvent vivre deux ans ou plus en théorie.Pour leur part, les lapins domestiques de compagnie peuvent vivre une dizaine d'années, s'ils sont bien soignés.
Certains individus battent des records de longévité en dépassant une quinzaine d'années.
Les lapins ont une capacité de reproduction importante avec plusieurs portées par an de plusieurs petits.
Certaines espèces peuvent même se montrer très envahissantes quand les conditions leur sont favorables.
Avec cinq portées par an pouvant compter chacune jusqu'à douze petits, on a calculé que la descendance théorique d'un seul couple de lapins de garenne pourrait atteindre le chiffre de 1 848 individus à la première génération, si tout facteur de mortalité précoce était écarté.
C'est ainsi que 24 lapins de garenne introduits en 1874 ont suffi à submerger l'Australie qui a compté jusqu'à trente millions d'individus, faute de prédateurs et de virus pour limiter leur prolifération.Même dans le cas d'une espèce volontairement introduite et qui se reproduit modérément, celle-ci peut perturber l'écosystème.
Elle peut être un vecteur de maladies, ou de parasites, et occuper la niche écologique des espèces indigènes en causant notamment des dégâts sur la végétation.
Ce fut par exemple le cas lors des essais d'introduction en Europe de lapins américains (Sylvilagus sp.)
et en particulier du Lapin de Floride (Sylvilagus floridanus).
En 1989, l'Union européenne a finalement mis fin à l'expérience en préconisant l'éradication totale des spécimens survivants déjà introduits.Toutefois, les maladies comme la myxomatose ou la fièvre hémorragique virale, la réduction ou la dégradation de leur habitat naturel, que ce soit sous l'action de l'homme ou des changements climatiques, ou bien la chasse excessive ont progressivement réduit certaines populations de lapins, faisant craindre la disparition locale ou totale de bon nombre d'espèces.
Le Lapin riverin par exemple a perdu 60 % de ses effectifs entre 1990 et 2010 environ, par perte de son habitat.
Or ces léporidés font partie des espèces clé de voûte, d'importance vitale pour bon nombre de prédateurs qui se retrouvent affectés par leur déclin.
Même le prolifique Lapin de garenne est menacé dans sa péninsule Ibérique d'origine depuis la fin du XXe siècle, à cause de l'épidémie de fièvre hémorragique, mettant en danger du même coup le Lynx ibérique (Lynx pardinus) ainsi que l'Aigle ibérique (Aquila adalberti).
On comprend donc les enjeux qu'il y a à mettre en place des mesures de protection de ces animaux comme le préconise l'Union internationale pour la conservation de la nature (IUCN).Le lapin domestique est la forme domestiquée du Lapin de garenne (Oryctolagus cuniculus) et le Lapin nain un lapin domestique de moins de 2 kg.Pour le nom des races de lapins domestiques voir la Liste des races de lapins.Liste alphabétique de noms vernaculaires attestés en français.Note : Cette liste exclut les races de lapins domestiques.
Certaines espèces ont plusieurs noms et, les classifications évoluant encore, certains noms scientifiques ont peut-être un autre synonyme valide.
En gras, les espèces les plus connues des francophones.La dénomination qui peut désigner ces animaux change selon les cas :Le terme lapin est le terme générique le plus utilisé.
Il pourrait venir de « lapereau » et dériver d'une interférence entre le terme « laper » (manger avec avidité) et de « levraut » (petit lièvre), ce dernier provenant de « lapriel » (du latin : leporellus, levraut).Avec un ou deux N, le terme con(n)in ou con(n)il, au féminin con(n)ille, désigne le lapin dans les textes anciens, il dérive du latin cuniculus, mot d'origine ibérique.
On retrouve cette racine ancienne dans le castillan conejo, le portugais coelho, le catalan conill, l'italien coniglio, l'occitan conilh (qui coexiste avec lapin), le breton konifl, l'alsacien Kénjele, le néerlandais konijn ou l'allemand Kaninchen.
Ce terme a été remplacé en français, probablement au XIVe siècle, par celui de « lapin ».
De même en anglais le terme ancien coney a fait place à rabbit au XVIIIe siècle.La femelle du lapin domestique est la « lapine » (/lapin/), tandis que la « hase » est celle du lapin de garenne, comme pour le lièvre.
Le « bouquin » ou « bouquet » désigne le mâle lapin comme le lièvre (rare) et le « lapereau » est leur petit.
« Lapiner » veut dire mettre bas.Le cri de détresse du lapin se dit clapir (clapissement), glapir (glapissement), ou couiner (couinement).Une « garenne » était autrefois une zone de chasse gardée pour le seigneur et désigne à présent l'espace où les lapins creusent leur terrier dans la nature, une « lapinière » est un élevage de lapins et un « clapier » un ensemble de cages à lapins.La « cuniculture » désigne l'élevage du lapin domestique.Le lapin a été domestiqué tardivement au XVe siècle, c'est le seul animal d'élevage originaire d'Europe.Le lapin domestique est exclusivement issu de la domestication d'une seule espèce : le Lapin de garenne (Oryctolagus cuniculus).
Son élevage, appelé cuniculture, s'est développé à partir du Moyen Âge.À lui seul Oryctolagus cuniculus est à l'origine des multiples races de lapins domestiques élevées à présent dans le monde entier mais stabilisées uniquement à partir de la seconde moitié du XIXe siècle.Ces diverses races ont été progressivement développées grâce à l'élevage sélectif de ces animaux par l'homme.
Elles présentent une très vaste gamme de tailles et de couleurs de robe et sont chacune adaptée à l'un de ces usages.
Les grandes races (de 5 à 7 kg et plus) étaient destinées à la production de viande, bien que négligées par la suite dans l'élevage industriel.
Les races moyennes (de 2,5 à 5,5 kg maximum) et petites races (idéalement de 2 à 3,5 kg) sont exploitées selon leurs qualités respectives, notamment les races à pelage spécial pour la fourrure ou le tissage (angora).
Enfin, les races « naines » (de 0,8 à 2 kg maximum) sont généralement utilisées comme animal de compagnie.Chaque année, 320 millions de lapins sont élevés pour leur viande en Europe, et 99 % d’entre eux sont enfermés en cage.Les conditions d’élevage sont parfois contestées : « Les cages les empêchent d’exprimer leurs comportements naturels, comme se mettre debout, faire des bonds, creuser, ronger, et leur causent des blessures et un stress permanent », selon le CIWF France.
Les lapins d'élevage passent leur vie entière en cage, dans des espaces étroits : ils naissent dans de petites cages grillagées hors-sol et y restent jusqu’à leur mort, soixante à quatre-vingts jours plus tard.
Les lapines reproductrices sont quant à elles maintenues isolées et confinées pendant 13 à 24 mois jusqu’à leur abattage.
Compte tenu des zoonoses inhérentes à la fois à l’espèce et à ce mode d’elevage, le recours aux produits vétérinaires, dont les antibiotiques est fréquent (les lapins sont les animaux les plus exposés à ces médicaments, devant les volailles et les porcs).Les lapins sauvages de toutes espèces sont chassés (ou braconnés) depuis toujours pour leur chair très largement appréciée, dont rôtie, en pâté ou en civet.L'élevage familial en clapier a été pratiqué dès l'an 1000, puis s'est intensifié avec l'apparition de l'élevage industriel.
Son but premier était la production de viande, mais il permet également la production de poils et de fourrures.Par ailleurs, les lapins sont depuis plusieurs décennies et aujourd'hui encore employés comme modèles dans les laboratoires, pour tester l'innocuité de divers produits cosmétiques notamment, ou par exemple pour tester la reprotoxicité ou toxicité cellulaire de certains métaux tels que le cuivre,.Les lapins (souches nanifiées notamment) peuvent également devenir des animaux de compagnie, du fait de leur caractère placide.
Le marché du lapin nain, notamment, se développe à la fin du XXe siècle et en 2003 c'est le petit mammifère préféré des Français.Leur peau a actuellement une valeur économique moindre que dans le passé où elle donnait lieu à un commerce traditionnel, récupérée par les chiffonniers, dits aussi « marchands de peaux de lapins » qui passaient à domicile collecter les peaux issues des élevages familiaux.
Elle forme une colle réputée la colle de peau de lapin.L'introduction d'une nouvelle espèce de lapin dans des contrées où ils n'ont pas de prédateur, comme le lapin de garenne, d'origine européenne, provoqua en Australie de nombreux dégâts écologiques et en fait une espèce invasive difficile à contenir.Le lapin, sans référence à aucune espèce  précise, est très présent dans la culture populaire et enfantine, ainsi que dans la mythologie.
Le lapin est aussi fortement associé à la fête de Pâques.Redouté par les marins qui ne prononcent jamais son nom, sous peine de porter malheur, et le désignent par des périphrases comme « l'animal aux longues oreilles », « cousin du lièvre », il est au contraire adopté comme symbole dans des cultures et des professions très diverses, un peu partout dans le monde.L'univers du marketing s'en est également emparé, créant des mascottes célèbres.
Le multimédia est également touché, notamment avec les lapins crétins d'Ubisoft.Dans les jeux vidéo, les lapins peuvent être des ennemis.
Dans Super Mario Odyssey par exemple, les Broodals, des lapins aux différentes formes, sont les minis boss du jeu.
On peut aussi les trouver dans des productions indépendantes comme Braid, créé par Jonathan Blow, où les lapins tueront le joueur au premier contact.Dans la littérature, Richard Adams fait des lapins les protagonistes de son roman Watership Down, et détaille leur société inventivement.
Toutefois, Lewis Carroll avait déjà mis en scène des lapins, dans son roman Alice au Pays des Merveilles, qui remplissaient les rôles de laquais au service de la Reine de Cœur.En motifs, en peluches ou en personnages de fiction, les lapins font partie des classiques de l'univers enfantin, notamment Bugs Bunny, personnage célèbre et mascotte de la compagnie Warner Bros.
Un auto-anticorps est un anticorps produit par le système immunitaire et dirigé contre une ou plusieurs protéines de l'individu lui-même.
De nombreuses maladies auto-immunes sont dues à la présence de ces auto-anticorps, mais la présence d'auto-anticorps n'est pas nécessairement synonyme d'une telle maladie.
En 2003, on recensait plus de deux cents spécimens antigéniques différents.On distingue cinq grandes classes d'auto-anticorps selon leurs antigènes cibles spécifiques comme certaines molécules (ADN, ARN, RNP, SRP, phospholipides, etc.), protéines ou enzymes (synthétases, protéinases, myéloperoxydases, histones, topoisomérases, récepteurs, etc.), structures intracellulaires (cytoplasme, noyau, nucléole, centromère, etc.), tissus et organes.Exemples d'auto-anticorps :
